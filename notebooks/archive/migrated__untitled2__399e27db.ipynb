{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b252c034-fa63-4593-b005-a093adf00768",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_564\\4264759999.py:179: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u2192' in position 229: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mUnicodeEncodeError\u001b[39m                        Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 234\u001b[39m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUTDIR/\u001b[33m\"\u001b[39m\u001b[33mresults.json\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: json.dump(results, f, indent=\u001b[32m2\u001b[39m)\n\u001b[32m    210\u001b[39m summary = \u001b[33mf\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[33mCNT One-Cell Groundbreaker — Blind Cross-Domain Test\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[33m====================================================\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    232\u001b[39m \u001b[33mArtifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m234\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUTDIR/\u001b[33m\"\u001b[39m\u001b[33msummary.txt\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: f.write(textwrap.dedent(summary))\n\u001b[32m    236\u001b[39m \u001b[38;5;28mprint\u001b[39m(summary.strip())\n\u001b[32m    237\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mArtifacts saved to:\u001b[39m\u001b[33m\"\u001b[39m, OUTDIR)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1252.py:19\u001b[39m, in \u001b[36mIncrementalEncoder.encode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     18\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mencode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcodecs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcharmap_encode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43mencoding_table\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mUnicodeEncodeError\u001b[39m: 'charmap' codec can't encode character '\\u2192' in position 229: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "# CNT One-Cell Groundbreaker: blind human→mouse transfer with prereg + permutation test\n",
    "# Files (optional): /mnt/data/HUMAN_EEG.csv and /mnt/data/MOUSE_EEG.csv\n",
    "# CSV shape: rows=time samples, cols=channels, plus 'label' (0/1). Assumes 4 s epochs @ 128 Hz.\n",
    "# Artifacts: /mnt/data/CNT_OneCell_Groundbreaker/{results.json,summary.txt,transfer_roc.png,perm_null.png}\n",
    "\n",
    "import os, json, textwrap\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "OUTDIR = Path(\"/mnt/data/CNT_OneCell_Groundbreaker\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    mask = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[mask].sum(axis=0), freqs, S\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    mask = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[mask] = F[mask]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C, xb\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k=8):\n",
    "    rng_local = np.random.default_rng(12345)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def glyph_invariant_feature(X, fs, band=(8,12), k=8):\n",
    "    C, _ = _cov_band(X, fs, band)\n",
    "    A = _orthobasis(C.shape[0], k=k)\n",
    "    ACAt = A.T @ C @ A\n",
    "    return float(np.linalg.norm(ACAt, 'fro') / (np.linalg.norm(C, 'fro') + 1e-9))\n",
    "\n",
    "def baseline_features(X, fs, bands=[(1,4),(4,8),(8,12),(12,30)]):\n",
    "    feats = []\n",
    "    for lo,hi in bands:\n",
    "        bp,_,_ = _fft_band_energy(X, fs, lo, hi)\n",
    "        feats.append(bp.mean())\n",
    "    hj = _hjorth_params(X)\n",
    "    feats += list(hj.mean(axis=0))\n",
    "    bp_full,_,_ = _fft_band_energy(X, fs, 0.5, 40)\n",
    "    feats += [bp_full.mean(), np.sqrt((bp_full**2).mean())]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def synth_domain(n_epochs=240, n_channels=32, fs=128.0, epoch_len=4.0, eo_shift=0.8, domain_noise=0.3, seed=0):\n",
    "    rngs = np.random.default_rng(seed)\n",
    "    t = np.arange(int(fs*epoch_len))/fs\n",
    "    freqs = [2,4,8,10,12,20]\n",
    "    X_list, y = [], []\n",
    "    for i in range(n_epochs):\n",
    "        label = int(i%2)\n",
    "        chs = []\n",
    "        for _ in range(n_channels):\n",
    "            sig = np.zeros_like(t)\n",
    "            for f in freqs:\n",
    "                amp = rngs.normal(0.8, 0.2)\n",
    "                if label==1 and 8<=f<=12: amp += eo_shift\n",
    "                sig += amp*np.sin(2*np.pi*f*t + rngs.uniform(0,2*np.pi))\n",
    "            sig += rngs.normal(0, domain_noise, size=t.shape)\n",
    "            chs.append(sig)\n",
    "        X_list.append(np.stack(chs, axis=1)); y.append(label)\n",
    "    return X_list, np.array(y), fs\n",
    "\n",
    "def load_or_synthesize():\n",
    "    fs, epoch_len = 128.0, 4.0\n",
    "    hp, mp = Path(\"/mnt/data/HUMAN_EEG.csv\"), Path(\"/mnt/data/MOUSE_EEG.csv\")\n",
    "    if hp.exists() and mp.exists():\n",
    "        def load_csv(p):\n",
    "            df = pd.read_csv(p); assert 'label' in df.columns\n",
    "            y = df['label'].astype(int).values\n",
    "            X = df.drop(columns=['label']).values\n",
    "            L = int(fs*epoch_len); n = (X.shape[0]//L)*L\n",
    "            X = X[:n].reshape(-1, L, X.shape[1]); y = y[:X.shape[0]]\n",
    "            return [X[i] for i in range(X.shape[0])], y, fs\n",
    "        Xh,yh,fsh = load_csv(hp); Xm,ym,fsm = load_csv(mp)\n",
    "        return Xh,yh,fsh, Xm,ym,fsm, True\n",
    "    # synthetic fallback\n",
    "    Xh,yh,fsh = synth_domain(domain_noise=0.25, seed=1)\n",
    "    Xm,ym,fsm = synth_domain(domain_noise=0.45, seed=2)\n",
    "    return Xh,yh,fsh, Xm,ym,fsm, False\n",
    "\n",
    "def featurize_block(X_list, fs):\n",
    "    G,B = [],[]\n",
    "    for X in X_list:\n",
    "        try: g = glyph_invariant_feature(X, fs, band=(8,12), k=8)\n",
    "        except: g = np.nan\n",
    "        b = baseline_features(X, fs)\n",
    "        G.append(g); B.append(b)\n",
    "    G = np.array(G).reshape(-1,1); B = np.array(B)\n",
    "    m = ~np.isnan(G).ravel()\n",
    "    return G[m], B[m], m\n",
    "\n",
    "def fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba>=0.5).astype(int)\n",
    "    return {\"auroc\": roc_auc_score(test_y, proba), \"acc\": accuracy_score(test_y, preds), \"proba\": proba}\n",
    "\n",
    "def nested_cv(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=7)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000, seed=77):\n",
    "    rngp = np.random.default_rng(seed)\n",
    "    aucs, deltas = [], []\n",
    "    for _ in range(n_perm):\n",
    "        y_perm = train_y.copy(); rngp.shuffle(y_perm)\n",
    "        out = fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"]); deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# ---------- run ----------\n",
    "Xh, yh, fs_h, Xm, ym, fs_m, used_real = load_or_synthesize()\n",
    "Gh, Bh, mh = featurize_block(Xh, fs_h); yh = yh[mh]\n",
    "Gm, Bm, mm = featurize_block(Xm, fs_m); ym = ym[mm]\n",
    "\n",
    "res_g = fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = fit_eval(Bh, yh, Bm, ym)\n",
    "cv_g = nested_cv(Gh, yh); cv_b = nested_cv(Bh, yh)\n",
    "\n",
    "n_perm = 1000\n",
    "perm_aucs_g, perm_deltas_g = perm_test(Gh, yh, Gm, ym, res_b[\"auroc\"], n_perm=n_perm, seed=77)\n",
    "p_g = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (n_perm + 1)\n",
    "p_delta = (np.sum(perm_deltas_g >= (res_g[\"auroc\"] - res_b[\"auroc\"])) + 1) / (n_perm + 1)\n",
    "\n",
    "# ---------- plots ----------\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph-Invariant (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph-Invariant)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n={n_perm}) | p={p_g:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "# ---------- reports ----------\n",
    "results = {\n",
    "    \"timestamp\": datetime.utcnow().isoformat()+\"Z\",\n",
    "    \"used_real_data\": bool(used_real),\n",
    "    \"fs_hz_human\": float(fs_h),\n",
    "    \"fs_hz_mouse\": float(fs_m),\n",
    "    \"n_human_epochs\": int(len(Gh)),\n",
    "    \"n_mouse_epochs\": int(len(Gm)),\n",
    "    \"transfer\": {\n",
    "        \"glyph_invariant\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(res_g[\"auroc\"] - res_b[\"auroc\"]),\n",
    "        \"perm_test\": {\n",
    "            \"n_perm\": n_perm, \"p_auroc\": float(p_g), \"p_delta\": float(p_delta),\n",
    "            \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g)),\n",
    "        }\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph_invariant\": {\"auroc_mean\": cv_g[0], \"auroc_std\": cv_g[1], \"acc_mean\": cv_g[2], \"acc_std\": cv_g[3]},\n",
    "        \"baseline\": {\"auroc_mean\": cv_b[0], \"auroc_std\": cv_b[1], \"acc_mean\": cv_b[2], \"acc_std\": cv_b[3]}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph-invariant > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph-invariant AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05,\n",
    "        \"test\": \"One-sided permutation test on training labels; n=1000\",\n",
    "        \"blinding\": \"Baseline features fixed; glyph basis fixed; test labels unseen during training.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 and glyph AUROC > 0.70.\"\n",
    "    },\n",
    "    \"notes\": \"Synthetic mode mimics alpha-band modulation; place real CSVs at /mnt/data to run empirically.\"\n",
    "}\n",
    "with open(OUTDIR/\"results.json\",\"w\") as f: json.dump(results, f, indent=2)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Blind Cross-Domain Test\n",
    "====================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: {\"REAL\" if results['used_real_data'] else \"SYNTHETIC\"}\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "\n",
    "TRANSFER (Train Human → Test Mouse)\n",
    "- Glyph-Invariant: AUROC={results['transfer']['glyph_invariant']['auroc']:.3f}, ACC={results['transfer']['glyph_invariant']['acc']:.3f}\n",
    "- Baseline      : AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Δ AUROC       : {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n={n_perm})\n",
    "- p(AUROC ≥ observed)   : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Δ AUROC ≥ observed) : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph-Invariant: AUROC={results['nested_cv_human']['glyph_invariant']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph_invariant']['auroc_std']:.3f}\n",
    "- Baseline      : AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
    "\"\"\"\n",
    "with open(OUTDIR/\"summary.txt\",\"w\") as f: f.write(textwrap.dedent(summary))\n",
    "\n",
    "print(summary.strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867b5afa-8801-408e-8475-744c976ebc2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT One-Cell Groundbreaker — Blind Cross-Domain Test\n",
      "====================================================\n",
      "UTC: 2025-09-29T03:38:46.173736+00:00\n",
      "Data mode: SYNTHETIC\n",
      "Human epochs: 240 | Mouse epochs: 240\n",
      "\n",
      "TRANSFER (Train Human -> Test Mouse)\n",
      "- Glyph-Invariant: AUROC=0.453, ACC=0.471\n",
      "- Baseline      : AUROC=1.000, ACC=1.000\n",
      "- Delta AUROC   : -0.547\n",
      "\n",
      "Permutation Test (n=1000)\n",
      "- p(AUROC >= observed)   : p=1.0000\n",
      "- p(Delta AUROC >= obs.) : p=1.0000\n",
      "\n",
      "Nested CV on Human\n",
      "- Glyph-Invariant: AUROC=0.475±0.060\n",
      "- Baseline      : AUROC=1.000±0.000\n",
      "\n",
      "PREREG DECISION RULE\n",
      "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
      "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
      "\n",
      "Artifacts saved to: \\mnt\\data\\CNT_OneCell_Groundbreaker\n"
     ]
    }
   ],
   "source": [
    "# CNT One-Cell Groundbreaker — Windows-safe (UTF-8 + timezone-aware) edition\n",
    "# - Blinded human→mouse transfer, CNT glyph-invariant vs baselines, 1000-permutation test\n",
    "# - Accepts optional /mnt/data/HUMAN_EEG.csv and /mnt/data/MOUSE_EEG.csv (cols = channels, plus 'label' 0/1)\n",
    "# - Writes artifacts with UTF-8 encoding to an existing folder (prefers /mnt/data if present)\n",
    "\n",
    "import os, json, textwrap, platform\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ---------- Output directory (portable) ----------\n",
    "def pick_outdir():\n",
    "    cand = [Path(\"/mnt/data\"), Path.cwd(), Path.home() / \"Documents\"]\n",
    "    for p in cand:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            test = p / \".touch_ok\"\n",
    "            with open(test, \"w\", encoding=\"utf-8\") as f: f.write(\"ok\")\n",
    "            test.unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "BASE = pick_outdir()\n",
    "OUTDIR = BASE / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    mask = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[mask].sum(axis=0), freqs, S\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    mask = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[mask] = F[mask]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C, xb\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k=8):\n",
    "    rng_local = np.random.default_rng(12345)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def glyph_invariant_feature(X, fs, band=(8,12), k=8):\n",
    "    C, _ = _cov_band(X, fs, band)\n",
    "    A = _orthobasis(C.shape[0], k=k)\n",
    "    ACAt = A.T @ C @ A\n",
    "    return float(np.linalg.norm(ACAt, 'fro') / (np.linalg.norm(C, 'fro') + 1e-9))\n",
    "\n",
    "def baseline_features(X, fs, bands=[(1,4),(4,8),(8,12),(12,30)]):\n",
    "    feats = []\n",
    "    for lo,hi in bands:\n",
    "        bp,_,_ = _fft_band_energy(X, fs, lo, hi)\n",
    "        feats.append(bp.mean())\n",
    "    hj = _hjorth_params(X)  # mean over channels\n",
    "    feats += list(hj.mean(axis=0))\n",
    "    bp_full,_,_ = _fft_band_energy(X, fs, 0.5, 40)\n",
    "    feats += [bp_full.mean(), np.sqrt((bp_full**2).mean())]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def synth_domain(n_epochs=240, n_channels=32, fs=128.0, epoch_len=4.0, eo_shift=0.8, domain_noise=0.3, seed=0):\n",
    "    rngs = np.random.default_rng(seed)\n",
    "    t = np.arange(int(fs*epoch_len))/fs\n",
    "    freqs = [2,4,8,10,12,20]\n",
    "    X_list, y = [], []\n",
    "    for i in range(n_epochs):\n",
    "        label = int(i%2)\n",
    "        chs = []\n",
    "        for _ in range(n_channels):\n",
    "            sig = np.zeros_like(t)\n",
    "            for f in freqs:\n",
    "                amp = rngs.normal(0.8, 0.2)\n",
    "                if label==1 and 8<=f<=12: amp += eo_shift\n",
    "                sig += amp*np.sin(2*np.pi*f*t + rngs.uniform(0,2*np.pi))\n",
    "            sig += rngs.normal(0, domain_noise, size=t.shape)\n",
    "            chs.append(sig)\n",
    "        X_list.append(np.stack(chs, axis=1)); y.append(label)\n",
    "    return X_list, np.array(y), fs\n",
    "\n",
    "def load_or_synthesize():\n",
    "    fs, epoch_len = 128.0, 4.0\n",
    "    hp, mp = Path(\"/mnt/data/HUMAN_EEG.csv\"), Path(\"/mnt/data/MOUSE_EEG.csv\")\n",
    "    if hp.exists() and mp.exists():\n",
    "        def load_csv(p):\n",
    "            df = pd.read_csv(p)\n",
    "            assert 'label' in df.columns, \"CSV must include a 'label' column.\"\n",
    "            y = df['label'].astype(int).values\n",
    "            X = df.drop(columns=['label']).values\n",
    "            L = int(fs*epoch_len)\n",
    "            n = (X.shape[0]//L)*L\n",
    "            X = X[:n].reshape(-1, L, X.shape[1])\n",
    "            y = y[:X.shape[0]]\n",
    "            return [X[i] for i in range(X.shape[0])], y, fs\n",
    "        Xh,yh,fsh = load_csv(hp); Xm,ym,fsm = load_csv(mp)\n",
    "        return Xh,yh,fsh, Xm,ym,fsm, True\n",
    "    # synthetic fallback\n",
    "    Xh,yh,fsh = synth_domain(domain_noise=0.25, seed=1)\n",
    "    Xm,ym,fsm = synth_domain(domain_noise=0.45, seed=2)\n",
    "    return Xh,yh,fsh, Xm,ym,fsm, False\n",
    "\n",
    "def featurize_block(X_list, fs):\n",
    "    G,B = [],[]\n",
    "    for X in X_list:\n",
    "        try: g = glyph_invariant_feature(X, fs, band=(8,12), k=8)\n",
    "        except: g = np.nan\n",
    "        b = baseline_features(X, fs)\n",
    "        G.append(g); B.append(b)\n",
    "    G = np.array(G).reshape(-1,1); B = np.array(B)\n",
    "    m = ~np.isnan(G).ravel()\n",
    "    return G[m], B[m], m\n",
    "\n",
    "def fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba>=0.5).astype(int)\n",
    "    return {\"auroc\": roc_auc_score(test_y, proba), \"acc\": accuracy_score(test_y, preds), \"proba\": proba}\n",
    "\n",
    "def nested_cv(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=7)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000, seed=77):\n",
    "    rngp = np.random.default_rng(seed)\n",
    "    aucs, deltas = [], []\n",
    "    for _ in range(n_perm):\n",
    "        y_perm = train_y.copy(); rngp.shuffle(y_perm)\n",
    "        out = fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"]); deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# ---------- run ----------\n",
    "Xh, yh, fs_h, Xm, ym, fs_m, used_real = load_or_synthesize()\n",
    "Gh, Bh, mh = featurize_block(Xh, fs_h); yh = yh[mh]\n",
    "Gm, Bm, mm = featurize_block(Xm, fs_m); ym = ym[mm]\n",
    "\n",
    "res_g = fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = fit_eval(Bh, yh, Bm, ym)\n",
    "cv_g = nested_cv(Gh, yh); cv_b = nested_cv(Bh, yh)\n",
    "\n",
    "n_perm = 1000\n",
    "perm_aucs_g, perm_deltas_g = perm_test(Gh, yh, Gm, ym, res_b[\"auroc\"], n_perm=n_perm, seed=77)\n",
    "p_g = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (n_perm + 1)\n",
    "p_delta = (np.sum(perm_deltas_g >= (res_g[\"auroc\"] - res_b[\"auroc\"])) + 1) / (n_perm + 1)\n",
    "\n",
    "# ---------- plots ----------\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph-Invariant (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph-Invariant)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n={n_perm}) | p={p_g:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "# ---------- reports (UTF-8, timezone-aware) ----------\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),  # timezone-aware UTC\n",
    "    \"used_real_data\": bool(used_real),\n",
    "    \"fs_hz_human\": float(fs_h),\n",
    "    \"fs_hz_mouse\": float(fs_m),\n",
    "    \"n_human_epochs\": int(len(Gh)),\n",
    "    \"n_mouse_epochs\": int(len(Gm)),\n",
    "    \"transfer\": {\n",
    "        \"glyph_invariant\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(res_g[\"auroc\"] - res_b[\"auroc\"]),\n",
    "        \"perm_test\": {\n",
    "            \"n_perm\": n_perm, \"p_auroc\": float(p_g), \"p_delta\": float(p_delta),\n",
    "            \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g)),\n",
    "        }\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph_invariant\": {\"auroc_mean\": cv_g[0], \"auroc_std\": cv_g[1], \"acc_mean\": cv_g[2], \"acc_std\": cv_g[3]},\n",
    "        \"baseline\": {\"auroc_mean\": cv_b[0], \"auroc_std\": cv_b[1], \"acc_mean\": cv_b[2], \"acc_std\": cv_b[3]}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph-invariant > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph-invariant AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05,\n",
    "        \"test\": \"One-sided permutation test on training labels; n=1000\",\n",
    "        \"blinding\": \"Baseline features fixed; glyph basis fixed; test labels unseen during training.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 and glyph AUROC > 0.70.\"\n",
    "    },\n",
    "    \"notes\": \"Place real CSVs in /mnt/data if available; otherwise synthetic mode runs.\"\n",
    "}\n",
    "\n",
    "# Write JSON with UTF-8 (allow Unicode) and TXT with UTF-8\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Blind Cross-Domain Test\n",
    "====================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: {\"REAL\" if results['used_real_data'] else \"SYNTHETIC\"}\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph-Invariant: AUROC={results['transfer']['glyph_invariant']['auroc']:.3f}, ACC={results['transfer']['glyph_invariant']['acc']:.3f}\n",
    "- Baseline      : AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Delta AUROC   : {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n={n_perm})\n",
    "- p(AUROC >= observed)   : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Delta AUROC >= obs.) : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph-Invariant: AUROC={results['nested_cv_human']['glyph_invariant']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph_invariant']['auroc_std']:.3f}\n",
    "- Baseline      : AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
    "\"\"\"\n",
    "\n",
    "try:\n",
    "    with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(textwrap.dedent(summary))\n",
    "except UnicodeEncodeError:\n",
    "    # Fallback: strip non-ASCII if user's environment forces a legacy encoding somewhere else\n",
    "    with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\", errors=\"ignore\") as f:\n",
    "        f.write(textwrap.dedent(summary))\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a191c257-a963-419e-a847-a9c727ff6c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
      "==================================================\n",
      "UTC: 2025-09-29T03:47:07.821606+00:00\n",
      "Data mode: SYNTHETIC\n",
      "Human epochs: 240 | Mouse epochs: 240\n",
      "Target channel dim (fixed): 32\n",
      "\n",
      "TRANSFER (Train Human -> Test Mouse)\n",
      "- Glyph:    AUROC=0.479, ACC=0.463\n",
      "- Baseline: AUROC=1.000, ACC=1.000\n",
      "- Δ AUROC:  -0.521\n",
      "\n",
      "Permutation Test (n=1000)\n",
      "- p(AUROC >= observed)         : p=0.6733\n",
      "- p(Δ AUROC >= observed (glyph-baseline)) : p=0.6733\n",
      "\n",
      "Nested CV on Human\n",
      "- Glyph:    AUROC=0.521±0.047\n",
      "- Baseline: AUROC=1.000±0.000\n",
      "\n",
      "PREREG DECISION RULE (LOCKED)\n",
      "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
      "\n",
      "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
      "\n",
      "Artifacts saved to: \\mnt\\data\\CNT_OneCell_Groundbreaker\n"
     ]
    }
   ],
   "source": [
    "# ========================= CNT One-Cell Groundbreaker (Prereg-Final, LOCKED) =========================\n",
    "# Blind Human→Mouse transfer. Compares CNT multi-glyph invariant vs. strong baselines.\n",
    "# Prereg DECISION RULE (FROZEN): Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "#\n",
    "# Inputs (optional):\n",
    "#   /mnt/data/HUMAN_EEG.csv\n",
    "#   /mnt/data/MOUSE_EEG.csv\n",
    "#   - CSV rows = contiguous samples, columns = channels + 'label' (0/1). Assumes 4 s epochs @ 128 Hz.\n",
    "#\n",
    "# Outputs (UTF-8):\n",
    "#   CNT_OneCell_Groundbreaker/results.json\n",
    "#   CNT_OneCell_Groundbreaker/summary.txt\n",
    "#   CNT_OneCell_Groundbreaker/transfer_roc.png\n",
    "#   CNT_OneCell_Groundbreaker/perm_null.png\n",
    "#\n",
    "# LOCKS (do not change to preserve prereg integrity):\n",
    "#   FS=128.0 Hz, EPOCH=4.0 s\n",
    "#   TARGET_CHANNEL_DIM=32 via fixed random projection (seeded)\n",
    "#   GLYPH_BANDS=[(6,9),(8,12),(10,14)], RANKS=[4,8,12]\n",
    "#   BASELINES = mean bandpowers (1–4, 4–8, 8–12, 12–30), Hjorth mean (activity, mobility, complexity),\n",
    "#               full-band PSD mean and RMS\n",
    "#   MODEL = LogisticRegression(lbfgs, max_iter=200)\n",
    "#   PERMUTATIONS = 1000, one-sided on ΔAUROC (glyph − baseline), labels permuted in TRAIN only\n",
    "#\n",
    "# =====================================================================================================\n",
    "\n",
    "import os, json, textwrap\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ---------- PREREG: FROZEN CONSTANTS ----------\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928  # fixed seed for reproducibility\n",
    "\n",
    "# ---------- Output dir (portable & UTF-8 safe) ----------\n",
    "def pick_outdir():\n",
    "    for p in [Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "BASE = pick_outdir()\n",
    "OUTDIR = BASE / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "rng_global = np.random.default_rng(SEED_MASTER)\n",
    "\n",
    "# ---------- Helpers (locked) ----------\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=777):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    \"\"\"Deterministic channel projector to TARGET_CHANNEL_DIM using QR; keeps prereg blind & reproducible.\"\"\"\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]  # ch_in x ch_out (orthonormal columns)\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    \"\"\"Map [T, ch] → [T, target_dim] with a fixed projection matrix determined by original ch.\"\"\"\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim:\n",
    "        return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P  # [T, ch_in] @ [ch_in, target_dim] → [T, target_dim]\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, fs, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    # Multi-glyph invariant vector over bands × ranks (FROZEN)\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k, seed=13579)\n",
    "            val = np.linalg.norm(A.T @ C @ A, 'fro') / Cn\n",
    "            C_feats.append(val)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        auroc=float(roc_auc_score(test_y, proba)),\n",
    "        acc=float(accuracy_score(test_y, preds)),\n",
    "        proba=proba\n",
    "    )\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=PERM_N):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for _ in range(n_perm):\n",
    "        y_perm = train_y.copy()\n",
    "        rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"])\n",
    "        deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "    aucs = np.array(aucs); deltas = np.array(deltas)\n",
    "    return aucs, deltas\n",
    "\n",
    "# ---------- Data load or synthetic fallback (harder) ----------\n",
    "def synth_domain(n_epochs=240, n_channels=TARGET_CHANNEL_DIM, fs=FS, epoch_len=EPOCH_S,\n",
    "                 eo_shift=0.6, domain_noise=0.5, seed=0, alpha_center=10.0, alpha_jitter=1.0):\n",
    "    rngs = np.random.default_rng(seed)\n",
    "    t = np.arange(int(fs*epoch_len))/fs\n",
    "    base_freqs = [2,4,8,12,20]\n",
    "    X_list, y = [], []\n",
    "    # domain-specific mixing matrix (but we map both domains to TARGET_CHANNEL_DIM later anyway)\n",
    "    for i in range(n_epochs):\n",
    "        label = int(i%2)  # 0/1 alternating\n",
    "        chs = []\n",
    "        for _ in range(n_channels):\n",
    "            sig = np.zeros_like(t)\n",
    "            for f in base_freqs:\n",
    "                amp = rngs.normal(0.8, 0.25)\n",
    "                if label==1 and 8<=f<=12:\n",
    "                    boost = eo_shift * np.exp(-0.5*((f - (alpha_center + rngs.normal(0,alpha_jitter)))/1.5)**2)\n",
    "                    amp += boost\n",
    "                sig += amp*np.sin(2*np.pi*f*t + rngs.uniform(0,2*np.pi))\n",
    "            sig += rngs.normal(0, domain_noise*(0.6+0.4*np.sin(2*np.pi*0.2*t)), size=t.shape)\n",
    "            chs.append(sig)\n",
    "        X = np.stack(chs, axis=1)\n",
    "        X_list.append(X); y.append(label)\n",
    "    return X_list, np.array(y, int), fs\n",
    "\n",
    "def load_or_synthesize():\n",
    "    hp, mp = Path(\"/mnt/data/HUMAN_EEG.csv\"), Path(\"/mnt/data/MOUSE_EEG.csv\")\n",
    "    if hp.exists() and mp.exists():\n",
    "        dfh = pd.read_csv(hp); dfm = pd.read_csv(mp)\n",
    "        assert 'label' in dfh.columns and 'label' in dfm.columns, \"CSVs must include a 'label' column.\"\n",
    "        y_h = dfh['label'].astype(int).values\n",
    "        y_m = dfm['label'].astype(int).values\n",
    "        X_h = dfh.drop(columns=['label']).values\n",
    "        X_m = dfm.drop(columns=['label']).values\n",
    "        L = int(FS*EPOCH_S)\n",
    "        n_h = (X_h.shape[0]//L)*L; n_m = (X_m.shape[0]//L)*L\n",
    "        X_h = X_h[:n_h].reshape(-1, L, X_h.shape[1]); y_h = y_h[:X_h.shape[0]]\n",
    "        X_m = X_m[:n_m].reshape(-1, L, X_m.shape[1]); y_m = y_m[:X_m.shape[0]]\n",
    "        used_real = True\n",
    "        return [X_h[i] for i in range(X_h.shape[0])], y_h, [X_m[i] for i in range(X_m.shape[0])], y_m, used_real\n",
    "    # Harder synthetic (two domains with different seeds/noise)\n",
    "    Xh, yh, _ = synth_domain(seed=111, domain_noise=0.40)\n",
    "    Xm, ym, _ = synth_domain(seed=222, domain_noise=0.55)\n",
    "    return Xh, yh, Xm, ym, False\n",
    "\n",
    "# ---------- Featurization (channel mapping + glyph stack + baselines) ----------\n",
    "def featurize_domain(X_list, y, fs=FS):\n",
    "    G_list, B_list = [], []\n",
    "    for X in X_list:\n",
    "        Xp = map_channels_epoch(X, TARGET_CHANNEL_DIM)\n",
    "        G_list.append(glyph_stack_features(Xp, fs))\n",
    "        B_list.append(baseline_features(Xp, fs))\n",
    "    G = np.asarray(G_list, float)\n",
    "    B = np.asarray(B_list, float)\n",
    "    # drop any NaN rows (defensive)\n",
    "    mask = ~np.isnan(G).any(axis=1)\n",
    "    return G[mask], B[mask], y[mask]\n",
    "\n",
    "# ---------- RUN (LOCKED FLOW) ----------\n",
    "Xh, yh, Xm, ym, used_real = load_or_synthesize()\n",
    "Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "# Train on HUMAN, blind test on MOUSE\n",
    "res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "# Sanity CV on HUMAN\n",
    "cv_g = nested_cv_scores(Gh, yh)\n",
    "cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "# Permutation on TRAIN labels (glyph), measuring ΔAUROC vs baseline\n",
    "perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=PERM_N)\n",
    "p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (PERM_N + 1)\n",
    "obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (PERM_N + 1)\n",
    "\n",
    "# ---------- Plots ----------\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR/\"transfer_roc.png\", dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n={PERM_N}) | p={p_auroc:.4f}\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUTDIR/\"perm_null.png\", dpi=200); plt.close()\n",
    "\n",
    "# ---------- Reports (UTF-8, timezone-aware) ----------\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"used_real_data\": bool(used_real),\n",
    "    \"fs_hz\": FS,\n",
    "    \"epoch_s\": EPOCH_S,\n",
    "    \"target_channel_dim\": TARGET_CHANNEL_DIM,\n",
    "    \"n_human_epochs\": int(Gh.shape[0]),\n",
    "    \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "    \"transfer\": {\n",
    "        \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(obs_delta),\n",
    "        \"perm_test\": {\n",
    "            \"n_perm\": PERM_N,\n",
    "            \"p_auroc\": float(p_auroc),\n",
    "            \"p_delta\": float(p_delta),\n",
    "            \"perm_mean_auroc\": float(np.mean(perm_aucs_g)),\n",
    "            \"perm_std_auroc\": float(np.std(perm_aucs_g)),\n",
    "        }\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph\": {\"auroc_mean\": cv_g[0], \"auroc_std\": cv_g[1], \"acc_mean\": cv_g[2], \"acc_std\": cv_g[3]},\n",
    "        \"baseline\": {\"auroc_mean\": cv_b[0], \"auroc_std\": cv_b[1], \"acc_mean\": cv_b[2], \"acc_std\": cv_b[3]}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05,\n",
    "        \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "        \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "==================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: {\"REAL\" if results['used_real_data'] else \"SYNTHETIC\"}\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "- Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Δ AUROC:  {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n={PERM_N})\n",
    "- p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Δ AUROC >= observed (glyph-baseline)) : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "- Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE (LOCKED)\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
    "\"\"\"\n",
    "with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textwrap.dedent(summary))\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n",
    "# ====================================== END LOCKED CELL ==============================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c83380d1-b11d-4e00-ae98-f4b5b38e24f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert MNE Epochs to the CSV the one-cell expects (rows = samples, cols = channels + 'label')\n",
    "def export_epochs(epochs, label_map, out_csv, fs_target=128.0, epoch_s=4.0):\n",
    "    import numpy as np, pandas as pd, mne\n",
    "    # Resample if needed\n",
    "    if epochs.info['sfreq'] != fs_target:\n",
    "        epochs = epochs.copy().resample(fs_target)\n",
    "    # Ensure fixed epoch length\n",
    "    L = int(fs_target * epoch_s)\n",
    "    X_list, y_list = [], []\n",
    "    for i, e in enumerate(epochs):\n",
    "        x = e[0]  # shape (n_channels, n_times)\n",
    "        if x.shape[1] < L:\n",
    "            continue\n",
    "        x = x[:, :L]  # trim/pad policy: trim\n",
    "        X_list.append(x.T)  # (L, n_channels)\n",
    "        # Map event id → 0/1 label\n",
    "        event_id = epochs.events[i, 2]\n",
    "        y_list.append(int(label_map.get(event_id, 0)))\n",
    "    if not X_list:\n",
    "        raise ValueError(\"No epochs exported. Check lengths and label_map.\")\n",
    "    X = np.vstack(X_list)  # (n_epochs*L, n_channels)\n",
    "    y = np.repeat(np.array(y_list, int), L)\n",
    "    df = pd.DataFrame(X)\n",
    "    df[\"label\"] = y\n",
    "    df.to_csv(out_csv, index=False)\n",
    "    print(f\"Wrote {out_csv} | rows={df.shape[0]} cols={df.shape[1]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93c954f5-85e2-4e84-a863-2ce819c54006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/12] Config…\n",
      "[2/12] OUTDIR = \\mnt\\data\\CNT_OneCell_Groundbreaker\n",
      "[3/12] Loading data or building synthetic…\n",
      "    No CSVs—running harder synthetic fallback (SYNTHETIC mode).\n",
      "[4/12] Shapes → HUMAN: 240 epochs | MOUSE: 240 epochs\n",
      "[5/12] Featurizing HUMAN…\n",
      "    … featurized 60/240\n",
      "    … featurized 120/240\n",
      "    … featurized 180/240\n",
      "    … featurized 240/240\n",
      "[6/12] Featurizing MOUSE…\n",
      "    … featurized 60/240\n",
      "    … featurized 120/240\n",
      "    … featurized 180/240\n",
      "    … featurized 240/240\n",
      "[7/12] Train on HUMAN, test on MOUSE…\n",
      "[8/12] Nested CV (HUMAN) for sanity…\n",
      "[9/12] Permutation test (this prints progress)…\n",
      "    … permutations 10/50\n",
      "    … permutations 20/50\n",
      "    … permutations 30/50\n",
      "    … permutations 40/50\n",
      "    … permutations 50/50\n",
      "[10/12] Plotting…\n",
      "[11/12] Writing reports…\n",
      "[12/12] DONE.\n",
      "CNT One-Cell Groundbreaker — VERBOSE SMOKE TEST\n",
      "===============================================\n",
      "UTC: 2025-09-29T03:53:51.484559+00:00\n",
      "Data mode: SYNTHETIC\n",
      "Human epochs: 240 | Mouse epochs: 240\n",
      "Target channel dim: 32\n",
      "\n",
      "TRANSFER (Train Human -> Test Mouse)\n",
      "- Glyph:    AUROC=0.479, ACC=0.463\n",
      "- Baseline: AUROC=1.000, ACC=1.000\n",
      "- Δ AUROC:  -0.521\n",
      "\n",
      "Permutation Test (n=50)\n",
      "- p(AUROC >= observed)   : p=0.6471\n",
      "- p(Δ AUROC >= observed) : p=0.6471\n",
      "\n",
      "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
      "Folder: \\mnt\\data\\CNT_OneCell_Groundbreaker\n"
     ]
    }
   ],
   "source": [
    "# === CNT One-Cell Groundbreaker (DIAGNOSTIC / VERBOSE) ===\n",
    "# Purpose: make sure you SEE output. Progress prints + quick permutation run.\n",
    "# If this works, set PERM_N=1000 below and re-run the same cell.\n",
    "\n",
    "import os, sys, json, textwrap, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def say(msg):\n",
    "    print(msg); sys.stdout.flush()\n",
    "\n",
    "try:\n",
    "    say(\"[1/12] Config…\")\n",
    "    FS = 128.0\n",
    "    EPOCH_S = 4.0\n",
    "    TARGET_CHANNEL_DIM = 32\n",
    "    GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "    GLYPH_RANKS = [4,8,12]\n",
    "    BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "    PERM_N = 50   # <<< smoke test; change to 1000 after this works\n",
    "    SEED_MASTER = 20250928\n",
    "\n",
    "    def pick_outdir():\n",
    "        for p in [Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "            try:\n",
    "                p.mkdir(parents=True, exist_ok=True)\n",
    "                (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "                (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "                return p\n",
    "            except Exception:\n",
    "                continue\n",
    "        return Path.cwd()\n",
    "\n",
    "    BASE = pick_outdir()\n",
    "    OUTDIR = BASE / \"CNT_OneCell_Groundbreaker\"\n",
    "    OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "    say(f\"[2/12] OUTDIR = {OUTDIR}\")\n",
    "\n",
    "    rng_global = np.random.default_rng(SEED_MASTER)\n",
    "\n",
    "    # ----- helpers -----\n",
    "    def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "        n = X.shape[0]\n",
    "        freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "        S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "        m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "        return S[m].sum(axis=0)\n",
    "\n",
    "    def _cov_band(X, fs, band):\n",
    "        n = X.shape[0]\n",
    "        F = np.fft.rfft(X, axis=0)\n",
    "        freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "        m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "        Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "        xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "        Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "        C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "        return C\n",
    "\n",
    "    def _hjorth_params(X):\n",
    "        dX = np.diff(X, axis=0)\n",
    "        var_x = X.var(axis=0)\n",
    "        var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "        mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "        ddX = np.diff(dX, axis=0)\n",
    "        var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "        mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "        comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "        return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "    def _orthobasis(channels, k, seed=13579):\n",
    "        rng_local = np.random.default_rng(seed + channels + k)\n",
    "        Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "        return Q[:, :k]\n",
    "\n",
    "    def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "        rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "        A = rng.normal(size=(ch_in, ch_out))\n",
    "        Q, _ = np.linalg.qr(A)\n",
    "        return Q[:, :ch_out]\n",
    "\n",
    "    def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "        ch_in = X_epoch.shape[1]\n",
    "        if ch_in == target_dim:\n",
    "            return X_epoch\n",
    "        P = fixed_projection_matrix(ch_in, target_dim)\n",
    "        return X_epoch @ P\n",
    "\n",
    "    def baseline_features(X, fs):\n",
    "        feats = []\n",
    "        for lo,hi in BASELINE_BANDS:\n",
    "            feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "        hj = _hjorth_params(X).mean(axis=0)\n",
    "        feats += list(hj)\n",
    "        bp_full = _fft_band_energy(X, fs, 0.5, 40.0)\n",
    "        feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "        return np.array(feats, float)\n",
    "\n",
    "    def glyph_stack_features(X, fs):\n",
    "        C_feats = []\n",
    "        for band in GLYPH_BANDS:\n",
    "            C = _cov_band(X, fs, band)\n",
    "            Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "            for k in GLYPH_RANKS:\n",
    "                A = _orthobasis(C.shape[0], k)\n",
    "                C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "        return np.array(C_feats, float)\n",
    "\n",
    "    def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "        clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "        clf.fit(train_X, train_y)\n",
    "        proba = clf.predict_proba(test_X)[:,1]\n",
    "        preds = (proba >= 0.5).astype(int)\n",
    "        return dict(\n",
    "            auroc=float(roc_auc_score(test_y, proba)),\n",
    "            acc=float(accuracy_score(test_y, preds)),\n",
    "            proba=proba\n",
    "        )\n",
    "\n",
    "    def nested_cv_scores(X, y, n_splits=5):\n",
    "        skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "        aucs, accs = [], []\n",
    "        for tr, te in skf.split(X, y):\n",
    "            out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "            aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "        return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "    def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=PERM_N):\n",
    "        rngp = np.random.default_rng(9090)\n",
    "        aucs, deltas = [], []\n",
    "        for i in range(n_perm):\n",
    "            y_perm = train_y.copy()\n",
    "            rngp.shuffle(y_perm)\n",
    "            out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "            aucs.append(out[\"auroc\"])\n",
    "            deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "            if (i+1) % max(1, n_perm//5) == 0:\n",
    "                say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "        return np.array(aucs), np.array(deltas)\n",
    "\n",
    "    # ----- data -----\n",
    "    say(\"[3/12] Loading data or building synthetic…\")\n",
    "    hp, mp = Path(\"/mnt/data/HUMAN_EEG.csv\"), Path(\"/mnt/data/MOUSE_EEG.csv\")\n",
    "    used_real = False\n",
    "    if hp.exists() and mp.exists():\n",
    "        say(\"    Found CSVs in /mnt/data (REAL mode).\")\n",
    "        dfh = pd.read_csv(hp); dfm = pd.read_csv(mp)\n",
    "        assert 'label' in dfh.columns and 'label' in dfm.columns, \"CSVs must include a 'label' column.\"\n",
    "        y_h = dfh['label'].astype(int).values\n",
    "        y_m = dfm['label'].astype(int).values\n",
    "        X_h = dfh.drop(columns=['label']).values\n",
    "        X_m = dfm.drop(columns=['label']).values\n",
    "        L = int(FS*EPOCH_S)\n",
    "        n_h = (X_h.shape[0]//L)*L; n_m = (X_m.shape[0]//L)*L\n",
    "        X_h = X_h[:n_h].reshape(-1, L, X_h.shape[1]); y_h = y_h[:X_h.shape[0]]\n",
    "        X_m = X_m[:n_m].reshape(-1, L, X_m.shape[1]); y_m = y_m[:X_m.shape[0]]\n",
    "        Xh = [X_h[i] for i in range(X_h.shape[0])]\n",
    "        Xm = [X_m[i] for i in range(X_m.shape[0])]\n",
    "        yh, ym = y_h, y_m\n",
    "        used_real = True\n",
    "    else:\n",
    "        say(\"    No CSVs—running harder synthetic fallback (SYNTHETIC mode).\")\n",
    "        def synth_domain(n_epochs=240, n_channels=TARGET_CHANNEL_DIM, fs=FS, epoch_len=EPOCH_S,\n",
    "                         eo_shift=0.6, domain_noise=0.5, seed=0, alpha_center=10.0, alpha_jitter=1.0):\n",
    "            rngs = np.random.default_rng(seed)\n",
    "            t = np.arange(int(fs*epoch_len))/fs\n",
    "            base_freqs = [2,4,8,12,20]\n",
    "            X_list, y = [], []\n",
    "            for i in range(n_epochs):\n",
    "                label = int(i%2)\n",
    "                chs = []\n",
    "                for _ in range(n_channels):\n",
    "                    sig = np.zeros_like(t)\n",
    "                    for f in base_freqs:\n",
    "                        amp = rngs.normal(0.8, 0.25)\n",
    "                        if label==1 and 8<=f<=12:\n",
    "                            boost = eo_shift * np.exp(-0.5*((f - (alpha_center + rngs.normal(0,alpha_jitter)))/1.5)**2)\n",
    "                            amp += boost\n",
    "                        sig += amp*np.sin(2*np.pi*f*t + rngs.uniform(0,2*np.pi))\n",
    "                    sig += rngs.normal(0, domain_noise*(0.6+0.4*np.sin(2*np.pi*0.2*t)), size=t.shape)\n",
    "                    chs.append(sig)\n",
    "                X = np.stack(chs, axis=1)\n",
    "                X_list.append(X); y.append(label)\n",
    "            return X_list, np.array(y, int)\n",
    "        Xh, yh = synth_domain(seed=111, domain_noise=0.40)\n",
    "        Xm, ym = synth_domain(seed=222, domain_noise=0.55)\n",
    "\n",
    "    say(f\"[4/12] Shapes → HUMAN: {len(Xh)} epochs | MOUSE: {len(Xm)} epochs\")\n",
    "\n",
    "    # ----- featurize -----\n",
    "    def featurize_domain(X_list, y, fs=FS):\n",
    "        G_list, B_list = [], []\n",
    "        for idx, X in enumerate(X_list):\n",
    "            Xp = map_channels_epoch(X, TARGET_CHANNEL_DIM)\n",
    "            G_list.append(glyph_stack_features(Xp, fs))\n",
    "            B_list.append(baseline_features(Xp, fs))\n",
    "            if (idx+1) % max(1, len(X_list)//4) == 0:\n",
    "                say(f\"    … featurized {idx+1}/{len(X_list)}\")\n",
    "        G = np.asarray(G_list, float)\n",
    "        B = np.asarray(B_list, float)\n",
    "        mask = ~np.isnan(G).any(axis=1)\n",
    "        return G[mask], B[mask], y[mask]\n",
    "\n",
    "    say(\"[5/12] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "    say(\"[6/12] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "    say(f\"[7/12] Train on HUMAN, test on MOUSE…\")\n",
    "    res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "    res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "    say(\"[8/12] Nested CV (HUMAN) for sanity…\")\n",
    "    cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "    say(\"[9/12] Permutation test (this prints progress)…\")\n",
    "    perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=PERM_N)\n",
    "    p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (PERM_N + 1)\n",
    "    obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "    p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (PERM_N + 1)\n",
    "\n",
    "    say(\"[10/12] Plotting…\")\n",
    "    fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "    fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "    plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR/\"transfer_roc.png\", dpi=200); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "    plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "    plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "    plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n={PERM_N}) | p={p_auroc:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR/\"perm_null.png\", dpi=200); plt.close()\n",
    "\n",
    "    say(\"[11/12] Writing reports…\")\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"used_real_data\": bool(used_real),\n",
    "        \"fs_hz\": FS,\n",
    "        \"epoch_s\": EPOCH_S,\n",
    "        \"target_channel_dim\": TARGET_CHANNEL_DIM,\n",
    "        \"n_human_epochs\": int(Gh.shape[0]),\n",
    "        \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "        \"transfer\": {\n",
    "            \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "            \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "            \"delta_auroc\": float(obs_delta),\n",
    "            \"perm_test\": {\n",
    "                \"n_perm\": PERM_N, \"p_auroc\": float(p_auroc), \"p_delta\": float(p_delta),\n",
    "                \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g)),\n",
    "            }\n",
    "        },\n",
    "        \"nested_cv_human\": {\n",
    "            \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "            \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "        },\n",
    "        \"prereg\": {\n",
    "            \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "            \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "            \"alpha\": 0.05,\n",
    "            \"test\": \"One-sided permutation on training labels\",\n",
    "            \"n_permutations\": PERM_N,\n",
    "            \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "            \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "        }\n",
    "    }\n",
    "    with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    summary = f\"\"\"\n",
    "    CNT One-Cell Groundbreaker — VERBOSE SMOKE TEST\n",
    "    ===============================================\n",
    "    UTC: {results['timestamp']}\n",
    "    Data mode: {\"REAL\" if results['used_real_data'] else \"SYNTHETIC\"}\n",
    "    Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "    Target channel dim: {results['target_channel_dim']}\n",
    "\n",
    "    TRANSFER (Train Human -> Test Mouse)\n",
    "    - Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "    - Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "    - Δ AUROC:  {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "    Permutation Test (n={PERM_N})\n",
    "    - p(AUROC >= observed)   : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "    - p(Δ AUROC >= observed) : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "    Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png\n",
    "    Folder: {OUTDIR}\n",
    "    \"\"\"\n",
    "    with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(textwrap.dedent(summary))\n",
    "\n",
    "    say(\"[12/12] DONE.\")\n",
    "    print(textwrap.dedent(summary).strip())\n",
    "\n",
    "except Exception as e:\n",
    "    say(\"!!! ERROR — printing traceback:\")\n",
    "    traceback.print_exc()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888dabd7-b49f-431b-b297-c209a8fe852d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/9] Checking for real CSVs...\n",
      "    No CSVs found — using harder synthetic fallback (SYNTHETIC mode).\n",
      "[2/9] Shapes → HUMAN: 240 epochs | MOUSE: 240 epochs\n",
      "[3/9] Featurizing HUMAN…\n",
      "    … featurized 60/240\n",
      "    … featurized 120/240\n",
      "    … featurized 180/240\n",
      "    … featurized 240/240\n",
      "[4/9] Featurizing MOUSE…\n",
      "    … featurized 60/240\n",
      "    … featurized 120/240\n",
      "    … featurized 180/240\n",
      "    … featurized 240/240\n",
      "[5/9] Train on HUMAN, blind test on MOUSE…\n",
      "[6/9] Nested CV on HUMAN…\n",
      "[7/9] Permutation test (1000 perms)…\n",
      "    … permutations 100/1000\n",
      "    … permutations 200/1000\n",
      "    … permutations 300/1000\n",
      "    … permutations 400/1000\n",
      "    … permutations 500/1000\n",
      "    … permutations 600/1000\n",
      "    … permutations 700/1000\n",
      "    … permutations 800/1000\n",
      "    … permutations 900/1000\n",
      "    … permutations 1000/1000\n",
      "[8/9] Plotting ROC and permutation null…\n",
      "[9/9] Writing reports + certificate…\n",
      "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
      "==================================================\n",
      "UTC: 2025-09-29T03:59:22.121250+00:00\n",
      "Data mode: SYNTHETIC\n",
      "Human epochs: 240 | Mouse epochs: 240\n",
      "Target channel dim (fixed): 32\n",
      "\n",
      "TRANSFER (Train Human -> Test Mouse)\n",
      "- Glyph:    AUROC=0.479, ACC=0.463\n",
      "- Baseline: AUROC=1.000, ACC=1.000\n",
      "- Delta AUROC: -0.521\n",
      "\n",
      "Permutation Test (n=1000)\n",
      "- p(AUROC >= observed)         : p=0.6733\n",
      "- p(Delta AUROC >= observed)   : p=0.6733\n",
      "\n",
      "Nested CV on Human\n",
      "- Glyph:    AUROC=0.521±0.047\n",
      "- Baseline: AUROC=1.000±0.000\n",
      "\n",
      "PREREG DECISION RULE (LOCKED)\n",
      "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
      "\n",
      "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
      "\n",
      "Artifacts saved to: \\mnt\\data\\CNT_OneCell_Groundbreaker\n"
     ]
    }
   ],
   "source": [
    "# ========================= CNT One-Cell Groundbreaker (ALL-IN-ONE, LOCKED) =========================\n",
    "# - Blind Human→Mouse transfer, CNT multi-glyph invariant vs strong baselines\n",
    "# - 1000-permutation significance (training-label permutations), verbose progress\n",
    "# - Uses real CSVs if found at /mnt/data/{HUMAN_EEG.csv,MOUSE_EEG.csv}, else harder synthetic fallback\n",
    "# - Windows-safe UTF-8 outputs, fixed channel projection, plots, and a 1-page PDF certificate\n",
    "#\n",
    "# Expected CSVs (optional):\n",
    "#   /mnt/data/HUMAN_EEG.csv\n",
    "#   /mnt/data/MOUSE_EEG.csv\n",
    "# Each: rows=time samples (contiguous), columns = EEG channels + 'label' (0/1). Assumes 4 s epochs @ 128 Hz.\n",
    "#\n",
    "# Outputs:\n",
    "#   CNT_OneCell_Groundbreaker/results.json\n",
    "#   CNT_OneCell_Groundbreaker/summary.txt\n",
    "#   CNT_OneCell_Groundbreaker/transfer_roc.png\n",
    "#   CNT_OneCell_Groundbreaker/perm_null.png\n",
    "#   CNT_OneCell_Groundbreaker/certificate_onecell.pdf\n",
    "#\n",
    "# PREREG DECISION RULE (LOCKED):\n",
    "#   Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70 on transfer.\n",
    "# ===================================================================================================\n",
    "\n",
    "import os, sys, json, textwrap, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# ----------------------- Helpers: printing -----------------------\n",
    "def say(msg):\n",
    "    print(msg); sys.stdout.flush()\n",
    "\n",
    "# ----------------------- PREREG: FROZEN CONSTANTS ----------------\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928  # deterministic\n",
    "\n",
    "# ----------------------- Output dir (portable, UTF-8) ------------\n",
    "def pick_outdir():\n",
    "    for p in [Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "BASE = pick_outdir()\n",
    "OUTDIR = BASE / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------- Core math helpers (locked) --------------\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=13579):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim: return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, fs, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k)\n",
    "            C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        auroc=float(roc_auc_score(test_y, proba)),\n",
    "        acc=float(accuracy_score(test_y, preds)),\n",
    "        proba=proba\n",
    "    )\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=PERM_N):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for i in range(n_perm):\n",
    "        y_perm = train_y.copy()\n",
    "        rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"])\n",
    "        deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "        if (i+1) % max(1, n_perm//10) == 0:\n",
    "            say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# ----------------------- Data load or synthetic -------------------\n",
    "try:\n",
    "    say(\"[1/9] Checking for real CSVs...\")\n",
    "    hp, mp = Path(\"/mnt/data/HUMAN_EEG.csv\"), Path(\"/mnt/data/MOUSE_EEG.csv\")\n",
    "    used_real = False\n",
    "    if hp.exists() and mp.exists():\n",
    "        say(\"    Found CSVs in /mnt/data (REAL mode).\")\n",
    "        dfh = pd.read_csv(hp); dfm = pd.read_csv(mp)\n",
    "        assert 'label' in dfh.columns and 'label' in dfm.columns, \"CSVs must include a 'label' column.\"\n",
    "        y_h = dfh['label'].astype(int).values\n",
    "        y_m = dfm['label'].astype(int).values\n",
    "        X_h = dfh.drop(columns=['label']).values\n",
    "        X_m = dfm.drop(columns=['label']).values\n",
    "        L = int(FS*EPOCH_S)\n",
    "        n_h = (X_h.shape[0]//L)*L; n_m = (X_m.shape[0]//L)*L\n",
    "        X_h = X_h[:n_h].reshape(-1, L, X_h.shape[1]); y_h = y_h[:X_h.shape[0]]\n",
    "        X_m = X_m[:n_m].reshape(-1, L, X_m.shape[1]); y_m = y_m[:X_m.shape[0]]\n",
    "        Xh = [X_h[i] for i in range(X_h.shape[0])]\n",
    "        Xm = [X_m[i] for i in range(X_m.shape[0])]\n",
    "        yh, ym = y_h, y_m\n",
    "        used_real = True\n",
    "    else:\n",
    "        say(\"    No CSVs found — using harder synthetic fallback (SYNTHETIC mode).\")\n",
    "        def synth_domain(n_epochs=240, n_channels=TARGET_CHANNEL_DIM, fs=FS, epoch_len=EPOCH_S,\n",
    "                         eo_shift=0.6, domain_noise=0.5, seed=0, alpha_center=10.0, alpha_jitter=1.0):\n",
    "            rngs = np.random.default_rng(seed)\n",
    "            t = np.arange(int(fs*epoch_len))/fs\n",
    "            base_freqs = [2,4,8,12,20]\n",
    "            X_list, y = [], []\n",
    "            for i in range(n_epochs):\n",
    "                label = int(i%2)\n",
    "                chs = []\n",
    "                for _ in range(n_channels):\n",
    "                    sig = np.zeros_like(t)\n",
    "                    for f in base_freqs:\n",
    "                        amp = rngs.normal(0.8, 0.25)\n",
    "                        if label==1 and 8<=f<=12:\n",
    "                            boost = eo_shift * np.exp(-0.5*((f - (alpha_center + rngs.normal(0,alpha_jitter)))/1.5)**2)\n",
    "                            amp += boost\n",
    "                        sig += amp*np.sin(2*np.pi*f*t + rngs.uniform(0,2*np.pi))\n",
    "                    sig += rngs.normal(0, domain_noise*(0.6+0.4*np.sin(2*np.pi*0.2*t)), size=t.shape)\n",
    "                    chs.append(sig)\n",
    "                X = np.stack(chs, axis=1)\n",
    "                X_list.append(X); y.append(label)\n",
    "            return X_list, np.array(y, int)\n",
    "        Xh, yh = synth_domain(seed=111, domain_noise=0.40)\n",
    "        Xm, ym = synth_domain(seed=222, domain_noise=0.55)\n",
    "    say(f\"[2/9] Shapes → HUMAN: {len(Xh)} epochs | MOUSE: {len(Xm)} epochs\")\n",
    "\n",
    "    # ------------------- Featurize both domains -------------------\n",
    "    def featurize_domain(X_list, y, fs=FS):\n",
    "        G_list, B_list = [], []\n",
    "        for idx, X in enumerate(X_list):\n",
    "            Xp = map_channels_epoch(X, TARGET_CHANNEL_DIM)\n",
    "            G_list.append(glyph_stack_features(Xp, fs))\n",
    "            B_list.append(baseline_features(Xp, fs))\n",
    "            if (idx+1) % max(1, len(X_list)//4) == 0:\n",
    "                say(f\"    … featurized {idx+1}/{len(X_list)}\")\n",
    "        G = np.asarray(G_list, float)\n",
    "        B = np.asarray(B_list, float)\n",
    "        mask = ~np.isnan(G).any(axis=1)\n",
    "        return G[mask], B[mask], y[mask]\n",
    "\n",
    "    say(\"[3/9] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "    say(\"[4/9] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "    # ------------------- Train/Test & CV --------------------------\n",
    "    say(\"[5/9] Train on HUMAN, blind test on MOUSE…\")\n",
    "    res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "    res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "    say(\"[6/9] Nested CV on HUMAN…\")\n",
    "    cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "    # ------------------- Permutation test -------------------------\n",
    "    say(\"[7/9] Permutation test (1000 perms)…\")\n",
    "    perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=PERM_N)\n",
    "    p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (PERM_N + 1)\n",
    "    obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "    p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (PERM_N + 1)\n",
    "\n",
    "    # ------------------- Plots ------------------------------------\n",
    "    say(\"[8/9] Plotting ROC and permutation null…\")\n",
    "    fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "    fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "    plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "    plt.plot([0,1],[0,1],'--')\n",
    "    plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "    plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "    plt.tight_layout()\n",
    "    roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "    plt.figure(figsize=(6,5))\n",
    "    plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "    plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "    plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "    plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n={PERM_N}) | p={p_auroc:.4f}\")\n",
    "    plt.tight_layout()\n",
    "    perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "    # ------------------- Reports (UTF-8) --------------------------\n",
    "    say(\"[9/9] Writing reports + certificate…\")\n",
    "    results = {\n",
    "        \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "        \"used_real_data\": bool(used_real),\n",
    "        \"fs_hz\": FS,\n",
    "        \"epoch_s\": EPOCH_S,\n",
    "        \"target_channel_dim\": TARGET_CHANNEL_DIM,\n",
    "        \"n_human_epochs\": int(Gh.shape[0]),\n",
    "        \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "        \"transfer\": {\n",
    "            \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "            \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "            \"delta_auroc\": float(obs_delta),\n",
    "            \"perm_test\": {\n",
    "                \"n_perm\": PERM_N,\n",
    "                \"p_auroc\": float(p_auroc),\n",
    "                \"p_delta\": float(p_delta),\n",
    "                \"perm_mean_auroc\": float(np.mean(perm_aucs_g)),\n",
    "                \"perm_std_auroc\": float(np.std(perm_aucs_g)),\n",
    "            }\n",
    "        },\n",
    "        \"nested_cv_human\": {\n",
    "            \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "            \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "        },\n",
    "        \"prereg\": {\n",
    "            \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "            \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "            \"alpha\": 0.05,\n",
    "            \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "            \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "            \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "        }\n",
    "    }\n",
    "    with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "    summary = f\"\"\"\n",
    "    CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "    ==================================================\n",
    "    UTC: {results['timestamp']}\n",
    "    Data mode: {\"REAL\" if results['used_real_data'] else \"SYNTHETIC\"}\n",
    "    Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "    Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "    TRANSFER (Train Human -> Test Mouse)\n",
    "    - Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "    - Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "    - Delta AUROC: {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "    Permutation Test (n={PERM_N})\n",
    "    - p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "    - p(Delta AUROC >= observed)   : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "    Nested CV on Human\n",
    "    - Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "    - Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "    PREREG DECISION RULE (LOCKED)\n",
    "    Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "    Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
    "    \"\"\"\n",
    "    with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(textwrap.dedent(summary))\n",
    "\n",
    "    # ------------------- Certificate PDF (1 page) -----------------\n",
    "    cert_path = OUTDIR/\"certificate_onecell.pdf\"\n",
    "    with PdfPages(cert_path) as pdf:\n",
    "        fig = plt.figure(figsize=(8.5, 11))  # US Letter portrait\n",
    "        ax = fig.add_axes([0.07, 0.07, 0.86, 0.86]); ax.axis(\"off\")\n",
    "\n",
    "        title = \"CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\"\n",
    "        hdr = f\"UTC: {results['timestamp']}   |   Data: {'REAL' if results['used_real_data'] else 'SYNTHETIC'}\\n\" \\\n",
    "              f\"Human epochs: {results['n_human_epochs']}   |   Mouse epochs: {results['n_mouse_epochs']}   |   Target ch: {results['target_channel_dim']}\"\n",
    "        body = (\n",
    "            f\"TRANSFER (Train Human -> Test Mouse)\\n\"\n",
    "            f\"  Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\\n\"\n",
    "            f\"  Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\\n\"\n",
    "            f\"  Delta AUROC: {results['transfer']['delta_auroc']:.3f}\\n\\n\"\n",
    "            f\"Permutation Test (n={PERM_N})\\n\"\n",
    "            f\"  p(AUROC >= observed): {results['transfer']['perm_test']['p_auroc']:.4f}\\n\"\n",
    "            f\"  p(Delta AUROC >= observed): {results['transfer']['perm_test']['p_delta']:.4f}\\n\\n\"\n",
    "            f\"Nested CV (Human)\\n\"\n",
    "            f\"  Glyph AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\\n\"\n",
    "            f\"  Baseline AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\\n\\n\"\n",
    "            \"PREREG DECISION RULE (LOCKED)\\n\"\n",
    "            \"  Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\"\n",
    "        )\n",
    "\n",
    "        ax.text(0.5, 0.96, title, ha=\"center\", va=\"top\", fontsize=16, weight=\"bold\")\n",
    "        ax.text(0.5, 0.92, hdr, ha=\"center\", va=\"top\", fontsize=10)\n",
    "        ax.text(0.05, 0.83, body, ha=\"left\", va=\"top\", fontsize=10, family=\"monospace\")\n",
    "\n",
    "        # Embed the two plots if present\n",
    "        y0 = 0.10\n",
    "        img_w, img_h = 0.42, 0.28\n",
    "        try:\n",
    "            import matplotlib.image as mpimg\n",
    "            roc_img = mpimg.imread(roc_path)\n",
    "            perm_img = mpimg.imread(perm_path)\n",
    "            fig.add_axes([0.06, y0+0.18, img_w, img_h]).imshow(roc_img); plt.axis('off')\n",
    "            fig.add_axes([0.52, y0+0.18, img_w, img_h]).imshow(perm_img); plt.axis('off')\n",
    "            ax.text(0.06, y0+0.47, \"ROC (Human→Mouse)\", fontsize=9)\n",
    "            ax.text(0.52, y0+0.47, \"Permutation Null\", fontsize=9)\n",
    "        except Exception:\n",
    "            ax.text(0.05, 0.45, \"[Plots unavailable to embed]\", fontsize=9)\n",
    "\n",
    "        pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "    # ------------------- Final console summary --------------------\n",
    "    print(textwrap.dedent(summary).strip())\n",
    "    print(\"\\nArtifacts saved to:\", OUTDIR)\n",
    "\n",
    "except Exception as e:\n",
    "    say(\"!!! ERROR — printing traceback:\")\n",
    "    traceback.print_exc()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4946e64-f1d0-46c8-8235-5b5ee8e005b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_epochs(epochs, label_map, out_csv, fs_target=128.0, epoch_s=4.0):\n",
    "    import numpy as np, pandas as pd\n",
    "    if epochs.info['sfreq'] != fs_target:\n",
    "        epochs = epochs.copy().resample(fs_target)\n",
    "    L = int(fs_target*epoch_s)\n",
    "    Xs, ys = [], []\n",
    "    for i, e in enumerate(epochs):\n",
    "        x = e[0]\n",
    "        if x.shape[1] < L: continue\n",
    "        Xs.append(x[:, :L].T)                  # (L, n_channels)\n",
    "        ys.append(int(label_map.get(epochs.events[i,2], 0)))\n",
    "    X = np.vstack(Xs); y = np.repeat(np.array(ys,int), L)\n",
    "    df = pd.DataFrame(X); df[\"label\"] = y\n",
    "    df.to_csv(out_csv, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "514d45cb-a692-4164-a5dc-8b5e68f758f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not find HUMAN_EEG.csv and MOUSE_EEG.csv in C:\\mnt\\data or /mnt/data. Place both files there.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 26\u001b[39m\n\u001b[32m     24\u001b[39m         base = p; \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m base \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m26\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCould not find HUMAN_EEG.csv and MOUSE_EEG.csv in C:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmnt\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mdata or /mnt/data. Place both files there.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     28\u001b[39m hp, mp = base/\u001b[33m\"\u001b[39m\u001b[33mHUMAN_EEG.csv\u001b[39m\u001b[33m\"\u001b[39m, base/\u001b[33m\"\u001b[39m\u001b[33mMOUSE_EEG.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     29\u001b[39m say(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[SANITY] Found:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  HUMAN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhp\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m  MOUSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Could not find HUMAN_EEG.csv and MOUSE_EEG.csv in C:\\mnt\\data or /mnt/data. Place both files there."
     ]
    }
   ],
   "source": [
    "# === CNT CSV Sanity + Prereg ALL-IN-ONE Runner (single cell) ===\n",
    "# - Verifies HUMAN_EEG.csv and MOUSE_EEG.csv\n",
    "# - Checks shape, NaNs, label balance per-epoch (L=512 = 4s @ 128Hz)\n",
    "# - If all good, runs the locked ALL-IN-ONE prereg (1000 perms) and writes artifacts.\n",
    "\n",
    "import os, sys, json, textwrap, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def say(m): \n",
    "    print(m); sys.stdout.flush()\n",
    "\n",
    "# ---------- Locate CSVs (Windows + Unix friendly) ----------\n",
    "candidates = [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd()]\n",
    "base = None\n",
    "for p in candidates:\n",
    "    if (p/\"HUMAN_EEG.csv\").exists() and (p/\"MOUSE_EEG.csv\").exists():\n",
    "        base = p; break\n",
    "if base is None:\n",
    "    raise FileNotFoundError(\"Could not find HUMAN_EEG.csv and MOUSE_EEG.csv in C:\\\\mnt\\\\data or /mnt/data. Place both files there.\")\n",
    "\n",
    "hp, mp = base/\"HUMAN_EEG.csv\", base/\"MOUSE_EEG.csv\"\n",
    "say(f\"[SANITY] Found:\\n  HUMAN: {hp}\\n  MOUSE: {mp}\")\n",
    "\n",
    "# ---------- Quick sanity: shape, NaNs, labels, epoch partition ----------\n",
    "L = 512  # 4 s @ 128 Hz (locked assumption downstream)\n",
    "def sanity_check(path, name):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(f\"{name} is missing a 'label' column.\")\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label'].astype(int).values\n",
    "    n_samples, n_ch = X.shape[0], X.shape[1]\n",
    "    nan_any = X.isna().to_numpy().any()\n",
    "    rem = n_samples % L\n",
    "    n_epochs = n_samples // L\n",
    "    # Epoch-wise majority label (assumes label was repeated per-sample)\n",
    "    lab_major = []\n",
    "    for i in range(n_epochs):\n",
    "        chunk = y[i*L:(i+1)*L]\n",
    "        if chunk.size < L: break\n",
    "        # majority vote\n",
    "        ones = int(chunk.sum())\n",
    "        lab_major.append(1 if ones >= (L-ones) else 0)\n",
    "    p1 = np.mean(lab_major) if lab_major else float('nan')\n",
    "    say(f\"[SANITY] {name}: samples={n_samples}, channels={n_ch}, epochs={n_epochs}, remainder={rem}, NaNs={nan_any}, epoch-mean(label)≈{p1:.3f}\")\n",
    "    return n_ch, n_epochs, rem, nan_any\n",
    "\n",
    "nch_h, ne_h, rem_h, nan_h = sanity_check(hp, \"HUMAN\")\n",
    "nch_m, ne_m, rem_m, nan_m = sanity_check(mp, \"MOUSE\")\n",
    "\n",
    "if rem_h or rem_m:\n",
    "    say(\"[WARN] Samples not divisible by 512 (4s epochs). The runner will trim trailing samples.\")\n",
    "if nan_h or nan_m:\n",
    "    say(\"[WARN] NaNs detected; consider cleaning or interpolating.\")\n",
    "\n",
    "# =================== RUN LOCKED ALL-IN-ONE PREREG (same as before) ===================\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928\n",
    "\n",
    "def pick_outdir():\n",
    "    for p in [Path(\"/mnt/data\"), Path(r\"C:\\mnt\\data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "OUTROOT = pick_outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=13579):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim: return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, fs, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k)\n",
    "            C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(\n",
    "        auroc=float(roc_auc_score(test_y, proba)),\n",
    "        acc=float(accuracy_score(test_y, preds)),\n",
    "        proba=proba\n",
    "    )\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for i in range(n_perm):\n",
    "        y_perm = train_y.copy()\n",
    "        rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"])\n",
    "        deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "        if (i+1) % max(1, n_perm//10) == 0:\n",
    "            say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# ---------- Load, epoch, and run ----------\n",
    "say(\"[RUN] Loading CSVs…\")\n",
    "dfh = pd.read_csv(hp); dfm = pd.read_csv(mp)\n",
    "Xh_all = dfh.drop(columns=['label']).values; yh_all = dfh['label'].astype(int).values\n",
    "Xm_all = dfm.drop(columns=['label']).values; ym_all = dfm['label'].astype(int).values\n",
    "\n",
    "# Trim to whole epochs\n",
    "n_h = (Xh_all.shape[0]//L)*L; n_m = (Xm_all.shape[0]//L)*L\n",
    "Xh_all, yh_all = Xh_all[:n_h], yh_all[:n_h]\n",
    "Xm_all, ym_all = Xm_all[:n_m], ym_all[:n_m]\n",
    "\n",
    "# Reshape to epochs\n",
    "Xh = Xh_all.reshape(-1, L, Xh_all.shape[1]); yh = yh_all[:Xh.shape[0]]\n",
    "Xm = Xm_all.reshape(-1, L, Xm_all.shape[1]); ym = ym_all[:Xm.shape[0]]\n",
    "\n",
    "say(f\"[RUN] Epochs → HUMAN={Xh.shape[0]} | MOUSE={Xm.shape[0]} | CH={Xh.shape[2]} vs {Xm.shape[2]}\")\n",
    "\n",
    "def featurize_domain(X_ep, y):\n",
    "    G_list, B_list = [], []\n",
    "    for i in range(X_ep.shape[0]):\n",
    "        Xp = map_channels_epoch(X_ep[i], TARGET_CHANNEL_DIM)\n",
    "        G_list.append(glyph_stack_features(Xp, FS))\n",
    "        B_list.append(baseline_features(Xp, FS))\n",
    "        if (i+1) % max(1, X_ep.shape[0]//4) == 0:\n",
    "            say(f\"    … featurized {i+1}/{X_ep.shape[0]}\")\n",
    "    G = np.asarray(G_list, float); B = np.asarray(B_list, float)\n",
    "    mask = ~np.isnan(G).any(axis=1)\n",
    "    return G[mask], B[mask], y[mask]\n",
    "\n",
    "say(\"[RUN] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "say(\"[RUN] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "say(\"[RUN] Train on HUMAN, blind test on MOUSE…\")\n",
    "res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "say(\"[RUN] Nested CV on HUMAN…\")\n",
    "cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "say(\"[RUN] Permutation test (n=1000)…\")\n",
    "perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=1000)\n",
    "p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (1000 + 1)\n",
    "obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (1000 + 1)\n",
    "\n",
    "# Plots\n",
    "plt.figure(figsize=(6,5))\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n=1000) | p={p_auroc:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "# Reports + certificate\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"used_real_data\": True,\n",
    "    \"fs_hz\": FS, \"epoch_s\": 4.0, \"target_channel_dim\": TARGET_CHANNEL_DIM,\n",
    "    \"n_human_epochs\": int(Gh.shape[0]), \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "    \"transfer\": {\n",
    "        \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(obs_delta),\n",
    "        \"perm_test\": {\"n_perm\": 1000, \"p_auroc\": float(p_auroc), \"p_delta\": float(p_delta),\n",
    "                      \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g))},\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "        \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05, \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "        \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "    }\n",
    "}\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "==================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: REAL\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "- Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Delta AUROC: {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n=1000)\n",
    "- p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Delta AUROC >= observed)   : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "- Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE (LOCKED)\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
    "\"\"\"\n",
    "\n",
    "with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textwrap.dedent(summary))\n",
    "\n",
    "cert_path = OUTDIR/\"certificate_onecell.pdf\"\n",
    "with PdfPages(cert_path) as pdf:\n",
    "    fig = plt.figure(figsize=(8.5, 11)); ax = fig.add_axes([0.07, 0.07, 0.86, 0.86]); ax.axis(\"off\")\n",
    "    title = \"CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\"\n",
    "    hdr = f\"UTC: {results['timestamp']} | Data: REAL | Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']} | Target ch: {results['target_channel_dim']}\"\n",
    "    body = (\n",
    "        f\"TRANSFER (Train Human -> Test Mouse)\\n\"\n",
    "        f\"  Glyph AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\\n\"\n",
    "        f\"  Δ AUROC={results['transfer']['delta_auroc']:.3f}\\n\\n\"\n",
    "        f\"Permutation Test (n=1000)\\n\"\n",
    "        f\"  p(AUROC ≥ observed)={results['transfer']['perm_test']['p_auroc']:.4f}\\n\"\n",
    "        f\"  p(Δ AUROC ≥ observed)={results['transfer']['perm_test']['p_delta']:.4f}\\n\\n\"\n",
    "        f\"Nested CV (Human)\\n\"\n",
    "        f\"  Glyph AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\\n\\n\"\n",
    "        \"PREREG DECISION RULE (LOCKED): Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\"\n",
    "    )\n",
    "    ax.text(0.5, 0.96, title, ha=\"center\", va=\"top\", fontsize=16, weight=\"bold\")\n",
    "    ax.text(0.5, 0.92, hdr, ha=\"center\", va=\"top\", fontsize=10)\n",
    "    ax.text(0.05, 0.82, body, ha=\"left\", va=\"top\", fontsize=10, family=\"monospace\")\n",
    "\n",
    "    # embed plots if present\n",
    "    try:\n",
    "        import matplotlib.image as mpimg\n",
    "        roc_img = mpimg.imread(OUTDIR/\"transfer_roc.png\")\n",
    "        perm_img = mpimg.imread(OUTDIR/\"perm_null.png\")\n",
    "        fig.add_axes([0.06, 0.48, 0.40, 0.26]).imshow(roc_img); plt.axis('off')\n",
    "        fig.add_axes([0.54, 0.48, 0.40, 0.26]).imshow(perm_img); plt.axis('off')\n",
    "        ax.text(0.06, 0.75, \"ROC (Human→Mouse)\", fontsize=9)\n",
    "        ax.text(0.54, 0.75, \"Permutation Null\", fontsize=9)\n",
    "    except Exception:\n",
    "        ax.text(0.05, 0.50, \"[Plots unavailable to embed]\", fontsize=9)\n",
    "\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51c914df-9f72-4248-8cf5-074bd1aaa8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISCOVER] Could not confidently match human vs mouse. Here are top CSV candidates:\n",
      "  score= 1 |   0.0 MB | C:\\Users\\caleb\\Downloads\\CNT-20250827T002504Z-1-001\\CNT\\releases\\null_label_permute_pvals.csv\n",
      "  score= 1 |   0.0 MB | C:\\Users\\caleb\\Downloads\\CNT-20250827T002504Z-1-001\\CNT\\releases\\label_noise_power.csv\n",
      "  score= 0 |  20.0 MB | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored_v2.csv\n",
      "  score= 0 |  17.3 MB | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\n",
      "  score= 0 |  12.8 MB | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_map.csv\n",
      "  score= 0 |   1.8 MB | C:\\Users\\caleb\\cnt_genome\\out\\mini_atlas_lipids\\table.csv\n",
      "  score= 0 |   1.8 MB | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_theta.csv\n",
      "  score= 0 |   1.8 MB | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_alpha.csv\n",
      "  score= 0 |   0.8 MB | C:\\Users\\caleb\\Downloads\\CNT_Replication_Pack_v1\\CNT_Replication_Pack_v1\\sample_data\\sample_signals.csv\n",
      "  score= 0 |   0.4 MB | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\features.csv\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Could not automatically locate HUMAN_EEG.csv and MOUSE_EEG.csv.\n→ Fix: set USER_HUMAN_CSV and USER_MOUSE_CSV at the top of this cell to the exact file paths\n   (or place them in C:\\mnt\\data or /mnt/data and re-run).",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 72\u001b[39m\n\u001b[32m     70\u001b[39m hp, mp = discover_csvs()\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m hp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m mp \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m72\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\n\u001b[32m     73\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mCould not automatically locate HUMAN_EEG.csv and MOUSE_EEG.csv.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     74\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m→ Fix: set USER_HUMAN_CSV and USER_MOUSE_CSV at the top of this cell to the exact file paths\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     75\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m   (or place them in C:\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mmnt\u001b[39m\u001b[38;5;130;01m\\\\\u001b[39;00m\u001b[33mdata or /mnt/data and re-run).\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     76\u001b[39m     )\n\u001b[32m     78\u001b[39m say(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[FOUND] HUMAN: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     79\u001b[39m say(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[FOUND] MOUSE: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: Could not automatically locate HUMAN_EEG.csv and MOUSE_EEG.csv.\n→ Fix: set USER_HUMAN_CSV and USER_MOUSE_CSV at the top of this cell to the exact file paths\n   (or place them in C:\\mnt\\data or /mnt/data and re-run)."
     ]
    }
   ],
   "source": [
    "# === CNT One-Cell Groundbreaker — Path-Smart ALL-IN-ONE (locked) ===\n",
    "# 1) Try user-provided paths; else auto-search common folders for HUMAN/MOUSE CSVs\n",
    "# 2) Sanity check (shape/NaNs/epoching) + Locked prereg run (1000 perms) + plots + PDF certificate\n",
    "\n",
    "import os, sys, json, textwrap, traceback, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def say(m): print(m); sys.stdout.flush()\n",
    "\n",
    "# --------- EDIT THESE IF YOU KNOW THE EXACT PATHS ---------\n",
    "USER_HUMAN_CSV = r\"\"  # e.g., r\"C:\\Users\\caleb\\Documents\\EEG\\HUMAN_EEG.csv\"\n",
    "USER_MOUSE_CSV = r\"\"  # e.g., r\"C:\\Users\\caleb\\Documents\\EEG\\MOUSE_EEG.csv\"\n",
    "# ----------------------------------------------------------\n",
    "\n",
    "# --------- Discover CSVs ----------\n",
    "def discover_csvs():\n",
    "    # 1) Use user-provided if present\n",
    "    if USER_HUMAN_CSV and USER_MOUSE_CSV:\n",
    "        hp = Path(USER_HUMAN_CSV); mp = Path(USER_MOUSE_CSV)\n",
    "        if hp.exists() and mp.exists(): return hp, mp\n",
    "\n",
    "    # 2) Try common roots\n",
    "    candidates = [\n",
    "        Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"),\n",
    "        Path.cwd(),\n",
    "        Path.home() / \"Documents\",\n",
    "        Path.home() / \"Downloads\",\n",
    "        Path.home() / \"Desktop\",\n",
    "    ]\n",
    "    found = []\n",
    "    for root in candidates:\n",
    "        if not root.exists(): continue\n",
    "        # shallow + one level deep to stay fast\n",
    "        for p in list(root.glob(\"*.csv\")) + list(root.glob(\"**/*.csv\")):\n",
    "            name_low = p.name.lower()\n",
    "            score = 0\n",
    "            if \"eeg\" in name_low: score += 2\n",
    "            if \"human\" in name_low: score += 3\n",
    "            if \"mouse\" in name_low or \"mice\" in name_low or \"rat\" in name_low: score += 3\n",
    "            if \"label\" in name_low: score += 1\n",
    "            size_mb = p.stat().st_size / (1024*1024)\n",
    "            found.append((score, size_mb, p))\n",
    "\n",
    "    if not found:\n",
    "        return None, None\n",
    "\n",
    "    # Rank by heuristic score, then size\n",
    "    found.sort(key=lambda t: (t[0], t[1]), reverse=True)\n",
    "\n",
    "    # Heuristic pairing: pick best \"human-like\" and \"mouse-like\"\n",
    "    human_like = [p for s,sz,p in found if re.search(r\"human|subj|participant\", p.name.lower())]\n",
    "    mouse_like = [p for s,sz,p in found if re.search(r\"mouse|mice|rat\", p.name.lower())]\n",
    "\n",
    "    if human_like and mouse_like:\n",
    "        return human_like[0], mouse_like[0]\n",
    "\n",
    "    # Fallback: show top candidates and bail so user can set the paths\n",
    "    say(\"[DISCOVER] Could not confidently match human vs mouse. Here are top CSV candidates:\")\n",
    "    for s, sz, p in found[:10]:\n",
    "        say(f\"  score={s:>2} | {sz:5.1f} MB | {p}\")\n",
    "    return None, None\n",
    "\n",
    "hp, mp = discover_csvs()\n",
    "if hp is None or mp is None:\n",
    "    raise FileNotFoundError(\n",
    "        \"Could not automatically locate HUMAN_EEG.csv and MOUSE_EEG.csv.\\n\"\n",
    "        \"→ Fix: set USER_HUMAN_CSV and USER_MOUSE_CSV at the top of this cell to the exact file paths\\n\"\n",
    "        \"   (or place them in C:\\\\mnt\\\\data or /mnt/data and re-run).\"\n",
    "    )\n",
    "\n",
    "say(f\"[FOUND] HUMAN: {hp}\")\n",
    "say(f\"[FOUND] MOUSE: {mp}\")\n",
    "\n",
    "# --------- Sanity checks ----------\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "L = int(FS*EPOCH_S)  # 512 samples/epoch\n",
    "def sanity_check(path, name):\n",
    "    df = pd.read_csv(path)\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(f\"{name} missing 'label' column.\")\n",
    "    X = df.drop(columns=['label'])\n",
    "    y = df['label'].astype(int).values\n",
    "    n_samples, n_ch = X.shape\n",
    "    rem = n_samples % L\n",
    "    n_epochs = n_samples // L\n",
    "    nan_any = X.isna().to_numpy().any()\n",
    "    # epoch-majority label (expects label repeated per sample)\n",
    "    maj = []\n",
    "    for i in range(n_epochs):\n",
    "        seg = y[i*L:(i+1)*L]\n",
    "        if len(seg) < L: break\n",
    "        maj.append(int(seg.mean() >= 0.5))\n",
    "    p1 = float(np.mean(maj)) if maj else float('nan')\n",
    "    say(f\"[SANITY] {name}: samples={n_samples}, ch={n_ch}, epochs={n_epochs}, remainder={rem}, NaNs={nan_any}, epoch-mean(label)≈{p1:.3f}\")\n",
    "    return X.values, y, n_ch\n",
    "\n",
    "Xh_all, yh_all, ch_h = sanity_check(hp, \"HUMAN\")\n",
    "Xm_all, ym_all, ch_m = sanity_check(mp, \"MOUSE\")\n",
    "\n",
    "# Trim to whole epochs and reshape\n",
    "n_h = (Xh_all.shape[0]//L)*L; n_m = (Xm_all.shape[0]//L)*L\n",
    "Xh_all, yh_all = Xh_all[:n_h], yh_all[:n_h]\n",
    "Xm_all, ym_all = Xm_all[:n_m], ym_all[:n_m]\n",
    "Xh = Xh_all.reshape(-1, L, ch_h); yh = yh_all[:Xh.shape[0]]\n",
    "Xm = Xm_all.reshape(-1, L, ch_m); ym = ym_all[:Xm.shape[0]]\n",
    "\n",
    "say(f\"[EPOCHS] HUMAN={Xh.shape[0]} | MOUSE={Xm.shape[0]} | CH={ch_h} vs {ch_m}\")\n",
    "\n",
    "# --------- Locked prereg constants ----------\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928\n",
    "\n",
    "def pick_outdir():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "OUTROOT = pick_outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# --------- Feature helpers (locked) ----------\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if ddX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=13579):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim: return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, FS, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k)\n",
    "            C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(auroc=float(roc_auc_score(test_y, proba)),\n",
    "                acc=float(accuracy_score(test_y, preds)),\n",
    "                proba=proba)\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for i in range(n_perm):\n",
    "        y_perm = train_y.copy(); rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"]); deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "        if (i+1) % max(1, n_perm//10) == 0:\n",
    "            say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# --------- Featurize & run ---------\n",
    "def featurize_domain(X_ep, y):\n",
    "    G_list, B_list = [], []\n",
    "    for i in range(X_ep.shape[0]):\n",
    "        Xp = map_channels_epoch(X_ep[i], TARGET_CHANNEL_DIM)\n",
    "        G_list.append(glyph_stack_features(Xp, FS))\n",
    "        B_list.append(baseline_features(Xp, FS))\n",
    "        if (i+1) % max(1, X_ep.shape[0]//4) == 0:\n",
    "            say(f\"    … featurized {i+1}/{X_ep.shape[0]}\")\n",
    "    G = np.asarray(G_list, float); B = np.asarray(B_list, float)\n",
    "    mask = ~np.isnan(G).any(axis=1)\n",
    "    return G[mask], B[mask], y[mask]\n",
    "\n",
    "say(\"[RUN] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "say(\"[RUN] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "say(\"[RUN] Train on HUMAN, blind test on MOUSE…\")\n",
    "res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "say(\"[RUN] Nested CV on HUMAN…\")\n",
    "cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "say(\"[RUN] Permutation test (n=1000)…\")\n",
    "perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=1000)\n",
    "p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (1000 + 1)\n",
    "obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (1000 + 1)\n",
    "\n",
    "# --------- Plots ---------\n",
    "def pick_outdir_for_write():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "OUTROOT = pick_outdir_for_write()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n=1000) | p={p_auroc:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "# --------- Reports + Certificate ---------\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"used_real_data\": True,\n",
    "    \"fs_hz\": FS, \"epoch_s\": EPOCH_S, \"target_channel_dim\": TARGET_CHANNEL_DIM,\n",
    "    \"n_human_epochs\": int(Gh.shape[0]), \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "    \"transfer\": {\n",
    "        \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(obs_delta),\n",
    "        \"perm_test\": {\"n_perm\": 1000, \"p_auroc\": float(p_auroc), \"p_delta\": float(p_delta),\n",
    "                      \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g))},\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "        \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05, \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "        \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "    }\n",
    "}\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "==================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: REAL\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "- Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Delta AUROC: {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n=1000)\n",
    "- p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Delta AUROC >= observed)   : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "- Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE (LOCKED)\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
    "\"\"\"\n",
    "with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textwrap.dedent(summary))\n",
    "\n",
    "cert_path = OUTDIR/\"certificate_onecell.pdf\"\n",
    "with PdfPages(cert_path) as pdf:\n",
    "    fig = plt.figure(figsize=(8.5, 11)); ax = fig.add_axes([0.07, 0.07, 0.86, 0.86]); ax.axis(\"off\")\n",
    "    title = \"CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\"\n",
    "    hdr = f\"UTC: {results['timestamp']} | Data: REAL | Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']} | Target ch: {results['target_channel_dim']}\"\n",
    "    body = (\n",
    "        f\"TRANSFER (Train Human -> Test Mouse)\\n\"\n",
    "        f\"  Glyph AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\\n\"\n",
    "        f\"  Δ AUROC={results['transfer']['delta_auroc']:.3f}\\n\\n\"\n",
    "        f\"Permutation Test (n=1000)\\n\"\n",
    "        f\"  p(AUROC ≥ observed)={results['transfer']['perm_test']['p_auroc']:.4f}\\n\"\n",
    "        f\"  p(Δ AUROC ≥ observed)={results['transfer']['perm_test']['p_delta']:.4f}\\n\\n\"\n",
    "        f\"Nested CV (Human)\\n\"\n",
    "        f\"  Glyph AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\\n\\n\"\n",
    "        \"PREREG DECISION RULE (LOCKED): Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\"\n",
    "    )\n",
    "    ax.text(0.5, 0.96, title, ha=\"center\", va=\"top\", fontsize=16, weight=\"bold\")\n",
    "    ax.text(0.5, 0.92, hdr, ha=\"center\", va=\"top\", fontsize=10)\n",
    "    ax.text(0.05, 0.82, body, ha=\"left\", va=\"top\", fontsize=10, family=\"monospace\")\n",
    "    # embed plots if present\n",
    "    try:\n",
    "        import matplotlib.image as mpimg\n",
    "        roc_img = mpimg.imread(OUTDIR/\"transfer_roc.png\")\n",
    "        perm_img = mpimg.imread(OUTDIR/\"perm_null.png\")\n",
    "        fig.add_axes([0.06, 0.48, 0.40, 0.26]).imshow(roc_img); plt.axis('off')\n",
    "        fig.add_axes([0.54, 0.48, 0.40, 0.26]).imshow(perm_img); plt.axis('off')\n",
    "        ax.text(0.06, 0.75, \"ROC (Human→Mouse)\", fontsize=9)\n",
    "        ax.text(0.54, 0.75, \"Permutation Null\", fontsize=9)\n",
    "    except Exception:\n",
    "        ax.text(0.05, 0.50, \"[Plots unavailable to embed]\", fontsize=9)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c1e06c-0e3f-418b-bd78-11f1581b893b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISCOVER] Scanning for CSVs…\n",
      "\n",
      "[DISCOVER] Top CSV candidates:\n",
      " 0: score=2 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'tuned_wpli', 'tuned_residual', 'tuned_lag95', 'PASS_resid'] | C:\\Users\\caleb\\Downloads\\S010R03_microPASS_20250821_073457.csv\n",
      " 1: score=2 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'tuned_wpli', 'tuned_residual', 'tuned_lag95', 'PASS_resid'] | C:\\Users\\caleb\\Downloads\\S010R03_lastmile_20250821_074258.csv\n",
      " 2: score=1 |   0.0 MB | label=True | cols=['t_start_s', 't_end_s', 'mu_ERD_med', 'mu_ERD_iqr', 'beta_ERD_med', 'beta_ERD_iqr'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_eval_groundtruth\\ME_ROI_ERD_epochs_S001R03.csv\n",
      " 3: score=0 |  20.0 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_name'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored_v2.csv\n",
      " 4: score=0 |  17.3 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_id'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\n",
      " 5: score=0 |  12.8 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_id'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_map.csv\n",
      " 6: score=0 |   1.8 MB | label=False | cols=['time', 'Ch0', 'Ch1', 'Ch2', 'Ch3', 'Ch4'] | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_theta.csv\n",
      " 7: score=0 |   1.8 MB | label=False | cols=['time', 'Ch0', 'Ch1', 'Ch2', 'Ch3', 'Ch4'] | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_alpha.csv\n",
      " 8: score=0 |   0.4 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\features.csv\n",
      " 9: score=0 |   0.4 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\features.csv\n",
      "10: score=0 |   0.3 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\features.csv\n",
      "11: score=0 |   0.3 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\features.csv\n",
      "12: score=0 |   0.1 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\state_assignments_named.csv\n",
      "13: score=0 |   0.0 MB | label=False | cols=['gene', 'ccre_id', 'Chromosome', 'pos', 'cnt_score', 'tissues'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_scaffold_CRISPR_candidates.csv\n",
      "14: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_eval_groundtruth\\epochs_with_predictions.csv\n",
      "15: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\state_assignments.csv\n",
      "16: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\state_assignments.csv\n",
      "17: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\state_assignments.csv\n",
      "18: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\metadata.csv\n",
      "19: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\metadata.csv\n",
      "20: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\metadata.csv\n",
      "21: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\metadata.csv\n",
      "22: score=0 |   0.0 MB | label=False | cols=['pair', 'PLV_control', 'PLV_anchor', 'delta'] | C:\\Users\\caleb\\Downloads\\plv_pairs.csv\n",
      "23: score=0 |   0.0 MB | label=False | cols=['Time', 'Neural Network', 'Social Field', 'AI Feedback', 'Neural Drift', 'Social Drift'] | C:\\Users\\caleb\\Downloads\\CNT_Parallax_Symbolic_Simulation.csv\n",
      "24: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state', 'fbCSP_task_proba', 'gt'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid_eval\\R03_epochs_hybrid.csv\n",
      "25: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_sim_alpha.csv\n",
      "26: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_sim_theta.csv\n",
      "27: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R03.csv\n",
      "28: score=0 |   0.0 MB | label=False | cols=['gene_name', 'cardio', 'derm', 'immune', 'metabolic', 'neuro'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_leaders_v2.csv\n",
      "29: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R01.csv\n",
      "30: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R02.csv\n",
      "31: score=0 |   0.0 MB | label=False | cols=['gene', 'ccre_id', 'fam_a', 'fam_b'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_cCRE_pairs.csv\n",
      "32: score=0 |   0.0 MB | label=False | cols=['state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\state_assignments.csv\n",
      "33: score=0 |   0.0 MB | label=False | cols=['gene_name', 'cardio', 'derm', 'immune', 'metabolic', 'neuro'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_leaders.csv\n",
      "34: score=0 |   0.0 MB | label=False | cols=['gene_name', 'loci', 'ccres', 'glyph_entropy', 'locus_resilience', 'cnt_peak'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_hubs.csv\n",
      "35: score=0 |   0.0 MB | label=False | cols=['gene_name', 'loci', 'ccres', 'glyph_entropy', 'locus_resilience', 'cnt_peak'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_scaffold_candidates.csv\n",
      "36: score=0 |   0.0 MB | label=False | cols=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\kmeans_centers_pc.csv\n",
      "37: score=0 |   0.0 MB | label=False | cols=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\kmeans_centers_pc.csv\n",
      "38: score=0 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'baseline_wpli', 'baseline_residual', 'baseline_lag95', 'tuned_wpli'] | C:\\Users\\caleb\\Downloads\\CNT_hard_datasets_autocal_v2_20250821_054331.csv\n",
      "39: score=0 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'baseline_wpli', 'baseline_residual', 'baseline_lag95', 'tuned_wpli'] | C:\\Users\\caleb\\Downloads\\CNT_hard_datasets_autocal_20250821_052644.csv\n",
      "\n",
      "Choose one index for HUMAN and one for MOUSE from the list above.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HUMAN index:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a number shown in the list above.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HUMAN index:  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please enter a number shown in the list above.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "HUMAN index:  2\n",
      "MOUSE index:  38\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[CHOICE] HUMAN → C:\\Users\\caleb\\cnt_genome\\cog_alphabet_eval_groundtruth\\ME_ROI_ERD_epochs_S001R03.csv\n",
      "[CHOICE] MOUSE → C:\\Users\\caleb\\Downloads\\CNT_hard_datasets_autocal_v2_20250821_054331.csv\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'rest'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 230\u001b[39m\n\u001b[32m    227\u001b[39m     say(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[EPOCHS] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: epochs=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape[\u001b[32m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | channels=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX.shape[\u001b[32m2\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    228\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m X, y\n\u001b[32m--> \u001b[39m\u001b[32m230\u001b[39m Xh, yh = \u001b[43mreshape_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mHUMAN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    231\u001b[39m Xm, ym = reshape_epochs(mp, \u001b[33m\"\u001b[39m\u001b[33mMOUSE\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfeaturize_domain\u001b[39m(X_ep, y):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 222\u001b[39m, in \u001b[36mreshape_epochs\u001b[39m\u001b[34m(csv_path, name)\u001b[39m\n\u001b[32m    220\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m is missing a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m\u001b[33m column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    221\u001b[39m X = df.drop(columns=[\u001b[33m'\u001b[39m\u001b[33mlabel\u001b[39m\u001b[33m'\u001b[39m]).values\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m y = \u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlabel\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m)\u001b[49m.values\n\u001b[32m    223\u001b[39m n = (X.shape[\u001b[32m0\u001b[39m]//L)*L\n\u001b[32m    224\u001b[39m X = X[:n]; y = y[:n]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:6662\u001b[39m, in \u001b[36mNDFrame.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m   6656\u001b[39m     results = [\n\u001b[32m   6657\u001b[39m         ser.astype(dtype, copy=copy, errors=errors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.items()\n\u001b[32m   6658\u001b[39m     ]\n\u001b[32m   6660\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   6661\u001b[39m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m6662\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   6663\u001b[39m     res = \u001b[38;5;28mself\u001b[39m._constructor_from_mgr(new_data, axes=new_data.axes)\n\u001b[32m   6664\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m res.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mastype\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:430\u001b[39m, in \u001b[36mBaseBlockManager.astype\u001b[39m\u001b[34m(self, dtype, copy, errors)\u001b[39m\n\u001b[32m    427\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[32m    428\u001b[39m     copy = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m430\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    431\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mastype\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    432\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    433\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    434\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    435\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    436\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:784\u001b[39m, in \u001b[36mBlock.astype\u001b[39m\u001b[34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[39m\n\u001b[32m    781\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCan not squeeze with more than one column.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    782\u001b[39m     values = values[\u001b[32m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m784\u001b[39m new_values = \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    786\u001b[39m new_values = maybe_coerce_values(new_values)\n\u001b[32m    788\u001b[39m refs = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:237\u001b[39m, in \u001b[36mastype_array_safe\u001b[39m\u001b[34m(values, dtype, copy, errors)\u001b[39m\n\u001b[32m    234\u001b[39m     dtype = dtype.numpy_dtype\n\u001b[32m    236\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m237\u001b[39m     new_values = \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[32m    239\u001b[39m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m errors == \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:182\u001b[39m, in \u001b[36mastype_array\u001b[39m\u001b[34m(values, dtype, copy)\u001b[39m\n\u001b[32m    179\u001b[39m     values = values.astype(dtype, copy=copy)\n\u001b[32m    181\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m     values = \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    184\u001b[39m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np.dtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values.dtype.type, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\astype.py:133\u001b[39m, in \u001b[36m_astype_nansafe\u001b[39m\u001b[34m(arr, dtype, copy, skipna)\u001b[39m\n\u001b[32m    129\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr.dtype == \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype == \u001b[38;5;28mobject\u001b[39m:\n\u001b[32m    132\u001b[39m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m arr.astype(dtype, copy=copy)\n",
      "\u001b[31mValueError\u001b[39m: invalid literal for int() with base 10: 'rest'"
     ]
    }
   ],
   "source": [
    "# === CNT One-Cell Groundbreaker — Interactive Picker + Locked Prereg Runner ===\n",
    "# 1) Scans common dirs for CSVs; prints a numbered list with quick diagnostics\n",
    "# 2) You enter the index for HUMAN and MOUSE\n",
    "# 3) Runs the locked prereg (Human→Mouse, 1000 perms), writes artifacts & PDF certificate\n",
    "\n",
    "import os, sys, json, textwrap, traceback, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def say(m): print(m); sys.stdout.flush()\n",
    "\n",
    "# --------- 1) Discover CSVs (shallow + one level deep) ----------\n",
    "roots = [\n",
    "    Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"),\n",
    "    Path.cwd(),\n",
    "    Path.home()/\"Desktop\",\n",
    "    Path.home()/\"Documents\",\n",
    "    Path.home()/\"Downloads\",\n",
    "]\n",
    "seen = set()\n",
    "candidates = []\n",
    "\n",
    "def list_csvs(root):\n",
    "    try:\n",
    "        items = list(root.glob(\"*.csv\")) + list(root.glob(\"*/*.csv\"))\n",
    "    except Exception:\n",
    "        items = []\n",
    "    return items\n",
    "\n",
    "say(\"[DISCOVER] Scanning for CSVs…\")\n",
    "for root in roots:\n",
    "    if not root.exists(): continue\n",
    "    for p in list_csvs(root):\n",
    "        try:\n",
    "            if p.resolve() in seen: continue\n",
    "            seen.add(p.resolve())\n",
    "            size_mb = p.stat().st_size/(1024*1024)\n",
    "            # Peek columns/snippet quickly (robust to large files)\n",
    "            try:\n",
    "                head = pd.read_csv(p, nrows=5)\n",
    "                cols = list(head.columns[:6])\n",
    "                has_label = (\"label\" in head.columns)\n",
    "            except Exception:\n",
    "                cols = [\"<unreadable>\"]; has_label = False\n",
    "            name = p.name.lower()\n",
    "            score = 0\n",
    "            if \"eeg\" in name: score += 2\n",
    "            if any(k in name for k in [\"human\",\"subj\",\"participant\",\"s01\",\"s1\"]): score += 2\n",
    "            if any(k in name for k in [\"mouse\",\"mice\",\"rat\"]): score += 2\n",
    "            if has_label: score += 1\n",
    "            candidates.append({\"path\": p, \"size_mb\": size_mb, \"cols\": cols, \"has_label\": has_label, \"score\": score})\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"No CSVs found in common folders. If you know the file paths, move/copy them to C:\\\\mnt\\\\data and name them HUMAN_EEG.csv / MOUSE_EEG.csv.\")\n",
    "\n",
    "# Sort by score then size\n",
    "candidates.sort(key=lambda d: (d[\"score\"], d[\"size_mb\"]), reverse=True)\n",
    "\n",
    "say(\"\\n[DISCOVER] Top CSV candidates:\")\n",
    "for i, c in enumerate(candidates[:40]):\n",
    "    say(f\"{i:>2}: score={c['score']} | {c['size_mb']:5.1f} MB | label={c['has_label']} | cols={c['cols']} | {c['path']}\")\n",
    "\n",
    "# --------- 2) Pick HUMAN & MOUSE by index ----------\n",
    "def pick_idx(prompt):\n",
    "    while True:\n",
    "        s = input(prompt).strip()\n",
    "        if not s:\n",
    "            print(\"Please enter a number shown in the list above.\")\n",
    "            continue\n",
    "        try:\n",
    "            idx = int(s)\n",
    "            if 0 <= idx < len(candidates):\n",
    "                return idx\n",
    "            else:\n",
    "                print(f\"Out of range. Enter 0–{len(candidates)-1}.\")\n",
    "        except ValueError:\n",
    "            print(\"Not a number. Try again.\")\n",
    "\n",
    "print(\"\\nChoose one index for HUMAN and one for MOUSE from the list above.\")\n",
    "h_idx = pick_idx(\"HUMAN index: \")\n",
    "m_idx = pick_idx(\"MOUSE index: \")\n",
    "\n",
    "hp = candidates[h_idx][\"path\"]\n",
    "mp = candidates[m_idx][\"path\"]\n",
    "say(f\"\\n[CHOICE] HUMAN → {hp}\")\n",
    "say(f\"[CHOICE] MOUSE → {mp}\")\n",
    "\n",
    "# --------- 3) Sanity + Locked Prereg Runner ----------\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "L = int(FS*EPOCH_S)  # 512 samples/epoch\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928\n",
    "\n",
    "def pick_outdir():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "OUTROOT = pick_outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=13579):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim: return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, FS, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k)\n",
    "            C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(auroc=float(roc_auc_score(test_y, proba)),\n",
    "                acc=float(accuracy_score(test_y, preds)),\n",
    "                proba=proba)\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for i in range(n_perm):\n",
    "        y_perm = train_y.copy(); rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"]); deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "        if (i+1) % max(1, n_perm//10) == 0:\n",
    "            say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# Epoch trim/reshape\n",
    "def reshape_epochs(csv_path, name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(f\"{name} is missing a 'label' column.\")\n",
    "    X = df.drop(columns=['label']).values\n",
    "    y = df['label'].astype(int).values\n",
    "    n = (X.shape[0]//L)*L\n",
    "    X = X[:n]; y = y[:n]\n",
    "    X = X.reshape(-1, L, X.shape[1])\n",
    "    y = y[:X.shape[0]]\n",
    "    say(f\"[EPOCHS] {name}: epochs={X.shape[0]} | channels={X.shape[2]}\")\n",
    "    return X, y\n",
    "\n",
    "Xh, yh = reshape_epochs(hp, \"HUMAN\")\n",
    "Xm, ym = reshape_epochs(mp, \"MOUSE\")\n",
    "\n",
    "def featurize_domain(X_ep, y):\n",
    "    G_list, B_list = [], []\n",
    "    for i in range(X_ep.shape[0]):\n",
    "        Xp = map_channels_epoch(X_ep[i], TARGET_CHANNEL_DIM)\n",
    "        G_list.append(glyph_stack_features(Xp, FS))\n",
    "        B_list.append(baseline_features(Xp, FS))\n",
    "        if (i+1) % max(1, X_ep.shape[0]//4) == 0:\n",
    "            say(f\"    … featurized {i+1}/{X_ep.shape[0]}\")\n",
    "    G = np.asarray(G_list, float); B = np.asarray(B_list, float)\n",
    "    mask = ~np.isnan(G).any(axis=1)\n",
    "    return G[mask], B[mask], y[mask]\n",
    "\n",
    "say(\"[RUN] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "say(\"[RUN] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "say(\"[RUN] Train on HUMAN, blind test on MOUSE…\")\n",
    "res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "say(\"[RUN] Nested CV on HUMAN…\")\n",
    "cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "say(\"[RUN] Permutation test (n=1000)…\")\n",
    "perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=1000)\n",
    "p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (1000 + 1)\n",
    "obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (1000 + 1)\n",
    "\n",
    "# Plots & outputs\n",
    "def outdir():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "OUTROOT = outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"; OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n=1000) | p={p_auroc:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"used_real_data\": True,\n",
    "    \"fs_hz\": 128.0, \"epoch_s\": 4.0, \"target_channel_dim\": 32,\n",
    "    \"n_human_epochs\": int(Gh.shape[0]), \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "    \"transfer\": {\n",
    "        \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(obs_delta),\n",
    "        \"perm_test\": {\"n_perm\": 1000, \"p_auroc\": float(p_auroc), \"p_delta\": float(p_delta),\n",
    "                      \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g))},\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "        \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05, \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "        \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "    }\n",
    "}\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "==================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: REAL\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "- Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Delta AUROC: {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n=1000)\n",
    "- p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Delta AUROC >= observed)   : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "- Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE (LOCKED)\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
    "\"\"\"\n",
    "with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textwrap.dedent(summary))\n",
    "\n",
    "cert_path = OUTDIR/\"certificate_onecell.pdf\"\n",
    "with PdfPages(cert_path) as pdf:\n",
    "    fig = plt.figure(figsize=(8.5, 11)); ax = fig.add_axes([0.07, 0.07, 0.86, 0.86]); ax.axis(\"off\")\n",
    "    title = \"CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\"\n",
    "    hdr = f\"UTC: {results['timestamp']} | Data: REAL | Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']} | Target ch: {results['target_channel_dim']}\"\n",
    "    body = (\n",
    "        f\"TRANSFER (Train Human -> Test Mouse)\\n\"\n",
    "        f\"  Glyph AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\\n\"\n",
    "        f\"  Δ AUROC={results['transfer']['delta_auroc']:.3f}\\n\\n\"\n",
    "        f\"Permutation Test (n=1000)\\n\"\n",
    "        f\"  p(AUROC ≥ observed)={results['transfer']['perm_test']['p_auroc']:.4f}\\n\"\n",
    "        f\"  p(Δ AUROC ≥ observed)={results['transfer']['perm_test']['p_delta']:.4f}\\n\\n\"\n",
    "        f\"Nested CV (Human)\\n\"\n",
    "        f\"  Glyph AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\\n\\n\"\n",
    "        \"PREREG DECISION RULE (LOCKED): Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\"\n",
    "    )\n",
    "    ax.text(0.5, 0.96, title, ha=\"center\", va=\"top\", fontsize=16, weight=\"bold\")\n",
    "    ax.text(0.5, 0.92, hdr, ha=\"center\", va=\"top\", fontsize=10)\n",
    "    ax.text(0.05, 0.82, body, ha=\"left\", va=\"top\", fontsize=10, family=\"monospace\")\n",
    "    # embed plots\n",
    "    try:\n",
    "        import matplotlib.image as mpimg\n",
    "        roc_img = mpimg.imread(OUTDIR/\"transfer_roc.png\")\n",
    "        perm_img = mpimg.imread(OUTDIR/\"perm_null.png\")\n",
    "        fig.add_axes([0.06, 0.48, 0.40, 0.26]).imshow(roc_img); plt.axis('off')\n",
    "        fig.add_axes([0.54, 0.48, 0.40, 0.26]).imshow(perm_img); plt.axis('off')\n",
    "        ax.text(0.06, 0.75, \"ROC (Human→Mouse)\", fontsize=9)\n",
    "        ax.text(0.54, 0.75, \"Permutation Null\", fontsize=9)\n",
    "    except Exception:\n",
    "        ax.text(0.05, 0.50, \"[Plots unavailable to embed]\", fontsize=9)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c424f855-125b-4ec2-9654-f10947224566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DISCOVER] Scanning for CSVs…\n",
      "\n",
      "[DISCOVER] Top CSV candidates:\n",
      " 0: score=2 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'tuned_wpli', 'tuned_residual', 'tuned_lag95', 'PASS_resid'] | C:\\Users\\caleb\\Downloads\\S010R03_microPASS_20250821_073457.csv\n",
      " 1: score=2 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'tuned_wpli', 'tuned_residual', 'tuned_lag95', 'PASS_resid'] | C:\\Users\\caleb\\Downloads\\S010R03_lastmile_20250821_074258.csv\n",
      " 2: score=1 |   0.0 MB | label=True | cols=['t_start_s', 't_end_s', 'mu_ERD_med', 'mu_ERD_iqr', 'beta_ERD_med', 'beta_ERD_iqr'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_eval_groundtruth\\ME_ROI_ERD_epochs_S001R03.csv\n",
      " 3: score=0 |  20.0 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_name'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored_v2.csv\n",
      " 4: score=0 |  17.3 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_id'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\n",
      " 5: score=0 |  12.8 MB | label=False | cols=['rsid', 'Chromosome', 'pos', 'trait', 'ccre_id', 'gene_id'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_map.csv\n",
      " 6: score=0 |   1.8 MB | label=False | cols=['time', 'Ch0', 'Ch1', 'Ch2', 'Ch3', 'Ch4'] | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_theta.csv\n",
      " 7: score=0 |   1.8 MB | label=False | cols=['time', 'Ch0', 'Ch1', 'Ch2', 'Ch3', 'Ch4'] | C:\\Users\\caleb\\cnt_genome\\brainwaves\\sim_alpha.csv\n",
      " 8: score=0 |   0.4 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\features.csv\n",
      " 9: score=0 |   0.4 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\features.csv\n",
      "10: score=0 |   0.3 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\features.csv\n",
      "11: score=0 |   0.3 MB | label=False | cols=['delta_rel_med', 'delta_rel_iqr', 'delta_rel_std', 'theta_rel_med', 'theta_rel_iqr', 'theta_rel_std'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\features.csv\n",
      "12: score=0 |   0.1 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\state_assignments_named.csv\n",
      "13: score=0 |   0.0 MB | label=False | cols=['gene', 'ccre_id', 'Chromosome', 'pos', 'cnt_score', 'tissues'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_scaffold_CRISPR_candidates.csv\n",
      "14: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_eval_groundtruth\\epochs_with_predictions.csv\n",
      "15: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\state_assignments.csv\n",
      "16: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\state_assignments.csv\n",
      "17: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\state_assignments.csv\n",
      "18: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\metadata.csv\n",
      "19: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\metadata.csv\n",
      "20: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\metadata.csv\n",
      "21: score=0 |   0.0 MB | label=False | cols=['file', 'epoch_idx', 't_start_s', 't_end_s', 'sfreq', 'n_channels'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_refit\\metadata.csv\n",
      "22: score=0 |   0.0 MB | label=False | cols=['pair', 'PLV_control', 'PLV_anchor', 'delta'] | C:\\Users\\caleb\\Downloads\\plv_pairs.csv\n",
      "23: score=0 |   0.0 MB | label=False | cols=['Time', 'Neural Network', 'Social Field', 'AI Feedback', 'Neural Drift', 'Social Drift'] | C:\\Users\\caleb\\Downloads\\CNT_Parallax_Symbolic_Simulation.csv\n",
      "24: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state', 'fbCSP_task_proba', 'gt'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid_eval\\R03_epochs_hybrid.csv\n",
      "25: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_sim_alpha.csv\n",
      "26: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_sim_theta.csv\n",
      "27: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R03.csv\n",
      "28: score=0 |   0.0 MB | label=False | cols=['gene_name', 'cardio', 'derm', 'immune', 'metabolic', 'neuro'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_leaders_v2.csv\n",
      "29: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R01.csv\n",
      "30: score=0 |   0.0 MB | label=False | cols=['file', 't_start_s', 't_end_s', 'state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_decode\\decode_S001R02.csv\n",
      "31: score=0 |   0.0 MB | label=False | cols=['gene', 'ccre_id', 'fam_a', 'fam_b'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_cCRE_pairs.csv\n",
      "32: score=0 |   0.0 MB | label=False | cols=['state'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_hybrid\\state_assignments.csv\n",
      "33: score=0 |   0.0 MB | label=False | cols=['gene_name', 'cardio', 'derm', 'immune', 'metabolic', 'neuro'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_leaders.csv\n",
      "34: score=0 |   0.0 MB | label=False | cols=['gene_name', 'loci', 'ccres', 'glyph_entropy', 'locus_resilience', 'cnt_peak'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_bridge_hubs.csv\n",
      "35: score=0 |   0.0 MB | label=False | cols=['gene_name', 'loci', 'ccres', 'glyph_entropy', 'locus_resilience', 'cnt_peak'] | C:\\Users\\caleb\\cnt_genome\\out\\CNT_scaffold_candidates.csv\n",
      "36: score=0 |   0.0 MB | label=False | cols=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio_betaSplit\\kmeans_centers_pc.csv\n",
      "37: score=0 |   0.0 MB | label=False | cols=['PC1', 'PC2', 'PC3', 'PC4', 'PC5', 'PC6'] | C:\\Users\\caleb\\cnt_genome\\cog_alphabet_physio\\kmeans_centers_pc.csv\n",
      "38: score=0 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'baseline_wpli', 'baseline_residual', 'baseline_lag95', 'tuned_wpli'] | C:\\Users\\caleb\\Downloads\\CNT_hard_datasets_autocal_v2_20250821_054331.csv\n",
      "39: score=0 |   0.0 MB | label=False | cols=['dataset', 'alpha_band', 'baseline_wpli', 'baseline_residual', 'baseline_lag95', 'tuned_wpli'] | C:\\Users\\caleb\\Downloads\\CNT_hard_datasets_autocal_20250821_052644.csv\n",
      "\n",
      "Choose one index for HUMAN and one for MOUSE from the list above.\n"
     ]
    }
   ],
   "source": [
    "# === CNT One-Cell Groundbreaker — Interactive Picker + Locked Prereg Runner ===\n",
    "# 1) Scans common dirs for CSVs; prints a numbered list with quick diagnostics\n",
    "# 2) You enter the index for HUMAN and MOUSE\n",
    "# 3) Runs the locked prereg (Human→Mouse, 1000 perms), writes artifacts & PDF certificate\n",
    "\n",
    "import os, sys, json, textwrap, traceback, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def say(m): print(m); sys.stdout.flush()\n",
    "\n",
    "# --------- 1) Discover CSVs (shallow + one level deep) ----------\n",
    "roots = [\n",
    "    Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"),\n",
    "    Path.cwd(),\n",
    "    Path.home()/\"Desktop\",\n",
    "    Path.home()/\"Documents\",\n",
    "    Path.home()/\"Downloads\",\n",
    "]\n",
    "seen = set()\n",
    "candidates = []\n",
    "\n",
    "def list_csvs(root):\n",
    "    try:\n",
    "        items = list(root.glob(\"*.csv\")) + list(root.glob(\"*/*.csv\"))\n",
    "    except Exception:\n",
    "        items = []\n",
    "    return items\n",
    "\n",
    "say(\"[DISCOVER] Scanning for CSVs…\")\n",
    "for root in roots:\n",
    "    if not root.exists(): continue\n",
    "    for p in list_csvs(root):\n",
    "        try:\n",
    "            if p.resolve() in seen: continue\n",
    "            seen.add(p.resolve())\n",
    "            size_mb = p.stat().st_size/(1024*1024)\n",
    "            # Peek columns/snippet quickly (robust to large files)\n",
    "            try:\n",
    "                head = pd.read_csv(p, nrows=5)\n",
    "                cols = list(head.columns[:6])\n",
    "                has_label = (\"label\" in head.columns)\n",
    "            except Exception:\n",
    "                cols = [\"<unreadable>\"]; has_label = False\n",
    "            name = p.name.lower()\n",
    "            score = 0\n",
    "            if \"eeg\" in name: score += 2\n",
    "            if any(k in name for k in [\"human\",\"subj\",\"participant\",\"s01\",\"s1\"]): score += 2\n",
    "            if any(k in name for k in [\"mouse\",\"mice\",\"rat\"]): score += 2\n",
    "            if has_label: score += 1\n",
    "            candidates.append({\"path\": p, \"size_mb\": size_mb, \"cols\": cols, \"has_label\": has_label, \"score\": score})\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "if not candidates:\n",
    "    raise FileNotFoundError(\"No CSVs found in common folders. If you know the file paths, move/copy them to C:\\\\mnt\\\\data and name them HUMAN_EEG.csv / MOUSE_EEG.csv.\")\n",
    "\n",
    "# Sort by score then size\n",
    "candidates.sort(key=lambda d: (d[\"score\"], d[\"size_mb\"]), reverse=True)\n",
    "\n",
    "say(\"\\n[DISCOVER] Top CSV candidates:\")\n",
    "for i, c in enumerate(candidates[:40]):\n",
    "    say(f\"{i:>2}: score={c['score']} | {c['size_mb']:5.1f} MB | label={c['has_label']} | cols={c['cols']} | {c['path']}\")\n",
    "\n",
    "# --------- 2) Pick HUMAN & MOUSE by index ----------\n",
    "def pick_idx(prompt):\n",
    "    while True:\n",
    "        s = input(prompt).strip()\n",
    "        if not s:\n",
    "            print(\"Please enter a number shown in the list above.\")\n",
    "            continue\n",
    "        try:\n",
    "            idx = int(s)\n",
    "            if 0 <= idx < len(candidates):\n",
    "                return idx\n",
    "            else:\n",
    "                print(f\"Out of range. Enter 0–{len(candidates)-1}.\")\n",
    "        except ValueError:\n",
    "            print(\"Not a number. Try again.\")\n",
    "\n",
    "print(\"\\nChoose one index for HUMAN and one for MOUSE from the list above.\")\n",
    "h_idx = pick_idx(\"HUMAN index: \")\n",
    "m_idx = pick_idx(\"MOUSE index: \")\n",
    "\n",
    "hp = candidates[h_idx][\"path\"]\n",
    "mp = candidates[m_idx][\"path\"]\n",
    "say(f\"\\n[CHOICE] HUMAN → {hp}\")\n",
    "say(f\"[CHOICE] MOUSE → {mp}\")\n",
    "\n",
    "# --------- 3) Sanity + Locked Prereg Runner ----------\n",
    "FS = 128.0\n",
    "EPOCH_S = 4.0\n",
    "L = int(FS*EPOCH_S)  # 512 samples/epoch\n",
    "TARGET_CHANNEL_DIM = 32\n",
    "GLYPH_BANDS = [(6,9),(8,12),(10,14)]\n",
    "GLYPH_RANKS = [4,8,12]\n",
    "BASELINE_BANDS = [(1,4),(4,8),(8,12),(12,30)]\n",
    "PERM_N = 1000\n",
    "SEED_MASTER = 20250928\n",
    "\n",
    "def pick_outdir():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            (p/\".touch_ok\").write_text(\"ok\", encoding=\"utf-8\")\n",
    "            (p/\".touch_ok\").unlink(missing_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "\n",
    "OUTROOT = pick_outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _fft_band_energy(X, fs, f_lo, f_hi):\n",
    "    n = X.shape[0]\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    S = np.abs(np.fft.rfft(X, axis=0))**2 / n\n",
    "    m = (freqs >= f_lo) & (freqs <= f_hi)\n",
    "    return S[m].sum(axis=0)\n",
    "\n",
    "def _cov_band(X, fs, band):\n",
    "    n = X.shape[0]\n",
    "    F = np.fft.rfft(X, axis=0)\n",
    "    freqs = np.fft.rfftfreq(n, d=1.0/fs)\n",
    "    m = (freqs >= band[0]) & (freqs <= band[1])\n",
    "    Fm = np.zeros_like(F); Fm[m] = F[m]\n",
    "    xb = np.fft.irfft(Fm, axis=0, n=n)\n",
    "    Xc = xb - xb.mean(axis=0, keepdims=True)\n",
    "    C = (Xc.T @ Xc) / max(1, (Xc.shape[0]-1))\n",
    "    return C\n",
    "\n",
    "def _hjorth_params(X):\n",
    "    dX = np.diff(X, axis=0)\n",
    "    var_x = X.var(axis=0)\n",
    "    var_dx = dX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob = np.sqrt(np.divide(var_dx, var_x, out=np.zeros_like(var_x), where=var_x>0))\n",
    "    ddX = np.diff(dX, axis=0)\n",
    "    var_ddx = ddX.var(axis=0) if dX.size else np.zeros(X.shape[1])\n",
    "    mob_dx = np.sqrt(np.divide(var_ddx, var_dx, out=np.zeros_like(var_dx), where=var_dx>0))\n",
    "    comp = np.divide(mob_dx, mob, out=np.zeros_like(mob), where=mob>0)\n",
    "    return np.vstack([var_x, mob, comp]).T\n",
    "\n",
    "def _orthobasis(channels, k, seed=13579):\n",
    "    rng_local = np.random.default_rng(seed + channels + k)\n",
    "    Q, _ = np.linalg.qr(rng_local.normal(size=(channels, channels)))\n",
    "    return Q[:, :k]\n",
    "\n",
    "def fixed_projection_matrix(ch_in, ch_out, seed=SEED_MASTER):\n",
    "    rng = np.random.default_rng(seed + 31*ch_in + 7*ch_out)\n",
    "    A = rng.normal(size=(ch_in, ch_out))\n",
    "    Q, _ = np.linalg.qr(A)\n",
    "    return Q[:, :ch_out]\n",
    "\n",
    "def map_channels_epoch(X_epoch, target_dim=TARGET_CHANNEL_DIM):\n",
    "    ch_in = X_epoch.shape[1]\n",
    "    if ch_in == target_dim: return X_epoch\n",
    "    P = fixed_projection_matrix(ch_in, target_dim)\n",
    "    return X_epoch @ P\n",
    "\n",
    "def baseline_features(X, fs):\n",
    "    feats = []\n",
    "    for lo,hi in BASELINE_BANDS:\n",
    "        feats.append(_fft_band_energy(X, fs, lo, hi).mean())\n",
    "    hj = _hjorth_params(X).mean(axis=0)\n",
    "    feats += list(hj)\n",
    "    bp_full = _fft_band_energy(X, FS, 0.5, 40.0)\n",
    "    feats += [bp_full.mean(), float(np.sqrt((bp_full**2).mean()))]\n",
    "    return np.array(feats, float)\n",
    "\n",
    "def glyph_stack_features(X, fs):\n",
    "    C_feats = []\n",
    "    for band in GLYPH_BANDS:\n",
    "        C = _cov_band(X, fs, band)\n",
    "        Cn = np.linalg.norm(C, 'fro') + 1e-9\n",
    "        for k in GLYPH_RANKS:\n",
    "            A = _orthobasis(C.shape[0], k)\n",
    "            C_feats.append(np.linalg.norm(A.T @ C @ A, 'fro') / Cn)\n",
    "    return np.array(C_feats, float)\n",
    "\n",
    "def model_fit_eval(train_X, train_y, test_X, test_y):\n",
    "    clf = LogisticRegression(max_iter=200, solver=\"lbfgs\")\n",
    "    clf.fit(train_X, train_y)\n",
    "    proba = clf.predict_proba(test_X)[:,1]\n",
    "    preds = (proba >= 0.5).astype(int)\n",
    "    return dict(auroc=float(roc_auc_score(test_y, proba)),\n",
    "                acc=float(accuracy_score(test_y, preds)),\n",
    "                proba=proba)\n",
    "\n",
    "def nested_cv_scores(X, y, n_splits=5):\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=4242)\n",
    "    aucs, accs = [], []\n",
    "    for tr, te in skf.split(X, y):\n",
    "        out = model_fit_eval(X[tr], y[tr], X[te], y[te])\n",
    "        aucs.append(out[\"auroc\"]); accs.append(out[\"acc\"])\n",
    "    return float(np.mean(aucs)), float(np.std(aucs)), float(np.mean(accs)), float(np.std(accs))\n",
    "\n",
    "def perm_test_delta(train_X, train_y, test_X, test_y, baseline_auc, n_perm=1000):\n",
    "    rngp = np.random.default_rng(9090)\n",
    "    aucs, deltas = [], []\n",
    "    for i in range(n_perm):\n",
    "        y_perm = train_y.copy(); rngp.shuffle(y_perm)\n",
    "        out = model_fit_eval(train_X, y_perm, test_X, test_y)\n",
    "        aucs.append(out[\"auroc\"]); deltas.append(out[\"auroc\"] - baseline_auc)\n",
    "        if (i+1) % max(1, n_perm//10) == 0:\n",
    "            say(f\"    … permutations {i+1}/{n_perm}\")\n",
    "    return np.array(aucs), np.array(deltas)\n",
    "\n",
    "# Epoch trim/reshape\n",
    "def reshape_epochs(csv_path, name):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    if 'label' not in df.columns:\n",
    "        raise ValueError(f\"{name} is missing a 'label' column.\")\n",
    "    X = df.drop(columns=['label']).values\n",
    "    y = df['label'].astype(int).values\n",
    "    n = (X.shape[0]//L)*L\n",
    "    X = X[:n]; y = y[:n]\n",
    "    X = X.reshape(-1, L, X.shape[1])\n",
    "    y = y[:X.shape[0]]\n",
    "    say(f\"[EPOCHS] {name}: epochs={X.shape[0]} | channels={X.shape[2]}\")\n",
    "    return X, y\n",
    "\n",
    "Xh, yh = reshape_epochs(hp, \"HUMAN\")\n",
    "Xm, ym = reshape_epochs(mp, \"MOUSE\")\n",
    "\n",
    "def featurize_domain(X_ep, y):\n",
    "    G_list, B_list = [], []\n",
    "    for i in range(X_ep.shape[0]):\n",
    "        Xp = map_channels_epoch(X_ep[i], TARGET_CHANNEL_DIM)\n",
    "        G_list.append(glyph_stack_features(Xp, FS))\n",
    "        B_list.append(baseline_features(Xp, FS))\n",
    "        if (i+1) % max(1, X_ep.shape[0]//4) == 0:\n",
    "            say(f\"    … featurized {i+1}/{X_ep.shape[0]}\")\n",
    "    G = np.asarray(G_list, float); B = np.asarray(B_list, float)\n",
    "    mask = ~np.isnan(G).any(axis=1)\n",
    "    return G[mask], B[mask], y[mask]\n",
    "\n",
    "say(\"[RUN] Featurizing HUMAN…\"); Gh, Bh, yh = featurize_domain(Xh, yh)\n",
    "say(\"[RUN] Featurizing MOUSE…\"); Gm, Bm, ym = featurize_domain(Xm, ym)\n",
    "\n",
    "say(\"[RUN] Train on HUMAN, blind test on MOUSE…\")\n",
    "res_g = model_fit_eval(Gh, yh, Gm, ym)\n",
    "res_b = model_fit_eval(Bh, yh, Bm, ym)\n",
    "\n",
    "say(\"[RUN] Nested CV on HUMAN…\")\n",
    "cv_g = nested_cv_scores(Gh, yh); cv_b = nested_cv_scores(Bh, yh)\n",
    "\n",
    "say(\"[RUN] Permutation test (n=1000)…\")\n",
    "perm_aucs_g, perm_deltas = perm_test_delta(Gh, yh, Gm, ym, baseline_auc=res_b[\"auroc\"], n_perm=1000)\n",
    "p_auroc = (np.sum(perm_aucs_g >= res_g[\"auroc\"]) + 1) / (1000 + 1)\n",
    "obs_delta = res_g[\"auroc\"] - res_b[\"auroc\"]\n",
    "p_delta = (np.sum(perm_deltas >= obs_delta) + 1) / (1000 + 1)\n",
    "\n",
    "# Plots & outputs\n",
    "def outdir():\n",
    "    for p in [Path(r\"C:\\mnt\\data\"), Path(\"/mnt/data\"), Path.cwd(), Path.home()/\"Documents\"]:\n",
    "        try:\n",
    "            p.mkdir(parents=True, exist_ok=True)\n",
    "            return p\n",
    "        except Exception:\n",
    "            continue\n",
    "    return Path.cwd()\n",
    "OUTROOT = outdir()\n",
    "OUTDIR = OUTROOT / \"CNT_OneCell_Groundbreaker\"; OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "fpr_g, tpr_g, _ = roc_curve(ym, res_g[\"proba\"])\n",
    "fpr_b, tpr_b, _ = roc_curve(ym, model_fit_eval(Bh, yh, Bm, ym)[\"proba\"])\n",
    "plt.plot(fpr_g, tpr_g, label=f\"Glyph (AUROC={res_g['auroc']:.3f})\")\n",
    "plt.plot(fpr_b, tpr_b, label=f\"Baseline (AUROC={res_b['auroc']:.3f})\")\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel(\"FPR\"); plt.ylabel(\"TPR\"); plt.legend(loc=\"lower right\")\n",
    "plt.title(\"Cross-Domain ROC (Train: HUMAN, Test: MOUSE)\")\n",
    "plt.tight_layout()\n",
    "roc_path = OUTDIR/\"transfer_roc.png\"; plt.savefig(roc_path, dpi=200); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.hist(perm_aucs_g, bins=30, alpha=0.7)\n",
    "plt.axvline(res_g[\"auroc\"], linestyle='--', linewidth=2)\n",
    "plt.xlabel(\"AUROC under label permutation (Glyph)\")\n",
    "plt.ylabel(\"Count\"); plt.title(f\"Permutation Test (n=1000) | p={p_auroc:.4f}\")\n",
    "plt.tight_layout()\n",
    "perm_path = OUTDIR/\"perm_null.png\"; plt.savefig(perm_path, dpi=200); plt.close()\n",
    "\n",
    "results = {\n",
    "    \"timestamp\": datetime.now(timezone.utc).isoformat(),\n",
    "    \"used_real_data\": True,\n",
    "    \"fs_hz\": 128.0, \"epoch_s\": 4.0, \"target_channel_dim\": 32,\n",
    "    \"n_human_epochs\": int(Gh.shape[0]), \"n_mouse_epochs\": int(Gm.shape[0]),\n",
    "    \"transfer\": {\n",
    "        \"glyph\": {\"auroc\": float(res_g[\"auroc\"]), \"acc\": float(res_g[\"acc\"])},\n",
    "        \"baseline\": {\"auroc\": float(res_b[\"auroc\"]), \"acc\": float(res_b[\"acc\"])},\n",
    "        \"delta_auroc\": float(obs_delta),\n",
    "        \"perm_test\": {\"n_perm\": 1000, \"p_auroc\": float(p_auroc), \"p_delta\": float(p_delta),\n",
    "                      \"perm_mean_auroc\": float(np.mean(perm_aucs_g)), \"perm_std_auroc\": float(np.std(perm_aucs_g))},\n",
    "    },\n",
    "    \"nested_cv_human\": {\n",
    "        \"glyph\": {\"auroc_mean\": float(cv_g[0]), \"auroc_std\": float(cv_g[1]), \"acc_mean\": float(cv_g[2]), \"acc_std\": float(cv_g[3])},\n",
    "        \"baseline\": {\"auroc_mean\": float(cv_b[0]), \"auroc_std\": float(cv_b[1]), \"acc_mean\": float(cv_b[2]), \"acc_std\": float(cv_b[3])}\n",
    "    },\n",
    "    \"prereg\": {\n",
    "        \"primary_endpoint\": \"Cross-domain AUROC (Train: HUMAN, Test: MOUSE) for glyph > baseline\",\n",
    "        \"null_hypothesis\": \"Glyph AUROC equals baseline under label permutation in training.\",\n",
    "        \"alpha\": 0.05, \"test\": \"One-sided permutation on training labels; n=1000\",\n",
    "        \"blinding\": \"Hyperparameters & projections fixed; test labels unseen; baseline fixed.\",\n",
    "        \"decision_rule\": \"Reject H0 if p_delta < 0.05 AND glyph AUROC > 0.70.\"\n",
    "    }\n",
    "}\n",
    "with open(OUTDIR/\"results.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(results, f, indent=2, ensure_ascii=False)\n",
    "\n",
    "summary = f\"\"\"\n",
    "CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\n",
    "==================================================\n",
    "UTC: {results['timestamp']}\n",
    "Data mode: REAL\n",
    "Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']}\n",
    "Target channel dim (fixed): {results['target_channel_dim']}\n",
    "\n",
    "TRANSFER (Train Human -> Test Mouse)\n",
    "- Glyph:    AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\n",
    "- Baseline: AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\n",
    "- Delta AUROC: {results['transfer']['delta_auroc']:.3f}\n",
    "\n",
    "Permutation Test (n=1000)\n",
    "- p(AUROC >= observed)         : p={results['transfer']['perm_test']['p_auroc']:.4f}\n",
    "- p(Delta AUROC >= observed)   : p={results['transfer']['perm_test']['p_delta']:.4f}\n",
    "\n",
    "Nested CV on Human\n",
    "- Glyph:    AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\n",
    "- Baseline: AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\n",
    "\n",
    "PREREG DECISION RULE (LOCKED)\n",
    "Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\n",
    "\n",
    "Artifacts: results.json, summary.txt, transfer_roc.png, perm_null.png, certificate_onecell.pdf\n",
    "\"\"\"\n",
    "with open(OUTDIR/\"summary.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(textwrap.dedent(summary))\n",
    "\n",
    "cert_path = OUTDIR/\"certificate_onecell.pdf\"\n",
    "with PdfPages(cert_path) as pdf:\n",
    "    fig = plt.figure(figsize=(8.5, 11)); ax = fig.add_axes([0.07, 0.07, 0.86, 0.86]); ax.axis(\"off\")\n",
    "    title = \"CNT One-Cell Groundbreaker — Prereg-Final (LOCKED)\"\n",
    "    hdr = f\"UTC: {results['timestamp']} | Data: REAL | Human epochs: {results['n_human_epochs']} | Mouse epochs: {results['n_mouse_epochs']} | Target ch: {results['target_channel_dim']}\"\n",
    "    body = (\n",
    "        f\"TRANSFER (Train Human -> Test Mouse)\\n\"\n",
    "        f\"  Glyph AUROC={results['transfer']['glyph']['auroc']:.3f}, ACC={results['transfer']['glyph']['acc']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['transfer']['baseline']['auroc']:.3f}, ACC={results['transfer']['baseline']['acc']:.3f}\\n\"\n",
    "        f\"  Δ AUROC={results['transfer']['delta_auroc']:.3f}\\n\\n\"\n",
    "        f\"Permutation Test (n=1000)\\n\"\n",
    "        f\"  p(AUROC ≥ observed)={results['transfer']['perm_test']['p_auroc']:.4f}\\n\"\n",
    "        f\"  p(Δ AUROC ≥ observed)={results['transfer']['perm_test']['p_delta']:.4f}\\n\\n\"\n",
    "        f\"Nested CV (Human)\\n\"\n",
    "        f\"  Glyph AUROC={results['nested_cv_human']['glyph']['auroc_mean']:.3f}±{results['nested_cv_human']['glyph']['auroc_std']:.3f}\\n\"\n",
    "        f\"  Baseline AUROC={results['nested_cv_human']['baseline']['auroc_mean']:.3f}±{results['nested_cv_human']['baseline']['auroc_std']:.3f}\\n\\n\"\n",
    "        \"PREREG DECISION RULE (LOCKED): Reject H0 if p_delta < 0.05 AND Glyph AUROC > 0.70 on transfer.\"\n",
    "    )\n",
    "    ax.text(0.5, 0.96, title, ha=\"center\", va=\"top\", fontsize=16, weight=\"bold\")\n",
    "    ax.text(0.5, 0.92, hdr, ha=\"center\", va=\"top\", fontsize=10)\n",
    "    ax.text(0.05, 0.82, body, ha=\"left\", va=\"top\", fontsize=10, family=\"monospace\")\n",
    "    # embed plots\n",
    "    try:\n",
    "        import matplotlib.image as mpimg\n",
    "        roc_img = mpimg.imread(OUTDIR/\"transfer_roc.png\")\n",
    "        perm_img = mpimg.imread(OUTDIR/\"perm_null.png\")\n",
    "        fig.add_axes([0.06, 0.48, 0.40, 0.26]).imshow(roc_img); plt.axis('off')\n",
    "        fig.add_axes([0.54, 0.48, 0.40, 0.26]).imshow(perm_img); plt.axis('off')\n",
    "        ax.text(0.06, 0.75, \"ROC (Human→Mouse)\", fontsize=9)\n",
    "        ax.text(0.54, 0.75, \"Permutation Null\", fontsize=9)\n",
    "    except Exception:\n",
    "        ax.text(0.05, 0.50, \"[Plots unavailable to embed]\", fontsize=9)\n",
    "    pdf.savefig(fig); plt.close(fig)\n",
    "\n",
    "print(textwrap.dedent(summary).strip())\n",
    "print(\"\\nArtifacts saved to:\", OUTDIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e51d176-0888-45b1-8ebd-8fd882b79c5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
