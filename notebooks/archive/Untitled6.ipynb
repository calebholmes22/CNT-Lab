{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa274a0-296e-4b37-a30f-e9a476234e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNT Lab — one-cell installer (Windows 11 / Py 3.13 friendly)\n",
    "# Run this once per new venv/kernel. Safe to re-run.\n",
    "\n",
    "import sys, subprocess, shutil, importlib, platform\n",
    "\n",
    "PY = sys.executable\n",
    "\n",
    "def pip(args):\n",
    "    print(f\"\\n[ pip ] pip {' '.join(args)}\")\n",
    "    subprocess.check_call([PY, \"-m\", \"pip\"] + args)\n",
    "\n",
    "print(\"== CNT Lab bootstrap ==\")\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "\n",
    "# 0) Base tooling\n",
    "pip([\"install\", \"--upgrade\", \"pip\", \"wheel\", \"setuptools\"])\n",
    "\n",
    "# 1) Jupyter + UX\n",
    "pip([\"install\",\n",
    "     \"jupyterlab\",\n",
    "     \"ipywidgets\",\n",
    "     \"jupyterlab_code_formatter\",\n",
    "     \"black\",\n",
    "     \"isort\",\n",
    "     \"nbformat\",\n",
    "     \"nbclient\",\n",
    "     \"jupyterlab-git\"])\n",
    "\n",
    "# 2) Numeric + data stack\n",
    "pip([\"install\",\n",
    "     \"numpy\",\n",
    "     \"scipy\",\n",
    "     \"pandas\",\n",
    "     \"pyarrow\",\n",
    "     \"polars\",\n",
    "     \"matplotlib\",\n",
    "     \"plotly\",\n",
    "     \"statsmodels\",\n",
    "     \"scikit-learn\",\n",
    "     \"scikit-image\",\n",
    "     \"numba\",\n",
    "     \"llvmlite\",\n",
    "     \"sympy\",\n",
    "     \"networkx\",\n",
    "     \"numexpr\",\n",
    "     \"fastparquet\",\n",
    "     \"python-dotenv\"])\n",
    "\n",
    "# 3) GPU / ML (try CUDA 12.4 first; fall back to CPU wheels if it fails)\n",
    "try:\n",
    "    pip([\"install\", \"--index-url\", \"https://download.pytorch.org/whl/cu124\",\n",
    "         \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "    cuda_ok = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"\\n[warn] CUDA 12.4 wheels failed; installing CPU-only PyTorch.\")\n",
    "    pip([\"install\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "    cuda_ok = False\n",
    "\n",
    "# CuPy w/ CUDA 12.x (optional but nice for GPU numpy); ignore failure gracefully\n",
    "try:\n",
    "    pip([\"install\", \"cupy-cuda12x\"])\n",
    "    cupy_ok = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"[warn] cupy-cuda12x failed (driver/CUDA mismatch?). Skipping.\")\n",
    "    cupy_ok = False\n",
    "\n",
    "# 4) Signal processing / EEG / time-series\n",
    "pip([\"install\",\n",
    "     \"mne\",\n",
    "     \"yasa\",\n",
    "     \"antropy\",\n",
    "     \"neurokit2\",\n",
    "     \"nitime\",\n",
    "     \"pywavelets\",\n",
    "     \"pingouin\"])\n",
    "\n",
    "# 5) Optimization, graphs, helpers\n",
    "pip([\"install\", \"cvxpy\", \"pydot\", \"graphviz\", \"networkx[default]\"])\n",
    "\n",
    "# 6) Files, tables, scientific IO\n",
    "pip([\"install\", \"h5py\", \"tables\", \"xarray\", \"netCDF4\", \"openpyxl\", \"lxml\", \"requests\"])\n",
    "\n",
    "# 7) Media / scraping helpers (adds imageio-ffmpeg for bundled ffmpeg)\n",
    "pip([\"install\", \"yt-dlp\", \"soundfile\", \"pydub\", \"ffmpeg-python\", \"imageio-ffmpeg\"])\n",
    "\n",
    "# 8) Visual extras (optional)\n",
    "pip([\"install\", \"shapely\", \"pyproj\", \"pyvis\", \"seaborn\"])\n",
    "\n",
    "# ---- Version report & sanity checks ----\n",
    "mods = [\n",
    " \"jupyterlab\",\"numpy\",\"scipy\",\"pandas\",\"pyarrow\",\"polars\",\"matplotlib\",\"plotly\",\n",
    " \"statsmodels\",\"sklearn\",\"numba\",\"sympy\",\"networkx\",\"torch\",\"torchvision\",\"torchaudio\",\n",
    " \"mne\",\"yasa\",\"antropy\",\"neurokit2\",\"nitime\",\"pywt\",\"pingouin\",\n",
    " \"cvxpy\",\"pydot\",\"graphviz\",\"h5py\",\"tables\",\"xarray\",\"netCDF4\",\"openpyxl\",\"requests\",\"yt_dlp\"\n",
    "]\n",
    "if cupy_ok:\n",
    "    mods.append(\"cupy\")\n",
    "\n",
    "print(\"\\n== Versions ==\")\n",
    "for m in mods:\n",
    "    try:\n",
    "        v = importlib.import_module(m).__version__\n",
    "    except Exception:\n",
    "        v = \"(installed, no __version__)\" if importlib.util.find_spec(m) else \"MISSING\"\n",
    "    print(f\"{m:12s}: {v}\")\n",
    "\n",
    "# Graphviz binary check (needed by graph drawing libs)\n",
    "print(\"\\n== Sanity checks ==\")\n",
    "dot = shutil.which(\"dot\")\n",
    "print(\"graphviz 'dot' on PATH:\", dot if dot else \"NOT FOUND (install system Graphviz if you need layout)\")\n",
    "if cuda_ok:\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"Torch CUDA available:\", torch.cuda.is_available(), \"| device_count:\", torch.cuda.device_count())\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"Torch CUDA device 0:\", torch.cuda.get_device_name(0))\n",
    "    except Exception as e:\n",
    "        print(\"Torch CUDA check error:\", e)\n",
    "else:\n",
    "    print(\"Installed CPU-only PyTorch (ok for dev; enable CUDA later if desired).\")\n",
    "\n",
    "# FFmpeg path via imageio-ffmpeg (helps yt-dlp/pydub conversions)\n",
    "try:\n",
    "    import imageio_ffmpeg as ioff\n",
    "    print(\"FFmpeg exe (imageio-ffmpeg):\", ioff.get_ffmpeg_exe())\n",
    "except Exception as e:\n",
    "    print(\"FFmpeg helper not found:\", e)\n",
    "\n",
    "print(\"\\nDone. If Jupyter UI extensions (like formatter) don’t appear, refresh the browser. If CUDA checks fail, update NVIDIA drivers and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eabd6739-0f2b-441d-8c08-90c3e56e8fd3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "No mouse *.npy files found. Set USE_DEMO=True to test, or place files in DATA_DIR.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m No mouse *.npy files found. Set USE_DEMO=True to test, or place files in DATA_DIR.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Roaming\\Python\\Python313\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# === CNT Mouse PLI Consensus — θ/γ quick test (single cell) ===\n",
    "# What this does:\n",
    "#   • Loads mouse LFP/EEG per subject: *.npy shaped [n_channels, n_time] (+ optional *.channels.txt)\n",
    "#   • Connectivity: Phase-Lag Index (PLI) using bandpass + Hilbert phases\n",
    "#   • Consensus: spectral clustering (k=2) on the co-association matrix\n",
    "#   • Null: label-preserving (randomize each subject’s labels but keep sizes)\n",
    "#   • Prints a table: band, n_subjects, cluster sizes, LOSO, null mean, p-value, intra/inter\n",
    "#\n",
    "# Notes:\n",
    "#   • Set FS to your sampling rate (common mouse LFP = 1 kHz; EEG varies ~250–1250 Hz)\n",
    "#   • KNN_K defaults lower (3) assuming fewer channels per mouse rig; adjust as needed\n",
    "#   • Bands default to θ=(6–12 Hz), γ=(30–55 Hz); add high-γ=(60–100 Hz) if you’d like\n",
    "\n",
    "import os, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "USE_DEMO   = False  # True = synthesize a small mouse-like dataset to test pipeline\n",
    "DATA_DIR   = r\"C:\\Users\\caleb\\CNT_Lab\\mouse_eeg\"  # folder with mouse_XX.npy\n",
    "GLOB       = \"*.npy\"                               # pattern for subjects\n",
    "FS         = 1000.0                                # <-- set to your mouse sampling rate (Hz)\n",
    "SUBJ_LIMIT = 12                                    # how many subjects to use\n",
    "\n",
    "# Mouse-sensible bands (you can add \"high_gamma\": (60, 100))\n",
    "BANDS_HZ   = { \"theta\": (6.0, 12.0), \"gamma\": (30.0, 55.0) }\n",
    "\n",
    "K_FIXED    = 2       # force non-trivial split\n",
    "KNN_K      = 3       # sparser graphs for typical low/medium channel counts\n",
    "NULL_PERMS = 200     # raise to 500–1000 if you have time\n",
    "OUT_ROOT   = r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_quicktest\"\n",
    "# ----------------------------------------------\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "OUT_MET = os.path.join(OUT_ROOT, \"metrics\"); os.makedirs(OUT_MET, exist_ok=True)\n",
    "OUT_TAB = os.path.join(OUT_ROOT, \"tables\");  os.makedirs(OUT_TAB, exist_ok=True)\n",
    "OUT_FIG = os.path.join(OUT_ROOT, \"figures\"); os.makedirs(OUT_FIG, exist_ok=True)\n",
    "\n",
    "# --------- helpers ---------\n",
    "def bandpass(x,fs,lo,hi,order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X,fs,lo,hi):\n",
    "    n = X.shape[0]; Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = bandpass(X[c], fs, lo, hi)\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k=3):\n",
    "    W = W.copy(); n = W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx = np.argsort(W[i])[::-1]; keep = idx[:min(k, n-1)]\n",
    "        mask = np.ones(n, dtype=bool); mask[keep] = False\n",
    "        W[i, mask] = 0.0\n",
    "    W = np.maximum(W, W.T); np.fill_diagonal(W, 0.0); return W\n",
    "\n",
    "def laplacian(W):\n",
    "    d = W.sum(1); d = np.where(d<=1e-12, 1.0, d)\n",
    "    Dmh = np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - Dmh @ W @ Dmh\n",
    "\n",
    "def spec_labels(W,k):\n",
    "    L = laplacian(W)\n",
    "    evals, evecs = np.linalg.eigh(L)\n",
    "    U = evecs[:, 1:k] if k>1 else evecs[:, :1]\n",
    "    U = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def build_coassoc(label_list):\n",
    "    n = len(label_list[0]); m = len(label_list)\n",
    "    co = np.zeros((n,n), float)\n",
    "    for lab in label_list:\n",
    "        for i in range(n):\n",
    "            li = lab[i]\n",
    "            for j in range(n):\n",
    "                co[i,j] += 1.0 if li == lab[j] else 0.0\n",
    "    return co / m\n",
    "\n",
    "def loso_ari_via_coassoc(label_list):\n",
    "    co_full = build_coassoc(label_list)\n",
    "    cons_full = spec_labels(co_full, k=2)\n",
    "    aris=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave = [lab for i, lab in enumerate(label_list) if i!=s]\n",
    "        co_l  = build_coassoc(leave)\n",
    "        cons_l= spec_labels(co_l, k=2)\n",
    "        aris.append(adjusted_rand_score(cons_full, cons_l))\n",
    "    return float(np.median(aris)), cons_full, co_full\n",
    "\n",
    "def randomize_labels_same_sizes(lab, rng):\n",
    "    n = len(lab)\n",
    "    uniq, cnts = np.unique(lab, return_counts=True)\n",
    "    idx = np.arange(n); rng.shuffle(idx)\n",
    "    out = np.empty(n, dtype=int); start=0\n",
    "    for label, c in zip(uniq, cnts):\n",
    "        seg = idx[start:start+c]; out[seg]=label; start+=c\n",
    "    return out\n",
    "\n",
    "# --------- load subjects or synthesize ---------\n",
    "if USE_DEMO:\n",
    "    rng = np.random.default_rng(7)\n",
    "    N_SUBJ, N_CH, T = 8, 16, int(FS*10)  # 10 s per subject\n",
    "    files = []\n",
    "    for s in range(N_SUBJ):\n",
    "        X = rng.normal(0,1,size=(N_CH, T))\n",
    "        # inject theta driver into \"hippocampal-like\" subset\n",
    "        t = np.arange(T)/FS\n",
    "        driver = np.sin(2*np.pi*8.0*t + rng.uniform(0,2*np.pi))\n",
    "        for c in range(N_CH//2, N_CH):\n",
    "            X[c] += 0.7*driver + 0.2*rng.normal(0,1,T)\n",
    "        path = os.path.join(OUT_TAB, f\"mouse_demo_{s:02d}.npy\")\n",
    "        np.save(path, X.astype(np.float32)); files.append(path)\n",
    "else:\n",
    "    files = sorted(glob.glob(os.path.join(DATA_DIR, GLOB)))[:SUBJ_LIMIT]\n",
    "    if not files:\n",
    "        raise SystemExit(\"No mouse *.npy files found. Set USE_DEMO=True to test, or place files in DATA_DIR.\")\n",
    "\n",
    "print(f\"[info] subjects={len(files)}\")\n",
    "\n",
    "# --------- run per band ---------\n",
    "rows = []\n",
    "rng = np.random.default_rng(11)\n",
    "for band, (lo, hi) in BANDS_HZ.items():\n",
    "    subj_labels=[]\n",
    "    for f in files:\n",
    "        X = np.load(f)\n",
    "        W = pli_matrix(X, FS, lo, hi)\n",
    "        W = knn(W, KNN_K)\n",
    "        labs = spec_labels(W, K_FIXED)\n",
    "        subj_labels.append(labs)\n",
    "\n",
    "    loso, cons_real, co_real = loso_ari_via_coassoc(subj_labels)\n",
    "    np.save(os.path.join(OUT_TAB, f\"mouse__{band}__coassoc.npy\"), co_real)\n",
    "    np.save(os.path.join(OUT_TAB, f\"mouse__{band}__consensus_labels.npy\"), cons_real)\n",
    "\n",
    "    # null (label-preserving)\n",
    "    null_aris=[]\n",
    "    for p in range(NULL_PERMS):\n",
    "        nlabs = [randomize_labels_same_sizes(lab, rng) for lab in subj_labels]\n",
    "        _, cons_n, _ = loso_ari_via_coassoc(nlabs)\n",
    "        null_aris.append(adjusted_rand_score(cons_real, cons_n))\n",
    "    null_aris = np.array(null_aris, float)\n",
    "    p_val = float((np.sum(null_aris >= loso) + 1) / (len(null_aris) + 1))\n",
    "\n",
    "    uniq,cnts = np.unique(cons_real, return_counts=True)\n",
    "    intra = co_real[cons_real[:,None]==cons_real[None,:]].mean()\n",
    "    inter = co_real[cons_real[:,None]!=cons_real[None,:]].mean()\n",
    "    ratio = float(intra/(inter+1e-12))\n",
    "\n",
    "    rows.append([band, len(files), cnts.tolist(), float(loso), float(null_aris.mean()), p_val, ratio])\n",
    "\n",
    "# print summary\n",
    "df = pd.DataFrame(rows, columns=[\"band\",\"n_subjects\",\"cluster_sizes\",\"LOSO\",\"null_ari_mean\",\"p_value\",\"intra_over_inter\"])\n",
    "print(\"\\n=== CNT Mouse PLI consensus — quick test ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# save summary CSV and a quick figure\n",
    "csv_path = os.path.join(OUT_ROOT, \"mouse_quicktest_summary.csv\")\n",
    "df.to_csv(csv_path, index=False)\n",
    "plt.figure()\n",
    "plt.plot(np.arange(len(df)), df[\"p_value\"].values, marker=\"o\")\n",
    "plt.xticks(np.arange(len(df)), df[\"band\"].values)\n",
    "plt.ylabel(\"p-value\"); plt.title(\"Mouse PLI consensus — p-values by band\")\n",
    "plt.tight_layout(); plt.savefig(os.path.join(OUT_FIG, \"mouse_pvalues.png\"), dpi=160); plt.close()\n",
    "print(\"\\nSaved:\")\n",
    "print(\"  - Summary CSV:\", csv_path)\n",
    "print(\"  - p-values plot:\", os.path.join(OUT_FIG, \"mouse_pvalues.png\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c87d8073-6af2-4cc4-aaa8-6b216c9d2639",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[convert] subjects prepared: 8\n",
      "\n",
      "=== CNT Mouse (OpenNeuro) — PLI consensus ===\n",
      " band  n_subjects cluster_sizes     LOSO  null_ari_mean  p_value  intra_over_inter\n",
      "theta           8        [8, 8] 0.531250      -0.006407 0.009950          1.660000\n",
      "gamma           8        [9, 7] 0.640664       0.003058 0.004975          1.618615\n",
      "\n",
      "Saved summary to: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_openneuro\\summary.csv\n"
     ]
    }
   ],
   "source": [
    "# === Mouse PLI consensus from OpenNeuro — download → convert → run (single cell) ===\n",
    "# What this does:\n",
    "#   1) (Optionally) download an OpenNeuro dataset (rodent EEG/LFP) with openneuro-py\n",
    "#   2) Convert per subject to *.npy [n_channels, n_time] + channels.txt (downsample + 60 s slice)\n",
    "#   3) Run PLI + spectral-on-coassoc (k=2) for theta (6–12 Hz) and gamma (30–55 Hz)\n",
    "#   4) Save artifacts in C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_openneuro\\\n",
    "\n",
    "import os, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.signal import butter, filtfilt, hilbert, decimate\n",
    "\n",
    "# -------------------- CONFIG --------------------\n",
    "USE_DEMO   = True          # Set to False when you have a real OpenNeuro dsID below\n",
    "MOUSE_DS   = \"dsXXXXXX\"    # e.g., \"ds004***\" (set a real OpenNeuro dataset ID)\n",
    "SUBJ_LIMIT = 12            # how many subjects to use (lower first, raise later)\n",
    "FS_IN      = 1000.0        # assumed/target fs (Hz) after conversion (we'll resample if needed)\n",
    "FS_OUT     = 1000.0        # resample to this (Hz) for the analysis stage\n",
    "SLICE_SEC  = 60            # keep first 60 seconds per subject for a quick test\n",
    "FILE_FILTERS = [\"*eeg*.edf\", \"*eeg*.mat\", \"*lfp*.npy\", \"*lfp*.mat\"]  # keep small, adjust if needed\n",
    "\n",
    "# Bands for mice\n",
    "BANDS_HZ   = {\"theta\": (6.0, 12.0), \"gamma\": (30.0, 55.0)}\n",
    "K_FIXED    = 2             # consensus split\n",
    "KNN_K      = 3             # sparse graphs (typical rodent rigs have fewer channels)\n",
    "NULL_PERMS = 200           # raise later\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DL_ROOT    = os.path.join(ROOT, \"mouse_openneuro_raw\")       # raw downloads\n",
    "OUT_DATA   = os.path.join(ROOT, \"mouse_eeg\")                 # exported *.npy\n",
    "OUT_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\")\n",
    "# ------------------------------------------------\n",
    "\n",
    "for p in [DL_ROOT, OUT_DATA, OUT_ROOT, os.path.join(OUT_ROOT,\"metrics\"), os.path.join(OUT_ROOT,\"tables\"), os.path.join(OUT_ROOT,\"figures\")]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# -------------------- 1) DOWNLOAD (OpenNeuro) --------------------\n",
    "if not USE_DEMO:\n",
    "    try:\n",
    "        import openneuro as on\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"openneuro-py\"])\n",
    "        import openneuro as on\n",
    "    print(f\"[download] dataset={MOUSE_DS}\")\n",
    "    # Download only files matching our filters to keep things light\n",
    "    for patt in FILE_FILTERS:\n",
    "        try:\n",
    "            on.download(dataset=MOUSE_DS, target=DL_ROOT, include=[patt], strict=False)\n",
    "            print(f\"[download] included: {patt}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[warn] include {patt} failed or empty: {e}\")\n",
    "\n",
    "# -------------------- 2) CONVERT to NPY --------------------\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "def try_load_edf(fp):\n",
    "    try:\n",
    "        import mne\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"mne\", \"pooch\"])\n",
    "        import mne\n",
    "    raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "    raw.pick_types(eeg=True, ecg=False, eog=False, emg=False, stim=False, misc=False)\n",
    "    return raw.get_data(), raw.info[\"sfreq\"], [ch for ch in raw.ch_names]\n",
    "\n",
    "def try_load_mat(fp):\n",
    "    # expects items 'data' [n_ch, n_t] and optional 'fs' in the MAT\n",
    "    from scipy.io import loadmat\n",
    "    m = loadmat(fp)\n",
    "    # heuristic: find the 2D array with the largest number of elements\n",
    "    arr = None\n",
    "    for k,v in m.items():\n",
    "        if isinstance(v, np.ndarray) and v.ndim == 2 and v.size > (arr.size if arr is not None else 0):\n",
    "            arr = v\n",
    "    if arr is None:\n",
    "        raise RuntimeError(\"No 2D array found in MAT\")\n",
    "    fs = float(m.get(\"fs\", np.array([[FS_IN]])).squeeze())\n",
    "    ch = [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "    return arr.astype(float), fs, ch\n",
    "\n",
    "def try_load_npy(fp):\n",
    "    X = np.load(fp)\n",
    "    if X.ndim != 2:\n",
    "        raise RuntimeError(\"expected [n_ch, n_t]\")\n",
    "    ch = [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "    return X.astype(float), FS_IN, ch\n",
    "\n",
    "def safe_resample(X, fs_in, fs_out):\n",
    "    if abs(fs_in - fs_out) < 1e-6:\n",
    "        return X, fs_in\n",
    "    # integer decimation if close; otherwise crude polyphase via SciPy not used here.\n",
    "    q = int(round(fs_in / fs_out))\n",
    "    if abs(fs_in / q - fs_out) < 1e-3 and q >= 1:\n",
    "        Y = np.vstack([decimate(X[i], q, ftype='fir', zero_phase=True) for i in range(X.shape[0])])\n",
    "        return Y, fs_out\n",
    "    # fallback: keep as-is (or implement resample_poly if needed)\n",
    "    return X, fs_in\n",
    "\n",
    "def export_subjects_from_folder(in_root, out_dir, subj_limit=SUBJ_LIMIT):\n",
    "    files = []\n",
    "    for patt in FILE_FILTERS + [\"*.npy\", \"*.edf\", \"*.mat\"]:\n",
    "        files.extend(glob.glob(os.path.join(in_root, \"**\", patt), recursive=True))\n",
    "    files = sorted(list(set(files)))\n",
    "    exported = []\n",
    "    for i, fp in enumerate(files[:1000]):  # hard-cap scan\n",
    "        try:\n",
    "            if fp.lower().endswith(\".edf\"):\n",
    "                X, fs, ch = try_load_edf(fp)\n",
    "            elif fp.lower().endswith(\".mat\"):\n",
    "                X, fs, ch = try_load_mat(fp)\n",
    "            elif fp.lower().endswith(\".npy\"):\n",
    "                X, fs, ch = try_load_npy(fp)\n",
    "            else:\n",
    "                continue\n",
    "            # resample\n",
    "            X, fs2 = safe_resample(X, fs, FS_OUT)\n",
    "            # slice to SLICE_SEC\n",
    "            n_keep = int(SLICE_SEC * fs2)\n",
    "            if X.shape[1] >= n_keep:\n",
    "                X = X[:, :n_keep]\n",
    "            else:\n",
    "                reps = int(np.ceil(n_keep / X.shape[1]))\n",
    "                X = np.tile(X, reps)[:, :n_keep]\n",
    "            base = os.path.join(out_dir, f\"mouse_{len(exported):02d}\")\n",
    "            np.save(base + \".npy\", X.astype(np.float32))\n",
    "            with open(base + \".channels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                for name in ch: f.write(f\"{name}\\n\")\n",
    "            exported.append(base + \".npy\")\n",
    "            if len(exported) >= subj_limit:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\"[skip] {fp}: {e}\")\n",
    "    return exported\n",
    "\n",
    "if USE_DEMO:\n",
    "    # synthesize small mouse-like set\n",
    "    rng = np.random.default_rng(7)\n",
    "    N_SUBJ, N_CH, T = 8, 16, int(FS_OUT * SLICE_SEC)\n",
    "    paths = []\n",
    "    for s in range(N_SUBJ):\n",
    "        X = rng.normal(0,1,size=(N_CH, T))\n",
    "        t = np.arange(T)/FS_OUT\n",
    "        theta_drv = np.sin(2*np.pi*8.0*t + rng.uniform(0,2*np.pi))\n",
    "        for c in range(N_CH//2, N_CH):\n",
    "            X[c] += 0.6*theta_drv + 0.2*rng.normal(0,1,T)\n",
    "        base = os.path.join(OUT_DATA, f\"mouse_demo_{s:02d}\")\n",
    "        np.save(base + \".npy\", X.astype(np.float32))\n",
    "        with open(base + \".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "            for i in range(N_CH): f.write(f\"ch{i}\\n\")\n",
    "        paths.append(base + \".npy\")\n",
    "else:\n",
    "    # export from OpenNeuro downloads\n",
    "    paths = export_subjects_from_folder(os.path.join(DL_ROOT, MOUSE_DS), OUT_DATA, subj_limit=SUBJ_LIMIT)\n",
    "\n",
    "print(f\"[convert] subjects prepared: {len(paths)}\")\n",
    "\n",
    "# -------------------- 3) RUN PLI CONSENSUS --------------------\n",
    "def bandpass(x,fs,lo,hi,order=4):\n",
    "    b,a=butter(order,[lo/(fs/2), hi/(fs/2)],btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X,fs,lo,hi):\n",
    "    n=X.shape[0]; Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=bandpass(X[c], fs, lo, hi)\n",
    "    ph=np.angle(hilbert(Y, axis=1)); W=np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "def knn(W,k=KNN_K):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:min(k,n-1)]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W): d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0])-D@W@D\n",
    "def spec(W,k):\n",
    "    L=lap(W); e,v=np.linalg.eigh(L); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/=np.linalg.norm(U,axis=1,keepdims=True)+1e-12\n",
    "    return KMeans(n_clusters=k,n_init=50,random_state=42).fit_predict(U)\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n))\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n):\n",
    "                co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "def loso_via_coassoc(labels):\n",
    "    cof=coassoc(labels); cons=spec(cof,2); vals=[]\n",
    "    for s in range(len(labels)):\n",
    "        leave=[lab for i,lab in enumerate(labels) if i!=s]\n",
    "        cons_l=spec(coassoc(leave),2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "def rand_same_sizes(lab, rng):\n",
    "    n=len(lab); uniq,cnts=np.unique(lab, return_counts=True)\n",
    "    idx=np.arange(n); rng.shuffle(idx); out=np.empty(n,int); st=0\n",
    "    for L,c in zip(uniq,cnts): seg=idx[st:st+c]; out[seg]=L; st+=c\n",
    "    return out\n",
    "\n",
    "rows=[]; rng=np.random.default_rng(11)\n",
    "use_paths = paths[:SUBJ_LIMIT]\n",
    "if len(use_paths) < 4:\n",
    "    raise SystemExit(\"Not enough mouse subjects prepared. Try USE_DEMO=True or increase SUBJ_LIMIT after download.\")\n",
    "\n",
    "for band,(lo,hi) in BANDS_HZ.items():\n",
    "    labs=[]\n",
    "    for pth in use_paths:\n",
    "        X=np.load(pth)\n",
    "        W=pli_matrix(X, FS_OUT, lo, hi); W=knn(W, KNN_K); labs.append(spec(W, K_FIXED))\n",
    "    loso, cons, cof = loso_via_coassoc(labs)\n",
    "    null=[]\n",
    "    for _ in range(NULL_PERMS):\n",
    "        nlabs=[rand_same_sizes(l, rng) for l in labs]\n",
    "        _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "        null.append(adjusted_rand_score(cons, cons_n))\n",
    "    null=np.array(null,float)\n",
    "    p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "    uniq,cnts=np.unique(cons, return_counts=True)\n",
    "    intra=cof[cons[:,None]==cons[None,:]].mean()\n",
    "    inter=cof[cons[:,None]!=cons[None,:]].mean()\n",
    "    rows.append([band, len(use_paths), cnts.tolist(), float(loso), float(null.mean()), p, float(intra/(inter+1e-12))])\n",
    "\n",
    "df=pd.DataFrame(rows, columns=[\"band\",\"n_subjects\",\"cluster_sizes\",\"LOSO\",\"null_ari_mean\",\"p_value\",\"intra_over_inter\"])\n",
    "print(\"\\n=== CNT Mouse (OpenNeuro) — PLI consensus ===\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "# save\n",
    "os.makedirs(os.path.join(OUT_ROOT,\"metrics\"), exist_ok=True)\n",
    "os.makedirs(os.path.join(OUT_ROOT,\"tables\"), exist_ok=True)\n",
    "df.to_csv(os.path.join(OUT_ROOT, \"summary.csv\"), index=False)\n",
    "print(\"\\nSaved summary to:\", os.path.join(OUT_ROOT, \"summary.csv\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3626b1e2-bbcd-456a-af0f-af268e0f07e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Mouse PLI consensus — tightened (KNN_K=4, NULL_PERMS=500) ===\n",
      "      band  n_subjects cluster_sizes     LOSO  null_ari_mean  p_value  intra_over_inter\n",
      "     theta           8        [8, 8] 1.000000       0.000301 0.001996          2.077381\n",
      "     gamma           8        [9, 7] 0.766082      -0.010750 0.001996          1.595804\n",
      "high_gamma           8        [7, 9] 0.750000       0.003739 0.001996          1.506626\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_openneuro\\mouse_tightened_summary.csv\n"
     ]
    }
   ],
   "source": [
    "# === Mouse PLI consensus — tighten & extend (θ, γ, high-γ) ===\n",
    "# Uses the same exported mouse subjects you just created in C:\\Users\\caleb\\CNT_Lab\\mouse_eeg\n",
    "# Changes from quick test:\n",
    "#   • Adds high_gamma (60–100 Hz)\n",
    "#   • Increases NULL_PERMS to 500\n",
    "#   • Uses KNN_K = 4 (a bit tighter than 3)\n",
    "# Saves a new summary CSV alongside your previous one.\n",
    "\n",
    "import os, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR   = os.path.join(ROOT, \"mouse_eeg\")\n",
    "OUT_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\")  # reuse folder\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "OUT_MET = os.path.join(OUT_ROOT, \"metrics\"); os.makedirs(OUT_MET, exist_ok=True)\n",
    "OUT_TAB = os.path.join(OUT_ROOT, \"tables\");  os.makedirs(OUT_TAB, exist_ok=True)\n",
    "OUT_FIG = os.path.join(OUT_ROOT, \"figures\"); os.makedirs(OUT_FIG, exist_ok=True)\n",
    "\n",
    "FS        = 1000.0\n",
    "SUBJ_LIMIT= 12   # raise if you prep more subjects later\n",
    "BANDS_HZ  = {\"theta\": (6.0, 12.0), \"gamma\": (30.0, 55.0), \"high_gamma\": (60.0, 100.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 4\n",
    "NULL_PERMS= 500\n",
    "\n",
    "def bandpass(x,fs,lo,hi,order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X,fs,lo,hi):\n",
    "    n=X.shape[0]; Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=bandpass(X[c],fs,lo,hi)\n",
    "    ph=np.angle(hilbert(Y,axis=1))\n",
    "    W=np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            d=ph[i]-ph[j]\n",
    "            W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:min(k,n-1)]\n",
    "        m=np.ones(n,bool); m[keep]=False; W[i,m]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0])-D@W@D\n",
    "def spec(W,k):\n",
    "    L=lap(W); e,v=np.linalg.eigh(L); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/=np.linalg.norm(U,axis=1,keepdims=True)+1e-12\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n))\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n):\n",
    "                co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "def loso_via_coassoc(labels):\n",
    "    cof=coassoc(labels); cons=spec(cof,2); vals=[]\n",
    "    for s in range(len(labels)):\n",
    "        leave=[lab for i,lab in enumerate(labels) if i!=s]\n",
    "        cons_l=spec(coassoc(leave),2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "def rand_same_sizes(lab, rng):\n",
    "    n=len(lab); uniq,cnts=np.unique(lab, return_counts=True)\n",
    "    idx=np.arange(n); rng.shuffle(idx); out=np.empty(n,int); st=0\n",
    "    for L,c in zip(uniq,cnts): seg=idx[st:st+c]; out[seg]=L; st+=c\n",
    "    return out\n",
    "\n",
    "files = sorted(glob.glob(os.path.join(DATA_DIR, \"*.npy\")))[:SUBJ_LIMIT]\n",
    "if len(files) < 4:\n",
    "    raise SystemExit(\"Need at least 4 mouse subjects (.npy).\")\n",
    "\n",
    "rows=[]; rng=np.random.default_rng(13)\n",
    "for band,(lo,hi) in BANDS_HZ.items():\n",
    "    labs=[]\n",
    "    for f in files:\n",
    "        X=np.load(f)\n",
    "        W=pli_matrix(X, FS, lo, hi); W=knn(W, KNN_K); labs.append(spec(W, K_FIXED))\n",
    "    loso, cons, cof = loso_via_coassoc(labs)\n",
    "    null=[]\n",
    "    for _ in range(NULL_PERMS):\n",
    "        nlabs=[rand_same_sizes(l, rng) for l in labs]\n",
    "        _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "        null.append(adjusted_rand_score(cons, cons_n))\n",
    "    null=np.array(null,float)\n",
    "    p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "    uniq,cnts=np.unique(cons, return_counts=True)\n",
    "    intra=cof[cons[:,None]==cons[None,:]].mean()\n",
    "    inter=cof[cons[:,None]!=cons[None,:]].mean()\n",
    "    rows.append([band, len(files), cnts.tolist(), float(loso), float(null.mean()), p, float(intra/(inter+1e-12))])\n",
    "\n",
    "df=pd.DataFrame(rows, columns=[\"band\",\"n_subjects\",\"cluster_sizes\",\"LOSO\",\"null_ari_mean\",\"p_value\",\"intra_over_inter\"])\n",
    "print(\"\\n=== Mouse PLI consensus — tightened (KNN_K=4, NULL_PERMS=500) ===\")\n",
    "print(df.to_string(index=False))\n",
    "out_csv=os.path.join(OUT_ROOT, \"mouse_tightened_summary.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"\\nSaved:\", out_csv)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02e1f534-b00f-4403-a833-ec0f9c39c28d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[human] WARNING: no left/right mapping; skipping.\n",
      "[mouse] tables folder not found or no bands present; skipping.\n",
      "\n",
      "No data frames to merge; check paths and bands.\n"
     ]
    }
   ],
   "source": [
    "# === CNT Hemispheric + Anterior/Posterior Analysis — Humans + Mice (single expanded cell) ===\n",
    "# Computes, for each species (human/mouse) and each available band:\n",
    "#   1) Within-hemisphere dual-module checks (left & right): same-module vs cross-module ratios.\n",
    "#   2) Cross-hemisphere coupling: (within-hemi vs cross-hemi) × (within-mod vs cross-mod) means.\n",
    "#   3) Asymmetry per module:\n",
    "#       - Left–Right LI = (Left−Right)/(Left+Right)  using degree to same-module nodes.\n",
    "#       - Anterior–Posterior AI = (Ant−Post)/(Ant+Post) using degree to same-module nodes.\n",
    "#   4) Module composition counts across hemispheres and ant/post quadrants.\n",
    "# Also writes:\n",
    "#   - Humans CSV  → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\hemisphere_humans.csv\n",
    "#   - Mice CSV    → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_openneuro\\hemisphere_mice.csv\n",
    "#   - Merged CSV  → C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_hemi_AP_merged.csv\n",
    "#\n",
    "# OPTIONAL: Set SAVE_FIGS=True to export small co-association images reordered by hemisphere+module.\n",
    "# NOTE: This operates on consensus artifacts already produced by your PLI spectral-on-coassoc pipeline.\n",
    "\n",
    "import os, re, glob, numpy as np, pandas as pd\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "ROOT            = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "# Human artifacts (n≈30):\n",
    "H_TAB_DIR       = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\tables\")\n",
    "H_CH_TXT        = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "H_OUT_CSV       = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\hemisphere_humans.csv\")\n",
    "H_BANDS         = [\"alpha\",\"theta\",\"beta\"]\n",
    "\n",
    "# Mouse artifacts (n≈8):\n",
    "M_TAB_DIR       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\tables\")\n",
    "M_CH_DIR        = os.path.join(ROOT, r\"mouse_eeg\")\n",
    "M_OUT_CSV       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\hemisphere_mice.csv\")\n",
    "M_BANDS_CAND    = [\"theta\",\"gamma\",\"high_gamma\"]  # on-disk check below\n",
    "\n",
    "# Output (merged)\n",
    "MERGED_CSV      = os.path.join(ROOT, r\"artifacts\\CNT_PLI_hemi_AP_merged.csv\")\n",
    "\n",
    "# Figures (optional)\n",
    "SAVE_FIGS       = True\n",
    "FIG_DIR_HUMAN   = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_hemi\")\n",
    "FIG_DIR_MOUSE   = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\figures_hemi\")\n",
    "# --------------------------------------------\n",
    "\n",
    "# Make figure dirs if needed\n",
    "if SAVE_FIGS:\n",
    "    os.makedirs(FIG_DIR_HUMAN, exist_ok=True)\n",
    "    os.makedirs(FIG_DIR_MOUSE, exist_ok=True)\n",
    "\n",
    "# File suffixes for artifacts\n",
    "CONS_SUFFIX = \"__consensus_labels.npy\"\n",
    "CO_SUFFIX   = \"__coassoc.npy\"\n",
    "\n",
    "# --------------- Name helpers ---------------\n",
    "def norm_key(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]\", \"\", s).upper()\n",
    "\n",
    "# Aliases for older 10–20:\n",
    "ALIAS_EQUIV = {\n",
    "    \"T3\":\"T7\", \"T4\":\"T8\", \"T5\":\"P7\", \"T6\":\"P8\",\n",
    "    \"FP1\":\"Fp1\", \"FP2\":\"Fp2\", \"FPZ\":\"Fpz\", \"CZ\":\"Cz\", \"PZ\":\"Pz\", \"FZ\":\"Fz\", \"OZ\":\"Oz\", \"POZ\":\"POz\"\n",
    "}\n",
    "\n",
    "# --------------- Hemisphere mapping ---------------\n",
    "def chan_hemisphere_map(ch_names):\n",
    "    \"\"\"\n",
    "    Returns left, right, midline indices using:\n",
    "      - Explicit tokens: '_L', '-L', '(L)', 'LEFT'  → Left\n",
    "                         '_R', '-R', '(R)', 'RIGHT' → Right\n",
    "      - 10–20 rule: odd=Left (Fp1,F3,...), even=Right (Fp2,F4,...), 'Z' midline (Fz,Cz,Pz,Oz)\n",
    "    Unknown → midline (conservative).\n",
    "    \"\"\"\n",
    "    L, R, Z = [], [], []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        raw = ch\n",
    "        # alias expansion for matching\n",
    "        alias = ALIAS_EQUIV.get(raw.upper(), raw)\n",
    "        key = norm_key(alias)\n",
    "\n",
    "        # Explicit L/R tags first\n",
    "        if re.search(r\"(^|[_\\-\\(])L($|[_\\-\\)])\", raw, flags=re.I) or re.search(r\"LEFT\", raw, flags=re.I):\n",
    "            L.append(i); continue\n",
    "        if re.search(r\"(^|[_\\-\\(])R($|[_\\-\\)])\", raw, flags=re.I) or re.search(r\"RIGHT\", raw, flags=re.I):\n",
    "            R.append(i); continue\n",
    "\n",
    "        # Midline 'Z' near end\n",
    "        if re.search(r\"[A-Za-z]Z$\", alias, flags=re.I):\n",
    "            Z.append(i); continue\n",
    "\n",
    "        # 10–20 odd/even trailing digit\n",
    "        m = re.search(r\"(\\d+)$\", alias)\n",
    "        if m:\n",
    "            try:\n",
    "                d = int(m.group(1))\n",
    "                (L if d % 2 == 1 else R).append(i)\n",
    "                continue\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        # If unknown but contains 'Z' anywhere → midline\n",
    "        if 'Z' in key:\n",
    "            Z.append(i)\n",
    "        else:\n",
    "            # conservative default\n",
    "            Z.append(i)\n",
    "    return np.array(L, int), np.array(R, int), np.array(Z, int)\n",
    "\n",
    "# --------------- Anterior / Posterior mapping ---------------\n",
    "ANT_PREFIXES = (\"FP\",\"AF\",\"F\",\"FC\")\n",
    "MID_PREFIXES = (\"C\",)      # central strip\n",
    "POST_PREFIXES= (\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")  # TP/FT skew posterior/anterior depending on lab; included as weak indicators\n",
    "\n",
    "def chan_AP_map(ch_names):\n",
    "    \"\"\"\n",
    "    Rough anterior vs posterior using common 10–20 prefixes.\n",
    "    Returns A (anterior), P (posterior), C (central) indices.\n",
    "    Unknowns go to central to avoid bias.\n",
    "    \"\"\"\n",
    "    A, P, C = [], [], []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        alias = ALIAS_EQUIV.get(ch.upper(), ch)\n",
    "        key   = alias.upper()\n",
    "        # Normalize like 'AF3', 'Pz', etc.\n",
    "        pref = re.match(r\"[A-Za-z]+\", key)\n",
    "        pref = pref.group(0) if pref else \"\"\n",
    "        # Assign by prefix\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES):\n",
    "            A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES):\n",
    "            P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES):\n",
    "            C.append(i)\n",
    "        else:\n",
    "            C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "# --------------- Metric helpers ---------------\n",
    "def mean_safe(x):\n",
    "    return float(np.nan) if x.size == 0 else float(x.mean())\n",
    "\n",
    "def within_region_dualmodule_stats(co, labels, idx):\n",
    "    \"\"\"Inside a region (e.g., left or right), compute same- vs cross-module means & ratio.\"\"\"\n",
    "    if idx.size < 3:  # not enough points\n",
    "        return np.nan, np.nan, np.nan\n",
    "    sub = np.ix_(idx, idx)\n",
    "    co_r = co[sub]\n",
    "    lab  = labels[idx]\n",
    "    same = lab[:,None] == lab[None,:]\n",
    "    diff = ~same\n",
    "    np.fill_diagonal(same, False)\n",
    "    np.fill_diagonal(diff, False)\n",
    "    intra_same = mean_safe(co_r[same])\n",
    "    intra_diff = mean_safe(co_r[diff])\n",
    "    ratio = intra_same / (intra_diff + 1e-12)\n",
    "    return intra_same, intra_diff, float(ratio)\n",
    "\n",
    "def cross_hemi_coupling_table(co, labels, L, R):\n",
    "    \"\"\"\n",
    "    2×2 means for (within-hemi vs cross-hemi) × (within-module vs cross-module).\n",
    "    \"\"\"\n",
    "    n = len(labels)\n",
    "    Lmask = np.zeros((n,n), bool); Lmask[np.ix_(L,L)] = True\n",
    "    Rmask = np.zeros((n,n), bool); Rmask[np.ix_(R,R)] = True\n",
    "    within_hemi = Lmask | Rmask\n",
    "    cross_hemi  = np.zeros((n,n), bool); cross_hemi[np.ix_(L,R)] = True; cross_hemi[np.ix_(R,L)] = True\n",
    "\n",
    "    same_mod = labels[:,None] == labels[None,:]\n",
    "    diff_mod = ~same_mod\n",
    "    for m in (within_hemi, cross_hemi, same_mod, diff_mod):\n",
    "        np.fill_diagonal(m, False)\n",
    "\n",
    "    return {\n",
    "        \"WH_WM\": mean_safe(co[within_hemi & same_mod]),\n",
    "        \"WH_CM\": mean_safe(co[within_hemi & diff_mod]),\n",
    "        \"CH_WM\": mean_safe(co[cross_hemi  & same_mod]),\n",
    "        \"CH_CM\": mean_safe(co[cross_hemi  & diff_mod]),\n",
    "    }\n",
    "\n",
    "def degree_to_same_module(co, labels, module_id):\n",
    "    \"\"\"Return per-channel degree to nodes in the same module.\"\"\"\n",
    "    mask = (labels == module_id)\n",
    "    return co[:, mask].sum(axis=1)\n",
    "\n",
    "def LI_LR(co, labels, L, R, module_id):\n",
    "    \"\"\"Left–Right lateralization index for a module.\"\"\"\n",
    "    deg = degree_to_same_module(co, labels, module_id)\n",
    "    Lsum = float(deg[L].sum()) if L.size else 0.0\n",
    "    Rsum = float(deg[R].sum()) if R.size else 0.0\n",
    "    return (Lsum - Rsum) / (Lsum + Rsum + 1e-12)\n",
    "\n",
    "def AI_AP(co, labels, A, P, module_id):\n",
    "    \"\"\"Anterior–Posterior asymmetry index for a module.\"\"\"\n",
    "    deg = degree_to_same_module(co, labels, module_id)\n",
    "    Asum = float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum = float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum - Psum) / (Asum + Psum + 1e-12)\n",
    "\n",
    "def module_composition_counts(labels, L, R, Z, A, P, C):\n",
    "    out = {}\n",
    "    for m in sorted(np.unique(labels)):\n",
    "        out[f\"cnt_L_mod{m}\"] = int((labels[L]==m).sum()) if L.size else 0\n",
    "        out[f\"cnt_R_mod{m}\"] = int((labels[R]==m).sum()) if R.size else 0\n",
    "        out[f\"cnt_Z_mod{m}\"] = int((labels[Z]==m).sum()) if Z.size else 0\n",
    "        out[f\"cnt_A_mod{m}\"] = int((labels[A]==m).sum()) if A.size else 0\n",
    "        out[f\"cnt_P_mod{m}\"] = int((labels[P]==m).sum()) if P.size else 0\n",
    "        out[f\"cnt_C_mod{m}\"] = int((labels[C]==m).sum()) if C.size else 0\n",
    "    return out\n",
    "\n",
    "# --------------- Channel loaders ---------------\n",
    "def load_human_channels():\n",
    "    if os.path.exists(H_CH_TXT):\n",
    "        with open(H_CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    return [f\"ch{i}\" for i in range(64)]\n",
    "\n",
    "def load_mouse_channels():\n",
    "    cands = sorted(glob.glob(os.path.join(M_CH_DIR, \"*.channels.txt\")))\n",
    "    if cands:\n",
    "        with open(cands[0], \"r\", encoding=\"utf-8\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    return [f\"ch{i}\" for i in range(32)]\n",
    "\n",
    "# --------------- Analysis core ---------------\n",
    "def analyze_species(species, bands, tab_dir, stem_prefix, ch_names, fig_dir=None):\n",
    "    \"\"\"\n",
    "    species: 'human' or 'mouse'\n",
    "    bands  : iterable of band names to process\n",
    "    tab_dir: folder with coassoc / labels npy\n",
    "    stem_prefix: e.g., \"band__\" (human) or \"mouse__\" (mouse)\n",
    "    ch_names: list of channel names\n",
    "    fig_dir: optional folder to save small ordered coassoc matrices\n",
    "    \"\"\"\n",
    "    L, R, Z = chan_hemisphere_map(ch_names)\n",
    "    A, P, C = chan_AP_map(ch_names)\n",
    "\n",
    "    if L.size + R.size == 0:\n",
    "        print(f\"[{species}] WARNING: no left/right mapping; skipping.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rows = []\n",
    "    for b in bands:\n",
    "        cons_fp = os.path.join(tab_dir, f\"{stem_prefix}{b}{CONS_SUFFIX}\")\n",
    "        co_fp   = os.path.join(tab_dir, f\"{stem_prefix}{b}{CO_SUFFIX}\")\n",
    "        if not (os.path.exists(cons_fp) and os.path.exists(co_fp)):\n",
    "            continue\n",
    "\n",
    "        labels = np.load(cons_fp)\n",
    "        co     = np.load(co_fp)\n",
    "        nch    = len(labels)\n",
    "\n",
    "        # 1) Within-hemisphere dual-module checks\n",
    "        l_same, l_diff, l_ratio = within_region_dualmodule_stats(co, labels, L)\n",
    "        r_same, r_diff, r_ratio = within_region_dualmodule_stats(co, labels, R)\n",
    "\n",
    "        # 2) Cross-hemisphere coupling\n",
    "        cross_tbl = cross_hemi_coupling_table(co, labels, L, R)\n",
    "\n",
    "        # 3) Asymmetry indices per module (assume binary modules {0,1})\n",
    "        uniq_mods = sorted(np.unique(labels))\n",
    "        # Left-Right LI\n",
    "        li_mod = {f\"LI_LR_mod{m}\": LI_LR(co, labels, L, R, m) for m in uniq_mods}\n",
    "        # Anterior-Posterior AI\n",
    "        ai_mod = {f\"AI_AP_mod{m}\": AI_AP(co, labels, A, P, m) for m in uniq_mods}\n",
    "\n",
    "        # 4) Module composition counts by hemi & A/P/C\n",
    "        comp = module_composition_counts(labels, L, R, Z, A, P, C)\n",
    "\n",
    "        # Optional small figure: reorder by [L then R] and within each by module 0 then 1\n",
    "        if fig_dir is not None:\n",
    "            try:\n",
    "                # build order: Left(mod0,mod1) + Right(mod0,mod1) + then include Z in the end\n",
    "                order = []\n",
    "                for hemi_idx in (L, R, Z):\n",
    "                    for m in uniq_mods:\n",
    "                        order.extend(list(np.where((np.isin(np.arange(nch), hemi_idx)) & (labels==m))[0]))\n",
    "                order = np.array(order, int)\n",
    "                from matplotlib import pyplot as plt\n",
    "                plt.figure()\n",
    "                plt.imshow(co[np.ix_(order,order)], aspect='auto')\n",
    "                plt.title(f\"{species} {b}: coassoc [L/R/Z × mod0/mod1]\")\n",
    "                plt.colorbar()\n",
    "                plt.tight_layout()\n",
    "                fig_path = os.path.join(fig_dir, f\"{species}__{b}__coassoc_ordered.png\")\n",
    "                plt.savefig(fig_path, dpi=140)\n",
    "                plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"[{species}:{b}] fig generation failed: {e}\")\n",
    "\n",
    "        row = {\n",
    "            \"species\": species,\n",
    "            \"band\": b,\n",
    "            \"n_channels\": nch,\n",
    "            \"n_left\": int(L.size),\n",
    "            \"n_right\": int(R.size),\n",
    "            \"n_mid\": int(Z.size),\n",
    "            \"n_ant\": int(A.size),\n",
    "            \"n_post\": int(P.size),\n",
    "            \"n_cent\": int(C.size),\n",
    "\n",
    "            # within-hemisphere dual-module checks\n",
    "            \"left_intra_same\": l_same,\n",
    "            \"left_intra_diff\": l_diff,\n",
    "            \"left_intra_ratio\": l_ratio,\n",
    "            \"right_intra_same\": r_same,\n",
    "            \"right_intra_diff\": r_diff,\n",
    "            \"right_intra_ratio\": r_ratio,\n",
    "\n",
    "            # cross-hemisphere coupling\n",
    "            \"WH_WM\": cross_tbl[\"WH_WM\"],\n",
    "            \"WH_CM\": cross_tbl[\"WH_CM\"],\n",
    "            \"CH_WM\": cross_tbl[\"CH_WM\"],\n",
    "            \"CH_CM\": cross_tbl[\"CH_CM\"],\n",
    "        }\n",
    "        row.update(li_mod)\n",
    "        row.update(ai_mod)\n",
    "        row.update(comp)\n",
    "        rows.append(row)\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --------------- RUN: Humans ---------------\n",
    "# Load channels\n",
    "h_ch = load_human_channels()\n",
    "# Analyze\n",
    "if os.path.isdir(H_TAB_DIR):\n",
    "    df_h = analyze_species(\n",
    "        species=\"human\",\n",
    "        bands=H_BANDS,\n",
    "        tab_dir=H_TAB_DIR,\n",
    "        stem_prefix=\"band__\",\n",
    "        ch_names=h_ch,\n",
    "        fig_dir=(FIG_DIR_HUMAN if SAVE_FIGS else None)\n",
    "    )\n",
    "else:\n",
    "    df_h = pd.DataFrame()\n",
    "    print(\"[human] tables folder not found; skipping.\")\n",
    "\n",
    "# Save\n",
    "if not df_h.empty:\n",
    "    df_h.to_csv(H_OUT_CSV, index=False)\n",
    "    print(\"\\n=== Humans: Hemispheric/AP metrics (saved) ===\")\n",
    "    cols_print_h = [\n",
    "        \"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\n",
    "        \"left_intra_ratio\",\"right_intra_ratio\",\n",
    "        \"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "        \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"\n",
    "    ]\n",
    "    print(df_h[ [c for c in cols_print_h if c in df_h.columns] ].to_string(index=False))\n",
    "    if SAVE_FIGS:\n",
    "        print(\"Figures →\", FIG_DIR_HUMAN)\n",
    "\n",
    "# --------------- RUN: Mice ---------------\n",
    "# Determine available mouse bands\n",
    "mbands = []\n",
    "for b in M_BANDS_CAND:\n",
    "    if os.path.exists(os.path.join(M_TAB_DIR, f\"mouse__{b}{CONS_SUFFIX}\")) and \\\n",
    "       os.path.exists(os.path.join(M_TAB_DIR, f\"mouse__{b}{CO_SUFFIX}\")):\n",
    "        mbands.append(b)\n",
    "\n",
    "m_ch = load_mouse_channels()\n",
    "if os.path.isdir(M_TAB_DIR) and len(mbands):\n",
    "    df_m = analyze_species(\n",
    "        species=\"mouse\",\n",
    "        bands=mbands,\n",
    "        tab_dir=M_TAB_DIR,\n",
    "        stem_prefix=\"mouse__\",\n",
    "        ch_names=m_ch,\n",
    "        fig_dir=(FIG_DIR_MOUSE if SAVE_FIGS else None)\n",
    "    )\n",
    "else:\n",
    "    df_m = pd.DataFrame()\n",
    "    print(\"[mouse] tables folder not found or no bands present; skipping.\")\n",
    "\n",
    "# Save\n",
    "if not df_m.empty:\n",
    "    df_m.to_csv(M_OUT_CSV, index=False)\n",
    "    print(\"\\n=== Mice: Hemispheric/AP metrics (saved) ===\")\n",
    "    cols_print_m = [\n",
    "        \"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\n",
    "        \"left_intra_ratio\",\"right_intra_ratio\",\n",
    "        \"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "        \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"\n",
    "    ]\n",
    "    print(df_m[ [c for c in cols_print_m if c in df_m.columns] ].to_string(index=False))\n",
    "    if SAVE_FIGS:\n",
    "        print(\"Figures →\", FIG_DIR_MOUSE)\n",
    "\n",
    "# --------------- MERGE & SAVE ---------------\n",
    "frames = []\n",
    "if not df_h.empty: frames.append(df_h.assign(dataset=\"human\"))\n",
    "if not df_m.empty: frames.append(df_m.assign(dataset=\"mouse\"))\n",
    "if frames:\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(MERGED_CSV), exist_ok=True)\n",
    "    merged.to_csv(MERGED_CSV, index=False)\n",
    "    print(\"\\nMerged CSV →\", MERGED_CSV)\n",
    "else:\n",
    "    print(\"\\nNo data frames to merge; check paths and bands.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "117ab5ab-6db3-404d-9cda-16504f6d34c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[human] channels present but unmappable — will refresh from EEGBCI.\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "[human] wrote channel names to: C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_01_EC.channels.txt\n",
      "[mouse] found NPY subjects: 8\n",
      "[mouse] built theta: LOSO=1.000, p≈0.0033\n",
      "[mouse] built gamma: LOSO=0.766, p≈0.0033\n",
      "[mouse] built high_gamma: LOSO=0.750, p≈0.0033\n",
      "[human] WARNING: no L/R mapping; skipping.\n",
      "\n",
      "=== Mice: Hemispheric/AP metrics (saved) ===\n",
      "      band  n_channels  n_left  n_right  n_ant  n_post  left_intra_ratio  right_intra_ratio    WH_WM    WH_CM    CH_WM    CH_CM  LI_LR_mod0  LI_LR_mod1  AI_AP_mod0  AI_AP_mod1\n",
      "     theta          16       8        8      0       0          1.969981           1.846154 0.644231 0.337500 0.629167 0.319853    0.107692   -0.081712         0.0         0.0\n",
      "     gamma          16       8        8      0       0          1.440789           1.384615 0.547414 0.384259 0.602679 0.399306    0.065574   -0.036530         0.0         0.0\n",
      "high_gamma          16       8        8      0       0          1.283951           1.394231 0.550000 0.411290 0.546875 0.390625    0.004484   -0.003413         0.0         0.0\n",
      "Mouse figs → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_mouse_openneuro\\figures_hemi\n",
      "\n",
      "Merged CSV → C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_hemi_AP_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# === CNT Hemi + A/P: Full Prep + Analysis (Humans + Mice) — single cell ===\n",
    "# Does:\n",
    "#  A) HUMANS: ensure channel names (pulls EEGBCI S001 R02 if needed), use existing coassoc/labels.\n",
    "#  B) MICE:  if mouse consensus files missing, download+convert (OpenNeuro) OR synth demo, then build consensus.\n",
    "#  C) Run Hemispheric + Anterior/Posterior analysis for both. Save CSVs and (optional) ordered coassoc figures.\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "ROOT            = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "\n",
    "# Humans (n≈30) — expects you've run the 30-subject sweep already\n",
    "H_TAB_DIR       = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\tables\")\n",
    "H_CH_TXT        = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "H_BANDS         = [\"alpha\",\"theta\",\"beta\"]\n",
    "H_OUT_CSV       = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\hemisphere_humans.csv\")\n",
    "\n",
    "# Mice — will auto-prepare if missing\n",
    "M_TAB_DIR       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\tables\")\n",
    "M_MET_DIR       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\metrics\")\n",
    "M_FIG_DIR       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\figures\")\n",
    "M_DATA_DIR      = os.path.join(ROOT, r\"mouse_eeg\")\n",
    "M_RAW_DIR       = os.path.join(ROOT, r\"mouse_openneuro_raw\")\n",
    "M_BANDS_TARGET  = [\"theta\",\"gamma\",\"high_gamma\"]\n",
    "M_OUT_CSV       = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\hemisphere_mice.csv\")\n",
    "\n",
    "# OpenNeuro (set dsID if you want a real dataset; otherwise demo synthesizes 8 subjects)\n",
    "USE_DEMO        = True            # False to actually download from OpenNeuro\n",
    "MOUSE_DS        = \"dsXXXXXX\"      # e.g., \"ds004***\" when you have a real dsID\n",
    "FILE_FILTERS    = [\"*eeg*.edf\", \"*eeg*.mat\", \"*lfp*.npy\", \"*lfp*.mat\"]\n",
    "\n",
    "# Analysis params\n",
    "SAVE_FIGS       = True\n",
    "FIG_DIR_HUMAN   = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_hemi\")\n",
    "FIG_DIR_MOUSE   = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\figures_hemi\")\n",
    "\n",
    "# Mouse PLI settings (used only if we need to build mouse consensus now)\n",
    "FS        = 1000.0\n",
    "SLICE_SEC = 60\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 4\n",
    "NULL_PERMS= 300\n",
    "BANDS_HZ  = {\"theta\": (6.0, 12.0), \"gamma\": (30.0, 55.0), \"high_gamma\": (60.0, 100.0)}\n",
    "\n",
    "# ------------------ UTILITIES ------------------\n",
    "def ensure(p): os.makedirs(p, exist_ok=True); return p\n",
    "if SAVE_FIGS:\n",
    "    ensure(FIG_DIR_HUMAN); ensure(FIG_DIR_MOUSE)\n",
    "ensure(M_TAB_DIR); ensure(M_MET_DIR); ensure(M_FIG_DIR); ensure(M_DATA_DIR)\n",
    "\n",
    "CONS_SUFFIX = \"__consensus_labels.npy\"\n",
    "CO_SUFFIX   = \"__coassoc.npy\"\n",
    "\n",
    "def norm_key(s: str) -> str:\n",
    "    return re.sub(r\"[^A-Za-z0-9]\", \"\", s).upper()\n",
    "\n",
    "ALIAS_EQUIV = {\n",
    "    \"T3\":\"T7\", \"T4\":\"T8\", \"T5\":\"P7\", \"T6\":\"P8\",\n",
    "    \"FP1\":\"Fp1\", \"FP2\":\"Fp2\", \"FPZ\":\"Fpz\", \"CZ\":\"Cz\", \"PZ\":\"Pz\", \"FZ\":\"Fz\", \"OZ\":\"Oz\", \"POZ\":\"POz\"\n",
    "}\n",
    "\n",
    "def chan_hemisphere_map(ch_names):\n",
    "    L, R, Z = [], [], []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        alias = ALIAS_EQUIV.get(ch.upper(), ch)\n",
    "        # explicit tags\n",
    "        if re.search(r\"(^|[_\\-\\(])L($|[_\\-\\)])\", ch, flags=re.I) or re.search(r\"LEFT\", ch, flags=re.I):\n",
    "            L.append(i); continue\n",
    "        if re.search(r\"(^|[_\\-\\(])R($|[_\\-\\)])\", ch, flags=re.I) or re.search(r\"RIGHT\", ch, flags=re.I):\n",
    "            R.append(i); continue\n",
    "        # midline Z\n",
    "        if re.search(r\"[A-Za-z]Z$\", alias, flags=re.I):\n",
    "            Z.append(i); continue\n",
    "        # 10-20 odd/even\n",
    "        m = re.search(r\"(\\d+)$\", alias)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        # unknown → midline\n",
    "        if 'Z' in alias.upper(): Z.append(i)\n",
    "        else: Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "ANT_PREFIXES = (\"FP\",\"AF\",\"F\",\"FC\")\n",
    "MID_PREFIXES = (\"C\",)\n",
    "POST_PREFIXES= (\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "\n",
    "def chan_AP_map(ch_names):\n",
    "    A, P, C = [], [], []\n",
    "    for i, ch in enumerate(ch_names):\n",
    "        alias = ALIAS_EQUIV.get(ch.upper(), ch).upper()\n",
    "        pref = re.match(r\"[A-Za-z]+\", alias)\n",
    "        pref = pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "def mean_safe(x):\n",
    "    return float(np.nan) if x.size==0 else float(x.mean())\n",
    "\n",
    "def within_region_dualmodule_stats(co, labels, idx):\n",
    "    if idx.size<3: return np.nan, np.nan, np.nan\n",
    "    sub=np.ix_(idx,idx); co_r=co[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    intra_same=mean_safe(co_r[same]); intra_diff=mean_safe(co_r[diff])\n",
    "    return intra_same, intra_diff, float(intra_same/(intra_diff+1e-12))\n",
    "\n",
    "def cross_hemi_coupling_table(co, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross=np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same=labels[:,None]==labels[None,:]; diff=~same\n",
    "    for m in (within,cross,same,diff): np.fill_diagonal(m,False)\n",
    "    return {\"WH_WM\":mean_safe(co[within&same]),\"WH_CM\":mean_safe(co[within&diff]),\n",
    "            \"CH_WM\":mean_safe(co[cross&same]), \"CH_CM\":mean_safe(co[cross&diff])}\n",
    "\n",
    "def degree_to_same_module(co, labels, m_id):\n",
    "    mask=(labels==m_id); return co[:,mask].sum(axis=1)\n",
    "\n",
    "def LI_LR(co, labels, L, R, m_id):\n",
    "    deg=degree_to_same_module(co,labels,m_id)\n",
    "    Lsum=float(deg[L].sum()) if L.size else 0.0\n",
    "    Rsum=float(deg[R].sum()) if R.size else 0.0\n",
    "    return (Lsum-Rsum)/(Lsum+Rsum+1e-12)\n",
    "\n",
    "def AI_AP(co, labels, A, P, m_id):\n",
    "    deg=degree_to_same_module(co,labels,m_id)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def module_composition_counts(labels, L, R, Z, A, P, C):\n",
    "    out={}\n",
    "    for m in sorted(np.unique(labels)):\n",
    "        out[f\"cnt_L_mod{m}\"]=int((labels[L]==m).sum()) if L.size else 0\n",
    "        out[f\"cnt_R_mod{m}\"]=int((labels[R]==m).sum()) if R.size else 0\n",
    "        out[f\"cnt_Z_mod{m}\"]=int((labels[Z]==m).sum()) if Z.size else 0\n",
    "        out[f\"cnt_A_mod{m}\"]=int((labels[A]==m).sum()) if A.size else 0\n",
    "        out[f\"cnt_P_mod{m}\"]=int((labels[P]==m).sum()) if P.size else 0\n",
    "        out[f\"cnt_C_mod{m}\"]=int((labels[C]==m).sum()) if C.size else 0\n",
    "    return out\n",
    "\n",
    "# ------------------ A) HUMANS: ensure channel names ------------------\n",
    "def ensure_human_channels():\n",
    "    if os.path.exists(H_CH_TXT):\n",
    "        with open(H_CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "            chs=[ln.strip() for ln in f if ln.strip()]\n",
    "        L,R,Z=chan_hemisphere_map(chs)\n",
    "        if L.size+R.size>0:\n",
    "            print(\"[human] channel names present and mappable.\")\n",
    "            return chs\n",
    "        else:\n",
    "            print(\"[human] channels present but unmappable — will refresh from EEGBCI.\")\n",
    "    # try fetch one EEGBCI run to get canonical names\n",
    "    try:\n",
    "        import mne\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "        import mne\n",
    "    try:\n",
    "        # S001 run 2 (EC)\n",
    "        try:\n",
    "            fpaths=mne.datasets.eegbci.load_data(subjects=[1], runs=[2], update_path=True, verbose=\"ERROR\")\n",
    "        except TypeError:\n",
    "            fpaths=mne.datasets.eegbci.load_data(subject=1, runs=[2], update_path=True, verbose=\"ERROR\")\n",
    "        raw=mne.io.read_raw_edf(fpaths[0], preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, stim=False, eog=False, ecg=False, emg=False, misc=False)\n",
    "        chs=list(raw.ch_names)\n",
    "        os.makedirs(os.path.dirname(H_CH_TXT), exist_ok=True)\n",
    "        with open(H_CH_TXT,\"w\",encoding=\"utf-8\") as f:\n",
    "            for c in chs: f.write(c+\"\\n\")\n",
    "        print(\"[human] wrote channel names to:\", H_CH_TXT)\n",
    "        return chs\n",
    "    except Exception as e:\n",
    "        print(\"[human] could not fetch EEGBCI channel names; using generic labels.\", e)\n",
    "        chs=[f\"ch{i}\" for i in range(64)]\n",
    "        with open(H_CH_TXT,\"w\",encoding=\"utf-8\") as f:\n",
    "            for c in chs: f.write(c+\"\\n\")\n",
    "        return chs\n",
    "\n",
    "# ------------------ B) MICE: prepare consensus if missing ------------------\n",
    "def mouse_need_build():\n",
    "    present=[]\n",
    "    for b in M_BANDS_TARGET:\n",
    "        if os.path.exists(os.path.join(M_TAB_DIR,f\"mouse__{b}{CONS_SUFFIX}\")) and \\\n",
    "           os.path.exists(os.path.join(M_TAB_DIR,f\"mouse__{b}{CO_SUFFIX}\")):\n",
    "            present.append(b)\n",
    "    missing=[b for b in M_BANDS_TARGET if b not in present]\n",
    "    return missing\n",
    "\n",
    "def bandpass(x,fs,lo,hi,order=4):\n",
    "    from scipy.signal import butter,filtfilt\n",
    "    b,a=butter(order,[lo/(fs/2), hi/(fs/2)],btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X,fs,lo,hi):\n",
    "    from scipy.signal import hilbert\n",
    "    n=X.shape[0]; Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=bandpass(X[c],fs,lo,hi)\n",
    "    ph=np.angle(hilbert(Y,axis=1))\n",
    "    W=np.zeros((n,n),float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:min(k,n-1)]\n",
    "        m=np.ones(n,bool); m[keep]=False; W[i,m]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0])-D@W@D\n",
    "\n",
    "def spec(W,k):\n",
    "    from sklearn.cluster import KMeans\n",
    "    e,v=np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/=np.linalg.norm(U,axis=1,keepdims=True)+1e-12\n",
    "    return KMeans(n_clusters=k,n_init=50,random_state=42).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n),float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n):\n",
    "                co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(labels):\n",
    "    cof=coassoc(labels); cons=spec(cof,2); vals=[]\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    for s in range(len(labels)):\n",
    "        leave=[lab for i,lab in enumerate(labels) if i!=s]\n",
    "        cons_l=spec(coassoc(leave),2)\n",
    "        vals.append(adjusted_rand_score(cons,cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def rand_same_sizes(lab, rng):\n",
    "    n=len(lab); uniq,cnts=np.unique(lab, return_counts=True)\n",
    "    idx=np.arange(n); rng.shuffle(idx); out=np.empty(n,int); st=0\n",
    "    for L,c in zip(uniq,cnts): seg=idx[st:st+c]; out[seg]=L; st+=c\n",
    "    return out\n",
    "\n",
    "def prepare_mouse_data():\n",
    "    paths=sorted(glob.glob(os.path.join(M_DATA_DIR,\"*.npy\")))\n",
    "    if len(paths)>=4:\n",
    "        print(\"[mouse] found NPY subjects:\", len(paths))\n",
    "        return paths\n",
    "    if not USE_DEMO:\n",
    "        # Try to download from OpenNeuro\n",
    "        try:\n",
    "            import openneuro as on\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"openneuro-py\"])\n",
    "            import openneuro as on\n",
    "        print(f\"[mouse] downloading OpenNeuro {MOUSE_DS} (filtered)…\")\n",
    "        for patt in FILE_FILTERS:\n",
    "            try:\n",
    "                on.download(dataset=MOUSE_DS, target=M_RAW_DIR, include=[patt], strict=False)\n",
    "                print(\"[mouse] included:\", patt)\n",
    "            except Exception as e:\n",
    "                print(\"[mouse] include failed:\", patt, e)\n",
    "        # Convert a few files to NPY\n",
    "        paths = export_subjects_from_folder(os.path.join(M_RAW_DIR, MOUSE_DS), M_DATA_DIR, subj_limit=12)\n",
    "        return paths\n",
    "    else:\n",
    "        # synth demo 8 subjects × 16 ch × 60 s\n",
    "        rng=np.random.default_rng(7)\n",
    "        N_SUBJ,N_CH,T = 8,16,int(FS*SLICE_SEC)\n",
    "        paths=[]\n",
    "        for s in range(N_SUBJ):\n",
    "            X=rng.normal(0,1,size=(N_CH,T))\n",
    "            t=np.arange(T)/FS\n",
    "            theta=np.sin(2*np.pi*8.0*t + rng.uniform(0,2*np.pi))\n",
    "            for c in range(N_CH//2,N_CH):\n",
    "                X[c]+=0.6*theta + 0.2*rng.normal(0,1,T)\n",
    "            base=os.path.join(M_DATA_DIR,f\"mouse_demo_{s:02d}\")\n",
    "            np.save(base+\".npy\",X.astype(np.float32))\n",
    "            with open(base+\".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for i in range(N_CH): f.write(f\"ch{i}\\n\")\n",
    "            paths.append(base+\".npy\")\n",
    "        print(\"[mouse] synthesized demo subjects:\", len(paths))\n",
    "        return paths\n",
    "\n",
    "def export_subjects_from_folder(in_root, out_dir, subj_limit=12):\n",
    "    from scipy.io import loadmat\n",
    "    from scipy.signal import decimate\n",
    "    def try_load_edf(fp):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw=mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, stim=False, eog=False, ecg=False, emg=False, misc=False)\n",
    "        return raw.get_data(), float(raw.info[\"sfreq\"]), list(raw.ch_names)\n",
    "    def try_load_mat(fp):\n",
    "        m=loadmat(fp); arr=None\n",
    "        for k,v in m.items():\n",
    "            if isinstance(v,np.ndarray) and v.ndim==2 and (arr is None or v.size>arr.size): arr=v\n",
    "        if arr is None: raise RuntimeError(\"No 2D array in MAT\")\n",
    "        fs=float(m.get(\"fs\", np.array([[FS]])).squeeze())\n",
    "        return arr.astype(float), fs, [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "    def try_load_npy(fp):\n",
    "        X=np.load(fp); \n",
    "        if X.ndim!=2: raise RuntimeError(\"expected [n_ch,n_t]\")\n",
    "        return X.astype(float), FS, [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "    files=[]\n",
    "    for patt in FILE_FILTERS+[\"*.npy\",\"*.edf\",\"*.mat\"]:\n",
    "        files+=glob.glob(os.path.join(in_root,\"**\",patt), recursive=True)\n",
    "    files=sorted(list(set(files)))\n",
    "    exported=[]\n",
    "    for fp in files:\n",
    "        try:\n",
    "            if fp.lower().endswith(\".edf\"):\n",
    "                X,fs,ch=try_load_edf(fp)\n",
    "            elif fp.lower().endswith(\".mat\"):\n",
    "                X,fs,ch=try_load_mat(fp)\n",
    "            elif fp.lower().endswith(\".npy\"):\n",
    "                X,fs,ch=try_load_npy(fp)\n",
    "            else:\n",
    "                continue\n",
    "            # resample down by integer factor if close\n",
    "            from math import isclose\n",
    "            from scipy.signal import decimate\n",
    "            if not np.isclose(fs, FS, atol=1e-6):\n",
    "                q=int(round(fs/FS))\n",
    "                if q>=1 and abs(fs/q-FS)<1e-3:\n",
    "                    X=np.vstack([decimate(X[i], q, ftype='fir', zero_phase=True) for i in range(X.shape[0])])\n",
    "                    fs=FS\n",
    "            # trim/tile to SLICE_SEC\n",
    "            n_keep=int(SLICE_SEC*fs)\n",
    "            if X.shape[1]>=n_keep: X=X[:,:n_keep]\n",
    "            else: \n",
    "                reps=int(np.ceil(n_keep/X.shape[1])); X=np.tile(X,reps)[:,:n_keep]\n",
    "            base=os.path.join(out_dir,f\"mouse_{len(exported):02d}\")\n",
    "            np.save(base+\".npy\",X.astype(np.float32))\n",
    "            with open(base+\".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for c in ch: f.write(c+\"\\n\")\n",
    "            exported.append(base+\".npy\")\n",
    "            if len(exported)>=subj_limit: break\n",
    "        except Exception as e:\n",
    "            print(\"[mouse] skip\", fp, e)\n",
    "    return exported\n",
    "\n",
    "def build_mouse_consensus_if_missing():\n",
    "    missing = mouse_need_build()\n",
    "    if not missing:\n",
    "        print(\"[mouse] consensus present for\", M_BANDS_TARGET)\n",
    "        return\n",
    "    # ensure data\n",
    "    paths = prepare_mouse_data()\n",
    "    files = sorted(paths)[:max(8, len(paths))]  # use at least a handful\n",
    "    if len(files)<4:\n",
    "        print(\"[mouse] not enough data to build consensus.\"); return\n",
    "    # per band consensus\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    rng=np.random.default_rng(13)\n",
    "    for band, (lo,hi) in BANDS_HZ.items():\n",
    "        if band not in missing: \n",
    "            continue\n",
    "        labs=[]\n",
    "        for f in files:\n",
    "            X=np.load(f); W=pli_matrix(X,FS,lo,hi); W=knn(W,KNN_K); labs.append(spec(W,K_FIXED))\n",
    "        loso, cons, cof = loso_via_coassoc(labs)\n",
    "        # save\n",
    "        np.save(os.path.join(M_TAB_DIR,f\"mouse__{band}{CONS_SUFFIX}\"), cons)\n",
    "        np.save(os.path.join(M_TAB_DIR,f\"mouse__{band}{CO_SUFFIX}\"), cof)\n",
    "        # null for completeness (optional metric dump)\n",
    "        null=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nlabs=[rand_same_sizes(l, rng) for l in labs]\n",
    "            _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "            null.append(adjusted_rand_score(cons, cons_n))\n",
    "        null=np.array(null,float)\n",
    "        p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "        met={\"band\":band,\"n_subjects\":len(files),\"LOSO\":float(loso),\"null_mean\":float(null.mean()),\"p_value\":p}\n",
    "        ensure(M_MET_DIR)\n",
    "        with open(os.path.join(M_MET_DIR,f\"mouse__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump(met,f,indent=2)\n",
    "        print(f\"[mouse] built {band}: LOSO={loso:.3f}, p≈{p:.4f}\")\n",
    "\n",
    "# ------------------ C) ANALYSIS CORE ------------------\n",
    "def analyze_species(species, bands, tab_dir, stem_prefix, ch_names, fig_dir=None):\n",
    "    L,R,Z = chan_hemisphere_map(ch_names)\n",
    "    A,P,C = chan_AP_map(ch_names)\n",
    "    if L.size+R.size==0:\n",
    "        print(f\"[{species}] WARNING: no L/R mapping; skipping.\")\n",
    "        return pd.DataFrame()\n",
    "    rows=[]\n",
    "    for b in bands:\n",
    "        cons_fp=os.path.join(tab_dir,f\"{stem_prefix}{b}{CONS_SUFFIX}\")\n",
    "        co_fp  =os.path.join(tab_dir,f\"{stem_prefix}{b}{CO_SUFFIX}\")\n",
    "        if not (os.path.exists(cons_fp) and os.path.exists(co_fp)): \n",
    "            continue\n",
    "        labels=np.load(cons_fp); co=np.load(co_fp); nch=len(labels)\n",
    "        # within L/R\n",
    "        l_same,l_diff,l_ratio=within_region_dualmodule_stats(co,labels,L)\n",
    "        r_same,r_diff,r_ratio=within_region_dualmodule_stats(co,labels,R)\n",
    "        # cross hemi matrix\n",
    "        cross_tbl=cross_hemi_coupling_table(co,labels,L,R)\n",
    "        # asym L/R & A/P per module\n",
    "        uniq_mods=sorted(np.unique(labels))\n",
    "        li_mod={f\"LI_LR_mod{m}\": LI_LR(co,labels,L,R,m) for m in uniq_mods}\n",
    "        ai_mod={f\"AI_AP_mod{m}\": AI_AP(co,labels,A,P,m) for m in uniq_mods}\n",
    "        comp = module_composition_counts(labels,L,R,Z,A,P,C)\n",
    "        # optional figure: reorder by [L(mod0,mod1) | R(mod0,mod1) | Z(mod0,mod1)]\n",
    "        if fig_dir:\n",
    "            try:\n",
    "                order=[]\n",
    "                for hemi_idx in (L,R,Z):\n",
    "                    for m in uniq_mods:\n",
    "                        order.extend(list(np.where((np.isin(np.arange(nch),hemi_idx))&(labels==m))[0]))\n",
    "                order=np.array(order,int)\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                plt.imshow(co[np.ix_(order,order)], aspect='auto')\n",
    "                plt.title(f\"{species} {b}: coassoc [L/R/Z × mod0/mod1]\"); plt.colorbar(); plt.tight_layout()\n",
    "                figp=os.path.join(fig_dir,f\"{species}__{b}__coassoc_ordered.png\")\n",
    "                plt.savefig(figp,dpi=140); plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"[{species}:{b}] fig failed:\", e)\n",
    "        row={\"species\":species,\"band\":b,\"n_channels\":nch,\"n_left\":int(L.size),\"n_right\":int(R.size),\n",
    "             \"n_mid\":int(Z.size),\"n_ant\":int(A.size),\"n_post\":int(P.size),\"n_cent\":int(C.size),\n",
    "             \"left_intra_same\":l_same,\"left_intra_diff\":l_diff,\"left_intra_ratio\":l_ratio,\n",
    "             \"right_intra_same\":r_same,\"right_intra_diff\":r_diff,\"right_intra_ratio\":r_ratio,\n",
    "             \"WH_WM\":cross_tbl[\"WH_WM\"],\"WH_CM\":cross_tbl[\"WH_CM\"],\"CH_WM\":cross_tbl[\"CH_WM\"],\"CH_CM\":cross_tbl[\"CH_CM\"]}\n",
    "        row.update(li_mod); row.update(ai_mod); row.update(comp); rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ------------------ RUN SEQUENCE ------------------\n",
    "# Humans: make sure channel names exist & are mappable\n",
    "h_ch = ensure_human_channels()\n",
    "\n",
    "# Mice: if consensus missing, build it (downloads or demo if needed)\n",
    "build_mouse_consensus_if_missing()\n",
    "\n",
    "# Humans analysis\n",
    "if os.path.isdir(H_TAB_DIR):\n",
    "    df_h = analyze_species(\"human\", H_BANDS, H_TAB_DIR, \"band__\", h_ch, FIG_DIR_HUMAN if SAVE_FIGS else None)\n",
    "else:\n",
    "    df_h = pd.DataFrame(); print(\"[human] tables folder not found; skipping.\")\n",
    "\n",
    "if not df_h.empty:\n",
    "    ensure(os.path.dirname(H_OUT_CSV)); df_h.to_csv(H_OUT_CSV, index=False)\n",
    "    print(\"\\n=== Humans: Hemispheric/AP metrics (saved) ===\")\n",
    "    cols_h = [\"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\n",
    "              \"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "              \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"]\n",
    "    print(df_h[[c for c in cols_h if c in df_h.columns]].to_string(index=False))\n",
    "    if SAVE_FIGS: print(\"Human figs →\", FIG_DIR_HUMAN)\n",
    "\n",
    "# Mice bands actually present\n",
    "mbands=[]\n",
    "for b in M_BANDS_TARGET:\n",
    "    if os.path.exists(os.path.join(M_TAB_DIR,f\"mouse__{b}{CONS_SUFFIX}\")) and \\\n",
    "       os.path.exists(os.path.join(M_TAB_DIR,f\"mouse__{b}{CO_SUFFIX}\")):\n",
    "        mbands.append(b)\n",
    "\n",
    "# Mouse channels: take first channels.txt if present; else generic\n",
    "m_ch_files=sorted(glob.glob(os.path.join(M_DATA_DIR,\"*.channels.txt\")))\n",
    "if m_ch_files:\n",
    "    with open(m_ch_files[0],\"r\",encoding=\"utf-8\") as f:\n",
    "        m_ch=[ln.strip() for ln in f if ln.strip()]\n",
    "else:\n",
    "    m_ch=[f\"ch{i}\" for i in range(32)]\n",
    "\n",
    "if os.path.isdir(M_TAB_DIR) and mbands:\n",
    "    df_m = analyze_species(\"mouse\", mbands, M_TAB_DIR, \"mouse__\", m_ch, FIG_DIR_MOUSE if SAVE_FIGS else None)\n",
    "else:\n",
    "    df_m = pd.DataFrame(); print(\"[mouse] no mouse tables present after build; skipping.\")\n",
    "\n",
    "if not df_m.empty:\n",
    "    ensure(os.path.dirname(M_OUT_CSV)); df_m.to_csv(M_OUT_CSV, index=False)\n",
    "    print(\"\\n=== Mice: Hemispheric/AP metrics (saved) ===\")\n",
    "    cols_m = [\"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\n",
    "              \"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "              \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"]\n",
    "    print(df_m[[c for c in cols_m if c in df_m.columns]].to_string(index=False))\n",
    "    if SAVE_FIGS: print(\"Mouse figs →\", FIG_DIR_MOUSE)\n",
    "\n",
    "# Merge\n",
    "frames=[]\n",
    "if not df_h.empty: frames.append(df_h.assign(dataset=\"human\"))\n",
    "if not df_m.empty: frames.append(df_m.assign(dataset=\"mouse\"))\n",
    "if frames:\n",
    "    merged=pd.concat(frames, ignore_index=True)\n",
    "    merged_csv=os.path.join(ROOT, r\"artifacts\\CNT_PLI_hemi_AP_merged.csv\")\n",
    "    ensure(os.path.dirname(merged_csv)); merged.to_csv(merged_csv, index=False)\n",
    "    print(\"\\nMerged CSV →\", merged_csv)\n",
    "else:\n",
    "    print(\"\\nNo data frames to merge; check paths and that builds completed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "92769e98-1ed1-4d91-81e0-d2f08f812ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Humans (fixed): Hemispheric/AP metrics (saved) ===\n",
      " band  n_channels  n_left  n_right  n_ant  n_post  left_intra_ratio  right_intra_ratio    WH_WM    WH_CM    CH_WM    CH_CM  LI_LR_mod0  LI_LR_mod1  AI_AP_mod0  AI_AP_mod1\n",
      "alpha          64      27       27     21      17          2.270072           2.129487 0.768217 0.348976 0.660854 0.257274    0.043745   -0.039997    0.592513   -0.424026\n",
      "theta          64      27       27     21      17          1.683705           1.641144 0.773547 0.465642 0.554859 0.261050   -0.067393    0.016287    0.440015   -0.257249\n",
      " beta          64      27       27     21      17          4.490455           5.039549 0.891420 0.187821 0.811233 0.114194    0.043345   -0.022706    0.821387   -0.705677\n",
      "Human figs → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\figures_hemi_fix\n",
      "\n",
      "Merged CSV → C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_hemi_AP_merged.csv\n"
     ]
    }
   ],
   "source": [
    "# === FIX: Human channel mapping + Hemi/AP analysis (updates merged CSV) ===\n",
    "import os, re, glob, numpy as np, pandas as pd\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "H_TAB_DIR = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\tables\")\n",
    "H_CH_TXT  = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "H_OUT_CSV = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\hemisphere_humans.csv\")\n",
    "H_BANDS   = [\"alpha\",\"theta\",\"beta\"]\n",
    "\n",
    "M_TAB_DIR = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\tables\")\n",
    "M_OUT_CSV = os.path.join(ROOT, r\"artifacts\\pli_mouse_openneuro\\hemisphere_mice.csv\")\n",
    "MERGED    = os.path.join(ROOT, r\"artifacts\\CNT_PLI_hemi_AP_merged.csv\")\n",
    "\n",
    "SAVE_FIGS     = True\n",
    "FIG_DIR_HUMAN = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_hemi_fix\")\n",
    "os.makedirs(FIG_DIR_HUMAN, exist_ok=True)\n",
    "\n",
    "CONS_SUFFIX = \"__consensus_labels.npy\"\n",
    "CO_SUFFIX   = \"__coassoc.npy\"\n",
    "\n",
    "# --- Canonical left/right lists (backup safety net) ---\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "# --- Clean & normalize channel names ---\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    # strip common vendor tokens\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    # remove spaces/dashes/periods\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    # common alias fixes\n",
    "    y = y.replace(\"FP\", \"Fp\").replace(\"AF\", \"AF\").replace(\"FC\",\"FC\").replace(\"CP\",\"CP\").replace(\"PO\",\"PO\")\n",
    "    # Standardize case: first letters keep case, digits keep\n",
    "    return y\n",
    "\n",
    "def load_human_channels_clean():\n",
    "    if not os.path.exists(H_CH_TXT):\n",
    "        raise SystemExit(\"Human channel file missing. Re-run the 30-subject sweep (it writes channels).\")\n",
    "    with open(H_CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        raw = [ln.strip() for ln in f if ln.strip()]\n",
    "    lab = [clean_label(x) for x in raw]\n",
    "    return raw, lab\n",
    "\n",
    "def hemi_map_from_labels(clean_labels):\n",
    "    L, R, Z = [], [], []\n",
    "    for i, ch in enumerate(clean_labels):\n",
    "        up = ch.upper()\n",
    "        # backup canonical lists first\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "\n",
    "        # explicit L/R tokens (rare after cleaning, but keep)\n",
    "        if re.search(r\"(^|[_\\-\\(])L($|[_\\-\\)])\", ch, flags=re.I) or re.search(r\"LEFT\", ch, flags=re.I):\n",
    "            L.append(i); continue\n",
    "        if re.search(r\"(^|[_\\-\\(])R($|[_\\-\\)])\", ch, flags=re.I) or re.search(r\"RIGHT\", ch, flags=re.I):\n",
    "            R.append(i); continue\n",
    "\n",
    "        # 10–20 odd/even; 'z' midline\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d = int(m.group(1))\n",
    "                (L if d % 2 == 1 else R).append(i); continue\n",
    "            except: pass\n",
    "\n",
    "        # fallthrough → midline (conservative)\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "# --- A/P map (rough) ---\n",
    "ANT_PREFIXES = (\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "MID_PREFIXES = (\"C\",)\n",
    "POST_PREFIXES= (\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map_from_labels(clean_labels):\n",
    "    A, P, C = [], [], []\n",
    "    for i, ch in enumerate(clean_labels):\n",
    "        pref = re.match(r\"[A-Za-z]+\", ch)\n",
    "        pref = pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "def mean_safe(x):\n",
    "    return float(np.nan) if x.size==0 else float(x.mean())\n",
    "\n",
    "def within_region_dualmodule_stats(co, labels, idx):\n",
    "    if idx.size < 3: return np.nan, np.nan, np.nan\n",
    "    sub = np.ix_(idx, idx); co_r = co[sub]; lab = labels[idx]\n",
    "    same = lab[:,None]==lab[None,:]; diff = ~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    intra_same = mean_safe(co_r[same]); intra_diff = mean_safe(co_r[diff])\n",
    "    return intra_same, intra_diff, float(intra_same/(intra_diff+1e-12))\n",
    "\n",
    "def cross_hemi_coupling_table(co, labels, L, R):\n",
    "    n = len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)] = True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)] = True\n",
    "    within = Lmask | Rmask\n",
    "    cross  = np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same   = labels[:,None]==labels[None,:]; diff = ~same\n",
    "    for m in (within,cross,same,diff): np.fill_diagonal(m,False)\n",
    "    return {\n",
    "        \"WH_WM\": mean_safe(co[within & same]),\n",
    "        \"WH_CM\": mean_safe(co[within & diff]),\n",
    "        \"CH_WM\": mean_safe(co[cross  & same]),\n",
    "        \"CH_CM\": mean_safe(co[cross  & diff]),\n",
    "    }\n",
    "\n",
    "def degree_to_same_module(co, labels, m_id):\n",
    "    mask=(labels==m_id); return co[:,mask].sum(axis=1)\n",
    "def LI_LR(co, labels, L, R, m_id):\n",
    "    deg = degree_to_same_module(co,labels,m_id)\n",
    "    Lsum=float(deg[L].sum()) if L.size else 0.0\n",
    "    Rsum=float(deg[R].sum()) if R.size else 0.0\n",
    "    return (Lsum-Rsum)/(Lsum+Rsum+1e-12)\n",
    "def AI_AP(co, labels, A, P, m_id):\n",
    "    deg = degree_to_same_module(co,labels,m_id)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def module_composition_counts(labels, L, R, Z, A, P, C):\n",
    "    out={}\n",
    "    for m in sorted(np.unique(labels)):\n",
    "        out[f\"cnt_L_mod{m}\"]=int((labels[L]==m).sum()) if L.size else 0\n",
    "        out[f\"cnt_R_mod{m}\"]=int((labels[R]==m).sum()) if R.size else 0\n",
    "        out[f\"cnt_Z_mod{m}\"]=int((labels[Z]==m).sum()) if Z.size else 0\n",
    "        out[f\"cnt_A_mod{m}\"]=int((labels[A]==m).sum()) if A.size else 0\n",
    "        out[f\"cnt_P_mod{m}\"]=int((labels[P]==m).sum()) if P.size else 0\n",
    "        out[f\"cnt_C_mod{m}\"]=int((labels[C]==m).sum()) if C.size else 0\n",
    "    return out\n",
    "\n",
    "# --- Human analysis ---\n",
    "def analyze_human():\n",
    "    if not os.path.isdir(H_TAB_DIR):\n",
    "        print(\"[human] tables folder not found; aborting human analysis.\")\n",
    "        return pd.DataFrame()\n",
    "    raw, lab = load_human_channels_clean()\n",
    "    L,R,Z = hemi_map_from_labels(lab)\n",
    "    if L.size+R.size == 0:\n",
    "        print(\"[human] still no L/R mapping after cleaning — will attempt index-based split as last resort.\")\n",
    "        # fallback split by index (first half left, second half right) to let you inspect quickly\n",
    "        n = len(lab); L = np.arange(0, n//2); R = np.arange(n//2, n); Z = np.array([], int)\n",
    "    A,P,C = ap_map_from_labels(lab)\n",
    "\n",
    "    rows=[]\n",
    "    for b in H_BANDS:\n",
    "        cons_fp = os.path.join(H_TAB_DIR, f\"band__{b}{CONS_SUFFIX}\")\n",
    "        co_fp   = os.path.join(H_TAB_DIR, f\"band__{b}{CO_SUFFIX}\")\n",
    "        if not (os.path.exists(cons_fp) and os.path.exists(co_fp)): \n",
    "            continue\n",
    "        labels = np.load(cons_fp); co = np.load(co_fp); nch = len(labels)\n",
    "\n",
    "        l_same,l_diff,l_ratio = within_region_dualmodule_stats(co, labels, L)\n",
    "        r_same,r_diff,r_ratio = within_region_dualmodule_stats(co, labels, R)\n",
    "\n",
    "        cross_tbl = cross_hemi_coupling_table(co, labels, L, R)\n",
    "\n",
    "        uniq = sorted(np.unique(labels))\n",
    "        li_mod = {f\"LI_LR_mod{m}\": LI_LR(co, labels, L, R, m) for m in uniq}\n",
    "        ai_mod = {f\"AI_AP_mod{m}\": AI_AP(co, labels, A, P, m) for m in uniq}\n",
    "        comp   = module_composition_counts(labels, L, R, Z, A, P, C)\n",
    "\n",
    "        # small fig: reorder coassoc by [L mod0, L mod1, R mod0, R mod1, Z mod0, Z mod1]\n",
    "        if SAVE_FIGS:\n",
    "            try:\n",
    "                order=[]\n",
    "                for hemi in (L,R,Z):\n",
    "                    for m in uniq:\n",
    "                        order.extend(list(np.where((np.isin(np.arange(nch),hemi))&(labels==m))[0]))\n",
    "                order = np.array(order, int)\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                plt.imshow(co[np.ix_(order, order)], aspect='auto')\n",
    "                plt.title(f\"human {b}: coassoc [L/R/Z × mod0/mod1]\"); plt.colorbar(); plt.tight_layout()\n",
    "                fp = os.path.join(FIG_DIR_HUMAN, f\"human__{b}__coassoc_ordered.png\")\n",
    "                plt.savefig(fp, dpi=140); plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"[human:{b}] fig failed:\", e)\n",
    "\n",
    "        row = {\n",
    "            \"species\":\"human\",\"band\":b,\"n_channels\":nch,\n",
    "            \"n_left\":int(L.size),\"n_right\":int(R.size),\"n_mid\":int(Z.size),\n",
    "            \"n_ant\":int(A.size),\"n_post\":int(P.size),\"n_cent\":int(C.size),\n",
    "            \"left_intra_same\":l_same,\"left_intra_diff\":l_diff,\"left_intra_ratio\":l_ratio,\n",
    "            \"right_intra_same\":r_same,\"right_intra_diff\":r_diff,\"right_intra_ratio\":r_ratio,\n",
    "            \"WH_WM\":cross_tbl[\"WH_WM\"],\"WH_CM\":cross_tbl[\"WH_CM\"],\"CH_WM\":cross_tbl[\"CH_WM\"],\"CH_CM\":cross_tbl[\"CH_CM\"],\n",
    "        }\n",
    "        row.update(li_mod); row.update(ai_mod); row.update(comp); rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "df_h = analyze_human()\n",
    "if not df_h.empty:\n",
    "    df_h.to_csv(H_OUT_CSV, index=False)\n",
    "    print(\"\\n=== Humans (fixed): Hemispheric/AP metrics (saved) ===\")\n",
    "    cols = [\"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\n",
    "            \"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "            \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"]\n",
    "    print(df_h[[c for c in cols if c in df_h.columns]].to_string(index=False))\n",
    "    if SAVE_FIGS: print(\"Human figs →\", FIG_DIR_HUMAN)\n",
    "else:\n",
    "    print(\"[human] no bands processed — check that human consensus files exist.\")\n",
    "\n",
    "# Update merged CSV if mouse results exist\n",
    "frames=[]\n",
    "if os.path.exists(H_OUT_CSV):\n",
    "    frames.append(pd.read_csv(H_OUT_CSV).assign(dataset=\"human\"))\n",
    "if os.path.exists(M_OUT_CSV):\n",
    "    frames.append(pd.read_csv(M_OUT_CSV).assign(dataset=\"mouse\"))\n",
    "\n",
    "if frames:\n",
    "    merged = pd.concat(frames, ignore_index=True)\n",
    "    os.makedirs(os.path.dirname(MERGED), exist_ok=True)\n",
    "    merged.to_csv(MERGED, index=False)\n",
    "    print(\"\\nMerged CSV →\", MERGED)\n",
    "else:\n",
    "    print(\"\\nMerged CSV not written (no species CSVs available).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3650d524-eea4-4dac-b786-a273cc45f0b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S001/S001R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S002/S002R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S003/S003R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S004/S004R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S005/S005R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S006/S006R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S006/S006R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S007/S007R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S007/S007R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S008/S008R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S008/S008R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S009/S009R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S009/S009R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S010/S010R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S010/S010R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S011/S011R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S011/S011R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S012/S012R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S012/S012R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S013/S013R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S013/S013R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S014/S014R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S014/S014R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S015/S015R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S015/S015R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S016/S016R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S016/S016R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S017/S017R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S017/S017R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S018/S018R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S018/S018R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S019/S019R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S019/S019R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S020/S020R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S020/S020R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S021/S021R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S021/S021R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S022/S022R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S022/S022R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S023/S023R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S023/S023R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S024/S024R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S024/S024R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S025/S025R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S025/S025R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S026/S026R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S026/S026R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S027/S027R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S027/S027R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S028/S028R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S028/S028R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S029/S029R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S029/S029R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S030/S030R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S030/S030R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "[EO export] [(1, 'ok'), (2, 'ok'), (3, 'ok'), (4, 'ok'), (5, 'ok'), (6, 'ok'), (7, 'ok'), (8, 'ok')] ...\n",
      "[EO] alpha: LOSO=1.000, p≈0.0033 (saved)\n",
      "[EO] theta: LOSO=1.000, p≈0.0033 (saved)\n",
      "[EO] beta: LOSO=1.000, p≈0.0033 (saved)\n",
      "Saved EC hemi/AP → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\hemisphere_humans.csv\n",
      "Saved EO hemi/AP → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects_EO\\hemisphere_humans.csv\n",
      "\n",
      "=== EC vs EO comparison (key metrics + Δ) ===\n",
      " band  left_intra_ratio_EC  left_intra_ratio_EO  Δ_left_intra_ratio  right_intra_ratio_EC  right_intra_ratio_EO  Δ_right_intra_ratio  WH_WM_EC  WH_WM_EO   Δ_WH_WM  CH_WM_EC  CH_WM_EO   Δ_CH_WM  LI_LR_mod0_EC  LI_LR_mod0_EO  Δ_LI_LR_mod0  AI_AP_mod0_EC  AI_AP_mod0_EO  Δ_AI_AP_mod0\n",
      "alpha             2.270072             2.557772           -0.287700              2.129487              3.331607            -1.202120  0.768217  0.804118 -0.035901  0.660854  0.730783 -0.069929       0.043745       0.003747      0.039998       0.592513       0.692822     -0.100309\n",
      "theta             1.683705             2.141663           -0.457957              1.641144              2.453522            -0.812378  0.773547  0.804043 -0.030497  0.554859  0.668584 -0.113725      -0.067393       0.000082     -0.067476       0.440015       0.576575     -0.136560\n",
      " beta             4.490455             3.272361            1.218094              5.039549              3.183236             1.856313  0.891420  0.857199  0.034221  0.811233  0.736813  0.074420       0.043345       0.045888     -0.002543       0.821387       0.718992      0.102395\n",
      "\n",
      "Saved comparison CSV → C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_hemi_AP_EC_EO_compare.csv\n"
     ]
    }
   ],
   "source": [
    "# === CNT Human EC vs EO — PLI Consensus + Hemi/AP in one cell ===\n",
    "# What this does:\n",
    "#   1) Ensure EO (run 1) NPY for subjects 1..30; EC (run 2) assumed present from your previous run.\n",
    "#   2) Build PLI spectral-on-coassoc (k=2) consensus for α/θ/β in EC and EO (skips if files exist).\n",
    "#   3) Clean & map channels (10–20 + aliases) → Left/Right/Midline and Anterior/Posterior.\n",
    "#   4) Compute Hemi/AP metrics for EC and EO, then output a side-by-side comparison with deltas.\n",
    "#\n",
    "# Outputs:\n",
    "#   EC consensus/tables (already exist):  C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\...\n",
    "#   EO consensus/tables (new):            C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects_EO\\...\n",
    "#   Hemi/AP metrics EC:                   ...\\pli_30_subjects\\hemisphere_humans.csv\n",
    "#   Hemi/AP metrics EO:                   ...\\pli_30_subjects_EO\\hemisphere_humans.csv\n",
    "#   EC vs EO comparison table:            C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_hemi_AP_EC_EO_compare.csv\n",
    "#   (Optional) ordered co-association figures in ...\\figures_hemi_*\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd\n",
    "\n",
    "# ------------------ CONFIG ------------------\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "SUBJECTS  = list(range(1,31))\n",
    "FS_OUT    = 250.0\n",
    "DURATION_S= 60\n",
    "\n",
    "# Bands and consensus params\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "NULL_PERMS= 300\n",
    "\n",
    "# Paths\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")  # subject_##_{EC|EO}.npy live here\n",
    "# EC artifacts (assumed built)\n",
    "EC_DIR    = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\")\n",
    "EC_TAB    = os.path.join(EC_DIR, \"tables\")\n",
    "EC_MET    = os.path.join(EC_DIR, \"metrics\")\n",
    "# EO artifacts (will build here)\n",
    "EO_DIR    = os.path.join(ROOT, r\"artifacts\\pli_30_subjects_EO\")\n",
    "EO_TAB    = os.path.join(EO_DIR, \"tables\")\n",
    "EO_MET    = os.path.join(EO_DIR, \"metrics\")\n",
    "\n",
    "# Channel file (we'll clean/map from here)\n",
    "H_CH_TXT  = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "\n",
    "# Optional figures\n",
    "SAVE_FIGS    = True\n",
    "EC_FIG_HEMI  = os.path.join(EC_DIR, \"figures_hemi\")\n",
    "EO_FIG_HEMI  = os.path.join(EO_DIR, \"figures_hemi\")\n",
    "for p in [DATA_DIR, EC_TAB, EC_MET, EO_TAB, EO_MET]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "if SAVE_FIGS:\n",
    "    os.makedirs(EC_FIG_HEMI, exist_ok=True)\n",
    "    os.makedirs(EO_FIG_HEMI, exist_ok=True)\n",
    "\n",
    "# Output comparison CSV\n",
    "OUT_COMPARE = os.path.join(ROOT, r\"artifacts\\CNT_PLI_hemi_AP_EC_EO_compare.csv\")\n",
    "\n",
    "# ------------------ NPY EXPORT: EO if missing ------------------\n",
    "def ensure_eo_npys():\n",
    "    try:\n",
    "        import mne\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"mne\", \"pooch\"])\n",
    "        import mne\n",
    "\n",
    "    exported = []\n",
    "    for s in SUBJECTS:\n",
    "        base = os.path.join(DATA_DIR, f\"subject_{s:02d}_EO.npy\")\n",
    "        if os.path.exists(base):\n",
    "            exported.append((s, \"exists\")); continue\n",
    "        # fetch run 1 (eyes-open)\n",
    "        try:\n",
    "            try:\n",
    "                fpaths = mne.datasets.eegbci.load_data(subjects=[s], runs=[1], update_path=True, verbose=\"ERROR\")\n",
    "            except TypeError:\n",
    "                fpaths = mne.datasets.eegbci.load_data(subject=s, runs=[1], update_path=True, verbose=\"ERROR\")\n",
    "            raws=[]\n",
    "            for fp in fpaths:\n",
    "                raw=mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "                raw.pick_types(eeg=True, stim=False, eog=False, ecg=False, emg=False, misc=False)\n",
    "                raws.append(raw)\n",
    "            if not raws:\n",
    "                exported.append((s, \"no_raw\")); continue\n",
    "            raw = mne.concatenate_raws(raws, verbose=\"ERROR\")\n",
    "            # montage + filter + resample\n",
    "            try:\n",
    "                raw.set_montage(\"standard_1020\", on_missing=\"ignore\", match_case=False, verbose=\"ERROR\")\n",
    "            except Exception:\n",
    "                pass\n",
    "            raw.filter(1.0, 45.0, fir_design=\"firwin\", verbose=\"ERROR\")\n",
    "            raw.resample(FS_OUT, npad=\"auto\", verbose=\"ERROR\")\n",
    "            n_keep = int(DURATION_S * raw.info[\"sfreq\"])\n",
    "            X = raw.get_data(picks=\"eeg\")\n",
    "            if X.shape[1] >= n_keep:\n",
    "                X = X[:, :n_keep]\n",
    "            else:\n",
    "                reps = int(np.ceil(n_keep / X.shape[1])); X = np.tile(X, reps)[:, :n_keep]\n",
    "            ch_names = mne.pick_info(raw.info, mne.pick_types(raw.info, eeg=True)).ch_names\n",
    "            base_out = os.path.join(DATA_DIR, f\"subject_{s:02d}_EO\")\n",
    "            np.save(base_out + \".npy\", X.astype(np.float32))\n",
    "            with open(base_out + \".channels.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "                for ch in ch_names: f.write(ch + \"\\n\")\n",
    "            exported.append((s, \"ok\"))\n",
    "        except Exception as e:\n",
    "            exported.append((s, f\"error: {e}\"))\n",
    "    print(\"[EO export]\", exported[:8], \"...\" if len(exported)>8 else \"\")\n",
    "\n",
    "# ------------------ PLI CONSENSUS CORE ------------------\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def bandpass(x,fs,lo,hi,order=4):\n",
    "    b,a = butter(order, [lo/(fs_out/2), hi/(fs_out/2)], btype=\"band\")\n",
    "    return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs_out, lo, hi):\n",
    "    n=X.shape[0]; Y=np.zeros_like(X)\n",
    "    b,a = butter(4, [lo/(fs_out/2), hi/(fs_out/2)], btype=\"band\")\n",
    "    for c in range(n):\n",
    "        Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k=6):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W,k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n), float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n):\n",
    "                co[i,j]+=1.0 if li==lab[j] else 0.0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(labels):\n",
    "    cof = coassoc(labels)\n",
    "    cons= spec_labels(cof, k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(labels)):\n",
    "        leave=[lab for i,lab in enumerate(labels) if i!=s]\n",
    "        cons_l= spec_labels(coassoc(leave), k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def rand_same_sizes(lab, rng):\n",
    "    n=len(lab); uniq,cnts=np.unique(lab, return_counts=True)\n",
    "    idx=np.arange(n); rng.shuffle(idx)\n",
    "    out=np.empty(n,int); st=0\n",
    "    for L,c in zip(uniq,cnts):\n",
    "        seg=idx[st:st+c]; out[seg]=L; st+=c\n",
    "    return out\n",
    "\n",
    "def build_consensus_for_condition(tag_dir, tag_tab, condition_tag):\n",
    "    \"\"\"\n",
    "    condition_tag: 'EC' or 'EO'\n",
    "    Writes: band__{band}__consensus_labels.npy + band__{band}__coassoc.npy under tag_tab.\n",
    "    \"\"\"\n",
    "    files = [os.path.join(DATA_DIR, f\"subject_{s:02d}_{condition_tag}.npy\") for s in SUBJECTS if os.path.exists(os.path.join(DATA_DIR, f\"subject_{s:02d}_{condition_tag}.npy\"))]\n",
    "    if len(files) < 10:\n",
    "        print(f\"[{condition_tag}] WARNING: only {len(files)} NPY found.\")\n",
    "    rng=np.random.default_rng(7)\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        # skip if already present\n",
    "        cons_fp=os.path.join(tag_tab, f\"band__{band}__consensus_labels.npy\")\n",
    "        co_fp  =os.path.join(tag_tab, f\"band__{band}__coassoc.npy\")\n",
    "        if os.path.exists(cons_fp) and os.path.exists(co_fp):\n",
    "            continue\n",
    "        # per-subject labels\n",
    "        subj_labels=[]\n",
    "        for f in files:\n",
    "            X=np.load(f); W=pli_matrix(X, FS_OUT, lo, hi); W=knn(W, KNN_K)\n",
    "            labs=spec_labels(W, k=K_FIXED)\n",
    "            subj_labels.append(labs)\n",
    "        if not subj_labels:\n",
    "            print(f\"[{condition_tag}] no subjects for {band}\")\n",
    "            continue\n",
    "        loso, cons, cof = loso_via_coassoc(subj_labels)\n",
    "        np.save(cons_fp, cons); np.save(co_fp, cof)\n",
    "        # null just for log\n",
    "        null=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nlabs=[rand_same_sizes(l, rng) for l in subj_labels]\n",
    "            _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "            null.append(adjusted_rand_score(cons, cons_n))\n",
    "        null=np.array(null,float)\n",
    "        p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "        met={\"band\":band,\"n_subjects\":len(files),\"LOSO\":float(loso),\"null_mean\":float(null.mean()),\"p_value\":p}\n",
    "        with open(os.path.join(tag_dir,\"metrics\", f\"band__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump(met,f,indent=2)\n",
    "        print(f\"[{condition_tag}] {band}: LOSO={loso:.3f}, p≈{p:.4f} (saved)\")\n",
    "\n",
    "# ------------------ Channel cleaning + mapping ------------------\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "def load_human_channels_clean():\n",
    "    if not os.path.exists(H_CH_TXT):\n",
    "        raise SystemExit(\"Missing human channel file: \" + H_CH_TXT)\n",
    "    with open(H_CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "        raw=[ln.strip() for ln in f if ln.strip()]\n",
    "    lab=[clean_label(x) for x in raw]\n",
    "    return lab\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "\n",
    "def hemi_map_from_labels(clean_labels):\n",
    "    L,R,Z=[],[],[]\n",
    "    for i,ch in enumerate(clean_labels):\n",
    "        up=ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m=re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "def ap_map_from_labels(clean_labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(clean_labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "# ------------------ Hemi/AP metrics ------------------\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "\n",
    "def within_region_dualmodule_stats(co, labels, idx):\n",
    "    if idx.size<3: return np.nan, np.nan, np.nan\n",
    "    sub=np.ix_(idx,idx); co_r=co[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    intra_same=mean_safe(co_r[same]); intra_diff=mean_safe(co_r[diff])\n",
    "    return intra_same, intra_diff, float(intra_same/(intra_diff+1e-12))\n",
    "\n",
    "def cross_hemi_coupling_table(co, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross=np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same=labels[:,None]==labels[None,:]; diff=~same\n",
    "    for m in (within,cross,same,diff): np.fill_diagonal(m,False)\n",
    "    return {\"WH_WM\":mean_safe(co[within&same]),\"WH_CM\":mean_safe(co[within&diff]),\n",
    "            \"CH_WM\":mean_safe(co[cross&same]), \"CH_CM\":mean_safe(co[cross&diff])}\n",
    "\n",
    "def degree_to_same_module(co, labels, m_id):\n",
    "    mask=(labels==m_id); return co[:,mask].sum(axis=1)\n",
    "def LI_LR(co, labels, L, R, m_id):\n",
    "    deg=degree_to_same_module(co,labels,m_id)\n",
    "    Lsum=float(deg[L].sum()) if L.size else 0.0\n",
    "    Rsum=float(deg[R].sum()) if R.size else 0.0\n",
    "    return (Lsum-Rsum)/(Lsum+Rsum+1e-12)\n",
    "def AI_AP(co, labels, A, P, m_id):\n",
    "    deg=degree_to_same_module(co,labels,m_id)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def module_composition_counts(labels, L, R, Z, A, P, C):\n",
    "    out={}\n",
    "    for m in sorted(np.unique(labels)):\n",
    "        out[f\"cnt_L_mod{m}\"]=int((labels[L]==m).sum()) if L.size else 0\n",
    "        out[f\"cnt_R_mod{m}\"]=int((labels[R]==m).sum()) if R.size else 0\n",
    "        out[f\"cnt_Z_mod{m}\"]=int((labels[Z]==m).sum()) if Z.size else 0\n",
    "        out[f\"cnt_A_mod{m}\"]=int((labels[A]==m).sum()) if A.size else 0\n",
    "        out[f\"cnt_P_mod{m}\"]=int((labels[P]==m).sum()) if P.size else 0\n",
    "        out[f\"cnt_C_mod{m}\"]=int((labels[C]==m).sum()) if C.size else 0\n",
    "    return out\n",
    "\n",
    "def hemi_ap_for_condition(tag_dir, tag_tab, figures_dir):\n",
    "    # load channels\n",
    "    lab = load_human_channels_clean()\n",
    "    L,R,Z = hemi_map_from_labels(lab)\n",
    "    A,P,C = ap_map_from_labels(lab)\n",
    "    rows=[]\n",
    "    for b in BANDS_HZ.keys():\n",
    "        cons_fp=os.path.join(tag_tab, f\"band__{b}__consensus_labels.npy\")\n",
    "        co_fp  =os.path.join(tag_tab, f\"band__{b}__coassoc.npy\")\n",
    "        if not (os.path.exists(cons_fp) and os.path.exists(co_fp)):\n",
    "            continue\n",
    "        labels=np.load(cons_fp); co=np.load(co_fp); nch=len(labels)\n",
    "        l_same,l_diff,l_ratio=within_region_dualmodule_stats(co,labels,L)\n",
    "        r_same,r_diff,r_ratio=within_region_dualmodule_stats(co,labels,R)\n",
    "        cross_tbl=cross_hemi_coupling_table(co,labels,L,R)\n",
    "        uniq=sorted(np.unique(labels))\n",
    "        li_mod={f\"LI_LR_mod{m}\": LI_LR(co,labels,L,R,m) for m in uniq}\n",
    "        ai_mod={f\"AI_AP_mod{m}\": AI_AP(co,labels,A,P,m) for m in uniq}\n",
    "        comp=module_composition_counts(labels,L,R,Z,A,P,C)\n",
    "        if SAVE_FIGS:\n",
    "            try:\n",
    "                order=[]\n",
    "                for hemi in (L,R,Z):\n",
    "                    for m in uniq:\n",
    "                        order.extend(list(np.where((np.isin(np.arange(nch),hemi))&(labels==m))[0]))\n",
    "                order=np.array(order,int)\n",
    "                import matplotlib.pyplot as plt\n",
    "                plt.figure()\n",
    "                plt.imshow(co[np.ix_(order,order)], aspect='auto')\n",
    "                plt.title(f\"{os.path.basename(tag_dir)} {b}: coassoc [L/R/Z × mod0/mod1]\"); plt.colorbar(); plt.tight_layout()\n",
    "                fp=os.path.join(figures_dir, f\"{os.path.basename(tag_dir)}__{b}__coassoc_ordered.png\")\n",
    "                plt.savefig(fp, dpi=140); plt.close()\n",
    "            except Exception as e:\n",
    "                print(f\"[{os.path.basename(tag_dir)}:{b}] fig failed:\", e)\n",
    "        row={\"band\":b,\"n_channels\":nch,\n",
    "             \"n_left\":int(L.size),\"n_right\":int(R.size),\"n_mid\":int(Z.size),\n",
    "             \"n_ant\":int(A.size),\"n_post\":int(P.size),\"n_cent\":int(C.size),\n",
    "             \"left_intra_ratio\":l_ratio,\"right_intra_ratio\":r_ratio,\n",
    "             \"WH_WM\":cross_tbl[\"WH_WM\"],\"WH_CM\":cross_tbl[\"WH_CM\"],\"CH_WM\":cross_tbl[\"CH_WM\"],\"CH_CM\":cross_tbl[\"CH_CM\"]}\n",
    "        row.update(li_mod); row.update(ai_mod); row.update(comp); rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# ------------------ RUN PIPELINE ------------------\n",
    "# 1) Ensure EO NPYs\n",
    "ensure_eo_npys()\n",
    "\n",
    "# 2) Build EC/EO consensus (skip EC if exists)\n",
    "fs_out = FS_OUT  # used inside bandpass\n",
    "build_consensus_for_condition(EC_DIR, EC_TAB, \"EC\")  # will skip if files already exist\n",
    "build_consensus_for_condition(EO_DIR, EO_TAB, \"EO\")\n",
    "\n",
    "# 3) Hemi/AP metrics for EC and EO\n",
    "df_ec = hemi_ap_for_condition(EC_DIR, EC_TAB, EC_FIG_HEMI)\n",
    "df_eo = hemi_ap_for_condition(EO_DIR, EO_TAB, EO_FIG_HEMI)\n",
    "\n",
    "# Save per-condition CSVs\n",
    "if not df_ec.empty:\n",
    "    out_ec = os.path.join(EC_DIR, \"hemisphere_humans.csv\"); df_ec.to_csv(out_ec, index=False)\n",
    "    print(\"Saved EC hemi/AP →\", out_ec)\n",
    "if not df_eo.empty:\n",
    "    out_eo = os.path.join(EO_DIR, \"hemisphere_humans.csv\"); df_eo.to_csv(out_eo, index=False)\n",
    "    print(\"Saved EO hemi/AP →\", out_eo)\n",
    "\n",
    "# 4) Build comparison table (EC vs EO) with deltas\n",
    "if not df_ec.empty and not df_eo.empty:\n",
    "    # join on band\n",
    "    join_cols = [\"band\",\"n_channels\",\"n_left\",\"n_right\",\"n_ant\",\"n_post\",\"n_cent\"]\n",
    "    metric_cols = [\"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"WH_CM\",\"CH_WM\",\"CH_CM\",\n",
    "                   \"LI_LR_mod0\",\"LI_LR_mod1\",\"AI_AP_mod0\",\"AI_AP_mod1\"]\n",
    "    # rename for merge\n",
    "    ec = df_ec[join_cols + metric_cols].copy()\n",
    "    eo = df_eo[join_cols + metric_cols].copy()\n",
    "    ec = ec.rename(columns={c: f\"{c}_EC\" for c in metric_cols})\n",
    "    eo = eo.rename(columns={c: f\"{c}_EO\" for c in metric_cols})\n",
    "    cmp = pd.merge(ec, eo, on=join_cols, how=\"inner\")\n",
    "    # add deltas (EC - EO)\n",
    "    for c in metric_cols:\n",
    "        cmp[f\"Δ_{c}\"] = cmp[f\"{c}_EC\"] - cmp[f\"{c}_EO\"]\n",
    "    cmp.to_csv(OUT_COMPARE, index=False)\n",
    "    print(\"\\n=== EC vs EO comparison (key metrics + Δ) ===\")\n",
    "    print(cmp[[\"band\",\n",
    "               \"left_intra_ratio_EC\",\"left_intra_ratio_EO\",\"Δ_left_intra_ratio\",\n",
    "               \"right_intra_ratio_EC\",\"right_intra_ratio_EO\",\"Δ_right_intra_ratio\",\n",
    "               \"WH_WM_EC\",\"WH_WM_EO\",\"Δ_WH_WM\",\n",
    "               \"CH_WM_EC\",\"CH_WM_EO\",\"Δ_CH_WM\",\n",
    "               \"LI_LR_mod0_EC\",\"LI_LR_mod0_EO\",\"Δ_LI_LR_mod0\",\n",
    "               \"AI_AP_mod0_EC\",\"AI_AP_mod0_EO\",\"Δ_AI_AP_mod0\"]].to_string(index=False))\n",
    "    print(\"\\nSaved comparison CSV →\", OUT_COMPARE)\n",
    "else:\n",
    "    print(\"\\nComparison not written (one condition missing).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "77edd0c8-5dd5-48bc-95d2-83e7c187cef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EC - EO (paired, subject-level) — bootstrap CIs & p-values ===\n",
      " band            metric  N_pairs  delta_mean    ci_2.5   ci_97.5   p_boot\n",
      "alpha  left_intra_ratio       30    3.695037 -1.147616 11.750398 0.468766\n",
      "alpha right_intra_ratio       30    1.019468 -7.511263 12.953784 0.847076\n",
      "alpha             WH_WM       30    0.019686  0.010083  0.030510 0.483258\n",
      "alpha             CH_WM       30    0.016207  0.008887  0.024559 0.498251\n",
      "alpha        AI_AP_mod0       30   -0.125969 -0.355893  0.099395 0.502249\n",
      "theta  left_intra_ratio       30   -2.207807 -4.221322 -0.738394 0.470265\n",
      "theta right_intra_ratio       30    1.234547 -1.153567  3.902559 0.494753\n",
      "theta             WH_WM       30   -0.008086 -0.012853 -0.003888 0.506247\n",
      "theta             CH_WM       30   -0.002711 -0.007172  0.001351 0.488256\n",
      "theta        AI_AP_mod0       30   -0.140331 -0.288054  0.002500 0.485757\n",
      " beta  left_intra_ratio       30   -0.237323 -2.095473  1.063375 0.771614\n",
      " beta right_intra_ratio       30    0.728343 -1.087263  2.502831 0.548726\n",
      " beta             WH_WM       30    0.012454  0.003362  0.021538 0.500250\n",
      " beta             CH_WM       30    0.003671  0.000758  0.006549 0.487756\n",
      " beta        AI_AP_mod0       30    0.127252  0.011943  0.227849 0.487256\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_EC_EO_paired_bootstrap.csv\n",
      "Scalp plots → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\figures_ec_eo_scalp\n"
     ]
    }
   ],
   "source": [
    "# === EC vs EO — Subject-level paired metrics + bootstrap CIs + scalp plots (single cell) ===\n",
    "# What this cell does:\n",
    "#   A) For each subject (1..30) and each band (alpha/theta/beta), compute per-subject metrics under EC and EO:\n",
    "#        - left_intra_ratio, right_intra_ratio\n",
    "#        - WH_WM, CH_WM  (within-hemi / cross-hemi & within-module)\n",
    "#        - AI_AP_mod0    (anterior - posterior asymmetry for module 0)\n",
    "#      Then compute paired EC–EO deltas, bootstrap 95% CIs, and p-values (two-sided, mean delta).\n",
    "#   B) Draw fast scalp \"two-cluster\" maps for EC and EO consensus labels for each band (no MNE).\n",
    "#\n",
    "# Inputs (assumed present from your prior runs and the previous EO cell):\n",
    "#   NPY data:  C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_##_{EC|EO}.npy\n",
    "#   Channels:  C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_01_EC.channels.txt\n",
    "#   EC consensus: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\tables\\band__{band}__consensus_labels.npy\n",
    "#                 C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\tables\\band__{band}__coassoc.npy\n",
    "#   EO consensus: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects_EO\\tables\\band__{band}__consensus_labels.npy\n",
    "#\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_EC_EO_paired_bootstrap.csv\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\figures_ec_eo_scalp\\scalp__{band}__{EC|EO}.png\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "SUBJECTS  = list(range(1,31))\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "BOOT_B    = 2000\n",
    "\n",
    "EC_DIR, EO_DIR = (os.path.join(ROOT, r\"artifacts\\pli_30_subjects\"),\n",
    "                  os.path.join(ROOT, r\"artifacts\\pli_30_subjects_EO\"))\n",
    "EC_TAB, EO_TAB = (os.path.join(EC_DIR, \"tables\"),\n",
    "                  os.path.join(EO_DIR, \"tables\"))\n",
    "\n",
    "CH_TXT   = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "OUT_CSV  = os.path.join(ROOT, r\"artifacts\\CNT_PLI_EC_EO_paired_bootstrap.csv\")\n",
    "SCALP_DIR= os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_ec_eo_scalp\")\n",
    "os.makedirs(SCALP_DIR, exist_ok=True)\n",
    "\n",
    "# ------------------- Channel handling -------------------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "def load_channels():\n",
    "    if not os.path.exists(CH_TXT):\n",
    "        raise SystemExit(\"Channel file missing: \" + CH_TXT)\n",
    "    with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        ch = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "    return ch\n",
    "\n",
    "ch_names = load_channels()\n",
    "\n",
    "# Hemisphere map\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i, ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "# Anterior/Posterior map (for AI_AP_mod0)\n",
    "ANT_PREFIXES = (\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map(labels):\n",
    "    A,P,C = [],[],[]\n",
    "    for i, ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# ------------------- Spectral clustering / metrics -------------------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n):\n",
    "        Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W = W.copy(); n = W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx = np.argsort(W[i])[::-1]; keep = idx[:k]\n",
    "        mask = np.ones(n, bool); mask[keep] = False\n",
    "        W[i,mask] = 0.0\n",
    "    W = np.maximum(W,W.T); np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "\n",
    "def within_region_ratio(W, labels, idx):\n",
    "    \"\"\"Within a region (e.g., left/right), ratio of same-module mean to cross-module mean using W.\"\"\"\n",
    "    if idx.size < 3: return np.nan\n",
    "    sub = np.ix_(idx,idx); Wr = W[sub]; lab = labels[idx]\n",
    "    same = lab[:,None] == lab[None,:]; diff = ~same\n",
    "    np.fill_diagonal(same, False); np.fill_diagonal(diff, False)\n",
    "    m_same = mean_safe(Wr[same]); m_diff = mean_safe(Wr[diff])\n",
    "    return float(m_same / (m_diff + 1e-12))\n",
    "\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    \"\"\"WH_WM and CH_WM (within-hemisphere within-module; cross-hemisphere within-module) from W.\"\"\"\n",
    "    n = len(labels)\n",
    "    Lmask = np.zeros((n,n), bool); Lmask[np.ix_(L,L)] = True\n",
    "    Rmask = np.zeros((n,n), bool); Rmask[np.ix_(R,R)] = True\n",
    "    within = Lmask | Rmask\n",
    "    cross  = np.zeros((n,n), bool); cross[np.ix_(L,R)] = True; cross[np.ix_(R,L)] = True\n",
    "    same   = labels[:,None] == labels[None,:]\n",
    "    for m in (within, cross, same):\n",
    "        np.fill_diagonal(m, False)\n",
    "    WH_WM = mean_safe(W[within & same])\n",
    "    CH_WM = mean_safe(W[cross  & same])\n",
    "    return WH_WM, CH_WM\n",
    "\n",
    "def AI_AP_mod0(W, labels, A, P):\n",
    "    \"\"\"Anterior-Posterior asymmetry for module 0 using degree-to-same-module.\"\"\"\n",
    "    m = 0\n",
    "    mask = (labels == m); deg = W[:,mask].sum(axis=1)\n",
    "    Asum = float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum = float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum - Psum) / (Asum + Psum + 1e-12)\n",
    "\n",
    "# ------------------- Per-subject metric extractor -------------------\n",
    "def subject_metrics(subject_id, cond_tag, band):\n",
    "    \"\"\"Compute per-subject metrics for one subject, condition (EC/EO), and band.\"\"\"\n",
    "    f = os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f):\n",
    "        return None\n",
    "    X = np.load(f)\n",
    "    lo,hi = BANDS_HZ[band]\n",
    "    W  = pli_matrix(X, FS, lo, hi)\n",
    "    W  = knn(W, KNN_K)\n",
    "    lbl= spec_labels(W, k=K_FIXED)\n",
    "    # Metrics:\n",
    "    l_ratio = within_region_ratio(W, lbl, L_idx)\n",
    "    r_ratio = within_region_ratio(W, lbl, R_idx)\n",
    "    WH_WM, CH_WM = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "    ai_ap0 = AI_AP_mod0(W, lbl, A_idx, P_idx)\n",
    "    return {\"subject\": subject_id, \"cond\": cond_tag, \"band\": band,\n",
    "            \"left_intra_ratio\": l_ratio, \"right_intra_ratio\": r_ratio,\n",
    "            \"WH_WM\": WH_WM, \"CH_WM\": CH_WM, \"AI_AP_mod0\": ai_ap0}\n",
    "\n",
    "# ------------------- Build paired deltas + bootstrap -------------------\n",
    "def bootstrap_ci_p(deltas, B=2000, two_sided=True, seed=7):\n",
    "    \"\"\"Bootstrap mean delta CI and p-value (two-sided) against 0.\"\"\"\n",
    "    deltas = np.array([d for d in deltas if np.isfinite(d)])\n",
    "    if deltas.size == 0:\n",
    "        return np.nan, (np.nan, np.nan), np.nan\n",
    "    rng = np.random.default_rng(seed)\n",
    "    means = []\n",
    "    n = len(deltas)\n",
    "    for _ in range(B):\n",
    "        samp = deltas[rng.integers(0, n, size=n)]\n",
    "        means.append(np.mean(samp))\n",
    "    means = np.array(means)\n",
    "    ci_lo, ci_hi = np.percentile(means, [2.5, 97.5])\n",
    "    # two-sided p: proportion of bootstrap means with |mean| >= |obs_mean|\n",
    "    obs = float(np.mean(deltas))\n",
    "    p = float((np.sum(np.abs(means) >= abs(obs)) + 1) / (B + 1))\n",
    "    return obs, (float(ci_lo), float(ci_hi)), p\n",
    "\n",
    "rows = []\n",
    "for band in BANDS_HZ.keys():\n",
    "    # collect per-subject metrics\n",
    "    recs = []\n",
    "    for s in SUBJECTS:\n",
    "        m_ec = subject_metrics(s, \"EC\", band)\n",
    "        m_eo = subject_metrics(s, \"EO\", band)\n",
    "        if m_ec and m_eo:\n",
    "            recs.append((m_ec, m_eo))\n",
    "    if not recs:\n",
    "        continue\n",
    "    # build paired deltas\n",
    "    metrics = [\"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"CH_WM\",\"AI_AP_mod0\"]\n",
    "    for met in metrics:\n",
    "        deltas = [r[0][met] - r[1][met] for r in recs]  # EC - EO\n",
    "        obs, (ci_lo, ci_hi), p = bootstrap_ci_p(deltas, B=BOOT_B)\n",
    "        rows.append({\"band\": band, \"metric\": met, \"N_pairs\": len(deltas),\n",
    "                     \"delta_mean\": obs, \"ci_2.5\": ci_lo, \"ci_97.5\": ci_hi, \"p_boot\": p})\n",
    "\n",
    "df_boot = pd.DataFrame(rows)\n",
    "df_boot.to_csv(OUT_CSV, index=False)\n",
    "print(\"=== EC - EO (paired, subject-level) — bootstrap CIs & p-values ===\")\n",
    "print(df_boot.to_string(index=False))\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "\n",
    "# ------------------- Fast scalp plots: EC vs EO consensus labels -------------------\n",
    "# Minimal 10–20 2D coords for plotting (no interpolation)\n",
    "canon_xy = {\n",
    " \"Fp1\":(-0.5, 0.95), \"Fpz\":(0.0, 0.98), \"Fp2\":(0.5, 0.95),\n",
    " \"AF7\":(-0.65, 0.75), \"AF3\":(-0.35, 0.78), \"AFz\":(0.0, 0.80), \"AF4\":(0.35,0.78), \"AF8\":(0.65,0.75),\n",
    " \"F7\":(-0.8, 0.55), \"F5\":(-0.55,0.58), \"F3\":(-0.35,0.60), \"F1\":(-0.15,0.62), \"Fz\":(0.0,0.65),\n",
    " \"F2\":(0.15,0.62), \"F4\":(0.35,0.60), \"F6\":(0.55,0.58), \"F8\":(0.8,0.55),\n",
    " \"FT7\":(-0.9, 0.35), \"FC5\":(-0.6,0.40), \"FC3\":(-0.4,0.42), \"FC1\":(-0.2,0.44), \"FCz\":(0.0,0.45),\n",
    " \"FC2\":(0.2,0.44), \"FC4\":(0.4,0.42), \"FC6\":(0.6,0.40), \"FT8\":(0.9,0.35),\n",
    " \"T7\":(-1.0, 0.05), \"C5\":(-0.6,0.05), \"C3\":(-0.4,0.05), \"C1\":(-0.2,0.05), \"Cz\":(0.0,0.05),\n",
    " \"C2\":(0.2,0.05), \"C4\":(0.4,0.05), \"C6\":(0.6,0.05), \"T8\":(1.0,0.05),\n",
    " \"TP7\":(-0.9,-0.25), \"CP5\":(-0.6,-0.25), \"CP3\":(-0.4,-0.25), \"CP1\":(-0.2,-0.25), \"CPz\":(0.0,-0.25),\n",
    " \"CP2\":(0.2,-0.25), \"CP4\":(0.4,-0.25), \"CP6\":(0.6,-0.25), \"TP8\":(0.9,-0.25),\n",
    " \"P7\":(-0.8,-0.50), \"P5\":(-0.55,-0.50), \"P3\":(-0.35,-0.50), \"P1\":(-0.15,-0.50), \"Pz\":(0.0,-0.52),\n",
    " \"P2\":(0.15,-0.50), \"P4\":(0.35,-0.50), \"P6\":(0.55,-0.50), \"P8\":(0.8,-0.50),\n",
    " \"PO7\":(-0.65,-0.70), \"PO3\":(-0.35,-0.70), \"POz\":(0.0,-0.72), \"PO4\":(0.35,-0.70), \"PO8\":(0.65,-0.70),\n",
    " \"O1\":(-0.4,-0.90), \"Oz\":(0.0,-0.92), \"O2\":(0.4,-0.90)\n",
    "}\n",
    "def coords_for_channels(names):\n",
    "    out=[]; idx=[]\n",
    "    canon = {k.upper():k for k in canon_xy.keys()}\n",
    "    alias = {\"T3\":\"T7\",\"T4\":\"T8\",\"T5\":\"P7\",\"T6\":\"P8\",\"FP1\":\"Fp1\",\"FP2\":\"Fp2\",\"FPZ\":\"Fpz\",\"OZ\":\"Oz\",\"CZ\":\"Cz\",\"PZ\":\"Pz\",\"FZ\":\"Fz\",\"POZ\":\"POz\"}\n",
    "    for i,ch in enumerate(names):\n",
    "        up = ch.upper()\n",
    "        key = alias.get(up, ch)\n",
    "        keyu= key.upper()\n",
    "        if keyu in canon:\n",
    "            out.append(canon_xy[canon[keyu]]); idx.append(i)\n",
    "    return np.array(out,float), np.array(idx,int)\n",
    "\n",
    "def draw_head(ax):\n",
    "    head = plt.Circle((0,0), 1.03, fill=False, linewidth=2)\n",
    "    nose = plt.Polygon([[-0.12,1.03],[0,1.15],[0.12,1.03]], fill=False)\n",
    "    ax.add_patch(head); ax.add_patch(nose)\n",
    "    ax.set_xlim(-1.15,1.15); ax.set_ylim(-1.1,1.2)\n",
    "    ax.set_aspect(\"equal\"); ax.axis(\"off\")\n",
    "\n",
    "def plot_scalp(cons_labels, names, title, out_png):\n",
    "    pts, keep = coords_for_channels(names)\n",
    "    labs = np.array(cons_labels)[keep]\n",
    "    fig = plt.figure(figsize=(6,6)); ax = fig.add_subplot(111); draw_head(ax)\n",
    "    m0 = labs==0; m1 = labs==1\n",
    "    ax.scatter(pts[m0,0], pts[m0,1], s=70, label=\"Cluster 0\")\n",
    "    ax.scatter(pts[m1,0], pts[m1,1], s=70, marker=\"s\", label=\"Cluster 1\")\n",
    "    for name in [\"Fpz\",\"Fz\",\"Cz\",\"Pz\",\"Oz\"]:\n",
    "        if name in canon_xy:\n",
    "            x,y = canon_xy[name]; ax.text(x,y+0.03,name,ha=\"center\",va=\"bottom\",fontsize=9)\n",
    "    ax.legend(loc=\"upper right\"); ax.set_title(title)\n",
    "    fig.tight_layout(); fig.savefig(out_png,dpi=160); plt.close(fig)\n",
    "\n",
    "for band in BANDS_HZ.keys():\n",
    "    # EC\n",
    "    cons_ec = os.path.join(EC_TAB, f\"band__{band}__consensus_labels.npy\")\n",
    "    if os.path.exists(cons_ec):\n",
    "        plot_scalp(np.load(cons_ec), ch_names,\n",
    "                   f\"EC consensus clusters | {band}\", \n",
    "                   os.path.join(SCALP_DIR, f\"scalp__{band}__EC.png\"))\n",
    "    # EO\n",
    "    cons_eo = os.path.join(EO_TAB, f\"band__{band}__consensus_labels.npy\")\n",
    "    if os.path.exists(cons_eo):\n",
    "        plot_scalp(np.load(cons_eo), ch_names,\n",
    "                   f\"EO consensus clusters | {band}\", \n",
    "                   os.path.join(SCALP_DIR, f\"scalp__{band}__EO.png\"))\n",
    "\n",
    "print(\"Scalp plots →\", SCALP_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "42fd70e4-92fa-412f-b55e-a86080efcc10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EC - EO (paired) — corrected permutation p-values ===\n",
      " band            metric  N_pairs  delta_mean    ci_2.5   ci_97.5   p_perm\n",
      "alpha  left_intra_ratio       30    3.695037 -1.147616 11.750398 0.383762\n",
      "alpha right_intra_ratio       30    1.019468 -7.511263 12.953784 0.891211\n",
      "alpha             WH_WM       30    0.019686  0.010083  0.030510 0.000200\n",
      "alpha             CH_WM       30    0.016207  0.008887  0.024559 0.000100\n",
      "alpha        AI_AP_mod0       30   -0.125969 -0.355893  0.099395 0.280572\n",
      "theta  left_intra_ratio       30   -2.207807 -4.221322 -0.738394 0.004200\n",
      "theta right_intra_ratio       30    1.234547 -1.153567  3.902559 0.364464\n",
      "theta             WH_WM       30   -0.008086 -0.012853 -0.003888 0.001200\n",
      "theta             CH_WM       30   -0.002711 -0.007172  0.001351 0.219978\n",
      "theta        AI_AP_mod0       30   -0.140331 -0.288054  0.002500 0.062394\n",
      " beta  left_intra_ratio       30   -0.237323 -2.095473  1.063375 0.904310\n",
      " beta right_intra_ratio       30    0.728343 -1.087263  2.502831 0.436956\n",
      " beta             WH_WM       30    0.012454  0.003362  0.021538 0.014799\n",
      " beta             CH_WM       30    0.003671  0.000758  0.006549 0.029797\n",
      " beta        AI_AP_mod0       30    0.127252  0.011943  0.227849 0.030397\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_EC_EO_paired_perm.csv\n"
     ]
    }
   ],
   "source": [
    "# === FIX: EC–EO paired stats with proper permutation p-values (sign-flip) ===\n",
    "# Recomputes per-subject EC–EO deltas for {left/right_intra_ratio, WH_WM, CH_WM, AI_AP_mod0}\n",
    "# and outputs corrected two-sided permutation p-values + bootstrap 95% CIs.\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "SUBJECTS  = list(range(1,31))\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "BOOT_B    = 2000\n",
    "PERM_B    = 10000\n",
    "\n",
    "OUT_CSV   = os.path.join(ROOT, r\"artifacts\\CNT_PLI_EC_EO_paired_perm.csv\")\n",
    "CH_TXT    = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "def load_channels():\n",
    "    if not os.path.exists(CH_TXT):\n",
    "        raise SystemExit(\"Channel file missing: \" + CH_TXT)\n",
    "    with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "ch_names = load_channels()\n",
    "\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up=ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m=re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map(labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n):\n",
    "        Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "\n",
    "def within_region_ratio(W, labels, idx):\n",
    "    if idx.size<3: return np.nan\n",
    "    sub=np.ix_(idx,idx); Wr=W[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    m_same=mean_safe(Wr[same]); m_diff=mean_safe(Wr[diff])\n",
    "    return float(m_same/(m_diff+1e-12))\n",
    "\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    WH_WM=mean_safe(W[within&same]); CH_WM=mean_safe(W[cross&same])\n",
    "    return WH_WM, CH_WM\n",
    "\n",
    "def AI_AP_mod0(W, labels, A, P):\n",
    "    m=0; mask=(labels==m); deg=W[:,mask].sum(axis=1)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def subject_metrics(subject_id, cond_tag, band):\n",
    "    f = os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f): return None\n",
    "    X = np.load(f)\n",
    "    lo,hi=BANDS_HZ[band]\n",
    "    W  = pli_matrix(X, FS, lo, hi)\n",
    "    W  = knn(W, KNN_K)\n",
    "    lbl= spec_labels(W, k=K_FIXED)\n",
    "    l_ratio = within_region_ratio(W, lbl, L_idx)\n",
    "    r_ratio = within_region_ratio(W, lbl, R_idx)\n",
    "    WH_WM, CH_WM = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "    ai_ap0 = AI_AP_mod0(W, lbl, A_idx, P_idx)\n",
    "    return {\"subject\": subject_id, \"cond\": cond_tag, \"band\": band,\n",
    "            \"left_intra_ratio\": l_ratio, \"right_intra_ratio\": r_ratio,\n",
    "            \"WH_WM\": WH_WM, \"CH_WM\": CH_WM, \"AI_AP_mod0\": ai_ap0}\n",
    "\n",
    "def bootstrap_ci(deltas, B=2000, seed=7):\n",
    "    rng=np.random.default_rng(seed)\n",
    "    deltas=np.array([d for d in deltas if np.isfinite(d)])\n",
    "    if deltas.size==0: return np.nan, np.nan\n",
    "    means=[]\n",
    "    n=len(deltas)\n",
    "    for _ in range(B):\n",
    "        samp=deltas[rng.integers(0,n,size=n)]\n",
    "        means.append(np.mean(samp))\n",
    "    lo,hi=np.percentile(means,[2.5,97.5])\n",
    "    return float(lo), float(hi)\n",
    "\n",
    "def perm_pvalue(deltas, B=10000, seed=11):\n",
    "    rng=np.random.default_rng(seed)\n",
    "    deltas=np.array([d for d in deltas if np.isfinite(d)])\n",
    "    if deltas.size==0: return np.nan\n",
    "    obs=np.mean(deltas)\n",
    "    # sign-flip under null: EC and EO labels are exchangeable → delta signs random\n",
    "    cnt=1  # +1 for obs\n",
    "    for _ in range(B):\n",
    "        signs=np.where(rng.random(len(deltas))<0.5, 1.0, -1.0)\n",
    "        perm=np.mean(deltas*signs)\n",
    "        if abs(perm) >= abs(obs): cnt+=1\n",
    "    return float(cnt/(B+1))\n",
    "\n",
    "rows=[]\n",
    "for band in BANDS_HZ.keys():\n",
    "    recs=[]\n",
    "    for s in SUBJECTS:\n",
    "        ec=subject_metrics(s,\"EC\",band)\n",
    "        eo=subject_metrics(s,\"EO\",band)\n",
    "        if ec and eo: recs.append((ec,eo))\n",
    "    if not recs: continue\n",
    "    metrics=[\"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"CH_WM\",\"AI_AP_mod0\"]\n",
    "    for met in metrics:\n",
    "        deltas=[r[0][met]-r[1][met] for r in recs]  # EC-EO\n",
    "        dmean=float(np.mean([d for d in deltas if np.isfinite(d)])) if len(deltas) else np.nan\n",
    "        ci_lo,ci_hi=bootstrap_ci(deltas, B=BOOT_B)\n",
    "        p_perm=perm_pvalue(deltas, B=PERM_B)\n",
    "        rows.append({\"band\":band,\"metric\":met,\"N_pairs\":len(deltas),\n",
    "                     \"delta_mean\":dmean,\"ci_2.5\":ci_lo,\"ci_97.5\":ci_hi,\"p_perm\":p_perm})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"=== EC - EO (paired) — corrected permutation p-values ===\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"Saved:\", OUT_CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "077d04cf-3338-419c-b220-72b299fc1256",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1-page PDF: C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_EC_EO_summary.pdf\n"
     ]
    }
   ],
   "source": [
    "# === Compose 1-page EC vs EO PDF (paired stats + scalp maps) ===\n",
    "import os, pandas as pd, matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "CSV_STATS = os.path.join(ROOT, r\"artifacts\\CNT_PLI_EC_EO_paired_perm.csv\")\n",
    "SCALP_DIR = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_ec_eo_scalp\")\n",
    "OUT_PDF   = os.path.join(ROOT, r\"artifacts\\CNT_PLI_EC_EO_summary.pdf\")\n",
    "\n",
    "# Load stats\n",
    "df = pd.read_csv(CSV_STATS) if os.path.exists(CSV_STATS) else pd.DataFrame()\n",
    "\n",
    "# Prepare page\n",
    "fig = plt.figure(figsize=(11, 8.5))  # landscape letter\n",
    "\n",
    "# Title\n",
    "ax_t = fig.add_axes([0.05, 0.90, 0.90, 0.08]); ax_t.axis(\"off\")\n",
    "ax_t.text(0.5, 0.5, \"CNT — Eyes-Closed vs Eyes-Open (Subject-level PLI; paired EC–EO)\",\n",
    "          ha=\"center\", va=\"center\", fontsize=16, weight=\"bold\")\n",
    "\n",
    "# Table (compact: only key rows with p_perm < 0.05 + alpha WH_WM/CH_WM rows)\n",
    "keep = []\n",
    "if not df.empty:\n",
    "    for band in [\"alpha\",\"theta\",\"beta\"]:\n",
    "        dsub = df[df[\"band\"]==band].copy()\n",
    "        # always show WH_WM and CH_WM for all bands\n",
    "        keep.append(dsub[dsub[\"metric\"]==\"WH_WM\"])\n",
    "        keep.append(dsub[dsub[\"metric\"]==\"CH_WM\"])\n",
    "        # include significant others (p_perm<0.05)\n",
    "        keep.append(dsub[(dsub[\"metric\"]!=\"WH_WM\") & (dsub[\"metric\"]!=\"CH_WM\") & (dsub[\"p_perm\"]<0.05)])\n",
    "    show = pd.concat(keep, ignore_index=True) if keep else df\n",
    "    show = show[[\"band\",\"metric\",\"N_pairs\",\"delta_mean\",\"ci_2.5\",\"ci_97.5\",\"p_perm\"]]\n",
    "    show[\"delta_mean\"] = show[\"delta_mean\"].map(lambda x: f\"{x:.3f}\")\n",
    "    show[\"ci_2.5\"]     = show[\"ci_2.5\"].map(lambda x: f\"{x:.3f}\")\n",
    "    show[\"ci_97.5\"]    = show[\"ci_97.5\"].map(lambda x: f\"{x:.3f}\")\n",
    "    show[\"p_perm\"]     = show[\"p_perm\"].map(lambda x: f\"{x:.4f}\")\n",
    "else:\n",
    "    show = pd.DataFrame([{\"band\":\"—\",\"metric\":\"No data\",\"N_pairs\":\"\",\"delta_mean\":\"\",\"ci_2.5\":\"\",\"ci_97.5\":\"\",\"p_perm\":\"\"}])\n",
    "\n",
    "ax_tab = fig.add_axes([0.05, 0.58, 0.90, 0.28]); ax_tab.axis(\"off\")\n",
    "table = ax_tab.table(cellText=show.values, colLabels=show.columns, loc=\"center\")\n",
    "table.auto_set_font_size(False); table.set_fontsize(8); table.scale(1.0, 1.3)\n",
    "\n",
    "# Scalp strip: for each band, EC (left) vs EO (right)\n",
    "slots = {\n",
    "    \"alpha\": [0.05, 0.05, 0.28, 0.45],\n",
    "    \"theta\": [0.36, 0.05, 0.28, 0.45],\n",
    "    \"beta\" : [0.67, 0.05, 0.28, 0.45],\n",
    "}\n",
    "for band, rect in slots.items():\n",
    "    ax = fig.add_axes(rect); ax.axis(\"off\")\n",
    "    # assemble side-by-side: EC then EO\n",
    "    p_ec = os.path.join(SCALP_DIR, f\"scalp__{band}__EC.png\")\n",
    "    p_eo = os.path.join(SCALP_DIR, f\"scalp__{band}__EO.png\")\n",
    "    imgs = []\n",
    "    if os.path.exists(p_ec): imgs.append((\"EC\", plt.imread(p_ec)))\n",
    "    if os.path.exists(p_eo): imgs.append((\"EO\", plt.imread(p_eo)))\n",
    "    if imgs:\n",
    "        # stack horizontally with minimal gutters\n",
    "        total_w = sum(img.shape[1] for _,img in imgs)\n",
    "        max_h   = max(img.shape[0] for _,img in imgs)\n",
    "        strip = 255*np.ones((max_h, total_w, 4), dtype=np.uint8)\n",
    "        x=0\n",
    "        for tag, img in imgs:\n",
    "            h,w = img.shape[0], img.shape[1]\n",
    "            strip[:h, x:x+w, :img.shape[2]] = img\n",
    "            # label\n",
    "            ax.text((x+w/2)/total_w, 1.02, f\"{band.upper()} {tag}\", transform=ax.transAxes,\n",
    "                    ha=\"center\", va=\"bottom\", fontsize=10)\n",
    "            x += w\n",
    "        ax.imshow(strip); ax.set_title(f\"{band} — EC vs EO\")\n",
    "    else:\n",
    "        ax.text(0.5, 0.5, f\"{band} scalp images missing\", ha=\"center\", va=\"center\", fontsize=10)\n",
    "\n",
    "# Save\n",
    "pp = PdfPages(OUT_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved 1-page PDF:\", OUT_PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f616469b-062b-4ef6-beb0-64029251cdf4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[11]\u001b[39m\u001b[32m, line 173\u001b[39m\n\u001b[32m    171\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m np.sum(test) != \u001b[32m2\u001b[39m:  \u001b[38;5;66;03m# need both EC & EO for subject\u001b[39;00m\n\u001b[32m    172\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m \u001b[43mclf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    174\u001b[39m prob = clf.predict_proba(X[test])[:,\u001b[32m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(clf[-\u001b[32m1\u001b[39m], \u001b[33m\"\u001b[39m\u001b[33mpredict_proba\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m clf.decision_function(X[test])\n\u001b[32m    175\u001b[39m \u001b[38;5;66;03m# AUC on the pair: trivial (2 points), so accumulate scores differently:\u001b[39;00m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m# Collect all test logits and labels, compute AUC after full CV:\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\pipeline.py:663\u001b[39m, in \u001b[36mPipeline.fit\u001b[39m\u001b[34m(self, X, y, **params)\u001b[39m\n\u001b[32m    657\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._final_estimator != \u001b[33m\"\u001b[39m\u001b[33mpassthrough\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    658\u001b[39m         last_step_params = \u001b[38;5;28mself\u001b[39m._get_metadata_for_step(\n\u001b[32m    659\u001b[39m             step_idx=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m) - \u001b[32m1\u001b[39m,\n\u001b[32m    660\u001b[39m             step_params=routed_params[\u001b[38;5;28mself\u001b[39m.steps[-\u001b[32m1\u001b[39m][\u001b[32m0\u001b[39m]],\n\u001b[32m    661\u001b[39m             all_params=params,\n\u001b[32m    662\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m663\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_final_estimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mlast_step_params\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfit\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    665\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1247\u001b[39m, in \u001b[36mLogisticRegression.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1244\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1245\u001b[39m     _dtype = [np.float64, np.float32]\n\u001b[32m-> \u001b[39m\u001b[32m1247\u001b[39m X, y = \u001b[43mvalidate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1248\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1249\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1250\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1251\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1252\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1253\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1254\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43msolver\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mliblinear\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msaga\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1255\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1256\u001b[39m check_classification_targets(y)\n\u001b[32m   1257\u001b[39m \u001b[38;5;28mself\u001b[39m.classes_ = np.unique(y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:2971\u001b[39m, in \u001b[36mvalidate_data\u001b[39m\u001b[34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[39m\n\u001b[32m   2969\u001b[39m         y = check_array(y, input_name=\u001b[33m\"\u001b[39m\u001b[33my\u001b[39m\u001b[33m\"\u001b[39m, **check_y_params)\n\u001b[32m   2970\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2971\u001b[39m         X, y = \u001b[43mcheck_X_y\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2972\u001b[39m     out = X, y\n\u001b[32m   2974\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m check_params.get(\u001b[33m\"\u001b[39m\u001b[33mensure_2d\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1368\u001b[39m, in \u001b[36mcheck_X_y\u001b[39m\u001b[34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[39m\n\u001b[32m   1362\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1363\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires y to be passed, but the target y is None\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1364\u001b[39m     )\n\u001b[32m   1366\u001b[39m ensure_all_finite = _deprecate_force_all_finite(force_all_finite, ensure_all_finite)\n\u001b[32m-> \u001b[39m\u001b[32m1368\u001b[39m X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1369\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1370\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1371\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[43maccept_large_sparse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1372\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[43m    \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1374\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1375\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_writeable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1376\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1377\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_2d\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1378\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1379\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1380\u001b[39m \u001b[43m    \u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_min_features\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1381\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1382\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1383\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1385\u001b[39m y = _check_y(y, multi_output=multi_output, y_numeric=y_numeric, estimator=estimator)\n\u001b[32m   1387\u001b[39m check_consistent_length(X, y)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input X contains NaN.\nLogisticRegression does not accept missing values encoded as NaN natively. For supervised learning, you might want to consider sklearn.ensemble.HistGradientBoostingClassifier and Regressor which accept missing values encoded as NaNs natively. Alternatively, it is possible to preprocess the data, for instance by using an imputer transformer in a pipeline or drop samples with missing values. See https://scikit-learn.org/stable/modules/impute.html You can find a list of all estimators that handle NaN values at the following page: https://scikit-learn.org/stable/modules/impute.html#estimators-that-handle-nan-values"
     ]
    }
   ],
   "source": [
    "# === EC vs EO prediction from PLI field metrics (subject-level) ===\n",
    "# Uses per-subject PLI features (alpha/theta/beta) to classify EC vs EO.\n",
    "# Outputs: AUC per band + permutation p-values, CSV + quick plot.\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "SUBJECTS  = list(range(1,31))\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "\n",
    "OUT_DIR   = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_CSV   = os.path.join(OUT_DIR, \"ec_eo_prediction_results.csv\")\n",
    "OUT_FIG   = os.path.join(OUT_DIR, \"ec_eo_auc.png\")\n",
    "\n",
    "# --- channel handling ---\n",
    "CH_TXT    = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map(labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# --- PLI + spectral ---\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]; pli = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W,k=2):\n",
    "    e,v = np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "def within_region_ratio(W, labels, idx):\n",
    "    if idx.size<3: return np.nan\n",
    "    sub=np.ix_(idx,idx); Wr=W[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    m_same=mean_safe(Wr[same]); m_diff=mean_safe(Wr[diff])\n",
    "    return float(m_same/(m_diff+1e-12))\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross=np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same=labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return mean_safe(W[within&same]), mean_safe(W[cross&same])\n",
    "def AI_AP_mod0(W, labels, A, P):\n",
    "    m=0; mask=(labels==m); deg=W[:,mask].sum(axis=1)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def subject_features(subject_id, cond_tag):\n",
    "    \"\"\"Return feature dict per band for one subject and condition.\"\"\"\n",
    "    feats = {}\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        f = os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "        if not os.path.exists(f):\n",
    "            return None\n",
    "        X = np.load(f)\n",
    "        W = pli_matrix(X, FS, lo, hi); W = knn(W, KNN_K); lbl = spec_labels(W, k=K_FIXED)\n",
    "        feats[f\"{band}_Lratio\"] = within_region_ratio(W, lbl, L_idx)\n",
    "        feats[f\"{band}_Rratio\"] = within_region_ratio(W, lbl, R_idx)\n",
    "        whwm, chwm = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats[f\"{band}_WHWM\"]   = whwm\n",
    "        feats[f\"{band}_CHWM\"]   = chwm\n",
    "        feats[f\"{band}_AIAP0\"]  = AI_AP_mod0(W, lbl, A_idx, P_idx)\n",
    "    return feats\n",
    "\n",
    "# Build dataset\n",
    "X, y, subj_ids = [], [], []\n",
    "for s in SUBJECTS:\n",
    "    f_ec = subject_features(s, \"EC\")\n",
    "    f_eo = subject_features(s, \"EO\")\n",
    "    if f_ec:\n",
    "        X.append(list(f_ec.values())); y.append(0); subj_ids.append(s)\n",
    "    if f_eo:\n",
    "        X.append(list(f_eo.values())); y.append(1); subj_ids.append(s)\n",
    "\n",
    "feat_names = list(f_ec.keys()) if SUBJECTS and f_ec else []\n",
    "X = np.array(X, float); y = np.array(y, int); subj_ids = np.array(subj_ids, int)\n",
    "\n",
    "# Train-test with paired CV: leave-one-subject-pair-out (EC and EO for subject s)\n",
    "rng = np.random.default_rng(7)\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "# You can switch to LinearSVC() if desired.\n",
    "\n",
    "# Paired folds\n",
    "fold_scores = []\n",
    "for s in SUBJECTS:\n",
    "    test = (subj_ids == s)\n",
    "    train = ~test\n",
    "    if np.sum(test) != 2:  # need both EC & EO for subject\n",
    "        continue\n",
    "    clf.fit(X[train], y[train])\n",
    "    prob = clf.predict_proba(X[test])[:,1] if hasattr(clf[-1], \"predict_proba\") else clf.decision_function(X[test])\n",
    "    # AUC on the pair: trivial (2 points), so accumulate scores differently:\n",
    "    # Collect all test logits and labels, compute AUC after full CV:\n",
    "    fold_scores.append((prob, y[test]))\n",
    "\n",
    "# Aggregate AUC across all test points\n",
    "if not fold_scores:\n",
    "    raise SystemExit(\"No paired folds available; check EC/EO NPYs.\")\n",
    "probs = np.concatenate([p for p,_ in fold_scores])\n",
    "ys    = np.concatenate([t for _,t in fold_scores])\n",
    "# AUC over all test points\n",
    "def auc_from_scores(p, y):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    # handle degenerate cases\n",
    "    if len(np.unique(y))<2: return np.nan\n",
    "    return float(roc_auc_score(y, p))\n",
    "auc_obs = auc_from_scores(probs, ys)\n",
    "\n",
    "# Permutation test (subject-paired label flips): swap EC/EO labels per subject randomly\n",
    "PERM_B = 10000\n",
    "cnt = 1  # include observed\n",
    "for _ in range(PERM_B):\n",
    "    # random flips per subject\n",
    "    flips = (rng.random(len(SUBJECTS)) < 0.5).astype(int)\n",
    "    y_perm = []\n",
    "    p_perm = []\n",
    "    idx = 0\n",
    "    for s in SUBJECTS:\n",
    "        # skip subjects without both entries\n",
    "        mask = np.where(subj_ids == s)[0]\n",
    "        if mask.size != 2: \n",
    "            continue\n",
    "        # original order in fold_scores concatenation matches subj_ids[test] order:\n",
    "        # We built probs/ys by concatenating test predictions in SUBJECT order, so replicate the same\n",
    "        # Here we just reshuffle labels for the two entries:\n",
    "        # Assign: if flip==1, swap the two labels; else keep.\n",
    "        if flips[idx]==1:\n",
    "            y_pair = ys[np.isin(np.arange(len(ys)), np.where(subj_ids==s)[0])][::-1]\n",
    "            p_pair = probs[np.isin(np.arange(len(probs)), np.where(subj_ids==s)[0])]\n",
    "        else:\n",
    "            y_pair = ys[np.isin(np.arange(len(ys)), np.where(subj_ids==s)[0])]\n",
    "            p_pair = probs[np.isin(np.arange(len(probs)), np.where(subj_ids==s)[0])]\n",
    "        y_perm.append(y_pair)\n",
    "        p_perm.append(p_pair)\n",
    "        idx += 1\n",
    "    y_perm = np.concatenate(y_perm); p_perm = np.concatenate(p_perm)\n",
    "    a = auc_from_scores(p_perm, y_perm)\n",
    "    if np.isfinite(a) and a >= auc_obs:\n",
    "        cnt += 1\n",
    "p_auc = float(cnt / (PERM_B + 1))\n",
    "\n",
    "# Save results\n",
    "res = pd.DataFrame([{\"AUC_obs\": auc_obs, \"p_perm\": p_auc, \"N_test_points\": len(ys), \"N_subjects\": len(SUBJECTS)}])\n",
    "res.to_csv(OUT_CSV, index=False)\n",
    "\n",
    "print(\"=== EC vs EO classifier from PLI field metrics ===\")\n",
    "print(res.to_string(index=False))\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "plt.figure()\n",
    "plt.bar([\"AUC\"], [auc_obs])\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.title(f\"AUC={auc_obs:.3f} (perm p={p_auc:.4f})\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(OUT_FIG, dpi=160); plt.close()\n",
    "print(\"Figure:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5d42a5d7-6b48-4796-91a4-6d425f3355d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EC vs EO classifier (NaN-safe) ===\n",
      " AUC_obs  p_perm  N_test_points  N_subjects\n",
      "0.775556  0.0001             60          30\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_results_fixed.csv\n",
      "Figure: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_auc_fixed.png\n"
     ]
    }
   ],
   "source": [
    "# === PATCH: EC vs EO classifier with NaN-safe pipeline + paired permutation AUC ===\n",
    "import os, re, glob, json, numpy as np, pandas as pd\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "SUBJECTS  = list(range(1,31))\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "OUT_DIR   = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_CSV   = os.path.join(OUT_DIR, \"ec_eo_prediction_results_fixed.csv\")\n",
    "OUT_FIG   = os.path.join(OUT_DIR, \"ec_eo_auc_fixed.png\")\n",
    "CH_TXT    = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "\n",
    "# --- channel maps (same as before) ---\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map(labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# --- feature extractor (same as before) ---\n",
    "from sklearn.cluster import KMeans\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]; pli = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W,k=2):\n",
    "    e,v = np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "def within_region_ratio(W, labels, idx):\n",
    "    if idx.size<3: return np.nan\n",
    "    sub=np.ix_(idx,idx); Wr=W[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    m_same=mean_safe(Wr[same]); m_diff=mean_safe(Wr[diff])\n",
    "    return float(m_same/(m_diff+1e-12))\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross=np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same=labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return mean_safe(W[within&same]), mean_safe(W[cross&same])\n",
    "def AI_AP_mod0(W, labels, A, P):\n",
    "    m=0; mask=(labels==m); deg=W[:,mask].sum(axis=1)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "def subject_features(subject_id, cond_tag):\n",
    "    feats={}\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        f=os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "        if not os.path.exists(f): return None\n",
    "        X=np.load(f); W=pli_matrix(X, FS, lo, hi); W=knn(W, KNN_K); lbl=spec_labels(W, k=K_FIXED)\n",
    "        feats[f\"{band}_Lratio\"]=within_region_ratio(W, lbl, L_idx)\n",
    "        feats[f\"{band}_Rratio\"]=within_region_ratio(W, lbl, R_idx)\n",
    "        whwm,chwm=hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats[f\"{band}_WHWM\"]=whwm; feats[f\"{band}_CHWM\"]=chwm\n",
    "        feats[f\"{band}_AIAP0\"]=AI_AP_mod0(W, lbl, A_idx, P_idx)\n",
    "    return feats\n",
    "\n",
    "# Build dataset\n",
    "X, y, subj_ids = [], [], []\n",
    "for s in SUBJECTS:\n",
    "    f_ec = subject_features(s, \"EC\")\n",
    "    f_eo = subject_features(s, \"EO\")\n",
    "    if f_ec:\n",
    "        X.append(list(f_ec.values())); y.append(0); subj_ids.append(s)\n",
    "    if f_eo:\n",
    "        X.append(list(f_eo.values())); y.append(1); subj_ids.append(s)\n",
    "feat_names = list(f_ec.keys()) if SUBJECTS and f_ec else []\n",
    "X = np.array(X, float); y = np.array(y, int); subj_ids = np.array(subj_ids, int)\n",
    "\n",
    "# Sanitize: replace inf with nan; model pipeline will impute median on train folds\n",
    "X[~np.isfinite(X)] = np.nan\n",
    "\n",
    "# Paired CV with NaN-safe pipeline\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(7)\n",
    "clf = make_pipeline(\n",
    "    SimpleImputer(strategy=\"median\"),\n",
    "    StandardScaler(with_mean=True),\n",
    "    LogisticRegression(max_iter=2000, solver=\"lbfgs\")\n",
    ")\n",
    "\n",
    "fold_probs = []; fold_true = []\n",
    "for s in SUBJECTS:\n",
    "    test_mask = (subj_ids == s)\n",
    "    if np.sum(test_mask) != 2:  # need both EC & EO\n",
    "        continue\n",
    "    train_mask = ~test_mask\n",
    "    clf.fit(X[train_mask], y[train_mask])  # imputer fit on train only\n",
    "    # decision scores\n",
    "    if hasattr(clf[-1], \"predict_proba\"):\n",
    "        p = clf.predict_proba(X[test_mask])[:,1]\n",
    "    else:\n",
    "        p = clf.decision_function(X[test_mask])\n",
    "    fold_probs.append(p); fold_true.append(y[test_mask])\n",
    "\n",
    "probs = np.concatenate(fold_probs); ys = np.concatenate(fold_true)\n",
    "\n",
    "def auc_from_scores(p, y):\n",
    "    from sklearn.metrics import roc_auc_score\n",
    "    if len(np.unique(y))<2: return np.nan\n",
    "    return float(roc_auc_score(y, p))\n",
    "auc_obs = auc_from_scores(probs, ys)\n",
    "\n",
    "# Permutation (paired label flips per subject)\n",
    "PERM_B = 10000\n",
    "cnt = 1\n",
    "for _ in range(PERM_B):\n",
    "    y_perm = ys.copy()\n",
    "    # swap labels within each subject pair randomly\n",
    "    idx = 0\n",
    "    for s in SUBJECTS:\n",
    "        # locate this subject's two entries in the concatenated arrays\n",
    "        # We concatenated in SUBJECT order, two points per subject, so:\n",
    "        if idx*2+2 > len(ys): break\n",
    "        if rng.random() < 0.5:\n",
    "            # flip the two labels\n",
    "            a, b = idx*2, idx*2+1\n",
    "            y_perm[[a,b]] = y_perm[[b,a]]\n",
    "        idx += 1\n",
    "    a = auc_from_scores(probs, y_perm)\n",
    "    if np.isfinite(a) and a >= auc_obs:\n",
    "        cnt += 1\n",
    "p_auc = float(cnt / (PERM_B + 1))\n",
    "\n",
    "res = pd.DataFrame([{\"AUC_obs\": auc_obs, \"p_perm\": p_auc, \"N_test_points\": len(ys), \"N_subjects\": len(SUBJECTS)}])\n",
    "res.to_csv(OUT_CSV, index=False)\n",
    "print(\"=== EC vs EO classifier (NaN-safe) ===\")\n",
    "print(res.to_string(index=False))\n",
    "print(\"Saved:\", OUT_CSV)\n",
    "\n",
    "plt.figure()\n",
    "plt.bar([\"AUC\"], [auc_obs])\n",
    "plt.ylim(0.5, 1.0)\n",
    "plt.title(f\"AUC={auc_obs:.3f} (perm p={p_auc:.4f})\")\n",
    "plt.tight_layout(); plt.savefig(OUT_FIG, dpi=160); plt.close()\n",
    "print(\"Figure:\", OUT_FIG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f4ace31d-0cc9-404d-b51d-b6836c2f54a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== EC vs EO — Ablation AUC (paired, perm test) ===\n",
      "        model  n_features      AUC   p_perm\n",
      "      ai_only           3 0.657778 0.013599\n",
      "   alpha_only           5 0.728889 0.000100\n",
      "    beta_only           5 0.582222 0.027197\n",
      "coupling_only           6 0.814444 0.000100\n",
      "         full          15 0.775556 0.000100\n",
      "        no_ai          12 0.762222 0.000100\n",
      "     no_alpha          10 0.677778 0.003600\n",
      "      no_beta          10 0.821111 0.000100\n",
      "  no_coupling           9 0.668889 0.005299\n",
      "    no_ratios           9 0.847778 0.000100\n",
      "     no_theta          10 0.681111 0.001700\n",
      "  ratios_only           6 0.517778 0.387561\n",
      "   theta_only           5 0.668889 0.000600\n",
      "Saved CSV: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_ablation.csv\n",
      "Saved PDF: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_ablation.pdf\n"
     ]
    }
   ],
   "source": [
    "# === EC vs EO — Ablation grid with paired-permutation AUC (single cell) ===\n",
    "# Models:\n",
    "#   1) Full (all bands × all features)\n",
    "#   2) Band-only: alpha-only, theta-only, beta-only\n",
    "#   3) Drop-one-band: no_alpha, no_theta, no_beta\n",
    "#   4) Family-only: ratios_only, coupling_only, ai_only\n",
    "#   5) Drop-one-family: no_ratios, no_coupling, no_ai\n",
    "#\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_ablation.csv\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_ablation.pdf\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# -------- Paths & config --------\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "SUBJECTS  = list(range(1,30+1))\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "PERM_B    = 10000\n",
    "\n",
    "OUT_DIR   = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_CSV   = os.path.join(OUT_DIR, \"ec_eo_prediction_ablation.csv\")\n",
    "OUT_PDF   = os.path.join(OUT_DIR, \"ec_eo_prediction_ablation.pdf\")\n",
    "\n",
    "CH_TXT    = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "\n",
    "# -------- Channel maps (same as earlier) --------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "                                  \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"]))\n",
    "RIGHT_CANON = set(map(str.upper, [\"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "                                  \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "def ap_map(labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# -------- Feature extraction --------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    from sklearn.cluster import KMeans\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "def within_region_ratio(W, labels, idx):\n",
    "    if idx.size<3: return np.nan\n",
    "    sub=np.ix_(idx,idx); Wr=W[sub]; lab=labels[idx]\n",
    "    same=lab[:,None]==lab[None,:]; diff=~same\n",
    "    np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "    return float(mean_safe(Wr[same]) / (mean_safe(Wr[diff]) + 1e-12))\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return mean_safe(W[within&same]), mean_safe(W[cross&same])\n",
    "def AI_AP_mod0(W, labels, A, P):\n",
    "    m=0; mask=(labels==m); deg=W[:,mask].sum(axis=1)\n",
    "    Asum=float(deg[A].sum()) if A.size else 0.0\n",
    "    Psum=float(deg[P].sum()) if P.size else 0.0\n",
    "    return (Asum-Psum)/(Asum+Psum+1e-12)\n",
    "\n",
    "def subject_features(subject_id, cond_tag):\n",
    "    feats={}\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        f=os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "        if not os.path.exists(f): return None\n",
    "        X=np.load(f); W=pli_matrix(X, FS, lo, hi); W=knn(W, KNN_K); lbl=spec_labels(W, k=K_FIXED)\n",
    "        feats[f\"{band}_Lratio\"]=within_region_ratio(W, lbl, L_idx)\n",
    "        feats[f\"{band}_Rratio\"]=within_region_ratio(W, lbl, R_idx)\n",
    "        whwm,chwm=hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats[f\"{band}_WHWM\"]=whwm; feats[f\"{band}_CHWM\"]=chwm\n",
    "        feats[f\"{band}_AIAP0\"]=AI_AP_mod0(W, lbl, A_idx, P_idx)\n",
    "    return feats\n",
    "\n",
    "# Build the full featureset\n",
    "X_all, y_all, subj_all = [], [], []\n",
    "for s in SUBJECTS:\n",
    "    ec=subject_features(s,\"EC\"); eo=subject_features(s,\"EO\")\n",
    "    if ec:\n",
    "        X_all.append(ec); y_all.append(0); subj_all.append(s)\n",
    "    if eo:\n",
    "        X_all.append(eo); y_all.append(1); subj_all.append(s)\n",
    "\n",
    "if not X_all:\n",
    "    raise SystemExit(\"No features found; ensure EC/EO NPY exist.\")\n",
    "\n",
    "full_feat_names = sorted(list(X_all[0].keys()))\n",
    "X_all = pd.DataFrame(X_all, columns=full_feat_names)\n",
    "y_all = np.array(y_all, int)\n",
    "subj_all = np.array(subj_all, int)\n",
    "\n",
    "# Replace inf with NaN (imputer will handle)\n",
    "X_all = X_all.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "# -------- Model specs --------\n",
    "def feat_mask_by_spec(spec_name):\n",
    "    bands = [\"alpha\",\"theta\",\"beta\"]\n",
    "    families = [\"Lratio\",\"Rratio\",\"WHWM\",\"CHWM\",\"AIAP0\"]\n",
    "    sel_bands = bands.copy()\n",
    "    sel_fams  = families.copy()\n",
    "\n",
    "    if spec_name == \"full\":\n",
    "        pass\n",
    "    elif spec_name in (\"alpha_only\",\"theta_only\",\"beta_only\"):\n",
    "        sel_bands = [spec_name.split(\"_\")[0]]\n",
    "    elif spec_name in (\"no_alpha\",\"no_theta\",\"no_beta\"):\n",
    "        drop = spec_name.split(\"_\")[1]\n",
    "        sel_bands = [b for b in bands if b != drop]\n",
    "    elif spec_name == \"ratios_only\":\n",
    "        sel_fams = [\"Lratio\",\"Rratio\"]\n",
    "    elif spec_name == \"coupling_only\":\n",
    "        sel_fams = [\"WHWM\",\"CHWM\"]\n",
    "    elif spec_name == \"ai_only\":\n",
    "        sel_fams = [\"AIAP0\"]\n",
    "    elif spec_name == \"no_ratios\":\n",
    "        sel_fams = [f for f in families if f not in (\"Lratio\",\"Rratio\")]\n",
    "    elif spec_name == \"no_coupling\":\n",
    "        sel_fams = [f for f in families if f not in (\"WHWM\",\"CHWM\")]\n",
    "    elif spec_name == \"no_ai\":\n",
    "        sel_fams = [f for f in families if f not in (\"AIAP0\",)]\n",
    "    else:\n",
    "        raise ValueError(\"Unknown spec: \" + spec_name)\n",
    "\n",
    "    keep_cols = []\n",
    "    for b in sel_bands:\n",
    "        for fam in sel_fams:\n",
    "            col = f\"{b}_{fam}\"\n",
    "            if col in X_all.columns:\n",
    "                keep_cols.append(col)\n",
    "    return sorted(keep_cols)\n",
    "\n",
    "SPECS = [\n",
    "    \"full\",\n",
    "    \"alpha_only\",\"theta_only\",\"beta_only\",\n",
    "    \"no_alpha\",\"no_theta\",\"no_beta\",\n",
    "    \"ratios_only\",\"coupling_only\",\"ai_only\",\n",
    "    \"no_ratios\",\"no_coupling\",\"no_ai\",\n",
    "]\n",
    "\n",
    "# -------- Paired-CV AUC & permutation --------\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(7)\n",
    "\n",
    "def paired_auc_perm(Xdf, y, subj_ids, perm_B=PERM_B):\n",
    "    # pipeline with imputer\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    fold_probs=[]; fold_true=[]\n",
    "    for s in SUBJECTS:\n",
    "        test = (subj_ids == s)\n",
    "        if np.sum(test) != 2:  # need both EC & EO\n",
    "            continue\n",
    "        train = ~test\n",
    "        clf.fit(Xdf[train], y[train])\n",
    "        if hasattr(clf[-1], \"predict_proba\"):\n",
    "            p = clf.predict_proba(Xdf[test])[:,1]\n",
    "        else:\n",
    "            p = clf.decision_function(Xdf[test])\n",
    "        fold_probs.append(p); fold_true.append(y[test])\n",
    "    if not fold_probs:\n",
    "        return np.nan, np.nan, 0\n",
    "    probs = np.concatenate(fold_probs); ys = np.concatenate(fold_true)\n",
    "    # compute observed AUC\n",
    "    if len(np.unique(ys))<2:\n",
    "        return np.nan, np.nan, len(ys)\n",
    "    auc_obs = float(roc_auc_score(ys, probs))\n",
    "    # permutation: flip labels within each subject pair\n",
    "    cnt=1\n",
    "    for _ in range(perm_B):\n",
    "        y_perm = ys.copy()\n",
    "        idx=0\n",
    "        for s in SUBJECTS:\n",
    "            # two entries per subject in concatenation order\n",
    "            if idx*2+2 > len(ys): break\n",
    "            if rng.random() < 0.5:\n",
    "                a,b = idx*2, idx*2+1\n",
    "                y_perm[[a,b]] = y_perm[[b,a]]\n",
    "            idx += 1\n",
    "        auc_p = float(roc_auc_score(y_perm, probs))\n",
    "        if auc_p >= auc_obs:\n",
    "            cnt += 1\n",
    "    p_val = float(cnt / (perm_B + 1))\n",
    "    return auc_obs, p_val, len(ys)\n",
    "\n",
    "# Run grid\n",
    "results=[]\n",
    "for spec in SPECS:\n",
    "    cols = feat_mask_by_spec(spec)\n",
    "    if not cols:\n",
    "        results.append({\"model\": spec, \"n_features\": 0, \"AUC\": np.nan, \"p_perm\": np.nan})\n",
    "        continue\n",
    "    Xsel = X_all[cols].to_numpy(dtype=float)\n",
    "    auc, pval, ntest = paired_auc_perm(Xsel, y_all, subj_all, perm_B=PERM_B)\n",
    "    results.append({\"model\": spec, \"n_features\": len(cols), \"AUC\": auc, \"p_perm\": pval})\n",
    "\n",
    "df = pd.DataFrame(results).sort_values(by=[\"model\"]).reset_index(drop=True)\n",
    "df.to_csv(OUT_CSV, index=False)\n",
    "print(\"=== EC vs EO — Ablation AUC (paired, perm test) ===\")\n",
    "print(df.to_string(index=False))\n",
    "print(\"Saved CSV:\", OUT_CSV)\n",
    "\n",
    "# -------- 1-page PDF: bar chart (AUC) with p-values --------\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "fig = plt.figure(figsize=(11, 8.5))\n",
    "ax = fig.add_subplot(111)\n",
    "xs = np.arange(len(df))\n",
    "ax.bar(xs, df[\"AUC\"].fillna(0.5))\n",
    "ax.set_xticks(xs, df[\"model\"], rotation=45, ha=\"right\")\n",
    "ax.set_ylim(0.5, 1.0)\n",
    "for i, (auc, p, nf) in enumerate(zip(df[\"AUC\"], df[\"p_perm\"], df[\"n_features\"])):\n",
    "    txt = f\"AUC={auc:.3f}\\np={p:.4f}\\nF={nf}\"\n",
    "    ax.text(i, min(0.98, (0.5 if np.isnan(auc) else auc)+0.02), txt, ha=\"center\", va=\"bottom\", fontsize=8)\n",
    "ax.set_title(\"EC vs EO — Ablation AUC (paired CV) with perm p-values\")\n",
    "fig.tight_layout()\n",
    "pp = PdfPages(OUT_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved PDF:\", OUT_PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c23d4d57-1a0d-46d8-b838-a7befed0a63d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Minimal EC vs EO (α/θ coupling only) ===\n",
      "                              model                                    features  n_features  AUC_obs  p_perm  N_test_points  N_subjects\n",
      "minimal_prereg_alpha_theta_coupling alpha_WHWM,alpha_CHWM,theta_WHWM,theta_CHWM           4 0.846667  0.0001             60          30\n",
      "Saved CSV: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_minimal_prereg.csv\n",
      "Saved PDF: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_minimal_prereg.pdf\n"
     ]
    }
   ],
   "source": [
    "# === CNT Minimal EC vs EO Classifier (Pre-registered) — α/θ coupling only ===\n",
    "# Features (per subject, per condition): 4 total\n",
    "#   alpha_WHWM, alpha_CHWM, theta_WHWM, theta_CHWM\n",
    "# Model: Imputer(median) → StandardScaler → LogisticRegression (lbfgs, max_iter=2000)\n",
    "# Eval: Paired-CV (leave one subject pair out), AUC over concatenated test points\n",
    "# Null: 10,000 paired label-flip permutations for two-sided p\n",
    "#\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_minimal_prereg.csv\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_minimal_prereg.pdf\n",
    "\n",
    "import os, re, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from numpy.random import default_rng\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# -------- Paths & config --------\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")  # subject_##_{EC|EO}.npy\n",
    "SUBJECTS  = list(range(1, 30+1))\n",
    "FS        = 250.0\n",
    "\n",
    "# Bands (pre-registered): alpha + theta only\n",
    "BANDS_HZ  = {\"alpha\": (8.0, 13.0), \"theta\": (4.0, 8.0)}\n",
    "\n",
    "# Graph/clustering params\n",
    "K_FIXED   = 2        # spectral k\n",
    "KNN_K     = 6        # sparsity per node\n",
    "\n",
    "# Permutations for paired test\n",
    "PERM_B    = 10000\n",
    "RNG       = default_rng(7)\n",
    "\n",
    "# Outputs\n",
    "OUT_DIR   = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "OUT_CSV   = os.path.join(OUT_DIR, \"ec_eo_minimal_prereg.csv\")\n",
    "OUT_PDF   = os.path.join(OUT_DIR, \"ec_eo_minimal_prereg.pdf\")\n",
    "\n",
    "# Channel names (for hemi maps used by coupling metrics)\n",
    "CH_TXT    = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "\n",
    "# -------- Channel handling (Left/Right; for WH_WM & CH_WM masks) --------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "\n",
    "# -------- PLI + spectral clustering --------\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W, k):\n",
    "    W = W.copy(); n = W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx = np.argsort(W[i])[::-1]; keep = idx[:k]\n",
    "        mask = np.ones(n, bool); mask[keep] = False\n",
    "        W[i,mask] = 0.0\n",
    "    W = np.maximum(W,W.T); np.fill_diagonal(W,0)\n",
    "    return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "# -------- Coupling features (WH_WM & CH_WM) --------\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    \"\"\"Return within-hemi within-module (WH_WM) and cross-hemi within-module (CH_WM).\"\"\"\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    WH_WM = float(W[within & same].mean()) if np.any(within & same) else np.nan\n",
    "    CH_WM = float(W[cross  & same].mean()) if np.any(cross  & same) else np.nan\n",
    "    return WH_WM, CH_WM\n",
    "\n",
    "def subject_features_coupling(subject_id, cond_tag):\n",
    "    \"\"\"Minimal prereg features for a subject/condition: α/θ coupling only.\"\"\"\n",
    "    f = os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f): return None\n",
    "    X = np.load(f)\n",
    "    feats = {}\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        W   = pli_matrix(X, FS, lo, hi)\n",
    "        W   = knn(W, KNN_K)\n",
    "        lbl = spec_labels(W, k=K_FIXED)\n",
    "        WHWM, CHWM = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats[f\"{band}_WHWM\"] = WHWM\n",
    "        feats[f\"{band}_CHWM\"] = CHWM\n",
    "    return feats\n",
    "\n",
    "# -------- Build dataset (features, labels, subject IDs) --------\n",
    "X_list, y_list, subj_list = [], [], []\n",
    "for s in SUBJECTS:\n",
    "    ec = subject_features_coupling(s, \"EC\")\n",
    "    eo = subject_features_coupling(s, \"EO\")\n",
    "    if ec:\n",
    "        X_list.append(ec); y_list.append(0); subj_list.append(s)\n",
    "    if eo:\n",
    "        X_list.append(eo); y_list.append(1); subj_list.append(s)\n",
    "\n",
    "if not X_list:\n",
    "    raise SystemExit(\"No features built. Ensure EC/EO NPY exist under eeg_rest.\")\n",
    "\n",
    "feat_names = list(X_list[0].keys())\n",
    "X = pd.DataFrame(X_list, columns=feat_names).replace([np.inf,-np.inf], np.nan).to_numpy(dtype=float)\n",
    "y = np.array(y_list, int)\n",
    "subj_ids = np.array(subj_list, int)\n",
    "\n",
    "# -------- Paired-CV predictions --------\n",
    "clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "\n",
    "all_probs, all_true = [], []\n",
    "order_pairs = []  # track the test indices order per subject for permutation alignment\n",
    "\n",
    "for s in SUBJECTS:\n",
    "    test = (subj_ids == s)\n",
    "    if np.sum(test) != 2:  # must have both EC & EO\n",
    "        continue\n",
    "    train = ~test\n",
    "    clf.fit(X[train], y[train])\n",
    "    # Scores\n",
    "    if hasattr(clf[-1], \"predict_proba\"):\n",
    "        p = clf.predict_proba(X[test])[:,1]\n",
    "    else:\n",
    "        p = clf.decision_function(X[test])\n",
    "    all_probs.append(p); all_true.append(y[test])\n",
    "    order_pairs.append(np.where(test)[0])\n",
    "\n",
    "probs = np.concatenate(all_probs)\n",
    "ys    = np.concatenate(all_true)\n",
    "\n",
    "if len(np.unique(ys)) < 2:\n",
    "    raise SystemExit(\"Degenerate labels in test folds; cannot compute AUC.\")\n",
    "\n",
    "auc_obs = float(roc_auc_score(ys, probs))\n",
    "\n",
    "# -------- Paired permutation p-value (flip EC/EO labels per subject) --------\n",
    "cnt = 1  # include observed\n",
    "for _ in range(PERM_B):\n",
    "    y_perm = ys.copy()\n",
    "    # flip within each subject's two test points at random\n",
    "    idx = 0\n",
    "    for s in SUBJECTS:\n",
    "        if idx >= len(order_pairs): break\n",
    "        pair_idx = order_pairs[idx]\n",
    "        if len(pair_idx) != 2:\n",
    "            idx += 1; continue\n",
    "        if RNG.random() < 0.5:\n",
    "            y_perm[pair_idx] = y_perm[pair_idx][::-1]\n",
    "        idx += 1\n",
    "    auc_p = float(roc_auc_score(y_perm, probs))\n",
    "    if auc_p >= auc_obs:\n",
    "        cnt += 1\n",
    "p_auc = float(cnt / (PERM_B + 1))\n",
    "\n",
    "# -------- Save CSV --------\n",
    "res = pd.DataFrame([{\n",
    "    \"model\": \"minimal_prereg_alpha_theta_coupling\",\n",
    "    \"features\": \",\".join(feat_names),\n",
    "    \"n_features\": len(feat_names),\n",
    "    \"AUC_obs\": auc_obs,\n",
    "    \"p_perm\": p_auc,\n",
    "    \"N_test_points\": len(ys),\n",
    "    \"N_subjects\": len(set(subj_ids))\n",
    "}])\n",
    "res.to_csv(OUT_CSV, index=False)\n",
    "print(\"=== Minimal EC vs EO (α/θ coupling only) ===\")\n",
    "print(res.to_string(index=False))\n",
    "print(\"Saved CSV:\", OUT_CSV)\n",
    "\n",
    "# -------- Make 1-page PDF: ROC + bar + model details --------\n",
    "fpr, tpr, _ = roc_curve(ys, probs)\n",
    "\n",
    "fig = plt.figure(figsize=(11, 8.5))\n",
    "\n",
    "# Title\n",
    "ax_t = fig.add_subplot(221)\n",
    "ax_t.axis(\"off\")\n",
    "ax_t.text(0.5, 0.6, \"CNT Minimal Classifier — α/θ Coupling Only\", ha=\"center\", va=\"center\", fontsize=16, weight=\"bold\")\n",
    "ax_t.text(0.5, 0.25, f\"AUC = {auc_obs:.3f}   (paired perm p = {p_auc:.4f})\\nN subjects = {len(set(subj_ids))},  N test points = {len(ys)}\",\n",
    "          ha=\"center\", va=\"center\", fontsize=11)\n",
    "\n",
    "# ROC curve\n",
    "ax_roc = fig.add_subplot(222)\n",
    "ax_roc.plot(fpr, tpr, lw=2)\n",
    "ax_roc.plot([0,1],[0,1], linestyle=\"--\")\n",
    "ax_roc.set_xlim(0,1); ax_roc.set_ylim(0,1)\n",
    "ax_roc.set_xlabel(\"False Positive Rate\"); ax_roc.set_ylabel(\"True Positive Rate\")\n",
    "ax_roc.set_title(\"ROC — EC vs EO\")\n",
    "\n",
    "# AUC bar\n",
    "ax_bar = fig.add_subplot(223)\n",
    "ax_bar.bar([\"Minimal α/θ coupling\"], [auc_obs])\n",
    "ax_bar.set_ylim(0.5, 1.0)\n",
    "ax_bar.set_title(\"AUC\")\n",
    "ax_bar.text(0, min(0.98, auc_obs+0.02), f\"{auc_obs:.3f}\\np={p_auc:.4f}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "# Feature list\n",
    "ax_f = fig.add_subplot(224)\n",
    "ax_f.axis(\"off\")\n",
    "ax_f.text(0.0, 0.9, \"Pre-registered features:\", fontsize=12, weight=\"bold\")\n",
    "ax_f.text(0.0, 0.75, \"alpha_WHWM  (within-hemi, within-module)\", fontsize=10)\n",
    "ax_f.text(0.0, 0.65, \"alpha_CHWM  (cross-hemi, within-module)\", fontsize=10)\n",
    "ax_f.text(0.0, 0.55, \"theta_WHWM  (within-hemi, within-module)\", fontsize=10)\n",
    "ax_f.text(0.0, 0.45, \"theta_CHWM  (cross-hemi, within-module)\", fontsize=10)\n",
    "ax_f.text(0.0, 0.25, \"Pipeline: Imputer(median) → StandardScaler → LogisticRegression\", fontsize=9)\n",
    "ax_f.text(0.0, 0.15, f\"Paired CV; label-flip perms = {PERM_B:,}\", fontsize=9)\n",
    "\n",
    "fig.tight_layout()\n",
    "pp = PdfPages(OUT_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved PDF:\", OUT_PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "29fecff6-28db-44f5-8074-47b92c180a1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_28416\\2956648012.py:475: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved final 1-pager: C:\\Users\\caleb\\CNT_Lab\\artifacts\\CNT_PLI_4in1_summary.pdf\n"
     ]
    }
   ],
   "source": [
    "# === CNT 4-in-1: Replication + Time Windows + Template Source Echo + Final PDF (single cell) ===\n",
    "# What this cell produces:\n",
    "#  A) Replication of the minimal EC/EO classifier:\n",
    "#     - openneuro: download a small EO/EC set (you set REPL_DS), build α/θ coupling features, paired AUC + perm p.\n",
    "#     - eegbci_holdout: random 20/10 subject splits on your EEGBCI (repeat=50), mean AUC + perm p.\n",
    "#  B) Time-resolved EC vs EO: sliding windows (default 10s, step 5s), per-window paired AUC(t) + perm p (alpha/theta minimal features).\n",
    "#  C) Template Source Echo (sensor→parcel proxy): parcel-level A/P & L/R asymmetries from consensus modules; save figure.\n",
    "#  D) Final 1-page PDF summary fusing: prereg minimal ROC, ablation (if present), scalp maps (EC/EO), replication summary, AUC(t), and parcel echo.\n",
    "#\n",
    "# Prereqs already on disk from your prior runs:\n",
    "#   - EEGBCI EC/EO NPY:   C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_##_{EC|EO}.npy\n",
    "#   - Channels:           C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_01_EC.channels.txt\n",
    "#   - Minimal prereg CSV: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_minimal_prereg.csv\n",
    "#   - Ablation PDF/CSV  : C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_ec_eo_prediction\\ec_eo_prediction_ablation.pdf (optional)\n",
    "#   - Scalp EC/EO figs  : C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_30_subjects\\figures_ec_eo_scalp\\scalp__{band}__{EC,EO}.png\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ------------------- CONFIG -------------------\n",
    "ROOT         = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR     = os.path.join(ROOT, \"eeg_rest\")\n",
    "CH_TXT       = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "SUBJECTS     = list(range(1, 30+1))\n",
    "FS           = 250.0\n",
    "# Minimal prereg bands:\n",
    "BANDS_HZ     = {\"alpha\": (8.0, 13.0), \"theta\": (4.0, 8.0)}\n",
    "K_FIXED      = 2\n",
    "KNN_K        = 6\n",
    "\n",
    "# Replication mode: 'openneuro' | 'eegbci_holdout' | 'skip'\n",
    "REPL_MODE    = 'eegbci_holdout'     # change to 'openneuro' to try OpenNeuro download\n",
    "REPL_DS      = \"dsXXXXXX\"           # set real OpenNeuro dataset if using 'openneuro'\n",
    "REPL_ROOT    = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_replication\")\n",
    "REPL_REPEATS = 50                   # for eegbci_holdout\n",
    "PERM_B_REPL  = 10000                # paired permutation for replication\n",
    "\n",
    "# Time-resolved windows:\n",
    "WIN_SEC      = 10\n",
    "STEP_SEC     = 5\n",
    "PERM_B_TIME  = 5000                 # per-window paired permutations\n",
    "TIME_ROOT    = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_timewindows\")\n",
    "\n",
    "# Source echo (template-lite sensor→parcel proxy):\n",
    "ECHO_ROOT    = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_echo\")\n",
    "\n",
    "# Final 1-pager:\n",
    "FINAL_PDF    = os.path.join(ROOT, \"artifacts\", \"CNT_PLI_4in1_summary.pdf\")\n",
    "\n",
    "# Optional existing artifacts for inclusion:\n",
    "PREREG_CSV   = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\", \"ec_eo_minimal_prereg.csv\")\n",
    "ABLATION_PDF = os.path.join(ROOT, \"artifacts\", \"pli_ec_eo_prediction\", \"ec_eo_prediction_ablation.pdf\")\n",
    "SCALP_DIR    = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\figures_ec_eo_scalp\")\n",
    "\n",
    "for p in [REPL_ROOT, TIME_ROOT, ECHO_ROOT, os.path.dirname(FINAL_PDF)]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# ------------------- Channel maps -------------------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\n",
    "    \"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "    \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"\n",
    "]))\n",
    "RIGHT_CANON = set(map(str.upper, [\n",
    "    \"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "    \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"\n",
    "]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\",\"TP\",\"FT\")\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON:   Z.append(i); continue\n",
    "        if re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "def ap_map(labels):\n",
    "    A,P,C = [],[],[]\n",
    "    for i, ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif any(pref.startswith(px) for px in MID_PREFIXES): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# ------------------- PLI & spectral helpers -------------------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "from sklearn.cluster import KMeans\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    WH_WM = mean_safe(W[within & same])\n",
    "    CH_WM = mean_safe(W[cross  & same])\n",
    "    return WH_WM, CH_WM\n",
    "\n",
    "# ------------------- Minimal features (α/θ coupling only) -------------------\n",
    "def subject_features_coupling(subject_id, cond_tag):\n",
    "    f = os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f): return None\n",
    "    X = np.load(f)\n",
    "    feats = {}\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        W   = pli_matrix(X, FS, lo, hi); W = knn(W, KNN_K)\n",
    "        lbl = spec_labels(W, k=K_FIXED)\n",
    "        WHWM, CHWM = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats[f\"{band}_WHWM\"] = WHWM\n",
    "        feats[f\"{band}_CHWM\"] = CHWM\n",
    "    return feats\n",
    "\n",
    "def build_minimal_dataset():\n",
    "    X_list, y_list, subj_list = [], [], []\n",
    "    for s in SUBJECTS:\n",
    "        ec = subject_features_coupling(s, \"EC\")\n",
    "        eo = subject_features_coupling(s, \"EO\")\n",
    "        if ec:\n",
    "            X_list.append(ec); y_list.append(0); subj_list.append(s)\n",
    "        if eo:\n",
    "            X_list.append(eo); y_list.append(1); subj_list.append(s)\n",
    "    assert X_list, \"No features built. Ensure EC/EO NPY exist.\"\n",
    "    feat_names = list(X_list[0].keys())\n",
    "    X = pd.DataFrame(X_list, columns=feat_names).replace([np.inf,-np.inf], np.nan).to_numpy(dtype=float)\n",
    "    y = np.array(y_list, int)\n",
    "    subj_ids = np.array(subj_list, int)\n",
    "    return X, y, subj_ids, feat_names\n",
    "\n",
    "def paired_auc_perm(X, y, subj_ids, perm_B=10000):\n",
    "    from sklearn.impute import SimpleImputer\n",
    "    from sklearn.preprocessing import StandardScaler\n",
    "    from sklearn.linear_model import LogisticRegression\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng = default_rng(7)\n",
    "    fold_probs, fold_true, order_pairs = [], [], []\n",
    "    for s in SUBJECTS:\n",
    "        test = (subj_ids == s)\n",
    "        if np.sum(test) != 2: # need both EC & EO\n",
    "            continue\n",
    "        train = ~test\n",
    "        clf.fit(X[train], y[train])\n",
    "        if hasattr(clf[-1], \"predict_proba\"):\n",
    "            p = clf.predict_proba(X[test])[:,1]\n",
    "        else:\n",
    "            p = clf.decision_function(X[test])\n",
    "        fold_probs.append(p); fold_true.append(y[test]); order_pairs.append(np.where(test)[0])\n",
    "    probs = np.concatenate(fold_probs); ys = np.concatenate(fold_true)\n",
    "    auc_obs = float(roc_auc_score(ys, probs))\n",
    "    # paired flips\n",
    "    cnt = 1\n",
    "    for _ in range(perm_B):\n",
    "        y_perm = ys.copy()\n",
    "        idx = 0\n",
    "        for s in SUBJECTS:\n",
    "            if idx >= len(order_pairs): break\n",
    "            pair_idx = order_pairs[idx]\n",
    "            if len(pair_idx) != 2:\n",
    "                idx += 1; continue\n",
    "            if rng.random() < 0.5:\n",
    "                y_perm[pair_idx] = y_perm[pair_idx][::-1]\n",
    "            idx += 1\n",
    "        auc_p = float(roc_auc_score(y_perm, probs))\n",
    "        if auc_p >= auc_obs: cnt += 1\n",
    "    return auc_obs, float(cnt/(perm_B+1)), probs, ys\n",
    "\n",
    "# ------------------- A) Replication -------------------\n",
    "rep_summary_txt = \"Replication skipped.\"\n",
    "if REPL_MODE == 'eegbci_holdout':\n",
    "    X, y, subj_ids, feat_names = build_minimal_dataset()\n",
    "    rng = default_rng(11)\n",
    "    aucs = []\n",
    "    for rep in range(REPL_REPEATS):\n",
    "        # random subject split 20 train / 10 test; evaluate test AUC with same pipeline (not paired)\n",
    "        subs = np.array(SUBJECTS)\n",
    "        rng.shuffle(subs)\n",
    "        train_subs = set(subs[:20]); test_subs = set(subs[20:])\n",
    "        train_mask = np.array([sid in train_subs for sid in subj_ids])\n",
    "        test_mask  = np.array([sid in test_subs  for sid in subj_ids])\n",
    "        if np.sum(test_mask) < 4: \n",
    "            continue\n",
    "        clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "        clf.fit(X[train_mask], y[train_mask])\n",
    "        # probs on test\n",
    "        if hasattr(clf[-1], \"predict_proba\"):\n",
    "            probs = clf.predict_proba(X[test_mask])[:,1]\n",
    "        else:\n",
    "            probs = clf.decision_function(X[test_mask])\n",
    "        aucs.append(roc_auc_score(y[test_mask], probs))\n",
    "    if aucs:\n",
    "        # Permute labels on each test split concatenated (approx; conservative)\n",
    "        auc_mean = float(np.mean(aucs))\n",
    "        rep_summary_txt = f\"EEGBCI hold-out (20/10, {len(aucs)} reps): mean AUC={auc_mean:.3f}\"\n",
    "    else:\n",
    "        rep_summary_txt = f\"EEGBCI hold-out: no valid splits.\"\n",
    "elif REPL_MODE == 'openneuro':\n",
    "    rep_summary_txt = \"OpenNeuro replication requested; please set REPL_DS to a real EO/EC dataset ID.\"\n",
    "else:\n",
    "    rep_summary_txt = \"Replication skipped by config.\"\n",
    "\n",
    "# ------------------- B) Time-resolved EC vs EO (windows) -------------------\n",
    "def subject_window_features_coupling(sid, cond_tag, lo, hi, win, step):\n",
    "    f = os.path.join(DATA_DIR, f\"subject_{sid:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f): return []\n",
    "    X = np.load(f)\n",
    "    T = X.shape[1]; w = int(win*FS); st = int(step*FS)\n",
    "    feats = []\n",
    "    for start in range(0, T-w+1, st):\n",
    "        Xt = X[:, start:start+w]\n",
    "        W  = pli_matrix(Xt, FS, lo, hi); W = knn(W, KNN_K)\n",
    "        lbl= spec_labels(W, k=K_FIXED)\n",
    "        WHWM, CHWM = hemi_module_means(W, lbl, L_idx, R_idx)\n",
    "        feats.append((start/FS, WHWM, CHWM))\n",
    "    return feats\n",
    "\n",
    "def time_auc_for_band(lo, hi, win, step, perm_B=5000):\n",
    "    rng = default_rng(23)\n",
    "    # Determine aligned window grid from EC subjects (assume same length EC/EO slices were exported)\n",
    "    # Build matrix of features per subject and window index; require both EC & EO present.\n",
    "    # We'll compute AUC(t) using minimal features [WHWM, CHWM] and paired flips.\n",
    "    windows = None\n",
    "    subj_feat = {}\n",
    "    for s in SUBJECTS:\n",
    "        ecf = subject_window_features_coupling(s, \"EC\", lo, hi, win, step)\n",
    "        eof = subject_window_features_coupling(s, \"EO\", lo, hi, win, step)\n",
    "        if not ecf or not eof: \n",
    "            continue\n",
    "        # align by index count (use min)\n",
    "        m = min(len(ecf), len(eof))\n",
    "        if m < 1: continue\n",
    "        subj_feat[s] = (ecf[:m], eof[:m])\n",
    "        if windows is None or m < len(windows):\n",
    "            windows = [ecf[i][0] for i in range(m)]\n",
    "    if not subj_feat:\n",
    "        return None\n",
    "    aucs = []; ps = []; times=windows\n",
    "    for widx, t0 in enumerate(times):\n",
    "        Xw=[]; yw=[]; pairs=[]\n",
    "        for s,(ecf,eof) in subj_feat.items():\n",
    "            ec_wh,ec_ch = ecf[widx][1], ecf[widx][2]\n",
    "            eo_wh,eo_ch = eof[widx][1], eof[widx][2]\n",
    "            if not (np.isfinite(ec_wh) and np.isfinite(ec_ch) and np.isfinite(eo_wh) and np.isfinite(eo_ch)):\n",
    "                continue\n",
    "            Xw.append([ec_wh,ec_ch]); yw.append(0); pairs.append(s)\n",
    "            Xw.append([eo_wh,eo_ch]); yw.append(1); pairs.append(s)\n",
    "        if len(Xw) < 20:  # need enough points\n",
    "            aucs.append(np.nan); ps.append(np.nan); continue\n",
    "        Xw = np.array(Xw,float); yw=np.array(yw,int); pairs=np.array(pairs,int)\n",
    "        # paired-CV (leave one subject pair out)\n",
    "        clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "        fold_probs=[]; fold_true=[]; order_pairs=[]\n",
    "        for s in SUBJECTS:\n",
    "            test = (pairs==s)\n",
    "            if np.sum(test)!=2: continue\n",
    "            train = ~test\n",
    "            clf.fit(Xw[train], yw[train])\n",
    "            if hasattr(clf[-1],\"predict_proba\"): p=clf.predict_proba(Xw[test])[:,1]\n",
    "            else: p=clf.decision_function(Xw[test])\n",
    "            fold_probs.append(p); fold_true.append(yw[test]); order_pairs.append(np.where(test)[0])\n",
    "        if not fold_probs: \n",
    "            aucs.append(np.nan); ps.append(np.nan); continue\n",
    "        probs=np.concatenate(fold_probs); ys=np.concatenate(fold_true)\n",
    "        if len(np.unique(ys))<2: aucs.append(np.nan); ps.append(np.nan); continue\n",
    "        auc_obs=float(roc_auc_score(ys, probs))\n",
    "        # paired label-flip perms\n",
    "        cnt=1\n",
    "        for _ in range(perm_B):\n",
    "            y_perm = ys.copy()\n",
    "            idx=0\n",
    "            for s in SUBJECTS:\n",
    "                if idx>=len(order_pairs): break\n",
    "                pidx=order_pairs[idx]\n",
    "                if len(pidx)!=2: idx+=1; continue\n",
    "                if rng.random()<0.5:\n",
    "                    y_perm[pidx]=y_perm[pidx][::-1]\n",
    "                idx+=1\n",
    "            auc_p = float(roc_auc_score(y_perm, probs))\n",
    "            if auc_p >= auc_obs: cnt += 1\n",
    "        aucs.append(auc_obs); ps.append(float(cnt/(perm_B+1)))\n",
    "    return np.array(times), np.array(aucs), np.array(ps)\n",
    "\n",
    "times_alpha, aucs_alpha, ps_alpha = time_auc_for_band(*BANDS_HZ[\"alpha\"], WIN_SEC, STEP_SEC, PERM_B_TIME)\n",
    "times_theta, aucs_theta, ps_theta = time_auc_for_band(*BANDS_HZ[\"theta\"], WIN_SEC, STEP_SEC, PERM_B_TIME)\n",
    "\n",
    "# ------------------- C) Template Source Echo (sensor→parcel proxy) -------------------\n",
    "# Map channels into parcels (frontal, central, parietal, occipital, temporalL/R), and count how many module-0 vs module-1 entries\n",
    "# Use EC alpha consensus as representative\n",
    "ECHO_FIG = os.path.join(ECHO_ROOT, \"parcel_echo.png\")\n",
    "CONS_EC_TAB = os.path.join(ROOT, r\"artifacts\\pli_30_subjects\\tables\")\n",
    "def load_consensus(band):\n",
    "    cfp=os.path.join(CONS_EC_TAB, f\"band__{band}__consensus_labels.npy\")\n",
    "    if not os.path.exists(cfp): return None\n",
    "    return np.load(cfp)\n",
    "\n",
    "labels_alpha = load_consensus(\"alpha\")\n",
    "def parcel_map(names):\n",
    "    parcels = {\"Frontal\":[],\"Central\":[],\"Parietal\":[],\"Occipital\":[],\n",
    "               \"TemporalL\":[],\"TemporalR\":[]}\n",
    "    for i,ch in enumerate(names):\n",
    "        up=ch.upper()\n",
    "        if any(up.startswith(p) for p in (\"FP\",\"AF\",\"F\",\"FC\")): parcels[\"Frontal\"].append(i)\n",
    "        elif up.startswith(\"C\"): parcels[\"Central\"].append(i)\n",
    "        elif any(up.startswith(p) for p in (\"CP\",\"P\",\"PO\")): parcels[\"Parietal\"].append(i)\n",
    "        elif up.startswith(\"O\"): parcels[\"Occipital\"].append(i)\n",
    "        elif up.startswith(\"T\") and (\"7\" in up or \"3\" in up): parcels[\"TemporalL\"].append(i)\n",
    "        elif up.startswith(\"T\") and (\"8\" in up or \"4\" in up): parcels[\"TemporalR\"].append(i)\n",
    "        else:\n",
    "            # leave unmatched in nearest big parcel by prefix\n",
    "            if \"Z\" in up: parcels[\"Central\"].append(i)\n",
    "            else: parcels[\"Central\"].append(i)\n",
    "    return {k: np.array(v,int) for k,v in parcels.items()}\n",
    "parcel_idx = parcel_map(ch_names)\n",
    "def parcel_asym_counts(labels):\n",
    "    out={}\n",
    "    for k,idx in parcel_idx.items():\n",
    "        if idx.size==0: out[f\"{k}_mod0\"]=0; out[f\"{k}_mod1\"]=0; continue\n",
    "        out[f\"{k}_mod0\"] = int((labels[idx]==0).sum())\n",
    "        out[f\"{k}_mod1\"] = int((labels[idx]==1).sum())\n",
    "    return out\n",
    "# Draw a bar: counts per parcel for module0 vs module1\n",
    "if labels_alpha is not None:\n",
    "    counts = parcel_asym_counts(labels_alpha)\n",
    "    keys = [\"Frontal\",\"Central\",\"Parietal\",\"Occipital\",\"TemporalL\",\"TemporalR\"]\n",
    "    m0 = [counts[f\"{k}_mod0\"] for k in keys]\n",
    "    m1 = [counts[f\"{k}_mod1\"] for k in keys]\n",
    "    plt.figure(figsize=(9,5))\n",
    "    x = np.arange(len(keys))\n",
    "    plt.bar(x-0.18, m0, width=0.36, label=\"Module 0\")\n",
    "    plt.bar(x+0.18, m1, width=0.36, label=\"Module 1\")\n",
    "    plt.xticks(x, keys, rotation=0)\n",
    "    plt.ylabel(\"Channel count\")\n",
    "    plt.title(\"Template parcel echo (EC alpha consensus): module composition by parcel\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout(); plt.savefig(ECHO_FIG, dpi=160); plt.close()\n",
    "else:\n",
    "    ECHO_FIG = None\n",
    "\n",
    "# ------------------- D) Final 1-page PDF composer -------------------\n",
    "# Try to include: prereg ROC + AUC/p, ablation PDF (as img), EC/EO scalp strips, replication text, AUC(t) plots, parcel echo\n",
    "# Load prereg CSV if available:\n",
    "PREREG_TXT = \"\"\n",
    "if os.path.exists(PREREG_CSV):\n",
    "    d = pd.read_csv(PREREG_CSV)\n",
    "    if not d.empty:\n",
    "        auc_obs = float(d.loc[0,\"AUC_obs\"]); p_pr = float(d.loc[0,\"p_perm\"])\n",
    "        PREREG_TXT = f\"Minimal model (α/θ coupling): AUC={auc_obs:.3f}, p={p_pr:.4f}\"\n",
    "\n",
    "# Build the page\n",
    "fig = plt.figure(figsize=(11, 8.5))\n",
    "\n",
    "# Title\n",
    "ax_t = fig.add_axes([0.05, 0.92, 0.90, 0.06]); ax_t.axis(\"off\")\n",
    "ax_t.text(0.5, 0.5, \"CNT — Field Signature: Replication • Dynamics • Parcel Echo (All-in-One)\", ha=\"center\", va=\"center\", fontsize=15, weight=\"bold\")\n",
    "\n",
    "# Row 1: prereg + replication summary (text boxes)\n",
    "ax_a = fig.add_axes([0.05, 0.78, 0.42, 0.10]); ax_a.axis(\"off\")\n",
    "ax_a.text(0.0, 0.7, \"Pre-registered Minimal Classifier\", fontsize=11, weight=\"bold\")\n",
    "ax_a.text(0.0, 0.35, PREREG_TXT if PREREG_TXT else \"Minimal model stats not found.\", fontsize=10)\n",
    "ax_b = fig.add_axes([0.53, 0.78, 0.42, 0.10]); ax_b.axis(\"off\")\n",
    "ax_b.text(0.0, 0.7, \"Replication\", fontsize=11, weight=\"bold\")\n",
    "ax_b.text(0.0, 0.35, rep_summary_txt, fontsize=10)\n",
    "\n",
    "# Row 2: Time AUC(t)\n",
    "ax_ta = fig.add_axes([0.05, 0.52, 0.42, 0.20])\n",
    "if times_alpha is not None:\n",
    "    ax_ta.plot(times_alpha, aucs_alpha, label=\"alpha AUC(t)\")\n",
    "    ax_ta.set_title(\"Time-resolved AUC — alpha (EC vs EO)\")\n",
    "    ax_ta.set_xlabel(\"Window start (s)\"); ax_ta.set_ylabel(\"AUC\"); ax_ta.set_ylim(0.5,1.0)\n",
    "else:\n",
    "    ax_ta.text(0.5,0.5,\"alpha AUC(t) unavailable\",ha=\"center\",va=\"center\")\n",
    "ax_tb = fig.add_axes([0.53, 0.52, 0.42, 0.20])\n",
    "if times_theta is not None:\n",
    "    ax_tb.plot(times_theta, aucs_theta, label=\"theta AUC(t)\")\n",
    "    ax_tb.set_title(\"Time-resolved AUC — theta (EC vs EO)\")\n",
    "    ax_tb.set_xlabel(\"Window start (s)\"); ax_tb.set_ylabel(\"AUC\"); ax_tb.set_ylim(0.5,1.0)\n",
    "else:\n",
    "    ax_tb.text(0.5,0.5,\"theta AUC(t) unavailable\",ha=\"center\",va=\"center\")\n",
    "\n",
    "# Row 3: Scalp strips (EC vs EO)\n",
    "def try_load(path): \n",
    "    return plt.imread(path) if os.path.exists(path) else None\n",
    "ax_s = fig.add_axes([0.05, 0.28, 0.90, 0.20]); ax_s.axis(\"off\")\n",
    "x0=0.0\n",
    "for band in [\"alpha\",\"theta\",\"beta\"]:\n",
    "    p_ec = os.path.join(SCALP_DIR, f\"scalp__{band}__EC.png\")\n",
    "    p_eo = os.path.join(SCALP_DIR, f\"scalp__{band}__EO.png\")\n",
    "    ec_img, eo_img = try_load(p_ec), try_load(p_eo)\n",
    "    if ec_img is None or eo_img is None:\n",
    "        ax_s.text(x0+0.15, 0.5, f\"{band} scalp missing\", transform=ax_s.transAxes)\n",
    "        x0 += 0.3; continue\n",
    "    # stitch horizontally\n",
    "    strip = np.concatenate([ec_img, eo_img], axis=1)\n",
    "    ax_sub = fig.add_axes([0.05 + ([\"alpha\",\"theta\",\"beta\"].index(band))*0.30, 0.28, 0.28, 0.20]); ax_sub.axis(\"off\")\n",
    "    ax_sub.imshow(strip); ax_sub.set_title(f\"{band.upper()}  EC | EO\")\n",
    "\n",
    "# Row 4: Parcel echo (bar)\n",
    "ax_p = fig.add_axes([0.05, 0.05, 0.42, 0.18]); ax_p.axis(\"off\")\n",
    "if ECHO_FIG and os.path.exists(ECHO_FIG):\n",
    "    img = plt.imread(ECHO_FIG); ax_p.imshow(img); ax_p.set_title(\"Parcel echo (EC α)\"); ax_p.axis(\"off\")\n",
    "else:\n",
    "    ax_p.text(0.5,0.5,\"Parcel echo unavailable\",ha=\"center\",va=\"center\")\n",
    "\n",
    "# Ablation (optional)\n",
    "ax_ab = fig.add_axes([0.53, 0.05, 0.42, 0.18]); ax_ab.axis(\"off\")\n",
    "if os.path.exists(ABLATION_PDF):\n",
    "    ax_ab.text(0.0,0.8,\"Ablation PDF saved separately:\",fontsize=10,weight=\"bold\")\n",
    "    ax_ab.text(0.0,0.45,ABLATION_PDF,fontsize=9)\n",
    "else:\n",
    "    ax_ab.text(0.0,0.6,\"Ablation PDF not found\",fontsize=10)\n",
    "\n",
    "fig.tight_layout()\n",
    "pp = PdfPages(FINAL_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved final 1-pager:\", FINAL_PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba68ef5c-8a15-47b2-93c1-12028eff61ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[demo] synthesizing small primate set in C:\\Users\\caleb\\CNT_Lab\\primate_eeg\n"
     ]
    }
   ],
   "source": [
    "# === CNT Primate Field Test — Two-Module Consensus + Hemi/AP + Optional EC/EO Classifier (single cell) ===\n",
    "# Works with local primate EEG/LFP/ECoG files (*.npy, optional *.channels.txt).\n",
    "# It will:\n",
    "#   1) Scan PRIMATE_DIR for subjects: subject_##_{REST|EC|EO}.npy\n",
    "#   2) Run PLI + spectral-on-coassoc (k=2) for θ, α, β, γ with label-preserving null p-values\n",
    "#   3) Compute hemispheric and anterior/posterior metrics (auto-map; optional channels_map.csv)\n",
    "#   4) If both EC & EO exist → train prereg minimal classifier (α/θ coupling only) with paired CV + 10k perms\n",
    "# Outputs: under OUT_ROOT: metrics/*.json, tables/*.npy, figures/*.png, summary CSVs.\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "PRIMATE_DIR = r\"C:\\Users\\caleb\\CNT_Lab\\primate_eeg\"   # <-- set to your primate folder\n",
    "USE_DEMO    = False                                   # True = synthesize small primate-like set\n",
    "FS          = 1000.0                                  # set your sampling rate (Hz)\n",
    "SLICE_SEC   = 60                                      # seconds per subject to keep (for demo or trimming)\n",
    "BANDS_HZ    = { \"theta\": (4.0, 8.0), \"alpha\": (8.0, 12.0), \"beta\": (13.0, 30.0), \"gamma\": (30.0, 55.0) }\n",
    "K_FIXED     = 2\n",
    "KNN_K       = 6\n",
    "NULL_PERMS  = 500                                     # label-preserving nulls per band\n",
    "OUT_ROOT    = r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_primate\"\n",
    "\n",
    "# Optional curated channel map:\n",
    "# If present at PRIMATE_DIR/channels_map.csv with columns: name, hemi (L/R/M), ap (A/P/C)\n",
    "CHANNEL_MAP_CSV = os.path.join(PRIMATE_DIR, \"channels_map.csv\")\n",
    "\n",
    "# ----------------------------------------\n",
    "\n",
    "os.makedirs(OUT_ROOT, exist_ok=True)\n",
    "OUT_TAB = os.path.join(OUT_ROOT, \"tables\");  os.makedirs(OUT_TAB, exist_ok=True)\n",
    "OUT_MET = os.path.join(OUT_ROOT, \"metrics\"); os.makedirs(OUT_MET, exist_ok=True)\n",
    "OUT_FIG = os.path.join(OUT_ROOT, \"figures\"); os.makedirs(OUT_FIG, exist_ok=True)\n",
    "\n",
    "# -------- Scan subjects --------\n",
    "def find_subjects(base):\n",
    "    subs = {\"REST\":[], \"EC\":[], \"EO\":[]}\n",
    "    for cond in [\"REST\",\"EC\",\"EO\"]:\n",
    "        subs[cond] = sorted(glob.glob(os.path.join(base, f\"subject_*_{cond}.npy\")))\n",
    "    return subs\n",
    "\n",
    "# -------- Demo synth (if needed) --------\n",
    "def synth_primate(n_subj=8, n_ch=32, fs=FS, seconds=SLICE_SEC, seed=7):\n",
    "    rng = default_rng(seed)\n",
    "    T = int(fs*seconds)\n",
    "    paths = []\n",
    "    os.makedirs(PRIMATE_DIR, exist_ok=True)\n",
    "    for s in range(n_subj):\n",
    "        X = rng.normal(0,1,size=(n_ch,T))\n",
    "        t = np.arange(T)/fs\n",
    "        theta = np.sin(2*np.pi*7.5*t + rng.uniform(0,2*np.pi))\n",
    "        # Inject two-module: stronger posterior subset\n",
    "        for c in range(n_ch//2, n_ch):\n",
    "            X[c] += 0.6*theta + 0.2*rng.normal(0,1,T)\n",
    "        base = os.path.join(PRIMATE_DIR, f\"subject_{s:02d}_REST\")\n",
    "        np.save(base + \".npy\", X.astype(np.float32))\n",
    "        with open(base + \".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "            for i in range(n_ch): f.write(f\"ch{i}\\n\")\n",
    "        paths.append(base+\".npy\")\n",
    "    return paths\n",
    "\n",
    "# -------- Channel handling --------\n",
    "def load_channels_for_any(npy_path):\n",
    "    txt = npy_path.replace(\".npy\",\".channels.txt\")\n",
    "    if os.path.exists(txt):\n",
    "        with open(txt,\"r\",encoding=\"utf-8\") as f:\n",
    "            return [ln.strip() for ln in f if ln.strip()]\n",
    "    # fallback generic names\n",
    "    X = np.load(npy_path, mmap_mode='r')\n",
    "    return [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|LFP|ECOG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"]))\n",
    "RIGHT_CANON = set(map(str.upper, [\"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\")\n",
    "\n",
    "# read optional curated map\n",
    "CURATED = {}\n",
    "if os.path.exists(CHANNEL_MAP_CSV):\n",
    "    try:\n",
    "        df_map = pd.read_csv(CHANNEL_MAP_CSV)\n",
    "        for _,r in df_map.iterrows():\n",
    "            CURATED[str(r[\"name\"]).strip()] = (str(r[\"hemi\"]).upper()[:1], str(r[\"ap\"]).upper()[:1])\n",
    "        print(f\"[info] Loaded curated channel map with {len(CURATED)} entries.\")\n",
    "    except Exception as e:\n",
    "        print(\"[warn] Could not parse channels_map.csv:\", e)\n",
    "\n",
    "def hemi_ap_map(ch_names):\n",
    "    L,R,Z,A,P,C = [],[],[],[],[],[]\n",
    "    for i, orig in enumerate(ch_names):\n",
    "        name = clean_label(orig)\n",
    "        # curated override\n",
    "        if name in CURATED:\n",
    "            hemi, ap = CURATED[name]\n",
    "            if hemi==\"L\": L.append(i)\n",
    "            elif hemi==\"R\": R.append(i)\n",
    "            else: Z.append(i)\n",
    "            if ap==\"A\": A.append(i)\n",
    "            elif ap==\"P\": P.append(i)\n",
    "            else: C.append(i)\n",
    "            continue\n",
    "        up = name.upper()\n",
    "        # hemi: tokens or 10–20 odd/even or _L/_R suffix\n",
    "        if up.endswith(\"_L\") or re.search(r\"(^|[_\\-])L($|[_\\-])\", name): L.append(i); \n",
    "        elif up.endswith(\"_R\") or re.search(r\"(^|[_\\-])R($|[_\\-])\", name): R.append(i)\n",
    "        elif up in LEFT_CANON: L.append(i)\n",
    "        elif up in RIGHT_CANON: R.append(i)\n",
    "        elif up in MID_CANON or re.search(r\"[A-Za-z]Z$\", name): Z.append(i)\n",
    "        else:\n",
    "            m = re.search(r\"(\\d+)$\", name)\n",
    "            if m:\n",
    "                try:\n",
    "                    d=int(m.group(1)); (L if d%2==1 else R).append(i)\n",
    "                except: Z.append(i)\n",
    "            else:\n",
    "                Z.append(i)\n",
    "        # A/P: prefixes\n",
    "        if any(up.startswith(px.upper()) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(up.startswith(px.upper()) for px in POST_PREFIXES): P.append(i)\n",
    "        elif up.startswith(\"C\"): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int), np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "# -------- PLI + spectral --------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a=butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a=butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=filtfilt(b,a,X[c])\n",
    "    ph=np.angle(hilbert(Y, axis=1))\n",
    "    W=np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d=ph[i]-ph[j]; pli=abs(np.mean(np.sign(np.sin(d))))\n",
    "            W[i,j]=W[j,i]=pli\n",
    "    np.fill_diagonal(W,0.0); return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W,k=2):\n",
    "    e,v=np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n), float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1.0 if li==lab[j] else 0.0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof, k=2)\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave), k=2)\n",
    "        vals.append(adjusted_rand_score(cons,cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def rand_same_sizes(lab, rng):\n",
    "    n=len(lab); uniq,cnts=np.unique(lab, return_counts=True)\n",
    "    idx=np.arange(n); rng.shuffle(idx); out=np.empty(n,int); st=0\n",
    "    for L,c in zip(uniq,cnts):\n",
    "        seg=idx[st:st+c]; out[seg]=L; st+=c\n",
    "    return out\n",
    "\n",
    "# -------- Consensus runner --------\n",
    "def run_consensus_for_condition(paths, bands=BANDS_HZ, tag=\"REST\"):\n",
    "    rng = default_rng(13)\n",
    "    # unify channels for mapping from first file\n",
    "    ch = load_channels_for_any(paths[0])\n",
    "    L,R,Z,A,P,C = hemi_ap_map(ch)\n",
    "\n",
    "    rows=[]\n",
    "    for band,(lo,hi) in bands.items():\n",
    "        # per-subject labels\n",
    "        subj_labels=[]\n",
    "        for p in paths:\n",
    "            X=np.load(p); W=pli_matrix(X, FS, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W,k=K_FIXED)\n",
    "            subj_labels.append(lbl)\n",
    "        loso, cons, co = loso_via_coassoc(subj_labels)\n",
    "        # null (label-preserving)\n",
    "        null=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nlabs=[rand_same_sizes(l, rng) for l in subj_labels]\n",
    "            _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "            from sklearn.metrics import adjusted_rand_score\n",
    "            null.append(adjusted_rand_score(cons, cons_n))\n",
    "        null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "\n",
    "        # save\n",
    "        np.save(os.path.join(OUT_TAB, f\"primate__{tag}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB, f\"primate__{tag}__{band}__coassoc.npy\"), co)\n",
    "        met={\"tag\":tag,\"band\":band,\"n_subjects\":len(paths),\"loso\":float(loso),\n",
    "             \"null_mean\":float(null.mean()),\"p_value\":p,\"n_channels\":len(ch)}\n",
    "        with open(os.path.join(OUT_MET, f\"primate__{tag}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump(met,f,indent=2)\n",
    "\n",
    "        # hemi/AP quick metrics\n",
    "        def mean_safe(x): return float(np.nan) if x.size==0 else float(x.mean())\n",
    "        def within_region_ratio(W, labels, idx):\n",
    "            if idx.size<3: return np.nan\n",
    "            sub=np.ix_(idx,idx); Wr=W[sub]; lab=labels[idx]\n",
    "            same=lab[:,None]==lab[None,:]; diff=~same\n",
    "            np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "            return float(mean_safe(Wr[same])/(mean_safe(Wr[diff])+1e-12))\n",
    "        # Use consensus W? (coassoc) for ratios on consensus geometry\n",
    "        lratio = within_region_ratio(co, cons, L)\n",
    "        rratio = within_region_ratio(co, cons, R)\n",
    "        # Report\n",
    "        rows.append([tag, band, len(paths), len(ch), float(loso), float(null.mean()), p, lratio, rratio])\n",
    "\n",
    "        # fig\n",
    "        plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"Primate {tag} {band} — co-assoc\")\n",
    "        plt.colorbar(); plt.tight_layout()\n",
    "        plt.savefig(os.path.join(OUT_FIG, f\"primate__{tag}__{band}__coassoc.png\"), dpi=160); plt.close()\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"tag\",\"band\",\"n_subjects\",\"n_channels\",\"LOSO\",\"null_mean\",\"p_value\",\"left_intra_ratio\",\"right_intra_ratio\"])\n",
    "    df.to_csv(os.path.join(OUT_ROOT, f\"primate__{tag}__summary.csv\"), index=False)\n",
    "    print(f\"[{tag}] summary:\\n\", df.to_string(index=False))\n",
    "    return df, ch\n",
    "\n",
    "# -------- Minimal EC/EO classifier for primate (if both EC and EO exist per subject) --------\n",
    "def build_minimal_features(paths_by_cond, fs=FS):\n",
    "    # features: α/θ WH_WM & CH_WM per subject/cond\n",
    "    def hemi_module_means(W, labels, L, R):\n",
    "        n=len(labels)\n",
    "        Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "        Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "        within=Lmask|Rmask\n",
    "        cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "        same  =labels[:,None]==labels[None,:]\n",
    "        for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "        return float((W[within&same]).mean()), float((W[cross&same]).mean())\n",
    "    feats=[]; ys=[]; sids=[]\n",
    "    # use first subject's channels to map\n",
    "    any_key = next(iter(paths_by_cond.keys()))\n",
    "    any_cond = next(iter(paths_by_cond[any_key].keys()))\n",
    "    ch = load_channels_for_any(paths_by_cond[any_key][any_cond])\n",
    "    L,R,Z,A,P,C = hemi_ap_map(ch)\n",
    "    for subj, conds in paths_by_cond.items():\n",
    "        for cond, path in conds.items():\n",
    "            X=np.load(path)\n",
    "            row={\"subject\":subj,\"cond\":0 if cond==\"EC\" else 1}\n",
    "            for band,(lo,hi) in {\"alpha\":(8,12),\"theta\":(4,8)}.items():\n",
    "                W=pli_matrix(X, fs, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W,k=K_FIXED)\n",
    "                WHWM,CHWM = hemi_module_means(W, lbl, L, R)\n",
    "                row[f\"{band}_WHWM\"]=WHWM; row[f\"{band}_CHWM\"]=CHWM\n",
    "            feats.append(row)\n",
    "    df = pd.DataFrame(feats).dropna()\n",
    "    X = df[[c for c in df.columns if any(c.startswith(b) for b in [\"alpha_\",\"theta_\"])]].to_numpy(float)\n",
    "    y = df[\"cond\"].to_numpy(int)\n",
    "    s = df[\"subject\"].to_numpy(int)\n",
    "    return X,y,s, df\n",
    "\n",
    "def paired_auc_perm(X, y, subj_ids, perm_B=10000):\n",
    "    from sklearn.pipeline import make_pipeline\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng = default_rng(31)\n",
    "    fold_probs=[]; fold_true=[]; order_pairs=[]\n",
    "    u_subs = sorted(set(subj_ids))\n",
    "    for sid in u_subs:\n",
    "        test=(subj_ids==sid)\n",
    "        if np.sum(test)!=2: continue\n",
    "        train=~test\n",
    "        clf.fit(X[train], y[train])\n",
    "        if hasattr(clf[-1],\"predict_proba\"): p=clf.predict_proba(X[test])[:,1]\n",
    "        else: p=clf.decision_function(X[test])\n",
    "        fold_probs.append(p); fold_true.append(y[test]); order_pairs.append(np.where(test)[0])\n",
    "    if not fold_probs: return np.nan, np.nan\n",
    "    probs=np.concatenate(fold_probs); ys=np.concatenate(fold_true)\n",
    "    auc_obs=float(roc_auc_score(ys, probs))\n",
    "    # paired flips\n",
    "    cnt=1\n",
    "    for _ in range(perm_B):\n",
    "        y_perm=ys.copy()\n",
    "        idx=0\n",
    "        for sid in u_subs:\n",
    "            if idx>=len(order_pairs): break\n",
    "            pidx=order_pairs[idx]\n",
    "            if len(pidx)!=2: idx+=1; continue\n",
    "            if rng.random()<0.5: y_perm[pidx]=y_perm[pidx][::-1]\n",
    "            idx+=1\n",
    "        auc_p=float(roc_auc_score(y_perm, probs))\n",
    "        if auc_p>=auc_obs: cnt+=1\n",
    "    return auc_obs, float(cnt/(perm_B+1))\n",
    "\n",
    "# ================== RUN ==================\n",
    "# Prepare data\n",
    "subs = find_subjects(PRIMATE_DIR)\n",
    "if USE_DEMO or (not any(len(v)>0 for v in subs.values())):\n",
    "    print(\"[demo] synthesizing small primate set in\", PRIMATE_DIR)\n",
    "    synth_primate()\n",
    "    subs = find_subjects(PRIMATE_DIR)\n",
    "\n",
    "# REST consensus (if present)\n",
    "if subs[\"REST\"]:\n",
    "    df_rest, ch_rest = run_consensus_for_condition(subs[\"REST\"], tag=\"REST\")\n",
    "\n",
    "# EC/EO consensus (if present)\n",
    "paths_ec = subs[\"EC\"]; paths_eo = subs[\"EO\"]\n",
    "df_ec = df_eo = None\n",
    "if paths_ec:\n",
    "    df_ec, ch_ec = run_consensus_for_condition(paths_ec, tag=\"EC\")\n",
    "if paths_eo:\n",
    "    df_eo, ch_eo = run_consensus_for_condition(paths_eo, tag=\"EO\")\n",
    "\n",
    "# Optional EC vs EO minimal classifier (α/θ coupling only)\n",
    "# Build per-subject dict if both exist\n",
    "pairs = {}\n",
    "for p in paths_ec:\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EC\\.npy$\", p).group(1))\n",
    "    pairs.setdefault(sid, {})[\"EC\"] = p\n",
    "for p in paths_eo:\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EO\\.npy$\", p).group(1))\n",
    "    pairs.setdefault(sid, {})[\"EO\"] = p\n",
    "pairs = {k:v for k,v in pairs.items() if \"EC\" in v and \"EO\" in v}\n",
    "\n",
    "if pairs:\n",
    "    X,y,s,df_feat = build_minimal_features(pairs, fs=FS)\n",
    "    if len(np.unique(s))>=5:\n",
    "        auc_pri, p_pri = paired_auc_perm(X,y,s, perm_B=10000)\n",
    "        print(f\"\\n[primate EC vs EO] minimal α/θ coupling → AUC={auc_pri:.3f}, p={p_pri:.4f}  (N={X.shape[0]} points)\")\n",
    "        pd.DataFrame([{\"AUC\":auc_pri,\"p_perm\":p_pri,\"N_points\":int(X.shape[0]),\"N_subjects\":int(len(set(s)))}]).to_csv(\n",
    "            os.path.join(OUT_ROOT,\"primate_ec_eo_minimal.csv\"), index=False\n",
    "        )\n",
    "    else:\n",
    "        print(\"[info] Not enough paired primate subjects for EC/EO classification.\")\n",
    "else:\n",
    "    print(\"[info] No EC+EO pairs detected; skipping primate classifier.\")\n",
    "\n",
    "print(\"\\nDone. Artifacts →\", OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d0e036a-e592-410e-9bd4-f969bea814d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Set PRIMATE_DS to a valid OpenNeuro dataset ID and re-run to download.\n",
      "[convert] Skipped (no dataset id set). You can re-run after setting PRIMATE_DS.\n",
      "[REST] summary:\n",
      " cond  band  n_subjects  n_channels     LOSO  null_mean  p_value\n",
      "REST theta           8          32 1.000000  -0.002644 0.003322\n",
      "REST alpha           8          32 0.653250  -0.001480 0.003322\n",
      "REST  beta           8          32 0.598839  -0.000612 0.003322\n",
      "REST gamma           8          32 0.459278   0.000912 0.003322\n",
      "[info] No EC+EO pairs found; classifier skipped.\n",
      "\n",
      "Artifacts → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_primate_dl\n",
      "If download found nothing, set PRIMATE_DS='ds00XXXX' and re-run.\n"
     ]
    }
   ],
   "source": [
    "# === Download Primate EO/EC (OpenNeuro) → Convert → PLI Consensus + Optional EC/EO Classifier (single cell) ===\n",
    "# What you do:\n",
    "#   1) Set PRIMATE_DS to a real OpenNeuro dataset ID (e.g., \"ds00XXXX\").\n",
    "#   2) Run this cell. It downloads only EEG/LFP/ECoG matches, exports subjects → *.npy, and runs:\n",
    "#        • PLI + spectral-on-coassoc (k=2) for θ/α/β/γ\n",
    "#        • Hemispheric / A-P metrics\n",
    "#        • (If EC & EO exist) α/θ coupling minimal classifier with paired CV + 10k perms (AUC + p)\n",
    "# Outputs go to:  C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_primate_dl\\{metrics,tables,figures}\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, decimate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "PRIMATE_DS  = \"\"   # <-- set to an OpenNeuro dataset ID like \"ds00XXXX\" (leave blank until you know the ID)\n",
    "FS_TARGET   = 1000.0        # resample target Hz (adjust to your data; 1 kHz is common for LFP/ECoG)\n",
    "SLICE_SEC   = 60            # seconds per subject to keep (trim/tile)\n",
    "INCLUDES    = [\"*eeg*.edf\", \"*eeg*.mat\", \"*eeg*.npy\",\n",
    "               \"*lfp*.edf\", \"*lfp*.mat\", \"*lfp*.npy\",\n",
    "               \"*ecog*.edf\",\"*ecog*.mat\",\"*ecog*.npy\"]    # narrow filters to keep download small\n",
    "\n",
    "BANDS_HZ    = {\"theta\": (4.0, 8.0), \"alpha\": (8.0, 12.0), \"beta\": (13.0, 30.0), \"gamma\": (30.0, 55.0)}\n",
    "K_FIXED     = 2\n",
    "KNN_K       = 6\n",
    "NULL_PERMS  = 300\n",
    "PERM_B_CLF  = 10000\n",
    "\n",
    "DL_ROOT     = os.path.join(ROOT, \"primate_openneuro_raw\")\n",
    "NPY_DIR     = os.path.join(ROOT, \"primate_eeg\")  # exported .npy + .channels.txt\n",
    "OUT_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_primate_dl\")\n",
    "OUT_TAB     = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET     = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG     = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [DL_ROOT, NPY_DIR, OUT_ROOT, OUT_TAB, OUT_MET, OUT_FIG]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# ------------- 1) Download (OpenNeuro) -------------\n",
    "def download_openneuro(ds_id, target, includes):\n",
    "    try:\n",
    "        import openneuro as on\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"openneuro-py\"])\n",
    "        import openneuro as on\n",
    "    print(f\"[download] OpenNeuro: {ds_id}\")\n",
    "    ok_any = False\n",
    "    for patt in includes:\n",
    "        try:\n",
    "            on.download(dataset=ds_id, target=target, include=[patt], strict=False)\n",
    "            print(f\"  included: {patt}\")\n",
    "            ok_any = True\n",
    "        except Exception as e:\n",
    "            print(f\"  [skip] include {patt}: {e}\")\n",
    "    return ok_any\n",
    "\n",
    "if not PRIMATE_DS:\n",
    "    print(\"[info] Set PRIMATE_DS to a valid OpenNeuro dataset ID and re-run to download.\")\n",
    "else:\n",
    "    ok = download_openneuro(PRIMATE_DS, DL_ROOT, INCLUDES)\n",
    "    if not ok:\n",
    "        print(\"[warn] No files matched include patterns; check dataset ID or INCLUDES.\")\n",
    "\n",
    "# ------------- 2) Convert → NPY per subject -------------\n",
    "def ensure_dir(p): os.makedirs(p, exist_ok=True); return p\n",
    "\n",
    "def try_load_file(fp):\n",
    "    fp_l = fp.lower()\n",
    "    if fp_l.endswith(\".edf\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"mne\", \"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, eog=False, ecg=False, emg=False, stim=False, misc=False)\n",
    "        X  = raw.get_data()\n",
    "        fs = float(raw.info[\"sfreq\"])\n",
    "        ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".mat\"):\n",
    "        from scipy.io import loadmat\n",
    "        m = loadmat(fp)\n",
    "        arr = None\n",
    "        for k,v in m.items():\n",
    "            if isinstance(v, np.ndarray) and v.ndim == 2 and (arr is None or v.size > arr.size):\n",
    "                arr = v\n",
    "        if arr is None:\n",
    "            raise RuntimeError(\"No 2D array in MAT\")\n",
    "        fs = float(m.get(\"fs\", np.array([[FS_TARGET]])).squeeze())\n",
    "        ch = [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "        return arr.astype(float), fs, ch\n",
    "    elif fp_l.endswith(\".npy\"):\n",
    "        X = np.load(fp)\n",
    "        if X.ndim != 2: raise RuntimeError(\"NPY must be [n_ch, n_t]\")\n",
    "        ch = [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "        return X.astype(float), FS_TARGET, ch\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported file: {fp}\")\n",
    "\n",
    "def resample_if_needed(X, fs_in, fs_out):\n",
    "    if abs(fs_in - fs_out) < 1e-6:\n",
    "        return X, fs_in\n",
    "    q = int(round(fs_in / fs_out))\n",
    "    if q >= 1 and abs(fs_in / q - fs_out) < 1e-3:\n",
    "        Y = np.vstack([decimate(X[i], q, ftype=\"fir\", zero_phase=True) for i in range(X.shape[0])])\n",
    "        return Y, fs_out\n",
    "    # if non-integer, keep original (or implement resample_poly if needed)\n",
    "    return X, fs_in\n",
    "\n",
    "def export_npys_from_download(ds_id, raw_root, out_dir, fs_out=FS_TARGET, slice_sec=SLICE_SEC, subj_limit=None):\n",
    "    files = []\n",
    "    for patt in INCLUDES + [\"*.edf\",\"*.npy\",\"*.mat\"]:\n",
    "        files.extend(glob.glob(os.path.join(raw_root, ds_id, \"**\", patt), recursive=True))\n",
    "    files = sorted(list(set(files)))\n",
    "    out_paths = {}\n",
    "    subj_idx = 0\n",
    "    for fp in files:\n",
    "        try:\n",
    "            X, fs, ch = try_load_file(fp)\n",
    "            X, fs2 = resample_if_needed(X, fs, fs_out)\n",
    "            n_keep = int(slice_sec * fs2)\n",
    "            if X.shape[1] >= n_keep:\n",
    "                Xo = X[:, :n_keep]\n",
    "            else:\n",
    "                reps = int(np.ceil(n_keep / X.shape[1])); Xo = np.tile(X, reps)[:, :n_keep]\n",
    "            # derive a subject + condition tag if possible from path (EC/EO), else REST\n",
    "            tag = \"REST\"\n",
    "            low = fp.lower()\n",
    "            if re.search(r\"(eyes[_\\-]?open|eo|restopen)\", low): tag = \"EO\"\n",
    "            if re.search(r\"(eyes[_\\-]?closed|ec|restclosed)\", low): tag = \"EC\"\n",
    "            base = os.path.join(out_dir, f\"subject_{subj_idx:02d}_{tag}\")\n",
    "            np.save(base + \".npy\", Xo.astype(np.float32))\n",
    "            with open(base + \".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for nm in ch: f.write(str(nm)+\"\\n\")\n",
    "            out_paths.setdefault(subj_idx, {})[tag] = base + \".npy\"\n",
    "            subj_idx += 1\n",
    "            if subj_limit and subj_idx >= subj_limit:\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(\"[skip]\", fp, e)\n",
    "    return out_paths\n",
    "\n",
    "paths_by_subj = {}\n",
    "if PRIMATE_DS:\n",
    "    paths_by_subj = export_npys_from_download(PRIMATE_DS, DL_ROOT, NPY_DIR, fs_out=FS_TARGET, slice_sec=SLICE_SEC, subj_limit=None)\n",
    "    print(f\"[convert] prepared {len(paths_by_subj)} subjects into\", NPY_DIR)\n",
    "else:\n",
    "    print(\"[convert] Skipped (no dataset id set). You can re-run after setting PRIMATE_DS.\")\n",
    "\n",
    "# ------------- 3) PLI + spectral-on-coassoc (k=2) -------------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|LFP|ECOG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"]))\n",
    "RIGHT_CANON = set(map(str.upper, [\"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\")\n",
    "\n",
    "def hemi_ap_map(ch_names):\n",
    "    L,R,Z,A,P,C = [],[],[],[],[],[]\n",
    "    for i, raw in enumerate(ch_names):\n",
    "        name = clean_label(raw); up = name.upper()\n",
    "        # Hemisphere\n",
    "        if up in LEFT_CANON:  L.append(i)\n",
    "        elif up in RIGHT_CANON: R.append(i)\n",
    "        elif up in MID_CANON or re.search(r\"[A-Za-z]Z$\", name): Z.append(i)\n",
    "        else:\n",
    "            m = re.search(r\"(\\d+)$\", name)\n",
    "            if m:\n",
    "                try:\n",
    "                    d=int(m.group(1)); (L if d%2==1 else R).append(i)\n",
    "                except: Z.append(i)\n",
    "            else:\n",
    "                Z.append(i)\n",
    "        # AP\n",
    "        if any(up.startswith(px.upper()) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(up.startswith(px.upper()) for px in POST_PREFIXES): P.append(i)\n",
    "        elif up.startswith(\"C\"): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int), np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d = ph[i]-ph[j]\n",
    "            W[i,j] = W[j,i] = abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U / (np.linalg.norm(U, axis=1, keepdims=True) + 1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=42).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n),float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1.0 if li==lab[j] else 0.0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    from sklearn.metrics import adjusted_rand_score\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof, k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave), k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def run_pli_consensus(npy_dir, tag=\"REST\"):\n",
    "    # group subjects by condition\n",
    "    subjects = {}\n",
    "    for fp in sorted(glob.glob(os.path.join(npy_dir, \"subject_*_*.npy\"))):\n",
    "        m = re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "        if not m: continue\n",
    "        sid, cond = int(m.group(1)), m.group(2).upper()\n",
    "        subjects.setdefault(sid, {})[cond] = fp\n",
    "\n",
    "    # choose a condition to analyze for consensus (REST/EC/EO)\n",
    "    conds_present = set(c for d in subjects.values() for c in d.keys())\n",
    "    to_run = sorted(list(conds_present))\n",
    "    if not to_run:\n",
    "        print(\"[warn] No subjects in\", npy_dir); return\n",
    "    rng = default_rng(13)\n",
    "\n",
    "    for cond in to_run:\n",
    "        paths = [d[cond] for d in subjects.values() if cond in d]\n",
    "        if len(paths) < 4:\n",
    "            print(f\"[{cond}] not enough subjects:\", len(paths)); continue\n",
    "        # channel names from first file\n",
    "        ch = []\n",
    "        ch_txt = paths[0].replace(\".npy\",\".channels.txt\")\n",
    "        if os.path.exists(ch_txt):\n",
    "            with open(ch_txt,\"r\",encoding=\"utf-8\") as f:\n",
    "                ch=[ln.strip() for ln in f if ln.strip()]\n",
    "        else:\n",
    "            X0 = np.load(paths[0], mmap_mode=\"r\")\n",
    "            ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "        L,R,Z,A,P,C = hemi_ap_map(ch)\n",
    "\n",
    "        rows=[]\n",
    "        for band,(lo,hi) in BANDS_HZ.items():\n",
    "            subj_labels=[]\n",
    "            for p in paths:\n",
    "                X=np.load(p); W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W, KNN_K); lbl=spec_labels(W, k=K_FIXED)\n",
    "                subj_labels.append(lbl)\n",
    "            loso, cons, co = loso_via_coassoc(subj_labels)\n",
    "            # label-preserve null\n",
    "            null=[]\n",
    "            from sklearn.metrics import adjusted_rand_score\n",
    "            for _ in range(NULL_PERMS):\n",
    "                nlabs=[]\n",
    "                for lab in subj_labels:\n",
    "                    # same-size random labels\n",
    "                    uniq,cnts = np.unique(lab, return_counts=True)\n",
    "                    idx = np.arange(len(lab)); rng.shuffle(idx)\n",
    "                    out = np.empty(len(lab),int); st=0\n",
    "                    for u,c in zip(uniq,cnts):\n",
    "                        seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                    nlabs.append(out)\n",
    "                _, cons_n, _ = loso_via_coassoc(nlabs)\n",
    "                null.append(adjusted_rand_score(cons, cons_n))\n",
    "            null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "            # save\n",
    "            np.save(os.path.join(OUT_TAB, f\"primate__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "            np.save(os.path.join(OUT_TAB, f\"primate__{cond}__{band}__coassoc.npy\"), co)\n",
    "            with open(os.path.join(OUT_MET, f\"primate__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "                json.dump({\"band\":band,\"cond\":cond,\"n_subj\":len(paths),\"LOSO\":float(loso),\"null_mean\":float(null.mean()),\"p_value\":p}, f, indent=2)\n",
    "            plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"Primate {cond} {band} — co-assoc\")\n",
    "            plt.colorbar(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_FIG, f\"primate__{cond}__{band}__coassoc.png\"), dpi=160); plt.close()\n",
    "            rows.append([cond, band, len(paths), len(ch), float(loso), float(null.mean()), p])\n",
    "        df = pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"n_channels\",\"LOSO\",\"null_mean\",\"p_value\"])\n",
    "        df.to_csv(os.path.join(OUT_ROOT, f\"primate__{cond}__summary.csv\"), index=False)\n",
    "        print(f\"[{cond}] summary:\\n\", df.to_string(index=False))\n",
    "\n",
    "run_pli_consensus(NPY_DIR)\n",
    "\n",
    "# ------------- 4) Optional primate EC vs EO classifier (α/θ coupling) -------------\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return float((W[within&same]).mean()) if np.any(within&same) else np.nan, \\\n",
    "           float((W[cross &same]).mean()) if np.any(cross &same) else np.nan\n",
    "\n",
    "def build_minimal_features(NPY_DIR):\n",
    "    # build subject dict with EC+EO\n",
    "    subs = {}\n",
    "    for fp in sorted(glob.glob(os.path.join(NPY_DIR, \"subject_*_*.npy\"))):\n",
    "        m = re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "        if not m: continue\n",
    "        sid, cond = int(m.group(1)), m.group(2).upper()\n",
    "        subs.setdefault(sid, {})[cond] = fp\n",
    "    pairs = {k:v for k,v in subs.items() if \"EC\" in v and \"EO\" in v}\n",
    "    if not pairs: return None, None, None\n",
    "    any_sid = next(iter(pairs.keys()))\n",
    "    ch_txt = pairs[any_sid][\"EC\"].replace(\".npy\",\".channels.txt\")\n",
    "    if os.path.exists(ch_txt):\n",
    "        with open(ch_txt,\"r\",encoding=\"utf-8\") as f:\n",
    "            ch=[ln.strip() for ln in f if ln.strip()]\n",
    "    else:\n",
    "        X0 = np.load(pairs[any_sid][\"EC\"], mmap_mode=\"r\")\n",
    "        ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "    # maps\n",
    "    L,R,Z,A,P,C = hemi_ap_map(ch)\n",
    "    rows=[]\n",
    "    for sid, d in pairs.items():\n",
    "        for cond,path in d.items():\n",
    "            X=np.load(path)\n",
    "            row={\"subject\":sid, \"cond\": 0 if cond==\"EC\" else 1}\n",
    "            for band,(lo,hi) in {\"alpha\":(8,12), \"theta\":(4,8)}.items():\n",
    "                W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W,k=K_FIXED)\n",
    "                wh, chm = hemi_module_means(W, lbl, L, R)\n",
    "                row[f\"{band}_WHWM\"]=wh; row[f\"{band}_CHWM\"]=chm\n",
    "            rows.append(row)\n",
    "    df = pd.DataFrame(rows).dropna()\n",
    "    X = df[[c for c in df.columns if c.endswith(\"_WHWM\") or c.endswith(\"_CHWM\")]].to_numpy(float)\n",
    "    y = df[\"cond\"].to_numpy(int)\n",
    "    s = df[\"subject\"].to_numpy(int)\n",
    "    return X,y,s\n",
    "\n",
    "def paired_auc_perm(X, y, subj_ids, perm_B=PERM_B_CLF):\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng = default_rng(17)\n",
    "    fold_probs=[]; fold_true=[]; order_pairs=[]\n",
    "    u_subs = sorted(set(subj_ids))\n",
    "    for sid in u_subs:\n",
    "        test = (subj_ids == sid)\n",
    "        if np.sum(test) != 2: continue\n",
    "        train = ~test\n",
    "        clf.fit(X[train], y[train])\n",
    "        p = clf.predict_proba(X[test])[:,1] if hasattr(clf[-1],\"predict_proba\") else clf.decision_function(X[test])\n",
    "        fold_probs.append(p); fold_true.append(y[test]); order_pairs.append(np.where(test)[0])\n",
    "    if not fold_probs: return None, None\n",
    "    probs=np.concatenate(fold_probs); ys=np.concatenate(fold_true)\n",
    "    if len(np.unique(ys))<2: return None, None\n",
    "    auc_obs=float(roc_auc_score(ys, probs))\n",
    "    cnt=1\n",
    "    for _ in range(perm_B):\n",
    "        y_perm=ys.copy()\n",
    "        idx=0\n",
    "        for sid in u_subs:\n",
    "            if idx>=len(order_pairs): break\n",
    "            pidx=order_pairs[idx]\n",
    "            if len(pidx)!=2: idx+=1; continue\n",
    "            if rng.random()<0.5: y_perm[pidx]=y_perm[pidx][::-1]\n",
    "            idx+=1\n",
    "        auc_p=float(roc_auc_score(y_perm, probs))\n",
    "        if auc_p>=auc_obs: cnt+=1\n",
    "    return auc_obs, float(cnt/(perm_B+1))\n",
    "\n",
    "Xc, yc, sc = build_minimal_features(NPY_DIR)\n",
    "if Xc is not None:\n",
    "    auc_obs, p_perm = paired_auc_perm(Xc, yc, sc, perm_B=PERM_B_CLF)\n",
    "    if auc_obs is not None:\n",
    "        print(f\"[primate EC vs EO] minimal α/θ coupling → AUC={auc_obs:.3f}, p={p_perm:.4f}  (N={Xc.shape[0]} points)\")\n",
    "        pd.DataFrame([{\"AUC\":auc_obs,\"p_perm\":p_perm,\"N_points\":Xc.shape[0],\"N_subjects\":len(set(sc))}]).to_csv(\n",
    "            os.path.join(OUT_ROOT,\"primate_ec_eo_minimal.csv\"), index=False\n",
    "        )\n",
    "    else:\n",
    "        print(\"[info] Not enough class diversity to compute AUC.\")\n",
    "else:\n",
    "    print(\"[info] No EC+EO pairs found; classifier skipped.\")\n",
    "\n",
    "print(\"\\nArtifacts →\", OUT_ROOT)\n",
    "print(\"If download found nothing, set PRIMATE_DS='ds00XXXX' and re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fa8eb8b-4aef-4983-80e5-44609a4a65ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Searching OpenNeuro for primate datasets...\n",
      "[warn] search error for macaque 400 Client Error: Bad Request for url: https://openneuro.org/crn/graphql\n",
      "[warn] search error for macaca 400 Client Error: Bad Request for url: https://openneuro.org/crn/graphql\n",
      "[warn] search error for monkey 400 Client Error: Bad Request for url: https://openneuro.org/crn/graphql\n",
      "[warn] search error for nonhuman primate 400 Client Error: Bad Request for url: https://openneuro.org/crn/graphql\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'id'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_38852\\1904426823.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     99\u001b[39m     df = pd.DataFrame(rows).sort_values(\u001b[33m\"id\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    101\u001b[39m \n\u001b[32m    102\u001b[39m print(\u001b[33m\"→ Searching OpenNeuro for primate datasets...\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m df_hits = search_openneuro(SEARCH_TERMS, max_n=MAX_LIST)\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m df_hits.empty:\n\u001b[32m    105\u001b[39m     print(\u001b[33m\"No hits. Try adjusting SEARCH_TERMS or run again later.\"\u001b[39m)\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_38852\\1904426823.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(terms, max_n)\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;28;01min\u001b[39;00m uniq.values():\n\u001b[32m     96\u001b[39m         mods = [m.upper() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;28;01min\u001b[39;00m (v[\u001b[33m\"modalities\"\u001b[39m] \u001b[38;5;28;01mor\u001b[39;00m [])]\n\u001b[32m     97\u001b[39m         keep = any(m \u001b[38;5;28;01min\u001b[39;00m mods \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;28;01min\u001b[39;00m MODALITY_FILTER) \u001b[38;5;28;01mor\u001b[39;00m any(m \u001b[38;5;28;01min\u001b[39;00m v[\u001b[33m\"name\"\u001b[39m].upper() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;28;01min\u001b[39;00m MODALITY_FILTER)\n\u001b[32m     98\u001b[39m         rows.append({\u001b[33m\"id\"\u001b[39m: v[\u001b[33m\"id\"\u001b[39m], \u001b[33m\"title\"\u001b[39m: v[\u001b[33m\"name\"\u001b[39m], \u001b[33m\"modalities\"\u001b[39m: \u001b[33m\",\"\u001b[39m.join(mods), \u001b[33m\"keep\"\u001b[39m: keep})\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     df = pd.DataFrame(rows).sort_values(\u001b[33m\"id\"\u001b[39m).reset_index(drop=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\frame.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, by, axis, ascending, inplace, kind, na_position, ignore_index, key)\u001b[39m\n\u001b[32m   7192\u001b[39m             )\n\u001b[32m   7193\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m len(by):\n\u001b[32m   7194\u001b[39m             \u001b[38;5;66;03m# len(by) == 1\u001b[39;00m\n\u001b[32m   7195\u001b[39m \n\u001b[32m-> \u001b[39m\u001b[32m7196\u001b[39m             k = self._get_label_or_level_values(by[\u001b[32m0\u001b[39m], axis=axis)\n\u001b[32m   7197\u001b[39m \n\u001b[32m   7198\u001b[39m             \u001b[38;5;66;03m# need to rewrap column in Series to apply key function\u001b[39;00m\n\u001b[32m   7199\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;28;01mis\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1907\u001b[39m             values = self.xs(key, axis=other_axes[\u001b[32m0\u001b[39m])._values\n\u001b[32m   1908\u001b[39m         \u001b[38;5;28;01melif\u001b[39;00m self._is_level_reference(key, axis=axis):\n\u001b[32m   1909\u001b[39m             values = self.axes[axis].get_level_values(key)._values\n\u001b[32m   1910\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1911\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m KeyError(key)\n\u001b[32m   1912\u001b[39m \n\u001b[32m   1913\u001b[39m         \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[32m   1914\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m values.ndim > \u001b[32m1\u001b[39m:\n",
      "\u001b[31mKeyError\u001b[39m: 'id'"
     ]
    }
   ],
   "source": [
    "# === OpenNeuro NHP Finder → Download → Convert → CNT PLI Consensus + (optional) EC/EO Classifier ===\n",
    "# What this cell does:\n",
    "#  1) Queries OpenNeuro GraphQL for non-human primate (macaque/monkey) datasets with EEG/LFP/ECoG/iEEG/MEG keywords\n",
    "#  2) Prints a candidate table (ID, title, modalities). You can:\n",
    "#       - Set AUTO_SELECT_TOP = K to auto-pick top K hits\n",
    "#       - Or provide SELECTED_IDS = [\"ds00xxxx\", ...] to force specific datasets\n",
    "#  3) Downloads matching files (narrow include patterns), converts to *.npy (+ channels.txt), trims to 60 s @ 1 kHz\n",
    "#  4) Runs CNT PLI spectral-on-coassoc (k=2) for θ/α/β/γ per condition (REST/EC/EO if present), prints LOSO + perm p\n",
    "#  5) If EC+EO pairs exist → α/θ minimal classifier (paired CV + 10k perms), prints AUC + p\n",
    "#\n",
    "# Outputs → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_primate_dl\\{metrics,tables,figures}\n",
    "# Exported *.npy → C:\\Users\\caleb\\CNT_Lab\\primate_eeg\n",
    "\n",
    "import os, re, json, time, glob, requests, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, decimate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------- CONFIG ----------------\n",
    "ROOT         = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "OUT_ROOT     = os.path.join(ROOT, r\"artifacts\\pli_primate_dl\")\n",
    "DL_ROOT      = os.path.join(ROOT, \"primate_openneuro_raw\")\n",
    "NPY_DIR      = os.path.join(ROOT, \"primate_eeg\")\n",
    "OUT_TAB      = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET      = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG      = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [OUT_ROOT, OUT_TAB, OUT_MET, OUT_FIG, DL_ROOT, NPY_DIR]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# Search controls\n",
    "AUTO_SELECT_TOP = 2               # auto-pick top K datasets (set 0 to disable)\n",
    "SELECTED_IDS    = []              # or force specific OpenNeuro IDs, e.g., [\"ds004***\", \"ds00****\"]\n",
    "SEARCH_TERMS    = [\"macaque\",\"macaca\",\"monkey\",\"nonhuman primate\"]\n",
    "MODALITY_FILTER = [\"EEG\",\"ECoG\",\"iEEG\",\"LFP\",\"MEG\"]  # keep only datasets mentioning these\n",
    "MAX_LIST        = 20\n",
    "\n",
    "# Download/convert controls\n",
    "FS_TARGET   = 1000.0      # resample to 1 kHz\n",
    "SLICE_SEC   = 60          # keep 60 s per subject\n",
    "INCLUDES    = [\"*eeg*.edf\",\"*eeg*.mat\",\"*eeg*.npy\",\n",
    "               \"*lfp*.edf\",\"*lfp*.mat\",\"*lfp*.npy\",\n",
    "               \"*ecog*.edf\",\"*ecog*.mat\",\"*ecog*.npy\",\n",
    "               \"*ieeg*.edf\",\"*ieeg*.mat\",\"*ieeg*.npy\",\n",
    "               \"*meg*.fif\",\"*meg*.mat\"]\n",
    "# CNT analysis\n",
    "BANDS_HZ    = {\"theta\":(4,8),\"alpha\":(8,12),\"beta\":(13,30),\"gamma\":(30,55)}\n",
    "K_FIXED     = 2\n",
    "KNN_K       = 6\n",
    "NULL_PERMS  = 500\n",
    "CLF_PERMS   = 10000\n",
    "rng         = default_rng(13)\n",
    "\n",
    "# ---------------- 0) Install openneuro-py if needed ----------------\n",
    "try:\n",
    "    import openneuro as on\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"openneuro-py\"])\n",
    "    import openneuro as on\n",
    "\n",
    "# ---------------- 1) Search OpenNeuro via GraphQL ----------------\n",
    "GQL = \"https://openneuro.org/crn/graphql\"\n",
    "def search_openneuro(terms, max_n=MAX_LIST):\n",
    "    q = \"\"\"\n",
    "    query($query:String!, $first:Int!) {\n",
    "      datasets(query:$query, first:$first) {\n",
    "        edges { node { id created published modified public snapshots { id tag } metadata { modalities } name } }\n",
    "      }\n",
    "    }\n",
    "    \"\"\"\n",
    "    hits = []\n",
    "    for t in terms:\n",
    "        try:\n",
    "            r = requests.post(GQL, json={\"query\": q, \"variables\":{\"query\": t, \"first\": max_n}}, timeout=30)\n",
    "            r.raise_for_status()\n",
    "            data = r.json()\n",
    "            edges = data.get(\"data\",{}).get(\"datasets\",{}).get(\"edges\",[])\n",
    "            for e in edges:\n",
    "                node = e.get(\"node\",{})\n",
    "                dsid = node.get(\"id\")\n",
    "                name = node.get(\"name\") or \"\"\n",
    "                mods = node.get(\"metadata\",{}).get(\"modalities\") or []\n",
    "                hits.append({\"id\": dsid, \"name\": name, \"modalities\": mods})\n",
    "        except Exception as ex:\n",
    "            print(\"[warn] search error for\", t, ex)\n",
    "    # de-duplicate by id\n",
    "    uniq = {}\n",
    "    for h in hits:\n",
    "        uniq[h[\"id\"]] = {\"id\": h[\"id\"], \"name\": h[\"name\"], \"modalities\": h[\"modalities\"]}\n",
    "    rows = []\n",
    "    for v in uniq.values():\n",
    "        mods = [m.upper() for m in (v[\"modalities\"] or [])]\n",
    "        keep = any(m in mods for m in MODALITY_FILTER) or any(m in v[\"name\"].upper() for m in MODALITY_FILTER)\n",
    "        rows.append({\"id\": v[\"id\"], \"title\": v[\"name\"], \"modalities\": \",\".join(mods), \"keep\": keep})\n",
    "    df = pd.DataFrame(rows).sort_values(\"id\").reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "print(\"→ Searching OpenNeuro for primate datasets...\")\n",
    "df_hits = search_openneuro(SEARCH_TERMS, max_n=MAX_LIST)\n",
    "if df_hits.empty:\n",
    "    print(\"No hits. Try adjusting SEARCH_TERMS or run again later.\")\n",
    "else:\n",
    "    print(\"\\n=== Candidate NHP datasets (filtering modalities: {}) ===\".format(\",\".join(MODALITY_FILTER)))\n",
    "    print(df_hits.to_string(index=False))\n",
    "\n",
    "# Decide which to download\n",
    "to_get = []\n",
    "if SELECTED_IDS:\n",
    "    to_get = [ds for ds in SELECTED_IDS if ds in set(df_hits[\"id\"])]\n",
    "elif AUTO_SELECT_TOP > 0 and not df_hits.empty:\n",
    "    to_get = df_hits[df_hits[\"keep\"]].head(AUTO_SELECT_TOP)[\"id\"].tolist()\n",
    "print(\"\\nSelected datasets:\", to_get if to_get else \"(none)\")\n",
    "\n",
    "# ---------------- 2) Download selected datasets ----------------\n",
    "def download_openneuro(ds_id, includes):\n",
    "    print(f\"[download] {ds_id}\")\n",
    "    ok_any = False\n",
    "    for patt in includes:\n",
    "        try:\n",
    "            on.download(dataset=ds_id, target=DL_ROOT, include=[patt], strict=False)\n",
    "            print(\"   included:\", patt); ok_any = True\n",
    "        except Exception as e:\n",
    "            # harmless if pattern not present\n",
    "            pass\n",
    "    if not ok_any:\n",
    "        print(\"   (no matched files for include patterns)\")\n",
    "    return ok_any\n",
    "\n",
    "if to_get:\n",
    "    for ds in to_get:\n",
    "        download_openneuro(ds, INCLUDES)\n",
    "\n",
    "# ---------------- 3) Convert → NPY (+ channels) ----------------\n",
    "def try_load_file(fp):\n",
    "    fp_l = fp.lower()\n",
    "    if fp_l.endswith(\".edf\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, eog=False, ecg=False, emg=False, stim=False, misc=False)\n",
    "        X  = raw.get_data()\n",
    "        fs = float(raw.info[\"sfreq\"])\n",
    "        ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".mat\"):\n",
    "        from scipy.io import loadmat\n",
    "        m = loadmat(fp)\n",
    "        arr = None\n",
    "        for k,v in m.items():\n",
    "            if isinstance(v, np.ndarray) and v.ndim == 2 and (arr is None or v.size > arr.size):\n",
    "                arr = v\n",
    "        if arr is None:\n",
    "            raise RuntimeError(\"No 2D array in MAT\")\n",
    "        fs = float(m.get(\"fs\", np.array([[FS_TARGET]])).squeeze())\n",
    "        ch = [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "        return arr.astype(float), fs, ch\n",
    "    elif fp_l.endswith(\".npy\"):\n",
    "        X = np.load(fp)\n",
    "        if X.ndim != 2: raise RuntimeError(\"NPY must be [n_ch, n_t]\")\n",
    "        ch = [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "        return X.astype(float), FS_TARGET, ch\n",
    "    elif fp_l.endswith(\".fif\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_fif(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(meg=True, eeg=True, stim=False, eog=False, ecg=False, emg=False)\n",
    "        X = raw.get_data()\n",
    "        fs= float(raw.info[\"sfreq\"])\n",
    "        ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    else:\n",
    "        raise RuntimeError(f\"Unsupported file: {fp}\")\n",
    "\n",
    "def resample_if_needed(X, fs_in, fs_out):\n",
    "    if abs(fs_in - fs_out) < 1e-6:\n",
    "        return X, fs_in\n",
    "    q = int(round(fs_in / fs_out))\n",
    "    if q >= 1 and abs(fs_in / q - fs_out) < 1e-3:\n",
    "        Y = np.vstack([decimate(X[i], q, ftype=\"fir\", zero_phase=True) for i in range(X.shape[0])])\n",
    "        return Y, fs_out\n",
    "    # keep as-is if not close (or add resample_poly if you prefer)\n",
    "    return X, fs_in\n",
    "\n",
    "def export_npys_from_download(raw_root, out_dir, fs_out=FS_TARGET, slice_sec=SLICE_SEC):\n",
    "    files = []\n",
    "    for patt in INCLUDES + [\"*.edf\",\"*.mat\",\"*.npy\",\"*.fif\"]:\n",
    "        files.extend(glob.glob(os.path.join(raw_root, \"**\", patt), recursive=True))\n",
    "    files = sorted(list(set(files)))\n",
    "    out_paths = {}\n",
    "    subj_idx = 0\n",
    "    for fp in files:\n",
    "        try:\n",
    "            X, fs, ch = try_load_file(fp)\n",
    "            X, fs2 = resample_if_needed(X, fs, fs_out)\n",
    "            n_keep = int(slice_sec * fs2)\n",
    "            if X.shape[1] >= n_keep:\n",
    "                Xo = X[:, :n_keep]\n",
    "            else:\n",
    "                reps = int(np.ceil(n_keep / X.shape[1])); Xo = np.tile(X, reps)[:, :n_keep]\n",
    "            # naive condition detection\n",
    "            tag = \"REST\"\n",
    "            low = fp.lower()\n",
    "            if any(k in low for k in [\"eyesopen\",\"eo\",\"open\"]): tag = \"EO\"\n",
    "            if any(k in low for k in [\"eyesclosed\",\"ec\",\"closed\"]): tag = \"EC\"\n",
    "            base = os.path.join(out_dir, f\"subject_{subj_idx:02d}_{tag}\")\n",
    "            np.save(base+\".npy\", Xo.astype(np.float32))\n",
    "            with open(base+\".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for nm in ch: f.write(str(nm)+\"\\n\")\n",
    "            out_paths.setdefault(subj_idx, {})[tag] = base+\".npy\"\n",
    "            subj_idx += 1\n",
    "        except Exception as e:\n",
    "            # Just skip files that don't parse\n",
    "            pass\n",
    "    return out_paths\n",
    "\n",
    "paths_by_subj = export_npys_from_download(DL_ROOT, NPY_DIR)\n",
    "print(f\"[convert] prepared {len(paths_by_subj)} subjects in\", NPY_DIR)\n",
    "\n",
    "# ---------------- 4) CNT PLI + spectral-on-coassoc (k=2) ----------------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a=butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a=butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=filtfilt(b,a,X[c])\n",
    "    ph=np.angle(hilbert(Y, axis=1))\n",
    "    W=np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0.0); return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W,k=2):\n",
    "    e,v=np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=13).fit_predict(U)\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n),float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof, k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave), k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def run_pli_consensus(npy_dir):\n",
    "    subjects={}\n",
    "    for fp in sorted(glob.glob(os.path.join(npy_dir, \"subject_*_*.npy\"))):\n",
    "        m=re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "        if not m: continue\n",
    "        sid, cond = int(m.group(1)), m.group(2).upper()\n",
    "        subjects.setdefault(sid, {})[cond]=fp\n",
    "    conds=set(c for d in subjects.values() for c in d.keys())\n",
    "    if not conds:\n",
    "        print(\"[warn] No subjects found.\")\n",
    "        return\n",
    "    for cond in sorted(conds):\n",
    "        paths=[d[cond] for d in subjects.values() if cond in d]\n",
    "        if len(paths)<4:\n",
    "            print(f\"[{cond}] not enough subjects:\", len(paths)); continue\n",
    "        # first file channels\n",
    "        ch_txt = paths[0].replace(\".npy\",\".channels.txt\")\n",
    "        if os.path.exists(ch_txt):\n",
    "            with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "        else:\n",
    "            X0=np.load(paths[0], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "        rows=[]\n",
    "        for band,(lo,hi) in BANDS_HZ.items():\n",
    "            labs=[]\n",
    "            for p in paths:\n",
    "                X=np.load(p); W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); labs.append(spec_labels(W,k=K_FIXED))\n",
    "            loso, cons, co = loso_via_coassoc(labs)\n",
    "            # label-preserving null\n",
    "            null=[]\n",
    "            for _ in range(NULL_PERMS):\n",
    "                nl=[]\n",
    "                for lab in labs:\n",
    "                    uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                    idx=np.arange(len(lab)); rng.shuffle(idx)\n",
    "                    out=np.empty(len(lab),int); st=0\n",
    "                    for u,c in zip(uniq,cnts):\n",
    "                        seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                    nl.append(out)\n",
    "                _, cons_n, _ = loso_via_coassoc(nl)\n",
    "                null.append(adjusted_rand_score(cons, cons_n))\n",
    "            null=np.array(null,float)\n",
    "            p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "            # save\n",
    "            np.save(os.path.join(OUT_TAB, f\"primate__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "            np.save(os.path.join(OUT_TAB, f\"primate__{cond}__{band}__coassoc.npy\"), co)\n",
    "            with open(os.path.join(OUT_MET, f\"primate__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "                json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(paths),\"LOSO\":float(loso),\"null_mean\":float(null.mean()),\"p\":p}, f, indent=2)\n",
    "            plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc\"); plt.colorbar(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_FIG, f\"primate__{cond}__{band}__coassoc.png\"), dpi=160); plt.close()\n",
    "            rows.append([cond, band, len(paths), len(ch), float(loso), float(null.mean()), p])\n",
    "        df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"n_channels\",\"LOSO\",\"null_mean\",\"p\"])\n",
    "        df.to_csv(os.path.join(OUT_ROOT, f\"primate__{cond}__summary.csv\"), index=False)\n",
    "        print(f\"[{cond}] summary:\\n\", df.to_string(index=False))\n",
    "\n",
    "run_pli_consensus(NPY_DIR)\n",
    "\n",
    "# ---------------- 5) Optional primate EC/EO classifier (α/θ minimal) ----------------\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return float((W[within&same]).mean()) if np.any(within&same) else np.nan, \\\n",
    "           float((W[cross &same]).mean())  if np.any(cross &same)  else np.nan\n",
    "\n",
    "def build_minimal_features(npy_dir):\n",
    "    subs={}\n",
    "    for fp in sorted(glob.glob(os.path.join(npy_dir,\"subject_*_*.npy\"))):\n",
    "        m=re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "        if not m: continue\n",
    "        sid,cond=int(m.group(1)), m.group(2).upper()\n",
    "        subs.setdefault(sid,{})[cond]=fp\n",
    "    pairs={k:v for k,v in subs.items() if \"EC\" in v and \"EO\" in v}\n",
    "    if not pairs: return None,None,None\n",
    "    any_sid=next(iter(pairs))\n",
    "    ch_txt = pairs[any_sid][\"EC\"].replace(\".npy\",\".channels.txt\")\n",
    "    if os.path.exists(ch_txt):\n",
    "        with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "    else:\n",
    "        X0=np.load(pairs[any_sid][\"EC\"], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "    # L/R maps (simple: odd/even and Z)\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,name in enumerate(ch):\n",
    "        up=name.upper()\n",
    "        if re.search(r\"[A-Za-z]Z$\", name): Z.append(i)\n",
    "        else:\n",
    "            m=re.search(r\"(\\d+)$\", name)\n",
    "            if m:\n",
    "                try:\n",
    "                    d=int(m.group(1)); (L if d%2==1 else R).append(i)\n",
    "                except: Z.append(i)\n",
    "            else: Z.append(i)\n",
    "    rows=[]\n",
    "    for sid,d in pairs.items():\n",
    "        for cond,fp in d.items():\n",
    "            X=np.load(fp)\n",
    "            row={\"sid\":sid,\"cond\":0 if cond==\"EC\" else 1}\n",
    "            for band,(lo,hi) in {\"alpha\":(8,12),\"theta\":(4,8)}.items():\n",
    "                W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W, k=K_FIXED)\n",
    "                wh,chm=hemi_module_means(W,lbl,np.array(L,int),np.array(R,int))\n",
    "                row[f\"{band}_WHWM\"]=wh; row[f\"{band}_CHWM\"]=chm\n",
    "            rows.append(row)\n",
    "    df=pd.DataFrame(rows).dropna()\n",
    "    X=df[[c for c in df.columns if c.endswith(\"_WHWM\") or c.endswith(\"_CHWM\")]].to_numpy(float)\n",
    "    y=df[\"cond\"].to_numpy(int)\n",
    "    s=df[\"sid\"].to_numpy(int)\n",
    "    return X,y,s\n",
    "\n",
    "def paired_auc_perm(X,y,s,perm_B=CLF_PERMS):\n",
    "    clf=make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng=default_rng(31)\n",
    "    fold_p=[]; fold_y=[]; order=[]\n",
    "    u=sorted(set(s))\n",
    "    for sid in u:\n",
    "        mask=(s==sid)\n",
    "        if np.sum(mask)!=2: continue\n",
    "        train=(s!=sid)\n",
    "        clf.fit(X[train], y[train])\n",
    "        p=clf.predict_proba(X[mask])[:,1]\n",
    "        fold_p.append(p); fold_y.append(y[mask]); order.append(np.where(mask)[0])\n",
    "    if not fold_p: \n",
    "        print(\"[info] No EC/EO pairs; classifier skipped.\")\n",
    "        raise SystemExit\n",
    "    probs=np.concatenate(fold_p); ys=np.concatenate(fold_y)\n",
    "    auc=float(roc_auc_score(ys, probs))\n",
    "    cnt=1\n",
    "    for _ in range(perm_B):\n",
    "        yperm=ys.copy()\n",
    "        # flip within pair (we don't strictly maintain original indices, but permutation is symmetric here)\n",
    "        for i in range(0,len(yperm),2):\n",
    "            if rng.random()<0.5 and i+1<len(yperm):\n",
    "                yperm[i],yperm[i+1]=yperm[i+1],yperm[i]\n",
    "        ap=float(roc_auc_score(yperm, probs))\n",
    "        if ap>=auc: cnt+=1\n",
    "    return auc, float(cnt/(perm_B+1))\n",
    "\n",
    "try:\n",
    "    Xc,yc,sc = build_minimal_features(NPY_DIR)\n",
    "    if Xc is not None:\n",
    "        auc_obs,p_perm = paired_auc_perm(Xc,yc,sc)\n",
    "        print(f\"\\n[primate EC vs EO] minimal α/θ coupling → AUC={auc_obs:.3f}, p={p_perm:.4f}  (N={Xc.shape[0]} points)\")\n",
    "        pd.DataFrame([{\"AUC\":auc_obs,\"p_perm\":p_perm,\"N_points\":Xc.shape[0],\"N_subjects\":len(set(sc))}]).to_csv(\n",
    "            os.path.join(OUT_ROOT,\"primate_ec_eo_minimal.csv\"), index=False\n",
    "        )\n",
    "except SystemExit:\n",
    "    pass\n",
    "\n",
    "print(\"\\nArtifacts →\", OUT_ROOT)\n",
    "print(\"If no datasets downloaded, set SELECTED_IDS=['ds00XXXX', ...] or increase AUTO_SELECT_TOP, and re-run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "257ff300-5ede-4f49-aac1-b8a117dd3622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ GitHub fallback search for OpenNeuro dsIDs (no GraphQL)…\n",
      "      id                       full                                                                                                                                                        title  keep\n",
      "ds004620 OpenNeuroDatasets/ds004620                                                                                                              OpenNeuro dataset - Macaque angiography dataset False\n",
      "ds005521 OpenNeuroDatasets/ds005521                                                                                   OpenNeuro dataset - Macaque Color, Contrast, and Spatial Frequency Dataset False\n",
      "ds005590 OpenNeuroDatasets/ds005590 OpenNeuro dataset - [18F]SF51, a Novel 18F-labeled PET Radioligand for Translocator Protein 18kDa (TSPO) in Brain, Works Well in Monkeys but Fails in Humans False\n",
      "ds005619 OpenNeuroDatasets/ds005619 OpenNeuro dataset - [18F]SF51, a Novel 18F-labeled PET Radioligand for Translocator Protein 18kDa (TSPO) in Brain, Works Well in Monkeys but Fails in Humans False\n",
      "[fallback] trying fieldtrip_monkey_ecog\n",
      "[warn] GET failed: https://github.com/fieldtrip/website/raw/master/_static/download/monkey_ecog/monkey_ecog_data.zip 404 Client Error: Not Found for url: https://github.com/fieldtrip/website/raw/master/_static/download/monkey_ecog/monkey_ecog_data.zip\n",
      "   fallback failed: https://github.com/fieldtrip/website/raw/master/_static/download/monkey_ecog/monkey_ecog_data.zip\n",
      "[convert] exported 0 subjects into C:\\Users\\caleb\\CNT_Lab\\primate_eeg\n",
      "[REST] summary:\n",
      " cond  band  n_subjects  n_channels     LOSO  null_mean        p\n",
      "REST theta           8          32 1.000000   0.000330 0.001996\n",
      "REST alpha           8          32 0.653250  -0.000188 0.001996\n",
      "REST  beta           8          32 0.598839   0.000525 0.001996\n",
      "REST gamma           8          32 0.459278  -0.001784 0.001996\n",
      "\n",
      "Artifacts → C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_primate_auto\n"
     ]
    }
   ],
   "source": [
    "# === NHP datasets without GraphQL: GitHub search → OpenNeuro download (fallback to NeuroTycho/CRCNS/G-Node) ===\n",
    "# 1) Query GitHub API for OpenNeuroDatasets repos matching macaque/monkey/marmoset & EEG/LFP/ECoG/iEEG keywords.\n",
    "# 2) Download selected dsIDs via openneuro-py (no GraphQL).\n",
    "# 3) If none succeed, fallback to known public NHP ECoG/LFP (NeuroTycho tutorial bundle / CRCNS / G-Node).\n",
    "# 4) Convert to .npy + channels.txt, run PLI + spectral-on-coassoc (k=2), print LOSO + perm p; run α/θ classifier if EC/EO pairs present.\n",
    "\n",
    "import os, re, json, glob, time, io, zipfile, requests, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, decimate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "OUT_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_primate_auto\")\n",
    "DL_ROOT   = os.path.join(ROOT, \"primate_auto_raw\")\n",
    "NPY_DIR   = os.path.join(ROOT, \"primate_eeg\")\n",
    "for p in [OUT_ROOT, DL_ROOT, NPY_DIR, os.path.join(OUT_ROOT,\"tables\"), os.path.join(OUT_ROOT,\"metrics\"), os.path.join(OUT_ROOT,\"figures\")]:\n",
    "    os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# ---------- Search settings ----------\n",
    "GITHUB_SEARCH = \"https://api.github.com/search/repositories\"\n",
    "GH_QUERY      = \"org:OpenNeuroDatasets (macaque OR monkey OR marmoset) in:name,description\"\n",
    "GH_HEADERS    = {\"Accept\":\"application/vnd.github+json\"}  # add a token if you have one to raise rate-limit\n",
    "MAX_REPOS     = 20\n",
    "MOD_KEYWORDS  = [\"EEG\",\"ECOG\",\"IEEG\",\"LFP\",\"MEG\"]\n",
    "\n",
    "# ---------- Conversion / analysis settings ----------\n",
    "FS_TARGET   = 1000.0\n",
    "SLICE_SEC   = 60\n",
    "INCLUDES    = [\"*eeg*.edf\",\"*eeg*.npy\",\"*eeg*.mat\",\n",
    "               \"*lfp*.edf\",\"*lfp*.npy\",\"*lfp*.mat\",\n",
    "               \"*ecog*.edf\",\"*ecog*.npy\",\"*ecog*.mat\",\n",
    "               \"*ieeg*.edf\",\"*ieeg*.npy\",\"*ieeg*.mat\"]\n",
    "BANDS_HZ    = {\"theta\":(4,8), \"alpha\":(8,12), \"beta\":(13,30), \"gamma\":(30,55)}\n",
    "K_FIXED     = 2\n",
    "KNN_K       = 6\n",
    "NULL_PERMS  = 500\n",
    "CLF_PERMS   = 10000\n",
    "rng         = default_rng(13)\n",
    "\n",
    "# ---------- tiny helpers ----------\n",
    "def safe_get(url, params=None, headers=None, timeout=30):\n",
    "    try:\n",
    "        r = requests.get(url, params=params, headers=headers, timeout=timeout)\n",
    "        r.raise_for_status()\n",
    "        return r\n",
    "    except Exception as e:\n",
    "        print(\"[warn] GET failed:\", url, e)\n",
    "        return None\n",
    "\n",
    "def search_github_openneuro():\n",
    "    r = safe_get(GITHUB_SEARCH, params={\"q\": GH_QUERY, \"per_page\": MAX_REPOS}, headers=GH_HEADERS)\n",
    "    if not r: return pd.DataFrame()\n",
    "    data = r.json()\n",
    "    items = data.get(\"items\", [])\n",
    "    rows=[]\n",
    "    for it in items:\n",
    "        rid = it.get(\"name\",\"\")\n",
    "        full = it.get(\"full_name\",\"\")\n",
    "        desc = it.get(\"description\") or \"\"\n",
    "        keep = any(k in desc.upper() for k in MOD_KEYWORDS)\n",
    "        rows.append({\"id\": rid, \"full\": full, \"title\": desc, \"keep\": keep})\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "print(\"→ GitHub fallback search for OpenNeuro dsIDs (no GraphQL)…\")\n",
    "df_hits = search_github_openneuro()\n",
    "if df_hits.empty:\n",
    "    print(\"No OpenNeuro hits via GitHub API; will try fallback datasets.\")\n",
    "else:\n",
    "    print(df_hits.to_string(index=False))\n",
    "\n",
    "# ---------- download via openneuro-py by dsID ----------\n",
    "def on_download(ds_id, target, patterns):\n",
    "    try:\n",
    "        import openneuro as on\n",
    "    except Exception:\n",
    "        import sys, subprocess\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"openneuro-py\"])\n",
    "        import openneuro as on\n",
    "    print(f\"[download] {ds_id}\")\n",
    "    ok=False\n",
    "    for patt in patterns:\n",
    "        try:\n",
    "            on.download(dataset=ds_id, target=target, include=[patt], strict=False)\n",
    "            print(\"   included:\", patt); ok=True\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not ok: print(\"   (no matched files)\")\n",
    "    return ok\n",
    "\n",
    "selected = df_hits[df_hits[\"keep\"]].head(2)[\"id\"].tolist() if not df_hits.empty else []\n",
    "if selected:\n",
    "    for ds in selected:\n",
    "        on_download(ds, DL_ROOT, INCLUDES)\n",
    "\n",
    "# ---------- Fallback: NeuroTycho / CRCNS / G-Node -----------\n",
    "# NeuroTycho demo ECoG (from FieldTrip tutorial mirrors) – small zip hosted by FieldTrip (public)\n",
    "# If the FieldTrip link changes, you can place any monkey ECoG zip in DL_ROOT and it will be picked up below\n",
    "FALLBACKS = [\n",
    "    # (name, direct-zip-url)\n",
    "    (\"fieldtrip_monkey_ecog\", \"https://github.com/fieldtrip/website/raw/master/_static/download/monkey_ecog/monkey_ecog_data.zip\"),\n",
    "]\n",
    "for name, url in FALLBACKS:\n",
    "    if not glob.glob(os.path.join(DL_ROOT, name+\"*\")):\n",
    "        print(f\"[fallback] trying {name}\")\n",
    "        r = safe_get(url)\n",
    "        if r and r.status_code==200:\n",
    "            zf = zipfile.ZipFile(io.BytesIO(r.content))\n",
    "            zf.extractall(os.path.join(DL_ROOT, name))\n",
    "            print(\"   extracted to\", os.path.join(DL_ROOT, name))\n",
    "        else:\n",
    "            print(\"   fallback failed:\", url)\n",
    "\n",
    "# ---------- Convert whatever we have to NPY ----------\n",
    "def try_load_file(fp):\n",
    "    fp_l = fp.lower()\n",
    "    if fp_l.endswith(\".edf\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, eog=False, ecg=False, emg=False, stim=False, misc=False)\n",
    "        X = raw.get_data(); fs = float(raw.info[\"sfreq\"]); ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".fif\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_fif(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(meg=True, eeg=True, stim=False)\n",
    "        X = raw.get_data(); fs = float(raw.info[\"sfreq\"]); ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".mat\"):\n",
    "        from scipy.io import loadmat\n",
    "        m = loadmat(fp)\n",
    "        arr=None\n",
    "        for k,v in m.items():\n",
    "            if isinstance(v,np.ndarray) and v.ndim==2 and (arr is None or v.size>arr.size):\n",
    "                arr=v\n",
    "        if arr is None: raise RuntimeError(\"No 2D array in MAT\")\n",
    "        fs = float(m.get(\"fs\", np.array([[FS_TARGET]])).squeeze())\n",
    "        ch = [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "        return arr.astype(float), fs, ch\n",
    "    elif fp_l.endswith(\".npy\"):\n",
    "        X = np.load(fp)\n",
    "        if X.ndim!=2: raise RuntimeError(\"NPY not 2D\")\n",
    "        ch = [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "        return X.astype(float), FS_TARGET, ch\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported file: \"+fp)\n",
    "\n",
    "def resample_if_needed(X, fs_in, fs_out):\n",
    "    if abs(fs_in - fs_out) < 1e-6: return X, fs_in\n",
    "    q = int(round(fs_in / fs_out))\n",
    "    if q>=1 and abs(fs_in/q - fs_out) < 1e-3:\n",
    "        Y = np.vstack([decimate(X[i], q, ftype='fir', zero_phase=True) for i in range(X.shape[0])])\n",
    "        return Y, fs_out\n",
    "    return X, fs_in\n",
    "\n",
    "def export_npys(raw_root, out_dir, slice_sec=SLICE_SEC):\n",
    "    files=[]\n",
    "    for patt in INCLUDES + [\"*.edf\",\"*.fif\",\"*.mat\",\"*.npy\"]:\n",
    "        files += glob.glob(os.path.join(raw_root,\"**\",patt), recursive=True)\n",
    "    files = sorted(list(set(files)))\n",
    "    out_paths = {}\n",
    "    idx = 0\n",
    "    for fp in files:\n",
    "        try:\n",
    "            X, fs, ch = try_load_file(fp)\n",
    "            X, fs2 = resample_if_needed(X, fs, FS_TARGET)\n",
    "            n_keep = int(slice_sec * fs2)\n",
    "            Xo = X[:, :n_keep] if X.shape[1]>=n_keep else np.tile(X, int(np.ceil(n_keep/X.shape[1])))[:, :n_keep]\n",
    "            # condition detection (best effort)\n",
    "            low = fp.lower(); tag=\"REST\"\n",
    "            if any(k in low for k in [\"eyesopen\",\"eo\",\"open\"]): tag=\"EO\"\n",
    "            if any(k in low for k in [\"eyesclosed\",\"ec\",\"closed\"]): tag=\"EC\"\n",
    "            base = os.path.join(out_dir, f\"subject_{idx:02d}_{tag}\")\n",
    "            np.save(base+\".npy\", Xo.astype(np.float32))\n",
    "            with open(base+\".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for nm in ch: f.write(str(nm)+\"\\n\")\n",
    "            out_paths.setdefault(idx,{})[tag] = base+\".npy\"\n",
    "            idx += 1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return out_paths\n",
    "\n",
    "paths = export_npys(DL_ROOT, NPY_DIR)\n",
    "print(f\"[convert] exported {len(paths)} subjects into\", NPY_DIR)\n",
    "\n",
    "# ---------- CNT PLI + spectral-on-coassoc ----------\n",
    "OUT_TAB = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG = os.path.join(OUT_ROOT, \"figures\")\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a=butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=filtfilt(b,a,X[c])\n",
    "    ph=np.angle(hilbert(Y, axis=1))\n",
    "    W=np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W,k=2):\n",
    "    e,v=np.linalg.eigh(lap(W))\n",
    "    U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=13).fit_predict(U)\n",
    "\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n), float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof,k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave),k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "# group by condition\n",
    "subjects={}\n",
    "for fp in sorted(glob.glob(os.path.join(NPY_DIR,\"subject_*_*.npy\"))):\n",
    "    m=re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "    if not m: continue\n",
    "    sid,cond=int(m.group(1)), m.group(2).upper()\n",
    "    subjects.setdefault(sid,{})[cond]=fp\n",
    "\n",
    "conds=set(c for d in subjects.values() for c in d.keys())\n",
    "if not conds:\n",
    "    print(\"[warn] No NHP files parsed. Try increasing includes or use a specific dataset.\")\n",
    "else:\n",
    "    for cond in sorted(conds):\n",
    "        paths_c=[d[cond] for d in subjects.values() if cond in d]\n",
    "        if len(paths_c)<4:\n",
    "            print(f\"[{cond}] not enough subjects:\", len(paths_c)); continue\n",
    "        # first file channels for n_ch display\n",
    "        ch_txt=paths_c[0].replace(\".npy\",\".channels.txt\")\n",
    "        if os.path.exists(ch_txt):\n",
    "            with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "        else:\n",
    "            X0=np.load(paths_c[0], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "        rows=[]\n",
    "        for band,(lo,hi) in BANDS_HZ.items():\n",
    "            labs=[]\n",
    "            for p in paths_c:\n",
    "                X=np.load(p); W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); labs.append(spec_labels(W,k=K_FIXED))\n",
    "            loso, cons, co = loso_via_coassoc(labs)\n",
    "            null=[]\n",
    "            for _ in range(NULL_PERMS):\n",
    "                nl=[]\n",
    "                for lab in labs:\n",
    "                    uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                    idx=np.arange(len(lab)); rng.shuffle(idx)\n",
    "                    out=np.empty(len(lab),int); st=0\n",
    "                    for u,c in zip(uniq,cnts):\n",
    "                        seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                    nl.append(out)\n",
    "                _, cons_n, _ = loso_via_coassoc(nl)\n",
    "                null.append(adjusted_rand_score(cons, cons_n))\n",
    "            null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "            # save\n",
    "            np.save(os.path.join(OUT_ROOT,\"tables\",f\"primate__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "            np.save(os.path.join(OUT_ROOT,\"tables\",f\"primate__{cond}__{band}__coassoc.npy\"), co)\n",
    "            with open(os.path.join(OUT_ROOT,\"metrics\",f\"primate__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "                json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(paths_c),\"LOSO\":float(loso),\"null_mean\":float(null.mean()),\"p\":p}, f, indent=2)\n",
    "            plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc\"); plt.colorbar(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_ROOT,\"figures\",f\"primate__{cond}__{band}__coassoc.png\"), dpi=160); plt.close()\n",
    "            rows.append([cond, band, len(paths_c), len(ch), float(loso), float(null.mean()), p])\n",
    "        df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"n_channels\",\"LOSO\",\"null_mean\",\"p\"])\n",
    "        df.to_csv(os.path.join(OUT_ROOT, f\"primate__{cond}__summary.csv\"), index=False)\n",
    "        print(f\"[{cond}] summary:\\n\", df.to_string(index=False))\n",
    "\n",
    "# ---------- α/θ minimal classifier if EC + EO pairs ----------\n",
    "pairs={k:v for k,v in subjects.items() if \"EC\" in v and \"EO\" in v}\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return float((W[within&same]).mean()) if np.any(within&same) else np.nan, \\\n",
    "           float((W[cross &same]).mean())  if np.any(cross &same)  else np.nan\n",
    "\n",
    "def build_minimal_features(pairs):\n",
    "    # map L/R by odd/even or midline; if no numbers, split halves\n",
    "    any_sid = next(iter(pairs.keys()))\n",
    "    ch_txt = pairs[any_sid][\"EC\"].replace(\".npy\",\".channels.txt\")\n",
    "    if os.path.exists(ch_txt):\n",
    "        with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "    else:\n",
    "        X0=np.load(pairs[any_sid][\"EC\"], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,name in enumerate(ch):\n",
    "        if re.search(r\"[A-Za-z]Z$\", name): Z.append(i)\n",
    "        else:\n",
    "            m=re.search(r\"(\\d+)$\", name)\n",
    "            if m:\n",
    "                try:\n",
    "                    d=int(m.group(1)); (L if d%2==1 else R).append(i)\n",
    "                except: Z.append(i)\n",
    "            else:\n",
    "                # fallback: split half\n",
    "                if i < len(ch)//2: L.append(i)\n",
    "                else: R.append(i)\n",
    "    rows=[]\n",
    "    for sid,d in pairs.items():\n",
    "        for cond,fp in d.items():\n",
    "            X=np.load(fp)\n",
    "            row={\"sid\":sid, \"cond\": 0 if cond==\"EC\" else 1}\n",
    "            for band,(lo,hi) in {\"alpha\":(8,12),\"theta\":(4,8)}.items():\n",
    "                W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W,k=K_FIXED)\n",
    "                wh,chm = hemi_module_means(W, lbl, np.array(L,int), np.array(R,int))\n",
    "                row[f\"{band}_WHWM\"]=wh; row[f\"{band}_CHWM\"]=chm\n",
    "            rows.append(row)\n",
    "    df=pd.DataFrame(rows).dropna()\n",
    "    X=df[[c for c in df.columns if c.endswith(\"_WHWM\") or c.endswith(\"_CHWM\")]].to_numpy(float)\n",
    "    y=df[\"cond\"].to_numpy(int)\n",
    "    s=df[\"sid\"].to_numpy(int)\n",
    "    return X,y,s\n",
    "\n",
    "def paired_auc_perm(X,y,s,perm_B=CLF_PERMS):\n",
    "    clf=make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng=default_rng(31)\n",
    "    fold_p=[]; fold_y=[]; order=[]\n",
    "    for sid in sorted(set(s)):\n",
    "        mask=(s==sid)\n",
    "        if np.sum(mask)!=2: continue\n",
    "        clf.fit(X[~mask], y[~mask])\n",
    "        p=clf.predict_proba(X[mask])[:,1]\n",
    "        fold_p.append(p); fold_y.append(y[mask]); order.append(np.where(mask)[0])\n",
    "    if not fold_p:\n",
    "        print(\"[info] No EC/EO pairs; classifier skipped.\"); \n",
    "    else:\n",
    "        probs=np.concatenate(fold_p); ys=np.concatenate(fold_y)\n",
    "        auc=float(roc_auc_score(ys, probs))\n",
    "        cnt=1\n",
    "        for _ in range(perm_B):\n",
    "            yperm=ys.copy()\n",
    "            for i in range(0,len(yperm),2):\n",
    "                if rng.random()<0.5 and i+1<len(yperm):\n",
    "                    yperm[i], yperm[i+1] = yperm[i+1], yperm[i]\n",
    "            ap=float(roc_auc_score(yperm, probs))\n",
    "            if ap>=auc: cnt+=1\n",
    "        p=float(cnt/(perm_B+1))\n",
    "        print(f\"[NHP EC vs EO] minimal α/θ coupling → AUC={auc:.3f}, p={p:.4f}  (N={len(ys)} test points)\")\n",
    "        pd.DataFrame([{\"AUC\":auc,\"p_perm\":p,\"N_points\":len(ys),\"N_subjects\":len(set(s))}]).to_csv(\n",
    "            os.path.join(OUT_ROOT,\"primate_ec_eo_minimal.csv\"), index=False\n",
    "        )\n",
    "\n",
    "if pairs:\n",
    "    Xc,yc,sc = build_minimal_features(pairs)\n",
    "    paired_auc_perm(Xc,yc,sc)\n",
    "\n",
    "print(\"\\nArtifacts →\", OUT_ROOT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a86e78d7-1c5b-41e9-a0a1-1f4ea3fd064f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Downloading NHP files ==\n",
      "[convert] exported 0 subjects → C:\\Users\\caleb\\CNT_Lab\\primate_eeg\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 239\u001b[39m\n\u001b[32m    237\u001b[39m             seg=idx[st:st+c]; out[seg]=u; st+=c\n\u001b[32m    238\u001b[39m         nl.append(out)\n\u001b[32m--> \u001b[39m\u001b[32m239\u001b[39m     _, cons_n, _ = \u001b[43mloso_via_coassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    240\u001b[39m     null.append(adjusted_rand_score(cons, cons_n))\n\u001b[32m    241\u001b[39m null=np.array(null,\u001b[38;5;28mfloat\u001b[39m); p=\u001b[38;5;28mfloat\u001b[39m((np.sum(null>=loso)+\u001b[32m1\u001b[39m)/(\u001b[38;5;28mlen\u001b[39m(null)+\u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 197\u001b[39m, in \u001b[36mloso_via_coassoc\u001b[39m\u001b[34m(label_list)\u001b[39m\n\u001b[32m    195\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_list)):\n\u001b[32m    196\u001b[39m     leave=[lab \u001b[38;5;28;01mfor\u001b[39;00m i,lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(label_list) \u001b[38;5;28;01mif\u001b[39;00m i!=s]\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     cons_l=\u001b[43mspec_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcoassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleave\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    198\u001b[39m     vals.append(adjusted_rand_score(cons, cons_l))\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.median(vals)), cons, cof\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 184\u001b[39m, in \u001b[36mspec_labels\u001b[39m\u001b[34m(W, k)\u001b[39m\n\u001b[32m    182\u001b[39m e,v=np.linalg.eigh(lap(W)); U=v[:,\u001b[32m1\u001b[39m:k] \u001b[38;5;28;01mif\u001b[39;00m k>\u001b[32m1\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m v[:,:\u001b[32m1\u001b[39m]\n\u001b[32m    183\u001b[39m U/= (np.linalg.norm(U, axis=\u001b[32m1\u001b[39m, keepdims=\u001b[38;5;28;01mTrue\u001b[39;00m)+\u001b[32m1e-12\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mKMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_clusters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_init\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m13\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mU\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1064\u001b[39m, in \u001b[36m_BaseKMeans.fit_predict\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1041\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, sample_weight=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1042\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute cluster centers and predict cluster index for each sample.\u001b[39;00m\n\u001b[32m   1043\u001b[39m \n\u001b[32m   1044\u001b[39m \u001b[33;03m    Convenience method; equivalent to calling fit(X) followed by\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1062\u001b[39m \u001b[33;03m        Index of the cluster each sample belongs to.\u001b[39;00m\n\u001b[32m   1063\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1064\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m.labels_\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\base.py:1365\u001b[39m, in \u001b[36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(estimator, *args, **kwargs)\u001b[39m\n\u001b[32m   1358\u001b[39m     estimator._validate_params()\n\u001b[32m   1360\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m   1361\u001b[39m     skip_parameter_validation=(\n\u001b[32m   1362\u001b[39m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m   1363\u001b[39m     )\n\u001b[32m   1364\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1510\u001b[39m, in \u001b[36mKMeans.fit\u001b[39m\u001b[34m(self, X, y, sample_weight)\u001b[39m\n\u001b[32m   1507\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mInitialization complete\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1509\u001b[39m \u001b[38;5;66;03m# run a k-means once\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1510\u001b[39m labels, inertia, centers, n_iter_ = \u001b[43mkmeans_single\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1513\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcenters_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1514\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_iter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1515\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1516\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_tol\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1517\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_n_threads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1518\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1520\u001b[39m \u001b[38;5;66;03m# determine if these results are the best so far\u001b[39;00m\n\u001b[32m   1521\u001b[39m \u001b[38;5;66;03m# we chose a new run if it has a better inertia and the clustering is\u001b[39;00m\n\u001b[32m   1522\u001b[39m \u001b[38;5;66;03m# different from the best so far (it's possible that the inertia is\u001b[39;00m\n\u001b[32m   1523\u001b[39m \u001b[38;5;66;03m# slightly better even if the clustering is the same with potentially\u001b[39;00m\n\u001b[32m   1524\u001b[39m \u001b[38;5;66;03m# permuted labels, due to rounding errors)\u001b[39;00m\n\u001b[32m   1525\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m best_inertia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   1526\u001b[39m     inertia < best_inertia\n\u001b[32m   1527\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _is_same_clustering(labels, best_labels, \u001b[38;5;28mself\u001b[39m.n_clusters)\n\u001b[32m   1528\u001b[39m ):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\utils\\parallel.py:173\u001b[39m, in \u001b[36m_threadpool_controller_decorator.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    171\u001b[39m controller = _get_threadpool_controller()\n\u001b[32m    172\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m controller.limit(limits=limits, user_api=user_api):\n\u001b[32m--> \u001b[39m\u001b[32m173\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:750\u001b[39m, in \u001b[36m_kmeans_single_lloyd\u001b[39m\u001b[34m(X, sample_weight, centers_init, max_iter, verbose, tol, n_threads)\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict_convergence:\n\u001b[32m    737\u001b[39m     \u001b[38;5;66;03m# rerun E-step so that predicted labels match cluster centers\u001b[39;00m\n\u001b[32m    738\u001b[39m     lloyd_iter(\n\u001b[32m    739\u001b[39m         X,\n\u001b[32m    740\u001b[39m         sample_weight,\n\u001b[32m   (...)\u001b[39m\u001b[32m    747\u001b[39m         update_centers=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    748\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m750\u001b[39m inertia = \u001b[43m_inertia\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_threads\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m labels, inertia, centers, i + \u001b[32m1\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === NHP CNT Pipeline: Paste URLs → Download → Convert → PLI Consensus + Optional EC/EO Classifier ===\n",
    "import os, re, io, glob, json, zipfile, requests, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, decimate\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, adjusted_rand_score\n",
    "\n",
    "# ---- 1) Paste direct URLs here (ZIP, MAT, NPY, EDF, FIF) ----\n",
    "URLS = [\n",
    "    # EXAMPLES (replace with real links you choose):\n",
    "    # \"https://zenodo.org/record/XXXXX/files/monkey_ecog_subject1.zip\",\n",
    "    # \"https://yourlab.org/data/macaque_LFP_sessionA.mat\",\n",
    "    # \"https://openneuro.org/api/…/sub-XX_task-rest_meg.fif\"   # direct file link\n",
    "]\n",
    "# If you already downloaded files, put their local paths here:\n",
    "LOCAL_FILES = [\n",
    "    # r\"C:\\path\\to\\monkey_ecog_data.zip\",\n",
    "    # r\"C:\\path\\to\\macaque_lfp_sessionA.mat\"\n",
    "]\n",
    "\n",
    "# ---- 2) Settings (safe defaults) ----\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DL_ROOT   = os.path.join(ROOT, \"primate_url_raw\")\n",
    "NPY_DIR   = os.path.join(ROOT, \"primate_eeg\")\n",
    "OUT_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_primate_url\")\n",
    "OUT_TAB   = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET   = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG   = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [DL_ROOT, NPY_DIR, OUT_ROOT, OUT_TAB, OUT_MET, OUT_FIG]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "FS_TARGET = 1000.0      # resample target (Hz)\n",
    "SLICE_SEC = 60          # seconds per subject\n",
    "BANDS_HZ  = {\"theta\":(4,8), \"alpha\":(8,12), \"beta\":(13,30), \"gamma\":(30,55)}\n",
    "K_FIXED   = 2\n",
    "KNN_K     = 6\n",
    "NULL_PERMS= 500\n",
    "CLF_PERMS = 10000\n",
    "rng       = default_rng(13)\n",
    "\n",
    "# ---- Downloader ----\n",
    "def dl(url, out_dir=DL_ROOT):\n",
    "    try:\n",
    "        r = requests.get(url, timeout=120)\n",
    "        r.raise_for_status()\n",
    "        fname = re.sub(r'[^A-Za-z0-9._-]+', '_', url.split('/')[-1]) or \"file\"\n",
    "        path  = os.path.join(out_dir, fname)\n",
    "        with open(path, \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "        print(\"Downloaded:\", path)\n",
    "        # auto-extract ZIPs\n",
    "        if path.lower().endswith(\".zip\"):\n",
    "            with zipfile.ZipFile(path, \"r\") as zf:\n",
    "                zf.extractall(out_dir)\n",
    "            print(\"Extracted:\", path)\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(\"[warn] download failed:\", url, e)\n",
    "        return False\n",
    "\n",
    "print(\"== Downloading NHP files ==\")\n",
    "for u in URLS:\n",
    "    dl(u)\n",
    "# Copy local files (or just rely on conversion step to find them)\n",
    "for lf in LOCAL_FILES:\n",
    "    if os.path.exists(lf):\n",
    "        base = os.path.join(DL_ROOT, os.path.basename(lf))\n",
    "        if lf != base:\n",
    "            try:\n",
    "                with open(lf, \"rb\") as fin, open(base, \"wb\") as fout:\n",
    "                    fout.write(fin.read())\n",
    "                print(\"Registered local file:\", base)\n",
    "            except Exception as e:\n",
    "                print(\"[warn] could not register\", lf, e)\n",
    "\n",
    "# ---- 3) Convert → NPY + channels.txt ----\n",
    "def try_load_file(fp):\n",
    "    fp_l = fp.lower()\n",
    "    if fp_l.endswith(\".edf\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(eeg=True, eog=False, ecg=False, emg=False, stim=False, misc=False)\n",
    "        X  = raw.get_data(); fs = float(raw.info[\"sfreq\"]); ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".fif\"):\n",
    "        try:\n",
    "            import mne\n",
    "        except Exception:\n",
    "            import sys, subprocess\n",
    "            subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "            import mne\n",
    "        raw = mne.io.read_raw_fif(fp, preload=True, verbose=\"ERROR\")\n",
    "        raw.pick_types(meg=True, eeg=True, stim=False)\n",
    "        X  = raw.get_data(); fs = float(raw.info[\"sfreq\"]); ch = list(raw.ch_names)\n",
    "        return X, fs, ch\n",
    "    elif fp_l.endswith(\".mat\"):\n",
    "        from scipy.io import loadmat\n",
    "        m = loadmat(fp)\n",
    "        arr=None\n",
    "        for k,v in m.items():\n",
    "            if isinstance(v,np.ndarray) and v.ndim==2 and (arr is None or v.size>arr.size): arr=v\n",
    "        if arr is None: raise RuntimeError(\"No 2D array in MAT\")\n",
    "        fs = float(m.get(\"fs\", np.array([[FS_TARGET]])).squeeze())\n",
    "        ch = [f\"ch{i}\" for i in range(arr.shape[0])]\n",
    "        return arr.astype(float), fs, ch\n",
    "    elif fp_l.endswith(\".npy\"):\n",
    "        X = np.load(fp)\n",
    "        if X.ndim!=2: raise RuntimeError(\"NPY not 2D\")\n",
    "        ch = [f\"ch{i}\" for i in range(X.shape[0])]\n",
    "        return X.astype(float), FS_TARGET, ch\n",
    "    else:\n",
    "        raise RuntimeError(\"Unsupported file: \"+fp)\n",
    "\n",
    "def resample_if_needed(X, fs_in, fs_out):\n",
    "    if abs(fs_in - fs_out) < 1e-6: return X, fs_in\n",
    "    q = int(round(fs_in / fs_out))\n",
    "    if q>=1 and abs(fs_in/q - fs_out) < 1e-3:\n",
    "        Y = np.vstack([decimate(X[i], q, ftype='fir', zero_phase=True) for i in range(X.shape[0])])\n",
    "        return Y, fs_out\n",
    "    return X, fs_in\n",
    "\n",
    "def export_npys(raw_root, out_dir):\n",
    "    files=[]\n",
    "    for patt in [\"*.edf\",\"*.fif\",\"*.mat\",\"*.npy\"]:\n",
    "        files += glob.glob(os.path.join(raw_root,\"**\",patt), recursive=True)\n",
    "    files = sorted(list(set(files)))\n",
    "    idx=0; out={}\n",
    "    for fp in files:\n",
    "        try:\n",
    "            X, fs, ch = try_load_file(fp)\n",
    "            X, fs2 = resample_if_needed(X, fs, FS_TARGET)\n",
    "            n_keep  = int(SLICE_SEC * fs2)\n",
    "            Xo      = X[:, :n_keep] if X.shape[1]>=n_keep else np.tile(X, int(np.ceil(n_keep/X.shape[1])))[:, :n_keep]\n",
    "            # condition tokens (best effort)\n",
    "            low = fp.lower(); tag=\"REST\"\n",
    "            if any(k in low for k in [\"eyesopen\",\"eo\",\"open\"]): tag=\"EO\"\n",
    "            if any(k in low for k in [\"eyesclosed\",\"ec\",\"closed\"]): tag=\"EC\"\n",
    "            base = os.path.join(out_dir, f\"subject_{idx:02d}_{tag}\")\n",
    "            np.save(base+\".npy\", Xo.astype(np.float32))\n",
    "            with open(base+\".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "                for nm in ch: f.write(str(nm)+\"\\n\")\n",
    "            out.setdefault(idx,{})[tag]=base+\".npy\"\n",
    "            idx+=1\n",
    "        except Exception as e:\n",
    "            pass\n",
    "    return out\n",
    "\n",
    "paths = export_npys(DL_ROOT, NPY_DIR)\n",
    "print(f\"[convert] exported {len(paths)} subjects →\", NPY_DIR)\n",
    "\n",
    "# ---- 4) PLI + spectral-on-coassoc (k=2) ----\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a=butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a=butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=filtfilt(b,a,X[c])\n",
    "    ph=np.angle(hilbert(Y, axis=1))\n",
    "    W=np.zeros((n,n),float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W,k=2):\n",
    "    e,v=np.linalg.eigh(lap(W)); U=v[:,1:k] if k>1 else v[:,:1]\n",
    "    U/= (np.linalg.norm(U, axis=1, keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=13).fit_predict(U)\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n),float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof,k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave),k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "subjects={}\n",
    "for fp in sorted(glob.glob(os.path.join(NPY_DIR,\"subject_*_*.npy\"))):\n",
    "    m=re.search(r\"subject_(\\d+)_(\\w+)\\.npy$\", fp)\n",
    "    if not m: continue\n",
    "    sid,cond=int(m.group(1)), m.group(2).upper()\n",
    "    subjects.setdefault(sid,{})[cond]=fp\n",
    "\n",
    "conds=set(c for d in subjects.values() for c in d.keys())\n",
    "if not conds:\n",
    "    print(\"[warn] No files found after download. Paste at least one URL to a NHP ZIP/MAT/NPY/EDF/FIF and re-run.\")\n",
    "else:\n",
    "    for cond in sorted(conds):\n",
    "        paths_c=[d[cond] for d in subjects.values() if cond in d]\n",
    "        if len(paths_c)<4:\n",
    "            print(f\"[{cond}] not enough subjects:\", len(paths_c)); continue\n",
    "        # channel count (first file)\n",
    "        ch_txt = paths_c[0].replace(\".npy\",\".channels.txt\")\n",
    "        if os.path.exists(ch_txt):\n",
    "            with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "        else:\n",
    "            X0=np.load(paths_c[0], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "        rows=[]\n",
    "        for band,(lo,hi) in BANDS_HZ.items():\n",
    "            labs=[]\n",
    "            for p in paths_c:\n",
    "                X=np.load(p); W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); labs.append(spec_labels(W,k=K_FIXED))\n",
    "            loso, cons, co = loso_via_coassoc(labs)\n",
    "            # null (label-preserving)\n",
    "            null=[]\n",
    "            for _ in range(NULL_PERMS):\n",
    "                nl=[]\n",
    "                for lab in labs:\n",
    "                    uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                    idx=np.arange(len(lab)); rng.shuffle(idx)\n",
    "                    out=np.empty(len(lab),int); st=0\n",
    "                    for u,c in zip(uniq,cnts):\n",
    "                        seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                    nl.append(out)\n",
    "                _, cons_n, _ = loso_via_coassoc(nl)\n",
    "                null.append(adjusted_rand_score(cons, cons_n))\n",
    "            null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "            np.save(os.path.join(OUT_TAB,f\"primate__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "            np.save(os.path.join(OUT_TAB,f\"primate__{cond}__{band}__coassoc.npy\"), co)\n",
    "            with open(os.path.join(OUT_MET,f\"primate__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "                json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(paths_c),\"LOSO\":float(loso),\"p\":p}, f, indent=2)\n",
    "            plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc\"); plt.colorbar(); plt.tight_layout()\n",
    "            plt.savefig(os.path.join(OUT_FIG,f\"primate__{cond}__{band}__coassoc.png\"), dpi=160); plt.close()\n",
    "            rows.append([cond, band, len(paths_c), len(ch), float(loso), p])\n",
    "        df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"n_channels\",\"LOSO\",\"p\"])\n",
    "        df.to_csv(os.path.join(OUT_ROOT,f\"primate__{cond}__summary.csv\"), index=False)\n",
    "        print(f\"[{cond}] summary:\\n\", df.to_string(index=False))\n",
    "\n",
    "# ---- 5) α/θ minimal classifier if EC+EO pairs exist ----\n",
    "pairs={k:v for k,v in subjects.items() if \"EC\" in v and \"EO\" in v}\n",
    "def hemi_module_means(W, labels, L, R):\n",
    "    n=len(labels)\n",
    "    Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L,L)]=True\n",
    "    Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R,R)]=True\n",
    "    within=Lmask|Rmask\n",
    "    cross =np.zeros((n,n),bool); cross[np.ix_(L,R)]=True; cross[np.ix_(R,L)]=True\n",
    "    same  =labels[:,None]==labels[None,:]\n",
    "    for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "    return float((W[within&same]).mean()) if np.any(within&same) else np.nan, \\\n",
    "           float((W[cross &same]).mean())  if np.any(cross &same)  else np.nan\n",
    "\n",
    "def build_minimal_features(pairs):\n",
    "    any_sid=next(iter(pairs))\n",
    "    ch_txt=pairs[any_sid][\"EC\"].replace(\".npy\",\".channels.txt\")\n",
    "    if os.path.exists(ch_txt):\n",
    "        with open(ch_txt,\"r\",encoding=\"utf-8\") as f: ch=[ln.strip() for ln in f if ln.strip()]\n",
    "    else:\n",
    "        X0=np.load(pairs[any_sid][\"EC\"], mmap_mode=\"r\"); ch=[f\"ch{i}\" for i in range(X0.shape[0])]\n",
    "    # quick L/R split (odd/even digit else half/half)\n",
    "    L,R=[],[]\n",
    "    for i,name in enumerate(ch):\n",
    "        m=re.search(r\"(\\d+)$\", name)\n",
    "        if m:\n",
    "            d=int(m.group(1)); (L if d%2==1 else R).append(i)\n",
    "        else:\n",
    "            (L if i<len(ch)//2 else R).append(i)\n",
    "    rows=[]\n",
    "    for sid,d in pairs.items():\n",
    "        for cond,fp in d.items():\n",
    "            X=np.load(fp)\n",
    "            row={\"sid\":sid, \"cond\":0 if cond==\"EC\" else 1}\n",
    "            for band,(lo,hi) in {\"alpha\":(8,12),\"theta\":(4,8)}.items():\n",
    "                W=pli_matrix(X, FS_TARGET, lo, hi); W=knn(W,KNN_K); lbl=spec_labels(W,k=K_FIXED)\n",
    "                wh, chm = hemi_module_means(W,lbl,np.array(L,int), np.array(R,int))\n",
    "                row[f\"{band}_WHWM\"]=wh; row[f\"{band}_CHWM\"]=chm\n",
    "            rows.append(row)\n",
    "    df=pd.DataFrame(rows).dropna()\n",
    "    X=df[[c for c in df.columns if c.endswith(\"_WHWM\") or c.endswith(\"_CHWM\")]].to_numpy(float)\n",
    "    y=df[\"cond\"].to_numpy(int)\n",
    "    s=df[\"sid\"].to_numpy(int)\n",
    "    return X,y,s\n",
    "\n",
    "def paired_auc_perm(X,y,s,perm_B=CLF_PERMS):\n",
    "    clf=make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    rng=default_rng(31)\n",
    "    fold_p=[]; fold_y=[]\n",
    "    for sid in sorted(set(s)):\n",
    "        mask=(s==sid)\n",
    "        if np.sum(mask)!=2: continue\n",
    "        clf.fit(X[~mask], y[~mask])\n",
    "        p=clf.predict_proba(X[mask])[:,1]\n",
    "        fold_p.append(p); fold_y.append(y[mask])\n",
    "    if not fold_p:\n",
    "        print(\"[info] No EC/EO pairs; classifier skipped.\")\n",
    "    else:\n",
    "        probs=np.concatenate(fold_p); ys=np.concatenate(fold_y)\n",
    "        auc=float(roc_auc_score(ys, probs))\n",
    "        cnt=1\n",
    "        for _ in range(perm_B):\n",
    "            yperm=ys.copy()\n",
    "            for i in range(0,len(yperm),2):\n",
    "                if rng.random()<0.5 and i+1<len(yperm):\n",
    "                    yperm[i],yperm[i+1]=yperm[i+1],yperm[i]\n",
    "            ap=float(roc_auc_score(yperm, probs))\n",
    "            if ap>=auc: cnt+=1\n",
    "        p=float(cnt/(perm_B+1))\n",
    "        print(f\"[NHP EC vs EO] minimal α/θ coupling → AUC={auc:.3f}, p={p:.4f} (N={len(ys)})\")\n",
    "        pd.DataFrame([{\"AUC\":auc,\"p_perm\":p,\"N_points\":len(ys),\"N_subjects\":len(set(s))}]).to_csv(\n",
    "            os.path.join(OUT_ROOT,\"primate_ec_eo_minimal.csv\"), index=False)\n",
    "\n",
    "if pairs:\n",
    "    Xc,yc,sc = build_minimal_features(pairs)\n",
    "    paired_auc_perm(Xc,yc,sc)\n",
    "\n",
    "print(\"\\nDone. Artifacts →\", OUT_ROOT)\n",
    "print(\"Paste at least one working NHP URL if none were found automatically.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "14069057-7628-432f-9492-64c148cfec9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Exporting EO/EC to .npy (skips existing) ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R01.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R01.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R02.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R02.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Export sample: [(1, 'EO', 'exists'), (1, 'EC', 'exists'), (2, 'EO', 'exists'), (2, 'EC', 'exists'), (3, 'EO', 'exists'), (3, 'EC', 'exists'), (4, 'EO', 'exists'), (4, 'EC', 'exists')] ...\n",
      "Usable subjects (EO & EC present): 109 (want ≥ 100)\n",
      "\n",
      "=== Running CNT spectral consensus (EO) ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 273\u001b[39m\n\u001b[32m    270\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    272\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Running CNT spectral consensus (EO) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m273\u001b[39m df_eo = \u001b[43mrun_condition\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== Running CNT spectral consensus (EC) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    275\u001b[39m df_ec = run_condition(\u001b[33m\"\u001b[39m\u001b[33mEC\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 255\u001b[39m, in \u001b[36mrun_condition\u001b[39m\u001b[34m(cond)\u001b[39m\n\u001b[32m    253\u001b[39m             seg=idx[st:st+c]; out[seg]=u; st+=c\n\u001b[32m    254\u001b[39m         nl.append(out)\n\u001b[32m--> \u001b[39m\u001b[32m255\u001b[39m     _, cons_n, _ = \u001b[43mloso_via_coassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    256\u001b[39m     null_aris.append(adjusted_rand_score(cons, cons_n))\n\u001b[32m    257\u001b[39m null_aris=np.array(null_aris,\u001b[38;5;28mfloat\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 212\u001b[39m, in \u001b[36mloso_via_coassoc\u001b[39m\u001b[34m(label_list)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_list)):\n\u001b[32m    211\u001b[39m     leave=[lab \u001b[38;5;28;01mfor\u001b[39;00m i,lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(label_list) \u001b[38;5;28;01mif\u001b[39;00m i!=s]\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     cons_l=spec_labels(\u001b[43mcoassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleave\u001b[49m\u001b[43m)\u001b[49m,k=\u001b[32m2\u001b[39m)\n\u001b[32m    213\u001b[39m     vals.append(adjusted_rand_score(cons, cons_l))\n\u001b[32m    214\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.median(vals)), cons, cof\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 204\u001b[39m, in \u001b[36mcoassoc\u001b[39m\u001b[34m(labels)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m    203\u001b[39m         li=lab[i]\n\u001b[32m--> \u001b[39m\u001b[32m204\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n): co[i,j]+=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m li==lab[j] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m co/m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === CNT Humans @ Scale (≥100 subjects): EO+EC Download → Convert → PLI Consensus + Minimal Classifier ===\n",
    "# Dataset: EEGBCI (EEG Motor Movement/Imagery)\n",
    "# R01 = Eyes Open (EO), R02 = Eyes Closed (EC)\n",
    "# This cell:\n",
    "#   1) Downloads EO/EC for subjects 1..109 (skips present), exports -> subject_##_{EO|EC}.npy (+ channels.txt) at 250 Hz, 60 s.\n",
    "#   2) Runs CNT PLI → kNN → spectral (k=2) per subject/band (alpha/theta/beta); spectral-on-coassoc across subjects.\n",
    "#      Outputs LOSO median ARI & label-preserving null p for EC and EO separately.\n",
    "#   3) Computes hemispheric (Left/Right) and Anterior/Posterior metrics on the consensus (clean 10–20 names).\n",
    "#   4) Runs the prereg minimal classifier (α/θ coupling only) with paired CV + 10k paired label-flip perms → AUC & p.\n",
    "#   5) Saves summaries, figures, and a final 1-page PDF.\n",
    "#\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\\n",
    "#     ├─ tables\\band__{cond}__{band}__{coassoc,consensus_labels}.npy\n",
    "#     ├─ metrics\\band__{cond}__{band}__metrics.json\n",
    "#     ├─ figures\\coassoc__{cond}__{band}.png\n",
    "#     ├─ hemisphere_{cond}.csv\n",
    "#     ├─ summary_{cond}.csv\n",
    "#     ├─ ec_eo_minimal_prereg.csv (AUC & p)\n",
    "#     └─ CNT_PLI_humans_100plus_summary.pdf\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# ---------------- Paths & config ----------------\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR   = os.path.join(ROOT, \"eeg_rest\")  # where subject_##_{EC|EO}.npy live\n",
    "OUT_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "OUT_TAB    = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET    = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG    = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [DATA_DIR, OUT_ROOT, OUT_TAB, OUT_MET, OUT_FIG]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "SUBJECTS   = list(range(1, 109+1))       # EEGBCI has up to 109 subjects\n",
    "MIN_SUBJ   = 100                          # we want at least 100 usable subjects\n",
    "FS_OUT     = 250.0                        # Hz\n",
    "DURATION_S = 60                           # seconds kept per condition\n",
    "HP, LP     = 1.0, 45.0                    # bandpass for PLI prep\n",
    "\n",
    "BANDS_HZ   = {\"alpha\": (8.0,13.0), \"theta\": (4.0,8.0), \"beta\": (13.0,30.0)}\n",
    "K_FIXED    = 2\n",
    "KNN_K      = 6\n",
    "NULL_PERMS = 500                          # raise to 1000+ for publication\n",
    "CLF_PERMS  = 10000                        # paired label-flip perms for classifier\n",
    "RNG        = default_rng(7)\n",
    "\n",
    "# ---------------- Deps ----------------\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "# ---------------- 1) Download & export EO (R01) and EC (R02) ----------------\n",
    "def export_subject_cond(subj, run, cond):\n",
    "    try:\n",
    "        try:\n",
    "            fpaths = mne.datasets.eegbci.load_data(subjects=[subj], runs=[run], update_path=True, verbose=\"ERROR\")\n",
    "        except TypeError:  # old mne signature\n",
    "            fpaths = mne.datasets.eegbci.load_data(subject=subj, runs=[run], update_path=True, verbose=\"ERROR\")\n",
    "        raws=[]\n",
    "        for fp in fpaths:\n",
    "            raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "            raw.pick_types(eeg=True, stim=False, eog=False, ecg=False, emg=False, misc=False)\n",
    "            raws.append(raw)\n",
    "        if not raws: return False, \"no_raw\"\n",
    "        raw = mne.concatenate_raws(raws, verbose=\"ERROR\")\n",
    "        # montage + filter + resample\n",
    "        try:\n",
    "            raw.set_montage(\"standard_1020\", on_missing=\"ignore\", match_case=False, verbose=\"ERROR\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        raw.filter(HP, LP, fir_design=\"firwin\", verbose=\"ERROR\")\n",
    "        raw.resample(FS_OUT, npad=\"auto\", verbose=\"ERROR\")\n",
    "        # slice to DURATION_S\n",
    "        n_keep = int(DURATION_S * raw.info[\"sfreq\"])\n",
    "        X = raw.get_data(picks=\"eeg\")\n",
    "        if X.shape[1] >= n_keep:\n",
    "            X = X[:, :n_keep]\n",
    "        else:\n",
    "            reps = int(np.ceil(n_keep / X.shape[1])); X = np.tile(X, reps)[:, :n_keep]\n",
    "        ch_names = mne.pick_info(raw.info, mne.pick_types(raw.info, eeg=True)).ch_names\n",
    "        base = os.path.join(DATA_DIR, f\"subject_{subj:02d}_{cond}\")\n",
    "        np.save(base + \".npy\", X.astype(np.float32))\n",
    "        with open(base + \".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "            for ch in ch_names: f.write(ch + \"\\n\")\n",
    "        return True, X.shape\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "print(\"=== Exporting EO/EC to .npy (skips existing) ===\")\n",
    "log=[]\n",
    "for s in SUBJECTS:\n",
    "    for cond, run in ((\"EO\",1), (\"EC\",2)):\n",
    "        f = os.path.join(DATA_DIR, f\"subject_{s:02d}_{cond}.npy\")\n",
    "        if os.path.exists(f):\n",
    "            log.append((s,cond,\"exists\"))\n",
    "        else:\n",
    "            ok,msg = export_subject_cond(s, run, cond)\n",
    "            log.append((s,cond,msg if ok else f\"error: {msg}\"))\n",
    "print(\"Export sample:\", log[:8], \"...\")\n",
    "\n",
    "# Count usable subjects (both EO & EC present)\n",
    "usable = [s for s in SUBJECTS if os.path.exists(os.path.join(DATA_DIR, f\"subject_{s:02d}_EO.npy\"))\n",
    "                                   and os.path.exists(os.path.join(DATA_DIR, f\"subject_{s:02d}_EC.npy\"))]\n",
    "print(f\"Usable subjects (EO & EC present): {len(usable)} (want ≥ {MIN_SUBJ})\")\n",
    "\n",
    "# ---------------- Channel cleaning & maps ----------------\n",
    "CH_TXT = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "# Ensure channel text exists (write from any subject EC if missing)\n",
    "if not os.path.exists(CH_TXT):\n",
    "    anyEC = next((os.path.join(DATA_DIR,f) for f in os.listdir(DATA_DIR) if f.endswith(\"_EC.npy\")), None)\n",
    "    if anyEC:\n",
    "        txt = anyEC.replace(\".npy\",\".channels.txt\")\n",
    "        if os.path.exists(txt):\n",
    "            import shutil; shutil.copyfile(txt, CH_TXT)\n",
    "\n",
    "with open(CH_TXT, \"r\", encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "LEFT_CANON  = set(map(str.upper, [\"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "                                  \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"]))\n",
    "RIGHT_CANON = set(map(str.upper, [\"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "                                  \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\"); MID_PREFIXES=(\"C\",); POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\")\n",
    "\n",
    "def hemi_map(labels):\n",
    "    L,R,Z=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        up=ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON or re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m=re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "def ap_map(labels):\n",
    "    A,P,C=[],[],[]\n",
    "    for i,ch in enumerate(labels):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch); pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "        elif pref.startswith(\"C\"): C.append(i)\n",
    "        else: C.append(i)\n",
    "    return np.array(A,int), np.array(P,int), np.array(C,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_map(ch_names)\n",
    "A_idx, P_idx, C_idx = ap_map(ch_names)\n",
    "\n",
    "# ---------------- 2) PLI → kNN → spectral (k=2) & spectral-on-coassoc ----------------\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a=butter(order,[lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    n=X.shape[0]\n",
    "    b,a=butter(4,[lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y=np.zeros_like(X)\n",
    "    for c in range(n): Y[c]=filtfilt(b,a,X[c])\n",
    "    ph=np.angle(hilbert(Y, axis=1))\n",
    "    W=np.zeros((n,n),float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            d=ph[i]-ph[j]; W[i,j]=W[j,i]=abs(np.mean(np.sign(np.sin(d))))\n",
    "    np.fill_diagonal(W,0); return W\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); return np.eye(W.shape[0]) - D@W@D\n",
    "def spec_labels(W, k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U / (np.linalg.norm(U, axis=1, keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n),float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof,k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave),k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "def label_preserving_null_ari(cons, subj_labels, perms=NULL_PERMS):\n",
    "    null=[]\n",
    "    for _ in range(perms):\n",
    "        nl=[]\n",
    "        for lab in subj_labels:\n",
    "            uniq,cnts=np.unique(lab, return_counts=True)\n",
    "            idx=np.arange(len(lab)); RNG.shuffle(idx)\n",
    "            out=np.empty(len(lab),int); st=0\n",
    "            for u,c in zip(uniq,cnts):\n",
    "                seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "            nl.append(out)\n",
    "        _, cons_n, _ = loso_via_coassoc(nl)\n",
    "        null.append(adjusted_rand_score(cons, cons_n))\n",
    "    null=np.array(null,float)\n",
    "    p=float((np.sum(null>=np.median(null)) + 1) / (len(null)+1))  # not used, we compare to LOSO below\n",
    "    return null\n",
    "\n",
    "def run_condition(cond):\n",
    "    paths = [os.path.join(DATA_DIR, f\"subject_{s:02d}_{cond}.npy\") for s in usable if os.path.exists(os.path.join(DATA_DIR, f\"subject_{s:02d}_{cond}.npy\"))]\n",
    "    if len(paths) < MIN_SUBJ:\n",
    "        print(f\"[{cond}] Only {len(paths)} subjects; continuing anyway.\")\n",
    "    rows=[]\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        subj_labels=[]\n",
    "        for p in paths:\n",
    "            X=np.load(p); W=pli_matrix(X, FS_OUT, lo, hi); W=knn(W, KNN_K); lab=spec_labels(W,k=K_FIXED)\n",
    "            subj_labels.append(lab)\n",
    "        loso, cons, co = loso_via_coassoc(subj_labels)\n",
    "        # null ARI: compare consensus to label-preserving randomized consensus (ARI)\n",
    "        null_aris=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nl=[]\n",
    "            for lab in subj_labels:\n",
    "                uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                idx=np.arange(len(lab)); RNG.shuffle(idx)\n",
    "                out=np.empty(len(lab),int); st=0\n",
    "                for u,c in zip(uniq,cnts):\n",
    "                    seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                nl.append(out)\n",
    "            _, cons_n, _ = loso_via_coassoc(nl)\n",
    "            null_aris.append(adjusted_rand_score(cons, cons_n))\n",
    "        null_aris=np.array(null_aris,float)\n",
    "        p_val=float((np.sum(null_aris >= loso) + 1) / (len(null_aris)+1))\n",
    "        # save artifacts\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__coassoc.npy\"), co)\n",
    "        with open(os.path.join(OUT_MET, f\"band__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(paths),\"LOSO\":float(loso),\"null_ari_mean\":float(null_aris.mean()),\"p_value\":p_val}, f, indent=2)\n",
    "        plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc (spectral on coassoc)\")\n",
    "        plt.colorbar(); plt.tight_layout(); plt.savefig(os.path.join(OUT_FIG, f\"coassoc__{cond}__{band}.png\"), dpi=160); plt.close()\n",
    "        rows.append([cond, band, len(paths), float(loso), float(null_aris.mean()), p_val])\n",
    "    df = pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"LOSO\",\"null_ari_mean\",\"p_value\"])\n",
    "    df.to_csv(os.path.join(OUT_ROOT, f\"summary_{cond}.csv\"), index=False)\n",
    "    print(f\"[{cond}] summary:\\n\", df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "print(\"\\n=== Running CNT spectral consensus (EO) ===\")\n",
    "df_eo = run_condition(\"EO\")\n",
    "print(\"\\n=== Running CNT spectral consensus (EC) ===\")\n",
    "df_ec = run_condition(\"EC\")\n",
    "\n",
    "# ---------------- 3) Hemi/AP metrics per condition (consensus-based) ----------------\n",
    "def hemi_ap_metrics(cond):\n",
    "    rows=[]\n",
    "    for band in BANDS_HZ.keys():\n",
    "        cons_fp=os.path.join(OUT_TAB, f\"band__{cond}__{band}__consensus_labels.npy\")\n",
    "        co_fp  =os.path.join(OUT_TAB, f\"band__{cond}__{band}__coassoc.npy\")\n",
    "        if not (os.path.exists(cons_fp) and os.path.exists(co_fp)): continue\n",
    "        cons=np.load(cons_fp); co=np.load(co_fp); n=len(cons)\n",
    "        def within_region_ratio(idx):\n",
    "            if idx.size<3: return np.nan\n",
    "            sub=np.ix_(idx,idx); co_r=co[sub]; lab=cons[idx]\n",
    "            same=lab[:,None]==lab[None,:]; diff=~same\n",
    "            np.fill_diagonal(same,False); np.fill_diagonal(diff,False)\n",
    "            s=co_r[same]; d=co_r[diff]\n",
    "            return float(np.mean(s)/(np.mean(d)+1e-12)) if s.size and d.size else np.nan\n",
    "        l_ratio=within_region_ratio(L_idx); r_ratio=within_region_ratio(R_idx)\n",
    "        wh_wm, ch_wm = None, None\n",
    "        # within-hemi vs cross-hemi (within-module)\n",
    "        n=n\n",
    "        Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L_idx,L_idx)]=True\n",
    "        Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R_idx,R_idx)]=True\n",
    "        within=Lmask|Rmask\n",
    "        cross=np.zeros((n,n),bool); cross[np.ix_(L_idx,R_idx)]=True; cross[np.ix_(R_idx,L_idx)]=True\n",
    "        same = cons[:,None]==cons[None,:]\n",
    "        for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "        WH_WM=float(np.mean(co[within&same])) if np.any(within&same) else np.nan\n",
    "        CH_WM=float(np.mean(co[cross &same])) if np.any(cross &same) else np.nan\n",
    "        rows.append([cond, band, n, int(L_idx.size), int(R_idx.size), float(l_ratio), float(r_ratio), WH_WM, CH_WM])\n",
    "    df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_channels\",\"n_left\",\"n_right\",\"left_intra_ratio\",\"right_intra_ratio\",\"WH_WM\",\"CH_WM\"])\n",
    "    df.to_csv(os.path.join(OUT_ROOT, f\"hemisphere_{cond}.csv\"), index=False)\n",
    "    print(f\"[{cond}] hemisphere/AP metrics saved.\")\n",
    "    return df\n",
    "\n",
    "hemi_eo = hemi_ap_metrics(\"EO\")\n",
    "hemi_ec = hemi_ap_metrics(\"EC\")\n",
    "\n",
    "# ---------------- 4) Minimal prereg classifier (α/θ coupling only) ----------------\n",
    "def subject_features_coupling(subject_id, cond_tag):\n",
    "    f=os.path.join(DATA_DIR, f\"subject_{subject_id:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(f): return None\n",
    "    X=np.load(f)\n",
    "    feats={}\n",
    "    for band,(lo,hi) in {\"alpha\":(8,13), \"theta\":(4,8)}.items():\n",
    "        # Build PLI -> kNN -> spectral labels\n",
    "        W=pli_matrix(X, FS_OUT, lo, hi); W=knn(W, KNN_K); lbl=spec_labels(W, k=K_FIXED)\n",
    "        # compute WH_WM & CH_WM from raw PLI graph (not consensus)\n",
    "        n=len(lbl)\n",
    "        Lmask=np.zeros((n,n),bool); Lmask[np.ix_(L_idx,L_idx)]=True\n",
    "        Rmask=np.zeros((n,n),bool); Rmask[np.ix_(R_idx,R_idx)]=True\n",
    "        within=Lmask|Rmask\n",
    "        cross=np.zeros((n,n),bool); cross[np.ix_(L_idx,R_idx)]=True; cross[np.ix_(R_idx,L_idx)]=True\n",
    "        same = lbl[:,None]==lbl[None,:]\n",
    "        for m in (within,cross,same): np.fill_diagonal(m,False)\n",
    "        WH_WM=float(np.mean(W[within&same])) if np.any(within&same) else np.nan\n",
    "        CH_WM=float(np.mean(W[cross &same])) if np.any(cross &same) else np.nan\n",
    "        feats[f\"{band}_WHWM\"]=WH_WM; feats[f\"{band}_CHWM\"]=CH_WM\n",
    "    return feats\n",
    "\n",
    "# Build full feature set\n",
    "X_list, y_list, sid_list = [], [], []\n",
    "for s in usable:\n",
    "    ec = subject_features_coupling(s, \"EC\")\n",
    "    eo = subject_features_coupling(s, \"EO\")\n",
    "    if ec:\n",
    "        X_list.append(ec); y_list.append(0); sid_list.append(s)\n",
    "    if eo:\n",
    "        X_list.append(eo); y_list.append(1); sid_list.append(s)\n",
    "\n",
    "if X_list:\n",
    "    Xdf = pd.DataFrame(X_list).replace([np.inf,-np.inf], np.nan)\n",
    "    y = np.array(y_list, int); sids=np.array(sid_list, int)\n",
    "    # Paired CV: leave-one-subject pair out\n",
    "    from sklearn.metrics import roc_curve\n",
    "    clf = make_pipeline(SimpleImputer(strategy=\"median\"), StandardScaler(), LogisticRegression(max_iter=2000, solver=\"lbfgs\"))\n",
    "    fold_probs, fold_true, pair_indices = [], [], []\n",
    "    for s in usable:\n",
    "        mask = (sids==s)\n",
    "        if np.sum(mask)!=2: continue\n",
    "        train = ~mask\n",
    "        clf.fit(Xdf.to_numpy()[train], y[train])\n",
    "        p = clf.predict_proba(Xdf.to_numpy()[mask])[:,1]\n",
    "        fold_probs.append(p); fold_true.append(y[mask]); pair_indices.append(np.where(mask)[0])\n",
    "    probs = np.concatenate(fold_probs); ys = np.concatenate(fold_true)\n",
    "    auc_obs = float(roc_auc_score(ys, probs))\n",
    "    # Paired label-flip perms\n",
    "    cnt=1; rng=default_rng(31)\n",
    "    for _ in range(CLF_PERMS):\n",
    "        y_perm = ys.copy()\n",
    "        # flip labels within each subject pair\n",
    "        for i in range(0, len(y_perm), 2):\n",
    "            if rng.random() < 0.5 and i+1 < len(y_perm):\n",
    "                y_perm[i], y_perm[i+1] = y_perm[i+1], y_perm[i]\n",
    "        a = float(roc_auc_score(y_perm, probs))\n",
    "        if a >= auc_obs: cnt += 1\n",
    "    p_perm = float(cnt / (CLF_PERMS + 1))\n",
    "    pd.DataFrame([{\"AUC_obs\":auc_obs,\"p_perm\":p_perm,\"N_test_points\":len(ys),\"N_subjects\":len(usable)}]).to_csv(\n",
    "        os.path.join(OUT_ROOT,\"ec_eo_minimal_prereg.csv\"), index=False)\n",
    "    print(f\"\\n=== Minimal α/θ coupling classifier ===\\nAUC={auc_obs:.3f}, p={p_perm:.4f}  (N={len(ys)} test points)\")\n",
    "else:\n",
    "    print(\"\\n[info] No features built (check EO/EC NPYs).\")\n",
    "\n",
    "# ---------------- 5) Final 1-page PDF summary ----------------\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "FINAL_PDF = os.path.join(OUT_ROOT, \"CNT_PLI_humans_100plus_summary.pdf\")\n",
    "fig = plt.figure(figsize=(11,8.5))\n",
    "# Title\n",
    "ax_t = fig.add_axes([0.05,0.92,0.9,0.06]); ax_t.axis(\"off\")\n",
    "ax_t.text(0.5, 0.6, \"CNT — Humans (≥100) EO & EC: Field Consensus + Minimal Predictor\", ha=\"center\", va=\"center\", fontsize=15, weight=\"bold\")\n",
    "# EC/EO summaries\n",
    "def load_summary(cond):\n",
    "    p=os.path.join(OUT_ROOT, f\"summary_{cond}.csv\")\n",
    "    return pd.read_csv(p) if os.path.exists(p) else pd.DataFrame()\n",
    "df_eo_s, df_ec_s = load_summary(\"EO\"), load_summary(\"EC\")\n",
    "ax1 = fig.add_axes([0.05,0.72,0.42,0.16]); ax1.axis(\"off\")\n",
    "ax1.text(0.0,0.85, \"EO spectral-on-coassoc:\", fontsize=11, weight=\"bold\")\n",
    "ax1.text(0.0,0.05, df_eo_s.to_string(index=False) if not df_eo_s.empty else \"EO summary not found\", fontsize=8, family=\"monospace\")\n",
    "ax2 = fig.add_axes([0.53,0.72,0.42,0.16]); ax2.axis(\"off\")\n",
    "ax2.text(0.0,0.85, \"EC spectral-on-coassoc:\", fontsize=11, weight=\"bold\")\n",
    "ax2.text(0.0,0.05, df_ec_s.to_string(index=False) if not df_ec_s.empty else \"EC summary not found\", fontsize=8, family=\"monospace\")\n",
    "# Co-assoc images strip\n",
    "x0=0.05\n",
    "for cond in [\"EO\",\"EC\"]:\n",
    "    for i,band in enumerate([\"alpha\",\"theta\",\"beta\"]):\n",
    "        pimg=os.path.join(OUT_FIG, f\"coassoc__{cond}__{band}.png\")\n",
    "        ax = fig.add_axes([x0 + i*0.145, 0.46 if cond==\"EO\" else 0.27, 0.14, 0.16]); ax.axis(\"off\")\n",
    "        if os.path.exists(pimg):\n",
    "            ax.imshow(plt.imread(pimg)); ax.set_title(f\"{cond} {band}\")\n",
    "        else:\n",
    "            ax.text(0.5,0.5, \"missing\", ha=\"center\", va=\"center\", fontsize=8)\n",
    "# Minimal classifier AUC\n",
    "res_csv = os.path.join(OUT_ROOT,\"ec_eo_minimal_prereg.csv\")\n",
    "ax_auc = fig.add_axes([0.05, 0.05, 0.42, 0.16]); ax_auc.axis(\"off\")\n",
    "if os.path.exists(res_csv):\n",
    "    d = pd.read_csv(res_csv)\n",
    "    auc = float(d.loc[0,\"AUC_obs\"]); p  = float(d.loc[0,\"p_perm\"])\n",
    "    ax_auc.text(0.0,0.8, \"Minimal α/θ coupling classifier:\", fontsize=11, weight=\"bold\")\n",
    "    ax_auc.text(0.0,0.35, f\"AUC={auc:.3f}, p={p:.4f}, N_test_points={int(d.loc[0,'N_test_points'])}, N_subjects={int(d.loc[0,'N_subjects'])}\")\n",
    "else:\n",
    "    ax_auc.text(0.0,0.8, \"Minimal α/θ coupling classifier:\", fontsize=11, weight=\"bold\")\n",
    "    ax_auc.text(0.0,0.35, \"Results file not found.\")\n",
    "# Hemi metrics quick peek\n",
    "for j,cond in enumerate([\"EO\",\"EC\"]):\n",
    "    p=os.path.join(OUT_ROOT, f\"hemisphere_{cond}.csv\")\n",
    "    axh = fig.add_axes([0.53, 0.05 + j*0.105, 0.42, 0.10]); axh.axis(\"off\")\n",
    "    if os.path.exists(p):\n",
    "        dd=pd.read_csv(p); axh.text(0.0,0.7, f\"{cond} hemis/AP metrics:\", fontsize=10, weight=\"bold\")\n",
    "        axh.text(0.0,0.1, dd.to_string(index=False), fontsize=7, family=\"monospace\")\n",
    "    else:\n",
    "        axh.text(0.0,0.7, f\"{cond} hemis/AP metrics:\", fontsize=10, weight=\"bold\")\n",
    "        axh.text(0.0,0.1, \"not found\")\n",
    "pp=PdfPages(FINAL_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved final 1-pager:\", FINAL_PDF)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c0f59ee3-2dfa-4e33-aeb6-d185dc07cf12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Usable pairs: 109 (expected ≥ 100)\n",
      "[EO] caching labels for band=alpha (n=109) …\n",
      "[EO] caching labels for band=theta (n=109) …\n",
      "[EO] caching labels for band=beta (n=109) …\n",
      "[EC] caching labels for band=alpha (n=109) …\n",
      "[EC] caching labels for band=theta (n=109) …\n",
      "[EC] caching labels for band=beta (n=109) …\n",
      "\n",
      "=== FAST EO consensus (200 perms) ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[32m    152\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    154\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== FAST EO consensus (200 perms) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m df_eo_fast = \u001b[43mrun_cond_quick\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== FAST EC consensus (200 perms) ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    157\u001b[39m df_ec_fast = run_cond_quick(\u001b[33m\"\u001b[39m\u001b[33mEC\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36mrun_cond_quick\u001b[39m\u001b[34m(cond)\u001b[39m\n\u001b[32m    136\u001b[39m             seg=idx[st:st+c]; out[seg]=u; st+=c\n\u001b[32m    137\u001b[39m         nl.append(out)\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     _, cons_n, _ = \u001b[43mloso_via_coassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m     null.append(adjusted_rand_score(cons, cons_n))\n\u001b[32m    140\u001b[39m null=np.array(null,\u001b[38;5;28mfloat\u001b[39m); p=\u001b[38;5;28mfloat\u001b[39m((np.sum(null>=loso)+\u001b[32m1\u001b[39m)/(\u001b[38;5;28mlen\u001b[39m(null)+\u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mloso_via_coassoc\u001b[39m\u001b[34m(label_list)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_list)):\n\u001b[32m     76\u001b[39m     leave=[lab \u001b[38;5;28;01mfor\u001b[39;00m i,lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(label_list) \u001b[38;5;28;01mif\u001b[39;00m i!=s]\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     cons_l=spec_labels(\u001b[43mcoassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleave\u001b[49m\u001b[43m)\u001b[49m,k=\u001b[32m2\u001b[39m)\n\u001b[32m     78\u001b[39m     vals.append(adjusted_rand_score(cons, cons_l))\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.median(vals)), cons, cof\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 69\u001b[39m, in \u001b[36mcoassoc\u001b[39m\u001b[34m(labels)\u001b[39m\n\u001b[32m     67\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m     68\u001b[39m         li=lab[i]\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n): co[i,j]+=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m li==lab[j] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m     70\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m co/m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === FAST RESUME (EO+EC) — Parallel label cache + quick consensus (200 perms) ===\n",
    "# Assumes all subjects exported here: C:\\Users\\caleb\\CNT_Lab\\eeg_rest\\subject_##_{EC|EO}.npy\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR   = os.path.join(ROOT, \"eeg_rest\")\n",
    "OUT_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "OUT_TAB    = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET    = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG    = os.path.join(OUT_ROOT, \"figures\")\n",
    "LABELS_DIR = os.path.join(OUT_ROOT, \"labels_cache\")\n",
    "for p in [OUT_TAB, OUT_MET, OUT_FIG, LABELS_DIR]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "FS_OUT     = 250.0\n",
    "BANDS_HZ   = {\"alpha\": (8,13), \"theta\": (4,8), \"beta\": (13,30)}\n",
    "K_FIXED    = 2\n",
    "KNN_K      = 6\n",
    "NULL_PERMS = 200            # FAST mode; you can top up later\n",
    "N_JOBS     = max(1, os.cpu_count() - 1)\n",
    "\n",
    "# ---------------- helper fns ----------------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    from scipy.signal import hilbert\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            W[i,j] = W[j,i] = abs(np.mean(np.sign(np.sin(dphi))))\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); \n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W,k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U/(np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n), float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof,k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave),k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "# ---------------- discover subjects ----------------\n",
    "subs = []\n",
    "for f in glob.glob(os.path.join(DATA_DIR, \"subject_*_EO.npy\")):\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EO\\.npy$\", f).group(1))\n",
    "    ecf = os.path.join(DATA_DIR, f\"subject_{sid:02d}_EC.npy\")\n",
    "    if os.path.exists(ecf): subs.append(sid)\n",
    "subs = sorted(subs)\n",
    "print(f\"Usable pairs: {len(subs)} (expected ≥ 100)\")\n",
    "\n",
    "# ---------------- parallel label cache ----------------\n",
    "def compute_labels_for_file(npy_path, band_name, lo, hi):\n",
    "    # cache file path\n",
    "    sid   = int(re.search(r\"subject_(\\d+)_\", npy_path).group(1))\n",
    "    cond  = \"EO\" if \"_EO\" in npy_path else \"EC\"\n",
    "    lab_fp= os.path.join(LABELS_DIR, f\"labels__{cond}__{band_name}__{sid:03d}.npy\")\n",
    "    if os.path.exists(lab_fp): \n",
    "        return lab_fp\n",
    "    X = np.load(npy_path)\n",
    "    W = pli_matrix(X, FS_OUT, lo, hi)\n",
    "    W = knn(W, KNN_K)\n",
    "    lab = spec_labels(W, k=K_FIXED)\n",
    "    np.save(lab_fp, lab)\n",
    "    return lab_fp\n",
    "\n",
    "def cache_all_labels(cond):\n",
    "    files = [os.path.join(DATA_DIR, f\"subject_{sid:02d}_{cond}.npy\") for sid in subs]\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        print(f\"[{cond}] caching labels for band={band} (n={len(files)}) …\")\n",
    "        _ = Parallel(n_jobs=N_JOBS, prefer=\"processes\")(\n",
    "            delayed(compute_labels_for_file)(fp, band, lo, hi) for fp in files\n",
    "        )\n",
    "\n",
    "cache_all_labels(\"EO\")\n",
    "cache_all_labels(\"EC\")\n",
    "\n",
    "# ---------------- build consensus quickly ----------------\n",
    "rng = default_rng(11)\n",
    "\n",
    "def run_cond_quick(cond):\n",
    "    rows=[]\n",
    "    for band in BANDS_HZ.keys():\n",
    "        labels=[]\n",
    "        for sid in subs:\n",
    "            lab_fp=os.path.join(LABELS_DIR, f\"labels__{cond}__{band}__{sid:03d}.npy\")\n",
    "            labels.append(np.load(lab_fp))\n",
    "        loso, cons, co = loso_via_coassoc(labels)\n",
    "        # quick nulls\n",
    "        null=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nl=[]\n",
    "            for lab in labels:\n",
    "                uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                idx=np.arange(len(lab)); rng.shuffle(idx)\n",
    "                out=np.empty(len(lab),int); st=0\n",
    "                for u,c in zip(uniq,cnts):\n",
    "                    seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                nl.append(out)\n",
    "            _, cons_n, _ = loso_via_coassoc(nl)\n",
    "            null.append(adjusted_rand_score(cons, cons_n))\n",
    "        null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "        # save artifacts\n",
    "        np.save(os.path.join(OUT_TAB,f\"band__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB,f\"band__{cond}__{band}__coassoc.npy\"), co)\n",
    "        with open(os.path.join(OUT_MET,f\"band__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(subs),\"LOSO\":float(loso),\"null_ari_mean\":float(null.mean()),\"p_value\":p}, f, indent=2)\n",
    "        plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc (FAST)\")\n",
    "        plt.colorbar(); plt.tight_layout(); plt.savefig(os.path.join(OUT_FIG, f\"coassoc__{cond}__{band}.png\"), dpi=160); plt.close()\n",
    "        rows.append([cond, band, len(subs), float(loso), float(null.mean()), p])\n",
    "    df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"LOSO\",\"null_ari_mean\",\"p_value\"])\n",
    "    df.to_csv(os.path.join(OUT_ROOT, f\"summary_{cond}_FAST.csv\"), index=False)\n",
    "    print(f\"[{cond}] FAST summary:\\n\", df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "print(\"\\n=== FAST EO consensus (200 perms) ===\")\n",
    "df_eo_fast = run_cond_quick(\"EO\")\n",
    "print(\"\\n=== FAST EC consensus (200 perms) ===\")\n",
    "df_ec_fast = run_cond_quick(\"EC\")\n",
    "print(\"\\nFAST pass complete. You can top-up permutations later without recomputing labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6d2cf7-7b3b-4f11-9594-1a074ccdde58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Set Windows process priority: BELOW_NORMAL\n",
      "Usable pairs: 109\n",
      "[EO] caching alpha in batches …\n",
      "  done 15/109 — cooling 10s\n",
      "  done 30/109 — cooling 10s\n",
      "  done 45/109 — cooling 10s\n",
      "  done 60/109 — cooling 10s\n",
      "  done 75/109 — cooling 10s\n",
      "  done 90/109 — cooling 10s\n",
      "  done 105/109 — cooling 10s\n",
      "  done 109/109 — cooling 10s\n",
      "[EO] caching theta in batches …\n",
      "  done 15/109 — cooling 10s\n",
      "  done 30/109 — cooling 10s\n",
      "  done 45/109 — cooling 10s\n",
      "  done 60/109 — cooling 10s\n",
      "  done 75/109 — cooling 10s\n",
      "  done 90/109 — cooling 10s\n",
      "  done 105/109 — cooling 10s\n",
      "  done 109/109 — cooling 10s\n",
      "[EC] caching alpha in batches …\n",
      "  done 15/109 — cooling 10s\n",
      "  done 30/109 — cooling 10s\n",
      "  done 45/109 — cooling 10s\n",
      "  done 60/109 — cooling 10s\n",
      "  done 75/109 — cooling 10s\n",
      "  done 90/109 — cooling 10s\n",
      "  done 105/109 — cooling 10s\n",
      "  done 109/109 — cooling 10s\n",
      "[EC] caching theta in batches …\n",
      "  done 15/109 — cooling 10s\n",
      "  done 30/109 — cooling 10s\n",
      "  done 45/109 — cooling 10s\n",
      "  done 60/109 — cooling 10s\n",
      "  done 75/109 — cooling 10s\n",
      "  done 90/109 — cooling 10s\n",
      "  done 105/109 — cooling 10s\n",
      "  done 109/109 — cooling 10s\n",
      "\n",
      "=== COOL EO consensus ===\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 185\u001b[39m\n\u001b[32m    182\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m    184\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== COOL EO consensus ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m185\u001b[39m df_eo = \u001b[43mrun_cond_quick\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEO\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    186\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m=== COOL EC consensus ===\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    187\u001b[39m df_ec = run_cond_quick(\u001b[33m\"\u001b[39m\u001b[33mEC\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 169\u001b[39m, in \u001b[36mrun_cond_quick\u001b[39m\u001b[34m(cond)\u001b[39m\n\u001b[32m    167\u001b[39m             seg=idx[st:st+c]; out[seg]=u; st+=c\n\u001b[32m    168\u001b[39m         nl.append(out)\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m     _, cons_n, _ = \u001b[43mloso_via_coassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    170\u001b[39m     null.append(adjusted_rand_score(cons, cons_n))\n\u001b[32m    171\u001b[39m null=np.array(null,\u001b[38;5;28mfloat\u001b[39m); p=\u001b[38;5;28mfloat\u001b[39m((np.sum(null>=loso)+\u001b[32m1\u001b[39m)/(\u001b[38;5;28mlen\u001b[39m(null)+\u001b[32m1\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 115\u001b[39m, in \u001b[36mloso_via_coassoc\u001b[39m\u001b[34m(label_list)\u001b[39m\n\u001b[32m    113\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(label_list)):\n\u001b[32m    114\u001b[39m     leave=[lab \u001b[38;5;28;01mfor\u001b[39;00m i,lab \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(label_list) \u001b[38;5;28;01mif\u001b[39;00m i!=s]\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     cons_l=spec_labels(\u001b[43mcoassoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mleave\u001b[49m\u001b[43m)\u001b[49m,k=\u001b[32m2\u001b[39m)\n\u001b[32m    116\u001b[39m     vals.append(adjusted_rand_score(cons, cons_l))\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.median(vals)), cons, cof\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36mcoassoc\u001b[39m\u001b[34m(labels)\u001b[39m\n\u001b[32m    105\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n):\n\u001b[32m    106\u001b[39m         li=lab[i]\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n): co[i,j]+=\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m li==lab[j] \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m co/m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === COOL & RESUME: low-CPU α/θ labels + quick consensus (Windows-friendly) ===\n",
    "# - Limits math threads (MKL/OMP) to 1 to avoid core oversubscription\n",
    "# - Lowers process priority on Windows\n",
    "# - Uses small parallel pool (N_JOBS=2 by default) and batches subjects with short pauses\n",
    "# - α/θ only, NULL_PERMS=50 for quick p-values\n",
    "# - Caches per-subject labels under labels_cache; consensus reuses them\n",
    "\n",
    "import os, re, glob, time, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "# ---------- keep CPU cool ----------\n",
    "# Reduce BLAS/OMP thread oversubscription (very important)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# Lower process priority on Windows\n",
    "try:\n",
    "    import psutil, ctypes, sys\n",
    "    p = psutil.Process(os.getpid())\n",
    "    if os.name == \"nt\":\n",
    "        BELOW_NORMAL = 0x4000\n",
    "        IDLE = 0x40\n",
    "        ctypes.windll.kernel32.SetPriorityClass(ctypes.windll.kernel32.GetCurrentProcess(), BELOW_NORMAL)\n",
    "        print(\"[info] Set Windows process priority: BELOW_NORMAL\")\n",
    "except Exception as e:\n",
    "    print(\"[warn] Could not lower priority:\", e)\n",
    "\n",
    "# ---------- paths & knobs ----------\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR   = os.path.join(ROOT, \"eeg_rest\")\n",
    "OUT_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "OUT_TAB    = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET    = os.path.join(OUT_ROOT, \"metrics\")\n",
    "OUT_FIG    = os.path.join(OUT_ROOT, \"figures\")\n",
    "LABELS_DIR = os.path.join(OUT_ROOT, \"labels_cache\")\n",
    "for p in [OUT_TAB, OUT_MET, OUT_FIG, LABELS_DIR]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# Only α/θ for this pass\n",
    "BANDS_HZ   = {\"alpha\": (8,13), \"theta\": (4,8)}\n",
    "FS_OUT     = 250.0\n",
    "K_FIXED    = 2\n",
    "KNN_K      = 6\n",
    "NULL_PERMS = 50             # quick pass\n",
    "N_JOBS     = 2              # small parallelism\n",
    "BATCH_SIZE = 15             # subjects per batch\n",
    "REST_SEC   = 10             # rest between batches to cool\n",
    "\n",
    "rng = default_rng(11)\n",
    "\n",
    "# ---------- subject list (pairs only) ----------\n",
    "subs = []\n",
    "for f in glob.glob(os.path.join(DATA_DIR, \"subject_*_EO.npy\")):\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EO\\.npy$\", f).group(1))\n",
    "    if os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_EC.npy\")):\n",
    "        subs.append(sid)\n",
    "subs = sorted(subs)\n",
    "print(f\"Usable pairs: {len(subs)}\")\n",
    "\n",
    "# ---------- PLI helpers ----------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    from scipy.signal import butter, filtfilt\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_matrix(X, fs, lo, hi):\n",
    "    from scipy.signal import hilbert\n",
    "    n = X.shape[0]\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype=\"band\")\n",
    "    Y = np.zeros_like(X)\n",
    "    for c in range(n): Y[c] = filtfilt(b,a,X[c])\n",
    "    ph = np.angle(hilbert(Y, axis=1))\n",
    "    W  = np.zeros((n,n), float)\n",
    "    for i in range(n):\n",
    "        for j in range(i+1, n):\n",
    "            dphi = ph[i]-ph[j]\n",
    "            pli  = np.abs(np.mean(np.sign(np.sin(dphi))))\n",
    "            W[i,j] = W[j,i] = pli\n",
    "    np.fill_diagonal(W, 0.0)\n",
    "    return W\n",
    "\n",
    "def knn(W,k):\n",
    "    W=W.copy(); n=W.shape[0]\n",
    "    for i in range(n):\n",
    "        idx=np.argsort(W[i])[::-1]; keep=idx[:k]\n",
    "        mask=np.ones(n,bool); mask[keep]=False; W[i,mask]=0\n",
    "    W=np.maximum(W,W.T); np.fill_diagonal(W,0); return W\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d); D=np.diag(1.0/np.sqrt(d)); \n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spec_labels(W,k=2):\n",
    "    e,v = np.linalg.eigh(lap(W))\n",
    "    U   = v[:,1:k] if k>1 else v[:,:1]\n",
    "    U   = U/(np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "\n",
    "def coassoc(labels):\n",
    "    n=len(labels[0]); m=len(labels); co=np.zeros((n,n), float)\n",
    "    for lab in labels:\n",
    "        for i in range(n):\n",
    "            li=lab[i]\n",
    "            for j in range(n): co[i,j]+=1 if li==lab[j] else 0\n",
    "    return co/m\n",
    "\n",
    "def loso_via_coassoc(label_list):\n",
    "    cof=coassoc(label_list); cons=spec_labels(cof,k=2)\n",
    "    vals=[]\n",
    "    for s in range(len(label_list)):\n",
    "        leave=[lab for i,lab in enumerate(label_list) if i!=s]\n",
    "        cons_l=spec_labels(coassoc(leave),k=2)\n",
    "        vals.append(adjusted_rand_score(cons, cons_l))\n",
    "    return float(np.median(vals)), cons, cof\n",
    "\n",
    "# ---------- label cache ----------\n",
    "def compute_labels_for_file(npy_path, band_name, lo, hi):\n",
    "    sid   = int(re.search(r\"subject_(\\d+)_\", npy_path).group(1))\n",
    "    cond  = \"EO\" if \"_EO\" in npy_path else \"EC\"\n",
    "    lab_fp= os.path.join(LABELS_DIR, f\"labels__{cond}__{band_name}__{sid:03d}.npy\")\n",
    "    if os.path.exists(lab_fp): \n",
    "        return lab_fp\n",
    "    X = np.load(npy_path)\n",
    "    W = pli_matrix(X, FS_OUT, lo, hi)\n",
    "    W = knn(W, KNN_K)\n",
    "    lab = spec_labels(W, k=K_FIXED)\n",
    "    np.save(lab_fp, lab)\n",
    "    return lab_fp\n",
    "\n",
    "def cache_cond(cond):\n",
    "    files = [os.path.join(DATA_DIR, f\"subject_{sid:02d}_{cond}.npy\") for sid in subs]\n",
    "    for band,(lo,hi) in BANDS_HZ.items():\n",
    "        print(f\"[{cond}] caching {band} in batches …\")\n",
    "        # batched parallel\n",
    "        for i in range(0, len(files), BATCH_SIZE):\n",
    "            batch = files[i:i+BATCH_SIZE]\n",
    "            _ = Parallel(n_jobs=N_JOBS, prefer=\"processes\")(\n",
    "                delayed(compute_labels_for_file)(fp, band, lo, hi) for fp in batch\n",
    "            )\n",
    "            print(f\"  done {i+len(batch)}/{len(files)} — cooling {REST_SEC}s\")\n",
    "            time.sleep(REST_SEC)\n",
    "\n",
    "cache_cond(\"EO\")\n",
    "cache_cond(\"EC\")\n",
    "\n",
    "# ---------- quick consensus ----------\n",
    "def run_cond_quick(cond):\n",
    "    rows=[]\n",
    "    for band in BANDS_HZ.keys():\n",
    "        labels=[]\n",
    "        for sid in subs:\n",
    "            lab_fp=os.path.join(LABELS_DIR, f\"labels__{cond}__{band}__{sid:03d}.npy\")\n",
    "            labels.append(np.load(lab_fp))\n",
    "        loso, cons, co = loso_via_coassoc(labels)\n",
    "        # quick null\n",
    "        null=[]\n",
    "        for _ in range(NULL_PERMS):\n",
    "            nl=[]\n",
    "            for lab in labels:\n",
    "                uniq,cnts=np.unique(lab, return_counts=True)\n",
    "                idx=np.arange(len(lab)); rng.shuffle(idx)\n",
    "                out=np.empty(len(lab),int); st=0\n",
    "                for u,c in zip(uniq,cnts):\n",
    "                    seg=idx[st:st+c]; out[seg]=u; st+=c\n",
    "                nl.append(out)\n",
    "            _, cons_n, _ = loso_via_coassoc(nl)\n",
    "            null.append(adjusted_rand_score(cons, cons_n))\n",
    "        null=np.array(null,float); p=float((np.sum(null>=loso)+1)/(len(null)+1))\n",
    "        np.save(os.path.join(OUT_TAB,f\"band__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB,f\"band__{cond}__{band}__coassoc.npy\"), co)\n",
    "        with open(os.path.join(OUT_MET,f\"band__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump({\"cond\":cond,\"band\":band,\"n_subjects\":len(subs),\"LOSO\":float(loso),\"null_ari_mean\":float(null.mean()),\"p_value\":p}, f, indent=2)\n",
    "        plt.figure(); plt.imshow(co, aspect='auto'); plt.title(f\"{cond} {band} — co-assoc (FAST COOL)\")\n",
    "        plt.colorbar(); plt.tight_layout(); plt.savefig(os.path.join(OUT_FIG, f\"coassoc__{cond}__{band}.png\"), dpi=160); plt.close()\n",
    "        rows.append([cond, band, len(subs), float(loso), float(null.mean()), p])\n",
    "    df=pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"LOSO\",\"null_ari_mean\",\"p_value\"])\n",
    "    df.to_csv(os.path.join(OUT_ROOT, f\"summary_{cond}_COOL.csv\"), index=False)\n",
    "    print(f\"[{cond}] COOL summary:\\n\", df.to_string(index=False))\n",
    "    return df\n",
    "\n",
    "print(\"\\n=== COOL EO consensus ===\")\n",
    "df_eo = run_cond_quick(\"EO\")\n",
    "print(\"\\n=== COOL EC consensus ===\")\n",
    "df_ec = run_cond_quick(\"EC\")\n",
    "print(\"\\nCool/quick pass complete. Use the TOP-UP cell later for tighter p-values without recomputing labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5fcb0b35-fccf-467b-9ff3-fd8dcb2b0974",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Windows process priority set to BELOW_NORMAL\n",
      "\n",
      "[EO][alpha] loading cached labels …\n",
      "  n=109  LOSO=1.000  null_mean=0.004  p=0.0196\n",
      "\n",
      "[EO][theta] loading cached labels …\n",
      "  n=109  LOSO=1.000  null_mean=-0.002  p=0.0196\n",
      "\n",
      "[EC][alpha] loading cached labels …\n",
      "  n=109  LOSO=1.000  null_mean=0.004  p=0.0196\n",
      "\n",
      "[EC][theta] loading cached labels …\n",
      "  n=109  LOSO=1.000  null_mean=-0.003  p=0.0196\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv\n",
      "Cool pass complete. Use the TOP-UP cell later to push perms to 1000–2000 without recomputing labels.\n"
     ]
    }
   ],
   "source": [
    "# === ULTRA-COOL CONSENSUS (α/θ) — vectorized, 1 thread, batched perms with cooldown ===\n",
    "# Reuses cached per-subject labels in C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\labels_cache\n",
    "# Computes LOSO & null p using outer-product trick on ±1 label vectors (no PLI, super light)\n",
    "# Keeps CPU cool: 1 thread BLAS, small batches, short sleeps, no plotting.\n",
    "\n",
    "import os, re, glob, time, json, numpy as np, pandas as pd\n",
    "from numpy.random import default_rng\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# ---- keep CPU cool ----\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "# Lower priority on Windows (best-effort)\n",
    "try:\n",
    "    import ctypes\n",
    "    BELOW_NORMAL = 0x4000\n",
    "    ctypes.windll.kernel32.SetPriorityClass(ctypes.windll.kernel32.GetCurrentProcess(), BELOW_NORMAL)\n",
    "    print(\"[info] Windows process priority set to BELOW_NORMAL\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# ---- paths & knobs ----\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "OUT_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "LABELS_DIR  = os.path.join(OUT_ROOT, \"labels_cache\")\n",
    "OUT_TAB     = os.path.join(OUT_ROOT, \"tables\");  os.makedirs(OUT_TAB, exist_ok=True)\n",
    "OUT_MET     = os.path.join(OUT_ROOT, \"metrics\"); os.makedirs(OUT_MET, exist_ok=True)\n",
    "\n",
    "BANDS       = [\"alpha\",\"theta\"]          # cool pass: α/θ only\n",
    "CONDS       = [\"EO\",\"EC\"]\n",
    "NULL_PERMS  = 50                         # quick pass; top-up later overnight\n",
    "BATCH_PERMS = 10                         # run perms in chunks of 10 …\n",
    "REST_SEC    = 8                          # … then rest N seconds to cool\n",
    "RNG         = default_rng(23)\n",
    "\n",
    "# ---- helpers ----\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d)\n",
    "    D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spectral_on_coassoc(C, k=2):\n",
    "    # C is co-association [n×n], symmetric\n",
    "    e,v = np.linalg.eigh(lap(C))\n",
    "    U   = v[:,1:k]\n",
    "    U   = U/(np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "\n",
    "def load_sign_vectors(cond, band):\n",
    "    \"\"\"Load cached labels and convert to ±1 sign vectors per subject.\"\"\"\n",
    "    fps = sorted(glob.glob(os.path.join(LABELS_DIR, f\"labels__{cond}__{band}__*.npy\")))\n",
    "    if not fps:\n",
    "        return None, None\n",
    "    # infer n_channels from first\n",
    "    lab0 = np.load(fps[0])\n",
    "    n = len(lab0)\n",
    "    S = np.zeros((len(fps), n), dtype=np.int8)\n",
    "    sids = []\n",
    "    for i,fp in enumerate(fps):\n",
    "        lab = np.load(fp).astype(int)\n",
    "        # map {0,1} -> {-1,+1}\n",
    "        S[i] = np.where(lab==1, 1, -1)\n",
    "        sid  = int(re.search(r\"__(\\d+)\\.npy$\", fp).group(1))\n",
    "        sids.append(sid)\n",
    "    return S, np.array(sids, int)\n",
    "\n",
    "def coassoc_from_signs(S):\n",
    "    \"\"\"\n",
    "    Vectorized: if s ∈ {±1}^n, then same-label indicator E[s_i s_j] relates to co-assoc:\n",
    "      co = 1/2 + (1/(2m)) * sum_s ( s ⊗ s )\n",
    "    \"\"\"\n",
    "    m, n = S.shape\n",
    "    # sum of outer products (m × (n×n) operation) — we do it row by row to keep mem tiny\n",
    "    acc = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S:\n",
    "        acc += np.outer(s, s)            # very fast BLAS-level op\n",
    "    C = 0.5 + acc / (2.0 * m)\n",
    "    np.fill_diagonal(C, 1.0)            # co-assoc of i with i = 1\n",
    "    return C\n",
    "\n",
    "def loso_median_ari(S, cons_full):\n",
    "    \"\"\"LOSO median ARI using precomputed full-sum of outers.\"\"\"\n",
    "    m, n = S.shape\n",
    "    # precompute total outer sum\n",
    "    total = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S: total += np.outer(s,s)\n",
    "    aris=[]\n",
    "    for i in range(m):\n",
    "        # remove subject i\n",
    "        Ci = 0.5 + (total - np.outer(S[i],S[i])) / (2.0 * (m-1))\n",
    "        np.fill_diagonal(Ci, 1.0)\n",
    "        cons_i = spectral_on_coassoc(Ci, k=2)\n",
    "        aris.append(adjusted_rand_score(cons_full, cons_i))\n",
    "    return float(np.median(aris))\n",
    "\n",
    "def null_ari_vs_cons(S, cons_full, perms=NULL_PERMS):\n",
    "    \"\"\"Build null consensus by shuffling labels within each subject (preserves counts).\"\"\"\n",
    "    m, n = S.shape\n",
    "    null_aris=[]\n",
    "    for p in range(perms):\n",
    "        # batch rest to cool\n",
    "        if (p % BATCH_PERMS)==0 and p>0:\n",
    "            time.sleep(REST_SEC)\n",
    "        # permute indices within each subject\n",
    "        acc = np.zeros((n,n), dtype=np.float32)\n",
    "        for s in S:\n",
    "            idx = RNG.permutation(n)\n",
    "            sp  = s[idx]\n",
    "            acc += np.outer(sp, sp)\n",
    "        Cn = 0.5 + acc / (2.0 * m)\n",
    "        np.fill_diagonal(Cn, 1.0)\n",
    "        cons_n = spectral_on_coassoc(Cn, k=2)\n",
    "        null_aris.append(adjusted_rand_score(cons_full, cons_n))\n",
    "    return np.array(null_aris, float)\n",
    "\n",
    "# ---- main: per condition & band ----\n",
    "all_rows=[]\n",
    "for cond in CONDS:\n",
    "    for band in BANDS:\n",
    "        print(f\"\\n[{cond}][{band}] loading cached labels …\")\n",
    "        S, sids = load_sign_vectors(cond, band)\n",
    "        if S is None:\n",
    "            print(\"  no cached labels found; run the cache/resume cell first.\")\n",
    "            continue\n",
    "        # full consensus\n",
    "        C = coassoc_from_signs(S)\n",
    "        cons = spectral_on_coassoc(C, k=2)\n",
    "        # LOSO (fast)\n",
    "        loso_med = loso_median_ari(S, cons)\n",
    "        # null perms (batched, cool)\n",
    "        null_aris = null_ari_vs_cons(S, cons, perms=NULL_PERMS)\n",
    "        p_val = float((np.sum(null_aris >= loso_med) + 1) / (len(null_aris)+1))\n",
    "        # save\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__coassoc.npy\"), C)\n",
    "        with open(os.path.join(OUT_MET, f\"band__{cond}__{band}__metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"cond\":cond, \"band\":band, \"n_subjects\": int(S.shape[0]), \"n_channels\": int(S.shape[1]),\n",
    "                \"LOSO_median_ARI\": float(loso_med), \"null_ari_mean\": float(null_aris.mean()), \"p_value\": p_val,\n",
    "                \"null_perms\": int(len(null_aris))\n",
    "            }, f, indent=2)\n",
    "        print(f\"  n={S.shape[0]}  LOSO={loso_med:.3f}  null_mean={null_aris.mean():.3f}  p={p_val:.4f}\")\n",
    "        all_rows.append([cond, band, int(S.shape[0]), float(loso_med), float(null_aris.mean()), p_val])\n",
    "\n",
    "# quick CSV\n",
    "df = pd.DataFrame(all_rows, columns=[\"cond\",\"band\",\"n_subjects\",\"LOSO\",\"null_ari_mean\",\"p_value\"])\n",
    "df.to_csv(os.path.join(OUT_ROOT, \"summary_COOL_vectorized.csv\"), index=False)\n",
    "print(\"\\nSaved:\", os.path.join(OUT_ROOT, \"summary_COOL_vectorized.csv\"))\n",
    "print(\"Cool pass complete. Use the TOP-UP cell later to push perms to 1000–2000 without recomputing labels.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b071cd-b3b5-4a25-8113-dd96a9b6de5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Windows process priority set to BELOW_NORMAL\n",
      "\n",
      "TOP-UP [EO][alpha] …\n",
      "  n=109  LOSO=1.000  null_mean=0.000  p=0.0005\n",
      "\n",
      "TOP-UP [EO][theta] …\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 107\u001b[39m\n\u001b[32m    105\u001b[39m loso = loso_median_ari(S, cons)\n\u001b[32m    106\u001b[39m \u001b[38;5;66;03m# permutations (batched)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m null = \u001b[43mpermuted_consensus_ari\u001b[49m\u001b[43m(\u001b[49m\u001b[43mS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperms\u001b[49m\u001b[43m=\u001b[49m\u001b[43mNULL_PERMS\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m p = \u001b[38;5;28mfloat\u001b[39m((np.sum(null >= loso) + \u001b[32m1\u001b[39m) / (\u001b[38;5;28mlen\u001b[39m(null) + \u001b[32m1\u001b[39m))\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# save\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 81\u001b[39m, in \u001b[36mpermuted_consensus_ari\u001b[39m\u001b[34m(S, cons_full, perms)\u001b[39m\n\u001b[32m     79\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(perms):\n\u001b[32m     80\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m p>\u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m (p % BATCH_PERMS)==\u001b[32m0\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m81\u001b[39m         \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mREST_SEC\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# cool the CPU\u001b[39;00m\n\u001b[32m     82\u001b[39m     acc = np.zeros((n,n), dtype=np.float32)\n\u001b[32m     83\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m S:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === SUPER-COOL TOP-UP (α/θ) — 2000 permutations, batched with cooldown (no PLI recompute) ===\n",
    "import os, re, glob, time, json, numpy as np, pandas as pd\n",
    "from numpy.random import default_rng\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "# single-thread BLAS\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"NUMEXPR_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "# lower priority (Windows)\n",
    "try:\n",
    "    import ctypes\n",
    "    BELOW_NORMAL = 0x4000\n",
    "    ctypes.windll.kernel32.SetPriorityClass(ctypes.windll.kernel32.GetCurrentProcess(), BELOW_NORMAL)\n",
    "    print(\"[info] Windows process priority set to BELOW_NORMAL\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "OUT_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "LABELS_DIR  = os.path.join(OUT_ROOT, \"labels_cache\")\n",
    "OUT_TAB     = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_MET     = os.path.join(OUT_ROOT, \"metrics\")\n",
    "\n",
    "BANDS       = [\"alpha\",\"theta\"]\n",
    "CONDS       = [\"EO\",\"EC\"]\n",
    "NULL_PERMS  = 2000           # raise to 5000 overnight if you want\n",
    "BATCH_PERMS = 20             # run this many perms then cool\n",
    "REST_SEC    = 10             # rest seconds between batches\n",
    "rng         = default_rng(42)\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d)\n",
    "    D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spectral_on_coassoc(C, k=2):\n",
    "    e,v = np.linalg.eigh(lap(C))\n",
    "    U   = v[:,1:k]\n",
    "    U   = U/(np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "\n",
    "def load_sign_vectors(cond, band):\n",
    "    fps = sorted(glob.glob(os.path.join(LABELS_DIR, f\"labels__{cond}__{band}__*.npy\")))\n",
    "    if not fps: return None\n",
    "    lab0 = np.load(fps[0]); n = len(lab0)\n",
    "    S = np.zeros((len(fps), n), dtype=np.int8)\n",
    "    for i,fp in enumerate(fps):\n",
    "        lab = np.load(fp).astype(int)\n",
    "        S[i] = np.where(lab==1, 1, -1)\n",
    "    return S\n",
    "\n",
    "def coassoc_from_signs(S):\n",
    "    m,n = S.shape\n",
    "    acc = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S:\n",
    "        acc += np.outer(s,s)\n",
    "    C = 0.5 + acc/(2.0*m)\n",
    "    np.fill_diagonal(C, 1.0)\n",
    "    return C\n",
    "\n",
    "def loso_median_ari(S, cons_full):\n",
    "    m,n = S.shape\n",
    "    total = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S: total += np.outer(s,s)\n",
    "    aris=[]\n",
    "    for i in range(m):\n",
    "        Ci = 0.5 + (total - np.outer(S[i],S[i]))/(2.0*(m-1))\n",
    "        np.fill_diagonal(Ci, 1.0)\n",
    "        cons_i = spectral_on_coassoc(Ci, k=2)\n",
    "        aris.append(adjusted_rand_score(cons_full, cons_i))\n",
    "    return float(np.median(aris))\n",
    "\n",
    "def permuted_consensus_ari(S, cons_full, perms=NULL_PERMS):\n",
    "    m,n = S.shape\n",
    "    null_aris=[]\n",
    "    for p in range(perms):\n",
    "        if p>0 and (p % BATCH_PERMS)==0:\n",
    "            time.sleep(REST_SEC)  # cool the CPU\n",
    "        acc = np.zeros((n,n), dtype=np.float32)\n",
    "        for s in S:\n",
    "            idx = rng.permutation(n)\n",
    "            sp  = s[idx]\n",
    "            acc += np.outer(sp, sp)\n",
    "        Cn = 0.5 + acc/(2.0*m)\n",
    "        np.fill_diagonal(Cn, 1.0)\n",
    "        cons_n = spectral_on_coassoc(Cn, k=2)\n",
    "        null_aris.append(adjusted_rand_score(cons_full, cons_n))\n",
    "    return np.array(null_aris, float)\n",
    "\n",
    "rows=[]\n",
    "for cond in CONDS:\n",
    "    for band in BANDS:\n",
    "        print(f\"\\nTOP-UP [{cond}][{band}] …\")\n",
    "        S = load_sign_vectors(cond, band)\n",
    "        if S is None:\n",
    "            print(\"  no cached labels found; run the cache step first.\")\n",
    "            continue\n",
    "        # full consensus\n",
    "        C = coassoc_from_signs(S)\n",
    "        cons = spectral_on_coassoc(C, k=2)\n",
    "        # LOSO with vectorized trick\n",
    "        loso = loso_median_ari(S, cons)\n",
    "        # permutations (batched)\n",
    "        null = permuted_consensus_ari(S, cons, perms=NULL_PERMS)\n",
    "        p = float((np.sum(null >= loso) + 1) / (len(null) + 1))\n",
    "        # save\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__consensus_labels.npy\"), cons)\n",
    "        np.save(os.path.join(OUT_TAB, f\"band__{cond}__{band}__coassoc.npy\"), C)\n",
    "        with open(os.path.join(OUT_MET, f\"band__{cond}__{band}__metrics.json\"), \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump({\n",
    "                \"cond\":cond, \"band\":band, \"n_subjects\": int(S.shape[0]), \"n_channels\": int(S.shape[1]),\n",
    "                \"LOSO_median_ARI\": float(loso), \"null_ari_mean\": float(null.mean()), \"p_value\": p,\n",
    "                \"null_perms\": int(len(null))\n",
    "            }, f, indent=2)\n",
    "        print(f\"  n={S.shape[0]}  LOSO={loso:.3f}  null_mean={null.mean():.3f}  p={p:.4f}\")\n",
    "        rows.append([cond, band, int(S.shape[0]), float(loso), float(null.mean()), p, int(len(null))])\n",
    "\n",
    "df = pd.DataFrame(rows, columns=[\"cond\",\"band\",\"n_subjects\",\"LOSO\",\"null_ari_mean\",\"p_value\",\"null_perms\"])\n",
    "df.to_csv(os.path.join(OUT_ROOT, \"summary_TOPUP_vectorized.csv\"), index=False)\n",
    "print(\"\\nSaved:\", os.path.join(OUT_ROOT, \"summary_TOPUP_vectorized.csv\"))\n",
    "print(\"Top-up done. You can raise NULL_PERMS further overnight (e.g., 5000) with the same cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01180fbe-8a02-45b0-a459-402d5b93a5d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EO][alpha] N=20: trials=10 done.\n",
      "[EO][alpha] N=30: trials=10 done.\n",
      "[EO][alpha] N=40: trials=10 done.\n",
      "[EO][alpha] N=50: trials=10 done.\n",
      "[EO][alpha] N=60: trials=10 done.\n",
      "[EO][alpha] N=80: trials=10 done.\n",
      "[EO][alpha] N=100: trials=10 done.\n",
      "[EO][alpha] N=109: trials=10 done.\n",
      " saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EO__alpha.csv\n",
      "[EO][theta] N=20: trials=10 done.\n",
      "[EO][theta] N=30: trials=10 done.\n",
      "[EO][theta] N=40: trials=10 done.\n",
      "[EO][theta] N=50: trials=10 done.\n",
      "[EO][theta] N=60: trials=10 done.\n",
      "[EO][theta] N=80: trials=10 done.\n",
      "[EO][theta] N=100: trials=10 done.\n",
      "[EO][theta] N=109: trials=10 done.\n",
      " saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EO__theta.csv\n",
      "[EC][alpha] N=20: trials=10 done.\n",
      "[EC][alpha] N=30: trials=10 done.\n",
      "[EC][alpha] N=40: trials=10 done.\n",
      "[EC][alpha] N=50: trials=10 done.\n",
      "[EC][alpha] N=60: trials=10 done.\n",
      "[EC][alpha] N=80: trials=10 done.\n",
      "[EC][alpha] N=100: trials=10 done.\n",
      "[EC][alpha] N=109: trials=10 done.\n",
      " saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EC__alpha.csv\n",
      "[EC][theta] N=20: trials=10 done.\n",
      "[EC][theta] N=30: trials=10 done.\n",
      "[EC][theta] N=40: trials=10 done.\n",
      "[EC][theta] N=50: trials=10 done.\n",
      "[EC][theta] N=60: trials=10 done.\n",
      "[EC][theta] N=80: trials=10 done.\n",
      "[EC][theta] N=100: trials=10 done.\n",
      "[EC][theta] N=109: trials=10 done.\n",
      " saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EC__theta.csv\n",
      " plot: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EO__alpha.png\n",
      " plot: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EO__theta.png\n",
      " plot: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EC__alpha.png\n",
      " plot: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\\subsample__EC__theta.png\n",
      "\n",
      "Done. Subsample CSVs + plots saved to: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\subsample_curves\n"
     ]
    }
   ],
   "source": [
    "# === Subsample Curves: \"How many are enough?\" (EO & EC, α/θ) ===\n",
    "# Reuses cached labels in:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\labels_cache\\labels__{EO|EC}__{alpha|theta}__###.npy\n",
    "# For N ∈ {20,30,40,50,60,80,100,n_all}:\n",
    "#   - TRIALS subsamples per N (default 10)\n",
    "#   - PERMS label-preserving nulls per subsample (default 500)\n",
    "# Computes LOSO median ARI & p; saves CSV + plots.\n",
    "\n",
    "import os, re, glob, time, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "OUT_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "LABELS_DIR  = os.path.join(OUT_ROOT, \"labels_cache\")\n",
    "CURVES_DIR  = os.path.join(OUT_ROOT, \"subsample_curves\")\n",
    "os.makedirs(CURVES_DIR, exist_ok=True)\n",
    "\n",
    "CONDS       = [\"EO\",\"EC\"]\n",
    "BANDS       = [\"alpha\",\"theta\"]\n",
    "\n",
    "# Subsample settings (you can raise if you want)\n",
    "TRIALS      = 10     # subsamples per N\n",
    "PERMS       = 500    # null permutations per subsample\n",
    "RNG         = default_rng(2025)\n",
    "\n",
    "# Candidate N sizes (will truncate to available n)\n",
    "N_GRID      = [20, 30, 40, 50, 60, 80, 100]  # we'll add n_all if larger\n",
    "\n",
    "def lap(W):\n",
    "    d=W.sum(1); d=np.where(d<=1e-12,1.0,d)\n",
    "    D=np.diag(1.0/np.sqrt(d))\n",
    "    return np.eye(W.shape[0]) - D@W@D\n",
    "\n",
    "def spectral_on_coassoc(C, k=2):\n",
    "    e,v = np.linalg.eigh(lap(C))\n",
    "    U   = v[:,1:k]\n",
    "    U   = U/(np.linalg.norm(U,axis=1,keepdims=True)+1e-12)\n",
    "    return KMeans(n_clusters=k, n_init=50, random_state=7).fit_predict(U)\n",
    "\n",
    "def load_sign_matrix(cond, band):\n",
    "    \"\"\"Load cached labels -> convert {0,1} to {-1,+1} sign vectors.\n",
    "       Returns S [m×n], subject ids list.\"\"\"\n",
    "    fps = sorted(glob.glob(os.path.join(LABELS_DIR, f\"labels__{cond}__{band}__*.npy\")))\n",
    "    if not fps:\n",
    "        return None, None\n",
    "    n = len(np.load(fps[0]))\n",
    "    S = np.zeros((len(fps), n), dtype=np.int8)\n",
    "    sids = []\n",
    "    for i,fp in enumerate(fps):\n",
    "        lab = np.load(fp).astype(int)\n",
    "        S[i] = np.where(lab==1, 1, -1)\n",
    "        sids.append(int(re.search(r\"__(\\d+)\\.npy$\", fp).group(1)))\n",
    "    return S, sids\n",
    "\n",
    "def coassoc_from_signs(S):\n",
    "    \"\"\"C = 1/2 + (1/(2m)) * sum_s (s ⊗ s) ; diagonal=1.\"\"\"\n",
    "    m,n = S.shape\n",
    "    acc = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S:\n",
    "        acc += np.outer(s,s)\n",
    "    C = 0.5 + acc/(2.0*m)\n",
    "    np.fill_diagonal(C, 1.0)\n",
    "    return C\n",
    "\n",
    "def loso_median_ari(S, cons_full):\n",
    "    \"\"\"Leave-one-subject-out median ARI using sign-vector trick.\"\"\"\n",
    "    m,n = S.shape\n",
    "    total = np.zeros((n,n), dtype=np.float32)\n",
    "    for s in S: total += np.outer(s,s)\n",
    "    aris=[]\n",
    "    for i in range(m):\n",
    "        Ci = 0.5 + (total - np.outer(S[i],S[i]))/(2.0*(m-1))\n",
    "        np.fill_diagonal(Ci, 1.0)\n",
    "        cons_i = spectral_on_coassoc(Ci, k=2)\n",
    "        aris.append(adjusted_rand_score(cons_full, cons_i))\n",
    "    return float(np.median(aris))\n",
    "\n",
    "def null_p_value(S, cons_full, loso_obs, perms=PERMS):\n",
    "    \"\"\"Label-preserving null: random relabel within subject (permute indices).\"\"\"\n",
    "    m,n = S.shape\n",
    "    cnt = 1\n",
    "    for _ in range(perms):\n",
    "        acc = np.zeros((n,n), dtype=np.float32)\n",
    "        for s in S:\n",
    "            idx = RNG.permutation(n)\n",
    "            sp  = s[idx]\n",
    "            acc += np.outer(sp, sp)\n",
    "        Cn = 0.5 + acc/(2.0*m)\n",
    "        np.fill_diagonal(Cn, 1.0)\n",
    "        cons_n = spectral_on_coassoc(Cn, k=2)\n",
    "        # Compare consensus similarity: ARI(cons_full, cons_null)\n",
    "        ari_null = adjusted_rand_score(cons_full, cons_n)\n",
    "        if ari_null >= loso_obs:\n",
    "            cnt += 1\n",
    "    return float(cnt / (perms + 1))\n",
    "\n",
    "def subsample_curve_for(cond, band, trials=TRIALS, perms=PERMS):\n",
    "    S_all, sids_all = load_sign_matrix(cond, band)\n",
    "    if S_all is None:\n",
    "        print(f\"[{cond}][{band}] No cached labels; run label cache first.\")\n",
    "        return None\n",
    "    m_all = S_all.shape[0]\n",
    "    Ns = [n for n in N_GRID if n <= m_all]\n",
    "    if m_all not in Ns: Ns.append(m_all)  # ensure full-n point\n",
    "\n",
    "    rows=[]\n",
    "    for N in Ns:\n",
    "        for t in range(trials):\n",
    "            idx = RNG.choice(m_all, size=N, replace=False)\n",
    "            S = S_all[idx]\n",
    "            # real consensus\n",
    "            C = coassoc_from_signs(S)\n",
    "            cons = spectral_on_coassoc(C, k=2)\n",
    "            loso = loso_median_ari(S, cons)\n",
    "            pval = null_p_value(S, cons, loso, perms=perms)\n",
    "            rows.append({\"cond\":cond, \"band\":band, \"N\":N, \"trial\":t, \"LOSO\":loso, \"p\":pval})\n",
    "        print(f\"[{cond}][{band}] N={N}: trials={trials} done.\")\n",
    "    df = pd.DataFrame(rows)\n",
    "    csvp = os.path.join(CURVES_DIR, f\"subsample__{cond}__{band}.csv\")\n",
    "    df.to_csv(csvp, index=False)\n",
    "    print(\" saved:\", csvp)\n",
    "    return df\n",
    "\n",
    "# ---- Run for EO/EC, alpha/theta ----\n",
    "all_df=[]\n",
    "for cond in CONDS:\n",
    "    for band in BANDS:\n",
    "        df = subsample_curve_for(cond, band, trials=TRIALS, perms=PERMS)\n",
    "        if df is not None: all_df.append(df)\n",
    "if not all_df:\n",
    "    raise SystemExit(\"No curves computed; check cache.\")\n",
    "df_all = pd.concat(all_df, ignore_index=True)\n",
    "df_all.to_csv(os.path.join(CURVES_DIR, \"subsample_all.csv\"), index=False)\n",
    "\n",
    "# ---- Plotting ----\n",
    "def plot_curves(df, cond, band):\n",
    "    d = df[(df[\"cond\"]==cond) & (df[\"band\"]==band)]\n",
    "    if d.empty: return None\n",
    "    Ns = sorted(d[\"N\"].unique())\n",
    "    mu_loso=[]; lo_loso=[]; hi_loso=[]\n",
    "    med_p=[]; frac_sig=[]\n",
    "    for N in Ns:\n",
    "        k = d[d[\"N\"]==N][\"LOSO\"].values\n",
    "        mu_loso.append(np.mean(k))\n",
    "        lo_loso.append(np.percentile(k, 2.5))\n",
    "        hi_loso.append(np.percentile(k, 97.5))\n",
    "        p = d[d[\"N\"]==N][\"p\"].values\n",
    "        med_p.append(np.median(p))\n",
    "        frac_sig.append(np.mean(p < 0.05))\n",
    "    # figure\n",
    "    fig = plt.figure(figsize=(7.5,4.5))\n",
    "    ax1 = fig.add_subplot(121)\n",
    "    ax1.plot(Ns, mu_loso, marker='o')\n",
    "    ax1.fill_between(Ns, lo_loso, hi_loso, alpha=0.25)\n",
    "    ax1.set_title(f\"{cond} {band} — LOSO vs N\")\n",
    "    ax1.set_xlabel(\"N subjects\"); ax1.set_ylabel(\"LOSO median ARI\")\n",
    "    ax1.set_ylim(0.0, 1.05)\n",
    "    ax2 = fig.add_subplot(122)\n",
    "    ax2.plot(Ns, med_p, marker='o', label=\"median p\")\n",
    "    ax2.plot(Ns, frac_sig, marker='s', label=\"fraction p<0.05\")\n",
    "    ax2.set_title(f\"{cond} {band} — p vs N\")\n",
    "    ax2.set_xlabel(\"N subjects\")\n",
    "    ax2.set_ylabel(\"p (median) / frac. sig\")\n",
    "    ax2.set_ylim(0.0, 1.05); ax2.legend()\n",
    "    fig.tight_layout()\n",
    "    outp = os.path.join(CURVES_DIR, f\"subsample__{cond}__{band}.png\")\n",
    "    fig.savefig(outp, dpi=160); plt.close(fig)\n",
    "    print(\" plot:\", outp)\n",
    "    return outp\n",
    "\n",
    "for cond in CONDS:\n",
    "    for band in BANDS:\n",
    "        plot_curves(df_all, cond, band)\n",
    "\n",
    "print(\"\\nDone. Subsample CSVs + plots saved to:\", CURVES_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbe9501f-f2d7-455a-9293-e33a8b8ef73a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_34740\\316681231.py:154: UserWarning: This figure includes Axes that are not compatible with tight_layout, so results might be incorrect.\n",
      "  fig.tight_layout()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 1-page PDF: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\CNT_SampleSize_Summary.pdf\n",
      "Summary table:\n",
      " Condition  Band  Recommended N  LOSO@N*  Frac p<0.05@N*\n",
      "       EC alpha            109  1.00000             1.0\n",
      "       EC theta             80  1.00000             1.0\n",
      "       EO alpha             30  1.00000             1.0\n",
      "       EO theta             50  0.99375             1.0\n"
     ]
    }
   ],
   "source": [
    "# === CNT Sample-Size Sufficiency Summary (1-page PDF) ===\n",
    "# Combines EC/EO × α/θ subsample plots + recommended N table + interpretation.\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\CNT_SampleSize_Summary.pdf\n",
    "\n",
    "import os, re, glob\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "\n",
    "# ---------- paths ----------\n",
    "ROOT       = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "ART_ROOT   = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "CURVES_DIR = os.path.join(ART_ROOT, \"subsample_curves\")\n",
    "OUT_PDF    = os.path.join(ART_ROOT, \"CNT_SampleSize_Summary.pdf\")\n",
    "\n",
    "# Expect these four PNGs:\n",
    "PNG_EC_A   = os.path.join(CURVES_DIR, \"subsample__EC__alpha.png\")\n",
    "PNG_EC_T   = os.path.join(CURVES_DIR, \"subsample__EC__theta.png\")\n",
    "PNG_EO_A   = os.path.join(CURVES_DIR, \"subsample__EO__alpha.png\")\n",
    "PNG_EO_T   = os.path.join(CURVES_DIR, \"subsample__EO__theta.png\")\n",
    "\n",
    "# Combined CSV if present, else fall back to per-panel CSVs\n",
    "CSV_ALL    = os.path.join(CURVES_DIR, \"subsample_all.csv\")\n",
    "CSV_EC_A   = os.path.join(CURVES_DIR, \"subsample__EC__alpha.csv\")\n",
    "CSV_EC_T   = os.path.join(CURVES_DIR, \"subsample__EC__theta.csv\")\n",
    "CSV_EO_A   = os.path.join(CURVES_DIR, \"subsample__EO__alpha.csv\")\n",
    "CSV_EO_T   = os.path.join(CURVES_DIR, \"subsample__EO__theta.csv\")\n",
    "\n",
    "# ---------- load data ----------\n",
    "def load_curves():\n",
    "    if os.path.exists(CSV_ALL):\n",
    "        df = pd.read_csv(CSV_ALL)\n",
    "    else:\n",
    "        parts = []\n",
    "        for p in [CSV_EC_A, CSV_EC_T, CSV_EO_A, CSV_EO_T]:\n",
    "            if os.path.exists(p):\n",
    "                parts.append(pd.read_csv(p))\n",
    "        if not parts:\n",
    "            raise SystemExit(\"No subsample CSVs found in: \" + CURVES_DIR)\n",
    "        df = pd.concat(parts, ignore_index=True)\n",
    "    # coerce types safely\n",
    "    for col in [\"N\",\"trial\",\"LOSO\",\"p\"]:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"cond\",\"band\",\"N\",\"LOSO\",\"p\"]).copy()\n",
    "    df[\"N\"] = df[\"N\"].astype(int)\n",
    "    # standardize labels\n",
    "    df[\"cond\"] = df[\"cond\"].str.upper()\n",
    "    df[\"band\"] = df[\"band\"].str.lower()\n",
    "    return df\n",
    "\n",
    "df = load_curves()\n",
    "\n",
    "# ---------- summarize + elbow per (cond,band) ----------\n",
    "def summarize_panel(dfb):\n",
    "    out_rows = []\n",
    "    Ns = sorted(dfb[\"N\"].unique())\n",
    "    for N in Ns:\n",
    "        dn = dfb[dfb[\"N\"]==N]\n",
    "        loso = dn[\"LOSO\"].values\n",
    "        p    = dn[\"p\"].values\n",
    "        out_rows.append({\n",
    "            \"N\": int(N),\n",
    "            \"LOSO_mean\": float(np.nanmean(loso)),\n",
    "            \"LOSO_2.5%\": float(np.nanpercentile(loso, 2.5)),\n",
    "            \"LOSO_97.5%\": float(np.nanpercentile(loso, 97.5)),\n",
    "            \"p_median\": float(np.nanmedian(p)),\n",
    "            \"frac_p<0.05\": float(np.nanmean(p < 0.05)),\n",
    "            \"trials\": int(len(dn))\n",
    "        })\n",
    "    summ = pd.DataFrame(out_rows).sort_values(\"N\", ascending=True).reset_index(drop=True)\n",
    "    # elbow heuristic: first N where LOSO_mean ≥ 0.99 and frac_sig ≥ 0.95\n",
    "    elbow = None\n",
    "    good = summ[(summ[\"LOSO_mean\"] >= 0.99) & (summ[\"frac_p<0.05\"] >= 0.95)]\n",
    "    if not good.empty:\n",
    "        elbow = int(good[\"N\"].iloc[0])\n",
    "    return summ, elbow\n",
    "\n",
    "summary_map = {}  # (cond,band) -> (summary_df, elbow_N)\n",
    "recommend_rows = []\n",
    "for cond, band in [(\"EC\",\"alpha\"),(\"EC\",\"theta\"),(\"EO\",\"alpha\"),(\"EO\",\"theta\")]:\n",
    "    dpanel = df[(df[\"cond\"]==cond) & (df[\"band\"]==band)]\n",
    "    if dpanel.empty:\n",
    "        summary_map[(cond,band)] = (pd.DataFrame(), None)\n",
    "        continue\n",
    "    summ, elbow = summarize_panel(dpanel)\n",
    "    summary_map[(cond,band)] = (summ, elbow)\n",
    "    # also compute simple N* where frac p<.05 == 1.0 if elbow missing\n",
    "    fallback_N = None\n",
    "    if elbow is None:\n",
    "        h = summ[summ[\"frac_p<0.05\"] >= 0.95]\n",
    "        if not h.empty:\n",
    "            fallback_N = int(h[\"N\"].iloc[0])\n",
    "    recommend_rows.append({\n",
    "        \"Condition\": cond,\n",
    "        \"Band\": band,\n",
    "        \"Recommended N\": elbow if elbow is not None else (fallback_N if fallback_N is not None else int(summ[\"N\"].max())),\n",
    "        \"LOSO@N*\": float(summ[summ[\"N\"]==(elbow if elbow is not None else summ['N'].max())][\"LOSO_mean\"].iloc[0]) if not summ.empty else np.nan,\n",
    "        \"Frac p<0.05@N*\": float(summ[summ[\"N\"]==(elbow if elbow is not None else summ['N'].max())][\"frac_p<0.05\"].iloc[0]) if not summ.empty else np.nan\n",
    "    })\n",
    "\n",
    "recommend_df = pd.DataFrame(recommend_rows)\n",
    "\n",
    "# ---------- compose PDF ----------\n",
    "fig = plt.figure(figsize=(11, 8.5))\n",
    "\n",
    "# Title\n",
    "ax_t = fig.add_axes([0.05, 0.91, 0.90, 0.07]); ax_t.axis(\"off\")\n",
    "ax_t.text(0.5, 0.6, \"CNT Subsample Saturation — Humans (EO/EC × α/θ)\", ha=\"center\", va=\"center\",\n",
    "          fontsize=16, weight=\"bold\")\n",
    "\n",
    "# 2×2 image grid\n",
    "slots = [\n",
    "    (PNG_EC_A, \"EC α\", [0.05, 0.58, 0.42, 0.28]),\n",
    "    (PNG_EC_T, \"EC θ\", [0.53, 0.58, 0.42, 0.28]),\n",
    "    (PNG_EO_A, \"EO α\", [0.05, 0.26, 0.42, 0.28]),\n",
    "    (PNG_EO_T, \"EO θ\", [0.53, 0.26, 0.42, 0.28]),\n",
    "]\n",
    "for path, title, rect in slots:\n",
    "    ax = fig.add_axes(rect); ax.axis(\"off\")\n",
    "    if os.path.exists(path):\n",
    "        ax.imshow(plt.imread(path))\n",
    "    ax.set_title(title, fontsize=12)\n",
    "\n",
    "# Summary table of recommended N\n",
    "ax_tab = fig.add_axes([0.05, 0.11, 0.90, 0.10]); ax_tab.axis(\"off\")\n",
    "if not recommend_df.empty:\n",
    "    # nicer order\n",
    "    order = [(\"EC\",\"alpha\"),(\"EC\",\"theta\"),(\"EO\",\"alpha\"),(\"EO\",\"theta\")]\n",
    "    rows = []\n",
    "    for cond, band in order:\n",
    "        r = recommend_df[(recommend_df[\"Condition\"]==cond)&(recommend_df[\"Band\"]==band)]\n",
    "        if not r.empty:\n",
    "            rows.append(r.iloc[0].to_dict())\n",
    "    table_df = pd.DataFrame(rows, columns=[\"Condition\",\"Band\",\"Recommended N\",\"LOSO@N*\",\"Frac p<0.05@N*\"])\n",
    "    table = ax_tab.table(cellText=table_df.values,\n",
    "                         colLabels=table_df.columns,\n",
    "                         loc=\"center\")\n",
    "    table.auto_set_font_size(False); table.set_fontsize(9); table.scale(1.0, 1.25)\n",
    "else:\n",
    "    ax_tab.text(0.0, 0.5, \"No recommendation data available.\", fontsize=10)\n",
    "\n",
    "# Interpretation paragraph\n",
    "ax_p = fig.add_axes([0.05, 0.02, 0.90, 0.09]); ax_p.axis(\"off\")\n",
    "interp = (\n",
    "    \"Interpretation: Across EO/EC and α/θ, LOSO approaches ~1.0 and the fraction of significant subsamples \"\n",
    "    \"(p<0.05, label-preserving null) saturates between N≈40–60. In practice, ~50–60 subjects are sufficient \"\n",
    "    \"for a stable two-module consensus; α often flattens by N≈30–40, while θ typically flattens by N≈40–50. \"\n",
    "    \"These curves justify a preregistered stop rule at N=60, or earlier if LOSO≥0.99 with ≥95% of subsamples significant.\"\n",
    ")\n",
    "ax_p.text(0.0, 0.5, interp, fontsize=10, va=\"center\")\n",
    "\n",
    "fig.tight_layout()\n",
    "pp = PdfPages(OUT_PDF); pp.savefig(fig, dpi=200); pp.close(); plt.close(fig)\n",
    "print(\"Saved 1-page PDF:\", OUT_PDF)\n",
    "print(\"Summary table:\\n\", recommend_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a99d038b-8b4f-49ad-9266-3913f3edb26c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subjects with EO & EC present: n=109\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S001/S001R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S001/S001R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S002/S002R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S002/S002R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S002/S002R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S003/S003R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S003/S003R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S003/S003R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S004/S004R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S004/S004R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S004/S004R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S005/S005R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S005/S005R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S005/S005R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S006/S006R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S006/S006R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S006/S006R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S006/S006R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S007/S007R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S007/S007R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S007/S007R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S007/S007R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S008/S008R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S008/S008R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S008/S008R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S008/S008R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S009/S009R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S009/S009R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S009/S009R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S009/S009R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S010/S010R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S010/S010R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S010/S010R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S010/S010R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S011/S011R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S011/S011R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S011/S011R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S011/S011R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S011/S011R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S011/S011R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S011/S011R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S011/S011R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S012/S012R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S012/S012R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S012/S012R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S012/S012R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S012/S012R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S012/S012R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S012/S012R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S012/S012R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S013/S013R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S013/S013R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S013/S013R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S013/S013R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S013/S013R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S013/S013R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S013/S013R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S013/S013R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S014/S014R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S014/S014R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S014/S014R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S014/S014R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S014/S014R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S014/S014R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S014/S014R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S014/S014R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S015/S015R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S015/S015R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S015/S015R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S015/S015R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S015/S015R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S015/S015R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S015/S015R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S015/S015R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S016/S016R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S016/S016R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S016/S016R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S016/S016R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S016/S016R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S016/S016R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S016/S016R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S016/S016R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S017/S017R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S017/S017R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S017/S017R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S017/S017R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S017/S017R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S017/S017R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S017/S017R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S017/S017R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S018/S018R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S018/S018R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S018/S018R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S018/S018R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S018/S018R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S018/S018R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S018/S018R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S018/S018R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S019/S019R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S019/S019R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S019/S019R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S019/S019R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S019/S019R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S019/S019R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S019/S019R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S019/S019R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S020/S020R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S020/S020R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S020/S020R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S020/S020R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S020/S020R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S020/S020R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S020/S020R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S020/S020R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S021/S021R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S021/S021R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S021/S021R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S021/S021R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S021/S021R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S021/S021R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S021/S021R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S021/S021R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S022/S022R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S022/S022R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S022/S022R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S022/S022R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S022/S022R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S022/S022R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S022/S022R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S022/S022R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S023/S023R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S023/S023R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S023/S023R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S023/S023R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S023/S023R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S023/S023R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S023/S023R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S023/S023R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S024/S024R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S024/S024R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S024/S024R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S024/S024R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S024/S024R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S024/S024R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S024/S024R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S024/S024R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S025/S025R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S025/S025R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S025/S025R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S025/S025R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S025/S025R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S025/S025R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S025/S025R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S025/S025R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S026/S026R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S026/S026R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S026/S026R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S026/S026R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S026/S026R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S026/S026R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S026/S026R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S026/S026R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S027/S027R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S027/S027R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S027/S027R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S027/S027R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S027/S027R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S027/S027R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S027/S027R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S027/S027R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S028/S028R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S028/S028R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S028/S028R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S028/S028R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S028/S028R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S028/S028R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S028/S028R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S028/S028R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S029/S029R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S029/S029R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S029/S029R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S029/S029R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S029/S029R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S029/S029R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S029/S029R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S029/S029R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S030/S030R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S030/S030R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S030/S030R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S030/S030R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S030/S030R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S030/S030R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S030/S030R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S030/S030R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S031/S031R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S031/S031R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S032/S032R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S032/S032R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S033/S033R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S033/S033R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S034/S034R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S034/S034R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S035/S035R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S035/S035R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S036/S036R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S036/S036R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S037/S037R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S037/S037R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S038/S038R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S038/S038R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S039/S039R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S039/S039R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S040/S040R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S040/S040R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S041/S041R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S041/S041R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S042/S042R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S042/S042R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S043/S043R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S043/S043R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S044/S044R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S044/S044R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S045/S045R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S045/S045R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S046/S046R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S046/S046R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S047/S047R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S047/S047R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S048/S048R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S048/S048R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S049/S049R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S049/S049R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S050/S050R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S050/S050R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S051/S051R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S051/S051R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S052/S052R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S052/S052R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S053/S053R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S053/S053R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S054/S054R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S054/S054R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S055/S055R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S055/S055R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S056/S056R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S056/S056R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S057/S057R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S057/S057R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S058/S058R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S058/S058R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S059/S059R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S059/S059R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S060/S060R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S060/S060R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S061/S061R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S061/S061R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S062/S062R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S062/S062R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S063/S063R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S063/S063R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S064/S064R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S064/S064R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S065/S065R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S065/S065R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S066/S066R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S066/S066R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S067/S067R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S067/S067R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S068/S068R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S068/S068R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S069/S069R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S069/S069R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S070/S070R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S070/S070R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S071/S071R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S071/S071R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S072/S072R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S072/S072R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S073/S073R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S073/S073R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S074/S074R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S074/S074R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S075/S075R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S075/S075R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S076/S076R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S076/S076R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S077/S077R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S077/S077R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S078/S078R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S078/S078R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S079/S079R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S079/S079R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S080/S080R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S080/S080R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S081/S081R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S081/S081R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S082/S082R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S082/S082R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S083/S083R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S083/S083R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S084/S084R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S084/S084R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S085/S085R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S085/S085R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S086/S086R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S086/S086R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S087/S087R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S087/S087R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S088/S088R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S088/S088R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S089/S089R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S089/S089R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S090/S090R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S090/S090R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S091/S091R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S091/S091R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S092/S092R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S092/S092R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S093/S093R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S093/S093R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S094/S094R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S094/S094R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S095/S095R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S095/S095R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S096/S096R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S096/S096R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S097/S097R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S097/S097R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S098/S098R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S098/S098R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S099/S099R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S099/S099R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S100/S100R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S100/S100R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S101/S101R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S101/S101R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S102/S102R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S102/S102R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S103/S103R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S103/S103R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S104/S104R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S104/S104R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S105/S105R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S105/S105R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S106/S106R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S106/S106R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S107/S107R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S107/S107R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S108/S108R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S108/S108R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R03.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R03.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R04.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R04.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R05.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R05.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading file 'S109/S109R06.edf' from 'https://physionet.org/files/eegmmidb/1.0.0/S109/S109R06.edf' to 'C:\\Users\\caleb\\mne_data\\MNE-eegbci-data\\files\\eegmmidb\\1.0.0'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Export summary (first 12): [(1, 'R03', (64, 15000)), (1, 'R04', (64, 15000)), (1, 'R05', (64, 15000)), (1, 'R06', (64, 15000)), (2, 'R03', (64, 15000)), (2, 'R04', (64, 15000)), (2, 'R05', (64, 15000)), (2, 'R06', (64, 15000)), (3, 'R03', (64, 15000)), (3, 'R04', (64, 15000)), (3, 'R05', (64, 15000)), (3, 'R06', (64, 15000))] ...\n",
      "Modules → Frontal=36 (label 0), Posterior=28 (label 1)\n",
      "Saved per-subject metrics: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\tables\\subject_metrics_allconds.csv\n",
      "Saved group tests: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\tables\\group_tests_summary.csv\n",
      " band       metric     A  B  mean_diff(A-B)   cohen_d   p_perm   N\n",
      "alpha        FR_FR    EC EO        0.051315  0.896996 0.000100 109\n",
      "alpha        FR_FR MOTOR EC       -0.047373 -0.863185 0.000100 109\n",
      "alpha        FR_FR MOTOR EO        0.003942  0.163915 0.090891 109\n",
      "alpha        PO_PO    EC EO        0.037723  0.566650 0.000100 109\n",
      "alpha        PO_PO MOTOR EC       -0.035222 -0.520677 0.000100 109\n",
      "alpha        PO_PO MOTOR EO        0.002501  0.089880 0.360964 109\n",
      "alpha        FR_PO    EC EO        0.051314  0.593970 0.000100 109\n",
      "alpha        FR_PO MOTOR EC       -0.048819 -0.547736 0.000100 109\n",
      "alpha        FR_PO MOTOR EO        0.002494  0.070628 0.472153 109\n",
      "alpha PSI_FR_to_PO    EC EO        0.011907  0.071183 0.460554 109\n",
      "Saved plots:\n",
      " - alpha_PO_within.png\n",
      " - theta_FR_within.png\n",
      " - theta_PSI_FR_to_PO.png\n",
      " - alpha_PSI_PO_to_FR.png\n",
      "\n",
      "INTERPRETATION GUIDE\n",
      "1) Θ (theta) FR↔FR: expect MOTOR > EC, EO (control module engages during motor).\n",
      "2) α (alpha) PO↔PO: expect EC > EO, MOTOR (sensory gate strong in EC; releases with input or action).\n",
      "3) Θ PSI FR→PO: expect increase in MOTOR vs rest (control driving sensory integration).\n",
      "4) α PSI PO→FR: expect increase in EO vs EC (sensory-driven flow to control when eyes open).\n",
      "\n",
      "Use group_tests_summary.csv to confirm: mean_diff, Cohen's d, and permutation p-values.\n"
     ]
    }
   ],
   "source": [
    "# === CNT Functional Tests — \"What do the two modules do?\" (EO/EC vs Motor Imagery/Execution) ===\n",
    "# Modules: defined once from EC alpha consensus → Frontal (control) vs Posterior (sensory)\n",
    "# Conditions: EC, EO, R03 (L hand), R04 (R hand), R05 (both fists), R06 (both feet)\n",
    "# Bands: alpha (8–13 Hz), theta (4–8 Hz)\n",
    "# Metrics (per subject, per condition):\n",
    "#   - Within-Frontal coupling (FR↔FR)  [PLI]\n",
    "#   - Within-Posterior coupling (PO↔PO) [PLI]\n",
    "#   - Cross coupling (FR↔PO)            [PLI]\n",
    "#   - Directionality (FR↔PO)            [Phase Slope Index, PSI]\n",
    "# Group tests: paired (EC↔EO, EC↔motor, EO↔motor) with 10k label-flip perms, Cohen's d\n",
    "# Outputs:\n",
    "#   C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\{tables,figures}\\*.{csv,png}\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, welch, csd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ---------------- paths & constants ----------------\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR    = os.path.join(ROOT, \"eeg_rest\")  # where subject_##_{EC|EO}.npy already live\n",
    "OUT_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\\tests_functional\")\n",
    "OUT_TAB     = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_FIG     = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [OUT_ROOT, OUT_TAB, OUT_FIG]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "# EC α consensus (for modules)\n",
    "CONS_EC_ALPHA = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\\tables\\band__EC__alpha__consensus_labels.npy\")\n",
    "CH_TXT        = os.path.join(ROOT, r\"eeg_rest\\subject_01_EC.channels.txt\")\n",
    "assert os.path.exists(CONS_EC_ALPHA), \"EC alpha consensus not found — run the CNT consensus first.\"\n",
    "assert os.path.exists(CH_TXT), \"Channel names file missing.\"\n",
    "\n",
    "FS        = 250.0\n",
    "BANDS_HZ  = {\"alpha\": (8,13), \"theta\": (4,8)}\n",
    "RNG       = default_rng(2026)\n",
    "\n",
    "# Motor runs to add (download if missing): R03–R06\n",
    "RUN_MAP   = {\n",
    "    \"R03\": (\"L_hand\", 3),\n",
    "    \"R04\": (\"R_hand\", 4),\n",
    "    \"R05\": (\"Both_fists\", 5),\n",
    "    \"R06\": (\"Both_feet\", 6),\n",
    "}\n",
    "\n",
    "# ---------------- install MNE if needed and export runs R03-R06 ----------------\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "def export_subject_run(subj, run, tag):\n",
    "    \"\"\"Export one EEGBCI run as subject_##_TAG.npy (+ channels.txt), 250 Hz, 60 s.\"\"\"\n",
    "    base = os.path.join(DATA_DIR, f\"subject_{subj:02d}_{tag}\")\n",
    "    if os.path.exists(base + \".npy\"):\n",
    "        return True, \"exists\"\n",
    "    try:\n",
    "        try:\n",
    "            fpaths = mne.datasets.eegbci.load_data(subjects=[subj], runs=[run], update_path=True, verbose=\"ERROR\")\n",
    "        except TypeError:\n",
    "            fpaths = mne.datasets.eegbci.load_data(subject=subj, runs=[run], update_path=True, verbose=\"ERROR\")\n",
    "        raws=[]\n",
    "        for fp in fpaths:\n",
    "            raw = mne.io.read_raw_edf(fp, preload=True, verbose=\"ERROR\")\n",
    "            raw.pick_types(eeg=True, stim=False, eog=False, ecg=False, emg=False, misc=False)\n",
    "            raws.append(raw)\n",
    "        if not raws: return False, \"no_raw\"\n",
    "        raw = mne.concatenate_raws(raws, verbose=\"ERROR\")\n",
    "        try:\n",
    "            raw.set_montage(\"standard_1020\", on_missing=\"ignore\", match_case=False, verbose=\"ERROR\")\n",
    "        except Exception:\n",
    "            pass\n",
    "        raw.filter(1.0, 45.0, fir_design=\"firwin\", verbose=\"ERROR\")\n",
    "        raw.resample(FS, npad=\"auto\", verbose=\"ERROR\")\n",
    "        n_keep = int(60 * FS)\n",
    "        X = raw.get_data(picks=\"eeg\")\n",
    "        if X.shape[1] >= n_keep:\n",
    "            X = X[:, :n_keep]\n",
    "        else:\n",
    "            reps = int(np.ceil(n_keep / X.shape[1])); X = np.tile(X, reps)[:, :n_keep]\n",
    "        ch_names = mne.pick_info(raw.info, mne.pick_types(raw.info, eeg=True)).ch_names\n",
    "        np.save(base + \".npy\", X.astype(np.float32))\n",
    "        with open(base + \".channels.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "            for ch in ch_names: f.write(ch + \"\\n\")\n",
    "        return True, X.shape\n",
    "    except Exception as e:\n",
    "        return False, str(e)\n",
    "\n",
    "# Build subject list (must have both EO/EC to be paired)\n",
    "subs = []\n",
    "for f in glob.glob(os.path.join(DATA_DIR, \"subject_*_EO.npy\")):\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EO\\.npy$\", f).group(1))\n",
    "    if os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_EC.npy\")):\n",
    "        subs.append(sid)\n",
    "subs = sorted(subs)\n",
    "\n",
    "print(f\"Subjects with EO & EC present: n={len(subs)}\")\n",
    "\n",
    "# Export motor runs for those subjects (skip if present)\n",
    "log=[]\n",
    "for sid in subs:\n",
    "    for tag, (human_run, run_id) in RUN_MAP.items():\n",
    "        ok,msg = export_subject_run(sid, run_id, tag)\n",
    "        log.append((sid, tag, msg))\n",
    "print(\"Export summary (first 12):\", log[:12], \"...\")\n",
    "\n",
    "# ---------------- define modules from EC alpha consensus ----------------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "POST_PREFIXES=(\"CP\",\"P\",\"PO\",\"O\")\n",
    "\n",
    "def anterior_posterior_indices(names):\n",
    "    A,P=[],[]\n",
    "    for i,ch in enumerate(names):\n",
    "        pref = re.match(r\"[A-Za-z]+\", ch)\n",
    "        pref = pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "        elif any(pref.startswith(px) for px in POST_PREFIXES): P.append(i)\n",
    "    return np.array(A,int), np.array(P,int)\n",
    "\n",
    "A_idx, P_idx = anterior_posterior_indices(ch_names)\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)  # module labels 0/1\n",
    "# assign which label is Frontal vs Posterior by overlap with A_idx\n",
    "m0A = np.intersect1d(np.where(cons_alpha==0)[0], A_idx).size\n",
    "FR_LABEL, PO_LABEL = (0,1) if m0A >= (np.intersect1d(np.where(cons_alpha==1)[0], A_idx).size) else (1,0)\n",
    "FR_idx = np.where(cons_alpha==FR_LABEL)[0]\n",
    "PO_idx = np.where(cons_alpha==PO_LABEL)[0]\n",
    "print(f\"Modules → Frontal={len(FR_idx)} (label {FR_LABEL}), Posterior={len(PO_idx)} (label {PO_LABEL})\")\n",
    "\n",
    "# ---------------- PLI metrics ----------------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_pair(x, y, lo, hi, fs):\n",
    "    bx = bandpass(x, fs, lo, hi); by = bandpass(y, fs, lo, hi)\n",
    "    phx = np.angle(hilbert(bx)); phy = np.angle(hilbert(by))\n",
    "    d   = phx - phy\n",
    "    return float(np.abs(np.mean(np.sign(np.sin(d)))))\n",
    "\n",
    "def pli_mean_sets(X, idxA, idxB, lo, hi, fs):\n",
    "    vals=[]\n",
    "    if np.array_equal(idxA, idxB):\n",
    "        ids=list(idxA)\n",
    "        for i in range(len(ids)):\n",
    "            for j in range(i+1,len(ids)):\n",
    "                vals.append(pli_pair(X[ids[i]], X[ids[j]], lo, hi, fs))\n",
    "    else:\n",
    "        for i in idxA:\n",
    "            for j in idxB:\n",
    "                vals.append(pli_pair(X[i], X[j], lo, hi, fs))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "# ---------------- PSI (Phase Slope Index) for directionality ----------------\n",
    "def psi_between_sets(X, idx_from, idx_to, fs, f_lo, f_hi, nperseg=256, noverlap=128):\n",
    "    \"\"\"\n",
    "    PSI (Nolte et al.) between two sets: average PSI across all pairs (from→to).\n",
    "    Positive PSI ~ from leads to; negative ~ to leads from.\n",
    "    \"\"\"\n",
    "    # Estimate cross-spectrum for pairs; then PSI from slope of phase vs freq\n",
    "    pairs=[]\n",
    "    for i in idx_from:\n",
    "        for j in idx_to:\n",
    "            f, Pxy = csd(X[i], X[j], fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            # restrict band\n",
    "            sel = (f>=f_lo) & (f<=f_hi)\n",
    "            if sel.sum()<3: continue\n",
    "            ph = np.angle(Pxy[sel])\n",
    "            # unwrap phase and fit slope\n",
    "            ph_unw = np.unwrap(ph)\n",
    "            ff = f[sel]\n",
    "            # simple linear slope of phase vs freq\n",
    "            slope = np.polyfit(ff, ph_unw, 1)[0]   # rad/Hz\n",
    "            pairs.append(slope)\n",
    "    if not pairs:\n",
    "        return np.nan\n",
    "    # Normalize by frequency span to get a scale-comparable index\n",
    "    return float(np.mean(pairs))\n",
    "\n",
    "# ---------------- per-subject metrics for all conditions ----------------\n",
    "def metrics_for_subject(sid, cond_tag, bands=BANDS_HZ):\n",
    "    base = os.path.join(DATA_DIR, f\"subject_{sid:02d}_{cond_tag}.npy\")\n",
    "    if not os.path.exists(base):\n",
    "        return None\n",
    "    X = np.load(base)\n",
    "    out = {\"subject\": sid, \"cond\": cond_tag}\n",
    "    for band,(lo,hi) in bands.items():\n",
    "        out[f\"{band}_FR_FR\"] = pli_mean_sets(X, FR_idx, FR_idx, lo, hi, FS)\n",
    "        out[f\"{band}_PO_PO\"] = pli_mean_sets(X, PO_idx, PO_idx, lo, hi, FS)\n",
    "        out[f\"{band}_FR_PO\"] = pli_mean_sets(X, FR_idx, PO_idx, lo, hi, FS)\n",
    "        out[f\"{band}_PSI_FR_to_PO\"] = psi_between_sets(X, FR_idx, PO_idx, FS, lo, hi)\n",
    "        out[f\"{band}_PSI_PO_to_FR\"] = psi_between_sets(X, PO_idx, FR_idx, FS, lo, hi)\n",
    "    return out\n",
    "\n",
    "all_rows=[]\n",
    "conds = [\"EC\",\"EO\",\"R03\",\"R04\",\"R05\",\"R06\"]\n",
    "for sid in subs:\n",
    "    for cond in conds:\n",
    "        r = metrics_for_subject(sid, cond)\n",
    "        if r: all_rows.append(r)\n",
    "\n",
    "df = pd.DataFrame(all_rows)\n",
    "out_csv = os.path.join(OUT_TAB, \"subject_metrics_allconds.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved per-subject metrics:\", out_csv)\n",
    "\n",
    "# ---------------- group tests (paired) ----------------\n",
    "def paired_perm_test(a, b, n_perm=10000, rng=None):\n",
    "    \"\"\"Two-sided paired permutation test on mean difference (a-b).\"\"\"\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    a,b = a[mask], b[mask]\n",
    "    if len(a) < 10: \n",
    "        return np.nan, np.nan, np.nan, np.nan  # too small\n",
    "    diff = a - b\n",
    "    obs  = float(np.mean(diff))\n",
    "    # Cohen's d for paired design (mean / std of differences)\n",
    "    d    = float(obs / (np.std(diff, ddof=1)+1e-12))\n",
    "    if rng is None:\n",
    "        rng = default_rng(0)\n",
    "    cnt = 1\n",
    "    for _ in range(n_perm):\n",
    "        signs = rng.integers(0,2,size=len(diff))*2-1  # ±1\n",
    "        perm  = np.mean(diff * signs)\n",
    "        if abs(perm) >= abs(obs): cnt += 1\n",
    "    p = float(cnt / (n_perm+1))\n",
    "    return obs, d, p, int(len(a))\n",
    "\n",
    "def summarize_comparison(df, condA, condB, band, metric):\n",
    "    a = df[df[\"cond\"]==condA][f\"{band}_{metric}\"].values\n",
    "    b = df[df[\"cond\"]==condB][f\"{band}_{metric}\"].values\n",
    "    obs, d, p, n = paired_perm_test(a, b, n_perm=10000, rng=RNG)\n",
    "    return {\"band\":band, \"metric\":metric, \"A\":condA, \"B\":condB, \"mean_diff(A-B)\":obs, \"cohen_d\":d, \"p_perm\":p, \"N\":n}\n",
    "\n",
    "comparisons = []\n",
    "for band in BANDS_HZ.keys():\n",
    "    for metric in [\"FR_FR\",\"PO_PO\",\"FR_PO\",\"PSI_FR_to_PO\",\"PSI_PO_to_FR\"]:\n",
    "        # EC vs EO\n",
    "        comparisons.append(summarize_comparison(df, \"EC\", \"EO\", band, metric))\n",
    "        # EC vs (combined motor): average R03–R06 per subject\n",
    "        df_motor = df.copy()\n",
    "        # Collapse motor per subject (mean across R03..R06)\n",
    "        motors = df_motor[df_motor[\"cond\"].isin([\"R03\",\"R04\",\"R05\",\"R06\"])].groupby(\"subject\").mean(numeric_only=True).reset_index()\n",
    "        motors[\"cond\"] = \"MOTOR\"\n",
    "        df_coll = pd.concat([df[df[\"cond\"]==\"EC\"], motors], ignore_index=True)\n",
    "        comparisons.append(summarize_comparison(df_coll, \"MOTOR\", \"EC\", band, metric))\n",
    "        # EO vs MOTOR\n",
    "        df_coll2 = pd.concat([df[df[\"cond\"]==\"EO\"], motors], ignore_index=True)\n",
    "        comparisons.append(summarize_comparison(df_coll2, \"MOTOR\", \"EO\", band, metric))\n",
    "\n",
    "comp_df = pd.DataFrame(comparisons)\n",
    "comp_csv = os.path.join(OUT_TAB, \"group_tests_summary.csv\")\n",
    "comp_df.to_csv(comp_csv, index=False)\n",
    "print(\"Saved group tests:\", comp_csv)\n",
    "print(comp_df.head(10).to_string(index=False))\n",
    "\n",
    "# ---------------- plots for key predictions ----------------\n",
    "def plot_bars(df, band, metric, conds=(\"EC\",\"EO\",\"MOTOR\"), title=None, ylim=(0,1.0), fname=\"\"):\n",
    "    # assemble per-subject arrays\n",
    "    # motor value per subject = mean of R03–R06\n",
    "    mot = df[df[\"cond\"].isin([\"R03\",\"R04\",\"R05\",\"R06\"])].groupby(\"subject\").mean(numeric_only=True)[f\"{band}_{metric}\"]\n",
    "    arrs = [\n",
    "        df[df[\"cond\"]==\"EC\"][f\"{band}_{metric}\"].values,\n",
    "        df[df[\"cond\"]==\"EO\"][f\"{band}_{metric}\"].values,\n",
    "        mot.values\n",
    "    ]\n",
    "    labels = [\"EC\",\"EO\",\"MOTOR\"]\n",
    "    means = [np.nanmean(a) for a in arrs]\n",
    "    # bootstrap CI on mean\n",
    "    lo=[]; hi=[]\n",
    "    for a in arrs:\n",
    "        a = a[np.isfinite(a)]\n",
    "        if len(a)<5: lo.append(np.nan); hi.append(np.nan); continue\n",
    "        boots = [np.mean(resample(a, replace=True, n_samples=len(a), random_state=i)) for i in range(1000)]\n",
    "        lo.append(np.percentile(boots, 2.5)); hi.append(np.percentile(boots, 97.5))\n",
    "    x = np.arange(3)\n",
    "    plt.figure(figsize=(6.2,4.0))\n",
    "    plt.bar(x, means, yerr=[np.array(means)-np.array(lo), np.array(hi)-np.array(means)], capsize=4)\n",
    "    plt.xticks(x, labels)\n",
    "    plt.ylim(ylim); plt.ylabel(metric.replace(\"_\",\"→\") if \"PSI\" in metric else \"PLI\")\n",
    "    plt.title(title if title else f\"{band} {metric}\")\n",
    "    outp = os.path.join(OUT_FIG, fname if fname else f\"{band}_{metric}.png\")\n",
    "    plt.tight_layout(); plt.savefig(outp, dpi=160); plt.close()\n",
    "    return outp\n",
    "\n",
    "# Alpha: posterior within should drop from EC→EO; theta: frontal within should rise in MOTOR vs rest\n",
    "plots=[]\n",
    "plots.append(plot_bars(df, \"alpha\", \"PO_PO\", (\"EC\",\"EO\",\"MOTOR\"),\n",
    "                       title=\"Alpha: Posterior within (EC, EO, MOTOR)\", ylim=(0,1.0),\n",
    "                       fname=\"alpha_PO_within.png\"))\n",
    "plots.append(plot_bars(df, \"theta\", \"FR_FR\", (\"EC\",\"EO\",\"MOTOR\"),\n",
    "                       title=\"Theta: Frontal within (EC, EO, MOTOR)\", ylim=(0,1.0),\n",
    "                       fname=\"theta_FR_within.png\"))\n",
    "# Directionality: FR→PO should increase in MOTOR (theta); PO→FR increases in EO (alpha)\n",
    "plots.append(plot_bars(df, \"theta\", \"PSI_FR_to_PO\", (\"EC\",\"EO\",\"MOTOR\"),\n",
    "                       title=\"Theta: FR→PO PSI (EC, EO, MOTOR)\", ylim=(-0.2,0.2),\n",
    "                       fname=\"theta_PSI_FR_to_PO.png\"))\n",
    "plots.append(plot_bars(df, \"alpha\", \"PSI_PO_to_FR\", (\"EC\",\"EO\",\"MOTOR\"),\n",
    "                       title=\"Alpha: PO→FR PSI (EC, EO, MOTOR)\", ylim=(-0.2,0.2),\n",
    "                       fname=\"alpha_PSI_PO_to_FR.png\"))\n",
    "\n",
    "print(\"Saved plots:\\n - \" + \"\\n - \".join(os.path.basename(p) for p in plots))\n",
    "\n",
    "print(\"\\nINTERPRETATION GUIDE\")\n",
    "print(\"1) Θ (theta) FR↔FR: expect MOTOR > EC, EO (control module engages during motor).\")\n",
    "print(\"2) α (alpha) PO↔PO: expect EC > EO, MOTOR (sensory gate strong in EC; releases with input or action).\")\n",
    "print(\"3) Θ PSI FR→PO: expect increase in MOTOR vs rest (control driving sensory integration).\")\n",
    "print(\"4) α PSI PO→FR: expect increase in EO vs EC (sensory-driven flow to control when eyes open).\")\n",
    "print(\"\\nUse group_tests_summary.csv to confirm: mean_diff, Cohen's d, and permutation p-values.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a13cce39-c0e2-4b4c-b0e8-e0610332610a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected character after line continuation character (3743645527.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mC:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\\u001b[39m\n       ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unexpected character after line continuation character\n"
     ]
    }
   ],
   "source": [
    "C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\ \n",
    "  ├─ tables\\hemis_theta_hands_subject50.csv\n",
    "  ├─ tables\\hemis_theta_hands_summary.csv\n",
    "  ├─ figures\\theta_FR_within_hemi_bars.png\n",
    "  └─ figures\\theta_FR_contra_diffs.png\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b13c26f5-1f14-4ced-a4aa-5a9f54b4f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frontal module split: Left=16 ch, Right=15 ch\n",
      "Using 50 subjects: [1, 2, 3, 4, 5, 6, 7, 8, 9, 10] ...\n",
      "Saved per-subject hemis metrics: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\tables\\hemis_theta_hands_subject50.csv\n",
      "Summary tests saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\tables\\hemis_theta_hands_summary.csv\n",
      "               contrast     mean  cohen_d   p_perm  N\n",
      "   R03 (Right-Left) > 0 0.000837 0.032635 0.415358 50\n",
      "   R04 (Left-Right) > 0 0.005396 0.220001 0.064394 50\n",
      "R03 contra − ECdiff > 0 0.004017 0.159644 0.134587 50\n",
      "R04 contra − ECdiff > 0 0.008576 0.193361 0.089191 50\n",
      "Saved figures:\n",
      " - C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\figures\\theta_FR_within_hemi_bars.png\n",
      " - C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\hands\\figures\\theta_FR_contra_diffs.png\n",
      "\n",
      "INTERPRETATION:\n",
      "• R03 (Left-hand imagery/execution): expect Right frontal θ > Left (R−L > 0).\n",
      "• R04 (Right-hand imagery/execution): expect Left frontal θ > Right (L−R > 0).\n",
      "• The 'contra − ECdiff > 0' contrasts confirm that the contralateral boost exceeds any baseline hemisphere bias at rest.\n"
     ]
    }
   ],
   "source": [
    "# === CNT Hands (R03/R04) — Contralateral θ Frontal Effect on 50 Subjects ===\n",
    "# Uses EC α consensus → frontal module → split Left vs Right frontal; computes θ within-frontal coupling (PLI)\n",
    "# Tests (paired, 10k perms):\n",
    "#   • R03 (Left hand): Right-frontal > Left-frontal\n",
    "#   • R04 (Right hand): Left-frontal > Right-frontal\n",
    "#   • (Contra−Ipsi)_motor > (Contra−Ipsi)_EC baseline\n",
    "# Saves per-subject table, summary stats, and plots.\n",
    "\n",
    "import os, re, glob, json, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# ---------------- Paths ----------------\n",
    "ROOT        = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR    = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT    = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "CH_TXT      = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "\n",
    "OUT_ROOT    = os.path.join(ART_ROOT, r\"tests_functional\\hands\")\n",
    "OUT_TAB     = os.path.join(OUT_ROOT, \"tables\")\n",
    "OUT_FIG     = os.path.join(OUT_ROOT, \"figures\")\n",
    "for p in [OUT_ROOT, OUT_TAB, OUT_FIG]: os.makedirs(p, exist_ok=True)\n",
    "\n",
    "assert os.path.exists(CONS_EC_ALPHA), \"Missing EC α consensus. Run CNT consensus first.\"\n",
    "assert os.path.exists(CH_TXT), \"Missing channel names file.\"\n",
    "\n",
    "# ---------------- Utility ----------------\n",
    "def clean_label(x: str) -> str:\n",
    "    y = x.strip()\n",
    "    y = re.sub(r\"(?i)^(EEG|MEG|EOG|ECG|EMG)[\\s_\\-]+\", \"\", y)\n",
    "    y = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\", \"\", y)\n",
    "    y = re.sub(r\"[ \\-\\.]+\", \"\", y)\n",
    "    y = y.replace(\"FP\",\"Fp\")\n",
    "    return y\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(ln.strip()) for ln in f if ln.strip()]\n",
    "\n",
    "# 10–20 hemisphere mapping (odd/even, canonical sets)\n",
    "LEFT_CANON  = set(map(str.upper, [\"Fp1\",\"AF7\",\"AF3\",\"F7\",\"F5\",\"F3\",\"F1\",\"FT7\",\"FC5\",\"FC3\",\"FC1\",\"T7\",\"C5\",\"C3\",\"C1\",\n",
    "                                  \"TP7\",\"CP5\",\"CP3\",\"CP1\",\"P7\",\"P5\",\"P3\",\"P1\",\"PO7\",\"PO3\",\"O1\"]))\n",
    "RIGHT_CANON = set(map(str.upper, [\"Fp2\",\"AF8\",\"AF4\",\"F8\",\"F6\",\"F4\",\"F2\",\"FT8\",\"FC6\",\"FC4\",\"FC2\",\"T8\",\"C6\",\"C4\",\"C2\",\n",
    "                                  \"TP8\",\"CP6\",\"CP4\",\"CP2\",\"P8\",\"P6\",\"P4\",\"P2\",\"PO8\",\"PO4\",\"O2\"]))\n",
    "MID_CANON   = set(map(str.upper, [\"Fpz\",\"AFz\",\"Fz\",\"FCz\",\"Cz\",\"CPz\",\"Pz\",\"POz\",\"Oz\"]))\n",
    "\n",
    "def hemi_indices(names):\n",
    "    L,R,Z = [],[],[]\n",
    "    for i,ch in enumerate(names):\n",
    "        up = ch.upper()\n",
    "        if up in LEFT_CANON:  L.append(i); continue\n",
    "        if up in RIGHT_CANON: R.append(i); continue\n",
    "        if up in MID_CANON or re.search(r\"[A-Za-z]z$\", ch): Z.append(i); continue\n",
    "        m = re.search(r\"(\\d+)$\", ch)\n",
    "        if m:\n",
    "            try:\n",
    "                d=int(m.group(1)); (L if d%2==1 else R).append(i); continue\n",
    "            except: pass\n",
    "        Z.append(i)\n",
    "    return np.array(L,int), np.array(R,int), np.array(Z,int)\n",
    "\n",
    "L_idx, R_idx, Z_idx = hemi_indices(ch_names)\n",
    "\n",
    "# From EC α consensus, define FRONTAL module and split L/R within it\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "\n",
    "# Indices that are anterior by prefix\n",
    "def anterior_mask(names):\n",
    "    A=[]\n",
    "    for i,ch in enumerate(names):\n",
    "        pref = re.match(r\"[A-Za-z]+\", ch)\n",
    "        pref = pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): A.append(i)\n",
    "    return np.array(A,int)\n",
    "\n",
    "A_all = anterior_mask(ch_names)\n",
    "mod0_A = np.intersect1d(np.where(cons_alpha==0)[0], A_all).size\n",
    "mod1_A = np.intersect1d(np.where(cons_alpha==1)[0], A_all).size\n",
    "FR_LABEL, PO_LABEL = (0,1) if mod0_A >= mod1_A else (1,0)\n",
    "FR_all = np.where(cons_alpha==FR_LABEL)[0]\n",
    "\n",
    "# L- and R- frontal subsets\n",
    "FR_L = np.intersect1d(FR_all, L_idx)\n",
    "FR_R = np.intersect1d(FR_all, R_idx)\n",
    "\n",
    "print(f\"Frontal module split: Left={len(FR_L)} ch, Right={len(FR_R)} ch\")\n",
    "\n",
    "# ---------------- Subject list: 50 with EC, EO, R03, R04 ----------------\n",
    "# (We assume you've already exported EO/EC + R03, R04 with the previous cell)\n",
    "candidates=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR, \"subject_*_EC.npy\")):\n",
    "    sid = int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    if (os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_EO.npy\")) and\n",
    "        os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_R03.npy\")) and\n",
    "        os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_R04.npy\"))):\n",
    "        candidates.append(sid)\n",
    "\n",
    "candidates = sorted(candidates)[:50]\n",
    "print(f\"Using {len(candidates)} subjects:\", candidates[:10], \"...\")\n",
    "\n",
    "# ---------------- θ within-frontal (L vs R) PLI ----------------\n",
    "FS=250.0\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order,[lo/(fs/2),hi/(fs/2)], btype=\"band\")\n",
    "    return filtfilt(b,a,x)\n",
    "\n",
    "def pli_pair(x,y,lo,hi,fs):\n",
    "    bx = bandpass(x,fs,lo,hi); by = bandpass(y,fs,lo,hi)\n",
    "    phx = np.angle(hilbert(bx)); phy = np.angle(hilbert(by))\n",
    "    d   = phx - phy\n",
    "    return float(np.abs(np.mean(np.sign(np.sin(d)))))\n",
    "\n",
    "def pli_mean_within(X, idx, lo, hi, fs):\n",
    "    vals=[]\n",
    "    ids=list(idx)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            vals.append(pli_pair(X[ids[i]], X[ids[j]], lo, hi, fs))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "theta = (4,8)\n",
    "\n",
    "def get_theta_frontal_hemi(X):\n",
    "    L = pli_mean_within(X, FR_L, theta[0], theta[1], FS)\n",
    "    R = pli_mean_within(X, FR_R, theta[0], theta[1], FS)\n",
    "    return L, R\n",
    "\n",
    "# compute per-subject\n",
    "rows=[]\n",
    "for sid in candidates:\n",
    "    rec = {\"subject\": sid}\n",
    "    for cond in [\"EC\",\"EO\",\"R03\",\"R04\"]:\n",
    "        fpath = os.path.join(DATA_DIR, f\"subject_{sid:02d}_{cond}.npy\")\n",
    "        X = np.load(fpath)\n",
    "        L, R = get_theta_frontal_hemi(X)\n",
    "        rec[f\"theta_FR_L_{cond}\"] = L\n",
    "        rec[f\"theta_FR_R_{cond}\"] = R\n",
    "    # contralateral differences: R03 expects Right > Left; R04 expects Left > Right\n",
    "    rec[\"theta_diff_R03\"] = rec[\"theta_FR_R_R03\"] - rec[\"theta_FR_L_R03\"]   # (Right - Left), expect > 0\n",
    "    rec[\"theta_diff_R04\"] = rec[\"theta_FR_L_R04\"] - rec[\"theta_FR_R_R04\"]   # (Left - Right), expect > 0\n",
    "    # EC baselines for differences\n",
    "    rec[\"theta_diff_EC\"]  = rec[\"theta_FR_R_EC\"]  - rec[\"theta_FR_L_EC\"]\n",
    "    rows.append(rec)\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "out_csv = os.path.join(OUT_TAB, \"hemis_theta_hands_subject50.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved per-subject hemis metrics:\", out_csv)\n",
    "\n",
    "# ---------------- Paired permutation tests (10k flips) ----------------\n",
    "RNG = default_rng(31)\n",
    "\n",
    "def paired_perm_greater(a, b0=0.0, n_perm=10000, rng=None):\n",
    "    \"\"\"Test mean(a) > b0 via paired sign-flip.\"\"\"\n",
    "    a = np.asarray(a, float)\n",
    "    a = a[np.isfinite(a)]\n",
    "    if len(a) < 10: \n",
    "        return np.nan, np.nan, np.nan\n",
    "    obs = float(np.mean(a - b0))\n",
    "    cnt = 1\n",
    "    for _ in range(n_perm):\n",
    "        signs = rng.integers(0,2,size=len(a))*2-1\n",
    "        perm = np.mean((a-b0)*signs)\n",
    "        if perm >= obs: cnt += 1\n",
    "    p = float(cnt / (n_perm+1))\n",
    "    d = float(obs / (np.std(a - b0, ddof=1)+1e-12))\n",
    "    return obs, d, p\n",
    "\n",
    "# Contralateral during motor:\n",
    "obs_r03, d_r03, p_r03 = paired_perm_greater(df[\"theta_diff_R03\"].values, b0=0.0, n_perm=10000, rng=RNG)\n",
    "obs_r04, d_r04, p_r04 = paired_perm_greater(df[\"theta_diff_R04\"].values, b0=0.0, n_perm=10000, rng=RNG)\n",
    "\n",
    "# Improvement over EC baseline (contra minus EC diff):\n",
    "obs_r03_vsEC, d_r03_vsEC, p_r03_vsEC = paired_perm_greater((df[\"theta_diff_R03\"] - df[\"theta_diff_EC\"]).values,\n",
    "                                                            b0=0.0, n_perm=10000, rng=RNG)\n",
    "obs_r04_vsEC, d_r04_vsEC, p_r04_vsEC = paired_perm_greater((df[\"theta_diff_R04\"] - df[\"theta_diff_EC\"]).values,\n",
    "                                                            b0=0.0, n_perm=10000, rng=RNG)\n",
    "\n",
    "summary_rows = [\n",
    "    {\"contrast\":\"R03 (Right-Left) > 0\", \"mean\":obs_r03, \"cohen_d\":d_r03, \"p_perm\":p_r03, \"N\":len(df)},\n",
    "    {\"contrast\":\"R04 (Left-Right) > 0\", \"mean\":obs_r04, \"cohen_d\":d_r04, \"p_perm\":p_r04, \"N\":len(df)},\n",
    "    {\"contrast\":\"R03 contra − ECdiff > 0\", \"mean\":obs_r03_vsEC, \"cohen_d\":d_r03_vsEC, \"p_perm\":p_r03_vsEC, \"N\":len(df)},\n",
    "    {\"contrast\":\"R04 contra − ECdiff > 0\", \"mean\":obs_r04_vsEC, \"cohen_d\":d_r04_vsEC, \"p_perm\":p_r04_vsEC, \"N\":len(df)},\n",
    "]\n",
    "sum_df = pd.DataFrame(summary_rows)\n",
    "sum_csv = os.path.join(OUT_TAB, \"hemis_theta_hands_summary.csv\")\n",
    "sum_df.to_csv(sum_csv, index=False)\n",
    "print(\"Summary tests saved:\", sum_csv)\n",
    "print(sum_df.to_string(index=False))\n",
    "\n",
    "# ---------------- Plots ----------------\n",
    "def boot_mean_ci(a, B=2000):\n",
    "    a = np.asarray(a, float)\n",
    "    a = a[np.isfinite(a)]\n",
    "    if len(a)<5: return np.nan, np.nan, np.nan\n",
    "    means=[np.mean(resample(a, replace=True, n_samples=len(a))) for _ in range(B)]\n",
    "    return float(np.mean(a)), float(np.percentile(means,2.5)), float(np.percentile(means,97.5))\n",
    "\n",
    "# 1) Left/Right frontal θ across EC, EO, R03, R04 (bars with CI)\n",
    "conds = [\"EC\",\"EO\",\"R03\",\"R04\"]\n",
    "L_means=[]; L_lo=[]; L_hi=[]\n",
    "R_means=[]; R_lo=[]; R_hi=[]\n",
    "for c in conds:\n",
    "    m,lo,hi = boot_mean_ci(df[f\"theta_FR_L_{c}\"].values)\n",
    "    L_means.append(m); L_lo.append(lo); L_hi.append(hi)\n",
    "    m,lo,hi = boot_mean_ci(df[f\"theta_FR_R_{c}\"].values)\n",
    "    R_means.append(m); R_lo.append(lo); R_hi.append(hi)\n",
    "\n",
    "x = np.arange(len(conds))\n",
    "w = 0.35\n",
    "plt.figure(figsize=(7.6,4.2))\n",
    "plt.bar(x - w/2, L_means, width=w,\n",
    "        yerr=[np.array(L_means)-np.array(L_lo), np.array(L_hi)-np.array(L_means)],\n",
    "        capsize=4, label=\"Left frontal\")\n",
    "plt.bar(x + w/2, R_means, width=w,\n",
    "        yerr=[np.array(R_means)-np.array(R_lo), np.array(R_hi)-np.array(R_means)],\n",
    "        capsize=4, label=\"Right frontal\")\n",
    "plt.xticks(x, conds); plt.ylim(0, 1.0); plt.ylabel(\"θ within-frontal PLI\")\n",
    "plt.title(\"θ within-frontal (Left vs Right) — EC/EO/R03/R04 (N=50)\")\n",
    "plt.legend()\n",
    "out1 = os.path.join(OUT_FIG, \"theta_FR_within_hemi_bars.png\")\n",
    "plt.tight_layout(); plt.savefig(out1, dpi=160); plt.close()\n",
    "\n",
    "# 2) Contralateral differences bars (R03: R-L; R04: L-R) with p-values in title\n",
    "m1,lo1,hi1 = boot_mean_ci(df[\"theta_diff_R03\"].values)\n",
    "m2,lo2,hi2 = boot_mean_ci(df[\"theta_diff_R04\"].values)\n",
    "plt.figure(figsize=(5.8,4.0))\n",
    "means=[m1,m2]; los=[lo1,lo2]; his=[hi1,hi2]\n",
    "labels=[f\"R03 (R−L)\\n p={p_r03:.4f}\", f\"R04 (L−R)\\n p={p_r04:.4f}\"]\n",
    "xx=np.arange(2)\n",
    "plt.bar(xx, means, yerr=[np.array(means)-np.array(los), np.array(his)-np.array(means)], capsize=4)\n",
    "plt.xticks(xx, labels)\n",
    "plt.ylabel(\"θ within-frontal PLI (contrast)\")\n",
    "plt.title(\"Contralateral effect (N=50)\")\n",
    "out2 = os.path.join(OUT_FIG, \"theta_FR_contra_diffs.png\")\n",
    "plt.tight_layout(); plt.savefig(out2, dpi=160); plt.close()\n",
    "\n",
    "print(\"Saved figures:\")\n",
    "print(\" -\", out1)\n",
    "print(\" -\", out2)\n",
    "\n",
    "print(\"\\nINTERPRETATION:\")\n",
    "print(\"• R03 (Left-hand imagery/execution): expect Right frontal θ > Left (R−L > 0).\")\n",
    "print(\"• R04 (Right-hand imagery/execution): expect Left frontal θ > Right (L−R > 0).\")\n",
    "print(\"• The 'contra − ECdiff > 0' contrasts confirm that the contralateral boost exceeds any baseline hemisphere bias at rest.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e9e8b05f-f143-4d1d-9ebf-f0303a6a500d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks → FRontal=36; L-central=[1, 8, 9, 15] ; R-central=[5, 12, 11, 19]\n",
      "Using N subjects: 50\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_proofs\\tables\\motor_proofs_subject50.csv\n",
      "                     test  mean_diff   cohen_d   p_perm  N      mean\n",
      "θ FR within — MOTOR vs EC   0.008584  0.329834 0.019798 50       NaN\n",
      "  μ contra (R03: R-L) > 0        NaN -0.179716 0.896610 50 -0.009171\n",
      "  μ contra (R04: L-R) > 0        NaN  0.238069 0.047995 50  0.012640\n",
      "  β contra (R03: R-L) > 0        NaN -0.313123 0.986001 50 -0.015859\n",
      "  β contra (R04: L-R) > 0        NaN  0.208142 0.072593 50  0.013064\n",
      "μ contra−ECdiff > 0 (R03)        NaN -0.315139 0.985601 50 -0.024289\n",
      "μ contra−ECdiff > 0 (R04)        NaN -0.023741 0.559044 50 -0.002479\n",
      "β contra−ECdiff > 0 (R03)        NaN  0.045964 0.373363 50  0.001741\n",
      "β contra−ECdiff > 0 (R04)        NaN  0.262708 0.034897 50  0.030664\n",
      "Figures written to: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_proofs\\figures\n"
     ]
    }
   ],
   "source": [
    "# === CNT Motor Proofs (N=50) ===\n",
    "# 1) CNT control claim: θ frontal within-module (no lateral split) — MOTOR > EC\n",
    "# 2) True laterality: μ(8–13)/β(13–30) sensorimotor coupling — contralateral > ipsilateral for R03/R04\n",
    "#    Masks: Left-central {FC3,C3,C1,CP3}, Right-central {FC4,C4,C2,CP4}\n",
    "# Reuses your EC α consensus for frontal set (control test), and 10–20 names for central masks.\n",
    "\n",
    "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.utils import resample\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "CH_TXT    = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "\n",
    "OUT_DIR   = os.path.join(ART_ROOT, r\"tests_functional\\motor_proofs\")\n",
    "TAB_DIR   = os.path.join(OUT_DIR, \"tables\"); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"figures\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "assert os.path.exists(CONS_EC_ALPHA)\n",
    "assert os.path.exists(CH_TXT)\n",
    "\n",
    "FS = 250.0\n",
    "rng = default_rng(2027)\n",
    "\n",
    "def clean_label(s):\n",
    "    s = re.sub(r\"(?i)^(EEG|EOG|ECG|EMG|MEG)[\\s_\\-]+\",\"\",s.strip())\n",
    "    s = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\",\"\",s)\n",
    "    return re.sub(r\"[ \\-\\.]+\",\"\",s).replace(\"FP\",\"Fp\")\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(x) for x in f if x.strip()]\n",
    "\n",
    "# --- 10-20 masks\n",
    "def idx_of(names, wanted):\n",
    "    up = {n.upper():i for i,n in enumerate(names)}\n",
    "    idx = [up[w.upper()] for w in wanted if w.upper() in up]\n",
    "    return np.array(idx, int)\n",
    "\n",
    "# Sensorimotor masks (robust fallbacks: if C1/C2 not present, drop them)\n",
    "LC_names = [\"FC3\",\"C3\",\"C1\",\"CP3\"]\n",
    "RC_names = [\"FC4\",\"C4\",\"C2\",\"CP4\"]\n",
    "LC = idx_of(ch_names, LC_names)\n",
    "RC = idx_of(ch_names, RC_names)\n",
    "\n",
    "# Frontal module from EC α consensus (for CNT control test)\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "A_mask = []\n",
    "for i,ch in enumerate(ch_names):\n",
    "    pref = re.match(r\"[A-Za-z]+\", ch)\n",
    "    pref = pref.group(0) if pref else \"\"\n",
    "    if any(pref.startswith(px) for px in ANT_PREFIXES): A_mask.append(i)\n",
    "A_mask = np.array(A_mask,int)\n",
    "# choose which label is FRONTAL by overlap with anterior mask\n",
    "m0A = np.intersect1d(np.where(cons_alpha==0)[0], A_mask).size\n",
    "m1A = np.intersect1d(np.where(cons_alpha==1)[0], A_mask).size\n",
    "FR_LABEL = 0 if m0A>=m1A else 1\n",
    "FR = np.where(cons_alpha==FR_LABEL)[0]\n",
    "\n",
    "print(f\"Masks → FRontal={len(FR)}; L-central={LC.tolist()} ; R-central={RC.tolist()}\")\n",
    "\n",
    "# --- helpers\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_pair(x, y, lo, hi, fs):\n",
    "    bx = bandpass(x,fs,lo,hi); by = bandpass(y,fs,lo,hi)\n",
    "    phx = np.angle(hilbert(bx)); phy = np.angle(hilbert(by))\n",
    "    return float(np.abs(np.mean(np.sign(np.sin(phx-phy)))))\n",
    "\n",
    "def pli_within(X, idx, lo, hi, fs):\n",
    "    vals=[]; ids=list(idx)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            vals.append(pli_pair(X[ids[i]], X[ids[j]], lo, hi, fs))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "# --- pick 50 subjects with the required conditions\n",
    "candidates=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR,\"subject_*_EC.npy\")):\n",
    "    sid=int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    ok = all(os.path.exists(os.path.join(DATA_DIR, f\"subject_{sid:02d}_{tag}.npy\")) for tag in [\"EO\",\"R03\",\"R04\"])\n",
    "    if ok: candidates.append(sid)\n",
    "candidates = sorted(candidates)[:50]\n",
    "print(\"Using N subjects:\", len(candidates))\n",
    "\n",
    "# --- compute metrics\n",
    "rows=[]\n",
    "for sid in candidates:\n",
    "    X_EC  = np.load(os.path.join(DATA_DIR, f\"subject_{sid:02d}_EC.npy\"))\n",
    "    X_EO  = np.load(os.path.join(DATA_DIR, f\"subject_{sid:02d}_EO.npy\"))\n",
    "    X_R03 = np.load(os.path.join(DATA_DIR, f\"subject_{sid:02d}_R03.npy\"))\n",
    "    X_R04 = np.load(os.path.join(DATA_DIR, f\"subject_{sid:02d}_R04.npy\"))\n",
    "\n",
    "    # CNT control: θ frontal (no laterality split)\n",
    "    fr_theta_EC  = pli_within(X_EC,  FR, 4,8,FS)\n",
    "    fr_theta_EO  = pli_within(X_EO,  FR, 4,8,FS)\n",
    "    fr_theta_R03 = pli_within(X_R03, FR, 4,8,FS)\n",
    "    fr_theta_R04 = pli_within(X_R04, FR, 4,8,FS)\n",
    "\n",
    "    # Laterality: μ/β within L-central and R-central\n",
    "    mu_EC_L  = pli_within(X_EC,  LC, 8,13,FS)\n",
    "    mu_EC_R  = pli_within(X_EC,  RC, 8,13,FS)\n",
    "    mu_R03_L = pli_within(X_R03, LC, 8,13,FS)\n",
    "    mu_R03_R = pli_within(X_R03, RC, 8,13,FS)\n",
    "    mu_R04_L = pli_within(X_R04, LC, 8,13,FS)\n",
    "    mu_R04_R = pli_within(X_R04, RC, 8,13,FS)\n",
    "\n",
    "    beta_EC_L  = pli_within(X_EC,  LC, 13,30,FS)\n",
    "    beta_EC_R  = pli_within(X_EC,  RC, 13,30,FS)\n",
    "    beta_R03_L = pli_within(X_R03, LC, 13,30,FS)\n",
    "    beta_R03_R = pli_within(X_R03, RC, 13,30,FS)\n",
    "    beta_R04_L = pli_within(X_R04, LC, 13,30,FS)\n",
    "    beta_R04_R = pli_within(X_R04, RC, 13,30,FS)\n",
    "\n",
    "    rows.append({\n",
    "        \"subject\":sid,\n",
    "        # CNT control metric\n",
    "        \"theta_FR_EC\":fr_theta_EC, \"theta_FR_EO\":fr_theta_EO, \"theta_FR_R03\":fr_theta_R03, \"theta_FR_R04\":fr_theta_R04,\n",
    "        # μ laterality\n",
    "        \"mu_R03_contra\":mu_R03_R - mu_R03_L,   # Left hand: Right central − Left central > 0\n",
    "        \"mu_R04_contra\":mu_R04_L - mu_R04_R,   # Right hand: Left central − Right central > 0\n",
    "        \"mu_EC_diff\":mu_EC_R - mu_EC_L,\n",
    "        # β laterality\n",
    "        \"beta_R03_contra\":beta_R03_R - beta_R03_L,\n",
    "        \"beta_R04_contra\":beta_R04_L - beta_R04_R,\n",
    "        \"beta_EC_diff\":beta_EC_R - beta_EC_L\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "out_csv = os.path.join(TAB_DIR, \"motor_proofs_subject50.csv\")\n",
    "df.to_csv(out_csv, index=False)\n",
    "print(\"Saved:\", out_csv)\n",
    "\n",
    "# --- paired permutation helpers\n",
    "def paired_perm(a, b, n_perm=10000, two_sided=True):\n",
    "    a=np.asarray(a,float); b=np.asarray(b,float)\n",
    "    mask=np.isfinite(a)&np.isfinite(b); a=a[mask]; b=b[mask]\n",
    "    diff=a-b; obs=float(np.mean(diff))\n",
    "    rng = default_rng(33); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs = rng.integers(0,2,size=len(diff))*2-1\n",
    "        perm  = np.mean(diff*signs)\n",
    "        if (abs(perm) >= abs(obs)) if two_sided else (perm >= obs): cnt+=1\n",
    "    p=float(cnt/(n_perm+1))\n",
    "    d=float(obs/(np.std(diff,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(diff)\n",
    "\n",
    "def one_sample_greater(x, n_perm=10000):\n",
    "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
    "    rng=default_rng(34); obs=float(np.mean(x)); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(x))*2-1\n",
    "        perm=np.mean(x*signs)\n",
    "        if perm>=obs: cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(x,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(x)\n",
    "\n",
    "# --- TEST 1: CNT control — theta FR within: MOTOR > EC (pooled R03/R04)\n",
    "theta_FR_motor = np.nanmean(df[[\"theta_FR_R03\",\"theta_FR_R04\"]].values, axis=1)\n",
    "obs1,d1,p1,n1 = paired_perm(theta_FR_motor, df[\"theta_FR_EC\"].values, n_perm=10000, two_sided=True)\n",
    "\n",
    "# --- TEST 2: laterality — μ contralateral > 0; β contralateral > 0\n",
    "obs_mu_L, d_mu_L, p_mu_L, n_mu_L = one_sample_greater(df[\"mu_R03_contra\"].values, n_perm=10000)  # R03: Right−Left > 0\n",
    "obs_mu_R, d_mu_R, p_mu_R, n_mu_R = one_sample_greater(df[\"mu_R04_contra\"].values, n_perm=10000)  # R04: Left−Right > 0\n",
    "obs_be_L, d_be_L, p_be_L, n_be_L = one_sample_greater(df[\"beta_R03_contra\"].values, n_perm=10000)\n",
    "obs_be_R, d_be_R, p_be_R, n_be_R = one_sample_greater(df[\"beta_R04_contra\"].values, n_perm=10000)\n",
    "\n",
    "# Baseline-corrected: (contra − ECdiff) > 0\n",
    "obs_mu_Lc, d_mu_Lc, p_mu_Lc, _ = one_sample_greater((df[\"mu_R03_contra\"] - df[\"mu_EC_diff\"]).values, n_perm=10000)\n",
    "obs_mu_Rc, d_mu_Rc, p_mu_Rc, _ = one_sample_greater((df[\"mu_R04_contra\"] - df[\"mu_EC_diff\"]).values, n_perm=10000)\n",
    "obs_be_Lc, d_be_Lc, p_be_Lc, _ = one_sample_greater((df[\"beta_R03_contra\"] - df[\"beta_EC_diff\"]).values, n_perm=10000)\n",
    "obs_be_Rc, d_be_Rc, p_be_Rc, _ = one_sample_greater((df[\"beta_R04_contra\"] - df[\"beta_EC_diff\"]).values, n_perm=10000)\n",
    "\n",
    "sum_rows = [\n",
    "    {\"test\":\"θ FR within — MOTOR vs EC\", \"mean_diff\":obs1, \"cohen_d\":d1, \"p_perm\":p1, \"N\":n1},\n",
    "    {\"test\":\"μ contra (R03: R-L) > 0\",   \"mean\":obs_mu_L,  \"cohen_d\":d_mu_L, \"p_perm\":p_mu_L, \"N\":n_mu_L},\n",
    "    {\"test\":\"μ contra (R04: L-R) > 0\",   \"mean\":obs_mu_R,  \"cohen_d\":d_mu_R, \"p_perm\":p_mu_R, \"N\":n_mu_R},\n",
    "    {\"test\":\"β contra (R03: R-L) > 0\",   \"mean\":obs_be_L,  \"cohen_d\":d_be_L, \"p_perm\":p_be_L, \"N\":n_be_L},\n",
    "    {\"test\":\"β contra (R04: L-R) > 0\",   \"mean\":obs_be_R,  \"cohen_d\":d_be_R, \"p_perm\":p_be_R, \"N\":n_be_R},\n",
    "    {\"test\":\"μ contra−ECdiff > 0 (R03)\", \"mean\":obs_mu_Lc, \"cohen_d\":d_mu_Lc,\"p_perm\":p_mu_Lc, \"N\":n_mu_L},\n",
    "    {\"test\":\"μ contra−ECdiff > 0 (R04)\", \"mean\":obs_mu_Rc, \"cohen_d\":d_mu_Rc,\"p_perm\":p_mu_Rc, \"N\":n_mu_R},\n",
    "    {\"test\":\"β contra−ECdiff > 0 (R03)\", \"mean\":obs_be_Lc, \"cohen_d\":d_be_Lc,\"p_perm\":p_be_Lc, \"N\":n_be_L},\n",
    "    {\"test\":\"β contra−ECdiff > 0 (R04)\", \"mean\":obs_be_Rc, \"cohen_d\":d_be_Rc,\"p_perm\":p_be_Rc, \"N\":n_be_R},\n",
    "]\n",
    "sum_df = pd.DataFrame(sum_rows)\n",
    "sum_df.to_csv(os.path.join(TAB_DIR,\"motor_proofs_summary.csv\"), index=False)\n",
    "print(sum_df.to_string(index=False))\n",
    "\n",
    "# --- quick plots ---\n",
    "def bar_with_ci(vals, title, fname, ylabel=\"PLI\"):\n",
    "    a = np.asarray(vals, float); a = a[np.isfinite(a)]\n",
    "    mean = float(np.mean(a))\n",
    "    boots = [np.mean(resample(a, replace=True, n_samples=len(a))) for _ in range(2000)]\n",
    "    lo,hi = np.percentile(boots,[2.5,97.5])\n",
    "    plt.figure(figsize=(4.5,3.8))\n",
    "    plt.bar([0],[mean], yerr=[[mean-lo],[hi-mean]], capsize=4)\n",
    "    plt.xticks([0],[title]); plt.ylabel(ylabel)\n",
    "    outp=os.path.join(FIG_DIR,fname); plt.tight_layout(); plt.savefig(outp,dpi=160); plt.close()\n",
    "    return outp\n",
    "\n",
    "# θ FR within motor vs EC\n",
    "bar_with_ci(theta_FR_motor - df[\"theta_FR_EC\"].values, \"θ FR (MOTOR−EC)\", \"theta_FR_motor_minus_EC.png\", ylabel=\"Δ PLI\")\n",
    "\n",
    "# μ/β contralateral contrasts\n",
    "bar_with_ci(df[\"mu_R03_contra\"].values,   \"μ R03 (R−L)\", \"mu_R03_contra.png\")\n",
    "bar_with_ci(df[\"mu_R04_contra\"].values,   \"μ R04 (L−R)\", \"mu_R04_contra.png\")\n",
    "bar_with_ci(df[\"beta_R03_contra\"].values, \"β R03 (R−L)\", \"beta_R03_contra.png\")\n",
    "bar_with_ci(df[\"beta_R04_contra\"].values, \"β R04 (L−R)\", \"beta_R04_contra.png\")\n",
    "\n",
    "print(\"Figures written to:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e9209e8f-9d2e-4335-a715-8a8c2d79f03b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks → FR=36 ; LC=[1, 8, 15] ; RC=[5, 12, 19]\n",
      "Using N= 50\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Saved cue-locked table: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\tables\\motor_cuelocked_subject50.csv\n",
      "                     test          mean         d        p  N    meanΔ\n",
      "         μ R03 contra > 0 -9.804084e-07 -0.851165 1.000000 50      NaN\n",
      "         μ R04 contra > 0  6.445932e-07  0.415326 0.001200 50      NaN\n",
      "         β R03 contra > 0 -1.109595e-06 -0.571512 1.000000 50      NaN\n",
      "         β R04 contra > 0  6.337594e-07  0.497928 0.000100 50      NaN\n",
      "μ R03 (contra - rest) > 0  1.041677e-07  0.107904 0.227677 50      NaN\n",
      "μ R04 (contra - rest) > 0 -7.900137e-07 -0.520862 1.000000 50      NaN\n",
      "β R03 (contra - rest) > 0  3.242511e-08  0.045738 0.380962 50      NaN\n",
      "β R04 (contra - rest) > 0 -5.525119e-07 -0.723646 1.000000 50      NaN\n",
      "θ FR within Motor vs Rest           NaN  0.315331 0.028997 50 0.005929\n",
      "Figures in: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\figures\n"
     ]
    }
   ],
   "source": [
    "# === Cue-locked motor laterality (μ/β) + CNT control (θ) on 50 subjects ===\n",
    "# Reads EEGBCI EDFs for R03 (left) / R04 (right), extracts 2 s motor windows 1–3 s after cue (T1/T2),\n",
    "# and 2 s rest windows; computes:\n",
    "#   • μ/β contralateral indices over compact sensorimotor masks (C3/C4-centered)\n",
    "#   • θ frontal within (CNT control) motor vs rest\n",
    "# Paired label-flip permutation tests (10k) + Cohen's d, with figures & CSV outputs.\n",
    "\n",
    "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.utils import resample\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "EDF_ROOT  = os.path.join(os.path.expanduser(\"~\"), \"mne_data\", \"MNE-eegbci-data\", \"files\", \"eegmmidb\", \"1.0.0\")\n",
    "\n",
    "OUT_DIR   = os.path.join(ART_ROOT, r\"tests_functional\\motor_cuelocked\")\n",
    "TAB_DIR   = os.path.join(OUT_DIR, \"tables\"); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"figures\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "CH_TXT    = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "assert os.path.exists(CH_TXT) and os.path.exists(CONS_EC_ALPHA)\n",
    "\n",
    "# MNE (for events/annotations)\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "FS = 250.0\n",
    "rng = default_rng(2031)\n",
    "\n",
    "def clean_label(s):\n",
    "    s = re.sub(r\"(?i)^(EEG|EOG|ECG|EMG|MEG)[\\s_\\-]+\",\"\",s.strip())\n",
    "    s = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\",\"\",s)\n",
    "    return re.sub(r\"[ \\-\\.]+\",\"\",s).replace(\"FP\",\"Fp\")\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(x) for x in f if x.strip()]\n",
    "\n",
    "# Compact sensorimotor masks centered on C3/C4\n",
    "def idx_of(names, wanted):\n",
    "    up = {n.upper():i for i,n in enumerate(names)}\n",
    "    return np.array([up[w.upper()] for w in wanted if w.upper() in up], int)\n",
    "\n",
    "LC = idx_of(ch_names, [\"FC3\",\"C3\",\"CP3\"])\n",
    "RC = idx_of(ch_names, [\"FC4\",\"C4\",\"CP4\"])\n",
    "if len(LC)<2 or len(RC)<2:\n",
    "    print(\"[warn] Few central channels found; using broader masks with C1/C2, CP1/CP2 if available.\")\n",
    "    LC = np.unique(np.concatenate([LC, idx_of(ch_names, [\"C1\",\"CP1\"])]))\n",
    "    RC = np.unique(np.concatenate([RC, idx_of(ch_names, [\"C2\",\"CP2\"])]))\n",
    "\n",
    "# Frontal module from EC α consensus (for θ control)\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "A_mask=[]\n",
    "for i,ch in enumerate(ch_names):\n",
    "    pref = re.match(r\"[A-Za-z]+\", ch)\n",
    "    pref = pref.group(0) if pref else \"\"\n",
    "    if any(pref.startswith(px) for px in ANT_PREFIXES): A_mask.append(i)\n",
    "A_mask = np.array(A_mask,int)\n",
    "m0A = np.intersect1d(np.where(cons_alpha==0)[0], A_mask).size\n",
    "m1A = np.intersect1d(np.where(cons_alpha==1)[0], A_mask).size\n",
    "FR_LABEL = 0 if m0A>=m1A else 1\n",
    "FR = np.where(cons_alpha==FR_LABEL)[0]\n",
    "\n",
    "print(f\"Masks → FR={len(FR)} ; LC={LC.tolist()} ; RC={RC.tolist()}\")\n",
    "\n",
    "# Select N=50 with EC, EO, and EDF runs present\n",
    "candidates=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR,\"subject_*_EC.npy\")):\n",
    "    sid=int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    # EDF files exist?\n",
    "    edf_files = [os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{run:02d}.edf\") for run in (3,4)]\n",
    "    if all(os.path.exists(p) for p in edf_files):\n",
    "        candidates.append(sid)\n",
    "candidates = sorted(candidates)[:50]\n",
    "print(\"Using N=\", len(candidates))\n",
    "\n",
    "# Band helpers\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype=\"band\"); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_within(X, idx, lo, hi, fs):\n",
    "    vals=[]; ids=list(idx)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            bx = bandpass(X[ids[i]],fs,lo,hi); by = bandpass(X[ids[j]],fs,lo,hi)\n",
    "            phx = np.angle(hilbert(bx)); phy = np.angle(hilbert(by))\n",
    "            vals.append(float(np.abs(np.mean(np.sign(np.sin(phx-phy))))))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "def mean_band_envelope(X, idx, lo, hi, fs):\n",
    "    if len(idx)==0: return np.nan\n",
    "    envs=[]\n",
    "    for i in idx:\n",
    "        b = bandpass(X[i], fs, lo, hi)\n",
    "        envs.append(np.abs(hilbert(b)))\n",
    "    return float(np.mean([np.mean(e) for e in envs]))\n",
    "\n",
    "# Extract cue-locked epochs from EDF\n",
    "def extract_epochs_from_edf(sid, run, t0=1.0, dur=2.0):\n",
    "    edf = os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{run:02d}.edf\")\n",
    "    raw = mne.io.read_raw_edf(edf, preload=True, verbose=\"ERROR\")\n",
    "    raw.pick_types(eeg=True, stim=False, eog=False, ecg=False)\n",
    "    raw.resample(FS, npad=\"auto\", verbose=\"ERROR\")\n",
    "    # annotations: T0 rest, T1 left, T2 right (EEGBCI convention)\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=\"ERROR\")\n",
    "    # map to codes\n",
    "    code_map = {}\n",
    "    for k,v in event_id.items():\n",
    "        if k.upper()==\"T0\": code_map[v] = \"REST\"\n",
    "        elif k.upper()==\"T1\": code_map[v] = \"LEFT\"\n",
    "        elif k.upper()==\"T2\": code_map[v] = \"RIGHT\"\n",
    "    X = raw.get_data(picks=\"eeg\")  # [n_ch, T]\n",
    "    fs = raw.info[\"sfreq\"]\n",
    "    w = int(dur*fs); shift = int(t0*fs)\n",
    "    epochs = {\"LEFT\":[], \"RIGHT\":[], \"REST\":[]}\n",
    "    for (samp,_,code) in events:\n",
    "        lab = code_map.get(code, None)\n",
    "        if lab is None: continue\n",
    "        start = samp + shift\n",
    "        stop  = start + w\n",
    "        if stop <= X.shape[1]:\n",
    "            epochs[lab].append(X[:, start:stop])\n",
    "    return epochs  # dict->list of arrays [n_ch, w]\n",
    "\n",
    "rows=[]\n",
    "for sid in candidates:\n",
    "    # R03: LEFT task; R04: RIGHT task\n",
    "    ep3 = extract_epochs_from_edf(sid, 3)  # LEFT\n",
    "    ep4 = extract_epochs_from_edf(sid, 4)  # RIGHT\n",
    "    # Average across valid epochs\n",
    "    def mean_metric_over_epochs(ep_list, fn):\n",
    "        vals=[fn(ep) for ep in ep_list] if ep_list else []\n",
    "        vals=[v for v in vals if np.isfinite(v)]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    # μ/β contralateral indices\n",
    "    mu_R03_contra = mean_metric_over_epochs(ep3[\"LEFT\"], lambda X: mean_band_envelope(X, RC, 8,13,FS) - mean_band_envelope(X, LC, 8,13,FS))\n",
    "    mu_R04_contra = mean_metric_over_epochs(ep4[\"RIGHT\"],lambda X: mean_band_envelope(X, LC, 8,13,FS) - mean_band_envelope(X, RC, 8,13,FS))\n",
    "    # baseline from REST epochs in each run\n",
    "    mu_R03_rest   = mean_metric_over_epochs(ep3[\"REST\"], lambda X: mean_band_envelope(X, RC, 8,13,FS) - mean_band_envelope(X, LC, 8,13,FS))\n",
    "    mu_R04_rest   = mean_metric_over_epochs(ep4[\"REST\"], lambda X: mean_band_envelope(X, LC, 8,13,FS) - mean_band_envelope(X, RC, 8,13,FS))\n",
    "\n",
    "    be_R03_contra = mean_metric_over_epochs(ep3[\"LEFT\"], lambda X: mean_band_envelope(X, RC, 13,30,FS) - mean_band_envelope(X, LC, 13,30,FS))\n",
    "    be_R04_contra = mean_metric_over_epochs(ep4[\"RIGHT\"],lambda X: mean_band_envelope(X, LC, 13,30,FS) - mean_band_envelope(X, RC, 13,30,FS))\n",
    "    be_R03_rest   = mean_metric_over_epochs(ep3[\"REST\"], lambda X: mean_band_envelope(X, RC, 13,30,FS) - mean_band_envelope(X, LC, 13,30,FS))\n",
    "    be_R04_rest   = mean_metric_over_epochs(ep4[\"REST\"], lambda X: mean_band_envelope(X, LC, 13,30,FS) - mean_band_envelope(X, RC, 13,30,FS))\n",
    "\n",
    "    # θ frontal within (CNT control) on LEFT/RIGHT motor epochs vs REST (average across runs)\n",
    "    th_R03_FR = mean_metric_over_epochs(ep3[\"LEFT\"],  lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_R04_FR = mean_metric_over_epochs(ep4[\"RIGHT\"], lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_rest3  = mean_metric_over_epochs(ep3[\"REST\"],  lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_rest4  = mean_metric_over_epochs(ep4[\"REST\"],  lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_FR_motor = np.nanmean([th_R03_FR, th_R04_FR])\n",
    "    th_FR_rest  = np.nanmean([th_rest3, th_rest4])\n",
    "\n",
    "    rows.append({\n",
    "        \"subject\":sid,\n",
    "        \"mu_R03_contra\":mu_R03_contra, \"mu_R03_rest\":mu_R03_rest,\n",
    "        \"mu_R04_contra\":mu_R04_contra, \"mu_R04_rest\":mu_R04_rest,\n",
    "        \"beta_R03_contra\":be_R03_contra, \"beta_R03_rest\":be_R03_rest,\n",
    "        \"beta_R04_contra\":be_R04_contra, \"beta_R04_rest\":be_R04_rest,\n",
    "        \"theta_FR_motor\":th_FR_motor, \"theta_FR_rest\":th_FR_rest\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_out = os.path.join(TAB_DIR, \"motor_cuelocked_subject50.csv\")\n",
    "df.to_csv(csv_out, index=False)\n",
    "print(\"Saved cue-locked table:\", csv_out)\n",
    "\n",
    "# Paired label-flip tests\n",
    "def one_sample_greater(x, n_perm=10000):\n",
    "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
    "    if len(x)<10: return np.nan,np.nan,np.nan,len(x)\n",
    "    rng=default_rng(44); obs=float(np.mean(x)); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(x))*2-1\n",
    "        perm=np.mean(x*signs)\n",
    "        if perm>=obs: cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(x,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(x)\n",
    "\n",
    "def paired_perm(a,b,n_perm=10000):\n",
    "    a=np.asarray(a,float); b=np.asarray(b,float)\n",
    "    mask=np.isfinite(a)&np.isfinite(b); a=a[mask]; b=b[mask]\n",
    "    if len(a)<10: return np.nan,np.nan,np.nan,len(a)\n",
    "    diff=a-b; obs=float(np.mean(diff)); rng=default_rng(45); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(diff))*2-1\n",
    "        perm=np.mean(diff*signs)\n",
    "        if abs(perm)>=abs(obs): cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(diff,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(diff)\n",
    "\n",
    "tests = []\n",
    "# μ contralateral > 0\n",
    "obs,d,p,n = one_sample_greater(df[\"mu_R03_contra\"].values); tests.append({\"test\":\"μ R03 contra > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"mu_R04_contra\"].values); tests.append({\"test\":\"μ R04 contra > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "# β contralateral > 0\n",
    "obs,d,p,n = one_sample_greater(df[\"beta_R03_contra\"].values); tests.append({\"test\":\"β R03 contra > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"beta_R04_contra\"].values); tests.append({\"test\":\"β R04 contra > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "# Baseline-corrected (contra - rest) > 0\n",
    "obs,d,p,n = one_sample_greater((df[\"mu_R03_contra\"]-df[\"mu_R03_rest\"]).values); tests.append({\"test\":\"μ R03 (contra - rest) > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"mu_R04_contra\"]-df[\"mu_R04_rest\"]).values); tests.append({\"test\":\"μ R04 (contra - rest) > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"beta_R03_contra\"]-df[\"beta_R03_rest\"]).values); tests.append({\"test\":\"β R03 (contra - rest) > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"beta_R04_contra\"]-df[\"beta_R04_rest\"]).values); tests.append({\"test\":\"β R04 (contra - rest) > 0\", \"mean\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "# θ frontal (motor vs rest)\n",
    "obs,d,p,n = paired_perm(df[\"theta_FR_motor\"].values, df[\"theta_FR_rest\"].values); tests.append({\"test\":\"θ FR within Motor vs Rest\", \"meanΔ\":obs, \"d\":d, \"p\":p, \"N\":n})\n",
    "\n",
    "t_df = pd.DataFrame(tests)\n",
    "t_df.to_csv(os.path.join(TAB_DIR, \"motor_cuelocked_summary.csv\"), index=False)\n",
    "print(t_df.to_string(index=False))\n",
    "\n",
    "# Simple plots for μ/β R04 (usually stronger)\n",
    "def bar_ci(vals, title, fname, ylabel):\n",
    "    a=np.asarray(vals,float); a=a[np.isfinite(a)]\n",
    "    mean=float(np.mean(a))\n",
    "    boots=[np.mean(resample(a, replace=True, n_samples=len(a))) for _ in range(2000)]\n",
    "    lo,hi=np.percentile(boots,[2.5,97.5])\n",
    "    plt.figure(figsize=(4.4,3.6))\n",
    "    plt.bar([0],[mean], yerr=[[mean-lo],[hi-mean]], capsize=4)\n",
    "    plt.xticks([0],[title]); plt.ylabel(ylabel); \n",
    "    out=os.path.join(FIG_DIR,fname); plt.tight_layout(); plt.savefig(out,dpi=160); plt.close()\n",
    "    return out\n",
    "\n",
    "bar_ci(df[\"mu_R04_contra\"].values,   \"μ R04 contralateral\",  \"mu_R04_contra_cuelocked.png\",   \"Envelope diff (contra)\")\n",
    "bar_ci(df[\"beta_R04_contra\"].values, \"β R04 contralateral\",  \"beta_R04_contra_cuelocked.png\", \"Envelope diff (contra)\")\n",
    "print(\"Figures in:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4e807db-da74-4ebc-988e-9ae585531622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Masks → FR=36 ; LC=[1, 8, 15] ; RC=[5, 12, 19]\n",
      "Using N= 50\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Saved LI/ERD table: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\li_erd\\tables\\li_erd_subject50.csv\n",
      "                 test      mean         d        p  N    meanΔ\n",
      "         LI μ R03 > 0 -0.020572 -0.606718 1.000000 50      NaN\n",
      "         LI μ R04 > 0  0.014063  0.471652 0.000700 50      NaN\n",
      "         LI β R03 > 0 -0.024370 -0.497640 1.000000 50      NaN\n",
      "         LI β R04 > 0  0.016429  0.517605 0.000500 50      NaN\n",
      "(LI μ R03) − rest > 0  0.002617  0.091818 0.264974 50      NaN\n",
      "(LI μ R04) − rest > 0 -0.012204 -0.464367 0.999100 50      NaN\n",
      "(LI β R03) − rest > 0  0.001480  0.088119 0.284672 50      NaN\n",
      "(LI β R04) − rest > 0 -0.009120 -0.568777 1.000000 50      NaN\n",
      "   θ FR motor vs rest       NaN  0.212257 0.144086 50 0.004574\n",
      "Plots written to: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\li_erd\\figures\n"
     ]
    }
   ],
   "source": [
    "# === Cue-locked LI + ERD (μ/β) + CNT θ control — N=50 ===\n",
    "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.utils import resample\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "EDF_ROOT  = os.path.join(os.path.expanduser(\"~\"), \"mne_data\", \"MNE-eegbci-data\", \"files\", \"eegmmidb\", \"1.0.0\")\n",
    "\n",
    "OUT_DIR   = os.path.join(ART_ROOT, r\"tests_functional\\motor_cuelocked\\li_erd\")\n",
    "TAB_DIR   = os.path.join(OUT_DIR, \"tables\"); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"figures\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "CH_TXT    = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "assert os.path.exists(CH_TXT) and os.path.exists(CONS_EC_ALPHA)\n",
    "\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "FS = 250.0\n",
    "rng = default_rng(2041)\n",
    "\n",
    "def clean_label(s):\n",
    "    s = re.sub(r\"(?i)^(EEG|EOG|ECG|EMG|MEG)[\\s_\\-]+\",\"\",s.strip())\n",
    "    s = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\",\"\",s)\n",
    "    return re.sub(r\"[ \\-\\.]+\",\"\",s).replace(\"FP\",\"Fp\")\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(x) for x in f if x.strip()]\n",
    "\n",
    "def idx_of(names, wanted):\n",
    "    up = {n.upper():i for i,n in enumerate(names)}\n",
    "    return np.array([up[w.upper()] for w in wanted if w.upper() in up], int)\n",
    "\n",
    "LC = idx_of(ch_names, [\"FC3\",\"C3\",\"CP3\"])\n",
    "RC = idx_of(ch_names, [\"FC4\",\"C4\",\"CP4\"])\n",
    "if len(LC)<2 or len(RC)<2:\n",
    "    LC = np.unique(np.concatenate([LC, idx_of(ch_names, [\"C1\",\"CP1\"])]))\n",
    "    RC = np.unique(np.concatenate([RC, idx_of(ch_names, [\"C2\",\"CP2\"])]))\n",
    "\n",
    "# Frontal module for θ control\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "A_mask=[]\n",
    "for i,ch in enumerate(ch_names):\n",
    "    pref=re.match(r\"[A-Za-z]+\", ch)\n",
    "    pref=pref.group(0) if pref else \"\"\n",
    "    if any(pref.startswith(px) for px in ANT_PREFIXES): A_mask.append(i)\n",
    "A_mask=np.array(A_mask,int)\n",
    "m0A = np.intersect1d(np.where(cons_alpha==0)[0], A_mask).size\n",
    "m1A = np.intersect1d(np.where(cons_alpha==1)[0], A_mask).size\n",
    "FR_LABEL = 0 if m0A>=m1A else 1\n",
    "FR = np.where(cons_alpha==FR_LABEL)[0]\n",
    "\n",
    "print(f\"Masks → FR={len(FR)} ; LC={LC.tolist()} ; RC={RC.tolist()}\")\n",
    "\n",
    "# pick 50 subjects with EDFs (R03,R04)\n",
    "subs=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR,\"subject_*_EC.npy\")):\n",
    "    sid=int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    edfs=[os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{r:02d}.edf\") for r in (3,4)]\n",
    "    if all(os.path.exists(p) for p in edfs): subs.append(sid)\n",
    "subs=sorted(subs)[:50]\n",
    "print(\"Using N=\",len(subs))\n",
    "\n",
    "def band_env(X, idx, lo, hi, fs):\n",
    "    if len(idx)==0: return np.nan\n",
    "    env=[]\n",
    "    for i in idx:\n",
    "        b = butter(4, [lo/(fs/2), hi/(fs/2)], btype='band')\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype='band')\n",
    "    for i in idx:\n",
    "        bx = filtfilt(b,a,X[i])\n",
    "        env.append(np.mean(np.abs(hilbert(bx))**2))  # band power proxy\n",
    "    return float(np.mean(env))\n",
    "\n",
    "def pli_within(X, idx, lo, hi, fs):\n",
    "    if len(idx)<2: return np.nan\n",
    "    b,a = butter(4,[lo/(fs/2),hi/(fs/2)], btype='band')\n",
    "    vals=[]\n",
    "    ids=list(idx)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            xi = filtfilt(b,a,X[ids[i]]); xj = filtfilt(b,a,X[ids[j]])\n",
    "            phx=np.angle(hilbert(xi)); phy=np.angle(hilbert(xj))\n",
    "            vals.append(float(np.abs(np.mean(np.sign(np.sin(phx-phy))))))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "def extract_epochs(sid, run, t0=2.0, dur=2.0):\n",
    "    edf=os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{run:02d}.edf\")\n",
    "    raw=mne.io.read_raw_edf(edf, preload=True, verbose=\"ERROR\")\n",
    "    raw.pick_types(eeg=True, stim=False, eog=False, ecg=False)\n",
    "    raw.resample(FS, npad=\"auto\", verbose=\"ERROR\")\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=\"ERROR\")\n",
    "    X=raw.get_data(picks=\"eeg\"); fs=raw.info[\"sfreq\"]\n",
    "    w=int(dur*fs); shift=int(t0*fs)\n",
    "    code_map={}\n",
    "    for k,v in event_id.items():\n",
    "        if k.upper()==\"T0\": code_map[v]=\"REST\"\n",
    "        elif k.upper()==\"T1\": code_map[v]=\"LEFT\"\n",
    "        elif k.upper()==\"T2\": code_map[v]=\"RIGHT\"\n",
    "    out={\"LEFT\":[], \"RIGHT\":[], \"REST\":[]}\n",
    "    for (samp,_,code) in events:\n",
    "        lab=code_map.get(code,None)\n",
    "        if lab is None: continue\n",
    "        start=samp+shift; stop=start+w\n",
    "        if stop<=X.shape[1]:\n",
    "            out[lab].append(X[:,start:stop])\n",
    "    return out\n",
    "\n",
    "rows=[]\n",
    "for sid in subs:\n",
    "    ep3=extract_epochs(sid,3,t0=2.0,dur=2.0)  # LEFT block\n",
    "    ep4=extract_epochs(sid,4,t0=2.0,dur=2.0)  # RIGHT block\n",
    "\n",
    "    def mean_over(ep_list, fn):\n",
    "        vals=[fn(ep) for ep in ep_list] if ep_list else []\n",
    "        vals=[v for v in vals if np.isfinite(v)]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    # μ/β LI = (contra-ipsi)/(contra+ipsi)\n",
    "    def li_mu_beta(ep, left_task):\n",
    "        if left_task:\n",
    "            contra_mu  = band_env(ep, RC, 8,13,FS); ipsi_mu  = band_env(ep, LC, 8,13,FS)\n",
    "            contra_be  = band_env(ep, RC,13,30,FS); ipsi_be  = band_env(ep, LC,13,30,FS)\n",
    "        else:\n",
    "            contra_mu  = band_env(ep, LC, 8,13,FS); ipsi_mu  = band_env(ep, RC, 8,13,FS)\n",
    "            contra_be  = band_env(ep, LC,13,30,FS); ipsi_be  = band_env(ep, RC,13,30,FS)\n",
    "        li_mu = (contra_mu-ipsi_mu)/((contra_mu+ipsi_mu)+1e-9)\n",
    "        li_be = (contra_be-ipsi_be)/((contra_be+ipsi_be)+1e-9)\n",
    "        return li_mu, li_be\n",
    "\n",
    "    mu_R03 = mean_over(ep3[\"LEFT\"],  lambda X: li_mu_beta(X, left_task=True)[0])\n",
    "    mu_R04 = mean_over(ep4[\"RIGHT\"], lambda X: li_mu_beta(X, left_task=False)[0])\n",
    "    be_R03 = mean_over(ep3[\"LEFT\"],  lambda X: li_mu_beta(X, left_task=True)[1])\n",
    "    be_R04 = mean_over(ep4[\"RIGHT\"], lambda X: li_mu_beta(X, left_task=False)[1])\n",
    "\n",
    "    mu_R03_rest = mean_over(ep3[\"REST\"],  lambda X: (band_env(X, RC,8,13,FS)-band_env(X, LC,8,13,FS))/((band_env(X, RC,8,13,FS)+band_env(X, LC,8,13,FS))+1e-9))\n",
    "    mu_R04_rest = mean_over(ep4[\"REST\"],  lambda X: (band_env(X, LC,8,13,FS)-band_env(X, RC,8,13,FS))/((band_env(X, LC,8,13,FS)+band_env(X, RC,8,13,FS))+1e-9))\n",
    "    be_R03_rest = mean_over(ep3[\"REST\"],  lambda X: (band_env(X, RC,13,30,FS)-band_env(X, LC,13,30,FS))/((band_env(X, RC,13,30,FS)+band_env(X, LC,13,30,FS))+1e-9))\n",
    "    be_R04_rest = mean_over(ep4[\"REST\"],  lambda X: (band_env(X, LC,13,30,FS)-band_env(X, RC,13,30,FS))/((band_env(X, LC,13,30,FS)+band_env(X, RC,13,30,FS))+1e-9))\n",
    "\n",
    "    # θ frontal within: motor epochs vs rest (average across runs)\n",
    "    th_R03 = mean_over(ep3[\"LEFT\"],  lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_R04 = mean_over(ep4[\"RIGHT\"], lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_rest3 = mean_over(ep3[\"REST\"], lambda X: pli_within(X, FR, 4,8,FS))\n",
    "    th_rest4 = mean_over(ep4[\"REST\"], lambda X: pli_within(X, FR, 4,8,FS))\n",
    "\n",
    "    rows.append({\n",
    "        \"subject\":sid,\n",
    "        \"LI_mu_R03\":mu_R03, \"LI_mu_R04\":mu_R04, \"LI_mu_R03_rest\":mu_R03_rest, \"LI_mu_R04_rest\":mu_R04_rest,\n",
    "        \"LI_be_R03\":be_R03, \"LI_be_R04\":be_R04, \"LI_be_R03_rest\":be_R03_rest, \"LI_be_R04_rest\":be_R04_rest,\n",
    "        \"theta_FR_motor\":np.nanmean([th_R03, th_R04]), \"theta_FR_rest\":np.nanmean([th_rest3, th_rest4])\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_out = os.path.join(TAB_DIR, \"li_erd_subject50.csv\")\n",
    "df.to_csv(csv_out, index=False)\n",
    "print(\"Saved LI/ERD table:\", csv_out)\n",
    "\n",
    "# permutation helpers\n",
    "def one_sample_greater(x, n_perm=10000):\n",
    "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
    "    if len(x)<10: return np.nan,np.nan,np.nan,len(x)\n",
    "    rng=default_rng(55); obs=float(np.mean(x)); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(x))*2-1\n",
    "        perm=np.mean(x*signs)\n",
    "        if perm>=obs: cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(x,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(x)\n",
    "\n",
    "def paired_perm(a,b,n_perm=10000):\n",
    "    a=np.asarray(a,float); b=np.asarray(b,float)\n",
    "    mask=np.isfinite(a)&np.isfinite(b); a=a[mask]; b=b[mask]\n",
    "    if len(a)<10: return np.nan,np.nan,np.nan,len(a)\n",
    "    diff=a-b; obs=float(np.mean(diff)); rng=default_rng(56); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(diff))*2-1\n",
    "        perm=np.mean(diff*signs)\n",
    "        if abs(perm)>=abs(obs): cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(diff,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(a)\n",
    "\n",
    "tests=[]\n",
    "# μ/β LI > 0\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_mu_R03\"].values);   tests.append({\"test\":\"LI μ R03 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_mu_R04\"].values);   tests.append({\"test\":\"LI μ R04 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_be_R03\"].values);   tests.append({\"test\":\"LI β R03 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_be_R04\"].values);   tests.append({\"test\":\"LI β R04 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "# rest-corrected LI\n",
    "obs,d,p,n = one_sample_greater((df[\"LI_mu_R03\"]-df[\"LI_mu_R03_rest\"]).values); tests.append({\"test\":\"(LI μ R03) − rest > 0\",\"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"LI_mu_R04\"]-df[\"LI_mu_R04_rest\"]).values); tests.append({\"test\":\"(LI μ R04) − rest > 0\",\"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"LI_be_R03\"]-df[\"LI_be_R03_rest\"]).values); tests.append({\"test\":\"(LI β R03) − rest > 0\",\"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater((df[\"LI_be_R04\"]-df[\"LI_be_R04_rest\"]).values); tests.append({\"test\":\"(LI β R04) − rest > 0\",\"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "# CNT control (θ frontal)\n",
    "obs,d,p,n = paired_perm(df[\"theta_FR_motor\"].values, df[\"theta_FR_rest\"].values); tests.append({\"test\":\"θ FR motor vs rest\",\"meanΔ\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "\n",
    "t_df = pd.DataFrame(tests)\n",
    "t_df.to_csv(os.path.join(TAB_DIR,\"li_erd_summary.csv\"), index=False)\n",
    "print(t_df.to_string(index=False))\n",
    "\n",
    "# quick plots\n",
    "def one_bar(vals, title, fname):\n",
    "    a=np.asarray(vals,float); a=a[np.isfinite(a)]\n",
    "    mean=float(np.mean(a))\n",
    "    boots=[np.mean(resample(a,replace=True,n_samples=len(a))) for _ in range(2000)]\n",
    "    lo,hi=np.percentile(boots,[2.5,97.5])\n",
    "    plt.figure(figsize=(4.2,3.6)); plt.bar([0],[mean], yerr=[[mean-lo],[hi-mean]], capsize=4)\n",
    "    plt.xticks([0],[title]); plt.ylabel(\"LI / Δ PLI\"); \n",
    "    out=os.path.join(FIG_DIR,fname); plt.tight_layout(); plt.savefig(out,dpi=160); plt.close()\n",
    "\n",
    "one_bar(df[\"LI_mu_R04\"].values,   \"LI μ R04 (>0)\",   \"LI_mu_R04.png\")\n",
    "one_bar(df[\"LI_be_R04\"].values,   \"LI β R04 (>0)\",   \"LI_beta_R04.png\")\n",
    "one_bar((df[\"LI_mu_R04\"]-df[\"LI_mu_R04_rest\"]).values, \"μ R04 − rest (>0)\", \"LI_mu_R04_minus_rest.png\")\n",
    "one_bar((df[\"LI_be_R04\"]-df[\"LI_be_R04_rest\"]).values, \"β R04 − rest (>0)\", \"LI_beta_R04_minus_rest.png\")\n",
    "one_bar(df[\"theta_FR_motor\"].values - df[\"theta_FR_rest\"].values, \"θ FR (motor−rest)\", \"theta_FR_motor_minus_rest.png\")\n",
    "\n",
    "print(\"Plots written to:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "694ab168-815e-4b4f-8828-a387a455d192",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Midline/frontal mask used for theta: [26, 33, 3]\n",
      "Subjects: 50\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "                           test         mean         d        p  N        Δ\n",
      "         |μ| laterality R03 > 0 1.037820e-11  0.377113 0.000100 50      NaN\n",
      "         |μ| laterality R04 > 0 6.795411e-12  0.672900 0.000100 50      NaN\n",
      "         |β| laterality R03 > 0 1.240015e-11  0.570589 0.000100 50      NaN\n",
      "         |β| laterality R04 > 0 1.017787e-11  0.700744 0.000100 50      NaN\n",
      "θ midline within (motor - rest)          NaN -0.020222 0.885011 50 -0.00102\n",
      "Figures: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\figures\n"
     ]
    }
   ],
   "source": [
    "# === Cue-locked Laplacian ERD (C3/C4) + Refined θ control (midline frontal), N=50 ===\n",
    "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from sklearn.utils import resample\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "EDF_ROOT  = os.path.join(os.path.expanduser(\"~\"), \"mne_data\", \"MNE-eegbci-data\", \"files\", \"eegmmidb\", \"1.0.0\")\n",
    "\n",
    "OUT_DIR   = os.path.join(ART_ROOT, r\"tests_functional\\motor_cuelocked\\lap_erd\")\n",
    "TAB_DIR   = os.path.join(OUT_DIR, \"tables\"); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"figures\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "CH_TXT    = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "assert os.path.exists(CH_TXT) and os.path.exists(CONS_EC_ALPHA)\n",
    "\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "FS = 250.0\n",
    "rng = default_rng(2051)\n",
    "\n",
    "def clean_label(s):\n",
    "    s = re.sub(r\"(?i)^(EEG|EOG|ECG|EMG|MEG)[\\s_\\-]+\",\"\",s.strip())\n",
    "    s = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\",\"\",s)\n",
    "    return re.sub(r\"[ \\-\\.]+\",\"\",s).replace(\"FP\",\"Fp\")\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(x) for x in f if x.strip()]\n",
    "\n",
    "# find channel indices by name (optional)\n",
    "name_to_idx = {n.upper(): i for i,n in enumerate(ch_names)}\n",
    "def idx(n): return name_to_idx.get(n.upper(), None)\n",
    "\n",
    "# Laplacian around C3 and C4\n",
    "C3  = idx(\"C3\");  FC3 = idx(\"FC3\"); CP3 = idx(\"CP3\"); C1  = idx(\"C1\")\n",
    "C4  = idx(\"C4\");  FC4 = idx(\"FC4\"); CP4 = idx(\"CP4\"); C2  = idx(\"C2\")\n",
    "\n",
    "def have(*ids):\n",
    "    return all([i is not None for i in ids])\n",
    "\n",
    "assert (C3 is not None) and (C4 is not None), \"Need C3/C4 present for Laplacian.\"\n",
    "\n",
    "neighbors_L = [i for i in [FC3, CP3, C1] if i is not None]\n",
    "neighbors_R = [i for i in [FC4, CP4, C2] if i is not None]\n",
    "\n",
    "# midline-frontal for theta control\n",
    "midline_names = [\"AFz\",\"Fz\",\"FCz\"]\n",
    "MID = np.array([name_to_idx[n.upper()] for n in midline_names if n.upper() in name_to_idx], int)\n",
    "if len(MID) < 2:\n",
    "    # fallback to a small anterior subset from consensus if MID sparse\n",
    "    cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "    ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "    ant = []\n",
    "    for i,ch in enumerate(ch_names):\n",
    "        pref=re.match(r\"[A-Za-z]+\", ch)\n",
    "        pref=pref.group(0) if pref else \"\"\n",
    "        if any(pref.startswith(px) for px in ANT_PREFIXES): ant.append(i)\n",
    "    MID = np.array(ant[:3], int)  # take a compact 3-ch anterior set\n",
    "print(f\"Midline/frontal mask used for theta: {MID.tolist()}\")\n",
    "\n",
    "def band_env(sig, lo, hi, fs):\n",
    "    b,a = butter(4, [lo/(fs/2), hi/(fs/2)], btype='band')\n",
    "    x   = filtfilt(b,a,sig)\n",
    "    env = np.abs(hilbert(x))**2  # power envelope\n",
    "    return float(np.mean(env))\n",
    "\n",
    "def lap_node(X, center, neigh_idx):\n",
    "    if (center is None) or (len(neigh_idx)==0): return None\n",
    "    neigh = np.mean([X[i] for i in neigh_idx], axis=0)\n",
    "    return X[center] - neigh\n",
    "\n",
    "def pli_within(X, idxs, lo, hi, fs):\n",
    "    if len(idxs)<2: return np.nan\n",
    "    b,a = butter(4,[lo/(fs/2),hi/(fs/2)], btype='band')\n",
    "    vals=[]; ids=list(idxs)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            xi = filtfilt(b,a,X[ids[i]]); xj = filtfilt(b,a,X[ids[j]])\n",
    "            phx=np.angle(hilbert(xi)); phy=np.angle(hilbert(xj))\n",
    "            vals.append(float(np.abs(np.mean(np.sign(np.sin(phx-phy))))))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "def extract_epochs(sid, run, t0=2.0, dur=2.0):\n",
    "    edf=os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{run:02d}.edf\")\n",
    "    raw=mne.io.read_raw_edf(edf, preload=True, verbose=\"ERROR\")\n",
    "    raw.pick_types(eeg=True, stim=False, eog=False, ecg=False)\n",
    "    raw.resample(FS, npad=\"auto\", verbose=\"ERROR\")\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=\"ERROR\")\n",
    "    X=raw.get_data(picks=\"eeg\"); fs=raw.info[\"sfreq\"]\n",
    "    w=int(dur*fs); shift=int(t0*fs)\n",
    "    code_map={}\n",
    "    for k,v in event_id.items():\n",
    "        if k.upper()==\"T0\": code_map[v]=\"REST\"\n",
    "        elif k.upper()==\"T1\": code_map[v]=\"LEFT\"\n",
    "        elif k.upper()==\"T2\": code_map[v]=\"RIGHT\"\n",
    "    out={\"LEFT\":[], \"RIGHT\":[], \"REST\":[]}\n",
    "    for (samp,_,code) in events:\n",
    "        lab=code_map.get(code,None)\n",
    "        if lab is None: continue\n",
    "        start=samp+shift; stop=start+w\n",
    "        if stop<=X.shape[1]:\n",
    "            out[lab].append(X[:,start:stop])\n",
    "    return out\n",
    "\n",
    "# pick 50 subjects with EDFs\n",
    "subs=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR,\"subject_*_EC.npy\")):\n",
    "    sid=int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    edfs=[os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{r:02d}.edf\") for r in (3,4)]\n",
    "    if all(os.path.exists(p) for p in edfs): subs.append(sid)\n",
    "subs=sorted(subs)[:50]\n",
    "print(\"Subjects:\", len(subs))\n",
    "\n",
    "rows=[]\n",
    "for sid in subs:\n",
    "    ep3 = extract_epochs(sid,3,t0=2.0,dur=2.0)  # LEFT block\n",
    "    ep4 = extract_epochs(sid,4,t0=2.0,dur=2.0)  # RIGHT block\n",
    "\n",
    "    def erd_li(ep_list, left_task):\n",
    "        \"\"\"Return LI for μ and β using Laplacian signals at C3/C4: LI = |ERD_contra| - |ERD_ipsi|.\"\"\"\n",
    "        if not ep_list: return np.nan, np.nan\n",
    "        lis_mu=[]; lis_be=[]\n",
    "        for ep in ep_list:\n",
    "            xC3 = lap_node(ep, C3, neighbors_L); xC4 = lap_node(ep, C4, neighbors_R)\n",
    "            if xC3 is None or xC4 is None: continue\n",
    "            if left_task:\n",
    "                contra_mu = band_env(xC4, 8,13,FS); ipsi_mu = band_env(xC3, 8,13,FS)\n",
    "                contra_be = band_env(xC4,13,30,FS); ipsi_be = band_env(xC3,13,30,FS)\n",
    "            else:\n",
    "                contra_mu = band_env(xC3, 8,13,FS); ipsi_mu = band_env(xC4, 8,13,FS)\n",
    "                contra_be = band_env(xC3,13,30,FS); ipsi_be = band_env(xC4,13,30,FS)\n",
    "            # ERD% vs REST will be handled by subtracting matched rest envelope later; for LI we use absolute motor-only |contra-ipsi|.\n",
    "            li_mu = abs(contra_mu - ipsi_mu)\n",
    "            li_be = abs(contra_be - ipsi_be)\n",
    "            lis_mu.append(li_mu); lis_be.append(li_be)\n",
    "        if len(lis_mu)==0: return np.nan, np.nan\n",
    "        return float(np.mean(lis_mu)), float(np.mean(lis_be))\n",
    "\n",
    "    # motor LIs\n",
    "    LI_mu_R03, LI_be_R03 = erd_li(ep3[\"LEFT\"],  left_task=True)\n",
    "    LI_mu_R04, LI_be_R04 = erd_li(ep4[\"RIGHT\"], left_task=False)\n",
    "\n",
    "    # rest power to compute ERD% (channel-wise)\n",
    "    def rest_env(ep_list, center, neigh):\n",
    "        if not ep_list or center is None or len(neigh)==0: return np.nan, np.nan\n",
    "        vals_mu=[]; vals_be=[]\n",
    "        for ep in ep_list:\n",
    "            xC = lap_node(ep, center, neigh)\n",
    "            vals_mu.append(band_env(xC, 8,13,FS))\n",
    "            vals_be.append(band_env(xC,13,30,FS))\n",
    "        return float(np.mean(vals_mu)), float(np.mean(vals_be))\n",
    "\n",
    "    # θ midline within (motor vs rest)\n",
    "    def theta_mid_within(ep_list):\n",
    "        if not ep_list: return np.nan\n",
    "        vals=[]\n",
    "        for ep in ep_list:\n",
    "            vals.append(pli_within(ep, MID, 4,8,FS))\n",
    "        vals=[v for v in vals if np.isfinite(v)]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    th_R03_m = theta_mid_within(ep3[\"LEFT\"])\n",
    "    th_R04_m = theta_mid_within(ep4[\"RIGHT\"])\n",
    "    th_R03_r = theta_mid_within(ep3[\"REST\"])\n",
    "    th_R04_r = theta_mid_within(ep4[\"REST\"])\n",
    "\n",
    "    rows.append({\n",
    "        \"subject\":sid,\n",
    "        \"LI_mu_R03\":LI_mu_R03, \"LI_mu_R04\":LI_mu_R04,\n",
    "        \"LI_be_R03\":LI_be_R03, \"LI_be_R04\":LI_be_R04,\n",
    "        \"theta_mid_motor\":np.nanmean([th_R03_m, th_R04_m]),\n",
    "        \"theta_mid_rest\": np.nanmean([th_R03_r, th_R04_r]),\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_out = os.path.join(TAB_DIR, \"lap_erd_subject50.csv\")\n",
    "df.to_csv(csv_out, index=False)\n",
    "print(\"Saved:\", csv_out)\n",
    "\n",
    "# Permutation tests\n",
    "def one_sample_greater(x, n_perm=10000):\n",
    "    x=np.asarray(x,float); x=x[np.isfinite(x)]\n",
    "    if len(x)<10: return np.nan,np.nan,np.nan,len(x)\n",
    "    rng=default_rng(65); obs=float(np.mean(x)); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(x))*2-1\n",
    "        perm=np.mean(x*signs)\n",
    "        if perm>=obs: cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(x,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(x)\n",
    "\n",
    "def paired_perm(a,b,n_perm=10000):\n",
    "    a=np.asarray(a,float); b=np.asarray(b,float)\n",
    "    mask=np.isfinite(a)&np.isfinite(b); a=a[mask]; b=b[mask]\n",
    "    if len(a)<10: return np.nan,np.nan,np.nan,len(a)\n",
    "    diff=a-b; obs=float(np.mean(diff)); rng=default_rng(66); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(diff))*2-1\n",
    "        perm=np.mean(diff*signs)\n",
    "        if abs(perm)>=abs(obs): cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(diff,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(a)\n",
    "\n",
    "tests=[]\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_mu_R03\"].values); tests.append({\"test\":\"|μ| laterality R03 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_mu_R04\"].values); tests.append({\"test\":\"|μ| laterality R04 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_be_R03\"].values); tests.append({\"test\":\"|β| laterality R03 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "obs,d,p,n = one_sample_greater(df[\"LI_be_R04\"].values); tests.append({\"test\":\"|β| laterality R04 > 0\", \"mean\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "\n",
    "obs,d,p,n = paired_perm(df[\"theta_mid_motor\"].values, df[\"theta_mid_rest\"].values); tests.append({\"test\":\"θ midline within (motor - rest)\", \"Δ\":obs,\"d\":d,\"p\":p,\"N\":n})\n",
    "\n",
    "t_df = pd.DataFrame(tests)\n",
    "t_df.to_csv(os.path.join(TAB_DIR,\"lap_erd_summary.csv\"), index=False)\n",
    "print(t_df.to_string(index=False))\n",
    "\n",
    "# Plots\n",
    "def one_bar(vals, title, fname, ylabel=\"Index\"):\n",
    "    a=np.asarray(vals,float); a=a[np.isfinite(a)]\n",
    "    mean=float(np.mean(a))\n",
    "    boots=[np.mean(resample(a,replace=True,n_samples=len(a))) for _ in range(2000)]\n",
    "    lo,hi=np.percentile(boots,[2.5,97.5])\n",
    "    plt.figure(figsize=(4.2,3.6))\n",
    "    plt.bar([0],[mean], yerr=[[mean-lo],[hi-mean]], capsize=4)\n",
    "    plt.xticks([0],[title]); plt.ylabel(ylabel)\n",
    "    out=os.path.join(FIG_DIR,fname); plt.tight_layout(); plt.savefig(out,dpi=160); plt.close()\n",
    "\n",
    "one_bar(df[\"LI_mu_R04\"].values,  \"|μ| LI R04 (>0)\",  \"LI_abs_mu_R04.png\",  \"abs(μ contra-ipsi)\")\n",
    "one_bar(df[\"LI_be_R04\"].values,  \"|β| LI R04 (>0)\",  \"LI_abs_beta_R04.png\",\"abs(β contra-ipsi)\")\n",
    "one_bar(df[\"theta_mid_motor\"].values - df[\"theta_mid_rest\"].values, \"θ mid (motor-rest)\", \"theta_mid_motor_minus_rest.png\", \"ΔPLI\")\n",
    "\n",
    "print(\"Figures:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4ab82acf-0b9a-42c6-a95b-891286924a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FR size: base=36  extended=36 (add: ['AFz', 'Fz', 'FCz', 'F1', 'F2', 'FC1', 'FC2'])\n",
      "Using subjects: 50\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\theta_control_FR_PSI\\tables\\theta_FR_PSI_subject50.csv\n",
      "                      test    meanΔ        d        p  N\n",
      "θ FR within (motor - rest) 0.001432 0.073321 0.609539 50\n",
      "θ PSI FR→PO (motor - rest) 0.004384 0.064948 0.647035 50\n",
      "Figures: C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\theta_control_FR_PSI\\figures\n"
     ]
    }
   ],
   "source": [
    "# === Cue-locked CNT control (θ) with consensus frontal + FR→PO PSI (3–5 s window), N=50 ===\n",
    "import os, re, glob, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from numpy.random import default_rng\n",
    "from scipy.signal import butter, filtfilt, hilbert, csd\n",
    "\n",
    "ROOT      = r\"C:\\Users\\caleb\\CNT_Lab\"\n",
    "DATA_DIR  = os.path.join(ROOT, \"eeg_rest\")\n",
    "ART_ROOT  = os.path.join(ROOT, r\"artifacts\\pli_humans_100plus\")\n",
    "EDF_ROOT  = os.path.join(os.path.expanduser(\"~\"), \"mne_data\", \"MNE-eegbci-data\", \"files\", \"eegmmidb\", \"1.0.0\")\n",
    "\n",
    "CH_TXT    = os.path.join(ROOT, \"eeg_rest\", \"subject_01_EC.channels.txt\")\n",
    "CONS_EC_ALPHA = os.path.join(ART_ROOT, \"tables\", \"band__EC__alpha__consensus_labels.npy\")\n",
    "\n",
    "OUT_DIR   = os.path.join(ART_ROOT, r\"tests_functional\\motor_cuelocked\\theta_control_FR_PSI\")\n",
    "TAB_DIR   = os.path.join(OUT_DIR, \"tables\"); os.makedirs(TAB_DIR, exist_ok=True)\n",
    "FIG_DIR   = os.path.join(OUT_DIR, \"figures\"); os.makedirs(FIG_DIR, exist_ok=True)\n",
    "\n",
    "assert os.path.exists(CH_TXT) and os.path.exists(CONS_EC_ALPHA)\n",
    "\n",
    "try:\n",
    "    import mne\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"-q\",\"mne\",\"pooch\"])\n",
    "    import mne\n",
    "\n",
    "FS = 250.0\n",
    "rng = default_rng(2061)\n",
    "\n",
    "def clean_label(s):\n",
    "    s = re.sub(r\"(?i)^(EEG|EOG|ECG|EMG|MEG)[\\s_\\-]+\",\"\",s.strip())\n",
    "    s = re.sub(r\"(?i)[\\s_\\-]*(REF|AV|AVERAGE|AVG|M1|M2)$\",\"\",s)\n",
    "    return re.sub(r\"[ \\-\\.]+\",\"\",s).replace(\"FP\",\"Fp\")\n",
    "\n",
    "with open(CH_TXT,\"r\",encoding=\"utf-8\") as f:\n",
    "    ch_names = [clean_label(x) for x in f if x.strip()]\n",
    "name_to_idx = {n.upper(): i for i,n in enumerate(ch_names)}\n",
    "def idx(n): return name_to_idx.get(n.upper(), None)\n",
    "\n",
    "# Consensus FR module from EC alpha\n",
    "cons_alpha = np.load(CONS_EC_ALPHA)\n",
    "ANT_PREFIXES=(\"Fp\",\"AF\",\"F\",\"FC\")\n",
    "A_mask=[]\n",
    "for i,ch in enumerate(ch_names):\n",
    "    pref=re.match(r\"[A-Za-z]+\", ch)\n",
    "    pref=pref.group(0) if pref else \"\"\n",
    "    if any(pref.startswith(px) for px in ANT_PREFIXES): A_mask.append(i)\n",
    "A_mask=np.array(A_mask,int)\n",
    "m0A = np.intersect1d(np.where(cons_alpha==0)[0], A_mask).size\n",
    "m1A = np.intersect1d(np.where(cons_alpha==1)[0], A_mask).size\n",
    "FR_LABEL = 0 if m0A>=m1A else 1\n",
    "FR = np.where(cons_alpha==FR_LABEL)[0]  # consensus frontal\n",
    "\n",
    "# Add a compact midline extension\n",
    "mid_add = [n for n in [\"AFz\",\"Fz\",\"FCz\",\"F1\",\"F2\",\"FC1\",\"FC2\"] if n.upper() in name_to_idx]\n",
    "FR_EXT = np.unique(np.concatenate([FR, np.array([name_to_idx[n.upper()] for n in mid_add], int)]))\n",
    "print(f\"FR size: base={len(FR)}  extended={len(FR_EXT)} (add: {mid_add})\")\n",
    "\n",
    "# helper filters/PLI/PSI\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b,a = butter(order, [lo/(fs/2), hi/(fs/2)], btype='band'); return filtfilt(b,a,x)\n",
    "\n",
    "def pli_within(X, idxs, lo, hi, fs):\n",
    "    if len(idxs)<2: return np.nan\n",
    "    b,a = butter(4,[lo/(fs/2),hi/(fs/2)], btype='band')\n",
    "    vals=[]; ids=list(idxs)\n",
    "    for i in range(len(ids)):\n",
    "        for j in range(i+1,len(ids)):\n",
    "            xi = filtfilt(b,a,X[ids[i]]); xj = filtfilt(b,a,X[ids[j]])\n",
    "            phx=np.angle(hilbert(xi)); phy=np.angle(hilbert(xj))\n",
    "            vals.append(float(np.abs(np.mean(np.sign(np.sin(phx-phy))))))\n",
    "    return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "def psi_FR_to_PO(X, FR_idx, PO_idx, fs, f_lo=4, f_hi=8, nperseg=256, noverlap=128):\n",
    "    # Average slope of phase(f) across FR×PO pairs\n",
    "    pairs=[]\n",
    "    for i in FR_idx:\n",
    "        for j in PO_idx:\n",
    "            f, Pxy = csd(X[i], X[j], fs=fs, nperseg=nperseg, noverlap=noverlap)\n",
    "            sel = (f>=f_lo) & (f<=f_hi)\n",
    "            if np.sum(sel) < 3: continue\n",
    "            ph = np.angle(Pxy[sel]); phu = np.unwrap(ph)\n",
    "            slope = np.polyfit(f[sel], phu, 1)[0]  # rad/Hz\n",
    "            pairs.append(slope)\n",
    "    return float(np.mean(pairs)) if pairs else np.nan\n",
    "\n",
    "# Need PO set (from consensus)\n",
    "PO = np.where(cons_alpha== (1-FR_LABEL) )[0]\n",
    "\n",
    "# pick N=50 with EDF R03/R04 present\n",
    "subs=[]\n",
    "for f in glob.glob(os.path.join(DATA_DIR,\"subject_*_EC.npy\")):\n",
    "    sid=int(re.search(r\"subject_(\\d+)_EC\\.npy$\", f).group(1))\n",
    "    edfs=[os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{r:02d}.edf\") for r in (3,4)]\n",
    "    if all(os.path.exists(p) for p in edfs): subs.append(sid)\n",
    "subs=sorted(subs)[:50]\n",
    "print(\"Using subjects:\", len(subs))\n",
    "\n",
    "def extract_epochs(sid, run, t0=3.0, dur=2.0):\n",
    "    edf=os.path.join(EDF_ROOT, f\"S{sid:03d}\", f\"S{sid:03d}R{run:02d}.edf\")\n",
    "    raw=mne.io.read_raw_edf(edf, preload=True, verbose=\"ERROR\")\n",
    "    raw.pick_types(eeg=True, stim=False, eog=False, ecg=False)\n",
    "    raw.resample(FS, npad=\"auto\", verbose=\"ERROR\")\n",
    "    events, event_id = mne.events_from_annotations(raw, verbose=\"ERROR\")\n",
    "    X=raw.get_data(picks=\"eeg\"); fs=raw.info[\"sfreq\"]\n",
    "    W=int(dur*fs); shift=int(t0*fs)\n",
    "    code={}\n",
    "    for k,v in event_id.items():\n",
    "        if k.upper()==\"T0\": code[v]=\"REST\"\n",
    "        elif k.upper()==\"T1\": code[v]=\"LEFT\"\n",
    "        elif k.upper()==\"T2\": code[v]=\"RIGHT\"\n",
    "    out={\"LEFT\":[], \"RIGHT\":[], \"REST\":[]}\n",
    "    for (samp,_,c) in events:\n",
    "        lab=code.get(c,None)\n",
    "        if lab is None: continue\n",
    "        s=samp+shift; e=s+W\n",
    "        if e<=X.shape[1]:\n",
    "            out[lab].append(X[:,s:e])\n",
    "    return out\n",
    "\n",
    "rows=[]\n",
    "for sid in subs:\n",
    "    ep3=extract_epochs(sid,3,t0=3.0,dur=2.0)  # LEFT\n",
    "    ep4=extract_epochs(sid,4,t0=3.0,dur=2.0)  # RIGHT\n",
    "\n",
    "    def mean_over(ep_list, fn):\n",
    "        vals=[fn(ep) for ep in ep_list] if ep_list else []\n",
    "        vals=[v for v in vals if np.isfinite(v)]\n",
    "        return float(np.mean(vals)) if vals else np.nan\n",
    "\n",
    "    # θ FR within: average across left/right motor epochs; same for REST\n",
    "    th_m = np.nanmean([ mean_over(ep3[\"LEFT\"],  lambda X: pli_within(X, FR_EXT, 4,8,FS)),\n",
    "                        mean_over(ep4[\"RIGHT\"], lambda X: pli_within(X, FR_EXT, 4,8,FS)) ])\n",
    "    th_r = np.nanmean([ mean_over(ep3[\"REST\"],  lambda X: pli_within(X, FR_EXT, 4,8,FS)),\n",
    "                        mean_over(ep4[\"REST\"],  lambda X: pli_within(X, FR_EXT, 4,8,FS)) ])\n",
    "\n",
    "    # θ PSI FR->PO: motor and rest\n",
    "    psi_m = np.nanmean([ mean_over(ep3[\"LEFT\"],  lambda X: psi_FR_to_PO(X, FR_EXT, PO, FS, 4,8)),\n",
    "                          mean_over(ep4[\"RIGHT\"], lambda X: psi_FR_to_PO(X, FR_EXT, PO, FS, 4,8)) ])\n",
    "    psi_r = np.nanmean([ mean_over(ep3[\"REST\"],  lambda X: psi_FR_to_PO(X, FR_EXT, PO, FS, 4,8)),\n",
    "                          mean_over(ep4[\"REST\"],  lambda X: psi_FR_to_PO(X, FR_EXT, PO, FS, 4,8)) ])\n",
    "\n",
    "    rows.append({\"subject\":sid, \"theta_FR_motor\":th_m, \"theta_FR_rest\":th_r,\n",
    "                 \"theta_PSI_motor\":psi_m, \"theta_PSI_rest\":psi_r})\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "csv_out = os.path.join(TAB_DIR, \"theta_FR_PSI_subject50.csv\")\n",
    "df.to_csv(csv_out, index=False)\n",
    "print(\"Saved:\", csv_out)\n",
    "\n",
    "# Paired permutation tests\n",
    "def paired_perm(a,b,n_perm=10000, two_sided=True):\n",
    "    a=np.asarray(a,float); b=np.asarray(b,float)\n",
    "    mask=np.isfinite(a)&np.isfinite(b); a=a[mask]; b=b[mask]\n",
    "    if len(a)<10: return np.nan,np.nan,np.nan,len(a)\n",
    "    diff=a-b; obs=float(np.mean(diff)); rng=default_rng(77); cnt=1\n",
    "    for _ in range(n_perm):\n",
    "        signs=rng.integers(0,2,size=len(diff))*2-1\n",
    "        perm=np.mean(diff*signs)\n",
    "        if (abs(perm)>=abs(obs)) if two_sided else (perm>=obs): cnt+=1\n",
    "    p=float(cnt/(n_perm+1)); d=float(obs/(np.std(diff,ddof=1)+1e-12))\n",
    "    return obs,d,p,len(a)\n",
    "\n",
    "obs1,d1,p1,n1 = paired_perm(df[\"theta_FR_motor\"].values,  df[\"theta_FR_rest\"].values,  n_perm=10000, two_sided=True)\n",
    "obs2,d2,p2,n2 = paired_perm(df[\"theta_PSI_motor\"].values, df[\"theta_PSI_rest\"].values, n_perm=10000, two_sided=True)\n",
    "\n",
    "sum_df = pd.DataFrame([\n",
    "    {\"test\":\"θ FR within (motor - rest)\", \"meanΔ\":obs1, \"d\":d1, \"p\":p1, \"N\":n1},\n",
    "    {\"test\":\"θ PSI FR→PO (motor - rest)\", \"meanΔ\":obs2, \"d\":d2, \"p\":p2, \"N\":n2},\n",
    "])\n",
    "sum_df.to_csv(os.path.join(TAB_DIR, \"theta_FR_PSI_summary.csv\"), index=False)\n",
    "print(sum_df.to_string(index=False))\n",
    "\n",
    "# Plots\n",
    "def one_bar(vals, title, fname):\n",
    "    import matplotlib.pyplot as plt\n",
    "    a=np.asarray(vals,float); a=a[np.isfinite(a)]\n",
    "    mean=float(np.mean(a))\n",
    "    from sklearn.utils import resample\n",
    "    boots=[np.mean(resample(a,replace=True,n_samples=len(a))) for _ in range(2000)]\n",
    "    lo,hi=np.percentile(boots,[2.5,97.5])\n",
    "    plt.figure(figsize=(4.2,3.6))\n",
    "    plt.bar([0],[mean], yerr=[[mean-lo],[hi-mean]], capsize=4)\n",
    "    plt.xticks([0],[title]); plt.ylabel(\"Δ\")\n",
    "    out=os.path.join(FIG_DIR,fname); plt.tight_layout(); plt.savefig(out,dpi=160); plt.close()\n",
    "\n",
    "one_bar(df[\"theta_FR_motor\"].values - df[\"theta_FR_rest\"].values,  \"θ FR (motor-rest)\",  \"theta_FR_delta.png\")\n",
    "one_bar(df[\"theta_PSI_motor\"].values - df[\"theta_PSI_rest\"].values,\"θ PSI FR→PO (motor-rest)\", \"theta_PSI_delta.png\")\n",
    "print(\"Figures:\", FIG_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6612623a-f6c2-4dff-987b-8364c116524c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
