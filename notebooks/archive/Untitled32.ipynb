{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8663243-e945-4dc1-b9d9-6b5b9351706e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_7828\\653980359.py:20: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  RUN_ID = dt.datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Quickstart — Completed ===\n",
      "Backend     : CuPy (GPU)\n",
      "Artifacts   : E:\\CNT\\artifacts\\cnt_quickstart\\20251110-031005Z-15c224\n",
      "K_knee      : 1.5000\n",
      "Kc_susc     : 1.5000\n",
      "Elapsed (s) : 185.44\n"
     ]
    }
   ],
   "source": [
    "# === CNT Quickstart Notebook — Single Cell (CPU/GPU autodetect) ===\n",
    "# Purpose: one-cell bootstrap for a reproducible Kuramoto sweep with artifacts.\n",
    "# Outputs:\n",
    "#   - artifacts/<RUN_ID>/kuramoto_sweep.png\n",
    "#   - artifacts/<RUN_ID>/kuramoto_sweep.csv\n",
    "#   - artifacts/<RUN_ID>/run_meta.json\n",
    "\n",
    "import os, json, math, time, sys, platform, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 0) Environment & paths\n",
    "# ------------------------------------------------------------\n",
    "# Preferred root (customize to your lab); falls back to local folder if unavailable\n",
    "CANDIDATES = [Path(\"E:/CNT\"), Path(\"E:\\\\CNT\"), Path(\"./CNT\")]\n",
    "ROOT = next((p for p in CANDIDATES if p.exists()), Path(\".\").resolve())\n",
    "ART = (ROOT / \"artifacts\").resolve()\n",
    "RUN_ID = dt.datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n",
    "RUN_DIR = (ART / f\"cnt_quickstart/{RUN_ID}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 1) Backend selection (CuPy if available, else NumPy)\n",
    "# ------------------------------------------------------------\n",
    "try:\n",
    "    import cupy as cp  # type: ignore\n",
    "    # Sanity check on device availability\n",
    "    _ = cp.zeros((1,))\n",
    "    xp = cp\n",
    "    HAS_CP = True\n",
    "except Exception:\n",
    "    xp = np\n",
    "    HAS_CP = False\n",
    "\n",
    "def to_np(a):\n",
    "    \"\"\"Safely convert xp-array to numpy array for saving/plotting.\"\"\"\n",
    "    if HAS_CP:\n",
    "        return cp.asnumpy(a)\n",
    "    return a\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 2) Kuramoto simulator (vectorized; supports xp = np/cp)\n",
    "# ------------------------------------------------------------\n",
    "def kuramoto_R_tail(omega_xp, K, dt=0.01, steps=6000, tail_frac=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Integrate Kuramoto phases: dθ_i/dt = ω_i + (K/N) * sum_j sin(θ_j - θ_i)\n",
    "    Returns time-averaged order parameter R over the final tail of the simulation.\n",
    "    \"\"\"\n",
    "    rs = xp.random.RandomState(seed) if not HAS_CP else xp.random.RandomState(seed)\n",
    "    N = omega_xp.shape[0]\n",
    "    theta = (2 * xp.pi) * rs.rand(N)\n",
    "    steps = int(steps)\n",
    "    tail_start = int((1.0 - tail_frac) * steps)\n",
    "\n",
    "    # Pre-alloc for running average of R in tail\n",
    "    R_sum, R_cnt = 0.0, 0\n",
    "\n",
    "    for t in range(steps):\n",
    "        # Compute the mean field via complex order parameter\n",
    "        z = xp.exp(1j * theta)\n",
    "        r = xp.abs(z.mean())  # instantaneous order parameter R_t\n",
    "\n",
    "        if t >= tail_start:\n",
    "            R_sum += float(r)\n",
    "            R_cnt += 1\n",
    "\n",
    "        # Mean-field coupling term: Im(e^{-iθ} * z_mean)\n",
    "        z_mean = z.mean()\n",
    "        coupling = xp.imag(z_mean * xp.exp(-1j * theta))\n",
    "        theta = theta + dt * (omega_xp + K * coupling)\n",
    "        # Keep phases numerically stable\n",
    "        if t % 200 == 0:\n",
    "            theta = xp.mod(theta, 2 * xp.pi)\n",
    "\n",
    "    R_tail = R_sum / max(R_cnt, 1)\n",
    "    return R_tail\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 3) Experiment spec\n",
    "# ------------------------------------------------------------\n",
    "N = 1024                 # oscillators\n",
    "SIGMA = 1.0              # freq std\n",
    "DIST = \"gaussian\"        # 'gaussian' or 'lorentz'\n",
    "K_MIN, K_MAX = 0.0, 3.0  # sweep range\n",
    "K_STEPS = 31             # number of K samples\n",
    "DT = 0.01\n",
    "STEPS = 8000\n",
    "TAIL_FRAC = 0.5\n",
    "SEED = 42\n",
    "\n",
    "# Frequency distribution\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "if DIST == \"gaussian\":\n",
    "    omega_np = rng_np.normal(0.0, SIGMA, size=N).astype(np.float64)\n",
    "elif DIST == \"lorentz\":\n",
    "    # Cauchy with gamma=SIGMA (scale), location=0\n",
    "    omega_np = rng_np.standard_cauchy(size=N).astype(np.float64) * SIGMA\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIST\")\n",
    "\n",
    "omega_xp = xp.asarray(omega_np)\n",
    "\n",
    "# K sweep\n",
    "Ks = np.linspace(K_MIN, K_MAX, K_STEPS)\n",
    "Rs = []\n",
    "t0 = time.time()\n",
    "for idx, K in enumerate(Ks):\n",
    "    R_tail = kuramoto_R_tail(omega_xp, float(K), dt=DT, steps=STEPS, tail_frac=TAIL_FRAC, seed=SEED + idx)\n",
    "    Rs.append(R_tail)\n",
    "\n",
    "elapsed = time.time() - t0\n",
    "Rs = np.array(Rs, dtype=np.float64)\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 4) Knee/critical-region estimate (simple change-point on discrete derivative)\n",
    "# ------------------------------------------------------------\n",
    "dR = np.diff(Rs)\n",
    "# Use a robust z-score to find the first significant slope jump\n",
    "mu, sd = float(np.median(dR)), float(np.median(np.abs(dR - np.median(dR))) + 1e-9)\n",
    "z = (dR - mu) / (sd if sd > 0 else 1.0)\n",
    "# Index where z first exceeds threshold\n",
    "Z_THR = 3.0\n",
    "idx_knee = int(np.argmax(z > Z_THR)) if np.any(z > Z_THR) else int(np.argmax(dR))\n",
    "K_knee = float(Ks[idx_knee + 1]) if idx_knee + 1 < len(Ks) else float(Ks[-1])\n",
    "\n",
    "# Optional: estimate \"Kc_susc\" via max slope\n",
    "idx_susc = int(np.argmax(dR))\n",
    "Kc_susc = float(Ks[idx_susc + 1]) if idx_susc + 1 < len(Ks) else float(Ks[-1])\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# 5) Save artifacts\n",
    "# ------------------------------------------------------------\n",
    "# CSV\n",
    "import csv\n",
    "csv_path = RUN_DIR / \"kuramoto_sweep.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    w = csv.writer(f)\n",
    "    w.writerow([\"K\", \"R_tail\"])\n",
    "    for k, r in zip(Ks, Rs):\n",
    "        w.writerow([f\"{k:.6f}\", f\"{r:.6f}\"])\n",
    "\n",
    "# Plot (single plot, matplotlib only, no styles/colors set)\n",
    "fig = plt.figure(figsize=(7.2, 4.5), dpi=140)\n",
    "plt.plot(Ks, Rs, marker=\"o\")\n",
    "plt.axvline(K_knee, linestyle=\"--\", label=f\"K_knee≈{K_knee:.3f}\")\n",
    "plt.axvline(Kc_susc, linestyle=\":\", label=f\"Kc_susc≈{Kc_susc:.3f}\")\n",
    "plt.xlabel(\"K (coupling)\")\n",
    "plt.ylabel(\"R (order parameter, tail mean)\")\n",
    "plt.title(f\"Kuramoto Sweep (N={N}, {DIST}, σ={SIGMA})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "png_path = RUN_DIR / \"kuramoto_sweep.png\"\n",
    "plt.savefig(png_path)\n",
    "plt.close(fig)\n",
    "\n",
    "# Meta JSON\n",
    "meta = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"root\": str(ROOT),\n",
    "    \"artifacts_dir\": str(RUN_DIR),\n",
    "    \"env\": {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"gpu_backend\": \"cupy\" if HAS_CP else \"numpy\",\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"N\": N, \"sigma\": SIGMA, \"dist\": DIST,\n",
    "        \"K_min\": K_MIN, \"K_max\": K_MAX, \"K_steps\": K_STEPS,\n",
    "        \"dt\": DT, \"steps\": STEPS, \"tail_frac\": TAIL_FRAC, \"seed\": SEED\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"K_knee\": K_knee,\n",
    "        \"Kc_susc\": Kc_susc,\n",
    "        \"elapsed_sec\": elapsed\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"csv\": str(csv_path),\n",
    "        \"png\": str(png_path)\n",
    "    }\n",
    "}\n",
    "with open(RUN_DIR / \"run_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"=== CNT Quickstart — Completed ===\")\n",
    "print(f\"Backend     : {'CuPy (GPU)' if HAS_CP else 'NumPy (CPU)'}\")\n",
    "print(f\"Artifacts   : {RUN_DIR}\")\n",
    "print(f\"K_knee      : {K_knee:.4f}\")\n",
    "print(f\"Kc_susc     : {Kc_susc:.4f}\")\n",
    "print(f\"Elapsed (s) : {elapsed:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "151311e1-8af8-46a6-894b-10e3d0c2889d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Quickstart v2 — Completed ===\n",
      "Backend     : CuPy (GPU)  | dtype: fp32\n",
      "Artifacts   : E:\\CNT\\artifacts\\cnt_quickstart\\20251110-031541Z-803a33\n",
      "K_knee      : 1.5000\n",
      "Kc_susc     : 1.6000\n",
      "Elapsed (s) : 46.63\n"
     ]
    }
   ],
   "source": [
    "# === CNT Quickstart v2 — Faster sweep, UTC-safe RUN_ID, FP32 option ===\n",
    "import os, json, math, time, sys, platform, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths & run id (UTC-safe)\n",
    "# ----------------------------\n",
    "CANDIDATES = [Path(\"E:/CNT\"), Path(\"E:\\\\CNT\"), Path(\"./CNT\")]\n",
    "ROOT = next((p for p in CANDIDATES if p.exists()), Path(\".\").resolve())\n",
    "ART = (ROOT / \"artifacts\").resolve()\n",
    "RUN_ID = dt.datetime.now(dt.timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n",
    "RUN_DIR = (ART / f\"cnt_quickstart/{RUN_ID}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Backend & dtype\n",
    "# ----------------------------\n",
    "try:\n",
    "    import cupy as cp  # type: ignore\n",
    "    _ = cp.zeros((1,))\n",
    "    xp = cp\n",
    "    HAS_CP = True\n",
    "except Exception:\n",
    "    xp = np\n",
    "    HAS_CP = False\n",
    "\n",
    "FP32 = True  # set False for FP64 fidelity; True is faster esp. on GPU\n",
    "DTYPE = np.float32 if FP32 else np.float64\n",
    "\n",
    "def to_np(a):\n",
    "    return cp.asnumpy(a) if HAS_CP else a\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Kuramoto (batched stepping)\n",
    "# ----------------------------\n",
    "def kuramoto_R_tail_batched(omega_xp, K, *, dt=0.01, steps=6000, block=5, tail_frac=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Integrate dθ/dt = ω + K * Im(z_mean * e^{-iθ}) with block sub-steps per loop\n",
    "    to reduce Python overhead. Returns tail-averaged R.\n",
    "    \"\"\"\n",
    "    rs = xp.random.RandomState(seed) if not HAS_CP else xp.random.RandomState(seed)\n",
    "    N = omega_xp.shape[0]\n",
    "    theta = (2 * xp.pi) * rs.rand(N, dtype=DTYPE)\n",
    "    steps = int(steps)\n",
    "    block = max(1, int(block))\n",
    "    outer = (steps + block - 1) // block\n",
    "    tail_start = int((1.0 - tail_frac) * steps)\n",
    "\n",
    "    R_sum, R_cnt = 0.0, 0\n",
    "    t = 0\n",
    "    for _ in range(outer):\n",
    "        # do up to 'block' fine steps within this outer iteration\n",
    "        b_left = min(block, steps - t)\n",
    "        for _ in range(b_left):\n",
    "            z = xp.exp(1j * theta)\n",
    "            z_mean = z.mean()\n",
    "            # instantaneous R\n",
    "            if t >= tail_start:\n",
    "                R_sum += float(xp.abs(z_mean))\n",
    "                R_cnt += 1\n",
    "            coupling = xp.imag(z_mean * xp.exp(-1j * theta))\n",
    "            theta = theta + dt * (omega_xp + K * coupling)\n",
    "            # periodic rewrap to avoid drift\n",
    "            if (t & 255) == 0:\n",
    "                theta = xp.mod(theta, 2 * xp.pi)\n",
    "            t += 1\n",
    "        # cheap barrier on GPU to avoid async backlog\n",
    "        if HAS_CP:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "    return R_sum / max(R_cnt, 1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Experiment spec\n",
    "# ----------------------------\n",
    "N = 1024                  # oscillators\n",
    "SIGMA = 1.0               # freq scale (std for Gaussian, gamma for Lorentz)\n",
    "DIST = \"gaussian\"         # 'gaussian' or 'lorentz'\n",
    "K_MIN, K_MAX = 0.0, 3.0\n",
    "K_STEPS = 31\n",
    "DTINTEGRATE = 0.01\n",
    "STEPS = 6000              # you used 8000; 6000 with BLOCK=5 usually suffices\n",
    "BLOCK = 5                 # sub-steps per Python loop (higher = fewer Python iters)\n",
    "TAIL_FRAC = 0.5\n",
    "SEED = 42\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Frequencies & arrays\n",
    "# ----------------------------\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "if DIST == \"gaussian\":\n",
    "    omega_np = rng_np.normal(0.0, SIGMA, size=N).astype(DTYPE)\n",
    "elif DIST == \"lorentz\":\n",
    "    omega_np = (rng_np.standard_cauchy(size=N).astype(DTYPE)) * SIGMA\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIST\")\n",
    "\n",
    "# move to backend with desired dtype\n",
    "omega_xp = xp.asarray(omega_np, dtype=DTYPE)\n",
    "\n",
    "Ks = np.linspace(K_MIN, K_MAX, K_STEPS, dtype=np.float64)  # keep K in FP64 for sweep grid\n",
    "Rs = np.empty_like(Ks, dtype=np.float64)\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Sweep\n",
    "# ----------------------------\n",
    "t0 = time.time()\n",
    "for i, K in enumerate(Ks):\n",
    "    Rs[i] = kuramoto_R_tail_batched(\n",
    "        omega_xp, float(K),\n",
    "        dt=DTINTEGRATE, steps=STEPS, block=BLOCK,\n",
    "        tail_frac=TAIL_FRAC, seed=SEED + i\n",
    "    )\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Knee estimates\n",
    "# ----------------------------\n",
    "dR = np.diff(Rs)\n",
    "mu = float(np.median(dR))\n",
    "sd = float(np.median(np.abs(dR - mu)) + 1e-9)\n",
    "z = (dR - mu) / (sd if sd > 0 else 1.0)\n",
    "Z_THR = 3.0\n",
    "idx_knee = int(np.argmax(z > Z_THR)) if np.any(z > Z_THR) else int(np.argmax(dR))\n",
    "K_knee = float(Ks[min(idx_knee + 1, len(Ks) - 1)])\n",
    "idx_susc = int(np.argmax(dR))\n",
    "Kc_susc = float(Ks[min(idx_susc + 1, len(Ks) - 1)])\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Artifacts\n",
    "# ----------------------------\n",
    "# CSV\n",
    "csv_path = RUN_DIR / \"kuramoto_sweep.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    f.write(\"K,R_tail\\n\")\n",
    "    for k, r in zip(Ks, Rs):\n",
    "        f.write(f\"{k:.6f},{r:.6f}\\n\")\n",
    "\n",
    "# Plot 1: R(K)\n",
    "fig1 = plt.figure(figsize=(7.2, 4.5), dpi=140)\n",
    "plt.plot(Ks, Rs, marker=\"o\")\n",
    "plt.axvline(K_knee, linestyle=\"--\", label=f\"K_knee≈{K_knee:.3f}\")\n",
    "plt.axvline(Kc_susc, linestyle=\":\", label=f\"Kc_susc≈{Kc_susc:.3f}\")\n",
    "plt.xlabel(\"K (coupling)\")\n",
    "plt.ylabel(\"R (order parameter, tail mean)\")\n",
    "plt.title(f\"Kuramoto Sweep (N={N}, {DIST}, σ/γ={SIGMA}, dtype={'fp32' if FP32 else 'fp64'})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "png1 = RUN_DIR / \"kuramoto_sweep.png\"\n",
    "plt.savefig(png1)\n",
    "plt.close(fig1)\n",
    "\n",
    "# Plot 2: slope dR/dK\n",
    "fig2 = plt.figure(figsize=(7.2, 3.8), dpi=140)\n",
    "dK = np.diff(Ks)\n",
    "plt.plot(Ks[:-1] + 0.5 * dK, dR, marker=\".\")\n",
    "plt.axvline(Kc_susc, linestyle=\":\", label=f\"max slope≈{Kc_susc:.3f}\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"ΔR / ΔK\")\n",
    "plt.title(\"Discrete slope of R(K)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "png2 = RUN_DIR / \"kuramoto_slope.png\"\n",
    "plt.savefig(png2)\n",
    "plt.close(fig2)\n",
    "\n",
    "# Meta\n",
    "meta = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"root\": str(ROOT),\n",
    "    \"artifacts_dir\": str(RUN_DIR),\n",
    "    \"env\": {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"backend\": \"cupy\" if HAS_CP else \"numpy\",\n",
    "        \"dtype\": \"fp32\" if FP32 else \"fp64\",\n",
    "    },\n",
    "    \"params\": {\n",
    "        \"N\": N, \"sigma_or_gamma\": SIGMA, \"dist\": DIST,\n",
    "        \"K_min\": float(K_MIN), \"K_max\": float(K_MAX), \"K_steps\": int(K_STEPS),\n",
    "        \"dt\": DTINTEGRATE, \"steps\": int(STEPS), \"block\": int(BLOCK),\n",
    "        \"tail_frac\": TAIL_FRAC, \"seed\": SEED\n",
    "    },\n",
    "    \"results\": {\n",
    "        \"K_knee\": K_knee,\n",
    "        \"Kc_susc\": Kc_susc,\n",
    "        \"elapsed_sec\": elapsed\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"csv\": str(csv_path),\n",
    "        \"png_R\": str(png1),\n",
    "        \"png_slope\": str(png2)\n",
    "    }\n",
    "}\n",
    "with open(RUN_DIR / \"run_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"=== CNT Quickstart v2 — Completed ===\")\n",
    "print(f\"Backend     : {'CuPy (GPU)' if HAS_CP else 'NumPy (CPU)'}  | dtype: {'fp32' if FP32 else 'fp64'}\")\n",
    "print(f\"Artifacts   : {RUN_DIR}\")\n",
    "print(f\"K_knee      : {K_knee:.4f}\")\n",
    "print(f\"Kc_susc     : {Kc_susc:.4f}\")\n",
    "print(f\"Elapsed (s) : {elapsed:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c26db0c-ef5d-49fd-86cf-a750a3a89a45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Finite-Size Scaling — Completed ===\n",
      "Backend     : CuPy (GPU) | dtype: fp32\n",
      "Artifacts   : E:\\CNT\\artifacts\\cnt_fss\\20251110-033047Z-b80f75\n",
      "N= 512 → Kc_susc≈1.5000\n",
      "N=1024 → Kc_susc≈1.6250\n",
      "N=2048 → Kc_susc≈1.6875\n",
      "Theory Kc   : 1.5958 (gaussian, σ/γ=1.0)\n",
      "β estimate  : 0.169\n",
      "Elapsed (s) : 200.72\n"
     ]
    }
   ],
   "source": [
    "# === CNT Finite-Size Scaling — One Cell (GPU/CPU, UTC-safe, fp32/fp64) ===\n",
    "# Runs Kuramoto sweeps for N in {512,1024,2048}; estimates Kc (max slope),\n",
    "# fits β from R ~ (K - Kc)^β, and emits clean artifacts.\n",
    "# Artifacts:\n",
    "#   E:/CNT/artifacts/cnt_fss/<RUN_ID>/\n",
    "#     - fss_R_vs_K.png         (R(K) for all N + Kc markers)\n",
    "#     - fss_slope.png          (dR/dK for all N + max-slope)\n",
    "#     - fss_beta_fit.png       (log-log fit for β with windowing)\n",
    "#     - fss_results.csv        (K, R, N rows)\n",
    "#     - run_meta.json          (params, Kc per N, β estimate, timing)\n",
    "\n",
    "import os, json, math, time, sys, platform, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths & run id (UTC-safe)\n",
    "# ----------------------------\n",
    "CANDIDATES = [Path(\"E:/CNT\"), Path(\"E:\\\\CNT\"), Path(\"./CNT\")]\n",
    "ROOT = next((p for p in CANDIDATES if p.exists()), Path(\".\").resolve())\n",
    "ART = (ROOT / \"artifacts\").resolve()\n",
    "RUN_ID = dt.datetime.now(dt.timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n",
    "RUN_DIR = (ART / f\"cnt_fss/{RUN_ID}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Backend & dtype\n",
    "# ----------------------------\n",
    "try:\n",
    "    import cupy as cp  # type: ignore\n",
    "    _ = cp.zeros((1,))\n",
    "    xp = cp\n",
    "    HAS_CP = True\n",
    "except Exception:\n",
    "    xp = np\n",
    "    HAS_CP = False\n",
    "\n",
    "FP32 = True  # True for speed (GPU esp.); False for fp64 fidelity\n",
    "DTYPE = np.float32 if FP32 else np.float64\n",
    "\n",
    "def to_np(a):\n",
    "    return cp.asnumpy(a) if HAS_CP else a\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Kuramoto (batched stepping)\n",
    "# ----------------------------\n",
    "def kuramoto_R_tail_batched(omega_xp, K, *, dt=0.01, steps=6000, block=5, tail_frac=0.5, seed=0):\n",
    "    \"\"\"Integrate dθ/dt = ω + K * Im(z_mean * e^{-iθ}) with 'block' sub-steps per loop.\n",
    "       Returns tail-averaged R.\"\"\"\n",
    "    rs = xp.random.RandomState(seed) if not HAS_CP else xp.random.RandomState(seed)\n",
    "    N = omega_xp.shape[0]\n",
    "    theta = (2 * xp.pi) * rs.rand(N, dtype=DTYPE)\n",
    "    steps = int(steps)\n",
    "    block = max(1, int(block))\n",
    "    outer = (steps + block - 1) // block\n",
    "    tail_start = int((1.0 - tail_frac) * steps)\n",
    "\n",
    "    R_sum, R_cnt = 0.0, 0\n",
    "    t = 0\n",
    "    for _ in range(outer):\n",
    "        b_left = min(block, steps - t)\n",
    "        for _ in range(b_left):\n",
    "            z = xp.exp(1j * theta)\n",
    "            z_mean = z.mean()\n",
    "            if t >= tail_start:\n",
    "                R_sum += float(xp.abs(z_mean))\n",
    "                R_cnt += 1\n",
    "            coupling = xp.imag(z_mean * xp.exp(-1j * theta))\n",
    "            theta = theta + dt * (omega_xp + K * coupling)\n",
    "            if (t & 255) == 0:\n",
    "                theta = xp.mod(theta, 2 * xp.pi)\n",
    "            t += 1\n",
    "        if HAS_CP:\n",
    "            cp.cuda.Stream.null.synchronize()\n",
    "    return R_sum / max(R_cnt, 1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Experiment spec\n",
    "# ----------------------------\n",
    "Ns = [512, 1024, 2048]    # finite-size sweep\n",
    "SIGMA = 1.0               # std (Gaussian) or gamma (Lorentz)\n",
    "DIST = \"gaussian\"         # 'gaussian' or 'lorentz'\n",
    "K_MIN, K_MAX = 0.0, 3.0\n",
    "K_STEPS = 49              # finer grid gives crisper slopes\n",
    "DTINTEGRATE = 0.01\n",
    "STEPS = 6000\n",
    "BLOCK = 5\n",
    "TAIL_FRAC = 0.5\n",
    "SEED = 42\n",
    "\n",
    "# Theoretical Kc (reference, not enforced)\n",
    "if DIST == \"gaussian\":\n",
    "    # g(0) = 1/(sigma*sqrt(2π)) → Kc = 2/(π g(0)) = 2 sigma sqrt(2π) / π\n",
    "    Kc_theory = 2.0 * SIGMA * math.sqrt(2.0 * math.pi) / math.pi\n",
    "elif DIST == \"lorentz\":\n",
    "    # Kc = 2γ\n",
    "    Kc_theory = 2.0 * SIGMA\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIST\")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Sweep for each N\n",
    "# ----------------------------\n",
    "rng_np = np.random.default_rng(SEED)\n",
    "Ks = np.linspace(K_MIN, K_MAX, K_STEPS, dtype=np.float64)\n",
    "rows = []\n",
    "Kc_by_N = {}\n",
    "elapsed_total = 0.0\n",
    "\n",
    "t0_all = time.time()\n",
    "for Ni in Ns:\n",
    "    # frequencies per N (same seed path; larger N draws more)\n",
    "    if DIST == \"gaussian\":\n",
    "        omega_np = rng_np.normal(0.0, SIGMA, size=Ni).astype(DTYPE)\n",
    "    else:\n",
    "        omega_np = (rng_np.standard_cauchy(size=Ni).astype(DTYPE)) * SIGMA\n",
    "    omega_xp = xp.asarray(omega_np, dtype=DTYPE)\n",
    "\n",
    "    Rs = np.empty_like(Ks, dtype=np.float64)\n",
    "    t0 = time.time()\n",
    "    for i, K in enumerate(Ks):\n",
    "        Rs[i] = kuramoto_R_tail_batched(\n",
    "            omega_xp, float(K),\n",
    "            dt=DTINTEGRATE, steps=STEPS, block=BLOCK,\n",
    "            tail_frac=TAIL_FRAC, seed=SEED + i\n",
    "        )\n",
    "    elapsed = time.time() - t0\n",
    "    elapsed_total += elapsed\n",
    "\n",
    "    # susceptibility proxy (max slope)\n",
    "    dR = np.diff(Rs)\n",
    "    idx_susc = int(np.argmax(dR))\n",
    "    Kc_susc = float(Ks[min(idx_susc + 1, len(Ks) - 1)])\n",
    "    Kc_by_N[int(Ni)] = {\"Kc_susc\": Kc_susc}\n",
    "\n",
    "    for k, r in zip(Ks, Rs):\n",
    "        rows.append((int(Ni), float(k), float(r)))\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Fit β using near-critical window\n",
    "# ----------------------------\n",
    "# Merge all points; for each N, use its Kc_susc\n",
    "rows_np = np.array(rows, dtype=[(\"N\", np.int32), (\"K\", np.float64), (\"R\", np.float64)])\n",
    "\n",
    "def fit_beta(rows_np, Kc_map, r_min=0.05, r_max=0.6):\n",
    "    X, Y = [], []\n",
    "    for (Ni, K, R) in rows_np:\n",
    "        KcN = Kc_map[int(Ni)][\"Kc_susc\"]\n",
    "        if K > KcN and r_min <= R <= r_max:\n",
    "            x = K - KcN\n",
    "            if x > 0:\n",
    "                X.append(math.log(x))\n",
    "                Y.append(math.log(R))\n",
    "    if len(X) < 4:  # not enough points; relax window if needed\n",
    "        # fall back to broader window\n",
    "        X, Y = [], []\n",
    "        for (Ni, K, R) in rows_np:\n",
    "            KcN = Kc_map[int(Ni)][\"Kc_susc\"]\n",
    "            if K > KcN and 0.02 <= R <= 0.8:\n",
    "                x = K - KcN\n",
    "                if x > 0:\n",
    "                    X.append(math.log(x))\n",
    "                    Y.append(math.log(R))\n",
    "    X = np.array(X, dtype=np.float64)\n",
    "    Y = np.array(Y, dtype=np.float64)\n",
    "    if len(X) >= 2:\n",
    "        m, b = np.polyfit(X, Y, 1)\n",
    "        beta = m  # slope in log-log; R ~ (K-Kc)^β\n",
    "        return beta, (m, b), X, Y\n",
    "    return float(\"nan\"), (float(\"nan\"), float(\"nan\")), np.array([]), np.array([])\n",
    "\n",
    "beta_est, (m_fit, b_fit), X_ll, Y_ll = fit_beta(rows_np, Kc_by_N)\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Save CSV\n",
    "# ----------------------------\n",
    "csv_path = RUN_DIR / \"fss_results.csv\"\n",
    "with open(csv_path, \"w\", newline=\"\") as f:\n",
    "    f.write(\"N,K,R\\n\")\n",
    "    for Nval, Kval, Rval in rows:\n",
    "        f.write(f\"{Nval},{Kval:.6f},{Rval:.6f}\\n\")\n",
    "\n",
    "# ----------------------------\n",
    "# 7) Plots (matplotlib, single plots, no custom colors/styles)\n",
    "# ----------------------------\n",
    "# R vs K\n",
    "fig1 = plt.figure(figsize=(7.8, 4.6), dpi=140)\n",
    "for Ni in Ns:\n",
    "    mask = rows_np[\"N\"] == Ni\n",
    "    Ki = rows_np[\"K\"][mask]\n",
    "    Ri = rows_np[\"R\"][mask]\n",
    "    plt.plot(Ki, Ri, marker=\"o\", label=f\"N={Ni}\")\n",
    "    plt.axvline(Kc_by_N[int(Ni)][\"Kc_susc\"], linestyle=\":\", label=f\"Kc(N={Ni})≈{Kc_by_N[int(Ni)]['Kc_susc']:.3f}\")\n",
    "plt.axvline(Kc_theory, linestyle=\"--\", label=f\"Kc_theory≈{Kc_theory:.3f}\")\n",
    "plt.xlabel(\"K (coupling)\")\n",
    "plt.ylabel(\"R (order parameter, tail mean)\")\n",
    "plt.title(f\"Kuramoto Finite-Size Sweep ({DIST}, σ/γ={SIGMA}, dtype={'fp32' if FP32 else 'fp64'})\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "png1 = RUN_DIR / \"fss_R_vs_K.png\"\n",
    "plt.savefig(png1); plt.close(fig1)\n",
    "\n",
    "# dR/dK\n",
    "fig2 = plt.figure(figsize=(7.8, 4.2), dpi=140)\n",
    "for Ni in Ns:\n",
    "    mask = rows_np[\"N\"] == Ni\n",
    "    Ki = rows_np[\"K\"][mask]\n",
    "    Ri = rows_np[\"R\"][mask]\n",
    "    dR = np.diff(Ri)\n",
    "    dK = np.diff(Ki)\n",
    "    Kmid = Ki[:-1] + 0.5 * dK\n",
    "    plt.plot(Kmid, dR / dK, marker=\".\", label=f\"N={Ni}\")\n",
    "    plt.axvline(Kc_by_N[int(Ni)][\"Kc_susc\"], linestyle=\":\", label=f\"Kc(N={Ni})\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"dR/dK (discrete)\")\n",
    "plt.title(\"Discrete slope of R(K)\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "png2 = RUN_DIR / \"fss_slope.png\"\n",
    "plt.savefig(png2); plt.close(fig2)\n",
    "\n",
    "# β fit (log-log)\n",
    "fig3 = plt.figure(figsize=(6.4, 4.6), dpi=140)\n",
    "if len(X_ll) >= 2:\n",
    "    x_grid = np.linspace(X_ll.min(), X_ll.max(), 200)\n",
    "    y_grid = m_fit * x_grid + b_fit\n",
    "    plt.plot(X_ll, Y_ll, marker=\"o\", linestyle=\"\", label=\"data (windowed)\")\n",
    "    plt.plot(x_grid, y_grid, label=f\"fit: β≈{m_fit:.3f}\")\n",
    "    plt.xlabel(\"log(K - Kc(N))\")\n",
    "    plt.ylabel(\"log R\")\n",
    "    plt.title(\"Critical scaling fit\")\n",
    "    plt.legend()\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"Insufficient points for β fit\", ha=\"center\", va=\"center\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "png3 = RUN_DIR / \"fss_beta_fit.png\"\n",
    "plt.savefig(png3); plt.close(fig3)\n",
    "\n",
    "elapsed_all = time.time() - t0_all\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Meta JSON\n",
    "# ----------------------------\n",
    "meta = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"artifacts_dir\": str(RUN_DIR),\n",
    "    \"env\": {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"backend\": \"cupy\" if HAS_CP else \"numpy\",\n",
    "        \"dtype\": \"fp32\" if FP32 else \"fp64\",\n",
    "    },\n",
    "    \"dist\": DIST,\n",
    "    \"sigma_or_gamma\": SIGMA,\n",
    "    \"theory\": {\"Kc_theory\": Kc_theory},\n",
    "    \"grid\": {\"K_min\": float(K_MIN), \"K_max\": float(K_MAX), \"K_steps\": int(K_STEPS)},\n",
    "    \"integrator\": {\"dt\": DTINTEGRATE, \"steps\": int(STEPS), \"block\": int(BLOCK), \"tail_frac\": float(TAIL_FRAC)},\n",
    "    \"sizes\": Ns,\n",
    "    \"results\": {\n",
    "        \"Kc_by_N\": Kc_by_N,\n",
    "        \"beta_est\": float(beta_est),\n",
    "        \"elapsed_sec_total\": elapsed_all\n",
    "    },\n",
    "    \"files\": {\n",
    "        \"csv\": str(csv_path),\n",
    "        \"png_R_vs_K\": str(png1),\n",
    "        \"png_slope\": str(png2),\n",
    "        \"png_beta_fit\": str(png3)\n",
    "    }\n",
    "}\n",
    "with open(RUN_DIR / \"run_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "print(\"=== CNT Finite-Size Scaling — Completed ===\")\n",
    "print(f\"Backend     : {'CuPy (GPU)' if HAS_CP else 'NumPy (CPU)'} | dtype: {'fp32' if FP32 else 'fp64'}\")\n",
    "print(f\"Artifacts   : {RUN_DIR}\")\n",
    "for Ni in Ns:\n",
    "    print(f\"N={Ni:4d} → Kc_susc≈{Kc_by_N[int(Ni)]['Kc_susc']:.4f}\")\n",
    "print(f\"Theory Kc   : {Kc_theory:.4f} ({DIST}, σ/γ={SIGMA})\")\n",
    "print(f\"β estimate  : {beta_est:.3f}\")\n",
    "print(f\"Elapsed (s) : {elapsed_all:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd8c1181-f2ca-4152-a8e5-abb9f39eaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Critical Refinement — Completed ===\n",
      "Artifacts : E:\\CNT\\artifacts\\cnt_crit_refine\\20251110-033907Z-18bc53\n",
      "Theory Kc : 1.5958  |  Kc(∞)≈1.8958\n",
      "N=512 : Kc_susc_coarse≈1.5000  |  Kc_susc_fine≈1.6375\n",
      "N=1024 : Kc_susc_coarse≈1.5700  |  Kc_susc_fine≈1.6263\n",
      "N=2048 : Kc_susc_coarse≈1.6750  |  Kc_susc_fine≈1.5063\n",
      "Crossing(N=512,1024) → Kc≈1.6926\n",
      "Crossing(N=1024,2048) → Kc≈1.7942\n",
      "β (shared Kc) ≈ nan\n",
      "Elapsed (s): 3131.34\n"
     ]
    }
   ],
   "source": [
    "# === CNT Critical Refinement — Multi-seed + Binder crossing + β fit (one cell) ===\n",
    "# Artifacts -> E:/CNT/artifacts/cnt_crit_refine/<RUN_ID>/\n",
    "\n",
    "import os, json, math, time, sys, platform, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ----------------------------\n",
    "# 0) Paths & UTC-safe run id\n",
    "# ----------------------------\n",
    "CANDIDATES = [Path(\"E:/CNT\"), Path(\"E:\\\\CNT\"), Path(\"./CNT\")]\n",
    "ROOT = next((p for p in CANDIDATES if p.exists()), Path(\".\").resolve())\n",
    "ART = (ROOT / \"artifacts\").resolve()\n",
    "RUN_ID = dt.datetime.now(dt.timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n",
    "RUN_DIR = (ART / f\"cnt_crit_refine/{RUN_ID}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Backend & dtype\n",
    "# ----------------------------\n",
    "try:\n",
    "    import cupy as cp  # type: ignore\n",
    "    _ = cp.zeros((1,))\n",
    "    xp = cp\n",
    "    HAS_CP = True\n",
    "except Exception:\n",
    "    xp = np\n",
    "    HAS_CP = False\n",
    "\n",
    "FP32 = True    # speed; set False for fp64 fidelity\n",
    "DTYPE = np.float32 if FP32 else np.float64\n",
    "\n",
    "def to_np(a): return cp.asnumpy(a) if HAS_CP else a\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Kuramoto integrator (returns tail moments)\n",
    "# ----------------------------\n",
    "def kuramoto_tail_moments(omega_xp, K, *, dt=0.01, steps=8000, block=5, tail_frac=0.5, seed=0):\n",
    "    \"\"\"\n",
    "    Integrate dθ/dt = ω + K * Im(z_mean e^{-iθ}); return tail-averaged\n",
    "    moments of R: <R>, <R^2>, <R^4> taken over time within the tail window.\n",
    "    \"\"\"\n",
    "    rs = xp.random.RandomState(seed) if not HAS_CP else xp.random.RandomState(seed)\n",
    "    N = omega_xp.shape[0]\n",
    "    theta = (2 * xp.pi) * rs.rand(N, dtype=DTYPE)\n",
    "    steps = int(steps); block = max(1, int(block))\n",
    "    outer = (steps + block - 1) // block\n",
    "    t, tail_start = 0, int((1.0 - tail_frac) * steps)\n",
    "\n",
    "    s1 = 0.0; s2 = 0.0; s4 = 0.0; cnt = 0\n",
    "    for _ in range(outer):\n",
    "        b = min(block, steps - t)\n",
    "        for _ in range(b):\n",
    "            z = xp.exp(1j * theta); z_mean = z.mean()\n",
    "            if t >= tail_start:\n",
    "                Rt = float(xp.abs(z_mean))\n",
    "                s1 += Rt; s2 += Rt*Rt; s4 += (Rt*Rt)*(Rt*Rt); cnt += 1\n",
    "            coupling = xp.imag(z_mean * xp.exp(-1j * theta))\n",
    "            theta = theta + dt * (omega_xp + K * coupling)\n",
    "            if (t & 255) == 0:\n",
    "                theta = xp.mod(theta, 2 * xp.pi)\n",
    "            t += 1\n",
    "        if HAS_CP: cp.cuda.Stream.null.synchronize()\n",
    "    if cnt == 0: return 0.0, 0.0, 0.0\n",
    "    m1 = s1 / cnt\n",
    "    m2 = s2 / cnt\n",
    "    m4 = s4 / cnt\n",
    "    return m1, m2, m4\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Experiment spec\n",
    "# ----------------------------\n",
    "Ns = [512, 1024, 2048]\n",
    "SEEDS = [101, 202, 303, 404, 505]   # multi-seed averaging\n",
    "DIST = \"gaussian\"                    # 'gaussian' or 'lorentz'\n",
    "SIGMA = 1.0\n",
    "DT = 0.01\n",
    "STEPS = 8000\n",
    "BLOCK = 5\n",
    "TAIL_FRAC = 0.5\n",
    "\n",
    "# theory reference\n",
    "if DIST == \"gaussian\":\n",
    "    Kc_theory = 2.0 * SIGMA * math.sqrt(2.0 * math.pi) / math.pi\n",
    "elif DIST == \"lorentz\":\n",
    "    Kc_theory = 2.0 * SIGMA\n",
    "else:\n",
    "    raise ValueError(\"Unknown DIST\")\n",
    "\n",
    "# coarse grid then adaptive zoom\n",
    "K_MIN, K_MAX = 0.8, 2.2\n",
    "K_STEPS_COARSE = 41\n",
    "COARSE_K = np.linspace(K_MIN, K_MAX, K_STEPS_COARSE)\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Sweep (coarse) → provisional Kc_susc(N)\n",
    "# ----------------------------\n",
    "rng_np = np.random.default_rng(42)\n",
    "data = {}   # N -> dict with arrays and results\n",
    "\n",
    "t_all = time.time()\n",
    "for Ni in Ns:\n",
    "    # draw frequencies\n",
    "    if DIST == \"gaussian\":\n",
    "        omega_np = rng_np.normal(0.0, SIGMA, size=Ni).astype(DTYPE)\n",
    "    else:\n",
    "        omega_np = (rng_np.standard_cauchy(size=Ni).astype(DTYPE)) * SIGMA\n",
    "    omega_xp = xp.asarray(omega_np, dtype=DTYPE)\n",
    "\n",
    "    R_mean = np.zeros_like(COARSE_K, dtype=np.float64)\n",
    "    R2_mean = np.zeros_like(COARSE_K, dtype=np.float64)\n",
    "    R4_mean = np.zeros_like(COARSE_K, dtype=np.float64)\n",
    "\n",
    "    for si, seed in enumerate(SEEDS):\n",
    "        for i, K in enumerate(COARSE_K):\n",
    "            m1, m2, m4 = kuramoto_tail_moments(\n",
    "                omega_xp, float(K), dt=DT, steps=STEPS, block=BLOCK, tail_frac=TAIL_FRAC, seed=seed+i\n",
    "            )\n",
    "            # online average\n",
    "            R_mean[i] = (R_mean[i]*si + m1) / (si+1)\n",
    "            R2_mean[i] = (R2_mean[i]*si + m2) / (si+1)\n",
    "            R4_mean[i] = (R4_mean[i]*si + m4) / (si+1)\n",
    "\n",
    "    # susceptibility proxy (max discrete slope of <R>)\n",
    "    dR = np.diff(R_mean); dK = np.diff(COARSE_K)\n",
    "    slope = dR / dK\n",
    "    idx_susc = int(np.argmax(slope))\n",
    "    Kc_susc = float(COARSE_K[min(idx_susc + 1, len(COARSE_K)-1)])\n",
    "\n",
    "    data[Ni] = {\n",
    "        \"K\": COARSE_K.copy(), \"R\": R_mean, \"R2\": R2_mean, \"R4\": R4_mean,\n",
    "        \"Kc_susc_coarse\": Kc_susc\n",
    "    }\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Adaptive zoom around each Kc_susc(N)\n",
    "# ----------------------------\n",
    "def refine_grid(Kc_guess, span=0.3, points=61):\n",
    "    lo = max(K_MIN, Kc_guess - span)\n",
    "    hi = min(K_MAX, Kc_guess + span)\n",
    "    return np.linspace(lo, hi, points)\n",
    "\n",
    "for Ni in Ns:\n",
    "    Kc_guess = data[Ni][\"Kc_susc_coarse\"]\n",
    "    K_ref = refine_grid(Kc_guess, span=0.25, points=81)\n",
    "    Rm = np.zeros_like(K_ref, dtype=np.float64)\n",
    "    R2 = np.zeros_like(K_ref, dtype=np.float64)\n",
    "    R4 = np.zeros_like(K_ref, dtype=np.float64)\n",
    "\n",
    "    # reuse frequencies to keep disorder fixed across seeds\n",
    "    if DIST == \"gaussian\":\n",
    "        omega_np = rng_np.normal(0.0, SIGMA, size=Ni).astype(DTYPE)\n",
    "    else:\n",
    "        omega_np = (rng_np.standard_cauchy(size=Ni).astype(DTYPE)) * SIGMA\n",
    "    omega_xp = xp.asarray(omega_np, dtype=DTYPE)\n",
    "\n",
    "    for si, seed in enumerate(SEEDS):\n",
    "        for i, K in enumerate(K_ref):\n",
    "            m1, m2, m4 = kuramoto_tail_moments(\n",
    "                omega_xp, float(K), dt=DT, steps=STEPS, block=BLOCK, tail_frac=TAIL_FRAC, seed=seed+i\n",
    "            )\n",
    "            Rm[i]  = (Rm[i]*si  + m1) / (si+1)\n",
    "            R2[i]  = (R2[i]*si  + m2) / (si+1)\n",
    "            R4[i]  = (R4[i]*si  + m4) / (si+1)\n",
    "\n",
    "    dR = np.diff(Rm); dK = np.diff(K_ref)\n",
    "    slope = dR / dK\n",
    "    idx_susc = int(np.argmax(slope))\n",
    "    Kc_fine = float(K_ref[min(idx_susc + 1, len(K_ref)-1)])\n",
    "\n",
    "    data[Ni].update({\"K\": K_ref, \"R\": Rm, \"R2\": R2, \"R4\": R4, \"Kc_susc_fine\": Kc_fine})\n",
    "\n",
    "# ----------------------------\n",
    "# 6) Binder-like cumulant and crossings\n",
    "# ----------------------------\n",
    "def binder_U(R2, R4):\n",
    "    # U = 1 - <R^4> / (3 <R^2>^2)\n",
    "    eps = 1e-12\n",
    "    return 1.0 - (R4 / (3.0 * np.maximum(R2*R2, eps)))\n",
    "\n",
    "def interp_crossing(K1, U1, K2, U2):\n",
    "    # find K where U1(K) - U2(K) = 0 via linear interpolation between nearest sign change\n",
    "    D = U1 - U2\n",
    "    s = np.sign(D)\n",
    "    idx = np.where(np.diff(s) != 0)[0]\n",
    "    if len(idx) == 0:\n",
    "        # fallback: nearest approach\n",
    "        j = int(np.argmin(np.abs(D)))\n",
    "        return float(K1[j])\n",
    "    j = int(idx[np.argmin(np.abs(D[idx]))])\n",
    "    x0, x1 = K1[j], K1[j+1]\n",
    "    y0, y1 = D[j], D[j+1]\n",
    "    if (y1 - y0) == 0: return float(x0)\n",
    "    return float(x0 - y0 * (x1 - x0) / (y1 - y0))\n",
    "\n",
    "U_by_N = {}\n",
    "for Ni in Ns:\n",
    "    U_by_N[Ni] = binder_U(data[Ni][\"R2\"], data[Ni][\"R4\"])\n",
    "\n",
    "crossings = []\n",
    "pairs = []\n",
    "for i in range(len(Ns)-1):\n",
    "    N1, N2 = Ns[i], Ns[i+1]\n",
    "    # align on common K grid by interpolation to N2's grid\n",
    "    K2 = data[N2][\"K\"]\n",
    "    U1i = np.interp(K2, data[N1][\"K\"], U_by_N[N1])\n",
    "    U2i = U_by_N[N2]\n",
    "    Kc_pair = interp_crossing(K2, U1i, K2, U2i)\n",
    "    crossings.append((N1, N2, Kc_pair))\n",
    "    pairs.append((N1, N2))\n",
    "\n",
    "# Estimate Kc(∞) via linear fit vs 1/N_mid, where N_mid is harmonic mean of pair\n",
    "N_mid = np.array([2/(1/N1 + 1/N2) for (N1, N2, _) in crossings], dtype=np.float64)\n",
    "Kc_pair_vals = np.array([k for (_,_,k) in crossings], dtype=np.float64)\n",
    "X = 1.0 / N_mid\n",
    "if len(X) >= 2:\n",
    "    a,b = np.polyfit(X, Kc_pair_vals, 1)  # Kc ~ a*(1/N_mid) + b\n",
    "    Kc_infty = float(b)\n",
    "else:\n",
    "    Kc_infty = float(np.mean(Kc_pair_vals)) if len(Kc_pair_vals)>0 else float('nan')\n",
    "\n",
    "# ----------------------------\n",
    "# 7) β fit using shared Kc(∞)\n",
    "# ----------------------------\n",
    "def fit_beta_shared_Kc(Kc_star, rows, r_lo=0.06, r_hi=0.6):\n",
    "    X_ll, Y_ll = [], []\n",
    "    for (N, K, R) in rows:\n",
    "        if K > Kc_star and r_lo <= R <= r_hi:\n",
    "            x = K - Kc_star\n",
    "            if x > 0:\n",
    "                X_ll.append(math.log(x)); Y_ll.append(math.log(R))\n",
    "    X_ll, Y_ll = np.array(X_ll), np.array(Y_ll)\n",
    "    if len(X_ll) >= 2:\n",
    "        m,b = np.polyfit(X_ll, Y_ll, 1)\n",
    "        return float(m), (m,b), X_ll, Y_ll\n",
    "    return float('nan'), (float('nan'), float('nan')), np.array([]), np.array([])\n",
    "\n",
    "rows_all = []\n",
    "for Ni in Ns:\n",
    "    K = data[Ni][\"K\"]; R = data[Ni][\"R\"]\n",
    "    for k, r in zip(K, R):\n",
    "        rows_all.append((Ni, float(k), float(r)))\n",
    "\n",
    "beta_est, (m_fit, b_fit), X_ll, Y_ll = fit_beta_shared_Kc(Kc_infty, rows_all)\n",
    "\n",
    "elapsed_all = time.time() - t_all\n",
    "\n",
    "# ----------------------------\n",
    "# 8) Save CSV + meta + plots\n",
    "# ----------------------------\n",
    "# CSV per N\n",
    "for Ni in Ns:\n",
    "    with open(RUN_DIR / f\"crit_{Ni}.csv\", \"w\") as f:\n",
    "        f.write(\"K,R,R2,R4,U\\n\")\n",
    "        K = data[Ni][\"K\"]; R = data[Ni][\"R\"]; R2 = data[Ni][\"R2\"]; R4 = data[Ni][\"R4\"]\n",
    "        U = binder_U(R2,R4)\n",
    "        for k,r,r2,r4,u in zip(K,R,R2,R4,U):\n",
    "            f.write(f\"{k:.6f},{r:.6f},{r2:.6f},{r4:.6f},{u:.6f}\\n\")\n",
    "\n",
    "meta = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"artifacts_dir\": str(RUN_DIR),\n",
    "    \"env\": {\n",
    "        \"python\": sys.version.split()[0],\n",
    "        \"platform\": platform.platform(),\n",
    "        \"backend\": \"cupy\" if HAS_CP else \"numpy\",\n",
    "        \"dtype\": \"fp32\" if FP32 else \"fp64\",\n",
    "    },\n",
    "    \"model\": {\"dist\": DIST, \"sigma_or_gamma\": SIGMA},\n",
    "    \"integrator\": {\"dt\": DT, \"steps\": STEPS, \"block\": BLOCK, \"tail_frac\": TAIL_FRAC},\n",
    "    \"sizes\": Ns,\n",
    "    \"seeds\": SEEDS,\n",
    "    \"coarse_grid\": {\"K_min\": float(K_MIN), \"K_max\": float(K_MAX), \"steps\": int(K_STEPS_COARSE)},\n",
    "    \"theory\": {\"Kc_theory\": Kc_theory},\n",
    "    \"results\": {\n",
    "        \"Kc_susc_coarse\": {int(N): data[N][\"Kc_susc_coarse\"] for N in Ns},\n",
    "        \"Kc_susc_fine\": {int(N): data[N][\"Kc_susc_fine\"] for N in Ns},\n",
    "        \"binder_crossings\": [{\"N1\": int(N1), \"N2\": int(N2), \"Kc_pair\": float(k)} for (N1,N2,k) in crossings],\n",
    "        \"Kc_infty\": Kc_infty,\n",
    "        \"beta_est\": beta_est,\n",
    "        \"elapsed_sec\": elapsed_all\n",
    "    }\n",
    "}\n",
    "with open(RUN_DIR / \"run_meta.json\", \"w\") as f:\n",
    "    json.dump(meta, f, indent=2)\n",
    "\n",
    "# Plots\n",
    "# (1) R(K) with Kc markers and Kc_infty\n",
    "fig1 = plt.figure(figsize=(8.0, 4.8), dpi=140)\n",
    "for Ni in Ns:\n",
    "    K = data[Ni][\"K\"]; R = data[Ni][\"R\"]\n",
    "    plt.plot(K, R, marker=\"o\", label=f\"N={Ni}\")\n",
    "    plt.axvline(data[Ni][\"Kc_susc_fine\"], linestyle=\":\", label=f\"Kc_susc(N={Ni})≈{data[Ni]['Kc_susc_fine']:.3f}\")\n",
    "plt.axvline(Kc_infty, linestyle=\"--\", label=f\"Kc(∞)≈{Kc_infty:.3f}\")\n",
    "plt.axvline(Kc_theory, linestyle=\"-.\", label=f\"Kc_theory≈{Kc_theory:.3f}\")\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"<R> (tail mean)\")\n",
    "plt.title(\"Kuramoto near-critical (multi-seed, refined)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"crit_R_vs_K.png\"); plt.close(fig1)\n",
    "\n",
    "# (2) Binder U(K) for all N + pairwise crossing Kc(N1,N2)\n",
    "fig2 = plt.figure(figsize=(8.0, 4.6), dpi=140)\n",
    "for Ni in Ns:\n",
    "    K = data[Ni][\"K\"]; U = binder_U(data[Ni][\"R2\"], data[Ni][\"R4\"])\n",
    "    plt.plot(K, U, marker=\".\", label=f\"N={Ni}\")\n",
    "for (N1,N2,kc) in crossings:\n",
    "    plt.axvline(kc, linestyle=\":\", label=f\"Kc({N1},{N2})≈{kc:.3f}\")\n",
    "plt.axvline(Kc_infty, linestyle=\"--\", label=f\"Kc(∞)≈{Kc_infty:.3f}\")\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"Binder-like U\")\n",
    "plt.title(\"Binder crossings and Kc(∞)\")\n",
    "plt.legend(); plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"crit_binder.png\"); plt.close(fig2)\n",
    "\n",
    "# (3) β fit with shared Kc(∞)\n",
    "fig3 = plt.figure(figsize=(6.4, 4.8), dpi=140)\n",
    "if len(X_ll) >= 2:\n",
    "    xg = np.linspace(X_ll.min(), X_ll.max(), 200)\n",
    "    yg = m_fit * xg + b_fit\n",
    "    plt.plot(X_ll, Y_ll, marker=\"o\", linestyle=\"\", label=\"data window\")\n",
    "    plt.plot(xg, yg, label=f\"fit β≈{m_fit:.3f}\")\n",
    "    plt.xlabel(\"log(K - Kc(∞))\"); plt.ylabel(\"log <R>\")\n",
    "    plt.title(\"Critical scaling with shared Kc(∞)\")\n",
    "    plt.legend()\n",
    "else:\n",
    "    plt.text(0.5, 0.5, \"Insufficient points for β fit\", ha=\"center\", va=\"center\")\n",
    "    plt.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(RUN_DIR / \"crit_beta_fit.png\"); plt.close(fig3)\n",
    "\n",
    "print(\"=== CNT Critical Refinement — Completed ===\")\n",
    "print(f\"Artifacts : {RUN_DIR}\")\n",
    "print(f\"Theory Kc : {Kc_theory:.4f}  |  Kc(∞)≈{Kc_infty:.4f}\")\n",
    "for Ni in Ns:\n",
    "    print(f\"N={Ni} : Kc_susc_coarse≈{data[Ni]['Kc_susc_coarse']:.4f}  |  Kc_susc_fine≈{data[Ni]['Kc_susc_fine']:.4f}\")\n",
    "for (N1,N2,kc) in crossings:\n",
    "    print(f\"Crossing(N={N1},{N2}) → Kc≈{kc:.4f}\")\n",
    "print(f\"β (shared Kc) ≈ {beta_est:.3f}\")\n",
    "print(f\"Elapsed (s): {elapsed_all:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02fdebbf-01c8-41e2-968e-ba2ed6b352d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CNT Critical Refinement v2 — nested disorder, fp64, parabolic crossings, robust β ===\n",
    "# Artifacts → E:/CNT/artifacts/cnt_crit_refine_v2/<RUN_ID>/\n",
    "\n",
    "import os, json, math, time, sys, platform, uuid, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- paths ----------\n",
    "CANDIDATES = [Path(\"E:/CNT\"), Path(\"E:\\\\CNT\"), Path(\"./CNT\")]\n",
    "ROOT = next((p for p in CANDIDATES if p.exists()), Path(\".\").resolve())\n",
    "ART = (ROOT / \"artifacts\").resolve()\n",
    "RUN_ID = dt.datetime.now(dt.timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\") + \"-\" + uuid.uuid4().hex[:6]\n",
    "RUN_DIR = (ART / f\"cnt_crit_refine_v2/{RUN_ID}\")\n",
    "RUN_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- backend ----------\n",
    "try:\n",
    "    import cupy as cp\n",
    "    _ = cp.zeros((1,))\n",
    "    xp, HAS_CP = cp, True\n",
    "except Exception:\n",
    "    xp, HAS_CP = np, False\n",
    "\n",
    "DTYPE = np.float64   # fp64 for stable moments\n",
    "def to_np(a): return cp.asnumpy(a) if HAS_CP else a\n",
    "\n",
    "# ---------- integrator: tail moments ----------\n",
    "def kuramoto_tail_moments(omega_xp, K, *, dt=0.01, steps=12000, block=10, tail_frac=0.6, seed=0):\n",
    "    rs = xp.random.RandomState(seed) if not HAS_CP else xp.random.RandomState(seed)\n",
    "    N = omega_xp.shape[0]\n",
    "    theta = (2 * xp.pi) * rs.rand(N, dtype=DTYPE)\n",
    "    steps = int(steps); block = max(1, int(block))\n",
    "    outer = (steps + block - 1) // block\n",
    "    t, tail_start = 0, int((1.0 - tail_frac) * steps)\n",
    "    s1=s2=s4=0.0; cnt=0\n",
    "    for _ in range(outer):\n",
    "        b = min(block, steps - t)\n",
    "        for _ in range(b):\n",
    "            z_mean = xp.exp(1j*theta).mean()\n",
    "            if t >= tail_start:\n",
    "                R = float(abs(z_mean))\n",
    "                s1 += R; s2 += R*R; s4 += (R*R)*(R*R); cnt += 1\n",
    "            coupling = xp.imag(z_mean * xp.exp(-1j*theta))\n",
    "            theta = theta + dt*(omega_xp + K*coupling)\n",
    "            if (t & 255) == 0:\n",
    "                theta = xp.mod(theta, 2*xp.pi)\n",
    "            t += 1\n",
    "        if HAS_CP: cp.cuda.Stream.null.synchronize()\n",
    "    if cnt == 0: return 0.0,0.0,0.0\n",
    "    m1 = s1/cnt; m2 = s2/cnt; m4 = s4/cnt\n",
    "    return m1, m2, m4\n",
    "\n",
    "# ---------- spec ----------\n",
    "SIGMA = 1.0\n",
    "DIST  = \"gaussian\"  # or 'lorentz'\n",
    "Ns_try = [512, 1024, 2048, 4096]     # will auto-drop 4096 if OOM\n",
    "SEEDS = [101,202,303,404,505,606,707]  # 7 seeds\n",
    "DT = 0.01; STEPS = 12000; BLOCK = 10; TAIL_FRAC = 0.6\n",
    "\n",
    "# theory\n",
    "if DIST==\"gaussian\":\n",
    "    Kc_theory = 2.0 * SIGMA * math.sqrt(2.0*math.pi) / math.pi   # ≈1.59577\n",
    "else:\n",
    "    Kc_theory = 2.0 * SIGMA\n",
    "\n",
    "# grids\n",
    "K_MIN, K_MAX = 1.1, 2.1\n",
    "K_FINE = np.linspace(K_MIN, K_MAX, 241)  # dense common grid for all Ns\n",
    "\n",
    "# ---------- master disorder (nested) ----------\n",
    "N_max = max(Ns_try)\n",
    "rng = np.random.default_rng(42)\n",
    "if DIST==\"gaussian\":\n",
    "    omega_master = rng.normal(0.0, SIGMA, size=N_max).astype(DTYPE)\n",
    "else:\n",
    "    omega_master = (rng.standard_cauchy(size=N_max).astype(DTYPE))*SIGMA\n",
    "\n",
    "# safely downselect Ns based on memory\n",
    "Ns = []\n",
    "for N in Ns_try:\n",
    "    try:\n",
    "        w = xp.asarray(omega_master[:N], dtype=DTYPE)\n",
    "        _ = w.sum()  # touch\n",
    "        Ns.append(N)\n",
    "    except Exception:\n",
    "        pass\n",
    "assert len(Ns)>0, \"No N fits GPU/CPU memory.\"\n",
    "\n",
    "# ---------- runs ----------\n",
    "def binder_U(R2, R4):\n",
    "    eps = 1e-12\n",
    "    return 1.0 - (R4 / (3.0*np.maximum(R2*R2, eps)))\n",
    "\n",
    "def multi_seed_curve(omega_xp, Ks, seeds):\n",
    "    Rm = np.zeros_like(Ks, dtype=np.float64)\n",
    "    R2 = np.zeros_like(Ks, dtype=np.float64)\n",
    "    R4 = np.zeros_like(Ks, dtype=np.float64)\n",
    "    for si, sd in enumerate(seeds):\n",
    "        for i, K in enumerate(Ks):\n",
    "            m1,m2,m4 = kuramoto_tail_moments(omega_xp, float(K),\n",
    "                                             dt=DT, steps=STEPS, block=BLOCK, tail_frac=TAIL_FRAC, seed=sd+i)\n",
    "            Rm[i] = (Rm[i]*si + m1)/(si+1)\n",
    "            R2[i] = (R2[i]*si + m2)/(si+1)\n",
    "            R4[i] = (R4[i]*si + m4)/(si+1)\n",
    "    return Rm, R2, R4\n",
    "\n",
    "data = {}\n",
    "t0 = time.time()\n",
    "for N in Ns:\n",
    "    omega_xp = xp.asarray(omega_master[:N], dtype=DTYPE)\n",
    "    Rm,R2,R4 = multi_seed_curve(omega_xp, K_FINE, SEEDS)\n",
    "    dR = np.diff(Rm)/np.diff(K_FINE)\n",
    "    k_susc = float(K_FINE[np.argmax(dR)+1])\n",
    "    data[N] = {\"K\":K_FINE.copy(), \"R\":Rm, \"R2\":R2, \"R4\":R4, \"Kc_susc\":k_susc}\n",
    "elapsed_sim = time.time()-t0\n",
    "\n",
    "# ---------- parabolic crossing refinement ----------\n",
    "def parabolic_crossing(K, U1, U2, window=5):\n",
    "    D = U1 - U2\n",
    "    j0 = int(np.argmin(np.abs(D)))                 # nearest approach\n",
    "    j_lo = max(0, j0-window); j_hi = min(len(K), j0+window+1)\n",
    "    x = K[j_lo:j_hi]; y = D[j_lo:j_hi]\n",
    "    if len(x) < 3:\n",
    "        return float(K[j0])\n",
    "    # fit y ≈ a x^2 + b x + c, root of quadratic closest to x[j0]\n",
    "    A = np.vstack([x*x, x, np.ones_like(x)]).T\n",
    "    try:\n",
    "        a,b,c = np.linalg.lstsq(A, y, rcond=None)[0]\n",
    "        disc = b*b - 4*a*c\n",
    "        if a==0 or disc<0:\n",
    "            return float(K[j0])\n",
    "        r1 = (-b - math.sqrt(disc))/(2*a)\n",
    "        r2 = (-b + math.sqrt(disc))/(2*a)\n",
    "        # choose root within [x.min,x.max] closest to x[j0]\n",
    "        candidates = [r for r in (r1,r2) if x.min()-1e-9 <= r <= x.max()+1e-9]\n",
    "        return float(min(candidates, key=lambda r: abs(r - K[j0]))) if candidates else float(K[j0])\n",
    "    except Exception:\n",
    "        return float(K[j0])\n",
    "\n",
    "U = {N: binder_U(data[N][\"R2\"], data[N][\"R4\"]) for N in Ns}\n",
    "\n",
    "pairs, Kc_pairs = [], []\n",
    "for i in range(len(Ns)-1):\n",
    "    N1,N2 = Ns[i], Ns[i+1]\n",
    "    # already on common grid; refine parabolically\n",
    "    kc = parabolic_crossing(data[N1][\"K\"], U[N1], U[N2], window=6)\n",
    "    pairs.append((N1,N2)); Kc_pairs.append(kc)\n",
    "\n",
    "# extrapolate Kc(∞): linear vs 1/N_mid (harmonic mean)\n",
    "N_mid = np.array([2/(1/p[0] + 1/p[1]) for p in pairs], dtype=np.float64)\n",
    "X = 1.0/N_mid; Y = np.array(Kc_pairs, dtype=np.float64)\n",
    "if len(X)>=2:\n",
    "    a,b = np.polyfit(X, Y, 1)\n",
    "    Kc_inf = float(b)\n",
    "else:\n",
    "    Kc_inf = float(Y.mean()) if len(Y) else float('nan')\n",
    "\n",
    "# ---------- β fit using shared Kc(∞) ----------\n",
    "def fit_beta_shared(Kc_star, rows, x_lo=0.03, x_hi=0.35, r_lo=0.03, r_hi=0.8):\n",
    "    Xl,Yl=[],[]\n",
    "    for (K,R) in rows:\n",
    "        x = K - Kc_star\n",
    "        if x>=x_lo and x<=x_hi and r_lo<=R<=r_hi:\n",
    "            Xl.append(math.log(x)); Yl.append(math.log(R))\n",
    "    if len(Xl)>=3:\n",
    "        m,b = np.polyfit(np.array(Xl), np.array(Yl), 1)\n",
    "        return float(m), (m,b), np.array(Xl), np.array(Yl)\n",
    "    return float('nan'), (float('nan'), float('nan')), np.array([]), np.array([])\n",
    "\n",
    "rows_all = []\n",
    "for N in Ns:\n",
    "    K = data[N][\"K\"]; R = data[N][\"R\"]\n",
    "    rows_all += list(zip(K,R))\n",
    "beta_est, (m_fit, b_fit), Xll, Yll = fit_beta_shared(Kc_inf, rows_all)\n",
    "\n",
    "# ---------- save ----------\n",
    "# CSV per N\n",
    "for N in Ns:\n",
    "    K = data[N][\"K\"]; R = data[N][\"R\"]; R2=data[N][\"R2\"]; R4=data[N][\"R4\"]; UU = U[N]\n",
    "    with open(RUN_DIR / f\"crit_N{N}.csv\",\"w\") as f:\n",
    "        f.write(\"K,R,R2,R4,U\\n\")\n",
    "        for k,r,r2,r4,u in zip(K,R,R2,R4,UU):\n",
    "            f.write(f\"{k:.6f},{r:.6f},{r2:.6f},{r4:.6f},{u:.6f}\\n\")\n",
    "\n",
    "meta = {\n",
    "  \"run_id\": RUN_ID,\n",
    "  \"env\": {\"backend\":\"cupy\" if HAS_CP else \"numpy\", \"dtype\":\"fp64\"},\n",
    "  \"model\":{\"dist\":DIST,\"sigma_or_gamma\":SIGMA},\n",
    "  \"integrator\":{\"dt\":DT,\"steps\":STEPS,\"block\":BLOCK,\"tail_frac\":TAIL_FRAC},\n",
    "  \"sizes\": Ns,\n",
    "  \"seeds\": SEEDS,\n",
    "  \"theory\":{\"Kc_theory\":Kc_theory},\n",
    "  \"results\":{\n",
    "    \"Kc_susc\": {int(N): float(data[N][\"Kc_susc\"]) for N in Ns},\n",
    "    \"binder_pairs\": [{\"N1\":int(a),\"N2\":int(b),\"Kc_pair\":float(k)} for (a,b),k in zip(pairs,Kc_pairs)],\n",
    "    \"Kc_infty\": float(Kc_inf),\n",
    "    \"beta\": float(beta_est),\n",
    "    \"elapsed_sim_sec\": elapsed_sim\n",
    "  }\n",
    "}\n",
    "with open(RUN_DIR/\"run_meta.json\",\"w\") as f: json.dump(meta,f,indent=2)\n",
    "\n",
    "# ---------- plots ----------\n",
    "# R(K)\n",
    "fig1 = plt.figure(figsize=(8,4.8), dpi=140)\n",
    "for N in Ns:\n",
    "    plt.plot(data[N][\"K\"], data[N][\"R\"], marker=\"o\", label=f\"N={N}\")\n",
    "    plt.axvline(data[N][\"Kc_susc\"], linestyle=\":\", label=f\"Kc_susc(N={N})≈{data[N]['Kc_susc']:.3f}\")\n",
    "plt.axvline(Kc_inf, linestyle=\"--\", label=f\"Kc(∞)≈{Kc_inf:.3f}\")\n",
    "plt.axvline(Kc_theory, linestyle=\"-.\", label=f\"Kc_theory≈{Kc_theory:.3f}\")\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"<R> (tail mean)\"); plt.title(\"Kuramoto near-critical (nested disorder, fp64)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(RUN_DIR/\"crit_R_vs_K.png\"); plt.close(fig1)\n",
    "\n",
    "# Binder U(K)\n",
    "fig2 = plt.figure(figsize=(8,4.6), dpi=140)\n",
    "for N in Ns:\n",
    "    plt.plot(data[N][\"K\"], U[N], marker=\".\", label=f\"N={N}\")\n",
    "for kc in Kc_pairs:\n",
    "    plt.axvline(kc, linestyle=\":\", label=f\"Kc(pair)≈{kc:.3f}\")\n",
    "plt.axvline(Kc_inf, linestyle=\"--\", label=f\"Kc(∞)≈{Kc_inf:.3f}\")\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"Binder-like U\"); plt.title(\"Binder crossings (parabolic)\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(RUN_DIR/\"crit_binder.png\"); plt.close(fig2)\n",
    "\n",
    "# β fit\n",
    "fig3 = plt.figure(figsize=(6.2,4.6), dpi=140)\n",
    "if len(Xll)>=3:\n",
    "    xr = np.linspace(Xll.min(), Xll.max(), 200); yr = m_fit*xr + b_fit\n",
    "    plt.plot(Xll, Yll, marker=\"o\", linestyle=\"\", label=\"windowed data\")\n",
    "    plt.plot(xr, yr, label=f\"fit β≈{m_fit:.3f}\")\n",
    "    plt.xlabel(\"log(K - Kc(∞))\"); plt.ylabel(\"log <R>\"); plt.title(\"Critical scaling (shared Kc)\")\n",
    "    plt.legend()\n",
    "else:\n",
    "    plt.text(0.5,0.5,\"Insufficient points for β fit\",ha=\"center\",va=\"center\"); plt.axis(\"off\")\n",
    "plt.tight_layout(); plt.savefig(RUN_DIR/\"crit_beta_fit.png\"); plt.close(fig3)\n",
    "\n",
    "print(\"=== CNT Critical Refinement v2 — Completed ===\")\n",
    "print(f\"Artifacts : {RUN_DIR}\")\n",
    "print(f\"Theory Kc : {Kc_theory:.4f} | Kc(∞)≈{Kc_inf:.4f}\")\n",
    "for N in Ns:\n",
    "    print(f\"N={N} : Kc_susc≈{data[N]['Kc_susc']:.4f}\")\n",
    "for (a,b),kc in zip(pairs,Kc_pairs):\n",
    "    print(f\"Crossing(N={a},{b}) → Kc≈{kc:.4f}\")\n",
    "print(f\"β (shared Kc) ≈ {beta_est:.3f}\")\n",
    "print(f\"Sim elapsed (s): {elapsed_sim:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f87ca9-3abe-4244-b006-0fb08e8fa890",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
