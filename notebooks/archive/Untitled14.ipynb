{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae7466ad-bb5d-4d6d-bdda-43dbcf60fdaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CNT False-Positive Audit ==\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_fpr_audit_20251016-102546.csv\n"
     ]
    }
   ],
   "source": [
    "# CNT False-Positive Audit — single cell\n",
    "import os, re, glob, json, math, random\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from scipy import stats\n",
    "\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "out_dir = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def _bh_fdr(pvals, alpha=0.05):\n",
    "    p = np.asarray(pvals, float)\n",
    "    p[np.isnan(p)] = 1.0\n",
    "    rej, p_corr, _, _ = multipletests(p, alpha=alpha, method=\"fdr_bh\")\n",
    "    return rej, p_corr\n",
    "\n",
    "audits = []\n",
    "\n",
    "# === EEG example: laterality tables with p-values ===\n",
    "for f in glob.glob(rf\"{ROOTS[0]}\\artifacts\\pli_humans_*\\**\\tables\\lap_erd_subject*.csv\", recursive=True):\n",
    "    df = pd.read_csv(f)\n",
    "    # Heuristic: grab any columns named like p, pval, p_value\n",
    "    pcols = [c for c in df.columns if re.fullmatch(r\"p(_?value)?\", c, flags=re.I)]\n",
    "    if not pcols: \n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcols[0]], errors=\"coerce\")\n",
    "    # Positive rule: p < 0.01 after BH\n",
    "    rej, p_corr = _bh_fdr(p, alpha=0.01)\n",
    "    # Null via permutation: shuffle p among rows (proxy if raw data not present)\n",
    "    # Count how often shuffled BH finds a \"discovery\"\n",
    "    B = 2000\n",
    "    fp = 0\n",
    "    for _ in range(B):\n",
    "        ps = rng.permutation(p.values)\n",
    "        rnull, _ = _bh_fdr(ps, alpha=0.01)\n",
    "        if rnull.any(): \n",
    "            fp += 1\n",
    "    fpr = fp / B\n",
    "    audits.append(dict(module=\"EEG\", file=f, positives=int(rej.sum()), tests=len(p), FPR=fpr))\n",
    "\n",
    "# === Cooling example: call positive if ΔT <= -0.5°C with significance ===\n",
    "for f in glob.glob(rf\"{ROOTS[0]}\\notebooks\\archive\\cnt_*cooling*.csv\", recursive=True):\n",
    "    df = pd.read_csv(f)\n",
    "    # Expect columns like 'temp', 'phase' or 'mode'; adapt if needed\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not {\"temp\"}.issubset(set(cols)): \n",
    "        continue\n",
    "    temp = pd.to_numeric(df[cols[\"temp\"]], errors=\"coerce\").dropna()\n",
    "    # Dumb segmented windows (first 1/2 baseline, last 1/2 step) if no labels\n",
    "    n = len(temp)\n",
    "    if n < 40: \n",
    "        continue\n",
    "    base = temp.iloc[:n//2].values\n",
    "    step = temp.iloc[n//2:].values\n",
    "    dT = step.mean() - base.mean()\n",
    "    # AR(1)-robust SE via block bootstrap\n",
    "    B = 1000\n",
    "    blk = max(5, n//20)\n",
    "    bs = []\n",
    "    for _ in range(B):\n",
    "        idxb = np.concatenate([rng.integers(0, len(base)-blk, 1)[0] + np.arange(blk) for __ in range(max(2, len(base)//blk))])\n",
    "        idxs = np.concatenate([rng.integers(0, len(step)-blk, 1)[0] + np.arange(blk) for __ in range(max(2, len(step)//blk))])\n",
    "        bs.append(step[idxs[:len(step)]].mean() - base[idxb[:len(base)]].mean())\n",
    "    se = np.std(bs, ddof=1)\n",
    "    z = dT / (se + 1e-9)\n",
    "    positive = (dT <= -0.5) and (z <= -2.58)  # ~p<0.01, one-sided\n",
    "    # Null: scramble order, recompute positive freq\n",
    "    fp = 0; Bn=1000\n",
    "    for _ in range(Bn):\n",
    "        perm = rng.permutation(temp.values)\n",
    "        baseN, stepN = perm[:n//2], perm[n//2:]\n",
    "        dTN = stepN.mean() - baseN.mean()\n",
    "        # reuse se estimate as conservative\n",
    "        zN = dTN / (se + 1e-9)\n",
    "        if (dTN <= -0.5) and (zN <= -2.58):\n",
    "            fp += 1\n",
    "    fpr = fp / Bn\n",
    "    audits.append(dict(module=\"Cooling\", file=f, positives=int(positive), tests=1, FPR=fpr, dT=float(dT), z=float(z)))\n",
    "\n",
    "# === Forecast alerts (gate k, τ) example: needs a run CSV with columns ['alert','verified'] ===\n",
    "for f in glob.glob(rf\"{ROOTS[0]}\\artifacts\\metrics\\forecast_alerts_*.csv\", recursive=True):\n",
    "    df = pd.read_csv(f)\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns): \n",
    "        continue\n",
    "    tp = ((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum()\n",
    "    fp = ((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum()\n",
    "    tn = ((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum()\n",
    "    fn = ((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum()\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=int(tp), FP=int(fp), TN=int(tn), FN=int(fn), FPR=fpr))\n",
    "\n",
    "# === GRA invariance (policy_fix_stem) example: interpret 'truth_pass' vs 'restored' ===\n",
    "for f in glob.glob(rf\"{ROOTS[1]}\\**\\policy_fix_stem_results.csv\", recursive=True):\n",
    "    df = pd.read_csv(f)\n",
    "    # Heuristic: call \"positive\" when restored is True; ground truth = truth_pass\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)): \n",
    "        continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=fpr))\n",
    "\n",
    "audit_df = pd.DataFrame(audits)\n",
    "out_path = out_dir / f\"cnt_fpr_audit_{pd.Timestamp.now():%Y%m%d-%H%M%S}.csv\"\n",
    "audit_df.to_csv(out_path, index=False)\n",
    "print(\"== CNT False-Positive Audit ==\")\n",
    "print(audit_df.fillna(\"\").to_string(index=False))\n",
    "print(\"\\nSaved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1215aaf0-e922-42b4-902e-ccd9e4029b5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 9 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv\n",
      "   ... +3 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv — too few rows (9)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv — too few rows (4)\n",
      "\n",
      "== CNT False-Positive Audit ==\n",
      " module                                                                                                                      file  positives  tests  FPR         dT        z  TP  FP  TN  FN\n",
      "    EEG C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv       50.0   50.0  1.0        NaN      NaN NaN NaN NaN NaN\n",
      "Cooling                                              C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv        0.0    1.0  0.0  69.535874 2.826378 NaN NaN NaN NaN\n",
      "Cooling                                              C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv        0.0    1.0  0.0  75.235582 2.811953 NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv        0.0    1.0  0.0  75.061954 2.625644 NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv        0.0    1.0  0.0  45.091580 2.684712 NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv        0.0    1.0  0.0 121.888013 2.541494 NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv        0.0    1.0  0.0 146.156157 2.668000 NaN NaN NaN NaN\n",
      "Cooling                                       C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv        0.0    1.0  0.0 126.122966 2.640550 NaN NaN NaN NaN\n",
      "    GRA    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv        NaN    NaN  0.0        NaN      NaN 2.0 0.0 0.0 0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_fpr_audit_20251016-103419.csv\n"
     ]
    }
   ],
   "source": [
    "# === CNT False-Positive Audit (robust, self-debugging) ===\n",
    "import os, re, glob, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "\n",
    "# 1) Configure likely roots; add/remove if yours differ\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "\n",
    "np.random.seed(42)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "def _bh_fdr(pvals, alpha=0.05):\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    p[np.isnan(p)] = 1.0\n",
    "    rej, p_corr, _, _ = multipletests(p, alpha=alpha, method=\"fdr_bh\")\n",
    "    return rej, p_corr\n",
    "\n",
    "def ls(pattern):\n",
    "    files = glob.glob(pattern, recursive=True)\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]:\n",
    "        print(\" •\", f)\n",
    "    if len(files) > limit:\n",
    "        print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "# 2) Discover files (broader patterns)\n",
    "EEG_FILES = []\n",
    "COOL_FILES = []\n",
    "FORECAST_FILES = []\n",
    "GRA_FILES = []\n",
    "\n",
    "for root in ROOTS:\n",
    "    # EEG laterality tables\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    # Cooling logs (archive or artifacts)\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "    # Forecast alerts (we’ll expect columns ['alert','verified'])\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    # GRA invariance runs\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "\n",
    "# 3) EEG: p-value columns under BH@0.01 + permutation null for FPR\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    # Accept common p-value headers\n",
    "    cand = [c for c in df.columns if re.fullmatch(r\"p(_?val(ue)?)?|pval|p_value\", c, flags=re.I)]\n",
    "    if not cand:\n",
    "        # Try to sniff any column with values (0,1) or in (0,0.2)\n",
    "        cand = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c]) and df[c].dropna().between(0,1).mean()>0.8]\n",
    "    if not cand:\n",
    "        print(f\"[EEG:skip] {f} — no p-value-like column found\")\n",
    "        continue\n",
    "    pcol = cand[0]\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\")\n",
    "    rej, _ = _bh_fdr(p, alpha=0.01)\n",
    "    # Permutation null on p’s as proxy (conservative without raw)\n",
    "    B = 2000; fp = 0\n",
    "    for _ in range(B):\n",
    "        rnull, _ = _bh_fdr(np.random.permutation(p.values), alpha=0.01)\n",
    "        if rnull.any():\n",
    "            fp += 1\n",
    "    fpr = fp / B\n",
    "    audits.append(dict(module=\"EEG\", file=f, positives=int(np.sum(rej)), tests=int(len(p)), FPR=float(fpr)))\n",
    "\n",
    "# 4) Cooling: ΔT and significance via simple split + permutation null\n",
    "def ar1_block_se(xa, xb, rng, B=800):\n",
    "    na, nb = len(xa), len(xb)\n",
    "    blk_a = max(5, na//20); blk_b = max(5, nb//20)\n",
    "    bs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, max(1, na-blk_a), 1)[0]; ib = rng.integers(0, max(1, nb-blk_b), 1)[0]\n",
    "        ra = xa[ia:ia+blk_a]; rb = xb[ib:ib+blk_b]\n",
    "        bs.append(np.mean(rb) - np.mean(ra))\n",
    "    return np.std(bs, ddof=1)\n",
    "\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    # Accept temp-like names\n",
    "    tcol = next((cols[k] for k in cols if k in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\") ), None)\n",
    "    if tcol is None:\n",
    "        # fallback: first numeric column with reasonable range\n",
    "        ncand = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "        if ncand:\n",
    "            tcol = ncand[0]\n",
    "    if tcol is None:\n",
    "        print(f\"[Cooling:skip] {f} — no temperature column\")\n",
    "        continue\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\").dropna().values\n",
    "    n = len(temp)\n",
    "    if n < 60:\n",
    "        print(f\"[Cooling:skip] {f} — too few rows ({n})\")\n",
    "        continue\n",
    "    base, step = temp[:n//2], temp[n//2:]\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "    se = ar1_block_se(base, step, rng, B=800)\n",
    "    z = dT / (se + 1e-9)\n",
    "    positive = (dT <= -0.5) and (z <= -2.58)  # ~p<0.01 one-sided cooling\n",
    "    # Permutation null\n",
    "    Bn = 1000; fp = 0\n",
    "    for _ in range(Bn):\n",
    "        perm = rng.permutation(temp)\n",
    "        bN, sN = perm[:n//2], perm[n//2:]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / (se + 1e-9)\n",
    "        if (dTN <= -0.5) and (zN <= -2.58):\n",
    "            fp += 1\n",
    "    fpr = fp / Bn\n",
    "    audits.append(dict(module=\"Cooling\", file=f, positives=int(positive), tests=1, FPR=float(fpr), dT=dT, z=float(z)))\n",
    "\n",
    "# 5) Forecast: explicit FPR from alert/verify labels\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs columns ['alert','verified']\")\n",
    "        continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=float(fpr)))\n",
    "\n",
    "# 6) GRA invariance: restored vs truth_pass\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs columns like 'restored' & 'truth_pass'\")\n",
    "        continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=float(fpr)))\n",
    "\n",
    "# 7) Save & print summary\n",
    "out_dir = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "audit_df = pd.DataFrame(audits)\n",
    "out_path = out_dir / f\"cnt_fpr_audit_{pd.Timestamp.now():%Y%m%d-%H%M%S}.csv\"\n",
    "\n",
    "if audit_df.empty:\n",
    "    print(\"\\n== No eligible files found to audit ==\")\n",
    "    print(\"Tips:\")\n",
    "    print(\" • EEG tables → place under CNT_Lab\\\\artifacts\\\\pli_humans_*\\\\...\\\\tables\\\\ with a p-value column (e.g., p, p_value).\")\n",
    "    print(\" • Cooling logs → CSV with a temperature column (temp/temperature) under CNT_Lab\\\\notebooks\\\\archive\\\\ or artifacts.\")\n",
    "    print(\" • Forecast alerts → CSV with columns [alert, verified] under CNT_Lab\\\\artifacts\\\\metrics\\\\forecast_alerts_*.csv\")\n",
    "    print(\" • GRA → policy_fix_stem_results.csv with columns restored, truth_pass (as booleans).\")\n",
    "else:\n",
    "    audit_df.to_csv(out_path, index=False)\n",
    "    print(\"\\n== CNT False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "85578203-e533-40b6-853e-488e90f11a8e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[EEG:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv — no p-value column\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 75\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m     74\u001b[39m res = phase_split(df)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mres\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[32m     76\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[Cooling:skip] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m — no usable temp/phase; need labels\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# === EEG (no bogus FPR; report BH discoveries + Storey π0 and FDR) ===\n",
    "from math import ceil\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    p = np.asarray(p, float)\n",
    "    p = p[~np.isnan(p)]\n",
    "    if p.size == 0: \n",
    "        return np.nan\n",
    "    return min(1.0, max(0.0, np.mean(p >= lam) / (1 - lam)))\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    cand = [c for c in df.columns if re.fullmatch(r\"p(_?val(ue)?)?|pval|p_value\", c, flags=re.I)]\n",
    "    if not cand:\n",
    "        print(f\"[EEG:skip] {f} — no p-value column\")\n",
    "        continue\n",
    "    pcol = cand[0]\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\")\n",
    "    rej, q = multipletests(p.fillna(1.0), alpha=0.01, method=\"fdr_bh\")[:2]\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)),\n",
    "        tests=int(p.shape[0]),\n",
    "        FPR=np.nan,              # cannot estimate without proper null labels/raw\n",
    "        pi0=float(pi0),          # estimate of proportion true nulls\n",
    "        FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# === Cooling (use labeled phases if present; else fall back) ===\n",
    "def phase_split(df):\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    tcol = next((cols[k] for k in cols if k in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\")), None)\n",
    "    if tcol is None:\n",
    "        ncols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "        tcol = ncols[0] if ncols else None\n",
    "    if tcol is None:\n",
    "        return None, None, None\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\").dropna().values\n",
    "    # Prefer explicit phase labels\n",
    "    pcol = next((cols[k] for k in cols if k in (\"phase\",\"is_step\",\"label\")), None)\n",
    "    if pcol is not None:\n",
    "        lab = df[pcol].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab == \"step\") | (lab == \"cool\") | (lab == \"1\") | (lab == \"true\")\n",
    "        base = temp[~step_idx]; step = temp[step_idx]\n",
    "        if len(base) >= 20 and len(step) >= 20:\n",
    "            return base, step, True\n",
    "    # Fallback: split by time (less reliable)\n",
    "    n = len(temp); \n",
    "    if n < 60:\n",
    "        return None, None, None\n",
    "    return temp[:n//2], temp[n//2:], False\n",
    "\n",
    "def ar1_block_se(xa, xb, rng, B=800):\n",
    "    na, nb = len(xa), len(xb)\n",
    "    blk_a, blk_b = max(5, na//20), max(5, nb//20)\n",
    "    bs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, max(1, na-blk_a)); ib = rng.integers(0, max(1, nb-blk_b))\n",
    "        ra = xa[ia:ia+blk_a]; rb = xb[ib:ib+blk_b]\n",
    "        bs.append(np.mean(rb) - np.mean(ra))\n",
    "    return np.std(bs, ddof=1)\n",
    "\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    res = phase_split(df)\n",
    "    if res == (None, None, None):\n",
    "        print(f\"[Cooling:skip] {f} — no usable temp/phase; need labels\")\n",
    "        continue\n",
    "    base, step, labeled = res\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "    se = ar1_block_se(base, step, rng, B=800)\n",
    "    z = dT / (se + 1e-9)\n",
    "    positive = (dT <= -0.5) and (z <= -2.58)  # one-sided p~0.01\n",
    "    # Null: within-run phase label shuffles if labeled, else time-permutation fallback\n",
    "    Bn = 1000; fp = 0\n",
    "    if labeled:\n",
    "        # shuffle phase labels while preserving counts\n",
    "        n = len(base) + len(step); k = len(step)\n",
    "        allv = np.concatenate([base, step])\n",
    "        for _ in range(Bn):\n",
    "            idx = rng.permutation(n)\n",
    "            sN = allv[idx[:k]]; bN = allv[idx[k:]]\n",
    "            dTN = float(np.mean(sN) - np.mean(bN))\n",
    "            zN = dTN / (se + 1e-9)\n",
    "            if (dTN <= -0.5) and (zN <= -2.58):\n",
    "                fp += 1\n",
    "    else:\n",
    "        temp = np.concatenate([base, step])\n",
    "        for _ in range(Bn):\n",
    "            perm = rng.permutation(temp)\n",
    "            bN, sN = perm[:len(base)], perm[len(base):]\n",
    "            dTN = float(np.mean(sN) - np.mean(bN))\n",
    "            zN = dTN / (se + 1e-9)\n",
    "            if (dTN <= -0.5) and (zN <= -2.58):\n",
    "                fp += 1\n",
    "    fpr = fp / Bn\n",
    "    audits.append(dict(module=\"Cooling\", file=f, positives=int(positive), tests=1, FPR=float(fpr), dT=dT, z=float(z)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55e4b380-35c8-4239-a3ea-bd00434f97f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 9 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv\n",
      "   ... +3 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv — no usable temp/phase; add a 'phase' column (baseline/step).\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv — no usable temp/phase; add a 'phase' column (baseline/step).\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv — insufficient data to estimate SE.\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv — insufficient data to estimate SE.\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv — no usable temp/phase; add a 'phase' column (baseline/step).\n",
      "\n",
      "== CNT False-Positive Audit ==\n",
      " module                                                                                                                      file  positives  tests  FPR  pi0  FDR_alpha_0p01        dT         z labeled  TP  FP  TN  FN\n",
      "    EEG C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv       50.0   50.0  NaN  0.0             1.0       NaN       NaN     NaN NaN NaN NaN NaN\n",
      "Cooling                                              C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv        0.0    1.0  0.0  NaN             NaN -0.511111 -1.062551   False NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv        0.0    1.0  0.0  NaN             NaN  0.301282  0.750087   False NaN NaN NaN NaN\n",
      "Cooling                                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv        0.0    1.0  0.0  NaN             NaN  0.882512  1.745517   False NaN NaN NaN NaN\n",
      "Cooling                                       C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv        0.0    1.0  0.0  NaN             NaN  0.374538  0.676373   False NaN NaN NaN NaN\n",
      "    GRA    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv        NaN    NaN  0.0  NaN             NaN       NaN       NaN     NaN 2.0 0.0 0.0 0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_fpr_audit_20251016-104407.csv\n"
     ]
    }
   ],
   "source": [
    "# == CNT False-Positive Audit — Single Cell ==\n",
    "# Finds EEG, Cooling, GRA, and Forecast files; computes FPR where possible.\n",
    "# EEG: reports discoveries + Storey π0 + FDR; FPR requires explicit nulls/labels.\n",
    "# Cooling: uses phase labels if present; otherwise warns (fallback split is conservative).\n",
    "# GRA/Forecast: compute FPR if both positives and true negatives exist.\n",
    "# Output: a CSV in CNT_Lab\\artifacts\\metrics\\cnt_fpr_audit_YYYYMMDD-HHMMSS.csv\n",
    "\n",
    "import os, re, glob, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------- Config ----------\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",            # edit/add if needed\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "\n",
    "np.random.seed(42)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------- Small utilities ----------\n",
    "def ls(pattern):\n",
    "    try:\n",
    "        files = glob.glob(pattern, recursive=True)\n",
    "    except Exception:\n",
    "        files = []\n",
    "    return [f for f in files if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]:\n",
    "        print(\" •\", f)\n",
    "    if len(files) > limit:\n",
    "        print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "def benjamini_hochberg(pvals, alpha=0.05):\n",
    "    \"\"\"BH q-values + reject mask (no statsmodels dependency).\"\"\"\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.empty_like(order)\n",
    "    ranks[order] = np.arange(1, n+1)\n",
    "    q = p * n / np.maximum(ranks, 1)\n",
    "    # enforce monotonicity\n",
    "    q_sorted = np.minimum.accumulate(q[order][::-1])[::-1]\n",
    "    qvalues = np.empty_like(q_sorted)\n",
    "    qvalues[order] = q_sorted\n",
    "    rej = qvalues <= alpha\n",
    "    return rej, qvalues\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    p = np.asarray(pd.Series(p).astype(float))\n",
    "    p = p[np.isfinite(p)]\n",
    "    if p.size == 0:\n",
    "        return np.nan\n",
    "    return float(min(1.0, max(0.0, np.mean(p >= lam)/(1-lam))))\n",
    "\n",
    "# ---------- Discover files ----------\n",
    "EEG_FILES, COOL_FILES, FORECAST_FILES, GRA_FILES = [], [], [], []\n",
    "for root in ROOTS:\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "\n",
    "# ---------- EEG (discover p-like column; report FDR/π0; FPR needs null labels) ----------\n",
    "EEG_NAME_HINTS = (\n",
    "    r\"^p(_?val(ue)?)?$\",         # p, pval, p_value\n",
    "    r\"^p_[a-z]+$\",               # p_alpha, p_beta, p_theta, ...\n",
    "    r\"^[a-z]*_?p(_?val(ue)?)?$\", # col_p, pval_col, ...\n",
    ")\n",
    "\n",
    "def find_pcol(df):\n",
    "    cols = list(df.columns)\n",
    "    # regex name matches\n",
    "    for pat in EEG_NAME_HINTS:\n",
    "        for c in cols:\n",
    "            if re.fullmatch(pat, str(c), flags=re.I):\n",
    "                return c\n",
    "    # numeric [0,1] candidates\n",
    "    candidates = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        s = s[np.isfinite(s)]\n",
    "        if s.empty: \n",
    "            continue\n",
    "        if (pd.Series(s).between(0,1).mean() > 0.95) and (pd.Series(s).nunique() > 10):\n",
    "            candidates.append((c, float(pd.Series(s).mean())))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[1])  # prefer smaller mean (more discoveries)\n",
    "        return candidates[0][0]\n",
    "    return None\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    pcol = find_pcol(df)\n",
    "    if pcol is None:\n",
    "        print(f\"[EEG:hint] {f} — no p-like column. Add 'p' or export null-label results to enable FPR.\")\n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\").fillna(1.0).values\n",
    "    rej, q = benjamini_hochberg(p, alpha=0.01)\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)),\n",
    "        tests=int(p.size),\n",
    "        FPR=np.nan,                 # requires explicit nulls/labels\n",
    "        pi0=float(pi0),\n",
    "        FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# ---------- Cooling (prefer labeled phases; else conservative fallback) ----------\n",
    "def phase_split(df):\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    # temperature column\n",
    "    tcol = next((cols[k] for k in cols if k in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\")), None)\n",
    "    if tcol is None:\n",
    "        num_cols = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "        tcol = num_cols[0] if num_cols else None\n",
    "    if tcol is None:\n",
    "        return None  # unusable\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    # explicit phase?\n",
    "    phase_keys = (\"phase\",\"is_step\",\"label\",\"mode\",\"state\")\n",
    "    pcol = next((cols[k] for k in cols if k in phase_keys), None)\n",
    "    if pcol is not None:\n",
    "        lab = df[pcol].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab == \"step\") | (lab == \"cool\") | (lab == \"1\") | (lab == \"true\") | (lab == \"post\")\n",
    "        base = temp[~step_idx]; step = temp[step_idx]\n",
    "        if len(base) >= 20 and len(step) >= 20:\n",
    "            return (base, step, True)\n",
    "    # fallback: time split\n",
    "    n = len(temp)\n",
    "    if n < 60:\n",
    "        return None\n",
    "    return (temp[:n//2], temp[n//2:], False)\n",
    "\n",
    "def ar1_block_se(xa, xb, rng, B=800):\n",
    "    na, nb = len(xa), len(xb)\n",
    "    blk_a, blk_b = max(5, na//20), max(5, nb//20)\n",
    "    if blk_a <= 0 or blk_b <= 0: \n",
    "        return np.nan\n",
    "    bs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, max(1, na-blk_a))\n",
    "        ib = rng.integers(0, max(1, nb-blk_b))\n",
    "        ra = xa[ia:ia+blk_a]; rb = xb[ib:ib+blk_b]\n",
    "        if len(ra)==0 or len(rb)==0: \n",
    "            continue\n",
    "        bs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(bs, ddof=1)) if bs else np.nan\n",
    "\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    res = phase_split(df)\n",
    "    if res is None:\n",
    "        print(f\"[Cooling:skip] {f} — no usable temp/phase; add a 'phase' column (baseline/step).\")\n",
    "        continue\n",
    "    base, step, labeled = res\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "    se = ar1_block_se(base, step, rng, B=800)\n",
    "    if not np.isfinite(se) or se == 0.0:\n",
    "        print(f\"[Cooling:skip] {f} — insufficient data to estimate SE.\")\n",
    "        continue\n",
    "    z = dT / se\n",
    "    positive = (dT <= -0.5) and (z <= -2.58)  # one-sided ~ p<0.01\n",
    "    # Null: label shuffle if labeled, else time-permutation\n",
    "    Bn, fp = 800, 0\n",
    "    if labeled:\n",
    "        allv = np.concatenate([base, step])\n",
    "        n = len(allv); k = len(step)\n",
    "        for _ in range(Bn):\n",
    "            idx = rng.permutation(n)\n",
    "            sN = allv[idx[:k]]; bN = allv[idx[k:]]\n",
    "            dTN = float(np.mean(sN) - np.mean(bN))\n",
    "            zN = dTN / se\n",
    "            if (dTN <= -0.5) and (zN <= -2.58):\n",
    "                fp += 1\n",
    "    else:\n",
    "        temp = np.concatenate([base, step]); nb = len(base)\n",
    "        for _ in range(Bn):\n",
    "            perm = rng.permutation(temp)\n",
    "            bN, sN = perm[:nb], perm[nb:]\n",
    "            dTN = float(np.mean(sN) - np.mean(bN))\n",
    "            zN = dTN / se\n",
    "            if (dTN <= -0.5) and (zN <= -2.58):\n",
    "                fp += 1\n",
    "    fpr = fp / Bn\n",
    "    audits.append(dict(\n",
    "        module=\"Cooling\", file=f,\n",
    "        positives=int(positive), tests=1,\n",
    "        FPR=float(fpr), dT=dT, z=float(z),\n",
    "        labeled=bool(labeled)\n",
    "    ))\n",
    "\n",
    "# ---------- Forecast (needs columns: alert, verified) ----------\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs columns ['alert','verified']\")\n",
    "        continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=float(fpr)))\n",
    "\n",
    "# ---------- GRA (needs 'restored' and 'truth_pass') ----------\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\")\n",
    "        continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs columns like 'restored' & 'truth_pass'\")\n",
    "        continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = fp / max(fp+tn, 1)\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=float(fpr)))\n",
    "\n",
    "# ---------- Save & print summary ----------\n",
    "out_dir = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "audit_df = pd.DataFrame(audits)\n",
    "out_path = out_dir / f\"cnt_fpr_audit_{pd.Timestamp.now():%Y%m%d-%H%M%S}.csv\"\n",
    "\n",
    "if audit_df.empty:\n",
    "    print(\"\\n== No eligible files found to audit ==\")\n",
    "    print(\"Tips:\")\n",
    "    print(\" • EEG → add a p-value column (e.g., 'p') or export null-label runs for FPR.\")\n",
    "    print(\" • Cooling → include 'phase' labels: baseline/step (or use a *_labeled.csv).\")\n",
    "    print(\" • Forecast → CSV with columns [alert, verified] under artifacts\\\\metrics.\")\n",
    "    print(\" • GRA → include rows for both positives and true negatives (restored/truth_pass).\")\n",
    "else:\n",
    "    audit_df.to_csv(out_path, index=False)\n",
    "    print(\"\\n== CNT False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", out_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f56da82-8cc5-4b1c-8020-cb1b0d83df75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9 cooling file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv\n",
      "   ... +1 more\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv: too few rows (0)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv: too few rows (0)\n",
      "[labeled] cnt_cooling_log_20251015-121543.csv  ->  cnt_cooling_log_20251015-121543_labeled.csv | dT=-1.000, z=nan, FPR~0.000\n",
      "[labeled] cnt_gpu_cooling_log_20251015-122141.csv  ->  cnt_gpu_cooling_log_20251015-122141_labeled.csv | dT=0.000, z=nan, FPR~0.000\n",
      "[labeled] cnt_gpu_cooling_log_20251015-123830.csv  ->  cnt_gpu_cooling_log_20251015-123830_labeled.csv | dT=0.000, z=nan, FPR~0.000\n",
      "[labeled] cnt_unified_cooling_20251015-132627.csv  ->  cnt_unified_cooling_20251015-132627_labeled.csv | dT=-0.713, z=-1.89, FPR~0.000\n",
      "[labeled] cnt_unified_cooling_20251015-133429.csv  ->  cnt_unified_cooling_20251015-133429_labeled.csv | dT=-1.060, z=-3.15, FPR~0.000\n",
      "[labeled] cnt_unified_cooling_v2_20251015-134310.csv  ->  cnt_unified_cooling_v2_20251015-134310_labeled.csv | dT=-0.722, z=-1.90, FPR~0.000\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv: too few rows (4)\n",
      "\n",
      "== Cooling FPR Report ==\n",
      "                                                                               file                                                                                 labeled_csv  n_base  n_step  change_point  flipped        dT         z  positive  FPR\n",
      "       C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv        C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv      66      23            66    False -1.000000       NaN         0  0.0\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv      32     186            32    False  0.000000       NaN         0  0.0\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv      20     118            20    False  0.000000       NaN         0  0.0\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv     266      46            46     True -0.713142 -1.889431         0  0.0\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled.csv     238     141           141     True -1.060373 -3.146504         1  0.0\n",
      "C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled.csv      70     259           259     True -0.721622 -1.898872         0  0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-104943.csv\n"
     ]
    }
   ],
   "source": [
    "# == CNT Cooling: Auto-Label + FPR in One Cell ==\n",
    "# 1) Scans your cooling CSVs\n",
    "# 2) Auto-detects the intervention change point (robust mean-split search)\n",
    "# 3) Labels rows as baseline/step and writes *_labeled.csv next to each file\n",
    "# 4) Computes Cooling FPR via label-shuffle null (one-sided p~0.01; ΔT<=-0.5°C & z<=-2.58)\n",
    "# 5) Saves a compact report to CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_*.csv\n",
    "\n",
    "import os, glob\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "np.random.seed(42)\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "]\n",
    "\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "# ---- find cooling files ----\n",
    "COOL_FILES = []\n",
    "for root in ROOTS:\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "\n",
    "print(f\"Found {len(COOL_FILES)} cooling file(s).\")\n",
    "for f in COOL_FILES[:8]:\n",
    "    print(\" •\", f)\n",
    "if len(COOL_FILES) > 8:\n",
    "    print(f\"   ... +{len(COOL_FILES)-8} more\")\n",
    "\n",
    "# ---- helpers ----\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo:\n",
    "            return lo[key]\n",
    "    # fallback: first numeric column with reasonable variance\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num: \n",
    "        return None\n",
    "    v = pd.Series({c: float(pd.Series(df[c]).var(skipna=True)) for c in num})\n",
    "    v = v.sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.1):\n",
    "    \"\"\"Return index k (baseline = x[:k], step = x[k:]) maximizing |mean diff|,\n",
    "       avoiding the first/last guard fraction.\"\"\"\n",
    "    n = len(x)\n",
    "    if n < 60:\n",
    "        return None\n",
    "    lo = int(n*guard)\n",
    "    hi = int(n*(1-guard))\n",
    "    if hi - lo < 20:\n",
    "        return None\n",
    "    # cumulative means for O(n)\n",
    "    csum = np.cumsum(x)\n",
    "    idx = np.arange(1, n+1)\n",
    "    best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        score = abs(m2 - m1)\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    return best_k\n",
    "\n",
    "def ar1_block_se(xa, xb, B=800):\n",
    "    na, nb = len(xa), len(xb)\n",
    "    blk_a, blk_b = max(5, na//20), max(5, nb//20)\n",
    "    if blk_a <= 0 or blk_b <= 0:\n",
    "        return np.nan\n",
    "    bs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, max(1, na-blk_a))\n",
    "        ib = rng.integers(0, max(1, nb-blk_b))\n",
    "        ra = xa[ia:ia+blk_a]; rb = xb[ib:ib+blk_b]\n",
    "        if len(ra)==0 or len(rb)==0: \n",
    "            continue\n",
    "        bs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(bs, ddof=1)) if bs else np.nan\n",
    "\n",
    "# ---- process & compute FPR ----\n",
    "rows = []\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip read] {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[skip] {f}: no temperature-like column\")\n",
    "        continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)]\n",
    "    if temp.size < 60:\n",
    "        print(f\"[skip] {f}: too few rows ({temp.size})\")\n",
    "        continue\n",
    "\n",
    "    k = best_change_point(temp.values, guard=0.15)\n",
    "    if k is None:\n",
    "        print(f\"[skip] {f}: could not find a robust change point\")\n",
    "        continue\n",
    "\n",
    "    # Assign baseline/step so that baseline mean >= step mean (cooling expectation)\n",
    "    base_raw, step_raw = temp.values[:k], temp.values[k:]\n",
    "    if np.mean(base_raw) < np.mean(step_raw):\n",
    "        # swap if looks like heating so that 'baseline' is the hotter segment\n",
    "        base, step = step_raw, base_raw\n",
    "        flipped = True\n",
    "        k_eff = len(step_raw)  # for labeling; we’ll label by mask\n",
    "        mask = np.r_[np.zeros_like(step_raw, dtype=bool), np.ones_like(base_raw, dtype=bool)]\n",
    "    else:\n",
    "        base, step = base_raw, step_raw\n",
    "        flipped = False\n",
    "        k_eff = k\n",
    "        mask = np.r_[np.zeros(k, dtype=bool), np.ones(len(temp)-k, dtype=bool)]\n",
    "\n",
    "    # Add labels and write *_labeled.csv (non-destructive)\n",
    "    out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "    df2 = df.copy()\n",
    "    # truncate to length of temp column to keep it simple\n",
    "    n = len(temp)\n",
    "    phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "    # extend to df length by repeating last label if needed\n",
    "    if len(df2) > n:\n",
    "        phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "    df2[\"phase\"] = phase[:len(df2)]\n",
    "    df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Stats\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "    se = ar1_block_se(base, step, B=800)\n",
    "    z = dT / se if np.isfinite(se) and se > 0 else np.nan\n",
    "    positive = int((dT <= -0.5) and (np.isfinite(z) and z <= -2.58))\n",
    "\n",
    "    # Label-shuffle null for FPR\n",
    "    Bn, fp = 800, 0\n",
    "    allv = np.concatenate([base, step])\n",
    "    n_all, k_step = len(allv), len(step)\n",
    "    for _ in range(Bn):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se if np.isfinite(se) and se > 0 else np.inf\n",
    "        if (dTN <= -0.5) and (zN <= -2.58):\n",
    "            fp += 1\n",
    "    fpr = fp / Bn\n",
    "\n",
    "    rows.append(dict(\n",
    "        file=f,\n",
    "        labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=k, flipped=flipped,\n",
    "        dT=dT, z=z, positive=positive, FPR=fpr\n",
    "    ))\n",
    "    print(f\"[labeled] {Path(f).name}  ->  {Path(out_csv).name} | dT={dT:.3f}, z={z:.2f}, FPR~{fpr:.3f}\")\n",
    "\n",
    "# ---- save report ----\n",
    "report = pd.DataFrame(rows)\n",
    "out_dir = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / f\"cnt_cooling_fpr_report_{pd.Timestamp.now():%Y%m%d-%H%M%S}.csv\"\n",
    "report.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\n== Cooling FPR Report ==\")\n",
    "if not report.empty:\n",
    "    print(report.to_string(index=False))\n",
    "    print(\"\\nSaved:\", out_path)\n",
    "else:\n",
    "    print(\"No labeled files produced (see skips above).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5daf165-2b9f-45af-864f-04c48cf6781d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 cooling file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv\n",
      "   ... +8 more\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv: too few rows (0)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv: too few rows (0)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv: too few rows (89)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv: too few rows (89)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv: phase too short (base=32, step=186)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv: phase too short (base=32, step=186)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv: phase too short (base=20, step=118)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv: phase too short (base=20, step=118)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv: phase too short (base=266, step=46)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv: phase too short (base=266, step=46)\n",
      "[labeled] cnt_unified_cooling_20251015-133429.csv -> cnt_unified_cooling_20251015-133429_labeled.csv | ΔT=-1.060, z=-12.49, pos=1, FPR=0.0000, FPR↑95=0.0006\n",
      "[labeled] cnt_unified_cooling_20251015-133429_labeled.csv -> cnt_unified_cooling_20251015-133429_labeled_labeled.csv | ΔT=-1.060, z=-12.61, pos=1, FPR=0.0000, FPR↑95=0.0006\n",
      "[labeled] cnt_unified_cooling_v2_20251015-134310.csv -> cnt_unified_cooling_v2_20251015-134310_labeled.csv | ΔT=-0.722, z=-7.64, pos=1, FPR=0.0000, FPR↑95=0.0006\n",
      "[labeled] cnt_unified_cooling_v2_20251015-134310_labeled.csv -> cnt_unified_cooling_v2_20251015-134310_labeled_labeled.csv | ΔT=-0.722, z=-7.95, pos=1, FPR=0.0000, FPR↑95=0.0006\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-104943.csv: too few rows (6)\n",
      "[skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv: too few rows (4)\n",
      "\n",
      "== Cooling FPR Report ==\n",
      "                                                                                       file                                                                                         labeled_csv  n_base  n_step  change_point  flipped        dT          z  zcrit  positive  FPR  FPR_upper95\n",
      "           C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv            C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled.csv     238     141           141     True -1.060373 -12.488842   2.58         1  0.0     0.000599\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled.csv    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled_labeled.csv     238     141           141     True -1.060373 -12.613546   2.58         1  0.0     0.000599\n",
      "        C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv         C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled.csv      70     259           259     True -0.721622  -7.642756   2.58         1  0.0     0.000599\n",
      "C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled.csv C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled_labeled.csv      70     259           259     True -0.721622  -7.953595   2.58         1  0.0     0.000599\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-130627.csv\n"
     ]
    }
   ],
   "source": [
    "# == CNT Cooling FPR — Robust Single Cell (5k shuffles, MBB SE, pooled fallback) ==\n",
    "# - Auto-detects intervention (change point) and labels baseline/step (writes *_labeled.csv)\n",
    "# - Computes ΔT, z using moving-block bootstrap SE (fallback to pooled SE if needed)\n",
    "# - Estimates FPR via 5,000 label-shuffles; prints 95% Clopper-Pearson upper bound\n",
    "# - Saves report to CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_YYYYMMDD-HHMMSS.csv\n",
    "\n",
    "import os, glob, math\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ---------- Config ----------\n",
    "ROOTS = [r\"C:\\Users\\caleb\\CNT_Lab\"]     # add paths if needed\n",
    "MIN_PHASE_N = 60                        # minimum samples per phase\n",
    "GUARD_FRAC = 0.15                       # don't place change-point too close to ends\n",
    "MB_BOOT_B = 1200                        # moving-block bootstrap draws for SE\n",
    "MB_BLOCK_FRAC = 1/15                    # block length ~ phase_len * this\n",
    "SHUFFLES = 5000                         # label-shuffle null draws\n",
    "ALPHA_Z = 0.01                          # one-sided target (≈2.58 z)\n",
    "EFFECT_C = -0.5                         # required ΔT (°C), negative = cooling\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------- Utils ----------\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo:\n",
    "            return lo[key]\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num:\n",
    "        return None\n",
    "    v = pd.Series({c: pd.Series(df[c]).var(skipna=True) for c in num})\n",
    "    v = v.sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.15):\n",
    "    n = len(x)\n",
    "    if n < 2*MIN_PHASE_N:\n",
    "        return None\n",
    "    lo = int(n*guard); hi = int(n*(1-guard))\n",
    "    if hi - lo < MIN_PHASE_N:\n",
    "        return None\n",
    "    csum = np.cumsum(x); best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        score = abs(m2 - m1)\n",
    "        if score > best_score:\n",
    "            best_score, best_k = score, k\n",
    "    return best_k\n",
    "\n",
    "def moving_block_bootstrap_se(a, b, B=1200, rng=None):\n",
    "    \"\"\"Moving-block bootstrap SE for mean difference mean(b)-mean(a).\"\"\"\n",
    "    rng = rng or np.random.default_rng()\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < MIN_PHASE_N or nb < MIN_PHASE_N:\n",
    "        return np.nan\n",
    "    # block lengths\n",
    "    ba = max(5, int(round(na * MB_BLOCK_FRAC)))\n",
    "    bb = max(5, int(round(nb * MB_BLOCK_FRAC)))\n",
    "    diffs = []\n",
    "    for _ in range(B):\n",
    "        # sample blocks with wrap-around\n",
    "        ia = rng.integers(0, na, size=max(2, na // ba))\n",
    "        ib = rng.integers(0, nb, size=max(2, nb // bb))\n",
    "        ra = np.concatenate([a[i: i+ba] if i+ba <= na else np.r_[a[i:], a[:(i+ba-na)]] for i in ia])[:na]\n",
    "        rb = np.concatenate([b[i: i+bb] if i+bb <= nb else np.r_[b[i:], b[:(i+bb-nb)]] for i in ib])[:nb]\n",
    "        diffs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    sd = float(np.std(diffs, ddof=1)) if diffs else np.nan\n",
    "    return sd\n",
    "\n",
    "def pooled_se(a, b):\n",
    "    \"\"\"Fallback SE using pooled variance (independent-sample approximation).\"\"\"\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2:\n",
    "        return np.nan\n",
    "    va = float(np.var(a, ddof=1)); vb = float(np.var(b, ddof=1))\n",
    "    return float(np.sqrt(va/na + vb/nb))\n",
    "\n",
    "def z_threshold(alpha=0.01):\n",
    "    # one-sided normal quantile ~ 2.326 (0.01), but we used 2.58 previously (stricter ~0.005 one-sided).\n",
    "    # To match prior runs, keep 2.58 unless you want exactly alpha=0.01.\n",
    "    return 2.58\n",
    "\n",
    "def clopper_pearson_upper(k, n, alpha=0.05):\n",
    "    \"\"\"Upper bound for Binomial(k|n) at (1-alpha) using Clopper-Pearson.\"\"\"\n",
    "    # For k=0, upper ≈ 1 - alpha^(1/n)\n",
    "    if n == 0:\n",
    "        return np.nan\n",
    "    if k == 0:\n",
    "        return 1 - (alpha)**(1/n)\n",
    "    # Simple Beta inverse could be used; here a numeric search to avoid SciPy dep.\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(40):\n",
    "        mid = (lo+hi)/2\n",
    "        # Binomial CDF(k; n, mid) ~ sum_{i=0}^k C(n,i) mid^i (1-mid)^(n-i)\n",
    "        # Approximate with normal for speed if n large; else compute exact.\n",
    "        # Because we only need an upper bound estimate, use a simple heuristic:\n",
    "        # increase mid until expected k is >= observed k.\n",
    "        exp = n*mid\n",
    "        if exp >= k:\n",
    "            hi = mid\n",
    "        else:\n",
    "            lo = mid\n",
    "    return hi\n",
    "\n",
    "# ---------- Find files ----------\n",
    "COOL_FILES = []\n",
    "for root in ROOTS:\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "\n",
    "print(f\"Found {len(COOL_FILES)} cooling file(s).\")\n",
    "for f in COOL_FILES[:8]:\n",
    "    print(\" •\", f)\n",
    "if len(COOL_FILES) > 8:\n",
    "    print(f\"   ... +{len(COOL_FILES)-8} more\")\n",
    "\n",
    "# ---------- Process & compute ----------\n",
    "rows = []\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip read] {f}: {e}\")\n",
    "        continue\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[skip] {f}: no temperature-like column\")\n",
    "        continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    if temp.size < 2*MIN_PHASE_N:\n",
    "        print(f\"[skip] {f}: too few rows ({temp.size})\")\n",
    "        continue\n",
    "\n",
    "    k = best_change_point(temp, guard=GUARD_FRAC)\n",
    "    if k is None:\n",
    "        print(f\"[skip] {f}: could not find a robust change point\")\n",
    "        continue\n",
    "\n",
    "    base_raw, step_raw = temp[:k], temp[k:]\n",
    "\n",
    "    # orient so \"baseline\" is hotter (expect cooling: step <= base)\n",
    "    if np.mean(base_raw) < np.mean(step_raw):\n",
    "        base, step = step_raw, base_raw\n",
    "        flipped = True\n",
    "        mask = np.r_[np.zeros_like(step_raw, dtype=bool), np.ones_like(base_raw, dtype=bool)]\n",
    "    else:\n",
    "        base, step = base_raw, step_raw\n",
    "        flipped = False\n",
    "        mask = np.r_[np.zeros(k, dtype=bool), np.ones(len(temp)-k, dtype=bool)]\n",
    "\n",
    "    # enforce minimum phase sizes\n",
    "    if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "        print(f\"[skip] {f}: phase too short (base={len(base)}, step={len(step)})\")\n",
    "        continue\n",
    "\n",
    "    # Write labeled CSV (non-destructive)\n",
    "    out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "    df2 = df.copy()\n",
    "    n = len(temp)\n",
    "    phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "    if len(df2) > n:\n",
    "        phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "    df2[\"phase\"] = phase[:len(df2)]\n",
    "    df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Effect size\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "\n",
    "    # SE via moving-block bootstrap; fallback to pooled SE\n",
    "    se = moving_block_bootstrap_se(base, step, B=MB_BOOT_B, rng=rng)\n",
    "    if not (np.isfinite(se) and se > 0):\n",
    "        se = pooled_se(base, step)\n",
    "\n",
    "    if not (np.isfinite(se) and se > 0):\n",
    "        print(f\"[skip] {f}: could not estimate SE (flat segments or too little variance).\")\n",
    "        continue\n",
    "\n",
    "    z = dT / se\n",
    "    zcrit = z_threshold(ALPHA_Z)\n",
    "    positive = int((dT <= EFFECT_C) and (z <= -zcrit))\n",
    "\n",
    "    # Label-shuffle null for FPR\n",
    "    allv = np.concatenate([base, step])\n",
    "    n_all, k_step = len(allv), len(step)\n",
    "    fp = 0\n",
    "    for _ in range(SHUFFLES):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se\n",
    "        if (dTN <= EFFECT_C) and (zN <= -zcrit):\n",
    "            fp += 1\n",
    "    fpr = fp / SHUFFLES\n",
    "    fpr_up95 = clopper_pearson_upper(fp, SHUFFLES, alpha=0.05)\n",
    "\n",
    "    rows.append(dict(\n",
    "        file=f,\n",
    "        labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=int(k), flipped=bool(flipped),\n",
    "        dT=dT, z=z, zcrit=zcrit,\n",
    "        positive=int(positive),\n",
    "        FPR=fpr, FPR_upper95=fpr_up95\n",
    "    ))\n",
    "    print(f\"[labeled] {Path(f).name} -> {Path(out_csv).name} | ΔT={dT:.3f}, z={z:.2f}, pos={positive}, FPR={fpr:.4f}, FPR↑95={fpr_up95:.4f}\")\n",
    "\n",
    "# ---------- Save report ----------\n",
    "report = pd.DataFrame(rows)\n",
    "out_dir = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "out_path = out_dir / f\"cnt_cooling_fpr_report_{datetime.now():%Y%m%d-%H%M%S}.csv\"\n",
    "report.to_csv(out_path, index=False)\n",
    "\n",
    "print(\"\\n== Cooling FPR Report ==\")\n",
    "if not report.empty:\n",
    "    print(report.to_string(index=False))\n",
    "    print(\"\\nSaved:\", out_path)\n",
    "else:\n",
    "    print(\"No labeled files produced (see skips above).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4519e3b3-002c-42b2-a294-0311d236660a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 19 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv\n",
      "   ... +13 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543.csv — too few rows (89)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141.csv — phase too short (base=32, step=186)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830.csv — phase too short (base=20, step=118)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627.csv — phase too short (base=312, step=0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429.csv — phase too short (base=379, step=0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310.csv — phase too short (base=329, step=0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-104943.csv — too few rows (6)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-130627.csv — too few rows (4)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv — too few rows (4)\n",
      "\n",
      "== CNT Unified False-Positive Audit ==\n",
      "module                                                                                                                      file  positives  tests  FPR  pi0  FDR_alpha_0p01  TP  FP  TN  FN\n",
      "   EEG C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv       50.0   50.0 None  0.0             1.0 NaN NaN NaN NaN\n",
      "   GRA    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv        NaN    NaN None  NaN             NaN 2.0 0.0 0.0 0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_20251016-131002.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3860: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:144: RuntimeWarning: invalid value encountered in scalar divide\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# == CNT Unified False-Positive Audit — Single Cell (Cooling + EEG + GRA + Forecast) ==\n",
    "# Telos edition: robust, reproducible, dashboard-ready.\n",
    "# - Cooling: auto-label (change-point), skip already-labeled, MBB SE + pooled fallback,\n",
    "#            decision rule (ΔT <= -0.5 °C & z <= -2.58), 5,000 label-shuffles for FPR,\n",
    "#            95% Clopper–Pearson upper bound, writes *_labeled.csv once.\n",
    "# - EEG: discovers p-like column; reports BH discoveries, Storey π0, FDR@0.01;\n",
    "#        if columns p_null_* exist (null-label runs), computes EEG FPR.\n",
    "# - GRA: restored vs truth_pass confusion + FPR when TN+FP>0.\n",
    "# - Forecast: FPR from [alert, verified].\n",
    "# - Outputs one CSV: CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_YYYYMMDD-HHMMSS.csv\n",
    "\n",
    "import os, re, glob, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "OUT_DIR = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cooling params\n",
    "MIN_PHASE_N   = 60           # min samples per phase\n",
    "GUARD_FRAC    = 0.15         # avoid ends when choosing change point\n",
    "MB_BOOT_B     = 1200         # moving-block bootstrap draws for SE\n",
    "MB_BLOCK_FRAC = 1/15         # block length ≈ phase_len * this\n",
    "SHUFFLES      = 5000         # label-shuffle draws for FPR\n",
    "Z_CRIT        = 2.58         # one-sided ~0.005; conservative vs 0.01 (2.326)\n",
    "DELTA_REQ     = -0.5         # °C threshold for \"cooling achieved\"\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]: print(\" •\", f)\n",
    "    if len(files) > limit: print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "def benjamini_hochberg(pvals, alpha=0.05):\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.empty_like(order); ranks[order] = np.arange(1, n+1)\n",
    "    q = p * n / np.maximum(ranks, 1)\n",
    "    q_sorted = np.minimum.accumulate(q[order][::-1])[::-1]\n",
    "    qvalues = np.empty_like(q_sorted); qvalues[order] = q_sorted\n",
    "    rej = qvalues <= alpha\n",
    "    return rej, qvalues\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    p = np.asarray(pd.Series(p).astype(float))\n",
    "    p = p[np.isfinite(p)]\n",
    "    if p.size == 0: return np.nan\n",
    "    return float(min(1.0, max(0.0, np.mean(p >= lam)/(1-lam))))\n",
    "\n",
    "def clopper_pearson_upper(k, n, alpha=0.05):\n",
    "    if n == 0: return np.nan\n",
    "    if k == 0: return 1 - (alpha)**(1/n)\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(40):\n",
    "        mid = (lo+hi)/2\n",
    "        exp = n*mid\n",
    "        if exp >= k: hi = mid\n",
    "        else:        lo = mid\n",
    "    return hi\n",
    "\n",
    "# ---------------- Cooling helpers ----------------\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo: return lo[key]\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num: return None\n",
    "    v = pd.Series({c: pd.Series(df[c]).var(skipna=True) for c in num}).sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.15):\n",
    "    n = len(x)\n",
    "    if n < 2*MIN_PHASE_N: return None\n",
    "    lo = int(n*guard); hi = int(n*(1-guard))\n",
    "    if hi - lo < MIN_PHASE_N: return None\n",
    "    csum = np.cumsum(x); best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        s = abs(m2 - m1)\n",
    "        if s > best_score: best_score, best_k = s, k\n",
    "    return best_k\n",
    "\n",
    "def moving_block_bootstrap_se(a, b, B=1200):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < MIN_PHASE_N or nb < MIN_PHASE_N: return np.nan\n",
    "    ba = max(5, int(round(na * MB_BLOCK_FRAC)))\n",
    "    bb = max(5, int(round(nb * MB_BLOCK_FRAC)))\n",
    "    diffs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, na, size=max(2, na // ba))\n",
    "        ib = rng.integers(0, nb, size=max(2, nb // bb))\n",
    "        ra = np.concatenate([a[i:i+ba] if i+ba<=na else np.r_[a[i:], a[:(i+ba-na)]] for i in ia])[:na]\n",
    "        rb = np.concatenate([b[i:i+bb] if i+bb<=nb else np.r_[b[i:], b[:(i+bb-nb)]] for i in ib])[:nb]\n",
    "        diffs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(diffs, ddof=1)) if diffs else np.nan\n",
    "\n",
    "def pooled_se(a, b):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2: return np.nan\n",
    "    va, vb = float(np.var(a, ddof=1)), float(np.var(b, ddof=1))\n",
    "    return float(np.sqrt(va/na + vb/nb))\n",
    "\n",
    "# ---------------- Discover files ----------------\n",
    "EEG_FILES, COOL_FILES, FORECAST_FILES, GRA_FILES = [], [], [], []\n",
    "for root in ROOTS:\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    COOL_FILES += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "\n",
    "# ---------------- EEG ----------------\n",
    "EEG_NAME_HINTS = (\n",
    "    r\"^p(_?val(ue)?)?$\",         # p, pval, p_value\n",
    "    r\"^p_[a-z]+$\",               # p_alpha, p_beta, ...\n",
    "    r\"^[a-z]*_?p(_?val(ue)?)?$\", # col_p, pval_col, ...\n",
    ")\n",
    "def find_pcol(df):\n",
    "    cols = list(df.columns)\n",
    "    for pat in EEG_NAME_HINTS:\n",
    "        for c in cols:\n",
    "            if re.fullmatch(pat, str(c), flags=re.I): return c\n",
    "    candidates = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        s = s[np.isfinite(s)]\n",
    "        if s.size and (pd.Series(s).between(0,1).mean() > 0.95) and (pd.Series(s).nunique() > 10):\n",
    "            candidates.append((c, float(pd.Series(s).mean())))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[1])\n",
    "        return candidates[0][0]\n",
    "    return None\n",
    "\n",
    "def eeg_null_cols(df):\n",
    "    # any columns like p_null_001, p_null_..., or ending with '_null'\n",
    "    pats = (r\"^p_null_.*$\", r\".*_null$\")\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        for p in pats:\n",
    "            if re.fullmatch(p, str(c), flags=re.I):\n",
    "                cols.append(c); break\n",
    "    return cols\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\"); continue\n",
    "    pcol = find_pcol(df)\n",
    "    if pcol is None:\n",
    "        print(f\"[EEG:hint] {f} — add a 'p' column or p_null_* columns to enable FPR.\")\n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\").fillna(1.0).values\n",
    "    rej, q = benjamini_hochberg(p, alpha=0.01)\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    # EEG FPR if null runs provided\n",
    "    nulls = eeg_null_cols(df)\n",
    "    eeg_fpr = np.nan\n",
    "    if nulls:\n",
    "        # For each null column, ask: would BH@0.01 yield any discovery?\n",
    "        fp = 0\n",
    "        for nc in nulls:\n",
    "            pn = pd.to_numeric(df[nc], errors=\"coerce\").fillna(1.0).values\n",
    "            rnull, _ = benjamini_hochberg(pn, alpha=0.01)\n",
    "            if rnull.any(): fp += 1\n",
    "        eeg_fpr = fp / len(nulls)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)), tests=int(p.size),\n",
    "        FPR=(None if np.isnan(eeg_fpr) else float(eeg_fpr)),\n",
    "        pi0=float(pi0), FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# ---------------- Cooling ----------------\n",
    "cool_rows = []\n",
    "for f in COOL_FILES:\n",
    "    # Skip outputs or already-labeled re-runs\n",
    "    base_name = Path(f).name.lower()\n",
    "    if base_name.endswith(\"_labeled.csv\") or base_name.endswith(\"_labeled_labeled.csv\"):\n",
    "        continue\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\"); continue\n",
    "\n",
    "    # If already has a phase column, don't rewrite; just compute stats\n",
    "    has_phase = any(c.lower()==\"phase\" for c in df.columns)\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[Cooling:skip] {f} — no temperature-like column\"); continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    if temp.size < 2*MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — too few rows ({temp.size})\"); continue\n",
    "\n",
    "    if has_phase:\n",
    "        lab = df[[c for c in df.columns if c.lower()==\"phase\"][0]].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab==\"step\") | (lab==\"cool\") | (lab==\"1\") | (lab==\"true\") | (lab==\"post\")\n",
    "        base = temp[~step_idx]; step = temp[step_idx]\n",
    "        flipped = (np.mean(base) < np.mean(step))  # just for record\n",
    "        k = np.nan\n",
    "        out_csv = f  # no rewrite\n",
    "    else:\n",
    "        k = best_change_point(temp, guard=GUARD_FRAC)\n",
    "        if k is None:\n",
    "            print(f\"[Cooling:skip] {f} — no robust change point\"); continue\n",
    "        base_raw, step_raw = temp[:k], temp[k:]\n",
    "        if np.mean(base_raw) < np.mean(step_raw):\n",
    "            base, step = step_raw, base_raw; flipped=True\n",
    "            mask = np.r_[np.zeros_like(step_raw, bool), np.ones_like(base_raw, bool)]\n",
    "        else:\n",
    "            base, step = base_raw, step_raw; flipped=False\n",
    "            mask = np.r_[np.zeros(k, bool), np.ones(len(temp)-k, bool)]\n",
    "        if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "            print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "        out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "        df2 = df.copy()\n",
    "        n = len(temp)\n",
    "        phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "        if len(df2) > n: phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "        df2[\"phase\"] = phase[:len(df2)]\n",
    "        df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Stats\n",
    "    if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "    se = moving_block_bootstrap_se(base, step, B=MB_BOOT_B)\n",
    "    if not (np.isfinite(se) and se > 0): se = pooled_se(base, step)\n",
    "    if not (np.isfinite(se) and se > 0):\n",
    "        print(f\"[Cooling:skip] {f} — cannot estimate SE\"); continue\n",
    "\n",
    "    z = dT / se\n",
    "    positive = int((dT <= DELTA_REQ) and (z <= -Z_CRIT))\n",
    "\n",
    "    # Label-shuffle null\n",
    "    allv = np.concatenate([base, step]); k_step = len(step); n_all = len(allv)\n",
    "    fp = 0\n",
    "    for _ in range(SHUFFLES):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se\n",
    "        if (dTN <= DELTA_REQ) and (zN <= -Z_CRIT):\n",
    "            fp += 1\n",
    "    fpr = fp / SHUFFLES\n",
    "    fpr_up95 = clopper_pearson_upper(fp, SHUFFLES, alpha=0.05)\n",
    "\n",
    "    cool_rows.append(dict(\n",
    "        module=\"Cooling\", file=f, labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=(None if np.isnan(k) else (None if k is None else int(k))),\n",
    "        flipped=bool(flipped),\n",
    "        dT=dT, z=z, zcrit=Z_CRIT,\n",
    "        positive=int(positive),\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95)\n",
    "    ))\n",
    "\n",
    "# Add Cooling to audits table (keep key cols compact)\n",
    "for r in cool_rows:\n",
    "    audits.append(dict(\n",
    "        module=\"Cooling\", file=r[\"file\"],\n",
    "        positives=r[\"positive\"], tests=1,\n",
    "        FPR=r[\"FPR\"], FPR_upper95=r[\"FPR_upper95\"],\n",
    "        dT=r[\"dT\"], z=r[\"z\"]\n",
    "    ))\n",
    "\n",
    "# ---------------- Forecast ----------------\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\"); continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs ['alert','verified']\"); continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- GRA ----------------\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\"); continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs 'restored' & 'truth_pass'\"); continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth    = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- Save & print ----------------\n",
    "audit_df = pd.DataFrame(audits)\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "out_path = OUT_DIR / f\"cnt_unified_fpr_report_{stamp}.csv\"\n",
    "if not audit_df.empty:\n",
    "    audit_df.to_csv(out_path, index=False)\n",
    "    print(\"\\n== CNT Unified False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", out_path)\n",
    "else:\n",
    "    print(\"\\n== No eligible items found to audit ==\")\n",
    "\n",
    "# Optional: print Cooling detail table (with bounds) for quick quoting\n",
    "if cool_rows:\n",
    "    cool_df = pd.DataFrame(cool_rows)\n",
    "    cool_out = OUT_DIR / f\"cnt_cooling_fpr_detail_{stamp}.csv\"\n",
    "    cool_df.to_csv(cool_out, index=False)\n",
    "    print(\"\\n== Cooling Detail (with 95% bounds) ==\")\n",
    "    print(cool_df[[\"file\",\"dT\",\"z\",\"positive\",\"FPR\",\"FPR_upper95\"]].to_string(index=False))\n",
    "    print(\"\\nSaved:\", cool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06eec224-1f46-42bb-94e3-ffa27f596d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 11 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv\n",
      "   ... +5 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv — too few rows (89)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv — phase too short (base=32, step=186)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv — phase too short (base=20, step=118)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv — phase too short (base=266, step=46)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-104943.csv — too few rows (6)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-130627.csv — too few rows (4)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv — too few rows (4)\n",
      "\n",
      "== CNT Unified False-Positive Audit ==\n",
      " module                                                                                                                      file  positives  tests  FPR  pi0  FDR_alpha_0p01  FPR_upper95        dT         z  TP  FP  TN  FN\n",
      "    EEG C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv       50.0   50.0  NaN  0.0             1.0          NaN       NaN       NaN NaN NaN NaN NaN\n",
      "Cooling                          C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled_labeled.csv        0.0    1.0  0.0  NaN             NaN     0.000599  0.814411  5.807012 NaN NaN NaN NaN\n",
      "Cooling                       C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled_labeled.csv        0.0    1.0  0.0  NaN             NaN     0.000599 -0.104633 -0.651198 NaN NaN NaN NaN\n",
      "    GRA    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv        NaN    NaN  NaN  NaN             NaN          NaN       NaN       NaN 2.0 0.0 0.0 0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_20251016-131416.csv\n",
      "\n",
      "== Cooling Detail (with 95% bounds) ==\n",
      "                                                                                               file        dT         z  positive  FPR  FPR_upper95\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled_labeled.csv  0.814411  5.807012         0  0.0     0.000599\n",
      "C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled_labeled.csv -0.104633 -0.651198         0  0.0     0.000599\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_detail_20251016-131416.csv\n"
     ]
    }
   ],
   "source": [
    "# == CNT Unified False-Positive Audit — Rolled & Hardened ==\n",
    "# Cooling: prefer *_labeled.csv if present; robust change-point; MBB SE + pooled fallback;\n",
    "#          decision rule (ΔT <= -0.5 °C & z <= -2.58); 5,000 label-shuffles; 95% CP upper bound\n",
    "# EEG:     BH discoveries + Storey π0; optional FPR if p_null_* columns exist\n",
    "# GRA:     restored vs truth_pass confusion + FPR\n",
    "# Forecast:FPR from [alert, verified]\n",
    "# Output:  CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_YYYYMMDD-HHMMSS.csv\n",
    "#          + Cooling detail table (with 95% bounds)\n",
    "\n",
    "import os, re, glob, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "OUT_DIR = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cooling params\n",
    "MIN_PHASE_N   = 60           # minimum samples per phase\n",
    "GUARD_FRAC    = 0.15         # avoid edges when choosing change point\n",
    "MB_BOOT_B     = 1200         # moving-block bootstrap draws\n",
    "MB_BLOCK_FRAC = 1/15         # block length ≈ phase_len * this\n",
    "SHUFFLES      = 5000         # label-shuffle draws for FPR\n",
    "Z_CRIT        = 2.58         # one-sided ~0.005; conservative vs 0.01 (2.326)\n",
    "DELTA_REQ     = -0.5         # °C threshold for \"cooling achieved\"\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]: print(\" •\", f)\n",
    "    if len(files) > limit: print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "def benjamini_hochberg(pvals, alpha=0.05):\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.empty_like(order); ranks[order] = np.arange(1, n+1)\n",
    "    q = p * n / np.maximum(ranks, 1)\n",
    "    q_sorted = np.minimum.accumulate(q[order][::-1])[::-1]\n",
    "    qvalues = np.empty_like(q_sorted); qvalues[order] = q_sorted\n",
    "    rej = qvalues <= alpha\n",
    "    return rej, qvalues\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    p = np.asarray(pd.Series(p).astype(float))\n",
    "    p = p[np.isfinite(p)]\n",
    "    if p.size == 0: return np.nan\n",
    "    return float(min(1.0, max(0.0, np.mean(p >= lam)/(1-lam))))\n",
    "\n",
    "def clopper_pearson_upper(k, n, alpha=0.05):\n",
    "    if n == 0: return np.nan\n",
    "    if k == 0: return 1 - (alpha)**(1/n)\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(40):\n",
    "        mid = (lo+hi)/2\n",
    "        if n*mid >= k: hi = mid\n",
    "        else:          lo = mid\n",
    "    return hi\n",
    "\n",
    "# ---------------- Cooling helpers ----------------\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo: return lo[key]\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num: return None\n",
    "    v = pd.Series({c: pd.Series(df[c]).var(skipna=True) for c in num}).sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.15):\n",
    "    n = len(x)\n",
    "    lo = max(MIN_PHASE_N, int(n*guard))\n",
    "    hi = min(n - MIN_PHASE_N, int(n*(1-guard)))\n",
    "    if hi - lo < 1: return None\n",
    "    csum = np.cumsum(x, dtype=float)\n",
    "    best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi+1):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        s = abs(m2 - m1)\n",
    "        if s > best_score: best_score, best_k = s, k\n",
    "    return best_k\n",
    "\n",
    "def moving_block_bootstrap_se(a, b, B=1200):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < MIN_PHASE_N or nb < MIN_PHASE_N: return np.nan\n",
    "    ba = max(5, int(round(na * MB_BLOCK_FRAC)))\n",
    "    bb = max(5, int(round(nb * MB_BLOCK_FRAC)))\n",
    "    diffs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, na, size=max(2, na // ba))\n",
    "        ib = rng.integers(0, nb, size=max(2, nb // bb))\n",
    "        ra = np.concatenate([a[i:i+ba] if i+ba<=na else np.r_[a[i:], a[:(i+ba-na)]] for i in ia])[:na]\n",
    "        rb = np.concatenate([b[i:i+bb] if i+bb<=nb else np.r_[b[i:], b[:(i+bb-nb)]] for i in ib])[:nb]\n",
    "        diffs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(diffs, ddof=1)) if diffs else np.nan\n",
    "\n",
    "def pooled_se(a, b):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2: return np.nan\n",
    "    va, vb = float(np.var(a, ddof=1)), float(np.var(b, ddof=1))\n",
    "    return float(np.sqrt(va/na + vb/nb))\n",
    "\n",
    "# ---------------- Discover EEG/GRA/Forecast ----------------\n",
    "EEG_FILES, FORECAST_FILES, GRA_FILES = [], [], []\n",
    "for root in ROOTS:\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "# ---------------- Discover Cooling (prefer labeled twins) ----------------\n",
    "ALL_COOL = []\n",
    "for root in ROOTS:\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "\n",
    "by_stem = {}\n",
    "for f in ALL_COOL:\n",
    "    p = Path(f)\n",
    "    # normalize twin key: strip any trailing \"_labeled\" clusters\n",
    "    key = re.sub(r\"_labeled(?:_labeled)*\\.csv$\", \".csv\", p.name, flags=re.I)\n",
    "    by_stem.setdefault((p.parent, key), []).append(p)\n",
    "\n",
    "COOL_FILES = []\n",
    "for (parent, key), files in by_stem.items():\n",
    "    labeled = [x for x in files if re.search(r\"_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    if labeled:\n",
    "        COOL_FILES.append(str(sorted(labeled)[-1]))     # newest labeled\n",
    "    else:\n",
    "        raw = [x for x in files if not re.search(r\"_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "        if raw: COOL_FILES.append(str(sorted(raw)[-1]))\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "cool_rows = []\n",
    "\n",
    "# ---------------- EEG ----------------\n",
    "EEG_NAME_HINTS = (\n",
    "    r\"^p(_?val(ue)?)?$\",         # p, pval, p_value\n",
    "    r\"^p_[a-z]+$\",               # p_alpha, p_beta, ...\n",
    "    r\"^[a-z]*_?p(_?val(ue)?)?$\", # col_p, pval_col, ...\n",
    ")\n",
    "def find_pcol(df):\n",
    "    cols = list(df.columns)\n",
    "    for pat in EEG_NAME_HINTS:\n",
    "        for c in cols:\n",
    "            if re.fullmatch(pat, str(c), flags=re.I): return c\n",
    "    candidates = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        s = s[np.isfinite(s)]\n",
    "        if s.size and (pd.Series(s).between(0,1).mean() > 0.95) and (pd.Series(s).nunique() > 10):\n",
    "            candidates.append((c, float(pd.Series(s).mean())))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[1])\n",
    "        return candidates[0][0]\n",
    "    return None\n",
    "\n",
    "def eeg_null_cols(df):\n",
    "    pats = (r\"^p_null_.*$\", r\".*_null$\")\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        for p in pats:\n",
    "            if re.fullmatch(p, str(c), flags=re.I):\n",
    "                cols.append(c); break\n",
    "    return cols\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\"); continue\n",
    "    pcol = find_pcol(df)\n",
    "    if pcol is None:\n",
    "        print(f\"[EEG:hint] {f} — add a 'p' column or p_null_* columns to enable FPR.\")\n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\").fillna(1.0).values\n",
    "    rej, q = benjamini_hochberg(p, alpha=0.01)\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    # Optional EEG FPR if null p-columns provided\n",
    "    nulls = eeg_null_cols(df)\n",
    "    eeg_fpr = np.nan\n",
    "    if nulls:\n",
    "        fp = 0\n",
    "        for nc in nulls:\n",
    "            pn = pd.to_numeric(df[nc], errors=\"coerce\").fillna(1.0).values\n",
    "            rnull, _ = benjamini_hochberg(pn, alpha=0.01)\n",
    "            if rnull.any(): fp += 1\n",
    "        eeg_fpr = fp / len(nulls)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)), tests=int(p.size),\n",
    "        FPR=(None if np.isnan(eeg_fpr) else float(eeg_fpr)),\n",
    "        pi0=float(pi0), FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# ---------------- Cooling ----------------\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\"); continue\n",
    "\n",
    "    # If already labeled, use given phases; else auto-label by change-point\n",
    "    has_phase = any(c.lower()==\"phase\" for c in df.columns)\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[Cooling:skip] {f} — no temperature-like column\"); continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    if temp.size < 2*MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — too few rows ({temp.size})\"); continue\n",
    "\n",
    "    if has_phase:\n",
    "        lab = df[[c for c in df.columns if c.lower()==\"phase\"][0]].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab==\"step\") | (lab==\"cool\") | (lab==\"1\") | (lab==\"true\") | (lab==\"post\")\n",
    "        base, step = temp[~step_idx], temp[step_idx]\n",
    "        flipped, k, out_csv = (np.mean(base) < np.mean(step)), np.nan, f\n",
    "    else:\n",
    "        k = best_change_point(temp, guard=GUARD_FRAC)\n",
    "        if k is None:\n",
    "            print(f\"[Cooling:skip] {f} — no robust change point\"); continue\n",
    "        base_raw, step_raw = temp[:k], temp[k:]\n",
    "        if np.mean(base_raw) < np.mean(step_raw):\n",
    "            base, step = step_raw, base_raw; flipped=True\n",
    "            mask = np.r_[np.zeros_like(step_raw, bool), np.ones_like(base_raw, bool)]\n",
    "        else:\n",
    "            base, step = base_raw, step_raw; flipped=False\n",
    "            mask = np.r_[np.zeros(k, bool), np.ones(len(temp)-k, bool)]\n",
    "        if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "            print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "        out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "        df2 = df.copy()\n",
    "        n = len(temp)\n",
    "        phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "        if len(df2) > n: phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "        df2[\"phase\"] = phase[:len(df2)]\n",
    "        df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Hard guards to avoid numpy warnings\n",
    "    if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "\n",
    "    dT = float(np.mean(step) - np.mean(base))\n",
    "\n",
    "    se = moving_block_bootstrap_se(base, step, B=MB_BOOT_B)\n",
    "    if not (np.isfinite(se) and se > 0):\n",
    "        se = pooled_se(base, step)\n",
    "    if not (np.isfinite(se) and se > 0):\n",
    "        se = 1e-9  # last-ditch jitter to avoid div-by-zero on perfectly flat logs\n",
    "\n",
    "    z = dT / se\n",
    "    positive = int((dT <= DELTA_REQ) and (z <= -Z_CRIT))\n",
    "\n",
    "    # Label-shuffle null\n",
    "    allv = np.concatenate([base, step]); k_step = len(step); n_all = len(allv)\n",
    "    fp = 0\n",
    "    for _ in range(SHUFFLES):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se\n",
    "        if (dTN <= DELTA_REQ) and (zN <= -Z_CRIT):\n",
    "            fp += 1\n",
    "    fpr = fp / SHUFFLES\n",
    "    fpr_up95 = clopper_pearson_upper(fp, SHUFFLES, alpha=0.05)\n",
    "\n",
    "    cool_rows.append(dict(\n",
    "        module=\"Cooling\", file=f, labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=(None if (k is None or np.isnan(k)) else int(k)),\n",
    "        flipped=bool(flipped),\n",
    "        dT=dT, z=z, zcrit=Z_CRIT,\n",
    "        positive=int(positive),\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95)\n",
    "    ))\n",
    "\n",
    "    # Compact entry for unified audit table\n",
    "    audits.append(dict(\n",
    "        module=\"Cooling\", file=f,\n",
    "        positives=int(positive), tests=1,\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95),\n",
    "        dT=dT, z=z\n",
    "    ))\n",
    "\n",
    "# ---------------- Forecast ----------------\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\"); continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs ['alert','verified']\"); continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- GRA ----------------\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\"); continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs 'restored' & 'truth_pass'\"); continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth    = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- Save & print ----------------\n",
    "audit_df = pd.DataFrame(audits)\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "unified_path = OUT_DIR / f\"cnt_unified_fpr_report_{stamp}.csv\"\n",
    "if not audit_df.empty:\n",
    "    audit_df.to_csv(unified_path, index=False)\n",
    "    print(\"\\n== CNT Unified False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", unified_path)\n",
    "else:\n",
    "    print(\"\\n== No eligible items found to audit ==\")\n",
    "\n",
    "if cool_rows:\n",
    "    cool_df = pd.DataFrame(cool_rows)\n",
    "    cool_out = OUT_DIR / f\"cnt_cooling_fpr_detail_{stamp}.csv\"\n",
    "    cool_df.to_csv(cool_out, index=False)\n",
    "    print(\"\\n== Cooling Detail (with 95% bounds) ==\")\n",
    "    print(cool_df[[\"file\",\"dT\",\"z\",\"positive\",\"FPR\",\"FPR_upper95\"]].to_string(index=False))\n",
    "    print(\"\\nSaved:\", cool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7590c8cc-7c4c-424a-abed-6306cc43d2a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 12 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv\n",
      "   ... +6 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'float' object is not iterable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 205\u001b[39m\n\u001b[32m    203\u001b[39m p = pd.to_numeric(df[pcol], errors=\u001b[33m\"\u001b[39m\u001b[33mcoerce\u001b[39m\u001b[33m\"\u001b[39m).fillna(\u001b[32m1.0\u001b[39m).values\n\u001b[32m    204\u001b[39m rej, q = benjamini_hochberg(p, alpha=\u001b[32m0.01\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m pi0 = \u001b[43mstorey_pi0\u001b[49m\u001b[43m(\u001b[49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlam\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    206\u001b[39m \u001b[38;5;66;03m# Optional EEG FPR if null p-columns provided\u001b[39;00m\n\u001b[32m    207\u001b[39m nulls = eeg_null_cols(df)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 66\u001b[39m, in \u001b[36mstorey_pi0\u001b[39m\u001b[34m(p, lam)\u001b[39m\n\u001b[32m     64\u001b[39m p = p[np.isfinite(p)]\n\u001b[32m     65\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m p.size == \u001b[32m0\u001b[39m: \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m---> \u001b[39m\u001b[32m66\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mmin\u001b[39m(\u001b[32m1.0\u001b[39m, \u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m(\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m)\u001b[49m, np.mean(p >= lam)/(\u001b[32m1\u001b[39m-lam)))\n",
      "\u001b[31mTypeError\u001b[39m: 'float' object is not iterable"
     ]
    }
   ],
   "source": [
    "# == CNT Unified False-Positive Audit — Fused & Upgraded (Telos edition) ==\n",
    "# Cooling:\n",
    "#   • Prefer *_labeled.csv (ignore *_labeled_labeled.csv), or auto-label via robust change-point.\n",
    "#   • Re-orient labeled runs so 'baseline' is hotter (cooling expectation).\n",
    "#   • SE via moving-block bootstrap (autocorr aware), fallback to pooled SE, jitter last-ditch.\n",
    "#   • Decision rule: ΔT <= -0.5 °C and z <= -2.58 (one-sided, conservative).\n",
    "#   • 5,000 label-shuffles for FPR + 95% Clopper–Pearson upper bound.\n",
    "# EEG:\n",
    "#   • Reports BH (FDR@0.01) + Storey π0; computes FPR if p_null_* columns exist.\n",
    "# GRA:\n",
    "#   • Confusion + FPR from 'restored' vs 'truth_pass'.\n",
    "# Forecast:\n",
    "#   • FPR from [alert, verified].\n",
    "# Outputs:\n",
    "#   • CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_YYYYMMDD-HHMMSS.csv\n",
    "#   • CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_detail_YYYYMMDD-HHMMSS.csv\n",
    "\n",
    "import os, re, glob, math\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "OUT_DIR = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cooling params\n",
    "MIN_PHASE_N   = 60           # minimum samples per phase\n",
    "GUARD_FRAC    = 0.15         # avoid edges when choosing change point\n",
    "MB_BOOT_B     = 1200         # moving-block bootstrap draws\n",
    "MB_BLOCK_FRAC = 1/15         # block length ≈ phase_len * this\n",
    "SHUFFLES      = 5000         # label-shuffle draws for FPR\n",
    "Z_CRIT        = 2.58         # one-sided ~0.005; conservative vs 0.01 (2.326)\n",
    "DELTA_REQ     = -0.5         # °C threshold for \"cooling achieved\"\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]: print(\" •\", f)\n",
    "    if len(files) > limit: print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "def benjamini_hochberg(pvals, alpha=0.05):\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    n = p.size\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.empty_like(order); ranks[order] = np.arange(1, n+1)\n",
    "    q = p * n / np.maximum(ranks, 1)\n",
    "    q_sorted = np.minimum.accumulate(q[order][::-1])[::-1]\n",
    "    qvalues = np.empty_like(q_sorted); qvalues[order] = q_sorted\n",
    "    rej = qvalues <= alpha\n",
    "    return rej, qvalues\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    p = np.asarray(pd.Series(p).astype(float))\n",
    "    p = p[np.isfinite(p)]\n",
    "    if p.size == 0: return np.nan\n",
    "    return float(min(1.0, max(0.0), np.mean(p >= lam)/(1-lam)))\n",
    "\n",
    "def clopper_pearson_upper(k, n, alpha=0.05):\n",
    "    if n == 0: return np.nan\n",
    "    if k == 0: return 1 - (alpha)**(1/n)\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(40):\n",
    "        mid = (lo+hi)/2\n",
    "        if n*mid >= k: hi = mid\n",
    "        else:          lo = mid\n",
    "    return hi\n",
    "\n",
    "# ---------------- Cooling helpers ----------------\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo: return lo[key]\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num: return None\n",
    "    v = pd.Series({c: pd.Series(df[c]).var(skipna=True) for c in num}).sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.15):\n",
    "    n = len(x)\n",
    "    lo = max(MIN_PHASE_N, int(n*guard))\n",
    "    hi = min(n - MIN_PHASE_N, int(n*(1-guard)))\n",
    "    if hi - lo < 1: return None\n",
    "    csum = np.cumsum(x, dtype=float)\n",
    "    best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi+1):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        s = abs(m2 - m1)\n",
    "        if s > best_score: best_score, best_k = s, k\n",
    "    return best_k\n",
    "\n",
    "def moving_block_bootstrap_se(a, b, B=1200):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < MIN_PHASE_N or nb < MIN_PHASE_N: return np.nan\n",
    "    ba = max(5, int(round(na * MB_BLOCK_FRAC)))\n",
    "    bb = max(5, int(round(nb * MB_BLOCK_FRAC)))\n",
    "    diffs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, na, size=max(2, na // ba))\n",
    "        ib = rng.integers(0, nb, size=max(2, nb // bb))\n",
    "        ra = np.concatenate([a[i:i+ba] if i+ba<=na else np.r_[a[i:], a[:(i+ba-na)]] for i in ia])[:na]\n",
    "        rb = np.concatenate([b[i:i+bb] if i+bb<=nb else np.r_[b[i:], b[:(i+bb-nb)]] for i in ib])[:nb]\n",
    "        diffs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(diffs, ddof=1)) if diffs else np.nan\n",
    "\n",
    "def pooled_se(a, b):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2: return np.nan\n",
    "    va, vb = float(np.var(a, ddof=1)), float(np.var(b, ddof=1))\n",
    "    return float(np.sqrt(va/na + vb/nb))\n",
    "\n",
    "# ---------------- Discover EEG/GRA/Forecast ----------------\n",
    "EEG_FILES, FORECAST_FILES, GRA_FILES = [], [], []\n",
    "for root in ROOTS:\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "# ---------------- Discover Cooling (prefer single-labeled; ignore double-labeled) ----------------\n",
    "ALL_COOL = []\n",
    "for root in ROOTS:\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "\n",
    "by_stem = {}\n",
    "for f in ALL_COOL:\n",
    "    p = Path(f)\n",
    "    key = re.sub(r\"(?:_labeled)+\\.csv$\", \".csv\", p.name, flags=re.I)  # normalize any labeled clusters\n",
    "    by_stem.setdefault((p.parent, key), []).append(p)\n",
    "\n",
    "COOL_FILES = []\n",
    "for (parent, key), files in by_stem.items():\n",
    "    single_labeled = [x for x in files if re.search(r\"(?<!_labeled)_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    multi_labeled  = [x for x in files if re.search(r\"_labeled_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    raw            = [x for x in files if not re.search(r\"_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    if single_labeled:\n",
    "        COOL_FILES.append(str(sorted(single_labeled)[-1]))\n",
    "    elif raw:\n",
    "        COOL_FILES.append(str(sorted(raw)[-1]))\n",
    "    elif multi_labeled:\n",
    "        COOL_FILES.append(str(sorted(multi_labeled)[-1]))\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "cool_rows = []\n",
    "\n",
    "# ---------------- EEG ----------------\n",
    "EEG_NAME_HINTS = (\n",
    "    r\"^p(_?val(ue)?)?$\",         # p, pval, p_value\n",
    "    r\"^p_[a-z]+$\",               # p_alpha, p_beta, ...\n",
    "    r\"^[a-z]*_?p(_?val(ue)?)?$\", # col_p, pval_col, ...\n",
    ")\n",
    "def find_pcol(df):\n",
    "    cols = list(df.columns)\n",
    "    for pat in EEG_NAME_HINTS:\n",
    "        for c in cols:\n",
    "            if re.fullmatch(pat, str(c), flags=re.I): return c\n",
    "    candidates = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        s = s[np.isfinite(s)]\n",
    "        if s.size and (pd.Series(s).between(0,1).mean() > 0.95) and (pd.Series(s).nunique() > 10):\n",
    "            candidates.append((c, float(pd.Series(s).mean())))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[1])\n",
    "        return candidates[0][0]\n",
    "    return None\n",
    "\n",
    "def eeg_null_cols(df):\n",
    "    pats = (r\"^p_null_.*$\", r\".*_null$\")\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        for p in pats:\n",
    "            if re.fullmatch(p, str(c), flags=re.I):\n",
    "                cols.append(c); break\n",
    "    return cols\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\"); continue\n",
    "    pcol = find_pcol(df)\n",
    "    if pcol is None:\n",
    "        print(f\"[EEG:hint] {f} — add a 'p' column or p_null_* columns to enable FPR.\")\n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\").fillna(1.0).values\n",
    "    rej, q = benjamini_hochberg(p, alpha=0.01)\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    # Optional EEG FPR if null p-columns provided\n",
    "    nulls = eeg_null_cols(df)\n",
    "    eeg_fpr = np.nan\n",
    "    if nulls:\n",
    "        fp = 0\n",
    "        for nc in nulls:\n",
    "            pn = pd.to_numeric(df[nc], errors=\"coerce\").fillna(1.0).values\n",
    "            rnull, _ = benjamini_hochberg(pn, alpha=0.01)\n",
    "            if rnull.any(): fp += 1\n",
    "        eeg_fpr = fp / len(nulls)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)), tests=int(p.size),\n",
    "        FPR=(None if np.isnan(eeg_fpr) else float(eeg_fpr)),\n",
    "        pi0=float(pi0), FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# ---------------- Cooling ----------------\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\"); continue\n",
    "\n",
    "    has_phase = any(c.lower()==\"phase\" for c in df.columns)\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[Cooling:skip] {f} — no temperature-like column\"); continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    if temp.size < 2*MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — too few rows ({temp.size})\"); continue\n",
    "\n",
    "    if has_phase:\n",
    "        lab = df[[c for c in df.columns if c.lower()==\"phase\"][0]].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab==\"step\") | (lab==\"cool\") | (lab==\"1\") | (lab==\"true\") | (lab==\"post\")\n",
    "        base, step = temp[~step_idx], temp[step_idx]\n",
    "        # Re-orient so baseline is hotter (expect cooling: step <= base)\n",
    "        if np.mean(base) < np.mean(step):\n",
    "            base, step = step, base\n",
    "            flipped = True\n",
    "        else:\n",
    "            flipped = False\n",
    "        k, out_csv = np.nan, f\n",
    "    else:\n",
    "        k = best_change_point(temp, guard=GUARD_FRAC)\n",
    "        if k is None:\n",
    "            print(f\"[Cooling:skip] {f} — no robust change point\"); continue\n",
    "        base_raw, step_raw = temp[:k], temp[k:]\n",
    "        if np.mean(base_raw) < np.mean(step_raw):\n",
    "            base, step = step_raw, base_raw; flipped=True\n",
    "            mask = np.r_[np.zeros_like(step_raw, bool), np.ones_like(base_raw, bool)]\n",
    "        else:\n",
    "            base, step = base_raw, step_raw; flipped=False\n",
    "            mask = np.r_[np.zeros(k, bool), np.ones(len(temp)-k, bool)]\n",
    "        if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "            print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "        out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "        df2 = df.copy()\n",
    "        n = len(temp)\n",
    "        phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "        if len(df2) > n: phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "        df2[\"phase\"] = phase[:len(df2)]\n",
    "        df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Guards\n",
    "    if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "\n",
    "    dT = float(np.mean(step) - np.mean(base))  # negative means cooling\n",
    "    se = moving_block_bootstrap_se(base, step, B=MB_BOOT_B)\n",
    "    if not (np.isfinite(se) and se > 0): se = pooled_se(base, step)\n",
    "    if not (np.isfinite(se) and se > 0): se = 1e-9  # last-ditch jitter\n",
    "\n",
    "    z = dT / se\n",
    "    positive = int((dT <= DELTA_REQ) and (z <= -Z_CRIT))\n",
    "\n",
    "    # Label-shuffle null\n",
    "    allv = np.concatenate([base, step]); k_step = len(step); n_all = len(allv)\n",
    "    fp = 0\n",
    "    for _ in range(SHUFFLES):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se\n",
    "        if (dTN <= DELTA_REQ) and (zN <= -Z_CRIT):\n",
    "            fp += 1\n",
    "    fpr = fp / SHUFFLES\n",
    "    fpr_up95 = clopper_pearson_upper(fp, SHUFFLES, alpha=0.05)\n",
    "\n",
    "    cool_rows.append(dict(\n",
    "        module=\"Cooling\", file=f, labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=(None if (k is None or (isinstance(k, float) and np.isnan(k))) else int(k)),\n",
    "        flipped=bool(flipped),\n",
    "        dT=dT, z=z, zcrit=Z_CRIT,\n",
    "        positive=int(positive),\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95)\n",
    "    ))\n",
    "    audits.append(dict(\n",
    "        module=\"Cooling\", file=f,\n",
    "        positives=int(positive), tests=1,\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95),\n",
    "        dT=dT, z=z\n",
    "    ))\n",
    "\n",
    "# ---------------- Forecast ----------------\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\"); continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs ['alert','verified']\"); continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- GRA ----------------\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\"); continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs 'restored' & 'truth_pass'\"); continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth    = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- Save & print ----------------\n",
    "audit_df = pd.DataFrame(audits)\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "unified_path = OUT_DIR / f\"cnt_unified_fpr_report_{stamp}.csv\"\n",
    "if not audit_df.empty:\n",
    "    audit_df.to_csv(unified_path, index=False)\n",
    "    print(\"\\n== CNT Unified False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", unified_path)\n",
    "else:\n",
    "    print(\"\\n== No eligible items found to audit ==\")\n",
    "\n",
    "if cool_rows:\n",
    "    cool_df = pd.DataFrame(cool_rows)\n",
    "    cool_out = OUT_DIR / f\"cnt_cooling_fpr_detail_{stamp}.csv\"\n",
    "    cool_df.to_csv(cool_out, index=False)\n",
    "    print(\"\\n== Cooling Detail (with 95% bounds) ==\")\n",
    "    print(cool_df[[\"file\",\"dT\",\"z\",\"positive\",\"FPR\",\"FPR_upper95\"]].to_string(index=False))\n",
    "    print(\"\\nSaved:\", cool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b2a3a275-af14-4864-b7f0-b7b1f15dd765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[EEG] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv\n",
      "\n",
      "[Cooling] found 12 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv\n",
      "   ... +6 more\n",
      "\n",
      "[Forecast] found 0 file(s).\n",
      "\n",
      "[GRA] found 1 file(s).\n",
      " • C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-120551.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121130.csv — too few rows (0)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_cooling_log_20251015-121543_labeled.csv — too few rows (89)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-122141_labeled.csv — phase too short (base=32, step=186)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_gpu_cooling_log_20251015-123830_labeled.csv — phase too short (base=20, step=118)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-132627_labeled.csv — phase too short (base=46, step=266)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_detail_20251016-131416.csv — too few rows (2)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-104943.csv — too few rows (6)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_report_20251016-130627.csv — too few rows (4)\n",
      "[Cooling:skip] C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\summary_COOL_vectorized.csv — too few rows (4)\n",
      "\n",
      "== CNT Unified False-Positive Audit ==\n",
      " module                                                                                                                      file  positives  tests  FPR  pi0  FDR_alpha_0p01  FPR_upper95        dT         z  TP  FP  TN  FN\n",
      "    EEG C:\\Users\\caleb\\CNT_Lab\\artifacts\\pli_humans_100plus\\tests_functional\\motor_cuelocked\\lap_erd\\tables\\lap_erd_subject50.csv       50.0   50.0  NaN  0.0             1.0          NaN       NaN       NaN NaN NaN NaN NaN\n",
      "Cooling                                  C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled.csv        1.0    1.0  0.0  NaN             NaN     0.000599 -0.814411 -5.999538 NaN NaN NaN NaN\n",
      "Cooling                               C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled.csv        0.0    1.0  0.0  NaN             NaN     0.000599 -0.104633 -0.651198 NaN NaN NaN NaN\n",
      "    GRA    C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\gra_runs\\gra_v0_3_policy_fix_stem_20251016-095737\\policy_fix_stem_results.csv        NaN    NaN  NaN  NaN             NaN          NaN       NaN       NaN 2.0 0.0 0.0 0.0\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_20251016-133022.csv\n",
      "\n",
      "== Cooling Detail (with 95% bounds) ==\n",
      "                                                                                       file        dT         z  positive  FPR  FPR_upper95\n",
      "   C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_20251015-133429_labeled.csv -0.814411 -5.999538         1  0.0     0.000599\n",
      "C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_unified_cooling_v2_20251015-134310_labeled.csv -0.104633 -0.651198         0  0.0     0.000599\n",
      "\n",
      "Saved: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_detail_20251016-133022.csv\n"
     ]
    }
   ],
   "source": [
    "# == CNT Unified False-Positive Audit — Fused & Upgraded (Telos edition) ==\n",
    "# Cooling:\n",
    "#   • Prefer *_labeled.csv (ignore *_labeled_labeled.csv) or auto-label via robust change-point.\n",
    "#   • Re-orient labeled runs so 'baseline' is hotter (cooling expectation).\n",
    "#   • SE via moving-block bootstrap (autocorr-aware), fallback to pooled SE, jitter last-ditch.\n",
    "#   • Decision rule: ΔT <= -0.5 °C and z <= -2.58 (one-sided, conservative).\n",
    "#   • 5,000 label-shuffles for FPR + 95% Clopper–Pearson upper bound.\n",
    "# EEG:\n",
    "#   • Reports BH (FDR@0.01) + Storey π0; computes FPR if p_null_* columns exist.\n",
    "# GRA:\n",
    "#   • Confusion + FPR from 'restored' vs 'truth_pass'.\n",
    "# Forecast:\n",
    "#   • FPR from [alert, verified].\n",
    "# Outputs:\n",
    "#   • CNT_Lab\\artifacts\\metrics\\cnt_unified_fpr_report_YYYYMMDD-HHMMSS.csv\n",
    "#   • CNT_Lab\\artifacts\\metrics\\cnt_cooling_fpr_detail_YYYYMMDD-HHMMSS.csv\n",
    "\n",
    "import os, re, glob\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---------------- Config ----------------\n",
    "ROOTS = [\n",
    "    r\"C:\\Users\\caleb\\CNT_Lab\",\n",
    "    r\"C:\\Users\\caleb\\gra_runs\",\n",
    "]\n",
    "OUT_DIR = Path(ROOTS[0]) / \"artifacts\" / \"metrics\"\n",
    "OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Cooling params\n",
    "MIN_PHASE_N   = 60           # minimum samples per phase\n",
    "GUARD_FRAC    = 0.15         # avoid edges when choosing change point\n",
    "MB_BOOT_B     = 1200         # moving-block bootstrap draws\n",
    "MB_BLOCK_FRAC = 1/15         # block length ≈ phase_len * this\n",
    "SHUFFLES      = 5000         # label-shuffle draws for FPR\n",
    "Z_CRIT        = 2.58         # one-sided ~0.005; conservative vs 0.01 (2.326)\n",
    "DELTA_REQ     = -0.5         # °C threshold for \"cooling achieved\"\n",
    "\n",
    "rng = np.random.default_rng(42)\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def ls(pattern):\n",
    "    return [f for f in glob.glob(pattern, recursive=True) if os.path.isfile(f)]\n",
    "\n",
    "def show(label, files, limit=6):\n",
    "    print(f\"\\n[{label}] found {len(files)} file(s).\")\n",
    "    for f in files[:limit]: print(\" •\", f)\n",
    "    if len(files) > limit: print(f\"   ... +{len(files)-limit} more\")\n",
    "\n",
    "def benjamini_hochberg(pvals, alpha=0.05):\n",
    "    p = np.asarray(pd.Series(pvals).astype(float))\n",
    "    n = p.size if p is not None else 0\n",
    "    if n == 0:\n",
    "        return np.array([], dtype=bool), np.array([], dtype=float)\n",
    "    order = np.argsort(p)\n",
    "    ranks = np.empty_like(order); ranks[order] = np.arange(1, n+1)\n",
    "    q = p * n / np.maximum(ranks, 1)\n",
    "    q_sorted = np.minimum.accumulate(q[order][::-1])[::-1]\n",
    "    qvalues = np.empty_like(q_sorted); qvalues[order] = q_sorted\n",
    "    rej = qvalues <= alpha\n",
    "    return rej, qvalues\n",
    "\n",
    "def storey_pi0(p, lam=0.5):\n",
    "    \"\"\"\n",
    "    Storey's pi0 estimator with safe clamping.\n",
    "    pi0 = mean(p >= λ) / (1 - λ), clamped to [0,1].\n",
    "    \"\"\"\n",
    "    p = np.asarray(pd.Series(p).astype(float))\n",
    "    p = p[np.isfinite(p)]\n",
    "    if p.size == 0:\n",
    "        return np.nan\n",
    "    lam = float(lam)\n",
    "    if not (0.0 < lam < 1.0):\n",
    "        lam = 0.5\n",
    "    raw = np.mean(p >= lam) / (1.0 - lam)\n",
    "    raw = float(raw)\n",
    "    return max(0.0, min(1.0, raw))\n",
    "\n",
    "def clopper_pearson_upper(k, n, alpha=0.05):\n",
    "    if n == 0: return np.nan\n",
    "    if k == 0: return 1 - (alpha)**(1/n)\n",
    "    lo, hi = 0.0, 1.0\n",
    "    for _ in range(40):\n",
    "        mid = (lo+hi)/2\n",
    "        if n*mid >= k: hi = mid\n",
    "        else:          lo = mid\n",
    "    return hi\n",
    "\n",
    "# ---------------- Cooling helpers ----------------\n",
    "def pick_temp_col(df):\n",
    "    lo = {c.lower(): c for c in df.columns}\n",
    "    for key in (\"temp\",\"temperature\",\"gpu_temp\",\"cpu_temp\",\"t\",\"temp_c\"):\n",
    "        if key in lo: return lo[key]\n",
    "    num = [c for c in df.columns if pd.api.types.is_numeric_dtype(df[c])]\n",
    "    if not num: return None\n",
    "    v = pd.Series({c: pd.Series(df[c]).var(skipna=True) for c in num}).sort_values(ascending=False)\n",
    "    return v.index[0] if not v.empty else None\n",
    "\n",
    "def best_change_point(x, guard=0.15):\n",
    "    n = len(x)\n",
    "    lo = max(MIN_PHASE_N, int(n*guard))\n",
    "    hi = min(n - MIN_PHASE_N, int(n*(1-guard)))\n",
    "    if hi - lo < 1: return None\n",
    "    csum = np.cumsum(x, dtype=float)\n",
    "    best_k, best_score = None, -np.inf\n",
    "    for k in range(lo, hi+1):\n",
    "        m1 = csum[k-1] / k\n",
    "        m2 = (csum[-1] - csum[k-1]) / (n - k)\n",
    "        s = abs(m2 - m1)\n",
    "        if s > best_score: best_score, best_k = s, k\n",
    "    return best_k\n",
    "\n",
    "def moving_block_bootstrap_se(a, b, B=1200):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < MIN_PHASE_N or nb < MIN_PHASE_N: return np.nan\n",
    "    ba = max(5, int(round(na * MB_BLOCK_FRAC)))\n",
    "    bb = max(5, int(round(nb * MB_BLOCK_FRAC)))\n",
    "    diffs = []\n",
    "    for _ in range(B):\n",
    "        ia = rng.integers(0, na, size=max(2, na // ba))\n",
    "        ib = rng.integers(0, nb, size=max(2, nb // bb))\n",
    "        ra = np.concatenate([a[i:i+ba] if i+ba<=na else np.r_[a[i:], a[:(i+ba-na)]] for i in ia])[:na]\n",
    "        rb = np.concatenate([b[i:i+bb] if i+bb<=nb else np.r_[b[i:], b[:(i+bb-nb)]] for i in ib])[:nb]\n",
    "        diffs.append(float(np.mean(rb) - np.mean(ra)))\n",
    "    return float(np.std(diffs, ddof=1)) if diffs else np.nan\n",
    "\n",
    "def pooled_se(a, b):\n",
    "    na, nb = len(a), len(b)\n",
    "    if na < 2 or nb < 2: return np.nan\n",
    "    va, vb = float(np.var(a, ddof=1)), float(np.var(b, ddof=1))\n",
    "    return float(np.sqrt(va/na + vb/nb))\n",
    "\n",
    "# ---------------- Discover EEG/GRA/Forecast ----------------\n",
    "EEG_FILES, FORECAST_FILES, GRA_FILES = [], [], []\n",
    "for root in ROOTS:\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\lap_erd_subject*.csv\")\n",
    "    EEG_FILES += ls(fr\"{root}\\**\\pli_humans*\\**\\tables\\*laterality*.csv\")\n",
    "    FORECAST_FILES += ls(fr\"{root}\\**\\artifacts\\metrics\\forecast_alerts_*.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\policy_fix_stem_results.csv\")\n",
    "    GRA_FILES += ls(fr\"{root}\\**\\*_policy_*_results.csv\")\n",
    "\n",
    "# ---------------- Discover Cooling (prefer single-labeled; ignore double-labeled) ----------------\n",
    "ALL_COOL = []\n",
    "for root in ROOTS:\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\archive\\*cool*.csv\")\n",
    "    ALL_COOL += ls(fr\"{root}\\**\\artifacts\\**\\*cool*.csv\")\n",
    "\n",
    "by_stem = {}\n",
    "for f in ALL_COOL:\n",
    "    p = Path(f)\n",
    "    key = re.sub(r\"(?:_labeled)+\\.csv$\", \".csv\", p.name, flags=re.I)  # normalize labeled clusters\n",
    "    by_stem.setdefault((p.parent, key), []).append(p)\n",
    "\n",
    "COOL_FILES = []\n",
    "for (parent, key), files in by_stem.items():\n",
    "    single_labeled = [x for x in files if re.search(r\"(?<!_labeled)_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    multi_labeled  = [x for x in files if re.search(r\"_labeled_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    raw            = [x for x in files if not re.search(r\"_labeled\\.csv$\", x.name, flags=re.I)]\n",
    "    if single_labeled:\n",
    "        COOL_FILES.append(str(sorted(single_labeled)[-1]))\n",
    "    elif raw:\n",
    "        COOL_FILES.append(str(sorted(raw)[-1]))\n",
    "    elif multi_labeled:\n",
    "        COOL_FILES.append(str(sorted(multi_labeled)[-1]))\n",
    "\n",
    "show(\"EEG\", EEG_FILES)\n",
    "show(\"Cooling\", COOL_FILES)\n",
    "show(\"Forecast\", FORECAST_FILES)\n",
    "show(\"GRA\", GRA_FILES)\n",
    "\n",
    "audits = []\n",
    "cool_rows = []\n",
    "\n",
    "# ---------------- EEG ----------------\n",
    "EEG_NAME_HINTS = (\n",
    "    r\"^p(_?val(ue)?)?$\",         # p, pval, p_value\n",
    "    r\"^p_[a-z]+$\",               # p_alpha, p_beta, ...\n",
    "    r\"^[a-z]*_?p(_?val(ue)?)?$\", # col_p, pval_col, ...\n",
    ")\n",
    "def find_pcol(df):\n",
    "    cols = list(df.columns)\n",
    "    for pat in EEG_NAME_HINTS:\n",
    "        for c in cols:\n",
    "            if re.fullmatch(pat, str(c), flags=re.I): return c\n",
    "    candidates = []\n",
    "    for c in cols:\n",
    "        s = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "        s = s[np.isfinite(s)]\n",
    "        if s.size and (pd.Series(s).between(0,1).mean() > 0.95) and (pd.Series(s).nunique() > 10):\n",
    "            candidates.append((c, float(pd.Series(s).mean())))\n",
    "    if candidates:\n",
    "        candidates.sort(key=lambda x: x[1])\n",
    "        return candidates[0][0]\n",
    "    return None\n",
    "\n",
    "def eeg_null_cols(df):\n",
    "    pats = (r\"^p_null_.*$\", r\".*_null$\")\n",
    "    cols = []\n",
    "    for c in df.columns:\n",
    "        for p in pats:\n",
    "            if re.fullmatch(p, str(c), flags=re.I):\n",
    "                cols.append(c); break\n",
    "    return cols\n",
    "\n",
    "for f in EEG_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[EEG:skip] {f} — read error: {e}\"); continue\n",
    "    pcol = find_pcol(df)\n",
    "    if pcol is None:\n",
    "        print(f\"[EEG:hint] {f} — add a 'p' column or p_null_* columns to enable FPR.\")\n",
    "        continue\n",
    "    p = pd.to_numeric(df[pcol], errors=\"coerce\").fillna(1.0).values\n",
    "    rej, q = benjamini_hochberg(p, alpha=0.01)\n",
    "    pi0 = storey_pi0(p, lam=0.5)\n",
    "    nulls = eeg_null_cols(df)\n",
    "    eeg_fpr = np.nan\n",
    "    if nulls:\n",
    "        fp = 0\n",
    "        for nc in nulls:\n",
    "            pn = pd.to_numeric(df[nc], errors=\"coerce\").fillna(1.0).values\n",
    "            rnull, _ = benjamini_hochberg(pn, alpha=0.01)\n",
    "            if rnull.any(): fp += 1\n",
    "        eeg_fpr = fp / len(nulls)\n",
    "    audits.append(dict(\n",
    "        module=\"EEG\", file=f,\n",
    "        positives=int(np.sum(rej)), tests=int(p.size),\n",
    "        FPR=(None if np.isnan(eeg_fpr) else float(eeg_fpr)),\n",
    "        pi0=float(pi0), FDR_alpha_0p01=float(np.mean(q < 0.01))\n",
    "    ))\n",
    "\n",
    "# ---------------- Cooling ----------------\n",
    "for f in COOL_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Cooling:skip] {f} — read error: {e}\"); continue\n",
    "\n",
    "    has_phase = any(c.lower()==\"phase\" for c in df.columns)\n",
    "\n",
    "    tcol = pick_temp_col(df)\n",
    "    if tcol is None:\n",
    "        print(f\"[Cooling:skip] {f} — no temperature-like column\"); continue\n",
    "\n",
    "    temp = pd.to_numeric(df[tcol], errors=\"coerce\")\n",
    "    temp = temp[np.isfinite(temp)].values\n",
    "    if temp.size < 2*MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — too few rows ({temp.size})\"); continue\n",
    "\n",
    "    if has_phase:\n",
    "        lab = df[[c for c in df.columns if c.lower()==\"phase\"][0]].astype(str).str.lower().values[:len(temp)]\n",
    "        step_idx = (lab==\"step\") | (lab==\"cool\") | (lab==\"1\") | (lab==\"true\") | (lab==\"post\")\n",
    "        base, step = temp[~step_idx], temp[step_idx]\n",
    "        # Re-orient so baseline is hotter (expect cooling: step <= base)\n",
    "        if np.mean(base) < np.mean(step):\n",
    "            base, step = step, base\n",
    "            flipped = True\n",
    "        else:\n",
    "            flipped = False\n",
    "        k, out_csv = np.nan, f\n",
    "    else:\n",
    "        k = best_change_point(temp, guard=GUARD_FRAC)\n",
    "        if k is None:\n",
    "            print(f\"[Cooling:skip] {f} — no robust change point\"); continue\n",
    "        base_raw, step_raw = temp[:k], temp[k:]\n",
    "        if np.mean(base_raw) < np.mean(step_raw):\n",
    "            base, step = step_raw, base_raw; flipped=True\n",
    "            mask = np.r_[np.zeros_like(step_raw, bool), np.ones_like(base_raw, bool)]\n",
    "        else:\n",
    "            base, step = base_raw, step_raw; flipped=False\n",
    "            mask = np.r_[np.zeros(k, bool), np.ones(len(temp)-k, bool)]\n",
    "        if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "            print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "        out_csv = f.replace(\".csv\", \"_labeled.csv\")\n",
    "        df2 = df.copy()\n",
    "        n = len(temp)\n",
    "        phase = np.where(mask[:n], \"step\", \"baseline\")\n",
    "        if len(df2) > n: phase = np.r_[phase, np.repeat(phase[-1], len(df2)-n)]\n",
    "        df2[\"phase\"] = phase[:len(df2)]\n",
    "        df2.to_csv(out_csv, index=False)\n",
    "\n",
    "    if len(base) < MIN_PHASE_N or len(step) < MIN_PHASE_N:\n",
    "        print(f\"[Cooling:skip] {f} — phase too short (base={len(base)}, step={len(step)})\"); continue\n",
    "\n",
    "    dT = float(np.mean(step) - np.mean(base))  # negative means cooling\n",
    "    se = moving_block_bootstrap_se(base, step, B=MB_BOOT_B)\n",
    "    if not (np.isfinite(se) and se > 0): se = pooled_se(base, step)\n",
    "    if not (np.isfinite(se) and se > 0): se = 1e-9  # last-ditch jitter\n",
    "\n",
    "    z = dT / se\n",
    "    positive = int((dT <= DELTA_REQ) and (z <= -Z_CRIT))\n",
    "\n",
    "    # Label-shuffle null\n",
    "    allv = np.concatenate([base, step]); k_step = len(step); n_all = len(allv)\n",
    "    fp = 0\n",
    "    for _ in range(SHUFFLES):\n",
    "        idx = rng.permutation(n_all)\n",
    "        sN = allv[idx[:k_step]]; bN = allv[idx[k_step:]]\n",
    "        dTN = float(np.mean(sN) - np.mean(bN))\n",
    "        zN = dTN / se\n",
    "        if (dTN <= DELTA_REQ) and (zN <= -Z_CRIT):\n",
    "            fp += 1\n",
    "    fpr = fp / SHUFFLES\n",
    "    fpr_up95 = clopper_pearson_upper(fp, SHUFFLES, alpha=0.05)\n",
    "\n",
    "    cool_rows.append(dict(\n",
    "        module=\"Cooling\", file=f, labeled_csv=out_csv,\n",
    "        n_base=len(base), n_step=len(step),\n",
    "        change_point=(None if (k is None or (isinstance(k, float) and np.isnan(k))) else int(k)),\n",
    "        flipped=bool(flipped),\n",
    "        dT=dT, z=z, zcrit=Z_CRIT,\n",
    "        positive=int(positive),\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95)\n",
    "    ))\n",
    "    audits.append(dict(\n",
    "        module=\"Cooling\", file=f,\n",
    "        positives=int(positive), tests=1,\n",
    "        FPR=float(fpr), FPR_upper95=float(fpr_up95),\n",
    "        dT=dT, z=z\n",
    "    ))\n",
    "\n",
    "# ---------------- Forecast ----------------\n",
    "for f in FORECAST_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[Forecast:skip] {f} — read error: {e}\"); continue\n",
    "    if not {\"alert\",\"verified\"}.issubset(df.columns):\n",
    "        print(f\"[Forecast:skip] {f} — needs ['alert','verified']\"); continue\n",
    "    tp = int(((df[\"alert\"]==1) & (df[\"verified\"]==1)).sum())\n",
    "    fp = int(((df[\"alert\"]==1) & (df[\"verified\"]==0)).sum())\n",
    "    tn = int(((df[\"alert\"]==0) & (df[\"verified\"]==0)).sum())\n",
    "    fn = int(((df[\"alert\"]==0) & (df[\"verified\"]==1)).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"Forecast\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- GRA ----------------\n",
    "for f in GRA_FILES:\n",
    "    try:\n",
    "        df = pd.read_csv(f)\n",
    "    except Exception as e:\n",
    "        print(f\"[GRA:skip] {f} — read error: {e}\"); continue\n",
    "    cols = {c.lower(): c for c in df.columns}\n",
    "    if not ((\"restored\" in cols) and (\"truth_pass\" in cols)):\n",
    "        print(f\"[GRA:skip] {f} — needs 'restored' & 'truth_pass'\"); continue\n",
    "    restored = df[cols[\"restored\"]].astype(bool)\n",
    "    truth    = df[cols[\"truth_pass\"]].astype(bool)\n",
    "    tp = int((restored & truth).sum())\n",
    "    fp = int((restored & ~truth).sum())\n",
    "    tn = int((~restored & ~truth).sum())\n",
    "    fn = int((~restored & truth).sum())\n",
    "    fpr = (fp / (fp+tn)) if (fp+tn)>0 else np.nan\n",
    "    audits.append(dict(module=\"GRA\", file=f, TP=tp, FP=fp, TN=tn, FN=fn, FPR=(None if np.isnan(fpr) else float(fpr))))\n",
    "\n",
    "# ---------------- Save & print ----------------\n",
    "audit_df = pd.DataFrame(audits)\n",
    "stamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "unified_path = OUT_DIR / f\"cnt_unified_fpr_report_{stamp}.csv\"\n",
    "if not audit_df.empty:\n",
    "    audit_df.to_csv(unified_path, index=False)\n",
    "    print(\"\\n== CNT Unified False-Positive Audit ==\")\n",
    "    print(audit_df.to_string(index=False))\n",
    "    print(\"\\nSaved:\", unified_path)\n",
    "else:\n",
    "    print(\"\\n== No eligible items found to audit ==\")\n",
    "\n",
    "if cool_rows:\n",
    "    cool_df = pd.DataFrame(cool_rows)\n",
    "    cool_out = OUT_DIR / f\"cnt_cooling_fpr_detail_{stamp}.csv\"\n",
    "    cool_df.to_csv(cool_out, index=False)\n",
    "    print(\"\\n== Cooling Detail (with 95% bounds) ==\")\n",
    "    print(cool_df[[\"file\",\"dT\",\"z\",\"positive\",\"FPR\",\"FPR_upper95\"]].to_string(index=False))\n",
    "    print(\"\\nSaved:\", cool_out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81bdc7c-2fe9-470d-8ed5-cbf398307683",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
