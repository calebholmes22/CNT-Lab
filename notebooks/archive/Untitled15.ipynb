{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2192f03e-3837-43e2-9f05-d3a7d5722654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not import regions, which is required for some of the functionalities of this module.\n",
      "[CNT] Techno-Anomaly v0 starting @ 20251016-173536  (RA=210.0, Dec=-0.5, R=0.8°)\n",
      "[info] Gaia rows: 50  |  XMatch rows: 28\n",
      "[save] cnt_anomaly\\out\\tile_raw_20251016-173536.csv\n",
      "[done] Views: ['V1_raw_robust', 'V2_colors_std', 'V3_log_reordered', 'V4_jitter', 'V5_mixed']\n",
      "[done] Stable anomalies (votes ≥ 4): 1\n",
      "[save] all: cnt_anomaly\\out\\tile_with_votes_20251016-173536.csv\n",
      "[save] stable: cnt_anomaly\\out\\stable_anomalies_20251016-173536.csv\n",
      "Figures: cnt_anomaly\\out\\figures\n",
      "[time] 9.7s\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly v0 — Gauge-Invariant Screen (Gaia DR3 × AllWISE)\n",
    "# Telos × Aetheron — Jupyter mega-cell\n",
    "# ---------------------------------------------------------------\n",
    "# What it does\n",
    "# 1) Pulls a small sky field from Gaia DR3, crossmatches with AllWISE (IR).\n",
    "# 2) Builds IR-excess & SED-slope features, absolute mags where possible.\n",
    "# 3) Runs multiple anomaly detectors across multiple symbol-preserving transforms.\n",
    "# 4) Reports only \"stable anomalies\" = flagged across ≥ K of the transforms.\n",
    "# 5) Saves a reproducible bundle (CSV + plots) to ./cnt_anomaly/out/.\n",
    "\n",
    "import os, sys, math, time, json, warnings, io\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ---- Config (edit these safely) --------------------------------\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE  = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SEED = 42\n",
    "N_MAX = 3000          # cap to keep runs snappy; raise (e.g., 15000) when stable\n",
    "RA, DEC, RADIUS_DEG = 210.0, -0.5, 0.8   # sky tile (RA/Dec in deg); change freely\n",
    "XMM_RADIUS_ARCSEC = 1.0                  # crossmatch radius\n",
    "K_STABILITY = 4                          # require anomaly in ≥ K transforms\n",
    "\n",
    "# Model knobs\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01        # expected anomaly rate (1%); tune if needed\n",
    "\n",
    "# ---- Imports (with auto-install) -------------------------------\n",
    "def pip_install(pkgs):\n",
    "    import subprocess, sys\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *pkgs])\n",
    "\n",
    "for pkg in [\"astroquery\", \"pyvo\", \"scikit-learn\", \"matplotlib\"]:\n",
    "    try:\n",
    "        __import__(pkg.replace(\"-\", \"_\"))\n",
    "    except Exception:\n",
    "        pip_install([pkg])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(SEED)\n",
    "\n",
    "# ---- Helpers ----------------------------------------------------\n",
    "def save_csv(df, name):\n",
    "    p = OUTDIR / name\n",
    "    df.to_csv(p, index=False)\n",
    "    return p\n",
    "\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=N_MAX):\n",
    "    Vizier.ROW_LIMIT = row_limit\n",
    "    if columns is None:\n",
    "        v = Vizier(columns=[\"**\"])\n",
    "    else:\n",
    "        v = Vizier(columns=columns)\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec=XMM_RADIUS_ARCSEC):\n",
    "    # Upload Gaia positions to CDS XMatch against AllWISE (VizieR: II/328/allwise)\n",
    "    if gaia_df.empty: \n",
    "        return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(\n",
    "        columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO()\n",
    "    t.write(buf, format=\"votable\")\n",
    "    buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf,\n",
    "                      cat2='vizier:II/328/allwise',\n",
    "                      max_distance=radius_arcsec * u.arcsec,\n",
    "                      colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    # Merge back Gaia columns by nearest (indices are aligned by XMatch output order)\n",
    "    # We'll re-join by ra/dec approximation\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    # small correction: ensure close in Dec too\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    # Clean column names\n",
    "    merged = merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "    return merged\n",
    "\n",
    "def clean_photometry(df):\n",
    "    # Rename common columns if present\n",
    "    ren = {\n",
    "        \"Gmag\":\"G\", \"BP-RP\":\"BP_RP\",\n",
    "        \"pmRA\":\"pmRA\", \"pmDE\":\"pmDE\",\n",
    "        \"W1mag\":\"W1\", \"W2mag\":\"W2\", \"W3mag\":\"W3\", \"W4mag\":\"W4\",\n",
    "        \"e_W1mag\":\"eW1\", \"e_W2mag\":\"eW2\", \"e_W3mag\":\"eW3\", \"e_W4mag\":\"eW4\",\n",
    "    }\n",
    "    for k,v in ren.items():\n",
    "        if k in df.columns: df[v] = df[k]\n",
    "    # Drop obvious junk\n",
    "    df = df.replace([np.inf, -np.inf], np.nan)\n",
    "    return df\n",
    "\n",
    "def add_derived_features(df):\n",
    "    d = df.copy()\n",
    "    # Colors (IR excess)\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d:\n",
    "            d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    # Gaia absolute magnitude (if parallax>0)\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    # Crude SED slope (W1→W3)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"]) / 2.0\n",
    "    # Proper motion norm (helps reject moving Solar System objects)\n",
    "    if \"pmRA\" in d and \"pmDE\" in d:\n",
    "        d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    # Quality flags (when present)\n",
    "    for q in [\"ccf\",\"var_flg\",\"ext_flg\",\"ph_qual\"]:\n",
    "        if q in d: d[q] = d[q].astype(str)\n",
    "    return d\n",
    "\n",
    "def make_feature_views(df):\n",
    "    # Build multiple symbol-preserving transforms (\"gauges\"):\n",
    "    #   raw mags/colors, standardized, reordered, jitter-resilient, and log-mix.\n",
    "    numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "    keep_cols = [c for c in numeric.columns if c not in [\"dist_pc\"]]  # dist often NaN if parallax<=0\n",
    "    X0 = numeric[keep_cols].fillna(numeric[keep_cols].median())\n",
    "\n",
    "    views = {}\n",
    "    # V1: direct robust-scaled colors+mags subset\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"G\",\"BP_RP\",\"MG\",\"SED_slope\",\"pm_norm\"))]\n",
    "    cols1 = [c for c in cols1 if not c.startswith((\"eW\"))]\n",
    "    scaler1 = RobustScaler()\n",
    "    views[\"V1_raw_robust\"] = scaler1.fit_transform(X0[cols1]) if len(cols1)>0 else None\n",
    "\n",
    "    # V2: colors only (unit-invariant), standardized\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c in [\"BP_RP\",\"SED_slope_W1_W3\"]]\n",
    "    scaler2 = StandardScaler()\n",
    "    views[\"V2_colors_std\"] = scaler2.fit_transform(X0[cols2]) if len(cols2)>0 else None\n",
    "\n",
    "    # V3: log(positive mags shifted) + re-ordered\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if len(cols3)>0:\n",
    "        X3 = X0[cols3].copy()\n",
    "        X3 = X3 - X3.min().min() + 1e-3\n",
    "        X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "\n",
    "    # V4: jitter-resilient (median-imputed + small noise)\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    cols4 = list(set(cols1+cols2))\n",
    "    if len(cols4)>0:\n",
    "        X4 = X0[cols4].copy()\n",
    "        X4 = X4 + rng.normal(0, 1e-3, size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "\n",
    "    # V5: mixed stats (robust+standard concatenation where possible)\n",
    "    if len(cols1)>0 and len(cols2)>0:\n",
    "        X5a = scaler1.fit_transform(X0[cols1])\n",
    "        X5b = scaler2.fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "\n",
    "    colmaps = {\"V1\":cols1, \"V2\":cols2, \"V3\":cols3, \"V4\":cols4, \"V5\":list(set(cols1+cols2))}\n",
    "    return views, colmaps\n",
    "\n",
    "def run_anomaly_ensemble(views):\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    flags = {}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: \n",
    "            continue\n",
    "        # Two families: IsolationForest + LocalOutlierFactor\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng)\n",
    "        iso.fit(X)\n",
    "        iso_flag = (iso.predict(X) == -1)\n",
    "\n",
    "        # LOF (use novelty-like score via fit_predict)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            lof_flag = (lof.fit_predict(X) == -1)\n",
    "        except Exception:\n",
    "            lof_flag = np.zeros(X.shape[0], dtype=bool)\n",
    "\n",
    "        flags[name] = iso_flag | lof_flag\n",
    "    return flags\n",
    "\n",
    "def stability_vote(flags):\n",
    "    # Count how many views flagged each row\n",
    "    names = list(flags.keys())\n",
    "    if not names: \n",
    "        return None, None\n",
    "    M = np.vstack([flags[n].astype(int) for n in names])  # [views, N]\n",
    "    votes = M.sum(axis=0)\n",
    "    return votes, names\n",
    "\n",
    "def plot_top_candidates(df, votes, names, topn=12):\n",
    "    idx = np.argsort(-votes)[:topn]\n",
    "    sel = df.iloc[idx].copy()\n",
    "    figdir = OUTDIR / \"figures\"; figdir.mkdir(exist_ok=True, parents=True)\n",
    "    # Simple SED-like strips\n",
    "    for i, (_, r) in enumerate(sel.iterrows(), 1):\n",
    "        mags = []; bands = []\n",
    "        for b in [\"G\",\"W1\",\"W2\",\"W3\",\"W4\"]:\n",
    "            if b in r and pd.notna(r[b]): \n",
    "                mags.append(r[b]); bands.append(b)\n",
    "        if len(mags) < 3: \n",
    "            continue\n",
    "        plt.figure(figsize=(4,3))\n",
    "        plt.plot(range(len(mags)), mags, marker=\"o\")\n",
    "        plt.xticks(range(len(mags)), bands)\n",
    "        plt.gca().invert_yaxis()\n",
    "        plt.title(f\"Candidate #{i}  votes={int(votes[idx[i-1]])}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(figdir / f\"candidate_{i:02d}.png\", dpi=150)\n",
    "        plt.close()\n",
    "    return sel\n",
    "\n",
    "# ---- Main pipeline ---------------------------------------------\n",
    "t0 = time.time()\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "print(f\"[CNT] Techno-Anomaly v0 starting @ {stamp}  (RA={RA}, Dec={DEC}, R={RADIUS_DEG}°)\")\n",
    "\n",
    "gaia_cache = CACHE / f\"gaia_{RA}_{DEC}_{RADIUS_DEG}.csv\"\n",
    "wise_cache = CACHE / f\"gaiaxwise_{RA}_{DEC}_{RADIUS_DEG}.csv\"\n",
    "\n",
    "# Step 1: Gaia tile\n",
    "if gaia_cache.exists():\n",
    "    gaia = pd.read_csv(gaia_cache)\n",
    "else:\n",
    "    # Gaia DR3 via VizieR: I/355/gaiadr3\n",
    "    gaia = vizier_query(\"I/355/gaiadr3\", RA, DEC, RADIUS_DEG,\n",
    "                        columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                        row_limit=N_MAX)\n",
    "    gaia.to_csv(gaia_cache, index=False)\n",
    "\n",
    "# Step 2: XMatch to AllWISE\n",
    "if wise_cache.exists():\n",
    "    gaia_wise = pd.read_csv(wise_cache)\n",
    "else:\n",
    "    if len(gaia)==0:\n",
    "        raise RuntimeError(\"Gaia query returned 0 rows; try a different tile or larger radius.\")\n",
    "    gaia_wise = xmatch_gaia_allwise(gaia)\n",
    "    gaia_wise.to_csv(wise_cache, index=False)\n",
    "\n",
    "print(f\"[info] Gaia rows: {len(gaia):,}  |  XMatch rows: {len(gaia_wise):,}\")\n",
    "\n",
    "# Step 3: Feature engineering\n",
    "df = clean_photometry(gaia_wise)\n",
    "df = add_derived_features(df)\n",
    "raw_csv = save_csv(df, f\"tile_raw_{stamp}.csv\")\n",
    "print(\"[save]\", raw_csv)\n",
    "\n",
    "# Step 4: Build multi-view features + anomaly ensemble\n",
    "views, colmaps = make_feature_views(df)\n",
    "flags = run_anomaly_ensemble(views)\n",
    "votes, names = stability_vote(flags)\n",
    "if votes is None:\n",
    "    raise RuntimeError(\"No usable feature views were constructed; check tile or data coverage.\")\n",
    "\n",
    "df[\"_votes\"] = votes\n",
    "df[\"_is_stable_anom\"] = df[\"_votes\"] >= K_STABILITY\n",
    "stable = df[df[\"_is_stable_anom\"]].copy()\n",
    "\n",
    "# Step 5: Export & plots\n",
    "stable_cols = [\"ra_deg\",\"dec\",\"G\",\"BP_RP\",\"parallax\",\"MG\",\"W1\",\"W2\",\"W3\",\"W4\",\n",
    "               \"W1-W2\",\"W2-W3\",\"W3-W4\",\"SED_slope_W1_W3\",\"pm_norm\",\"_votes\"]\n",
    "stable = stable[[c for c in stable_cols if c in stable.columns]]\n",
    "top_show = min(12, len(stable))\n",
    "sel = plot_top_candidates(df, votes, names, topn=top_show)\n",
    "\n",
    "bundle = {\n",
    "  \"tile_center\": {\"RA\": RA, \"Dec\": DEC, \"radius_deg\": RADIUS_DEG},\n",
    "  \"crossmatch_radius_arcsec\": XMM_RADIUS_ARCSEC,\n",
    "  \"views\": {k: colmaps[k[:2]] if k[:2] in colmaps else [] for k in views.keys()},\n",
    "  \"models\": {\"IsolationForest\": {\"n_estimators\": N_ESTIMATORS, \"contamination\": CONTAM},\n",
    "             \"LOF\": {\"neighbors\": 35, \"contamination\": CONTAM}},\n",
    "  \"stability_rule\": f\"flag if votes >= {K_STABILITY} across transforms\",\n",
    "  \"seed\": SEED,\n",
    "  \"run_stamp\": stamp\n",
    "}\n",
    "with open(OUTDIR / f\"run_{stamp}.json\",\"w\") as f:\n",
    "    json.dump(bundle, f, indent=2)\n",
    "\n",
    "out_all = save_csv(df, f\"tile_with_votes_{stamp}.csv\")\n",
    "out_stable = save_csv(stable, f\"stable_anomalies_{stamp}.csv\")\n",
    "\n",
    "print(f\"[done] Views: {list(views.keys())}\")\n",
    "print(f\"[done] Stable anomalies (votes ≥ {K_STABILITY}): {len(stable):,}\")\n",
    "print(\"[save] all:\", out_all)\n",
    "print(\"[save] stable:\", out_stable)\n",
    "print(\"Figures:\", OUTDIR/\"figures\")\n",
    "print(f\"[time] {time.time()-t0:0.1f}s\")\n",
    "\n",
    "# ---- What \"good\" looks like ------------------------------------\n",
    "# - Nonzero stable anomalies with clearly red IR colors (e.g., W1-W2 > ~0.8)\n",
    "# - Reasonable parallax or large pm_norm for nearby dusty objects (to reject SS bodies)\n",
    "# - Candidates that persist when you tweak K_STABILITY or CONTAM slightly\n",
    "# Next: aggregate multiple tiles; add WISE quality flags (ph_qual) filters;\n",
    "#       export a short-list for manual vetting or cross-check with SIMBAD names.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9825e5dd-5d97-4edd-aa33-701a485e3d3a",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1609326779.py, line 1)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mpython -m pip install regions\u001b[39m\n              ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "python -m pip install regions\n",
    "# if you ever use image cutouts:\n",
    "python -m pip install astrocut\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a0db421-791e-480b-af67-eb8a202d7982",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[env] Python exe: C:\\Users\\caleb\\CNT_Lab\\.venv\\Scripts\\python.exe\n",
      "[env] pip used:  C:\\Users\\caleb\\CNT_Lab\\.venv\\Scripts\\pip.EXE\n",
      "[run] C:\\Users\\caleb\\CNT_Lab\\.venv\\Scripts\\python.exe -m pip install --upgrade regions>=0.7 astrocut>=0.11\n",
      "\n",
      "== Install check ==\n",
      "regions  : OK — 0.10\n",
      "astrocut : OK — 1.1.0\n",
      "\n",
      "If Jupyter still shows the 'Could not import regions' warning, do: Kernel → Restart.\n"
     ]
    }
   ],
   "source": [
    "# CNT Astro add-ons — installer & smoke test\n",
    "# Installs: regions (required), astrocut (optional but handy for cutouts)\n",
    "import sys, subprocess, importlib, shutil\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    print(f\"[env] Python exe: {sys.executable}\")\n",
    "    pip = shutil.which(\"pip\") or sys.executable\n",
    "    print(f\"[env] pip used:  {pip}\")\n",
    "    cmd = [sys.executable, \"-m\", \"pip\", \"install\", \"--upgrade\", *pkgs]\n",
    "    print(\"[run]\", \" \".join(cmd))\n",
    "    subprocess.check_call(cmd)\n",
    "\n",
    "# --- install ---\n",
    "pip_install([\n",
    "    \"regions>=0.7\",\n",
    "    \"astrocut>=0.11\"   # optional; safe to keep\n",
    "])\n",
    "\n",
    "# --- smoke test ---\n",
    "results = {}\n",
    "for name in [\"regions\", \"astrocut\"]:\n",
    "    try:\n",
    "        m = importlib.import_module(name)\n",
    "        ver = getattr(m, \"__version__\", \"OK (no __version__)\")\n",
    "        results[name] = f\"OK — {ver}\"\n",
    "    except Exception as e:\n",
    "        results[name] = f\"IMPORT ERROR — {e!r}\"\n",
    "\n",
    "print(\"\\n== Install check ==\")\n",
    "for k, v in results.items():\n",
    "    print(f\"{k:9s}: {v}\")\n",
    "\n",
    "print(\"\\nIf Jupyter still shows the 'Could not import regions' warning, do: Kernel → Restart.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "938f0259-9806-48fa-ae4c-605fcbbd654f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading: cnt_anomaly\\out\\stable_anomalies_20251016-173536.csv\n",
      "Quality-pass candidates: 0/1\n",
      "Saved annotated: cnt_anomaly\\out\\stable_annotated_20251016-173536.csv\n",
      "SED thumbs written to: cnt_anomaly\\out\\figures\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Candidate Annotator (SIMBAD + Quality filters)\n",
    "import os, re, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\")\n",
    "shortlist = sorted(OUTDIR.glob(\"stable_anomalies_*.csv\"))\n",
    "assert shortlist, \"No stable_anomalies_*.csv found. Run the main cell first.\"\n",
    "csv_path = shortlist[-1]\n",
    "print(\"Reading:\", csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# —— Optional quality filters (tighten to reduce false positives)\n",
    "# keep good WISE photometry & point-like (if available)\n",
    "for q in [\"ph_qual\", \"ext_flg\"]:\n",
    "    if q not in df.columns:\n",
    "        df[q] = np.nan\n",
    "mask_quality = np.full(len(df), True)\n",
    "# ph_qual: require A or B in W1 and W2 if present\n",
    "def ok_phqual(s):\n",
    "    s = str(s)\n",
    "    # pattern like 'AAA?' per band; accept cases where W1/W2 are A/B\n",
    "    return (\"A\" in s[:2]) or (\"B\" in s[:2])\n",
    "mask_quality &= df[\"ph_qual\"].apply(ok_phqual)\n",
    "\n",
    "# ext_flg: prefer 0 (point-like) when present\n",
    "mask_quality &= ((df[\"ext_flg\"].isna()) | (df[\"ext_flg\"].astype(str).isin([\"0\",\"nan\"])))\n",
    "\n",
    "df_q = df[mask_quality].copy()\n",
    "print(f\"Quality-pass candidates: {len(df_q)}/{len(df)}\")\n",
    "\n",
    "# —— SIMBAD lookup (2 arcsec radius)\n",
    "custom = Simbad()\n",
    "custom.add_votable_fields(\"otype\",\"sp\",\"flux(V)\",\"flux(B)\",\"ids\")\n",
    "rows = []\n",
    "for i, r in df_q.reset_index(drop=True).iterrows():\n",
    "    ra = r.get(\"ra_deg\") or r.get(\"ra\") or r.get(\"RA_ICRS\") or np.nan\n",
    "    dec = r.get(\"dec\") or r.get(\"DE_ICRS\") or np.nan\n",
    "    if not np.isfinite(ra) or not np.isfinite(dec):\n",
    "        rows.append({**r.to_dict(), \"simbad_match\": False})\n",
    "        continue\n",
    "    coord = SkyCoord(ra*u.deg, dec*u.deg, frame=\"icrs\")\n",
    "    try:\n",
    "        res = custom.query_region(coord, radius=2*u.arcsec)\n",
    "    except Exception as e:\n",
    "        print(\"SIMBAD query error:\", e)\n",
    "        res = None\n",
    "    if res is None or len(res)==0:\n",
    "        rows.append({**r.to_dict(), \"simbad_match\": False})\n",
    "        continue\n",
    "    # take nearest\n",
    "    res = res.to_pandas().iloc[0]\n",
    "    rows.append({\n",
    "        **r.to_dict(),\n",
    "        \"simbad_match\": True,\n",
    "        \"simbad_main_id\": res.get(\"MAIN_ID\", \"\"),\n",
    "        \"simbad_otype\": res.get(\"OTYPE\", \"\"),\n",
    "        \"simbad_sp\": res.get(\"SP_TYPE\", \"\"),\n",
    "        \"simbad_fluxV\": res.get(\"FLUX_V\", np.nan),\n",
    "        \"simbad_fluxB\": res.get(\"FLUX_B\", np.nan),\n",
    "    })\n",
    "\n",
    "annot = pd.DataFrame(rows)\n",
    "annot_path = OUTDIR / (csv_path.stem.replace(\"stable_anomalies_\", \"stable_annotated_\") + \".csv\")\n",
    "annot.to_csv(annot_path, index=False)\n",
    "print(\"Saved annotated:\", annot_path)\n",
    "\n",
    "# —— Tiny SED plots for quick eyeballing\n",
    "figdir = OUTDIR / \"figures\"; figdir.mkdir(exist_ok=True, parents=True)\n",
    "bands = [\"G\",\"W1\",\"W2\",\"W3\",\"W4\"]\n",
    "for j, r in annot.iterrows():\n",
    "    mags, used = [], []\n",
    "    for b in bands:\n",
    "        if b in r and pd.notna(r[b]): \n",
    "            mags.append(r[b]); used.append(b)\n",
    "    if len(used) < 3:\n",
    "        continue\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.plot(range(len(used)), mags, marker=\"o\")\n",
    "    plt.xticks(range(len(used)), used)\n",
    "    plt.gca().invert_yaxis()\n",
    "    title = f\"cand{j:03d}  match={bool(r.get('simbad_match'))}  votes={int(r.get('_votes',0))}\"\n",
    "    plt.title(title)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(figdir / f\"cand_{j:03d}_sed.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "print(\"SED thumbs written to:\", figdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a478e5ea-f229-4690-8b2c-a4db9529bb20",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Run the WISE Flag Enricher first.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAssertionError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m OUTDIR = Path(\u001b[33m\"\u001b[39m\u001b[33m./cnt_anomaly/out\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      6\u001b[39m enriched_all = \u001b[38;5;28msorted\u001b[39m(OUTDIR.glob(\u001b[33m\"\u001b[39m\u001b[33mstable_enriched_all_*.csv\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m enriched_all, \u001b[33m\"\u001b[39m\u001b[33mRun the WISE Flag Enricher first.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m df = pd.read_csv(enriched_all[-\u001b[32m1\u001b[39m])\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Relax gates: allow ext_flg != 0, accept W1/W2 = A/B/C with SNR support\u001b[39;00m\n",
      "\u001b[31mAssertionError\u001b[39m: Run the WISE Flag Enricher first."
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Relaxed Gate (inspection)\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\")\n",
    "enriched_all = sorted(OUTDIR.glob(\"stable_enriched_all_*.csv\"))\n",
    "assert enriched_all, \"Run the WISE Flag Enricher first.\"\n",
    "df = pd.read_csv(enriched_all[-1])\n",
    "\n",
    "# Relax gates: allow ext_flg != 0, accept W1/W2 = A/B/C with SNR support\n",
    "def wise_ok_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1, w2 = (s[0] if len(s)>0 else \"\"), (s[1] if len(s)>1 else \"\")\n",
    "    return (w1 in \"ABC\") and (w2 in \"ABC\")\n",
    "\n",
    "mask = np.full(len(df), True)\n",
    "mask &= df[\"w1snr\"].fillna(0) >= 5\n",
    "mask &= df[\"w2snr\"].fillna(0) >= 5\n",
    "mask &= df[\"ph_qual\"].apply(wise_ok_phqual)\n",
    "\n",
    "relaxed = df[mask].copy()\n",
    "relaxed_path = OUTDIR / \"stable_enriched_relaxed.csv\"\n",
    "relaxed.to_csv(relaxed_path, index=False)\n",
    "print(f\"Relaxed shortlist: {len(relaxed)}  → {relaxed_path}\")\n",
    "cols = [\"ra_deg\",\"dec\",\"_votes\",\"ph_qual\",\"ext_flg\",\"cc_flags\",\"w1snr\",\"w2snr\",\"W1mag\",\"W2mag\",\"W3mag\",\"W4mag\"]\n",
    "print(relaxed[cols].fillna(\"\").to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde2d6bd-3930-45b7-99b4-56a95bcc7f94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] cnt_anomaly\\out\\stable_anomalies_20251016-173536.csv\n",
      "[save] enriched (all):     cnt_anomaly\\out\\stable_enriched_all_20251016-173536.csv (1)\n",
      "[save] strict shortlist:   cnt_anomaly\\out\\stable_enriched_strict_20251016-173536.csv (0)\n",
      "[save] relaxed shortlist:  cnt_anomaly\\out\\stable_enriched_relaxed_20251016-173536.csv (0)\n",
      "\n",
      "== STRICT: 0 ==\n",
      "\n",
      "== RELAXED: 0 ==\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Enrich + Strict & Relaxed Filters (one-button)\n",
    "# Works even if you haven't run any prior \"enricher\" cell.\n",
    "\n",
    "import sys, subprocess, importlib, warnings, os\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# --- Soft deps check (astroquery) ---\n",
    "def ensure(pkgs):\n",
    "    import importlib\n",
    "    to_install = []\n",
    "    for p in pkgs:\n",
    "        try:\n",
    "            importlib.import_module(p)\n",
    "        except Exception:\n",
    "            to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "ensure([\"astroquery\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\")\n",
    "assert OUTDIR.exists(), \"Output folder not found. Run the main anomaly cell first.\"\n",
    "\n",
    "# 1) Locate latest stable anomalies CSV\n",
    "stable_csvs = sorted(OUTDIR.glob(\"stable_anomalies_*.csv\"))\n",
    "assert stable_csvs, \"No stable_anomalies_*.csv found. Run the main anomaly cell first.\"\n",
    "src_path = stable_csvs[-1]\n",
    "print(\"[load]\", src_path)\n",
    "base_stamp = src_path.stem.replace(\"stable_anomalies_\", \"\")\n",
    "\n",
    "df = pd.read_csv(src_path)\n",
    "if df.empty:\n",
    "    raise SystemExit(\"Stable anomalies file is empty; loosen K_STABILITY or scan a different tile.\")\n",
    "\n",
    "# 2) Enrich with WISE flags (AllWISE II/328) within 2\"\n",
    "Vizier.ROW_LIMIT = -1\n",
    "want_cols = [\n",
    "    \"AllWISE\",\"RAJ2000\",\"DEJ2000\",\"ph_qual\",\"cc_flags\",\"ext_flg\",\"var_flg\",\n",
    "    \"W1mag\",\"W2mag\",\"W3mag\",\"W4mag\",\"e_W1mag\",\"e_W2mag\",\"e_W3mag\",\"e_W4mag\",\n",
    "    \"w1snr\",\"w2snr\",\"w3snr\",\"w4snr\"\n",
    "]\n",
    "\n",
    "enriched_rows = []\n",
    "for i, r in df.reset_index(drop=True).iterrows():\n",
    "    ra = r.get(\"ra_deg\") or r.get(\"ra\") or r.get(\"RA_ICRS\")\n",
    "    dec = r.get(\"dec\") or r.get(\"DE_ICRS\")\n",
    "    row = r.to_dict()\n",
    "    if not (pd.notna(ra) and pd.notna(dec)):\n",
    "        for c in want_cols: row[c] = np.nan\n",
    "        row[\"sep_arcsec\"] = np.nan\n",
    "        enriched_rows.append(row)\n",
    "        continue\n",
    "    coord = SkyCoord(float(ra)*u.deg, float(dec)*u.deg, frame=\"icrs\")\n",
    "    try:\n",
    "        q = Vizier(columns=want_cols).query_region(coord, radius=2*u.arcsec, catalog=\"II/328/allwise\")\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            for c in want_cols: row[c] = np.nan\n",
    "            row[\"sep_arcsec\"] = np.nan\n",
    "        else:\n",
    "            tab = q[0].to_pandas()\n",
    "            sra = tab[\"RAJ2000\"].astype(float).values\n",
    "            sde = tab[\"DEJ2000\"].astype(float).values\n",
    "            seps = SkyCoord(sra*u.deg, sde*u.deg).separation(coord).arcsec\n",
    "            j = int(np.argmin(seps))\n",
    "            for c in want_cols: row[c] = tab.iloc[j].get(c, np.nan)\n",
    "            row[\"sep_arcsec\"] = float(seps[j])\n",
    "    except Exception as e:\n",
    "        # On Vizier hiccup, fill NaNs so downstream still works\n",
    "        for c in want_cols: row[c] = np.nan\n",
    "        row[\"sep_arcsec\"] = np.nan\n",
    "    enriched_rows.append(row)\n",
    "\n",
    "enriched = pd.DataFrame(enriched_rows)\n",
    "\n",
    "# 3) Define gates\n",
    "def wise_good_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"AB\") and (w2 in \"AB\")\n",
    "\n",
    "def wise_ok_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"ABC\") and (w2 in \"ABC\")\n",
    "\n",
    "# STRICT: high-quality, point-like preference\n",
    "mask_strict = np.full(len(enriched), True)\n",
    "mask_strict &= enriched[\"ph_qual\"].apply(wise_good_phqual)\n",
    "mask_strict &= enriched[\"w1snr\"].fillna(0) >= 5\n",
    "mask_strict &= enriched[\"w2snr\"].fillna(0) >= 5\n",
    "mask_strict &= enriched[\"ext_flg\"].astype(str).isin([\"0\",\"\", \"nan\", \"NaN\"])\n",
    "\n",
    "strict = enriched[mask_strict].copy()\n",
    "\n",
    "# RELAXED: allow C in ph_qual, any ext_flg, but keep S/N support\n",
    "mask_relaxed = np.full(len(enriched), True)\n",
    "mask_relaxed &= enriched[\"ph_qual\"].apply(wise_ok_phqual)\n",
    "mask_relaxed &= enriched[\"w1snr\"].fillna(0) >= 5\n",
    "mask_relaxed &= enriched[\"w2snr\"].fillna(0) >= 5\n",
    "relaxed = enriched[mask_relaxed].copy()\n",
    "\n",
    "# 4) Save artifacts\n",
    "all_path     = OUTDIR / f\"stable_enriched_all_{base_stamp}.csv\"\n",
    "strict_path  = OUTDIR / f\"stable_enriched_strict_{base_stamp}.csv\"\n",
    "relaxed_path = OUTDIR / f\"stable_enriched_relaxed_{base_stamp}.csv\"\n",
    "\n",
    "enriched.to_csv(all_path, index=False)\n",
    "strict.to_csv(strict_path, index=False)\n",
    "relaxed.to_csv(relaxed_path, index=False)\n",
    "\n",
    "print(f\"[save] enriched (all):     {all_path} ({len(enriched)})\")\n",
    "print(f\"[save] strict shortlist:   {strict_path} ({len(strict)})\")\n",
    "print(f\"[save] relaxed shortlist:  {relaxed_path} ({len(relaxed)})\")\n",
    "\n",
    "# 5) Human-friendly preview tables\n",
    "cols = [\"ra_deg\",\"dec\",\"_votes\",\"ph_qual\",\"ext_flg\",\"cc_flags\",\"w1snr\",\"w2snr\",\"W1mag\",\"W2mag\",\"W3mag\",\"W4mag\",\"sep_arcsec\"]\n",
    "def show(df_, name):\n",
    "    if df_.empty:\n",
    "        print(f\"\\n== {name}: 0 ==\")\n",
    "    else:\n",
    "        print(f\"\\n== {name}: {len(df_)} ==\")\n",
    "        print(df_[ [c for c in cols if c in df_.columns] ].fillna(\"\").to_string(index=False))\n",
    "\n",
    "show(strict,  \"STRICT\")\n",
    "show(relaxed, \"RELAXED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a646574-4b8d-4cfa-87e3-9a9994636d54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] cnt_anomaly\\out\\stable_anomalies_20251016-173536.csv\n",
      "[save] all:     cnt_anomaly\\out\\stable_enriched_all_20251016-173536.pmwise.csv (1)\n",
      "[save] STRICT:  cnt_anomaly\\out\\stable_enriched_strict_20251016-173536.pmwise.csv (0)\n",
      "[save] RELAXED: cnt_anomaly\\out\\stable_enriched_relaxed_20251016-173536.pmwise.csv (0)\n",
      "\n",
      "== STRICT: 0 ==\n",
      "\n",
      "== RELAXED: 0 ==\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Proper-Motion WISE Enricher v2 (with fallback)\n",
    "# - Propagates Gaia position to WISE epoch (~2010.5)\n",
    "# - Expands cone to 5\"\n",
    "# - Falls back to pseudo-flags from xmatch mags/errors if no Vizier row\n",
    "import sys, subprocess, importlib, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.time import Time\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p)\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "ensure([\"astroquery\"])\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\")\n",
    "assert OUTDIR.exists(), \"Run the main anomaly cell first.\"\n",
    "stable_csvs = sorted(OUTDIR.glob(\"stable_anomalies_*.csv\"))\n",
    "assert stable_csvs, \"No stable_anomalies_*.csv found.\"\n",
    "src_path = stable_csvs[-1]\n",
    "stamp = src_path.stem.replace(\"stable_anomalies_\", \"\")\n",
    "print(\"[load]\", src_path)\n",
    "\n",
    "df = pd.read_csv(src_path)\n",
    "if df.empty:\n",
    "    raise SystemExit(\"Stable anomalies file is empty; loosen K_STABILITY or scan a different tile.\")\n",
    "\n",
    "# Helper: propagate Gaia ICRS to epoch 2010.5 (WISE)\n",
    "# Expect pmRA, pmDE in mas/yr; RA/Dec in deg; parallax ignored for tiny cones\n",
    "def propagate_to_epoch(row, epoch_from=2016.0, epoch_to=2010.5):\n",
    "    ra = row.get(\"ra_deg\") or row.get(\"RA_ICRS\") or row.get(\"ra\")\n",
    "    dec = row.get(\"dec\") or row.get(\"DE_ICRS\")\n",
    "    pmra = row.get(\"pmRA\", np.nan)   # mas/yr\n",
    "    pmde = row.get(\"pmDE\", np.nan)   # mas/yr\n",
    "    if not (pd.notna(ra) and pd.notna(dec)):\n",
    "        return np.nan, np.nan\n",
    "    dt = (epoch_to - epoch_from)  # years (negative going back)\n",
    "    # Convert mas/yr to deg/yr: 1 mas = 1/3.6e6 deg\n",
    "    k = 1.0 / 3.6e6\n",
    "    dra = (pmra if pd.notna(pmra) else 0.0) * k / np.cos(np.deg2rad(dec)) * dt\n",
    "    ddec = (pmde if pd.notna(pmde) else 0.0) * k * dt\n",
    "    return float(ra + dra), float(dec + ddec)\n",
    "\n",
    "# Pull WISE flags near the proper-motion-corrected position\n",
    "Vizier.ROW_LIMIT = -1\n",
    "want_cols = [\n",
    "    \"AllWISE\",\"RAJ2000\",\"DEJ2000\",\"ph_qual\",\"cc_flags\",\"ext_flg\",\"var_flg\",\n",
    "    \"W1mag\",\"W2mag\",\"W3mag\",\"W4mag\",\"e_W1mag\",\"e_W2mag\",\"e_W3mag\",\"e_W4mag\",\n",
    "    \"w1snr\",\"w2snr\",\"w3snr\",\"w4snr\"\n",
    "]\n",
    "\n",
    "rows=[]\n",
    "for i, r in df.reset_index(drop=True).iterrows():\n",
    "    ra_pm, dec_pm = propagate_to_epoch(r)\n",
    "    ra0 = r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\")\n",
    "    dec0 = r.get(\"dec\") or r.get(\"DE_ICRS\")\n",
    "    row = r.to_dict()\n",
    "    row[\"ra_pm2010\"]  = ra_pm\n",
    "    row[\"dec_pm2010\"] = dec_pm\n",
    "\n",
    "    # default fill\n",
    "    for c in want_cols: row[c] = np.nan\n",
    "    row[\"sep_arcsec\"] = np.nan\n",
    "    row[\"match_mode\"] = \"none\"\n",
    "\n",
    "    # Try Vizier around pm-corrected position first, then original if needed\n",
    "    def try_query(ra_deg, dec_deg, mode):\n",
    "        if not (pd.notna(ra_deg) and pd.notna(dec_deg)): \n",
    "            return False\n",
    "        coord = SkyCoord(ra_deg*u.deg, dec_deg*u.deg)\n",
    "        q = Vizier(columns=want_cols).query_region(coord, radius=5*u.arcsec, catalog=\"II/328/allwise\")\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            return False\n",
    "        tab = q[0].to_pandas()\n",
    "        sra = tab[\"RAJ2000\"].astype(float).values\n",
    "        sde = tab[\"DEJ2000\"].astype(float).values\n",
    "        seps = SkyCoord(sra*u.deg, sde*u.deg).separation(coord).arcsec\n",
    "        j = int(np.argmin(seps))\n",
    "        for c in want_cols: row[c] = tab.iloc[j].get(c, np.nan)\n",
    "        row[\"sep_arcsec\"] = float(seps[j])\n",
    "        row[\"match_mode\"] = mode\n",
    "        return True\n",
    "\n",
    "    ok = try_query(ra_pm, dec_pm, \"pm2010.5\") or try_query(ra0, dec0, \"icrs_now\")\n",
    "\n",
    "    # Fallback: estimate SNR & a pseudo ph_qual from magnitude errors we already have (from xmatch)\n",
    "    # SNR ~ 1.0857 / e_mag (since e_mag ≈ 1.0857/SNR)\n",
    "    if not ok:\n",
    "        for band, eband in [(\"W1\",\"e_W1mag\"),(\"W2\",\"e_W2mag\"),(\"W3\",\"e_W3mag\"),(\"W4\",\"e_W4mag\")]:\n",
    "            if band in row and eband in row and pd.notna(row[eband]):\n",
    "                snr = 1.0857 / row[eband] if row[eband] and row[eband]>0 else np.nan\n",
    "                row[f\"w{band[1].lower()}snr_est\"] = snr\n",
    "        # Construct pseudo ph_qual from estimated SNR where possible\n",
    "        def qual_from_snr(snr):\n",
    "            if not pd.notna(snr): return \"U\"\n",
    "            return \"A\" if snr>=10 else (\"B\" if snr>=5 else (\"C\" if snr>=3 else \"U\"))\n",
    "        w1q = qual_from_snr(row.get(\"w1snr_est\", np.nan))\n",
    "        w2q = qual_from_snr(row.get(\"w2snr_est\", np.nan))\n",
    "        w3q = qual_from_snr(row.get(\"w3snr_est\", np.nan))\n",
    "        w4q = qual_from_snr(row.get(\"w4snr_est\", np.nan))\n",
    "        row[\"ph_qual\"] = f\"{w1q}{w2q}{w3q}{w4q}\"\n",
    "        row[\"match_mode\"] = \"fallback_est\"\n",
    "\n",
    "    rows.append(row)\n",
    "\n",
    "enriched = pd.DataFrame(rows)\n",
    "\n",
    "# Gates (strict/relaxed)\n",
    "def wise_good_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"AB\") and (w2 in \"AB\")\n",
    "\n",
    "def wise_ok_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"ABC\") and (w2 in \"ABC\")\n",
    "\n",
    "# Use measured SNR if available, else estimated fallback\n",
    "w1snr = enriched[\"w1snr\"].fillna(enriched.get(\"w1snr_est\", np.nan))\n",
    "w2snr = enriched[\"w2snr\"].fillna(enriched.get(\"w2snr_est\", np.nan))\n",
    "\n",
    "mask_strict = wise_good_phqual(enriched[\"ph_qual\"]) & (w1snr.fillna(0)>=5) & (w2snr.fillna(0)>=5) & (\n",
    "    enriched[\"ext_flg\"].astype(str).isin([\"0\",\"\",\"nan\",\"NaN\"]) | enriched[\"match_mode\"].eq(\"fallback_est\")\n",
    ")\n",
    "\n",
    "mask_relaxed = wise_ok_phqual(enriched[\"ph_qual\"]) & (w1snr.fillna(0)>=3) & (w2snr.fillna(0)>=3)\n",
    "\n",
    "strict  = enriched[mask_strict].copy()\n",
    "relaxed = enriched[mask_relaxed].copy()\n",
    "\n",
    "all_path     = OUTDIR / f\"stable_enriched_all_{stamp}.pmwise.csv\"\n",
    "strict_path  = OUTDIR / f\"stable_enriched_strict_{stamp}.pmwise.csv\"\n",
    "relaxed_path = OUTDIR / f\"stable_enriched_relaxed_{stamp}.pmwise.csv\"\n",
    "\n",
    "enriched.to_csv(all_path, index=False)\n",
    "strict.to_csv(strict_path, index=False)\n",
    "relaxed.to_csv(relaxed_path, index=False)\n",
    "\n",
    "cols = [\"ra_deg\",\"dec\",\"_votes\",\"match_mode\",\"ph_qual\",\"ext_flg\",\"cc_flags\",\n",
    "        \"w1snr\",\"w2snr\",\"w1snr_est\",\"w2snr_est\",\"W1\",\"W2\",\"W3\",\"W4\",\"sep_arcsec\"]\n",
    "print(f\"[save] all:     {all_path} ({len(enriched)})\")\n",
    "print(f\"[save] STRICT:  {strict_path} ({len(strict)})\")\n",
    "print(f\"[save] RELAXED: {relaxed_path} ({len(relaxed)})\")\n",
    "\n",
    "def show(df_, name):\n",
    "    if df_.empty:\n",
    "        print(f\"\\n== {name}: 0 ==\")\n",
    "    else:\n",
    "        print(f\"\\n== {name}: {len(df_)} ==\")\n",
    "        print(df_[ [c for c in cols if c in df_.columns] ].fillna(\"\").to_string(index=False))\n",
    "\n",
    "show(strict,  \"STRICT\")\n",
    "show(relaxed, \"RELAXED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5381a30-355e-45f6-9dfc-f8ce0160fd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tile 1/9] RA=209.200 Dec=-1.300 …\n",
      "[tile 2/9] RA=210.000 Dec=-1.300 …\n",
      "[tile 3/9] RA=210.800 Dec=-1.300 …\n",
      "[tile 4/9] RA=209.200 Dec=-0.500 …\n",
      "[tile 5/9] RA=210.000 Dec=-0.500 …\n",
      "[tile 6/9] RA=210.800 Dec=-0.500 …\n",
      "[tile 7/9] RA=209.200 Dec=0.300 …\n",
      "[tile 8/9] RA=210.000 Dec=0.300 …\n",
      "[tile 9/9] RA=210.800 Dec=0.300 …\n",
      "[save] master stable anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251016-180208.csv  (N=12)\n",
      "[save] enriched (all):     cnt_anomaly\\out\\stable_enriched_all_20251016-180208_grid3x3_K3.csv (12)\n",
      "[save] strict shortlist:   cnt_anomaly\\out\\stable_enriched_strict_20251016-180208_grid3x3_K3.csv (12)\n",
      "[save] relaxed shortlist:  cnt_anomaly\\out\\stable_enriched_relaxed_20251016-180208_grid3x3_K3.csv (12)\n",
      "[time] 144.4s\n",
      "\n",
      "== STRICT: 12 ==\n",
      "    ra_deg       dec  _votes  tile_ra  tile_dec match_mode ph_qual ext_flg cc_flags w1snr w2snr  w1snr_est  w2snr_est     W1     W2     W3    W4  sep_arcsec\n",
      "208.941437 -2.045680       4    209.2      -1.3   pm2010.5                                       45.237500  41.757691 12.510 12.554 11.734 8.905    0.175678\n",
      "210.137533 -2.022507       5    210.0      -1.3   pm2010.5                                       47.204348  49.350000 11.997 11.997 11.813 9.183    0.023997\n",
      "210.460969 -2.001703       5    210.8      -1.3   pm2010.5                                       49.350000  57.142107  9.506  9.555  9.513 8.946    0.157726\n",
      "209.236537 -1.289745       4    209.2      -0.5   pm2010.5                                       37.437932  27.838461 14.349 14.000 10.232 8.481    0.224532\n",
      "210.305273 -1.213642       4    210.0      -0.5   pm2010.5                                       47.204348  49.350000 11.509 11.591 11.180 9.023    0.071150\n",
      "210.910946 -1.291592       4    210.8      -0.5   pm2010.5                                       31.932351  12.772941 15.128 15.196 12.670 9.344    0.131746\n",
      "210.997438 -1.268082       5    210.8      -0.5   pm2010.5                                       49.350000  43.427999 12.556 12.588 12.344 9.172    0.093892\n",
      "209.305983 -0.421871       5    209.2       0.3   pm2010.5                                       49.350000  54.285001 10.455 10.485 10.500 8.825    0.005225\n",
      "209.917527 -0.456956       5    210.0       0.3   pm2010.5                                       47.204348  49.350000 11.425 11.511 11.571 8.507    0.094348\n",
      "209.920252 -0.434121       3    210.0       0.3   pm2010.5                                       35.022581  25.248836 14.651 14.256 12.239 8.687    0.094244\n",
      "210.728039 -0.496451       3    210.8       0.3   pm2010.5                                       33.928123  17.233333 14.923 14.922 12.304 8.708    0.271086\n",
      "211.229857 -0.368180       3    210.8       0.3   pm2010.5                                       43.427999  35.022581 13.691 13.543  9.861 7.699    0.133142\n",
      "\n",
      "== RELAXED: 12 ==\n",
      "    ra_deg       dec  _votes  tile_ra  tile_dec match_mode ph_qual ext_flg cc_flags w1snr w2snr  w1snr_est  w2snr_est     W1     W2     W3    W4  sep_arcsec\n",
      "208.941437 -2.045680       4    209.2      -1.3   pm2010.5                                       45.237500  41.757691 12.510 12.554 11.734 8.905    0.175678\n",
      "210.137533 -2.022507       5    210.0      -1.3   pm2010.5                                       47.204348  49.350000 11.997 11.997 11.813 9.183    0.023997\n",
      "210.460969 -2.001703       5    210.8      -1.3   pm2010.5                                       49.350000  57.142107  9.506  9.555  9.513 8.946    0.157726\n",
      "209.236537 -1.289745       4    209.2      -0.5   pm2010.5                                       37.437932  27.838461 14.349 14.000 10.232 8.481    0.224532\n",
      "210.305273 -1.213642       4    210.0      -0.5   pm2010.5                                       47.204348  49.350000 11.509 11.591 11.180 9.023    0.071150\n",
      "210.910946 -1.291592       4    210.8      -0.5   pm2010.5                                       31.932351  12.772941 15.128 15.196 12.670 9.344    0.131746\n",
      "210.997438 -1.268082       5    210.8      -0.5   pm2010.5                                       49.350000  43.427999 12.556 12.588 12.344 9.172    0.093892\n",
      "209.305983 -0.421871       5    209.2       0.3   pm2010.5                                       49.350000  54.285001 10.455 10.485 10.500 8.825    0.005225\n",
      "209.917527 -0.456956       5    210.0       0.3   pm2010.5                                       47.204348  49.350000 11.425 11.511 11.571 8.507    0.094348\n",
      "209.920252 -0.434121       3    210.0       0.3   pm2010.5                                       35.022581  25.248836 14.651 14.256 12.239 8.687    0.094244\n",
      "210.728039 -0.496451       3    210.8       0.3   pm2010.5                                       33.928123  17.233333 14.923 14.922 12.304 8.708    0.271086\n",
      "211.229857 -0.368180       3    210.8       0.3   pm2010.5                                       43.427999  35.022581 13.691 13.543  9.861 7.699    0.133142\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — 3×3 Tile Sweeper + PM-WISE Enrichment (one-button)\n",
    "# Telos × Aetheron\n",
    "# ---------------------------------------------------------------\n",
    "import os, io, sys, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# ===== Config =====\n",
    "CENTER_RA, CENTER_DEC = 210.0, -0.5   # change to roam the sky\n",
    "RADIUS_DEG = 0.8                      # per-tile radius\n",
    "GRID_STEP_DEG = 0.8                   # spacing between tile centers\n",
    "GRID_SIZE = 3                         # 3×3 grid\n",
    "N_MAX = 3000                          # Gaia row cap per tile\n",
    "XMM_RADIUS_ARCSEC = 1.0               # Gaia↔WISE xmatch radius\n",
    "K_STABILITY = 3                       # discovery mode; later push back to 4\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01                         # expected anomaly rate\n",
    "WISE_CONE_ARCSEC = 5.0                # pmwise Vizier cone\n",
    "\n",
    "OUTDIR = Path(\"./cnt_anomaly/out\"); OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "CACHE  = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "ensure([\"astroquery\",\"pyvo\",\"scikit-learn\",\"matplotlib\",\"astropy\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# ===== Anomaly helpers (same logic as before) =====\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=N_MAX):\n",
    "    Vizier.ROW_LIMIT = row_limit\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec=XMM_RADIUS_ARCSEC):\n",
    "    if gaia_df.empty: \n",
    "        return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in df.columns: df[v] = df[k]\n",
    "    return df.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(df):\n",
    "    d = df.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d:\n",
    "            d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d:\n",
    "        d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "def make_feature_views(df):\n",
    "    numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "    keep_cols = [c for c in numeric.columns if c!=\"dist_pc\"]\n",
    "    X0 = numeric[keep_cols].fillna(numeric[keep_cols].median())\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"G\",\"BP_RP\",\"MG\",\"SED_slope\",\"pm_norm\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c in [\"BP_RP\",\"SED_slope_W1_W3\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    rng = np.random.default_rng(SEED)\n",
    "    if cols1:\n",
    "        views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2:\n",
    "        views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy(); X4 += rng.normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1])\n",
    "        X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a,X5b],axis=1)\n",
    "    colmaps = {\"V1\":cols1,\"V2\":cols2,\"V3\":cols3,\"V4\":cols4,\"V5\":list(set(cols1+cols2))}\n",
    "    return views, colmaps\n",
    "\n",
    "def run_anomaly_ensemble(views):\n",
    "    flags = {}\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    return flags\n",
    "\n",
    "def stability_vote(flags):\n",
    "    if not flags: return None,None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0), list(flags.keys())\n",
    "\n",
    "def process_tile(ra, dec, stamp):\n",
    "    gaia_cache = CACHE / f\"gaia_{ra}_{dec}_{RADIUS_DEG}.csv\"\n",
    "    wise_cache = CACHE / f\"gaiaxwise_{ra}_{dec}_{RADIUS_DEG}.csv\"\n",
    "    if gaia_cache.exists():\n",
    "        gaia = pd.read_csv(gaia_cache)\n",
    "    else:\n",
    "        gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, RADIUS_DEG,\n",
    "                            columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                            row_limit=N_MAX)\n",
    "        gaia.to_csv(gaia_cache, index=False)\n",
    "    if wise_cache.exists():\n",
    "        gw = pd.read_csv(wise_cache)\n",
    "    else:\n",
    "        gw = xmatch_gaia_allwise(gaia)\n",
    "        gw.to_csv(wise_cache, index=False)\n",
    "    if gw.empty: \n",
    "        return pd.DataFrame()\n",
    "    df = add_derived_features(clean_photometry(gw))\n",
    "    views, colmaps = make_feature_views(df)\n",
    "    votes, names = stability_vote(run_anomaly_ensemble(views))\n",
    "    if votes is None: \n",
    "        return pd.DataFrame()\n",
    "    df[\"_votes\"] = votes\n",
    "    df[\"_is_stable_anom\"] = df[\"_votes\"] >= K_STABILITY\n",
    "    st = df[df[\"_is_stable_anom\"]].copy()\n",
    "    st[\"tile_ra\"] = ra; st[\"tile_dec\"] = dec\n",
    "    return st\n",
    "\n",
    "# ===== Sweep tiles =====\n",
    "t0 = time.time()\n",
    "stamp = datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ras, decs = [], []\n",
    "offsets = np.linspace(-GRID_STEP_DEG, GRID_STEP_DEG, GRID_SIZE)\n",
    "for dy in offsets:\n",
    "    for dx in offsets:\n",
    "        ras.append(CENTER_RA + dx)\n",
    "        decs.append(CENTER_DEC + dy)\n",
    "\n",
    "all_stable = []\n",
    "for i,(ra,dec) in enumerate(zip(ras,decs),1):\n",
    "    print(f\"[tile {i}/{GRID_SIZE**2}] RA={ra:.3f} Dec={dec:.3f} …\")\n",
    "    try:\n",
    "        st = process_tile(ra, dec, stamp)\n",
    "    except Exception as e:\n",
    "        print(\"  [warn]\", e); st = pd.DataFrame()\n",
    "    if not st.empty:\n",
    "        all_stable.append(st)\n",
    "\n",
    "if all_stable:\n",
    "    master = pd.concat(all_stable, ignore_index=True)\n",
    "else:\n",
    "    master = pd.DataFrame(columns=[\"ra_deg\",\"dec\",\"_votes\",\"tile_ra\",\"tile_dec\"])\n",
    "\n",
    "master_path = OUTDIR / f\"stable_anomalies_master_{stamp}.csv\"\n",
    "master.to_csv(master_path, index=False)\n",
    "print(f\"[save] master stable anomalies: {master_path}  (N={len(master)})\")\n",
    "\n",
    "# ===== PM-WISE enrichment on master file =====\n",
    "from astropy.time import Time\n",
    "\n",
    "Vizier.ROW_LIMIT = -1\n",
    "want_cols = [\n",
    "    \"AllWISE\",\"RAJ2000\",\"DEJ2000\",\"ph_qual\",\"cc_flags\",\"ext_flg\",\"var_flg\",\n",
    "    \"W1mag\",\"W2mag\",\"W3mag\",\"W4mag\",\"e_W1mag\",\"e_W2mag\",\"e_W3mag\",\"e_W4mag\",\n",
    "    \"w1snr\",\"w2snr\",\"w3snr\",\"w4snr\"\n",
    "]\n",
    "\n",
    "def propagate_to_epoch(row, epoch_from=2016.0, epoch_to=2010.5):\n",
    "    ra = row.get(\"ra_deg\") or row.get(\"RA_ICRS\") or row.get(\"ra\")\n",
    "    dec = row.get(\"dec\") or row.get(\"DE_ICRS\")\n",
    "    pmra = row.get(\"pmRA\", np.nan); pmde = row.get(\"pmDE\", np.nan)\n",
    "    if not (pd.notna(ra) and pd.notna(dec)):\n",
    "        return np.nan, np.nan\n",
    "    dt = (epoch_to - epoch_from)\n",
    "    k = 1.0/3.6e6\n",
    "    dra = (pmra if pd.notna(pmra) else 0.0) * k / np.cos(np.deg2rad(dec)) * dt\n",
    "    ddec= (pmde if pd.notna(pmde) else 0.0) * k * dt\n",
    "    return float(ra + dra), float(dec + ddec)\n",
    "\n",
    "rows=[]\n",
    "for i,r in master.reset_index(drop=True).iterrows():\n",
    "    row = r.to_dict()\n",
    "    ra_pm, dec_pm = propagate_to_epoch(r)\n",
    "    ra0 = r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\")\n",
    "    dec0 = r.get(\"dec\") or r.get(\"DE_ICRS\")\n",
    "    for c in want_cols: row[c] = np.nan\n",
    "    row[\"sep_arcsec\"] = np.nan; row[\"match_mode\"] = \"none\"\n",
    "    def try_q(ra_deg,dec_deg,mode):\n",
    "        if not (pd.notna(ra_deg) and pd.notna(dec_deg)): return False\n",
    "        coord = SkyCoord(ra_deg*u.deg, dec_deg*u.deg)\n",
    "        q = Vizier(columns=want_cols).query_region(coord, radius=WISE_CONE_ARCSEC*u.arcsec, catalog=\"II/328/allwise\")\n",
    "        if len(q)==0 or len(q[0])==0: return False\n",
    "        tab = q[0].to_pandas()\n",
    "        sra = tab[\"RAJ2000\"].astype(float).values\n",
    "        sde = tab[\"DEJ2000\"].astype(float).values\n",
    "        seps = SkyCoord(sra*u.deg, sde*u.deg).separation(coord).arcsec\n",
    "        j = int(np.argmin(seps))\n",
    "        for c in want_cols: row[c] = tab.iloc[j].get(c, np.nan)\n",
    "        row[\"sep_arcsec\"] = float(seps[j]); row[\"match_mode\"] = mode\n",
    "        return True\n",
    "    ok = try_q(ra_pm,dec_pm,\"pm2010.5\") or try_q(ra0,dec0,\"icrs_now\")\n",
    "    # fallback est from our xmatch errors if present\n",
    "    for band, eband in [(\"W1\",\"eW1\"),(\"W2\",\"eW2\"),(\"W3\",\"eW3\"),(\"W4\",\"eW4\")]:\n",
    "        if pd.isna(row.get(f\"w{band[1].lower()}snr\", np.nan)) and (eband in r) and pd.notna(r[eband]):\n",
    "            snr = 1.0857 / r[eband] if r[eband]>0 else np.nan\n",
    "            row[f\"w{band[1].lower()}snr_est\"] = snr\n",
    "    rows.append(row)\n",
    "\n",
    "enriched = pd.DataFrame(rows)\n",
    "\n",
    "def wise_good_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"; w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"AB\") and (w2 in \"AB\")\n",
    "\n",
    "def wise_ok_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"; w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"ABC\") and (w2 in \"ABC\")\n",
    "\n",
    "w1snr = enriched[\"w1snr\"].fillna(enriched.get(\"w1snr_est\", np.nan))\n",
    "w2snr = enriched[\"w2snr\"].fillna(enriched.get(\"w2snr_est\", np.nan))\n",
    "\n",
    "mask_strict  = enriched[\"ph_qual\"].apply(wise_good_phqual) & (w1snr.fillna(0)>=5) & (w2snr.fillna(0)>=5)\n",
    "mask_relaxed = enriched[\"ph_qual\"].apply(wise_ok_phqual)   & (w1snr.fillna(0)>=3) & (w2snr.fillna(0)>=3)\n",
    "\n",
    "strict  = enriched[mask_strict].copy()\n",
    "relaxed = enriched[mask_relaxed].copy()\n",
    "\n",
    "base = f\"{stamp}_grid{GRID_SIZE}x{GRID_SIZE}_K{K_STABILITY}\"\n",
    "all_path     = OUTDIR / f\"stable_enriched_all_{base}.csv\"\n",
    "strict_path  = OUTDIR / f\"stable_enriched_strict_{base}.csv\"\n",
    "relaxed_path = OUTDIR / f\"stable_enriched_relaxed_{base}.csv\"\n",
    "enriched.to_csv(all_path, index=False)\n",
    "strict.to_csv(strict_path, index=False)\n",
    "relaxed.to_csv(relaxed_path, index=False)\n",
    "\n",
    "print(f\"[save] enriched (all):     {all_path} ({len(enriched)})\")\n",
    "print(f\"[save] strict shortlist:   {strict_path} ({len(strict)})\")\n",
    "print(f\"[save] relaxed shortlist:  {relaxed_path} ({len(relaxed)})\")\n",
    "print(f\"[time] {time.time()-t0:0.1f}s\")\n",
    "\n",
    "# Pretty previews\n",
    "cols = [\"ra_deg\",\"dec\",\"_votes\",\"tile_ra\",\"tile_dec\",\"match_mode\",\"ph_qual\",\"ext_flg\",\"cc_flags\",\n",
    "        \"w1snr\",\"w2snr\",\"w1snr_est\",\"w2snr_est\",\"W1\",\"W2\",\"W3\",\"W4\",\"sep_arcsec\"]\n",
    "def show(df_, name):\n",
    "    if df_.empty:\n",
    "        print(f\"\\n== {name}: 0 ==\")\n",
    "    else:\n",
    "        print(f\"\\n== {name}: {len(df_)} ==\")\n",
    "        print(df_[ [c for c in cols if c in df_.columns] ].fillna(\"\").to_string(index=False))\n",
    "show(strict,\"STRICT\")\n",
    "show(relaxed,\"RELAXED\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e57315be-239c-4b90-9582-ada1de0ec1bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] cnt_anomaly\\out\\stable_enriched_strict_20251016-180208_grid3x3_K3.csv\n",
      "\n",
      "[save] Ranked shortlist → cnt_anomaly\\out\\strict_ranked_shortlist.csv\n",
      "[save] Summary markdown → cnt_anomaly\\out\\strict_shortlist_summary.md\n",
      "[save] Plots → cnt_anomaly\\out\\figures\n",
      "[save] Cutouts (FITS) → cnt_anomaly\\out\\cutouts\n",
      "\n",
      "Top 5 preview:\n",
      " rank_score     ra_deg       dec  _votes     W1-W2  W2-W3  ph_qual  ext_flg class_hint  cutouts_saved\n",
      "   6.960547 209.236537 -1.289745       4  0.349000  3.768      NaN      NaN  ambiguous           True\n",
      "   5.931826 210.910946 -1.291592       4 -0.068000  2.526      NaN      NaN  ambiguous           True\n",
      "   5.839600 210.137533 -2.022507       5  0.000000  0.184      NaN      NaN  ambiguous           True\n",
      "   5.830610 210.997438 -1.268082       5 -0.032001  0.244      NaN      NaN  ambiguous           True\n",
      "   5.749000 209.305983 -0.421871       5 -0.030000 -0.015      NaN      NaN  ambiguous           True\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Rapid Triage Dashboard + Cutouts (strict set)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, math, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p)\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\"])\n",
    "\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(exist_ok=True, parents=True)\n",
    "CUT = OUT/\"cutouts\"; CUT.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# 1) Load the newest STRICT enriched file from the grid sweep\n",
    "stricts = sorted(OUT.glob(\"stable_enriched_strict_*_grid3x3_*.csv\"))\n",
    "if not stricts:\n",
    "    # fallback: any strict file (pmwise or single tile)\n",
    "    stricts = sorted(OUT.glob(\"stable_enriched_strict_*.csv\"))\n",
    "assert stricts, \"No strict enriched CSVs found.\"\n",
    "csv_path = stricts[-1]\n",
    "print(\"[load]\", csv_path)\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2) Compute diagnostics — colors, crude class flags, ranks\n",
    "def add_diagnostics(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d:\n",
    "            d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    # Proper motion norm (if present from earlier steps)\n",
    "    if \"pmRA\" in d and \"pmDE\" in d:\n",
    "        d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    # Heuristics:\n",
    "    #   AGN/galaxy-ish: W1-W2 ≥ 0.8 AND W2-W3 ≥ 1.6 (very red mid-IR; Stern+12-style vibe)\n",
    "    #   YSO/dusty star-ish: W1-W2 ≥ 0.3 AND W2-W3 ≥ 1.0 with significant parallax or proper motion\n",
    "    #   Stellar-ish: parallax ≥ 1 mas OR pm_norm ≥ ~20 mas/yr AND modest colors\n",
    "    w12 = d.get(\"W1-W2\")\n",
    "    w23 = d.get(\"W2-W3\")\n",
    "    par = d.get(\"parallax\", pd.Series([np.nan]*len(d)))\n",
    "    pmn = d.get(\"pm_norm\", pd.Series([np.nan]*len(d)))\n",
    "\n",
    "    agn_like = (w12 >= 0.8) & (w23 >= 1.6)\n",
    "    yso_like = (w12 >= 0.3) & (w23 >= 1.0) & ((par >= 1.0) | (pmn >= 20.0))\n",
    "    stellar  = ((par >= 1.0) | (pmn >= 20.0)) & ((w12 < 0.8) | (w23 < 1.6))\n",
    "\n",
    "    # Rank score: more votes + redder colors + smaller sep, penalize large ext_flg\n",
    "    score = d[\"_votes\"].fillna(0).astype(float)\n",
    "    score += (w12.fillna(0) + 0.5*w23.fillna(0)).clip(lower=0)\n",
    "    score += (1.0 - (d.get(\"sep_arcsec\", pd.Series(1.0, index=d.index)).fillna(1.0).clip(0.01,10.0)/10.0))\n",
    "    # penalize obviously extended if you prefer point-like technosignatures; use small penalty\n",
    "    score -= 0.25*(d.get(\"ext_flg\", pd.Series(\"0\", index=d.index)).astype(str) != \"0\").astype(float)\n",
    "\n",
    "    d[\"class_hint\"] = np.where(agn_like, \"AGN/galaxy-like\",\n",
    "                        np.where(yso_like, \"YSO/dusty-star-like\",\n",
    "                        np.where(stellar, \"stellar-like\", \"ambiguous\")))\n",
    "    d[\"rank_score\"] = score\n",
    "    return d\n",
    "\n",
    "df = add_diagnostics(df).sort_values(\"rank_score\", ascending=False).reset_index(drop=True)\n",
    "\n",
    "# 3) Plots: W1-W2 vs W2-W3 scatter + votes vs W1-W2\n",
    "plt.figure(figsize=(5,4))\n",
    "if \"W1-W2\" in df and \"W2-W3\" in df:\n",
    "    plt.scatter(df[\"W1-W2\"], df[\"W2-W3\"], s=30)\n",
    "    plt.xlabel(\"W1 - W2 (mag)\")\n",
    "    plt.ylabel(\"W2 - W3 (mag)\")\n",
    "    plt.title(\"Color–Color: WISE\")\n",
    "    # rough AGN wedge guideline lines\n",
    "    xs = np.linspace(-0.5, 2.5, 200)\n",
    "    plt.plot([0.8,0.8], [ -0.5, 4.0 ])\n",
    "    plt.plot(xs, 1.6*np.ones_like(xs))\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG/\"diag_wise_color_color.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "plt.figure(figsize=(5,4))\n",
    "if \"W1-W2\" in df:\n",
    "    plt.scatter(df[\"W1-W2\"], df[\"_votes\"], s=30)\n",
    "    plt.xlabel(\"W1 - W2 (mag)\")\n",
    "    plt.ylabel(\"Gauge votes\")\n",
    "    plt.title(\"Votes vs IR color\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(FIG/\"diag_votes_vs_w12.png\", dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# 4) Cutouts: Pan-STARRS (gri stack) and DSS2 Red\n",
    "def fetch_cutout(ra, dec, name, fov_arcmin=2.0):\n",
    "    # Try Pan-STARRS first; fallback to DSS2 Red\n",
    "    surveys = [[\"PanSTARRS g\", \"PanSTARRS r\", \"PanSTARRS i\"], [\"DSS2 Red\"]]\n",
    "    for group in surveys:\n",
    "        try:\n",
    "            imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=group, pixels=512,\n",
    "                                      height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "            if imgs:\n",
    "                # Save each plane separately\n",
    "                for k, img in enumerate(imgs):\n",
    "                    hdu = imgs[k][0]\n",
    "                    fn = CUT / f\"{name}__{group[k].replace(' ','_')}.fits\"\n",
    "                    hdu.writeto(fn, overwrite=True)\n",
    "                return True\n",
    "        except Exception as e:\n",
    "            continue\n",
    "    return False\n",
    "\n",
    "rows = []\n",
    "for i, r in df.iterrows():\n",
    "    ra = float(r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\"))\n",
    "    dec = float(r.get(\"dec\") or r.get(\"DE_ICRS\"))\n",
    "    tag = f\"cand{i:02d}_ra{ra:.5f}_dec{dec:.5f}\"\n",
    "    ok = fetch_cutout(ra, dec, tag, fov_arcmin=2.0)\n",
    "    rows.append({**r.to_dict(), \"cutouts_saved\": bool(ok), \"tag\": tag})\n",
    "\n",
    "df2 = pd.DataFrame(rows)\n",
    "\n",
    "# 5) Save ranked shortlist and a tiny markdown summary\n",
    "ranked_path = OUT/\"strict_ranked_shortlist.csv\"\n",
    "df2.to_csv(ranked_path, index=False)\n",
    "\n",
    "md = OUT/\"strict_shortlist_summary.md\"\n",
    "with open(md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# CNT Techno-Anomaly — Strict Shortlist\\n\\n\")\n",
    "    f.write(f\"Source file: `{csv_path.name}`\\n\\n\")\n",
    "    f.write(f\"Diagnostics saved in: `{FIG}`\\n\\n\")\n",
    "    f.write(\"| rank | ra_deg | dec | votes | W1-W2 | W2-W3 | class_hint | cutouts |\\n\")\n",
    "    f.write(\"|---:|---:|---:|---:|---:|---:|:---|:---:|\\n\")\n",
    "    for i, r in df2.reset_index().iterrows():\n",
    "        f.write(f\"| {i+1} | {r['ra_deg']:.6f} | {r['dec']:.6f} | {int(r['_votes'])} | \"\n",
    "                f\"{r.get('W1-W2',np.nan):.3f} | {r.get('W2-W3',np.nan):.3f} | \"\n",
    "                f\"{r.get('class_hint','')} | {'yes' if r['cutouts_saved'] else 'no'} |\\n\")\n",
    "\n",
    "print(\"\\n[save] Ranked shortlist →\", ranked_path)\n",
    "print(\"[save] Summary markdown →\", md)\n",
    "print(\"[save] Plots →\", FIG)\n",
    "print(\"[save] Cutouts (FITS) →\", CUT)\n",
    "print(\"\\nTop 5 preview:\")\n",
    "cols = [\"rank_score\",\"ra_deg\",\"dec\",\"_votes\",\"W1-W2\",\"W2-W3\",\"ph_qual\",\"ext_flg\",\"class_hint\",\"cutouts_saved\"]\n",
    "print(df2.sort_values(\"rank_score\", ascending=False).head(5)[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b98449c-5de3-4eaa-af87-3bdfb304f83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] cnt_anomaly\\out\\stable_enriched_strict_20251016-180208_grid3x3_K3.csv\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'parallax'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3811\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m3812\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3813\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:167\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/index.pyx:196\u001b[39m, in \u001b[36mpandas._libs.index.IndexEngine.get_loc\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/hashtable_class_helper.pxi:7096\u001b[39m, in \u001b[36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mKeyError\u001b[39m: 'parallax'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 157\u001b[39m\n\u001b[32m    155\u001b[39m mask_votes = d[\u001b[33m\"\u001b[39m\u001b[33m_votes\u001b[39m\u001b[33m\"\u001b[39m].fillna(\u001b[32m0\u001b[39m) >= \u001b[32m4\u001b[39m\n\u001b[32m    156\u001b[39m mask_color = d[\u001b[33m\"\u001b[39m\u001b[33mW2-W3\u001b[39m\u001b[33m\"\u001b[39m].fillna(-\u001b[32m99\u001b[39m) >= \u001b[32m1.0\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m157\u001b[39m mask_dist  = (d.get(\u001b[33m\"\u001b[39m\u001b[33mparallax\u001b[39m\u001b[33m\"\u001b[39m, pd.Series(np.nan, index=d.index)).fillna(np.nan) < \u001b[32m1.0\u001b[39m) | \u001b[43md\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m.isna()\n\u001b[32m    158\u001b[39m mask_pm    = (d.get(\u001b[33m\"\u001b[39m\u001b[33mpm_norm\u001b[39m\u001b[33m\"\u001b[39m, pd.Series(np.nan, index=d.index)).fillna(np.nan) < \u001b[32m20.0\u001b[39m) | d[\u001b[33m\"\u001b[39m\u001b[33mpm_norm\u001b[39m\u001b[33m\"\u001b[39m].isna()\n\u001b[32m    159\u001b[39m mask_phq   = d[\u001b[33m\"\u001b[39m\u001b[33mph_qual\u001b[39m\u001b[33m\"\u001b[39m].apply(wise_good_phqual) | d[\u001b[33m\"\u001b[39m\u001b[33mph_qual\u001b[39m\u001b[33m\"\u001b[39m].isna()  \u001b[38;5;66;03m# allow unknown if SNR already ok from earlier step\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4113\u001b[39m, in \u001b[36mDataFrame.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   4111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.columns.nlevels > \u001b[32m1\u001b[39m:\n\u001b[32m   4112\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._getitem_multilevel(key)\n\u001b[32m-> \u001b[39m\u001b[32m4113\u001b[39m indexer = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4114\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[32m   4115\u001b[39m     indexer = [indexer]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3819\u001b[39m, in \u001b[36mIndex.get_loc\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   3814\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[32m   3815\u001b[39m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc.Iterable)\n\u001b[32m   3816\u001b[39m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[32m   3817\u001b[39m     ):\n\u001b[32m   3818\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[32m-> \u001b[39m\u001b[32m3819\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m   3820\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   3821\u001b[39m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[32m   3822\u001b[39m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[32m   3823\u001b[39m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[32m   3824\u001b[39m     \u001b[38;5;28mself\u001b[39m._check_indexing_error(key)\n",
      "\u001b[31mKeyError\u001b[39m: 'parallax'"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Label, Compose PNGs, and Pick a Gold Set\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p)\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astropy\",\"astroquery\"])\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "from astroquery.simbad import Simbad\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(exist_ok=True, parents=True)\n",
    "CUT = OUT/\"cutouts\"; CUT.mkdir(exist_ok=True, parents=True)\n",
    "WEB = OUT/\"web\"; WEB.mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# 1) Load strict shortlist produced by the triage cell\n",
    "stricts = sorted(OUT.glob(\"stable_enriched_strict_*_grid3x3_*.csv\"))\n",
    "if not stricts:\n",
    "    stricts = sorted(OUT.glob(\"stable_enriched_strict_*.csv\"))\n",
    "assert stricts, \"No strict enriched CSV found.\"\n",
    "src_path = stricts[-1]\n",
    "print(\"[load]\", src_path)\n",
    "df = pd.read_csv(src_path).reset_index(drop=True)\n",
    "\n",
    "# 2) Batch SIMBAD resolver (2\" radius, nearest match)\n",
    "custom = Simbad()\n",
    "custom.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "labels = []\n",
    "for i, r in df.iterrows():\n",
    "    ra = float(r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\"))\n",
    "    dec = float(r.get(\"dec\") or r.get(\"DE_ICRS\"))\n",
    "    coord = SkyCoord(ra*u.deg, dec*u.deg, frame=\"icrs\")\n",
    "    try:\n",
    "        res = custom.query_region(coord, radius=2*u.arcsec)\n",
    "    except Exception as e:\n",
    "        res = None\n",
    "    if res is None or len(res)==0:\n",
    "        labels.append({\"simbad_match\": False, \"simbad_main_id\": \"\", \"simbad_otype\": \"\", \"simbad_otypes\": \"\", \"simbad_sp\": \"\", \"simbad_fluxV\": np.nan})\n",
    "    else:\n",
    "        p = res.to_pandas().iloc[0]\n",
    "        labels.append({\n",
    "            \"simbad_match\": True,\n",
    "            \"simbad_main_id\": p.get(\"MAIN_ID\",\"\"),\n",
    "            \"simbad_otype\": p.get(\"OTYPE\",\"\"),\n",
    "            \"simbad_otypes\": p.get(\"OTYPES\",\"\"),\n",
    "            \"simbad_sp\": p.get(\"SP_TYPE\",\"\"),\n",
    "            \"simbad_fluxV\": p.get(\"FLUX_V\", np.nan),\n",
    "        })\n",
    "\n",
    "lab = pd.DataFrame(labels)\n",
    "dfL = pd.concat([df, lab], axis=1)\n",
    "\n",
    "# 3) Compose PNGs from Pan-STARRS FITS (g,r,i if present), fallback to DSS2 Red\n",
    "def find_plane(tag, surveys=(\"PanSTARRS_g\",\"PanSTARRS_r\",\"PanSTARRS_i\")):\n",
    "    # Return available FITS paths by priority\n",
    "    found = {}\n",
    "    for s in surveys:\n",
    "        p = CUT/f\"{tag}__{s}.fits\"\n",
    "        if p.exists(): found[s] = p\n",
    "    return found\n",
    "\n",
    "def load_fits_as_img(path):\n",
    "    try:\n",
    "        with fits.open(path) as hdul:\n",
    "            data = hdul[0].data.astype(np.float32)\n",
    "        norm = ImageNormalize(data, interval=ZScaleInterval(), stretch=AsinhStretch())\n",
    "        img = norm(data)\n",
    "        img = np.clip(img, 0, 1)\n",
    "        return img\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "png_rows = []\n",
    "for i, r in dfL.reset_index(drop=True).iterrows():\n",
    "    ra = float(r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\"))\n",
    "    dec = float(r.get(\"dec\") or r.get(\"DE_ICRS\"))\n",
    "    tag = f\"cand{i:02d}_ra{ra:.5f}_dec{dec:.5f}\"\n",
    "    planes = find_plane(tag)\n",
    "    out_png = WEB/f\"{tag}.png\"\n",
    "\n",
    "    if {\"PanSTARRS_g\",\"PanSTARRS_r\",\"PanSTARRS_i\"}.issubset(planes.keys()):\n",
    "        g = load_fits_as_img(planes[\"PanSTARRS_g\"])\n",
    "        r_ = load_fits_as_img(planes[\"PanSTARRS_r\"])\n",
    "        i = load_fits_as_img(planes[\"PanSTARRS_i\"])\n",
    "        if g is not None and r_ is not None and i is not None:\n",
    "            # Compose RGB as (R= i, G= r, B= g)\n",
    "            H, W = i.shape\n",
    "            rgb = np.zeros((H, W, 3), dtype=np.float32)\n",
    "            rgb[...,0] = i\n",
    "            rgb[...,1] = r_\n",
    "            rgb[...,2] = g\n",
    "            plt.figure(figsize=(3.2,3.2))\n",
    "            plt.imshow(rgb, origin=\"lower\")\n",
    "            plt.axis('off')\n",
    "            plt.title(tag)\n",
    "            plt.tight_layout(pad=0)\n",
    "            plt.savefig(out_png, dpi=150, bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "            png_rows.append({\"tag\": tag, \"png\": str(out_png), \"rgb\": True})\n",
    "            continue\n",
    "\n",
    "    # Fallback: DSS2 Red if present\n",
    "    dss = CUT/f\"{tag}__DSS2_Red.fits\"\n",
    "    if dss.exists():\n",
    "        m = load_fits_as_img(dss)\n",
    "        if m is not None:\n",
    "            plt.figure(figsize=(3.2,3.2))\n",
    "            plt.imshow(m, origin=\"lower\", cmap=\"gray\")\n",
    "            plt.axis('off')\n",
    "            plt.title(tag+\" (DSS2)\")\n",
    "            plt.tight_layout(pad=0)\n",
    "            plt.savefig(out_png, dpi=150, bbox_inches=\"tight\", pad_inches=0)\n",
    "            plt.close()\n",
    "            png_rows.append({\"tag\": tag, \"png\": str(out_png), \"rgb\": False})\n",
    "            continue\n",
    "\n",
    "    png_rows.append({\"tag\": tag, \"png\": \"\", \"rgb\": False})\n",
    "\n",
    "PNG = pd.DataFrame(png_rows)\n",
    "\n",
    "# 4) Gold-set gating (tight but simple; tweak as you like)\n",
    "d = dfL.copy()\n",
    "# Add colors if missing\n",
    "if \"W1\" in d and \"W2\" in d: d[\"W1-W2\"] = d[\"W1\"] - d[\"W2\"]\n",
    "if \"W2\" in d and \"W3\" in d: d[\"W2-W3\"] = d[\"W2\"] - d[\"W3\"]\n",
    "if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "\n",
    "# Gates:\n",
    "#  - Gauge votes ≥ 4 (higher stability)\n",
    "#  - Red mid-IR slope OR warm dust signal: W2−W3 ≥ 1.0\n",
    "#  - \"likely not nearby star\": parallax < 1 mas AND pm_norm < 20 mas/yr (when available)\n",
    "#  - Good WISE quality in W1/W2 if known: ph_qual A/B\n",
    "def wise_good_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"AB\") and (w2 in \"AB\")\n",
    "\n",
    "mask_votes = d[\"_votes\"].fillna(0) >= 4\n",
    "mask_color = d[\"W2-W3\"].fillna(-99) >= 1.0\n",
    "mask_dist  = (d.get(\"parallax\", pd.Series(np.nan, index=d.index)).fillna(np.nan) < 1.0) | d[\"parallax\"].isna()\n",
    "mask_pm    = (d.get(\"pm_norm\", pd.Series(np.nan, index=d.index)).fillna(np.nan) < 20.0) | d[\"pm_norm\"].isna()\n",
    "mask_phq   = d[\"ph_qual\"].apply(wise_good_phqual) | d[\"ph_qual\"].isna()  # allow unknown if SNR already ok from earlier step\n",
    "\n",
    "gold = d[mask_votes & mask_color & mask_dist & mask_pm & mask_phq].reset_index(drop=True)\n",
    "\n",
    "# 5) Save rich tables + a simple HTML gallery\n",
    "rank_cols = [\"ra_deg\",\"dec\",\"_votes\",\"W1\",\"W2\",\"W3\",\"W4\",\"W1-W2\",\"W2-W3\",\"parallax\",\"pm_norm\",\"ph_qual\",\n",
    "             \"simbad_match\",\"simbad_main_id\",\"simbad_otype\",\"simbad_sp\"]\n",
    "long_path = OUT/\"strict_labeled_long.csv\"\n",
    "dfL.to_csv(long_path, index=False)\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "gold.to_csv(gold_path, index=False)\n",
    "\n",
    "# Merge with PNG info\n",
    "gallery = dfL.copy()\n",
    "gallery[\"tag\"] = [f\"cand{i:02d}_ra{float(r.get('ra_deg', r.get('RA_ICRS', r.get('ra', 0)) )):.5f}_dec{float(r.get('dec', r.get('DE_ICRS', 0))):.5f}\" for i, r in gallery.iterrows()]\n",
    "gallery = gallery.merge(PNG, on=\"tag\", how=\"left\")\n",
    "\n",
    "html = WEB/\"index.html\"\n",
    "with open(html, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"<html><head><meta charset='utf-8'><title>CNT Strict Shortlist</title>\")\n",
    "    f.write(\"<style>body{font-family:system-ui,Segoe UI,Arial;margin:24px} .card{display:flex;gap:16px;align-items:center;border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:180px;height:auto}</style>\")\n",
    "    f.write(\"</head><body><h1>CNT Strict Shortlist</h1>\")\n",
    "    f.write(f\"<p>Source: {src_path.name}</p>\")\n",
    "    for i, r in gallery.sort_values(\"_votes\", ascending=False).iterrows():\n",
    "        png = r.get(\"png\",\"\")\n",
    "        f.write(\"<div class='card'>\")\n",
    "        if png and Path(png).exists():\n",
    "            f.write(f\"<img src='../{Path(png).relative_to(OUT)}'/>\")\n",
    "        else:\n",
    "            f.write(\"<div style='width:180px;height:135px;background:#f3f3f3;border-radius:8px;display:flex;align-items:center;justify-content:center;color:#888'>no image</div>\")\n",
    "        f.write(\"<div>\")\n",
    "        f.write(f\"<div><b>RA,Dec:</b> {float(r['ra_deg']):.6f}, {float(r['dec']):.6f} &nbsp; <b>votes:</b> {int(r['_votes'])}</div>\")\n",
    "        f.write(f\"<div><b>W1-W2:</b> {r.get('W1')-r.get('W2') if pd.notna(r.get('W1')) and pd.notna(r.get('W2')) else '—'} &nbsp; \"\n",
    "                f\"<b>W2-W3:</b> {r.get('W2')-r.get('W3') if pd.notna(r.get('W2')) and pd.notna(r.get('W3')) else '—'}</div>\")\n",
    "        if bool(r.get(\"simbad_match\", False)):\n",
    "            f.write(f\"<div><b>SIMBAD:</b> {r.get('simbad_main_id','')} ({r.get('simbad_otype','')}) {r.get('simbad_sp','')}</div>\")\n",
    "        f.write(\"</div></div>\")\n",
    "    f.write(\"<h2>Gold Candidates</h2>\")\n",
    "    if len(gold)==0:\n",
    "        f.write(\"<p><i>No sources passed the gold gates; tweak thresholds or inspect relaxed set.</i></p>\")\n",
    "    else:\n",
    "        f.write(\"<ol>\")\n",
    "        for _, r in gold.iterrows():\n",
    "            f.write(f\"<li>{float(r['ra_deg']):.6f}, {float(r['dec']):.6f} (votes={int(r['_votes'])}, W2−W3={float(r['W2-W3']):.2f})</li>\")\n",
    "        f.write(\"</ol>\")\n",
    "    f.write(\"</body></html>\")\n",
    "\n",
    "print(\"\\n[save] Labeled long CSV →\", long_path)\n",
    "print(\"[save] Gold candidates   →\", gold_path, f\"({len(gold)})\")\n",
    "print(\"[save] PNGs/HTML gallery →\", html)\n",
    "# Preview top rows\n",
    "print(\"\\nTop rows (labeled):\")\n",
    "print(dfL[rank_cols].head(5).to_string(index=False))\n",
    "print(\"\\nGold candidates preview:\")\n",
    "print(gold[rank_cols].head(10).to_string(index=False) if len(gold) else \"(none yet)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79eff92f-e331-47c5-8f23-e8935e05450f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] cnt_anomaly\\out\\stable_enriched_strict_20251016-180208_grid3x3_K3.csv\n",
      "[save] Gold candidates → cnt_anomaly\\out\\strict_gold_candidates.csv (N=2)\n",
      "\n",
      "Gold preview:\n",
      "    ra_deg       dec  _votes     W1     W2     W3    W4  W1-W2  W2-W3  ph_qual\n",
      "209.236537 -1.289745       4 14.349 14.000 10.232 8.481  0.349  3.768      NaN\n",
      "210.910946 -1.291592       4 15.128 15.196 12.670 9.344 -0.068  2.526      NaN\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — GOLD gate (robust to missing columns)\n",
    "# Re-run even if 'parallax' or 'pm_norm' aren't present in the strict CSV.\n",
    "\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\")\n",
    "stricts = sorted(OUT.glob(\"stable_enriched_strict_*_grid3x3_*.csv\")) or sorted(OUT.glob(\"stable_enriched_strict_*.csv\"))\n",
    "assert stricts, \"No strict enriched CSV found.\"\n",
    "src_path = stricts[-1]\n",
    "print(\"[load]\", src_path)\n",
    "d = pd.read_csv(src_path).reset_index(drop=True)\n",
    "\n",
    "# ---- Safe feature rebuilds ----\n",
    "# Colors\n",
    "if \"W1\" in d and \"W2\" in d and \"W1-W2\" not in d:\n",
    "    d[\"W1-W2\"] = d[\"W1\"] - d[\"W2\"]\n",
    "if \"W2\" in d and \"W3\" in d and \"W2-W3\" not in d:\n",
    "    d[\"W2-W3\"] = d[\"W2\"] - d[\"W3\"]\n",
    "\n",
    "# pm_norm if possible\n",
    "if \"pm_norm\" not in d and (\"pmRA\" in d and \"pmDE\" in d):\n",
    "    d[\"pm_norm\"] = np.hypot(d[\"pmRA\"].astype(float), d[\"pmDE\"].astype(float))\n",
    "\n",
    "# Safe accessors\n",
    "par = d[\"parallax\"] if \"parallax\" in d.columns else pd.Series(np.nan, index=d.index)\n",
    "pmn = d[\"pm_norm\"] if \"pm_norm\" in d.columns else pd.Series(np.nan, index=d.index)\n",
    "\n",
    "# ph_qual gate helper\n",
    "def wise_good_phqual(s):\n",
    "    s = str(s) if isinstance(s, str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"\n",
    "    w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in \"AB\") and (w2 in \"AB\")\n",
    "\n",
    "# ---- GOLD masks (robust) ----\n",
    "votes     = d[\"_votes\"].fillna(0)\n",
    "w2w3      = d[\"W2-W3\"] if \"W2-W3\" in d else pd.Series(-99, index=d.index)\n",
    "phq_ok    = d[\"ph_qual\"].apply(wise_good_phqual) if \"ph_qual\" in d else pd.Series(True, index=d.index)\n",
    "\n",
    "mask_votes = votes >= 4\n",
    "mask_color = w2w3.fillna(-99) >= 1.0\n",
    "mask_dist  = (par.fillna(np.inf) < 1.0) | par.isna()        # pass if unknown or <1 mas\n",
    "mask_pm    = (pmn.fillna(np.inf) < 20.0) | pmn.isna()       # pass if unknown or <20 mas/yr\n",
    "mask_phq   = phq_ok                                         # allow True if unknown above\n",
    "\n",
    "gold = d[mask_votes & mask_color & mask_dist & mask_pm & mask_phq].copy().reset_index(drop=True)\n",
    "\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "d.to_csv(OUT/\"strict_labeled_long.csv\", index=False)\n",
    "gold.to_csv(gold_path, index=False)\n",
    "\n",
    "print(f\"[save] Gold candidates → {gold_path} (N={len(gold)})\")\n",
    "print(\"\\nGold preview:\")\n",
    "show_cols = [c for c in [\"ra_deg\",\"dec\",\"_votes\",\"W1\",\"W2\",\"W3\",\"W4\",\"W1-W2\",\"W2-W3\",\"parallax\",\"pm_norm\",\"ph_qual\"] if c in gold.columns]\n",
    "print(\"(none)\" if gold.empty else gold[show_cols].head(10).to_string(index=False))\n",
    "\n",
    "# Optional: quick diagnostic scatter if colors exist\n",
    "if \"W1-W2\" in d and \"W2-W3\" in d:\n",
    "    import matplotlib.pyplot as plt\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.scatter(d[\"W1-W2\"], d[\"W2-W3\"], s=24, alpha=0.8, label=\"strict\")\n",
    "    if not gold.empty:\n",
    "        plt.scatter(gold.get(\"W1-W2\", []), gold.get(\"W2-W3\", []), s=40, marker=\"*\", label=\"gold\")\n",
    "    plt.xlabel(\"W1 - W2 (mag)\"); plt.ylabel(\"W2 - W3 (mag)\"); plt.legend()\n",
    "    plt.title(\"WISE color–color (gold highlighted)\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUT/\"figures/diag_wise_color_color_gold.png\", dpi=150)\n",
    "    plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c01ce406-b640-4c3e-b57f-e0c85e6fcb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[verify] RA=209.236537 Dec=-1.289745 — rechecking K=4 in R=0.5°\n",
      "[verify] RA=210.910946 Dec=-1.291592 — rechecking K=4 in R=0.5°\n",
      "[save] gold verification → cnt_anomaly\\out\\gold_verification.csv\n",
      "[save] summary → cnt_anomaly\\out\\gold_verification_summary.md\n",
      "\n",
      "Preview:\n",
      "    ra_deg       dec  old_votes  new_votes_at_source     W1     W2     W3    W4  W1-W2  W2-W3  simbad_match simbad_main_id simbad_otype simbad_otypes simbad_sp\n",
      "209.236537 -1.289745          4                  NaN 14.349 14.000 10.232 8.481  0.349  3.768          True                                                    \n",
      "210.910946 -1.291592          4                  NaN 15.128 15.196 12.670 9.344 -0.068  2.526         False                                                    \n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Gold Verifier v1 (K=4 recheck + SIMBAD labels)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"pyvo\",\"scikit-learn\",\"astropy\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "assert gold_path.exists(), \"strict_gold_candidates.csv not found. Run the gold gate cell first.\"\n",
    "gold = pd.read_csv(gold_path)\n",
    "assert len(gold)>0, \"Gold list is empty.\"\n",
    "\n",
    "# ---- Parameters for recheck ----\n",
    "RADIUS_DEG = 0.5     # tighter field\n",
    "N_MAX = 3000\n",
    "XMM_RADIUS_ARCSEC = 1.0\n",
    "K_STABILITY = 4      # gold mode\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Vizier.ROW_LIMIT = N_MAX\n",
    "\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=N_MAX):\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec=XMM_RADIUS_ARCSEC):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in df.columns: df[v] = df[k]\n",
    "    return df.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d:\n",
    "        d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "def make_feature_views(df):\n",
    "    numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "    keep_cols = [c for c in numeric.columns if c!=\"dist_pc\"]\n",
    "    X0 = numeric[keep_cols].fillna(numeric[keep_cols].median())\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"G\",\"BP_RP\",\"MG\",\"SED_slope\",\"pm_norm\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c in [\"BP_RP\",\"SED_slope_W1_W3\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4: views[\"V4_jitter\"] = X0[cols4].values + np.random.default_rng(SEED).normal(0,1e-3,size=X0[cols4].shape)\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a,X5b],axis=1)\n",
    "    return views\n",
    "\n",
    "def ensemble_flags(views):\n",
    "    flags = {}\n",
    "    rng = np.random.RandomState(42)\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    return flags\n",
    "\n",
    "def vote(flags):\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "# SIMBAD setup\n",
    "custom = Simbad()\n",
    "custom.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "rows=[]\n",
    "for idx, r in gold.iterrows():\n",
    "    ra = float(r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\"))\n",
    "    dec = float(r.get(\"dec\") or r.get(\"DE_ICRS\"))\n",
    "    print(f\"[verify] RA={ra:.6f} Dec={dec:.6f} — rechecking K=4 in R={RADIUS_DEG}°\")\n",
    "\n",
    "    # Rebuild local anomaly context\n",
    "    gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, RADIUS_DEG,\n",
    "                        columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"], row_limit=N_MAX)\n",
    "    gw = xmatch_gaia_allwise(gaia)\n",
    "    df = add_derived_features(clean_photometry(gw))\n",
    "    views = make_feature_views(df)\n",
    "    votes = vote(ensemble_flags(views))\n",
    "    if votes is None or len(df)==0:\n",
    "        new_votes_at_source = np.nan\n",
    "    else:\n",
    "        df[\"_votes\"] = votes\n",
    "        # nearest row to our RA/Dec within 3\"\n",
    "        coord0 = SkyCoord(ra*u.deg, dec*u.deg)\n",
    "        coords = SkyCoord(df[\"ra_deg\"].values*u.deg, df[\"dec\"].values*u.deg)\n",
    "        sep = coords.separation(coord0).arcsec\n",
    "        j = int(np.argmin(sep)) if len(sep)>0 else None\n",
    "        new_votes_at_source = int(df.iloc[j][\"_votes\"]) if j is not None and sep[j] <= 3.0 else np.nan\n",
    "\n",
    "    # SIMBAD label\n",
    "    coord = SkyCoord(ra*u.deg, dec*u.deg)\n",
    "    try:\n",
    "        s = custom.query_region(coord, radius=2*u.arcsec)\n",
    "    except Exception:\n",
    "        s = None\n",
    "    if s is None or len(s)==0:\n",
    "        smatch=False; sid=\"\"; otype=\"\"; otypes=\"\"; sp=\"\"\n",
    "    else:\n",
    "        p = s.to_pandas().iloc[0]\n",
    "        smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\"); otypes=p.get(\"OTYPES\",\"\"); sp=p.get(\"SP_TYPE\",\"\")\n",
    "\n",
    "    rows.append({\n",
    "        \"ra_deg\": ra, \"dec\": dec,\n",
    "        \"old_votes\": int(r[\"_votes\"]),\n",
    "        \"new_votes_at_source\": new_votes_at_source,\n",
    "        \"W1\": r.get(\"W1\", np.nan), \"W2\": r.get(\"W2\", np.nan), \"W3\": r.get(\"W3\", np.nan), \"W4\": r.get(\"W4\", np.nan),\n",
    "        \"W1-W2\": r.get(\"W1\", np.nan) - r.get(\"W2\", np.nan) if pd.notna(r.get(\"W1\", np.nan)) and pd.notna(r.get(\"W2\", np.nan)) else np.nan,\n",
    "        \"W2-W3\": r.get(\"W2\", np.nan) - r.get(\"W3\", np.nan) if pd.notna(r.get(\"W2\", np.nan)) and pd.notna(r.get(\"W3\", np.nan)) else np.nan,\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype, \"simbad_otypes\": otypes, \"simbad_sp\": sp\n",
    "    })\n",
    "\n",
    "ver = pd.DataFrame(rows)\n",
    "ver_path = OUT/\"gold_verification.csv\"\n",
    "ver.to_csv(ver_path, index=False)\n",
    "print(f\"[save] gold verification → {ver_path}\")\n",
    "\n",
    "# Tiny summary\n",
    "md = OUT/\"gold_verification_summary.md\"\n",
    "with open(md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# CNT Techno-Anomaly — Gold Verification\\n\\n\")\n",
    "    for _, r in ver.iterrows():\n",
    "        f.write(f\"- RA={r['ra_deg']:.6f}, Dec={r['dec']:.6f}: old_votes={int(r['old_votes'])}, \"\n",
    "                f\"new_votes_at_source={r.get('new_votes_at_source')}, \"\n",
    "                f\"W1−W2={r.get('W1-W2'):.3f}, W2−W3={r.get('W2-W3'):.3f}, \"\n",
    "                f\"SIMBAD={'✓' if r['simbad_match'] else '—'} {r.get('simbad_main_id','')} ({r.get('simbad_otype','')})\\n\")\n",
    "print(\"[save] summary →\", md)\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "print(ver.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5fef8f9-290a-4067-90d7-96c45d353067",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[verify-v2] RA=209.236537 Dec=-1.289745\n",
      "[verify-v2] RA=210.910946 Dec=-1.291592\n",
      "[save] gold verification v2 → cnt_anomaly\\out\\gold_verification_v2.csv\n",
      "\n",
      "Preview:\n",
      "    ra_deg       dec  old_votes  new_votes_at_nearest  nearest_sep_arcsec  W1-W2  W2-W3          class_hint  simbad_match simbad_main_id simbad_otype  simbad_radius_used_arcsec\n",
      "209.236537 -1.289745          4                   NaN         1552.979729  0.349  3.768 YSO/dusty-star-like          True                                                    2.0\n",
      "210.910946 -1.291592          4                   NaN         1567.746745 -0.068  2.526           ambiguous         False                                                    NaN\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Gold Verifier v2 (robust nearest match + richer SIMBAD)\n",
    "import os, io, sys, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"pyvo\",\"scikit-learn\",\"astropy\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "assert gold_path.exists(), \"strict_gold_candidates.csv not found.\"\n",
    "gold = pd.read_csv(gold_path); assert len(gold)>0\n",
    "\n",
    "# ---- Params ----\n",
    "RADIUS_DEG = 0.5\n",
    "N_MAX = 3000\n",
    "XMM_RADIUS_ARCSEC = 1.0\n",
    "K_STABILITY = 4\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01\n",
    "NEAREST_ARCSEC = 10.0   # expanded nearest-neighbor catch radius\n",
    "SIMBAD_RADII = [2.0, 5.0]  # try 2\", then 5\"\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Vizier.ROW_LIMIT = N_MAX\n",
    "\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=N_MAX):\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec=XMM_RADIUS_ARCSEC):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in df.columns: df[v] = df[k]\n",
    "    return df.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d:\n",
    "        d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "def make_feature_views(df):\n",
    "    numeric = df.select_dtypes(include=[np.number]).copy()\n",
    "    keep_cols = [c for c in numeric.columns if c!=\"dist_pc\"]\n",
    "    X0 = numeric[keep_cols].fillna(numeric[keep_cols].median())\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"G\",\"BP_RP\",\"MG\",\"SED_slope\",\"pm_norm\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c in [\"BP_RP\",\"SED_slope_W1_W3\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4: views[\"V4_jitter\"] = X0[cols4].values + np.random.default_rng(SEED).normal(0,1e-3,size=X0[cols4].shape)\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a,X5b],axis=1)\n",
    "    return views\n",
    "\n",
    "def ensemble_votes(df):\n",
    "    views = make_feature_views(df)\n",
    "    flags = {}\n",
    "    rng = np.random.RandomState(42)\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "# SIMBAD config\n",
    "custom = Simbad()\n",
    "custom.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "def simbad_best_label(ra, dec):\n",
    "    coord = SkyCoord(ra*u.deg, dec*u.deg)\n",
    "    for rad in SIMBAD_RADII:\n",
    "        try:\n",
    "            res = custom.query_region(coord, radius=rad*u.arcsec)\n",
    "        except Exception:\n",
    "            res = None\n",
    "        if res is not None and len(res)>0:\n",
    "            p = res.to_pandas().iloc[0]\n",
    "            return True, p.get(\"MAIN_ID\",\"\"), p.get(\"OTYPE\",\"\"), p.get(\"OTYPES\",\"\"), p.get(\"SP_TYPE\",\"\"), rad\n",
    "    return False, \"\", \"\", \"\", \"\", None\n",
    "\n",
    "def class_hint(row):\n",
    "    w12 = row.get(\"W1\") - row.get(\"W2\") if pd.notna(row.get(\"W1\")) and pd.notna(row.get(\"W2\")) else np.nan\n",
    "    w23 = row.get(\"W2\") - row.get(\"W3\") if pd.notna(row.get(\"W2\")) and pd.notna(row.get(\"W3\")) else np.nan\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12 >= 0.8) and (w23 >= 1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12 >= 0.3) and (w23 >= 1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "rows=[]\n",
    "for _, r in gold.iterrows():\n",
    "    ra0 = float(r.get(\"ra_deg\") or r.get(\"RA_ICRS\") or r.get(\"ra\"))\n",
    "    dec0= float(r.get(\"dec\") or r.get(\"DE_ICRS\"))\n",
    "    print(f\"[verify-v2] RA={ra0:.6f} Dec={dec0:.6f}\")\n",
    "\n",
    "    # Local field, votes\n",
    "    gaia = vizier_query(\"I/355/gaiadr3\", ra0, dec0, RADIUS_DEG,\n",
    "                        columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"], row_limit=N_MAX)\n",
    "    gw = xmatch_gaia_allwise(gaia)\n",
    "    df = add_derived_features(clean_photometry(gw))\n",
    "    vote_arr = ensemble_votes(df)\n",
    "    if vote_arr is None or df.empty:\n",
    "        new_votes = np.nan; nearest_sep = np.nan; nearest_ra = np.nan; nearest_dec = np.nan\n",
    "    else:\n",
    "        df[\"_votes\"] = vote_arr\n",
    "        # nearest within 10\"\n",
    "        target = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "        coords = SkyCoord(df[\"ra_deg\"].values*u.deg, df[\"dec\"].values*u.deg)\n",
    "        seps = coords.separation(target).arcsec\n",
    "        j = int(np.argmin(seps))\n",
    "        nearest_sep = float(seps[j])\n",
    "        if nearest_sep <= NEAREST_ARCSEC:\n",
    "            new_votes = int(df.iloc[j][\"_votes\"])\n",
    "            nearest_ra = float(df.iloc[j][\"ra_deg\"]); nearest_dec = float(df.iloc[j][\"dec\"])\n",
    "        else:\n",
    "            new_votes = np.nan; nearest_ra = np.nan; nearest_dec = np.nan\n",
    "\n",
    "    smatch, sid, otype, otypes, sp, used_rad = simbad_best_label(ra0, dec0)\n",
    "\n",
    "    rows.append({\n",
    "        \"ra_deg\": ra0, \"dec\": dec0,\n",
    "        \"old_votes\": int(r[\"_votes\"]),\n",
    "        \"new_votes_at_nearest\": new_votes,\n",
    "        \"nearest_sep_arcsec\": nearest_sep,\n",
    "        \"nearest_ra\": nearest_ra, \"nearest_dec\": nearest_dec,\n",
    "        \"W1\": r.get(\"W1\", np.nan), \"W2\": r.get(\"W2\", np.nan), \"W3\": r.get(\"W3\", np.nan), \"W4\": r.get(\"W4\", np.nan),\n",
    "        \"W1-W2\": (r.get(\"W1\", np.nan)-r.get(\"W2\", np.nan)) if pd.notna(r.get(\"W1\", np.nan)) and pd.notna(r.get(\"W2\", np.nan)) else np.nan,\n",
    "        \"W2-W3\": (r.get(\"W2\", np.nan)-r.get(\"W3\", np.nan)) if pd.notna(r.get(\"W2\", np.nan)) and pd.notna(r.get(\"W3\", np.nan)) else np.nan,\n",
    "        \"class_hint\": class_hint(r),\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype, \"simbad_otypes\": otypes, \"simbad_sp\": sp,\n",
    "        \"simbad_radius_used_arcsec\": used_rad\n",
    "    })\n",
    "\n",
    "ver2 = pd.DataFrame(rows)\n",
    "ver2_path = OUT/\"gold_verification_v2.csv\"\n",
    "ver2.to_csv(ver2_path, index=False)\n",
    "print(f\"[save] gold verification v2 → {ver2_path}\")\n",
    "\n",
    "print(\"\\nPreview:\")\n",
    "cols = [\"ra_deg\",\"dec\",\"old_votes\",\"new_votes_at_nearest\",\"nearest_sep_arcsec\",\"W1-W2\",\"W2-W3\",\"class_hint\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\",\"simbad_radius_used_arcsec\"]\n",
    "print(ver2[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2752abda-9c12-4ad4-bcac-f0563ad3612f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Invalid value '73.5' for dtype 'Int32'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2401\u001b[39m, in \u001b[36mExtensionBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[39m\n\u001b[32m   2400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2401\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2402\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[32m   2403\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2404\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   2405\u001b[39m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:267\u001b[39m, in \u001b[36mBaseMaskedArray.fillna\u001b[39m\u001b[34m(self, value, method, limit, copy)\u001b[39m\n\u001b[32m    266\u001b[39m             new_values = \u001b[38;5;28mself\u001b[39m[:]\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m = value\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:315\u001b[39m, in \u001b[36mBaseMaskedArray.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     \u001b[38;5;28mself\u001b[39m._data[key] = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:306\u001b[39m, in \u001b[36mBaseMaskedArray._validate_setitem_value\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    302\u001b[39m     \u001b[38;5;66;03m# TODO: unsigned checks\u001b[39;00m\n\u001b[32m    303\u001b[39m \n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# Note: without the \"str\" here, the f-string rendering raises in\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m#  py38 builds.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid value \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Invalid value '73.5' for dtype 'Int32'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 137\u001b[39m\n\u001b[32m    135\u001b[39m wise = res[\u001b[32m0\u001b[39m].to_pandas()\n\u001b[32m    136\u001b[39m \u001b[38;5;66;03m# Build features & votes\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m wise_feat, views = \u001b[43mwise_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwise\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    138\u001b[39m v = votes_from_views(views)\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m v \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 64\u001b[39m, in \u001b[36mwise_features\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     62\u001b[39m num = d.select_dtypes(include=[np.number]).copy()\n\u001b[32m     63\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mdist_pc\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m num: num = num.drop(columns=[\u001b[33m\"\u001b[39m\u001b[33mdist_pc\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m X0 = \u001b[43mnum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmedian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[38;5;66;03m# build five symbol-preserving views\u001b[39;00m\n\u001b[32m     66\u001b[39m views = {}\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:7407\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7394\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7395\u001b[39m     downcast_k = (\n\u001b[32m   7396\u001b[39m         \u001b[38;5;66;03m# error: Incompatible types in assignment (expression\u001b[39;00m\n\u001b[32m   7397\u001b[39m         \u001b[38;5;66;03m# has type \"Union[Dict[Any, Any], None,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   7404\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m downcast.get(k)  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   7405\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m7407\u001b[39m res_k = \u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast_k\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7409\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m inplace:\n\u001b[32m   7410\u001b[39m     result[k] = res_k\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:7372\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7365\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   7367\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m parameter must be a scalar, dict \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Series, but you passed a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7369\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7370\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m7372\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\n\u001b[32m   7374\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7376\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[32m   7377\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:186\u001b[39m, in \u001b[36mDataManager.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[32m    184\u001b[39m     limit = libalgos.validate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit=limit)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfillna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:2407\u001b[39m, in \u001b[36mExtensionBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[39m\n\u001b[32m   2404\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[32m   2405\u001b[39m     \u001b[38;5;66;03m# 3rd party EA that has not implemented copy keyword yet\u001b[39;00m\n\u001b[32m   2406\u001b[39m     refs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2407\u001b[39m     new_values = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2408\u001b[39m     \u001b[38;5;66;03m# issue the warning *after* retrying, in case the TypeError\u001b[39;00m\n\u001b[32m   2409\u001b[39m     \u001b[38;5;66;03m#  was caused by an invalid fill_value\u001b[39;00m\n\u001b[32m   2410\u001b[39m     warnings.warn(\n\u001b[32m   2411\u001b[39m         \u001b[38;5;66;03m# GH#53278\u001b[39;00m\n\u001b[32m   2412\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mExtensionArray.fillna added a \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcopy\u001b[39m\u001b[33m'\u001b[39m\u001b[33m keyword in pandas \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m   2418\u001b[39m         stacklevel=find_stack_level(),\n\u001b[32m   2419\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:267\u001b[39m, in \u001b[36mBaseMaskedArray.fillna\u001b[39m\u001b[34m(self, value, method, limit, copy)\u001b[39m\n\u001b[32m    265\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    266\u001b[39m             new_values = \u001b[38;5;28mself\u001b[39m[:]\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m         \u001b[43mnew_values\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m = value\n\u001b[32m    268\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    269\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m copy:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:315\u001b[39m, in \u001b[36mBaseMaskedArray.__setitem__\u001b[39m\u001b[34m(self, key, value)\u001b[39m\n\u001b[32m    313\u001b[39m     \u001b[38;5;28mself\u001b[39m._mask[key] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    314\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m315\u001b[39m     value = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_setitem_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    316\u001b[39m     \u001b[38;5;28mself\u001b[39m._data[key] = value\n\u001b[32m    317\u001b[39m     \u001b[38;5;28mself\u001b[39m._mask[key] = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\arrays\\masked.py:306\u001b[39m, in \u001b[36mBaseMaskedArray._validate_setitem_value\u001b[39m\u001b[34m(self, value)\u001b[39m\n\u001b[32m    301\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m value\n\u001b[32m    302\u001b[39m     \u001b[38;5;66;03m# TODO: unsigned checks\u001b[39;00m\n\u001b[32m    303\u001b[39m \n\u001b[32m    304\u001b[39m \u001b[38;5;66;03m# Note: without the \"str\" here, the f-string rendering raises in\u001b[39;00m\n\u001b[32m    305\u001b[39m \u001b[38;5;66;03m#  py38 builds.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid value \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mvalue\u001b[38;5;132;01m!s}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m for dtype \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Invalid value '73.5' for dtype 'Int32'"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Gold Verifier v3 (AllWISE-only, robust nearest match)\n",
    "# Recomputes gauge votes around each gold target using AllWISE features only.\n",
    "# Finds the nearest AllWISE source (≤10\") and reports votes, colors, and SIMBAD labels.\n",
    "\n",
    "import os, io, sys, json, time, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    to_install=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: to_install.append(p)\n",
    "    if to_install:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *to_install])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "assert gold_path.exists(), \"strict_gold_candidates.csv not found. Run the gold gate cell first.\"\n",
    "gold = pd.read_csv(gold_path); assert len(gold)>0, \"Gold list is empty.\"\n",
    "\n",
    "# ==== Config ====\n",
    "CONE_ARCMIN = 6.0        # AllWISE search radius around each gold target\n",
    "NEAREST_ARCSEC = 10.0    # accept nearest match within this radius\n",
    "K_STABILITY = 4          # gold threshold\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Vizier.ROW_LIMIT = -1\n",
    "\n",
    "# ==== Helpers ====\n",
    "def wise_features(df):\n",
    "    d = df.copy()\n",
    "    # rename standard columns if present\n",
    "    ren = {\n",
    "        \"W1mag\":\"W1\", \"W2mag\":\"W2\", \"W3mag\":\"W3\", \"W4mag\":\"W4\",\n",
    "        \"e_W1mag\":\"eW1\", \"e_W2mag\":\"eW2\", \"e_W3mag\":\"eW3\", \"e_W4mag\":\"eW4\",\n",
    "        \"RAJ2000\":\"ra_deg\", \"DEJ2000\":\"dec\"\n",
    "    }\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    # colors + simple slope\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d:\n",
    "            d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if all(c in d.columns for c in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    # numeric block\n",
    "    num = d.select_dtypes(include=[np.number]).copy()\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    X0 = num.fillna(num.median(numeric_only=True))\n",
    "    # build five symbol-preserving views\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy()\n",
    "        X3 = X3 - X3.min().min() + 1e-3\n",
    "        X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        rng = np.random.default_rng(SEED)\n",
    "        X4 += rng.normal(0, 1e-3, size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1])\n",
    "        X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return d, views\n",
    "\n",
    "def votes_from_views(views):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    flags = {}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "def class_hint_row(r):\n",
    "    w12 = r.get(\"W1\") - r.get(\"W2\") if pd.notna(r.get(\"W1\")) and pd.notna(r.get(\"W2\")) else np.nan\n",
    "    w23 = r.get(\"W2\") - r.get(\"W3\") if pd.notna(r.get(\"W2\")) and pd.notna(r.get(\"W3\")) else np.nan\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12 >= 0.8) and (w23 >= 1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12 >= 0.3) and (w23 >= 1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "# SIMBAD config\n",
    "simb = Simbad(); simb.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "rows=[]\n",
    "for _, g in gold.iterrows():\n",
    "    ra0 = float(g.get(\"ra_deg\") or g.get(\"RA_ICRS\") or g.get(\"ra\"))\n",
    "    dec0= float(g.get(\"dec\") or g.get(\"DE_ICRS\"))\n",
    "    target = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "\n",
    "    # AllWISE cone around the target (no Gaia dependency)\n",
    "    Vizier.columns = [\"**\"]\n",
    "    res = Vizier.query_region(target, radius=(CONE_ARCMIN*u.arcmin), catalog=\"II/328/allwise\")\n",
    "    if len(res)==0 or len(res[0])==0:\n",
    "        rows.append({\n",
    "            \"ra_deg\": ra0, \"dec\": dec0, \"votes_allwise_nearest\": np.nan,\n",
    "            \"nearest_sep_arcsec\": np.nan, \"nearest_ra\": np.nan, \"nearest_dec\": np.nan,\n",
    "            \"class_hint\": \"no AllWISE in cone\", \"simbad_match\": False, \"simbad_main_id\": \"\", \"simbad_otype\": \"\"\n",
    "        })\n",
    "        continue\n",
    "\n",
    "    wise = res[0].to_pandas()\n",
    "    # Build features & votes\n",
    "    wise_feat, views = wise_features(wise)\n",
    "    v = votes_from_views(views)\n",
    "    if v is None:\n",
    "        rows.append({\n",
    "            \"ra_deg\": ra0, \"dec\": dec0, \"votes_allwise_nearest\": np.nan,\n",
    "            \"nearest_sep_arcsec\": np.nan, \"nearest_ra\": np.nan, \"nearest_dec\": np.nan,\n",
    "            \"class_hint\": \"no features\", \"simbad_match\": False, \"simbad_main_id\": \"\", \"simbad_otype\": \"\"\n",
    "        })\n",
    "        continue\n",
    "    wise_feat[\"_votes\"] = v\n",
    "\n",
    "    # Nearest AllWISE to the gold coordinate\n",
    "    coords = SkyCoord(wise_feat[\"ra_deg\"].values*u.deg, wise_feat[\"dec\"].values*u.deg)\n",
    "    seps = coords.separation(target).arcsec\n",
    "    j = int(np.argmin(seps))\n",
    "    nearest_sep = float(seps[j])\n",
    "    votes_nearest = int(wise_feat.iloc[j][\"_votes\"]) if nearest_sep <= NEAREST_ARCSEC else np.nan\n",
    "\n",
    "    # SIMBAD label (try 5\")\n",
    "    try:\n",
    "        s = simb.query_region(target, radius=5.0*u.arcsec)\n",
    "        if s is not None and len(s)>0:\n",
    "            p = s.to_pandas().iloc[0]\n",
    "            smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\")\n",
    "        else:\n",
    "            smatch=False; sid=\"\"; otype=\"\"\n",
    "    except Exception:\n",
    "        smatch=False; sid=\"\"; otype=\"\"\n",
    "\n",
    "    r = wise_feat.iloc[j].to_dict()\n",
    "    rows.append({\n",
    "        \"ra_deg\": ra0, \"dec\": dec0,\n",
    "        \"nearest_ra\": float(r.get(\"ra_deg\", np.nan)),\n",
    "        \"nearest_dec\": float(r.get(\"dec\", np.nan)),\n",
    "        \"nearest_sep_arcsec\": nearest_sep,\n",
    "        \"votes_allwise_nearest\": votes_nearest,\n",
    "        \"passes_gold_K\": bool(votes_nearest >= K_STABILITY) if pd.notna(votes_nearest) else False,\n",
    "        \"W1\": r.get(\"W1\", np.nan), \"W2\": r.get(\"W2\", np.nan), \"W3\": r.get(\"W3\", np.nan), \"W4\": r.get(\"W4\", np.nan),\n",
    "        \"W1-W2\": (r.get(\"W1\", np.nan)-r.get(\"W2\", np.nan)) if pd.notna(r.get(\"W1\", np.nan)) and pd.notna(r.get(\"W2\", np.nan)) else np.nan,\n",
    "        \"W2-W3\": (r.get(\"W2\", np.nan)-r.get(\"W3\", np.nan)) if pd.notna(r.get(\"W2\", np.nan)) and pd.notna(r.get(\"W3\", np.nan)) else np.nan,\n",
    "        \"class_hint\": class_hint_row(r),\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype\n",
    "    })\n",
    "\n",
    "ver3 = pd.DataFrame(rows)\n",
    "out_csv = OUT/\"gold_verification_allwise.csv\"\n",
    "ver3.to_csv(out_csv, index=False)\n",
    "\n",
    "print(f\"[save] AllWISE verifier → {out_csv}\")\n",
    "print(\"\\nPreview:\")\n",
    "cols = [\"ra_deg\",\"dec\",\"nearest_sep_arcsec\",\"votes_allwise_nearest\",\"passes_gold_K\",\"W1-W2\",\"W2-W3\",\"class_hint\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\"]\n",
    "print(ver3[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fc8d45c4-4002-48d9-b750-a7059ce70660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wise_features() hotfixed: numeric columns coerced to float64 before fillna.\n"
     ]
    }
   ],
   "source": [
    "# HOTFIX — make wise_features robust to pandas Int32 masked dtypes\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "def wise_features(df):\n",
    "    d = df.copy()\n",
    "    # Standardize column names if present\n",
    "    ren = {\n",
    "        \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "        \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "        \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"\n",
    "    }\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "\n",
    "    # Colors & simple slope (safe even if some cols missing)\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d:\n",
    "            d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if all(c in d.columns for c in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"]) / 2.0\n",
    "\n",
    "    # === Robust numeric block ===\n",
    "    num = d.select_dtypes(include=[np.number]).copy()\n",
    "\n",
    "    # Force EVERY numeric column to float64 to avoid Int32 fillna issues\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "\n",
    "    # (drop any derived distance if it sneaks in)\n",
    "    if \"dist_pc\" in num:\n",
    "        num = num.drop(columns=[\"dist_pc\"])\n",
    "\n",
    "    # Median impute on float64 — now safe\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0 = num.fillna(med)\n",
    "\n",
    "    views = {}\n",
    "    # V1: robust scale on mags/colors/slope-only columns\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "    if cols1:\n",
    "        views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "\n",
    "    # V2: colors-only standardized\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "    if cols2:\n",
    "        views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "\n",
    "    # V3: log-reordered on raw W1..W4\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy()\n",
    "        X3 = X3 - X3.min().min() + 1e-3\n",
    "        X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "\n",
    "    # V4: jitter-resilient (small noise on combined cols)\n",
    "    cols4 = sorted(set(cols1 + cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        rng = np.random.default_rng(42)\n",
    "        X4 += rng.normal(0, 1e-3, size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "\n",
    "    # V5: mixed (robust+standard concat)\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1])\n",
    "        X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "\n",
    "    return d, views\n",
    "\n",
    "print(\"wise_features() hotfixed: numeric columns coerced to float64 before fillna.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94363ae3-732b-4463-b80f-3b1826df15ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] AllWISE verifier → cnt_anomaly\\out\\gold_verification_allwise.csv\n",
      "\n",
      "Preview:\n",
      "    ra_deg       dec  nearest_sep_arcsec  votes_allwise_nearest  passes_gold_K    W1-W2  W2-W3      class_hint  simbad_match simbad_main_id simbad_otype\n",
      "209.236537 -1.289745          255.341902                    NaN          False 0.884999  3.861 AGN/galaxy-like          True                            \n",
      "210.910946 -1.291592          206.118495                    NaN          False 0.216000  3.340       ambiguous         False                            \n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — AllWISE Verifier (lite; uses hot-fixed wise_features)\n",
    "import os, importlib, warnings, subprocess, sys\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# ---- Config\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold_path = OUT/\"strict_gold_candidates.csv\"\n",
    "assert gold_path.exists(), \"strict_gold_candidates.csv not found.\"\n",
    "gold = pd.read_csv(gold_path); assert len(gold)>0\n",
    "\n",
    "CONE_ARCMIN = 6.0\n",
    "NEAREST_ARCSEC = 10.0\n",
    "K_STABILITY = 4\n",
    "N_ESTIMATORS = 300\n",
    "CONTAM = 0.01\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Vizier.ROW_LIMIT = -1\n",
    "\n",
    "# ---- Helpers (reuse your hot-fixed wise_features from globals)\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "\n",
    "def votes_from_views(views):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=N_ESTIMATORS, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name]= (f1|f2)\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "def class_hint_row(r):\n",
    "    w12 = r.get(\"W1\")-r.get(\"W2\") if pd.notna(r.get(\"W1\")) and pd.notna(r.get(\"W2\")) else np.nan\n",
    "    w23 = r.get(\"W2\")-r.get(\"W3\") if pd.notna(r.get(\"W2\")) and pd.notna(r.get(\"W3\")) else np.nan\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12>=0.8) and (w23>=1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12>=0.3) and (w23>=1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "simb = Simbad(); simb.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "rows=[]\n",
    "for _, g in gold.iterrows():\n",
    "    ra0 = float(g.get(\"ra_deg\") or g.get(\"RA_ICRS\") or g.get(\"ra\"))\n",
    "    dec0= float(g.get(\"dec\") or g.get(\"DE_ICRS\"))\n",
    "    target = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "\n",
    "    # AllWISE cone\n",
    "    res = Vizier(columns=[\"**\"]).query_region(target, radius=(CONE_ARCMIN*u.arcmin), catalog=\"II/328/allwise\")\n",
    "    if len(res)==0 or len(res[0])==0:\n",
    "        rows.append({\"ra_deg\":ra0,\"dec\":dec0,\"votes_allwise_nearest\":np.nan,\"nearest_sep_arcsec\":np.nan,\n",
    "                     \"class_hint\":\"no AllWISE in cone\",\"simbad_match\":False,\"simbad_main_id\":\"\",\"simbad_otype\":\"\"})\n",
    "        continue\n",
    "\n",
    "    wise = res[0].to_pandas()\n",
    "    # Use the hot-fixed wise_features already defined in your kernel\n",
    "    wise_feat, views = wise_features(wise)  # <-- uses your patched function\n",
    "    v = votes_from_views(views)\n",
    "    if v is None:\n",
    "        rows.append({\"ra_deg\":ra0,\"dec\":dec0,\"votes_allwise_nearest\":np.nan,\"nearest_sep_arcsec\":np.nan,\n",
    "                     \"class_hint\":\"no features\",\"simbad_match\":False,\"simbad_main_id\":\"\",\"simbad_otype\":\"\"})\n",
    "        continue\n",
    "\n",
    "    wise_feat[\"_votes\"] = v\n",
    "    coords = SkyCoord(wise_feat[\"ra_deg\"].values*u.deg, wise_feat[\"dec\"].values*u.deg)\n",
    "    seps   = coords.separation(target).arcsec\n",
    "    j      = int(np.argmin(seps))\n",
    "    nearest_sep = float(seps[j])\n",
    "    votes_near  = int(wise_feat.iloc[j][\"_votes\"]) if nearest_sep<=NEAREST_ARCSEC else np.nan\n",
    "    r = wise_feat.iloc[j].to_dict()\n",
    "\n",
    "    # SIMBAD at 5\"\n",
    "    try:\n",
    "        s = simb.query_region(target, radius=5.0*u.arcsec)\n",
    "        if s is not None and len(s)>0:\n",
    "            p = s.to_pandas().iloc[0]\n",
    "            smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\")\n",
    "        else:\n",
    "            smatch=False; sid=\"\"; otype=\"\"\n",
    "    except Exception:\n",
    "        smatch=False; sid=\"\"; otype=\"\"\n",
    "\n",
    "    rows.append({\n",
    "        \"ra_deg\":ra0,\"dec\":dec0,\"nearest_sep_arcsec\":nearest_sep,\n",
    "        \"votes_allwise_nearest\":votes_near,\n",
    "        \"passes_gold_K\": bool(votes_near>=K_STABILITY) if pd.notna(votes_near) else False,\n",
    "        \"W1\":r.get(\"W1\",np.nan),\"W2\":r.get(\"W2\",np.nan),\"W3\":r.get(\"W3\",np.nan),\"W4\":r.get(\"W4\",np.nan),\n",
    "        \"W1-W2\": (r.get(\"W1\",np.nan)-r.get(\"W2\",np.nan)) if pd.notna(r.get(\"W1\",np.nan)) and pd.notna(r.get(\"W2\",np.nan)) else np.nan,\n",
    "        \"W2-W3\": (r.get(\"W2\",np.nan)-r.get(\"W3\",np.nan)) if pd.notna(r.get(\"W2\",np.nan)) and pd.notna(r.get(\"W3\",np.nan)) else np.nan,\n",
    "        \"class_hint\": class_hint_row(r),\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype\n",
    "    })\n",
    "\n",
    "ver = pd.DataFrame(rows)\n",
    "out_csv = OUT/\"gold_verification_allwise.csv\"\n",
    "ver.to_csv(out_csv, index=False)\n",
    "print(f\"[save] AllWISE verifier → {out_csv}\")\n",
    "print(\"\\nPreview:\")\n",
    "print(ver[[\"ra_deg\",\"dec\",\"nearest_sep_arcsec\",\"votes_allwise_nearest\",\"passes_gold_K\",\"W1-W2\",\"W2-W3\",\"class_hint\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\"]].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6830730-3984-421a-a946-4028004bff77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[bind] Gaia gold @ RA=209.236537, Dec=-1.289745 → XMatch→AllWISE (≤5.0\")\n",
      "[bind] Gaia gold @ RA=210.910946, Dec=-1.291592 → XMatch→AllWISE (≤5.0\")\n",
      "[save] bound verification → cnt_anomaly\\out\\gold_verification_bound.csv\n",
      "\n",
      "Preview:\n",
      "   gaia_ra  gaia_dec  bound    wise_ra  wise_dec             wise_id  nearest_sep_arcsec  votes_near  passes_gold_K    W1-W2  W2-W3  simbad_match simbad_main_id simbad_otype\n",
      "209.236537 -1.289745   True 209.236592 -1.289716 J135656.78-011722.9          255.405722         NaN          False 0.884999  3.861          True                            \n",
      "210.910946 -1.291592   True 210.910910 -1.291585 J140338.61-011729.7          206.227427         NaN          False 0.216000  3.340         False                            \n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Bind Gold to AllWISE & Reverify (K=4)\n",
    "# Fixes the coordinate anchor by using CDS XMatch to get true AllWISE positions.\n",
    "import os, io, sys, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# Reuse your hot-fixed wise_features from kernel; if not present, define minimal safe one:\n",
    "try:\n",
    "    wise_features\n",
    "except NameError:\n",
    "    def wise_features(df):\n",
    "        d = df.copy()\n",
    "        ren = {\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "               \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "               \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"}\n",
    "        for k,v in ren.items():\n",
    "            if k in d.columns: d[v] = d[k]\n",
    "        for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "            if a in d and b in d: d[f\"{a}-{b}\"] = d[a]-d[b]\n",
    "        if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "        num = d.select_dtypes(include=[np.number]).copy()\n",
    "        for c in num.columns: num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "        if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "        med = num.median(numeric_only=True)\n",
    "        X0 = num.fillna(med)\n",
    "        views={}\n",
    "        cols1=[c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "        cols2=[c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "        cols3=[c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "        if cols1: views[\"V1_raw_robust\"]=RobustScaler().fit_transform(X0[cols1])\n",
    "        if cols2: views[\"V2_colors_std\"]=StandardScaler().fit_transform(X0[cols2])\n",
    "        if cols3:\n",
    "            X3=X0[cols3].copy(); X3=X3 - X3.min().min() + 1e-3; X3=np.log1p(X3)\n",
    "            views[\"V3_log_reordered\"]=X3[sorted(X3.columns, reverse=True)].values\n",
    "        cols4=sorted(set(cols1+cols2))\n",
    "        if cols4:\n",
    "            X4=X0[cols4].copy(); X4 += np.random.default_rng(42).normal(0,1e-3,size=X4.shape)\n",
    "            views[\"V4_jitter\"]=X4.values\n",
    "        if cols1 and cols2:\n",
    "            X5a=RobustScaler().fit_transform(X0[cols1]); X5b=StandardScaler().fit_transform(X0[cols2])\n",
    "            views[\"V5_mixed\"]=np.concatenate([X5a,X5b],axis=1)\n",
    "        return d, views\n",
    "\n",
    "def votes_from_views(views, seed=42, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(seed)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=contam)\n",
    "            f2  = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2  = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold = pd.read_csv(OUT/\"strict_gold_candidates.csv\")\n",
    "assert len(gold)>0, \"Gold list is empty.\"\n",
    "\n",
    "K_STABILITY = 4\n",
    "XMM_ARCSEC  = 5.0     # strict crossmatch radius\n",
    "CONE_ARCMIN = 6.0     # local verification cone\n",
    "NEAR_ARCSEC = 3.0     # accept if we can hit the exact matched AllWISE row\n",
    "\n",
    "simb = Simbad(); simb.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "Vizier.ROW_LIMIT = -1\n",
    "\n",
    "rows=[]\n",
    "for _, g in gold.iterrows():\n",
    "    ra0 = float(g.get(\"ra_deg\") or g.get(\"RA_ICRS\") or g.get(\"ra\"))\n",
    "    dec0= float(g.get(\"dec\") or g.get(\"DE_ICRS\"))\n",
    "    print(f\"[bind] Gaia gold @ RA={ra0:.6f}, Dec={dec0:.6f} → XMatch→AllWISE (≤{XMM_ARCSEC}\\\")\")\n",
    "\n",
    "    # Build a one-row VOTable for XMatch\n",
    "    from astropy.table import Table\n",
    "    t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\"))\n",
    "    t.add_row((ra0, dec0))\n",
    "    buf = io.BytesIO()\n",
    "    t.write(buf, format=\"votable\")\n",
    "    buf.seek(0)\n",
    "\n",
    "    try:\n",
    "        xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                          max_distance=XMM_ARCSEC*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "        xdf = xm.to_pandas()\n",
    "    except Exception as e:\n",
    "        xdf = pd.DataFrame()\n",
    "\n",
    "    if xdf.empty:\n",
    "        rows.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"bound\":False,\"msg\":\"no AllWISE within 5\\\"\"})\n",
    "        continue\n",
    "\n",
    "    # Take best match by smallest angDist\n",
    "    xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "    wise_ra = float(xdf.loc[0, \"RAJ2000\"])\n",
    "    wise_dec= float(xdf.loc[0, \"DEJ2000\"])\n",
    "    wise_id = str(xdf.loc[0, \"AllWISE\"]) if \"AllWISE\" in xdf.columns else \"\"\n",
    "\n",
    "    # Now verify *at the bound AllWISE coord*\n",
    "    center = SkyCoord(wise_ra*u.deg, wise_dec*u.deg)\n",
    "    res = Vizier(columns=[\"**\"]).query_region(center, radius=(CONE_ARCMIN*u.arcmin), catalog=\"II/328/allwise\")\n",
    "    if len(res)==0 or len(res[0])==0:\n",
    "        rows.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"bound\":True,\"wise_ra\":wise_ra,\"wise_dec\":wise_dec,\n",
    "                     \"nearest_sep_arcsec\":np.nan,\"votes_near\":np.nan,\"passes_gold_K\":False,\n",
    "                     \"wise_id\":wise_id,\"msg\":\"no AllWISE rows in cone\"})\n",
    "        continue\n",
    "\n",
    "    wise = res[0].to_pandas()\n",
    "    wise_feat, views = wise_features(wise)\n",
    "    vote_arr = votes_from_views(views)\n",
    "    if vote_arr is None:\n",
    "        rows.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"bound\":True,\"wise_ra\":wise_ra,\"wise_dec\":wise_dec,\n",
    "                     \"nearest_sep_arcsec\":np.nan,\"votes_near\":np.nan,\"passes_gold_K\":False,\n",
    "                     \"wise_id\":wise_id,\"msg\":\"no features/votes\"})\n",
    "        continue\n",
    "    wise_feat[\"_votes\"] = vote_arr\n",
    "\n",
    "    # find the exact matched row (prefer exact ID; else nearest coord)\n",
    "    if wise_id and \"AllWISE\" in wise_feat.columns and wise_id in set(wise_feat[\"AllWISE\"].astype(str)):\n",
    "        j = int(wise_feat.index[wise_feat[\"AllWISE\"].astype(str)==wise_id][0])\n",
    "        nearest_sep = SkyCoord(wise_feat.loc[j,\"ra_deg\"]*u.deg, wise_feat.loc[j,\"dec\"]*u.deg).separation(center).arcsec\n",
    "    else:\n",
    "        coords = SkyCoord(wise_feat[\"ra_deg\"].values*u.deg, wise_feat[\"dec\"].values*u.deg)\n",
    "        seps   = coords.separation(center).arcsec\n",
    "        j      = int(np.argmin(seps))\n",
    "        nearest_sep = float(seps[j])\n",
    "\n",
    "    votes_near = int(wise_feat.iloc[j][\"_votes\"]) if nearest_sep <= max(NEAR_ARCSEC, 1.0) else np.nan\n",
    "\n",
    "    # SIMBAD label at 5\"\n",
    "    try:\n",
    "        s = simb.query_region(center, radius=5.0*u.arcsec)\n",
    "        if s is not None and len(s)>0:\n",
    "            p = s.to_pandas().iloc[0]\n",
    "            smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\")\n",
    "        else:\n",
    "            smatch=False; sid=\"\"; otype=\"\"\n",
    "    except Exception:\n",
    "        smatch=False; sid=\"\"; otype=\"\"\n",
    "\n",
    "    r = wise_feat.iloc[j].to_dict()\n",
    "    rows.append({\n",
    "        \"gaia_ra\":ra0,\"gaia_dec\":dec0,\n",
    "        \"bound\":True,\"wise_ra\":wise_ra,\"wise_dec\":wise_dec,\"wise_id\":wise_id,\n",
    "        \"nearest_sep_arcsec\": nearest_sep,\n",
    "        \"votes_near\": votes_near,\n",
    "        \"passes_gold_K\": bool(votes_near>=K_STABILITY) if pd.notna(votes_near) else False,\n",
    "        \"W1\": r.get(\"W1\",np.nan),\"W2\": r.get(\"W2\",np.nan),\"W3\": r.get(\"W3\",np.nan),\"W4\": r.get(\"W4\",np.nan),\n",
    "        \"W1-W2\": (r.get(\"W1\",np.nan)-r.get(\"W2\",np.nan)) if pd.notna(r.get(\"W1\",np.nan)) and pd.notna(r.get(\"W2\",np.nan)) else np.nan,\n",
    "        \"W2-W3\": (r.get(\"W2\",np.nan)-r.get(\"W3\",np.nan)) if pd.notna(r.get(\"W2\",np.nan)) and pd.notna(r.get(\"W3\",np.nan)) else np.nan,\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(rows)\n",
    "OUT_PATH = OUT/\"gold_verification_bound.csv\"\n",
    "out.to_csv(OUT_PATH, index=False)\n",
    "print(f\"[save] bound verification → {OUT_PATH}\")\n",
    "print(\"\\nPreview:\")\n",
    "cols = [\"gaia_ra\",\"gaia_dec\",\"bound\",\"wise_ra\",\"wise_dec\",\"wise_id\",\"nearest_sep_arcsec\",\n",
    "        \"votes_near\",\"passes_gold_K\",\"W1-W2\",\"W2-W3\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\",\"msg\"]\n",
    "print(out[ [c for c in cols if c in out.columns] ].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2781e311-44eb-4802-bfb3-b7abb4b95833",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[id-lock] RA=209.236537 Dec=-1.289745 — binding to AllWISE ID (≤5.0\")\n",
      "[id-lock] RA=210.910946 Dec=-1.291592 — binding to AllWISE ID (≤5.0\")\n",
      "[save] ID-locked verification → cnt_anomaly\\out\\gold_verification_idlocked.csv\n",
      "\n",
      "Preview:\n",
      "            wise_id  sep_to_exact_arcsec  votes_at_exact  passes_gold_K    W1-W2  W2-W3  simbad_match simbad_main_id simbad_otype            status\n",
      "J135656.78-011722.9           255.405722             NaN          False 0.884999  3.861          True                             exact-not-in-cone\n",
      "J140338.61-011729.7           206.227427             NaN          False 0.216000  3.340         False                             exact-not-in-cone\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — ID-LOCKED Gold Verifier (definitive)\n",
    "import os, io, sys, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# Uses your hot-fixed wise_features() already in the kernel:\n",
    "try:\n",
    "    wise_features\n",
    "except NameError:\n",
    "    raise RuntimeError(\"wise_features() hotfix not found. Run the hotfix cell first.\")\n",
    "\n",
    "def votes_from_views(views, seed=42, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(seed)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=contam)\n",
    "            f2  = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2  = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold = pd.read_csv(OUT/\"strict_gold_candidates.csv\")\n",
    "assert len(gold)>0\n",
    "\n",
    "K_STABILITY = 4\n",
    "XMM_ARCSEC  = 5.0      # XMatch cone to bind ID\n",
    "ENV_ARCMIN  = 6.0      # environment cone to compute votes\n",
    "NEAR_ARCSEC = 3.0      # accept exact row within 3\"\n",
    "\n",
    "simb = Simbad(); simb.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "Vizier.ROW_LIMIT = -1\n",
    "\n",
    "records=[]\n",
    "for _, g in gold.iterrows():\n",
    "    ra0 = float(g.get(\"ra_deg\") or g.get(\"RA_ICRS\") or g.get(\"ra\"))\n",
    "    dec0= float(g.get(\"dec\") or g.get(\"DE_ICRS\"))\n",
    "    print(f\"[id-lock] RA={ra0:.6f} Dec={dec0:.6f} — binding to AllWISE ID (≤{XMM_ARCSEC}\\\")\")\n",
    "\n",
    "    # 1) Bind to AllWISE ID via XMatch\n",
    "    t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    try:\n",
    "        xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                          max_distance=XMM_ARCSEC*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "        xdf = xm.to_pandas()\n",
    "    except Exception:\n",
    "        xdf = pd.DataFrame()\n",
    "\n",
    "    if xdf.empty:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"status\":\"no-allwise-within-5arcsec\"})\n",
    "        continue\n",
    "\n",
    "    xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "    wise_id  = str(xdf.loc[0,\"AllWISE\"]) if \"AllWISE\" in xdf.columns else \"\"\n",
    "    wise_ra  = float(xdf.loc[0,\"RAJ2000\"]); wise_dec = float(xdf.loc[0,\"DEJ2000\"])\n",
    "    center   = SkyCoord(wise_ra*u.deg, wise_dec*u.deg)\n",
    "\n",
    "    # 2) Pull the exact AllWISE row by ID\n",
    "    exact = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wise_id)\n",
    "    if len(exact)==0 or len(exact[0])==0:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"wise_id\":wise_id,\"status\":\"id-not-found-in-vizier\"})\n",
    "        continue\n",
    "    exact_df = exact[0].to_pandas()\n",
    "\n",
    "    # 3) Pull environment cone and compute votes\n",
    "    env = Vizier(columns=[\"**\"]).query_region(center, radius=(ENV_ARCMIN*u.arcmin), catalog=\"II/328/allwise\")\n",
    "    if len(env)==0 or len(env[0])==0:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"wise_id\":wise_id,\"status\":\"no-env\"})\n",
    "        continue\n",
    "    env_df = env[0].to_pandas()\n",
    "\n",
    "    env_feat, views = wise_features(env_df)\n",
    "    vote_arr = votes_from_views(views)\n",
    "    if vote_arr is None:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"wise_id\":wise_id,\"status\":\"no-votes\"})\n",
    "        continue\n",
    "    env_feat[\"_votes\"] = vote_arr\n",
    "\n",
    "    # 4) Locate the exact row inside env by ID; if missing, match by nearest to bound coords\n",
    "    j = None\n",
    "    if \"AllWISE\" in env_feat.columns:\n",
    "        same = env_feat.index[ env_feat[\"AllWISE\"].astype(str) == wise_id ]\n",
    "        if len(same)>0: j = int(same[0])\n",
    "    if j is None:\n",
    "        coords = SkyCoord(env_feat[\"RAJ2000\"].astype(float).values*u.deg,\n",
    "                          env_feat[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "        seps = coords.separation(center).arcsec\n",
    "        j = int(np.argmin(seps))\n",
    "        nearest_sep = float(seps[j])\n",
    "    else:\n",
    "        nearest_sep = SkyCoord(float(env_feat.loc[j,\"RAJ2000\"])*u.deg,\n",
    "                               float(env_feat.loc[j,\"DEJ2000\"])*u.deg).separation(center).arcsec\n",
    "\n",
    "    votes_here = int(env_feat.iloc[j][\"_votes\"]) if nearest_sep <= NEAR_ARCSEC else np.nan\n",
    "\n",
    "    # 5) Colors & SIMBAD\n",
    "    W1 = env_feat.iloc[j].get(\"W1mag\", np.nan)\n",
    "    W2 = env_feat.iloc[j].get(\"W2mag\", np.nan)\n",
    "    W3 = env_feat.iloc[j].get(\"W3mag\", np.nan)\n",
    "    W4 = env_feat.iloc[j].get(\"W4mag\", np.nan)\n",
    "    w12 = (W1 - W2) if pd.notna(W1) and pd.notna(W2) else np.nan\n",
    "    w23 = (W2 - W3) if pd.notna(W2) and pd.notna(W3) else np.nan\n",
    "\n",
    "    try:\n",
    "        s = Simbad().query_region(center, radius=5.0*u.arcsec)\n",
    "        if s is not None and len(s)>0:\n",
    "            p = s.to_pandas().iloc[0]\n",
    "            smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\")\n",
    "        else:\n",
    "            smatch=False; sid=\"\"; otype=\"\"\n",
    "    except Exception:\n",
    "        smatch=False; sid=\"\"; otype=\"\"\n",
    "\n",
    "    records.append({\n",
    "        \"gaia_ra\":ra0,\"gaia_dec\":dec0,\n",
    "        \"wise_id\":wise_id,\"wise_ra\":wise_ra,\"wise_dec\":wise_dec,\n",
    "        \"sep_to_exact_arcsec\": nearest_sep,\n",
    "        \"votes_at_exact\": votes_here,\n",
    "        \"passes_gold_K\": bool(votes_here>=K_STABILITY) if pd.notna(votes_here) else False,\n",
    "        \"W1-W2\": w12, \"W2-W3\": w23,\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype,\n",
    "        \"status\":\"ok\" if pd.notna(votes_here) else \"exact-not-in-cone\"  # rare\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(records)\n",
    "path = OUT/\"gold_verification_idlocked.csv\"\n",
    "out.to_csv(path, index=False)\n",
    "print(f\"[save] ID-locked verification → {path}\")\n",
    "print(\"\\nPreview:\")\n",
    "cols = [\"wise_id\",\"sep_to_exact_arcsec\",\"votes_at_exact\",\"passes_gold_K\",\"W1-W2\",\"W2-W3\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\",\"status\"]\n",
    "print(out[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1fb58f15-26cd-45e3-9b38-7ea6dd1e2e73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] final ID-locked verification → cnt_anomaly\\out\\gold_verification_idlocked_final.csv\n",
      "\n",
      "Preview:\n",
      "            wise_id  sep_to_exact_arcsec  votes_at_exact  passes_gold_K  W1-W2  W2-W3  simbad_match simbad_main_id simbad_otype status\n",
      "J135656.78-011722.9                  0.0               4           True  0.349  3.768          True                                 ok\n",
      "J140338.61-011729.7                  0.0               0          False -0.068  2.526         False                                 ok\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — FINAL ID-locked verifier (append exact row into env, compute votes at exact)\n",
    "import os, io, sys, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "# Use your hot-fixed wise_features(); if absent, define a safe one\n",
    "try:\n",
    "    wise_features\n",
    "except NameError:\n",
    "    def wise_features(df):\n",
    "        d = df.copy()\n",
    "        ren = {\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "               \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "               \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"}\n",
    "        for k,v in ren.items():\n",
    "            if k in d.columns: d[v] = d[k]\n",
    "        for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "            if a in d and b in d: d[f\"{a}-{b}\"] = d[a]-d[b]\n",
    "        if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "        num = d.select_dtypes(include=[np.number]).copy()\n",
    "        for c in num.columns: num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "        if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "        med = num.median(numeric_only=True)\n",
    "        X0 = num.fillna(med)\n",
    "        views={}\n",
    "        cols1=[c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "        cols2=[c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "        cols3=[c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "        if cols1: views[\"V1_raw_robust\"]=RobustScaler().fit_transform(X0[cols1])\n",
    "        if cols2: views[\"V2_colors_std\"]=StandardScaler().fit_transform(X0[cols2])\n",
    "        if cols3:\n",
    "            X3=X0[cols3].copy(); X3=X3 - X3.min().min() + 1e-3; X3=np.log1p(X3)\n",
    "            views[\"V3_log_reordered\"]=X3[sorted(X3.columns, reverse=True)].values\n",
    "        cols4=sorted(set(cols1+cols2))\n",
    "        if cols4:\n",
    "            X4=X0[cols4].copy(); X4 += np.random.default_rng(42).normal(0,1e-3,size=X4.shape)\n",
    "            views[\"V4_jitter\"]=X4.values\n",
    "        if cols1 and cols2:\n",
    "            X5a=RobustScaler().fit_transform(X0[cols1]); X5b=StandardScaler().fit_transform(X0[cols2])\n",
    "            views[\"V5_mixed\"]=np.concatenate([X5a,X5b],axis=1)\n",
    "        return d, views\n",
    "\n",
    "def votes_from_views(views, seed=42, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(seed)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=contam)\n",
    "            f2  = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2  = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = f1 | f2\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold = pd.read_csv(OUT/\"strict_gold_candidates.csv\")\n",
    "assert len(gold)>0, \"Gold list is empty.\"\n",
    "\n",
    "K_STABILITY = 4\n",
    "XMM_ARCSEC  = 5.0       # bind radius\n",
    "ENV_ARCMIN  = 8.0       # environment (a bit larger)\n",
    "NEAR_ARCSEC = 5.0       # accept exact row within 5\"\n",
    "Vizier.ROW_LIMIT = -1\n",
    "simb = Simbad(); simb.add_votable_fields(\"otypes\",\"otype\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "\n",
    "def sanitize_id(s):\n",
    "    return str(s).strip()\n",
    "\n",
    "records=[]\n",
    "for _, g in gold.iterrows():\n",
    "    ra0 = float(g.get(\"ra_deg\") or g.get(\"RA_ICRS\") or g.get(\"ra\"))\n",
    "    dec0= float(g.get(\"dec\") or g.get(\"DE_ICRS\"))\n",
    "    target = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "\n",
    "    # 1) Bind to AllWISE ID via XMatch\n",
    "    t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    try:\n",
    "        xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                          max_distance=XMM_ARCSEC*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "        xdf = xm.to_pandas()\n",
    "    except Exception:\n",
    "        xdf = pd.DataFrame()\n",
    "\n",
    "    if xdf.empty:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"status\":\"no-allwise-within-5arcsec\"})\n",
    "        continue\n",
    "\n",
    "    xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "    wise_id  = sanitize_id(xdf.loc[0,\"AllWISE\"]) if \"AllWISE\" in xdf.columns else \"\"\n",
    "    wise_ra  = float(xdf.loc[0,\"RAJ2000\"]); wise_dec = float(xdf.loc[0,\"DEJ2000\"])\n",
    "    center   = SkyCoord(wise_ra*u.deg, wise_dec*u.deg)\n",
    "\n",
    "    # 2) Exact row by ID (definitive)\n",
    "    exact = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wise_id)\n",
    "    if len(exact)==0 or len(exact[0])==0:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"wise_id\":wise_id,\"status\":\"id-not-found-in-vizier\"})\n",
    "        continue\n",
    "    exact_df = exact[0].to_pandas()\n",
    "    exact_df[\"AllWISE\"] = sanitize_id(exact_df[\"AllWISE\"].astype(str))\n",
    "\n",
    "    # 3) Environment cone and APPEND exact row if missing\n",
    "    env = Vizier(columns=[\"**\"]).query_region(center, radius=(ENV_ARCMIN*u.arcmin), catalog=\"II/328/allwise\")\n",
    "    env_df = env[0].to_pandas() if len(env)>0 and len(env[0])>0 else pd.DataFrame()\n",
    "    if \"AllWISE\" in env_df.columns:\n",
    "        env_df[\"AllWISE\"] = env_df[\"AllWISE\"].astype(str).map(sanitize_id)\n",
    "    else:\n",
    "        env_df[\"AllWISE\"] = \"\"\n",
    "\n",
    "    if wise_id not in set(env_df[\"AllWISE\"]):\n",
    "        env_df = pd.concat([env_df, exact_df], ignore_index=True)\n",
    "\n",
    "    # 4) Compute votes on env (with exact row guaranteed present)\n",
    "    env_feat, views = wise_features(env_df)\n",
    "    vote_arr = votes_from_views(views)\n",
    "    if vote_arr is None:\n",
    "        records.append({\"gaia_ra\":ra0,\"gaia_dec\":dec0,\"wise_id\":wise_id,\"status\":\"no-votes\"})\n",
    "        continue\n",
    "    env_feat[\"_votes\"] = vote_arr\n",
    "\n",
    "    # locate exact row by ID (fall back to nearest to center if something odd)\n",
    "    j = None\n",
    "    if \"AllWISE\" in env_feat.columns:\n",
    "        ids = env_feat[\"AllWISE\"].astype(str).map(sanitize_id)\n",
    "        hit = ids[ids == wise_id]\n",
    "        if len(hit)>0:\n",
    "            j = int(hit.index[0])\n",
    "\n",
    "    if j is None:\n",
    "        # nearest to the bound center\n",
    "        coords = SkyCoord(env_feat[\"RAJ2000\"].astype(float).values*u.deg,\n",
    "                          env_feat[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "        seps = coords.separation(center).arcsec\n",
    "        j = int(np.argmin(seps))\n",
    "        sep_to_exact = float(seps[j])\n",
    "    else:\n",
    "        sep_to_exact = SkyCoord(float(env_feat.loc[j,\"RAJ2000\"])*u.deg,\n",
    "                                float(env_feat.loc[j,\"DEJ2000\"])*u.deg).separation(center).arcsec\n",
    "\n",
    "    votes_here = int(env_feat.iloc[j][\"_votes\"]) if sep_to_exact <= NEAR_ARCSEC else np.nan\n",
    "\n",
    "    # 5) Colors & SIMBAD\n",
    "    W1 = env_feat.iloc[j].get(\"W1mag\", np.nan)\n",
    "    W2 = env_feat.iloc[j].get(\"W2mag\", np.nan)\n",
    "    W3 = env_feat.iloc[j].get(\"W3mag\", np.nan)\n",
    "    W4 = env_feat.iloc[j].get(\"W4mag\", np.nan)\n",
    "    w12 = (W1 - W2) if pd.notna(W1) and pd.notna(W2) else np.nan\n",
    "    w23 = (W2 - W3) if pd.notna(W2) and pd.notna(W3) else np.nan\n",
    "\n",
    "    try:\n",
    "        s = Simbad().query_region(center, radius=5.0*u.arcsec)\n",
    "        if s is not None and len(s)>0:\n",
    "            p = s.to_pandas().iloc[0]\n",
    "            smatch=True; sid=p.get(\"MAIN_ID\",\"\"); otype=p.get(\"OTYPE\",\"\")\n",
    "        else:\n",
    "            smatch=False; sid=\"\"; otype=\"\"\n",
    "    except Exception:\n",
    "        smatch=False; sid=\"\"; otype=\"\"\n",
    "\n",
    "    records.append({\n",
    "        \"gaia_ra\":ra0,\"gaia_dec\":dec0,\n",
    "        \"wise_id\":wise_id,\"wise_ra\":wise_ra,\"wise_dec\":wise_dec,\n",
    "        \"sep_to_exact_arcsec\": sep_to_exact,\n",
    "        \"votes_at_exact\": votes_here,\n",
    "        \"passes_gold_K\": bool(votes_here>=K_STABILITY) if pd.notna(votes_here) else False,\n",
    "        \"W1-W2\": w12, \"W2-W3\": w23,\n",
    "        \"simbad_match\": smatch, \"simbad_main_id\": sid, \"simbad_otype\": otype,\n",
    "        \"status\": \"ok\" if pd.notna(votes_here) else \"exact-present-but-outside-5arcsec\"\n",
    "    })\n",
    "\n",
    "out = pd.DataFrame(records)\n",
    "PATH = OUT/\"gold_verification_idlocked_final.csv\"\n",
    "out.to_csv(PATH, index=False)\n",
    "print(f\"[save] final ID-locked verification → {PATH}\")\n",
    "print(\"\\nPreview:\")\n",
    "cols = [\"wise_id\",\"sep_to_exact_arcsec\",\"votes_at_exact\",\"passes_gold_K\",\"W1-W2\",\"W2-W3\",\"simbad_match\",\"simbad_main_id\",\"simbad_otype\",\"status\"]\n",
    "print(out[cols].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "895750b0-5937-4a6b-a7a1-40aa581f8bdb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNT] Fused pipeline start @ 20251016-195213\n",
      "[tile 1/9] RA=209.200 Dec=-1.300\n",
      "[tile 2/9] RA=210.000 Dec=-1.300\n",
      "[tile 3/9] RA=210.800 Dec=-1.300\n",
      "[tile 4/9] RA=209.200 Dec=-0.500\n",
      "[tile 5/9] RA=210.000 Dec=-0.500\n",
      "[tile 6/9] RA=210.800 Dec=-0.500\n",
      "[tile 7/9] RA=209.200 Dec=0.300\n",
      "[tile 8/9] RA=210.000 Dec=0.300\n",
      "[tile 9/9] RA=210.800 Dec=0.300\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251016-195213.csv (N=13)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251016-195213.csv (N=13)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251016-195213.csv (N=0)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251016-195213.csv (N=0)\n",
      "[note] No candidates passed WISE quality; proceeding with enriched set for triage.\n",
      "[save] gallery → cnt_anomaly\\out\\web\\index_20251016-195213.html\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251016-195213.csv (N=4)\n",
      "[save] ID-locked verification → cnt_anomaly\\out\\gold_verification_idlocked_20251016-195213.csv\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type WindowsPath is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 516\u001b[39m\n\u001b[32m    513\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m -\u001b[39m\u001b[33m\"\u001b[39m, html)\n\u001b[32m    515\u001b[39m \u001b[38;5;66;03m# ======= RUN =======\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m516\u001b[39m \u001b[43mrun_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 503\u001b[39m, in \u001b[36mrun_pipeline\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m    494\u001b[39m \u001b[38;5;66;03m# tiny prereg statement file\u001b[39;00m\n\u001b[32m    495\u001b[39m claim = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    496\u001b[39m     when=stamp,\n\u001b[32m    497\u001b[39m     center=(cfg[\u001b[33m\"\u001b[39m\u001b[33mCENTER_RA\u001b[39m\u001b[33m\"\u001b[39m], cfg[\u001b[33m\"\u001b[39m\u001b[33mCENTER_DEC\u001b[39m\u001b[33m\"\u001b[39m]),\n\u001b[32m   (...)\u001b[39m\u001b[32m    501\u001b[39m     gold=\u001b[38;5;28mstr\u001b[39m(gold_path), verify=\u001b[38;5;28mstr\u001b[39m(ver_path)\n\u001b[32m    502\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m503\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(OUT/\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpreregister_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mw\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f: \u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclaim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    504\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m[save] prereg json →\u001b[39m\u001b[33m\"\u001b[39m, OUT/\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mpreregister_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstamp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.json\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    505\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m== SUMMARY ==\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:179\u001b[39m, in \u001b[36mdump\u001b[39m\u001b[34m(obj, fp, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    173\u001b[39m     iterable = \u001b[38;5;28mcls\u001b[39m(skipkeys=skipkeys, ensure_ascii=ensure_ascii,\n\u001b[32m    174\u001b[39m         check_circular=check_circular, allow_nan=allow_nan, indent=indent,\n\u001b[32m    175\u001b[39m         separators=separators,\n\u001b[32m    176\u001b[39m         default=default, sort_keys=sort_keys, **kw).iterencode(obj)\n\u001b[32m    177\u001b[39m \u001b[38;5;66;03m# could accelerate with writelines in some versions of Python, at\u001b[39;00m\n\u001b[32m    178\u001b[39m \u001b[38;5;66;03m# a debuggability cost\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m179\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrite\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:433\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    431\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_list(o, _current_indent_level)\n\u001b[32m    432\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(o, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m433\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m _iterencode_dict(o, _current_indent_level)\n\u001b[32m    434\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    435\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:407\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode_dict\u001b[39m\u001b[34m(dct, _current_indent_level)\u001b[39m\n\u001b[32m    405\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    406\u001b[39m             chunks = _iterencode(value, _current_indent_level)\n\u001b[32m--> \u001b[39m\u001b[32m407\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m chunks\n\u001b[32m    408\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m first \u001b[38;5;129;01mand\u001b[39;00m newline_indent \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    409\u001b[39m     _current_indent_level -= \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:440\u001b[39m, in \u001b[36m_make_iterencode.<locals>._iterencode\u001b[39m\u001b[34m(o, _current_indent_level)\u001b[39m\n\u001b[32m    438\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCircular reference detected\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    439\u001b[39m     markers[markerid] = o\n\u001b[32m--> \u001b[39m\u001b[32m440\u001b[39m o = \u001b[43m_default\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    441\u001b[39m \u001b[38;5;28;01myield from\u001b[39;00m _iterencode(o, _current_indent_level)\n\u001b[32m    442\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m markers \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type WindowsPath is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Fused & Upgraded v1 (Full pipeline, ID-locked verification)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, time, json, math, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ======= CONFIG (edit freely) =======\n",
    "CFG = dict(\n",
    "    CENTER_RA = 210.0,              # deg\n",
    "    CENTER_DEC = -0.5,              # deg\n",
    "    RADIUS_DEG = 0.8,               # per-tile search radius\n",
    "    GRID_SIZE = 3,                  # 1=single tile; 3=3x3 grid\n",
    "    GRID_STEP_DEG = 0.8,            # tile spacing\n",
    "    N_MAX = 3000,                   # Gaia row cap per tile\n",
    "    XMM_RADIUS_ARCSEC = 1.0,        # Gaia↔AllWISE crossmatch radius\n",
    "    WISE_XMATCH_ARCSEC = 5.0,       # binding gold to AllWISE ID\n",
    "    CONE_ENV_ARCMIN = 8.0,          # environment cone for verification\n",
    "    NEAR_ARCSEC = 5.0,              # accept exact row within this distance\n",
    "    K_DISC = 3,                     # discovery threshold (votes)\n",
    "    K_GOLD = 4,                     # gold threshold (votes)\n",
    "    GOLD_W23_MIN = 1.0,             # color gate for gold (W2-W3)\n",
    "    STRICT_W1W2_QUAL = \"AB\",        # accept A/B in W1,W2 for strict\n",
    "    STRICT_SNR_MIN = 5.0,           # min SNR in W1,W2 for strict\n",
    "    RELAX_SNR_MIN = 3.0,            # fallback relxed SNR\n",
    "    OUTDIR = \"./cnt_anomaly/out\",\n",
    "    CACHEDIR = \"./cnt_anomaly/cache\",\n",
    "    SEED = 42\n",
    ")\n",
    "\n",
    "# ======= ENV / DEPENDENCIES =======\n",
    "def ensure(pkgs):\n",
    "    missing=[]\n",
    "    for p in pkgs:\n",
    "        mod = p if p!=\"scikit-learn\" else \"sklearn\"\n",
    "        try:\n",
    "            importlib.import_module(mod)\n",
    "        except Exception:\n",
    "            missing.append(p)\n",
    "    if missing:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.skyview import SkyView\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "np.random.seed(CFG[\"SEED\"])\n",
    "OUT = Path(CFG[\"OUTDIR\"]); OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(CFG[\"CACHEDIR\"]); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "CUT = OUT/\"cutouts\"; CUT.mkdir(parents=True, exist_ok=True)\n",
    "WEB = OUT/\"web\"; WEB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ======= UTILS =======\n",
    "def ts(): return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def sanitize_id(s): return str(s).strip()\n",
    "\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=None):\n",
    "    if row_limit is None: row_limit = CFG[\"N_MAX\"]\n",
    "    Vizier.ROW_LIMIT = row_limit\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    return d.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "# HOTFIX: wise_features robust to Int32 masked types (floatify first)\n",
    "def wise_features(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "           \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if all(c in d.columns for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "\n",
    "    num = d.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0 = num.fillna(med)\n",
    "\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy()\n",
    "        X3 = X3 - X3.min().min() + 1e-3\n",
    "        X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        rng = np.random.default_rng(CFG[\"SEED\"])\n",
    "        X4 += rng.normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1])\n",
    "        X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return d, views\n",
    "\n",
    "def votes_from_views(views, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(CFG[\"SEED\"])\n",
    "    flags = {}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=contam)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = (f1 | f2)\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "def triage_class_hint(w12, w23):\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12 >= 0.8) and (w23 >= 1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12 >= 0.3) and (w23 >= 1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "def wise_good_phqual(s, good=\"AB\"):\n",
    "    s = str(s) if isinstance(s,str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"; w2 = s[1] if len(s)>1 else \"\"\n",
    "    return (w1 in good) and (w2 in good)\n",
    "\n",
    "def fetch_cutout_png(ra, dec, tag, fov_arcmin=2.0):\n",
    "    # Try PanSTARRS g,r,i → compose RGB; else DSS2 Red grayscale\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"PanSTARRS g\",\"PanSTARRS r\",\"PanSTARRS i\"],\n",
    "                                  pixels=512, height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "        if imgs and len(imgs)>=3:\n",
    "            from astropy.io import fits\n",
    "            from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "            planes = []\n",
    "            for hdu_list in imgs:\n",
    "                hdu = hdu_list[0]\n",
    "                planes.append(hdu.data.astype(np.float32))\n",
    "            g, r, i = planes[0], planes[1], planes[2]\n",
    "            norm = lambda a: np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            R, G, B = norm(i), norm(r), norm(g)\n",
    "            rgb = np.stack([R,G,B],axis=-1)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(rgb, origin=\"lower\"); plt.axis(\"off\")\n",
    "            out = WEB/f\"{tag}.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "            return str(out)\n",
    "    except Exception:\n",
    "        pass\n",
    "    # Fallback DSS2 Red\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                  pixels=512, height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "        if imgs:\n",
    "            from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "            a = imgs[0][0].data.astype(np.float32)\n",
    "            img = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(img, origin=\"lower\", cmap=\"gray\"); plt.axis(\"off\")\n",
    "            out = WEB/f\"{tag}.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "            return str(out)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return \"\"\n",
    "\n",
    "# ======= PIPELINE =======\n",
    "def run_pipeline(cfg):\n",
    "    stamp = ts()\n",
    "    print(f\"[CNT] Fused pipeline start @ {stamp}\")\n",
    "    # --- grid tiles ---\n",
    "    offsets = np.linspace(-cfg[\"GRID_STEP_DEG\"], cfg[\"GRID_STEP_DEG\"], cfg[\"GRID_SIZE\"])\n",
    "    tiles = [(cfg[\"CENTER_RA\"]+dx, cfg[\"CENTER_DEC\"]+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    # --- sweep & anomaly votes (discovery K_DISC) ---\n",
    "    stable_all = []\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{cfg['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{cfg['RADIUS_DEG']}.csv\"\n",
    "        if gaia_cache.exists(): gaia = pd.read_csv(gaia_cache)\n",
    "        else:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, cfg[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=cfg[\"N_MAX\"])\n",
    "            gaia.to_csv(gaia_cache, index=False)\n",
    "        if wise_cache.exists(): gw = pd.read_csv(wise_cache)\n",
    "        else:\n",
    "            gw = xmatch_gaia_allwise(gaia, cfg[\"XMM_RADIUS_ARCSEC\"])\n",
    "            gw.to_csv(wise_cache, index=False)\n",
    "        if gw.empty: \n",
    "            print(\"  [skip] no crossmatches\")\n",
    "            continue\n",
    "        df = add_derived_features(clean_photometry(gw))\n",
    "        _, views = wise_features(df)  # reuse view logic (on Gaia×WISE numeric block)\n",
    "        votes = votes_from_views(views)\n",
    "        if votes is None:\n",
    "            print(\"  [skip] no usable views\")\n",
    "            continue\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= cfg[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            stable_all.append(st)\n",
    "\n",
    "    master = pd.concat(stable_all, ignore_index=True) if stable_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"; master.to_csv(master_path, index=False)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "\n",
    "    if master.empty:\n",
    "        print(\"[done] No stable anomalies. Consider lowering K_DISC or changing field.\")\n",
    "        return\n",
    "\n",
    "    # --- Enrich master with AllWISE flags via XMatch + per-ID row fetch ---\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    enriched_rows=[]\n",
    "    for _, r in master.iterrows():\n",
    "        ra0 = float(r.get(\"ra_deg\", r.get(\"RA_ICRS\", np.nan)))\n",
    "        dec0= float(r.get(\"dec\", r.get(\"DE_ICRS\", np.nan)))\n",
    "        if not (pd.notna(ra0) and pd.notna(dec0)):\n",
    "            continue\n",
    "        # Bind to AllWISE by XMatch\n",
    "        t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "        buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "        try:\n",
    "            xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                              max_distance=cfg[\"WISE_XMATCH_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "            xdf = xm.to_pandas()\n",
    "        except Exception:\n",
    "            xdf = pd.DataFrame()\n",
    "        if xdf.empty:\n",
    "            row = r.to_dict()\n",
    "            row.update({\"AllWISE\":\"\", \"ph_qual\":np.nan,\"ext_flg\":np.nan,\"cc_flags\":np.nan,\n",
    "                        \"w1snr\":np.nan,\"w2snr\":np.nan,\"w3snr\":np.nan,\"w4snr\":np.nan})\n",
    "            enriched_rows.append(row); continue\n",
    "        xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "        wid = sanitize_id(xdf.loc[0,\"AllWISE\"]) if \"AllWISE\" in xdf.columns else \"\"\n",
    "        # fetch exact row by ID for flags/SNR\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            row = r.to_dict(); row.update({\"AllWISE\":wid})\n",
    "            enriched_rows.append(row); continue\n",
    "        aw = q[0].to_pandas().iloc[0]\n",
    "        row = r.to_dict()\n",
    "        row.update({\"AllWISE\":wid,\n",
    "                    \"RAJ2000\":aw.get(\"RAJ2000\",np.nan), \"DEJ2000\":aw.get(\"DEJ2000\",np.nan),\n",
    "                    \"ph_qual\":aw.get(\"ph_qual\",np.nan), \"ext_flg\":aw.get(\"ext_flg\",np.nan),\n",
    "                    \"cc_flags\":aw.get(\"cc_flags\",np.nan),\n",
    "                    \"w1snr\":aw.get(\"w1snr\",np.nan),\"w2snr\":aw.get(\"w2snr\",np.nan),\n",
    "                    \"w3snr\":aw.get(\"w3snr\",np.nan),\"w4snr\":aw.get(\"w4snr\",np.nan),\n",
    "                    \"W1\":aw.get(\"W1mag\",np.nan), \"W2\":aw.get(\"W2mag\",np.nan),\n",
    "                    \"W3\":aw.get(\"W3mag\",np.nan), \"W4\":aw.get(\"W4mag\",np.nan)})\n",
    "        enriched_rows.append(row)\n",
    "\n",
    "    enr = pd.DataFrame(enriched_rows)\n",
    "    enr_path = OUT/f\"stable_enriched_all_{stamp}.csv\"; enr.to_csv(enr_path, index=False)\n",
    "    print(f\"[save] enriched (all): {enr_path} (N={len(enr)})\")\n",
    "\n",
    "    # --- STRICT / RELAXED gates on enriched ---\n",
    "    def phq_ok(s): return wise_good_phqual(s, cfg[\"STRICT_W1W2_QUAL\"])\n",
    "    strict_mask = enr[\"ph_qual\"].apply(phq_ok) & (enr[\"w1snr\"].fillna(0)>=cfg[\"STRICT_SNR_MIN\"]) & (enr[\"w2snr\"].fillna(0)>=cfg[\"STRICT_SNR_MIN\"])\n",
    "    strict = enr[strict_mask].copy()\n",
    "    strict_path = OUT/f\"stable_enriched_strict_{stamp}.csv\"; strict.to_csv(strict_path, index=False)\n",
    "\n",
    "    relaxed_mask = (enr[\"w1snr\"].fillna(0)>=cfg[\"RELAX_SNR_MIN\"]) & (enr[\"w2snr\"].fillna(0)>=cfg[\"RELAX_SNR_MIN\"])\n",
    "    relaxed = enr[relaxed_mask].copy()\n",
    "    relaxed_path = OUT/f\"stable_enriched_relaxed_{stamp}.csv\"; relaxed.to_csv(relaxed_path, index=False)\n",
    "\n",
    "    print(f\"[save] strict shortlist:  {strict_path} (N={len(strict)})\")\n",
    "    print(f\"[save] relaxed shortlist: {relaxed_path} (N={len(relaxed)})\")\n",
    "\n",
    "    # choose base set for triage (strict if any, else relaxed)\n",
    "    base = strict if len(strict)>0 else relaxed\n",
    "    if base.empty:\n",
    "        print(\"[note] No candidates passed WISE quality; proceeding with enriched set for triage.\")\n",
    "        base = enr.copy()\n",
    "\n",
    "    # --- TRIAGE: colors, class hints, plots, cutouts, gallery ---\n",
    "    base[\"W1-W2\"] = base.get(\"W1\",np.nan) - base.get(\"W2\",np.nan)\n",
    "    base[\"W2-W3\"] = base.get(\"W2\",np.nan) - base.get(\"W3\",np.nan)\n",
    "    base[\"class_hint\"] = [triage_class_hint(w12,w23) for w12,w23 in zip(base[\"W1-W2\"], base[\"W2-W3\"])]\n",
    "\n",
    "    # Plots\n",
    "    if \"W1-W2\" in base and \"W2-W3\" in base:\n",
    "        plt.figure(figsize=(5,4)); plt.scatter(base[\"W1-W2\"], base[\"W2-W3\"], s=24)\n",
    "        plt.xlabel(\"W1 - W2 (mag)\"); plt.ylabel(\"W2 - W3 (mag)\"); plt.title(\"WISE color–color (triage)\")\n",
    "        plt.tight_layout(); plt.savefig(FIG/f\"diag_wise_color_color_{stamp}.png\", dpi=150); plt.close()\n",
    "\n",
    "    # Cutouts + simple HTML gallery\n",
    "    cards=[]\n",
    "    for i, r in base.reset_index(drop=True).iterrows():\n",
    "        ra = float(r.get(\"RAJ2000\", r.get(\"ra_deg\", np.nan)))\n",
    "        dec= float(r.get(\"DEJ2000\", r.get(\"dec\", np.nan)))\n",
    "        if not (pd.notna(ra) and pd.notna(dec)): continue\n",
    "        tag = f\"cand{i:02d}_ra{ra:.5f}_dec{dec:.5f}\"\n",
    "        png = fetch_cutout_png(ra, dec, tag, fov_arcmin=2.0)\n",
    "        cards.append((tag, png, float(r.get(\"W1-W2\",np.nan)), float(r.get(\"W2-W3\",np.nan)), int(r.get(\"_votes\",0)), r.get(\"AllWISE\",\"\")))\n",
    "\n",
    "    html = WEB/f\"index_{stamp}.html\"\n",
    "    with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(\"<html><head><meta charset='utf-8'><title>CNT Shortlist</title><style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:180px}</style></head><body>\")\n",
    "        f.write(f\"<h1>CNT Shortlist — {stamp}</h1>\")\n",
    "        for (tag,png,w12,w23,v,wid) in cards:\n",
    "            f.write(\"<div class='card'>\")\n",
    "            if png and Path(png).exists(): f.write(f\"<img src='../{Path(png).relative_to(OUT)}'/>\")\n",
    "            else: f.write(\"<div style='width:180px;height:135px;background:#f3f3f3;border-radius:8px;display:flex;align-items:center;justify-content:center;color:#888'>no image</div>\")\n",
    "            f.write(f\"<div><div><b>tag:</b> {tag} &nbsp; <b>votes:</b> {v} &nbsp; <b>AllWISE:</b> {wid}</div>\")\n",
    "            f.write(f\"<div><b>W1−W2:</b> {w12:.3f} &nbsp; <b>W2−W3:</b> {w23:.3f}</div></div></div>\")\n",
    "        f.write(\"</body></html>\")\n",
    "    print(f\"[save] gallery → {html}\")\n",
    "\n",
    "    # --- GOLD gating (votes≥K_GOLD + W2-W3≥min; allow unknown parallax/pm) ---\n",
    "    base[\"_votes\"] = base[\"_votes\"].fillna(0)\n",
    "    gold_mask = (base[\"_votes\"] >= cfg[\"K_GOLD\"]) & (base[\"W2-W3\"].fillna(-99) >= cfg[\"GOLD_W23_MIN\"])\n",
    "    gold = base[gold_mask].copy().reset_index(drop=True)\n",
    "    gold[\"W1-W2\"] = gold.get(\"W1\",np.nan) - gold.get(\"W2\",np.nan); gold[\"W2-W3\"] = gold.get(\"W2\",np.nan) - gold.get(\"W3\",np.nan)\n",
    "    gold_path = OUT/f\"strict_gold_candidates_{stamp}.csv\"; gold.to_csv(gold_path, index=False)\n",
    "    print(f\"[save] GOLD set → {gold_path} (N={len(gold)})\")\n",
    "\n",
    "    if gold.empty:\n",
    "        print(\"[done] No gold candidates at current gates; adjust K_GOLD or GOLD_W23_MIN.\")\n",
    "        return\n",
    "\n",
    "    # --- ID-LOCKED GOLD VERIFICATION at exact AllWISE ID (definitive) + SIMBAD/NED labels ---\n",
    "    Simbad.add_votable_fields(\"otype\",\"otypes\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "    ver_rows=[]\n",
    "    for _, g in gold.iterrows():\n",
    "        # bind to AllWISE ID (from enriched base); if missing, bind now from RA/Dec\n",
    "        wid = sanitize_id(g.get(\"AllWISE\",\"\"))\n",
    "        ra_bind = float(g.get(\"RAJ2000\", g.get(\"ra_deg\", np.nan)))\n",
    "        dec_bind= float(g.get(\"DEJ2000\", g.get(\"dec\", np.nan)))\n",
    "        if (not wid) or (not (pd.notna(ra_bind) and pd.notna(dec_bind))):\n",
    "            # fallback bind by XMatch from Gaia coords if available\n",
    "            ra0 = float(g.get(\"ra_deg\", np.nan)); dec0=float(g.get(\"dec\", np.nan))\n",
    "            if pd.notna(ra0) and pd.notna(dec0):\n",
    "                t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "                buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "                try:\n",
    "                    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                                      max_distance=CFG[\"WISE_XMATCH_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "                    xdf = xm.to_pandas().sort_values(\"angDist\")\n",
    "                    if len(xdf):\n",
    "                        wid = sanitize_id(xdf.iloc[0][\"AllWISE\"]); ra_bind=float(xdf.iloc[0][\"RAJ2000\"]); dec_bind=float(xdf.iloc[0][\"DEJ2000\"])\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        if not wid:\n",
    "            ver_rows.append({\"wise_id\":\"\", \"status\":\"no-allwise-id\", \"votes_at_exact\":np.nan})\n",
    "            continue\n",
    "\n",
    "        # exact row by ID\n",
    "        q_exact = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q_exact)==0 or len(q_exact[0])==0:\n",
    "            ver_rows.append({\"wise_id\":wid,\"status\":\"id-not-found\", \"votes_at_exact\":np.nan})\n",
    "            continue\n",
    "        exact = q_exact[0].to_pandas()\n",
    "        wise_ra = float(exact.iloc[0][\"RAJ2000\"]); wise_dec=float(exact.iloc[0][\"DEJ2000\"])\n",
    "        center = SkyCoord(wise_ra*u.deg, wise_dec*u.deg)\n",
    "\n",
    "        # environment cone (ensure exact is present)\n",
    "        env = Vizier(columns=[\"**\"]).query_region(center, radius=(CFG[\"CONE_ENV_ARCMIN\"]*u.arcmin), catalog=\"II/328/allwise\")\n",
    "        env_df = env[0].to_pandas() if len(env)>0 and len(env[0])>0 else pd.DataFrame()\n",
    "        if \"AllWISE\" in env_df.columns:\n",
    "            env_df[\"AllWISE\"] = env_df[\"AllWISE\"].astype(str).map(sanitize_id)\n",
    "        else:\n",
    "            env_df[\"AllWISE\"] = \"\"\n",
    "        if wid not in set(env_df[\"AllWISE\"]):\n",
    "            env_df = pd.concat([env_df, exact], ignore_index=True)\n",
    "\n",
    "        env_feat, views = wise_features(env_df)\n",
    "        v_arr = votes_from_views(views)\n",
    "        if v_arr is None:\n",
    "            ver_rows.append({\"wise_id\":wid,\"status\":\"no-votes\",\"votes_at_exact\":np.nan})\n",
    "            continue\n",
    "        env_feat[\"_votes\"] = v_arr\n",
    "        # locate exact row\n",
    "        j = None\n",
    "        if \"AllWISE\" in env_feat.columns:\n",
    "            idxs = env_feat.index[env_feat[\"AllWISE\"].astype(str).map(sanitize_id) == wid]\n",
    "            if len(idxs)>0: j = int(idxs[0])\n",
    "        if j is None:\n",
    "            coords = SkyCoord(env_feat[\"RAJ2000\"].astype(float).values*u.deg, env_feat[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "            seps = coords.separation(center).arcsec\n",
    "            j = int(np.argmin(seps))\n",
    "            sep_to_exact = float(seps[j])\n",
    "        else:\n",
    "            sep_to_exact = SkyCoord(float(env_feat.loc[j,\"RAJ2000\"])*u.deg,\n",
    "                                    float(env_feat.loc[j,\"DEJ2000\"])*u.deg).separation(center).arcsec\n",
    "\n",
    "        votes_here = int(env_feat.iloc[j][\"_votes\"]) if sep_to_exact <= CFG[\"NEAR_ARCSEC\"] else np.nan\n",
    "\n",
    "        # colors at exact\n",
    "        W1 = env_feat.iloc[j].get(\"W1mag\", np.nan); W2 = env_feat.iloc[j].get(\"W2mag\", np.nan)\n",
    "        W3 = env_feat.iloc[j].get(\"W3mag\", np.nan); W4 = env_feat.iloc[j].get(\"W4mag\", np.nan)\n",
    "        w12 = (W1-W2) if pd.notna(W1) and pd.notna(W2) else np.nan\n",
    "        w23 = (W2-W3) if pd.notna(W2) and pd.notna(W3) else np.nan\n",
    "\n",
    "        # SIMBAD / NED labels\n",
    "        try:\n",
    "            s = Simbad.query_region(center, radius=5.0*u.arcsec)\n",
    "            if s is not None and len(s)>0:\n",
    "                p = s.to_pandas().iloc[0]; simbad_id = p.get(\"MAIN_ID\",\"\"); simbad_type=p.get(\"OTYPE\",\"\")\n",
    "            else: simbad_id=\"\"; simbad_type=\"\"\n",
    "        except Exception:\n",
    "            simbad_id=\"\"; simbad_type=\"\"\n",
    "\n",
    "        if HAVE_NED:\n",
    "            try:\n",
    "                n = Ned.query_region(center, radius=5.0*u.arcsec)\n",
    "                if n is not None and len(n)>0:\n",
    "                    npd = n.to_pandas().iloc[0]; ned_name=npd.get(\"Object Name\",\"\"); ned_type=npd.get(\"Type\",\"\"); ned_z=npd.get(\"Redshift\",\"\")\n",
    "                else: ned_name=\"\"; ned_type=\"\"; ned_z=\"\"\n",
    "            except Exception:\n",
    "                ned_name=\"\"; ned_type=\"\"; ned_z=\"\"\n",
    "        else:\n",
    "            ned_name=ned_type=ned_z=\"\"\n",
    "\n",
    "        ver_rows.append({\n",
    "            \"wise_id\": wid, \"wise_ra\": wise_ra, \"wise_dec\": wise_dec,\n",
    "            \"sep_to_exact_arcsec\": sep_to_exact,\n",
    "            \"votes_at_exact\": votes_here,\n",
    "            \"passes_gold_K\": bool(votes_here>=cfg[\"K_GOLD\"]) if pd.notna(votes_here) else False,\n",
    "            \"W1-W2\": w12, \"W2-W3\": w23,\n",
    "            \"simbad_id\": simbad_id, \"simbad_type\": simbad_type,\n",
    "            \"ned_name\": ned_name, \"ned_type\": ned_type, \"ned_z\": ned_z,\n",
    "            \"status\": \"ok\" if pd.notna(votes_here) else \"exact-present-but-outside-near-radius\"\n",
    "        })\n",
    "\n",
    "    ver = pd.DataFrame(ver_rows)\n",
    "    ver_path = OUT/f\"gold_verification_idlocked_{stamp}.csv\"; ver.to_csv(ver_path, index=False)\n",
    "    print(f\"[save] ID-locked verification → {ver_path}\")\n",
    "\n",
    "    # tiny prereg statement file\n",
    "    claim = dict(\n",
    "        when=stamp,\n",
    "        center=(cfg[\"CENTER_RA\"], cfg[\"CENTER_DEC\"]),\n",
    "        tiles=len(tiles),\n",
    "        K_DISC=cfg[\"K_DISC\"], K_GOLD=cfg[\"K_GOLD\"], GOLD_W23_MIN=cfg[\"GOLD_W23_MIN\"],\n",
    "        master=str(master_path), enriched=str(enr_path), strict=strict_path, relaxed=relaxed_path,\n",
    "        gold=str(gold_path), verify=str(ver_path)\n",
    "    )\n",
    "    with open(OUT/f\"preregister_{stamp}.json\",\"w\") as f: json.dump(claim, f, indent=2)\n",
    "    print(\"[save] prereg json →\", OUT/f\"preregister_{stamp}.json\")\n",
    "    print(\"\\n== SUMMARY ==\")\n",
    "    print(f\"Tiles: {len(tiles)} | Master stable: {len(master)} | Strict: {len(strict)} | Relaxed: {len(relaxed)} | GOLD: {len(gold)}\")\n",
    "    print(\"Top files:\")\n",
    "    print(\" -\", master_path)\n",
    "    print(\" -\", enr_path)\n",
    "    print(\" -\", strict_path)\n",
    "    print(\" -\", gold_path)\n",
    "    print(\" -\", ver_path)\n",
    "    print(\" -\", html)\n",
    "\n",
    "# ======= RUN =======\n",
    "run_pipeline(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b101f674-10b1-4aec-96af-9648c6933591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CNT] Fused v2 start @ 20251016-200351\n",
      "[tile 1/9] RA=209.200 Dec=-1.300\n",
      "[tile 2/9] RA=210.000 Dec=-1.300\n",
      "[tile 3/9] RA=210.800 Dec=-1.300\n",
      "[tile 4/9] RA=209.200 Dec=-0.500\n",
      "[tile 5/9] RA=210.000 Dec=-0.500\n",
      "[tile 6/9] RA=210.800 Dec=-0.500\n",
      "[tile 7/9] RA=209.200 Dec=0.300\n",
      "[tile 8/9] RA=210.000 Dec=0.300\n",
      "[tile 9/9] RA=210.800 Dec=0.300\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251016-200351.csv (N=12)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251016-200351.csv (N=12)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251016-200351.csv (N=12)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251016-200351.csv (N=0)\n",
      "[save] gallery → cnt_anomaly\\out\\web\\index_20251016-200351.html\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251016-200351.csv (N=2)\n",
      "[save] ID-locked verification → cnt_anomaly\\out\\gold_verification_idlocked_20251016-200351.csv\n",
      "[save] prereg json → cnt_anomaly\\out\\preregister_20251016-200351.json\n",
      "[save] report → cnt_anomaly\\out\\CNT_TechnoAnomaly_Report_20251016-200351.md\n",
      "[bundle] zip → cnt_anomaly\\out\\CNT_TechnoAnomaly_20251016-200351.zip\n",
      "\n",
      "== SUMMARY ==\n",
      "Tiles: 9 | Master: 12 | Strict: 12 | Relaxed: 0 | Gold: 2\n",
      "ID-locked Gold passes: 0\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Fused & Upgraded v2 (robust gates + morphology + bundle)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, time, json, warnings, subprocess, importlib, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================= CONFIG =================\n",
    "CFG = dict(\n",
    "    CENTER_RA = 210.0,                # deg\n",
    "    CENTER_DEC = -0.5,                # deg\n",
    "    RADIUS_DEG = 0.8,                 # per-tile search radius\n",
    "    GRID_SIZE = 3,                    # 1=single tile; 3=3×3 grid\n",
    "    GRID_STEP_DEG = 0.8,              # spacing between tile centers\n",
    "    N_MAX = 3000,                     # Gaia rows cap per tile\n",
    "    XMM_RADIUS_ARCSEC = 1.0,          # Gaia↔AllWISE xmatch radius\n",
    "    WISE_XMATCH_ARCSEC = 5.0,         # binding gold to AllWISE ID\n",
    "    CONE_ENV_ARCMIN = 8.0,            # env cone for verification\n",
    "    NEAR_ARCSEC = 5.0,                # accept exact row within this distance\n",
    "    K_DISC = 3,                       # discovery votes threshold\n",
    "    K_GOLD = 4,                       # gold votes threshold\n",
    "    GOLD_W23_MIN = 1.0,               # color gate for gold (W2-W3)\n",
    "    STRICT_W1W2_QUAL = \"AB\",          # ph_qual allowed for strict (W1/W2)\n",
    "    STRICT_SNR_MIN = 5.0,             # min SNR in W1/W2 for strict\n",
    "    RELAX_SNR_MIN = 3.0,              # relaxed SNR min\n",
    "    ALLOW_C_IF_SNR = 8.0,             # accept 'C' if SNR>=this\n",
    "    CC_EXCLUDE = \"DHOP\",              # reject if cc_flags contains any of these\n",
    "    GALAXY_MODE = False,              # if True, prefer extended (ext_flg>0 or morph extended)\n",
    "    OUTDIR = \"./cnt_anomaly/out\",\n",
    "    CACHEDIR = \"./cnt_anomaly/cache\",\n",
    "    SEED = 42\n",
    ")\n",
    "\n",
    "# ================ ENV ================\n",
    "def ensure(pkgs):\n",
    "    missing=[]\n",
    "    for p in pkgs:\n",
    "        mod = p if p!=\"scikit-learn\" else \"sklearn\"\n",
    "        try: importlib.import_module(mod)\n",
    "        except Exception: missing.append(p)\n",
    "    if missing:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *missing])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.skyview import SkyView\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "np.random.seed(CFG[\"SEED\"])\n",
    "OUT = Path(CFG[\"OUTDIR\"]); OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(CFG[\"CACHEDIR\"]); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "CUT = OUT/\"cutouts\"; CUT.mkdir(parents=True, exist_ok=True)\n",
    "WEB = OUT/\"web\"; WEB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ================ UTILS ================\n",
    "def ts(): return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "def sanitize_id(s): return str(s).strip()\n",
    "\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=None):\n",
    "    Vizier.ROW_LIMIT = row_limit or CFG[\"N_MAX\"]\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec,\n",
    "                      colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    return d.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "# Robust numeric views (floatify first)\n",
    "def wise_views_numeric(df):\n",
    "    num = df.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0 = num.fillna(med)\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\",\"MG\",\"pm_norm\",\"G\",\"BP_RP\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\") or c in [\"BP_RP\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        X4 += np.random.default_rng(CFG[\"SEED\"]).normal(0, 1e-3, size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return views\n",
    "\n",
    "def votes_from_views(views, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(CFG[\"SEED\"])\n",
    "    flags = {}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=contam)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = (f1 | f2)\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "# Morphology: Pan-STARRS or DSS2 concentration + second moment\n",
    "def fetch_cutout_planes(ra, dec, fov_arcmin=2.0):\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"PanSTARRS r\"], pixels=512,\n",
    "                                  height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "        if imgs:\n",
    "            return imgs[0][0].data.astype(np.float32), \"PS1-r\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"], pixels=512,\n",
    "                                  height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "        if imgs:\n",
    "            return imgs[0][0].data.astype(np.float32), \"DSS2-Red\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    return None, None\n",
    "\n",
    "def morph_metrics(img):\n",
    "    if img is None or img.size==0: return np.nan, np.nan, np.nan\n",
    "    H, W = img.shape\n",
    "    y0, x0 = H//2, W//2\n",
    "    yy, xx = np.indices(img.shape)\n",
    "    r = np.hypot(yy - y0, xx - x0)\n",
    "    # robust background subtract\n",
    "    bg = np.median(img[(r>80) & (r<110)])\n",
    "    data = np.clip(img - bg, 0, None)\n",
    "    # inner/outer flux\n",
    "    rin, rout = 6, 20\n",
    "    fin = data[r<=rin].sum()\n",
    "    fout = data[(r<=rout)].sum()\n",
    "    conc = fin / max(fout, 1e-6)\n",
    "    # second moment (radius^2 weighted)\n",
    "    tot = data.sum()\n",
    "    r2 = ( (r**2)*data ).sum() / max(tot, 1e-6)\n",
    "    # simple FWHM-ish from moment\n",
    "    fwhm = 2.355*np.sqrt(r2/2.0) if np.isfinite(r2) else np.nan\n",
    "    return conc, r2, fwhm\n",
    "\n",
    "def triage_class_hint(w12, w23):\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12 >= 0.8) and (w23 >= 1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12 >= 0.3) and (w23 >= 1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "def wise_good_phqual(s, good=\"AB\", allow_c_if_snr=None, w1snr=0, w2snr=0):\n",
    "    s = str(s) if isinstance(s,str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"; w2 = s[1] if len(s)>1 else \"\"\n",
    "    ok = (w1 in good) and (w2 in good)\n",
    "    if (not ok) and allow_c_if_snr is not None:\n",
    "        if (w1 in \"ABC\") and (w2 in \"ABC\") and (w1snr>=allow_c_if_snr) and (w2snr>=allow_c_if_snr):\n",
    "            ok = True\n",
    "    return ok\n",
    "\n",
    "def cc_clean(flags, exclude=\"DHOP\"):\n",
    "    s = str(flags) if isinstance(flags, str) else \"\"\n",
    "    return not any(ch in s for ch in exclude)\n",
    "\n",
    "# ================ MAIN PIPELINE ================\n",
    "def run_pipeline(cfg):\n",
    "    stamp = ts()\n",
    "    print(f\"[CNT] Fused v2 start @ {stamp}\")\n",
    "    offsets = np.linspace(-cfg[\"GRID_STEP_DEG\"], cfg[\"GRID_STEP_DEG\"], cfg[\"GRID_SIZE\"])\n",
    "    tiles = [(cfg[\"CENTER_RA\"]+dx, cfg[\"CENTER_DEC\"]+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    # Sweep & anomaly votes (discovery)\n",
    "    st_all = []\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{cfg['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{cfg['RADIUS_DEG']}.csv\"\n",
    "        if gaia_cache.exists(): gaia = pd.read_csv(gaia_cache)\n",
    "        else:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, cfg[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=cfg[\"N_MAX\"])\n",
    "            gaia.to_csv(gaia_cache, index=False)\n",
    "        if wise_cache.exists(): gw = pd.read_csv(wise_cache)\n",
    "        else:\n",
    "            gw = xmatch_gaia_allwise(gaia, cfg[\"XMM_RADIUS_ARCSEC\"])\n",
    "            gw.to_csv(wise_cache, index=False)\n",
    "        if gw.empty: \n",
    "            print(\"  [skip] no crossmatches\")\n",
    "            continue\n",
    "\n",
    "        df = add_derived_features(clean_photometry(gw))\n",
    "        views = wise_views_numeric(df)\n",
    "        votes = votes_from_views(views)\n",
    "        if votes is None:\n",
    "            print(\"  [skip] no usable views\")\n",
    "            continue\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= cfg[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            st_all.append(st)\n",
    "\n",
    "    master = pd.concat(st_all, ignore_index=True) if st_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"; master.to_csv(master_path, index=False)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "    if master.empty:\n",
    "        print(\"[done] No stable anomalies. Adjust K_DISC / field and rerun.\")\n",
    "        return\n",
    "\n",
    "    # Enrich with AllWISE flags by ID bind\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    enr_rows=[]\n",
    "    for _, r in master.iterrows():\n",
    "        ra0 = float(r.get(\"ra_deg\", r.get(\"RA_ICRS\", np.nan)))\n",
    "        dec0= float(r.get(\"dec\", r.get(\"DE_ICRS\", np.nan)))\n",
    "        if not (pd.notna(ra0) and pd.notna(dec0)): continue\n",
    "        t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "        buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "        try:\n",
    "            xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                              max_distance=cfg[\"WISE_XMATCH_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "            xdf = xm.to_pandas()\n",
    "        except Exception:\n",
    "            xdf = pd.DataFrame()\n",
    "        if xdf.empty:\n",
    "            row = r.to_dict(); row.update({\"AllWISE\":\"\",\"bind_sep_arcsec\":np.nan})\n",
    "            enr_rows.append(row); continue\n",
    "        xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "        wid = sanitize_id(xdf.loc[0,\"AllWISE\"])\n",
    "        bind_sep = float(xdf.loc[0,\"angDist\"])*3600.0 if \"angDist\" in xdf.columns else np.nan\n",
    "\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            row = r.to_dict(); row.update({\"AllWISE\":wid,\"bind_sep_arcsec\":bind_sep})\n",
    "            enr_rows.append(row); continue\n",
    "        aw = q[0].to_pandas().iloc[0]\n",
    "        # SNR fallbacks from mag errors\n",
    "        def est_snr(emag): \n",
    "            try:\n",
    "                return float(1.0857/float(emag)) if (pd.notna(emag) and float(emag)>0) else np.nan\n",
    "            except Exception:\n",
    "                return np.nan\n",
    "        w1snr = aw.get(\"w1snr\", np.nan); w2snr = aw.get(\"w2snr\", np.nan)\n",
    "        if (pd.isna(w1snr)): w1snr = est_snr(aw.get(\"e_W1mag\", np.nan))\n",
    "        if (pd.isna(w2snr)): w2snr = est_snr(aw.get(\"e_W2mag\", np.nan))\n",
    "\n",
    "        row = r.to_dict()\n",
    "        row.update({\n",
    "            \"AllWISE\": wid, \"bind_sep_arcsec\": bind_sep,\n",
    "            \"RAJ2000\": aw.get(\"RAJ2000\",np.nan), \"DEJ2000\": aw.get(\"DEJ2000\",np.nan),\n",
    "            \"ph_qual\": aw.get(\"ph_qual\",np.nan), \"ext_flg\": aw.get(\"ext_flg\",np.nan),\n",
    "            \"cc_flags\": aw.get(\"cc_flags\",np.nan),\n",
    "            \"w1snr\": w1snr, \"w2snr\": w2snr, \"w3snr\": aw.get(\"w3snr\",np.nan), \"w4snr\": aw.get(\"w4snr\",np.nan),\n",
    "            \"W1\": aw.get(\"W1mag\",np.nan), \"W2\": aw.get(\"W2mag\",np.nan),\n",
    "            \"W3\": aw.get(\"W3mag\",np.nan), \"W4\": aw.get(\"W4mag\",np.nan)\n",
    "        })\n",
    "        enr_rows.append(row)\n",
    "\n",
    "    enr = pd.DataFrame(enr_rows)\n",
    "    # dedup by AllWISE or by coord within ~1\"\n",
    "    if \"AllWISE\" in enr.columns:\n",
    "        enr = enr.sort_values([\"AllWISE\",\"_votes\"], ascending=[True,False]).drop_duplicates(subset=[\"AllWISE\"])\n",
    "    enr_path = OUT/f\"stable_enriched_all_{stamp}.csv\"; enr.to_csv(enr_path, index=False)\n",
    "    print(f\"[save] enriched (all): {enr_path} (N={len(enr)})\")\n",
    "\n",
    "    # Reason tags + strict/relaxed gating\n",
    "    reasons=[]\n",
    "    def row_reason(r):\n",
    "        rs=[]\n",
    "        pq = r.get(\"ph_qual\", \"\")\n",
    "        w1s, w2s = float(r.get(\"w1snr\",0) or 0), float(r.get(\"w2snr\",0) or 0)\n",
    "        if not wise_good_phqual(pq, CFG[\"STRICT_W1W2_QUAL\"], CFG[\"ALLOW_C_IF_SNR\"], w1s, w2s):\n",
    "            rs.append(\"ph_qual_fail\")\n",
    "        if (w1s<CFG[\"STRICT_SNR_MIN\"]) or (w2s<CFG[\"STRICT_SNR_MIN\"]):\n",
    "            rs.append(\"snr_low\")\n",
    "        if not cc_clean(r.get(\"cc_flags\",\"\"), CFG[\"CC_EXCLUDE\"]):\n",
    "            rs.append(\"artifact_flag\")\n",
    "        if CFG[\"GALAXY_MODE\"] and str(r.get(\"ext_flg\",\"\"))==\"0\":\n",
    "            rs.append(\"ext_pref\")  # soft reason; will be used for gold tightening\n",
    "        return \";\".join(rs)\n",
    "\n",
    "    enr[\"reject_reasons\"] = [row_reason(r) for _,r in enr.iterrows()]\n",
    "\n",
    "    def pass_strict(r):\n",
    "        pq = r.get(\"ph_qual\",\"\"); w1s, w2s = float(r.get(\"w1snr\",0) or 0), float(r.get(\"w2snr\",0) or 0)\n",
    "        return (wise_good_phqual(pq, CFG[\"STRICT_W1W2_QUAL\"], CFG[\"ALLOW_C_IF_SNR\"], w1s, w2s)\n",
    "                and (w1s>=CFG[\"STRICT_SNR_MIN\"]) and (w2s>=CFG[\"STRICT_SNR_MIN\"])\n",
    "                and cc_clean(r.get(\"cc_flags\",\"\"), CFG[\"CC_EXCLUDE\"]))\n",
    "\n",
    "    def pass_relaxed(r):\n",
    "        w1s, w2s = float(r.get(\"w1snr\",0) or 0), float(r.get(\"w2snr\",0) or 0)\n",
    "        pq = r.get(\"ph_qual\",\"\")\n",
    "        return ((w1s>=CFG[\"RELAX_SNR_MIN\"]) and (w2s>=CFG[\"RELAX_SNR_MIN\"])\n",
    "                and (pq==pq) and cc_clean(r.get(\"cc_flags\",\"\"), CFG[\"CC_EXCLUDE\"]))\n",
    "\n",
    "    strict = enr[[pass_strict(r) for _,r in enr.iterrows()]].copy()\n",
    "    relaxed = enr[[pass_relaxed(r) for _,r in enr.iterrows()]].copy()\n",
    "    strict_path = OUT/f\"stable_enriched_strict_{stamp}.csv\"; strict.to_csv(strict_path, index=False)\n",
    "    relaxed_path = OUT/f\"stable_enriched_relaxed_{stamp}.csv\"; relaxed.to_csv(relaxed_path, index=False)\n",
    "    print(f\"[save] strict shortlist:  {strict_path} (N={len(strict)})\")\n",
    "    print(f\"[save] relaxed shortlist: {relaxed_path} (N={len(relaxed)})\")\n",
    "\n",
    "    base = strict if len(strict)>0 else (relaxed if len(relaxed)>0 else enr.copy())\n",
    "    # colors & hints\n",
    "    base[\"W1-W2\"] = base.get(\"W1\",np.nan) - base.get(\"W2\",np.nan)\n",
    "    base[\"W2-W3\"] = base.get(\"W2\",np.nan) - base.get(\"W3\",np.nan)\n",
    "    base[\"class_hint\"] = [triage_class_hint(w12,w23) for w12,w23 in zip(base[\"W1-W2\"], base[\"W2-W3\"])]\n",
    "\n",
    "    # Morphology (quick)\n",
    "    morph_rows=[]\n",
    "    for i, r in base.reset_index(drop=True).iterrows():\n",
    "        ra = float(r.get(\"RAJ2000\", r.get(\"ra_deg\", np.nan)))\n",
    "        dec= float(r.get(\"DEJ2000\", r.get(\"dec\", np.nan)))\n",
    "        if not (pd.notna(ra) and pd.notna(dec)):\n",
    "            morph_rows.append({\"conc\":np.nan,\"r2\":np.nan,\"fwhm\":np.nan,\"morph_src\":\"\"}); continue\n",
    "        img, src = fetch_cutout_planes(ra, dec, fov_arcmin=2.0)\n",
    "        conc, r2, fwhm = morph_metrics(img)\n",
    "        morph_rows.append({\"conc\":conc,\"r2\":r2,\"fwhm\":fwhm,\"morph_src\":src})\n",
    "    mdf = pd.DataFrame(morph_rows)\n",
    "    base = pd.concat([base.reset_index(drop=True), mdf], axis=1)\n",
    "    # heuristic: extended if concentration low OR fwhm larger than typical star (~<3px here)\n",
    "    base[\"morph_label\"] = np.where((base[\"conc\"]<=0.35) | (base[\"fwhm\"]>=6.0), \"extended\", \"pointlike\")\n",
    "\n",
    "    # Gallery\n",
    "    cards=[]\n",
    "    for i, r in base.reset_index(drop=True).iterrows():\n",
    "        ra = float(r.get(\"RAJ2000\", r.get(\"ra_deg\", np.nan)))\n",
    "        dec= float(r.get(\"DEJ2000\", r.get(\"dec\", np.nan)))\n",
    "        if not (pd.notna(ra) and pd.notna(dec)): continue\n",
    "        # make a PNG if not already by morph step\n",
    "        try:\n",
    "            imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"PanSTARRS g\",\"PanSTARRS r\",\"PanSTARRS i\"],\n",
    "                                      pixels=512, height=2.0*u.arcmin, width=2.0*u.arcmin)\n",
    "            if imgs and len(imgs)>=3:\n",
    "                def norm(a): return np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "                g = imgs[0][0].data.astype(np.float32)\n",
    "                r_ = imgs[1][0].data.astype(np.float32)\n",
    "                i_ = imgs[2][0].data.astype(np.float32)\n",
    "                rgb = np.stack([norm(i_), norm(r_), norm(g)], axis=-1)\n",
    "                tag = f\"cand_{i:02d}\"\n",
    "                outp = WEB/f\"{tag}.png\"\n",
    "                plt.figure(figsize=(3.2,3.2)); plt.imshow(rgb, origin=\"lower\"); plt.axis(\"off\")\n",
    "                plt.tight_layout(pad=0); plt.savefig(outp, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "                png = str(outp)\n",
    "            else:\n",
    "                png = \"\"\n",
    "        except Exception:\n",
    "            png = \"\"\n",
    "        cards.append((png, float(r.get(\"W1-W2\",np.nan)), float(r.get(\"W2-W3\",np.nan)),\n",
    "                      int(r.get(\"_votes\",0)), str(r.get(\"AllWISE\",\"\")), r.get(\"morph_label\",\"\")))\n",
    "\n",
    "    html = WEB/f\"index_{stamp}.html\"\n",
    "    with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(\"<html><head><meta charset='utf-8'><title>CNT Shortlist v2</title>\"\n",
    "                \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;\"\n",
    "                \"max-width:180px}</style></head><body>\")\n",
    "        f.write(f\"<h1>CNT Shortlist v2 — {stamp}</h1>\")\n",
    "        for (png,w12,w23,v,wid,morph) in cards:\n",
    "            f.write(\"<div class='card'>\")\n",
    "            if png and Path(png).exists(): f.write(f\"<img src='../{Path(png).relative_to(OUT)}'/>\")\n",
    "            else: f.write(\"<div style='width:180px;height:135px;background:#f3f3f3;border-radius:8px;display:flex;\"\n",
    "                          \"align-items:center;justify-content:center;color:#888'>no image</div>\")\n",
    "            f.write(f\"<div><div><b>votes:</b> {v} &nbsp; <b>AllWISE:</b> {wid} &nbsp; <b>morph:</b> {morph}</div>\")\n",
    "            f.write(f\"<div><b>W1−W2:</b> {w12:.3f} &nbsp; <b>W2−W3:</b> {w23:.3f}</div></div></div>\")\n",
    "        f.write(\"</body></html>\")\n",
    "    print(f\"[save] gallery → {html}\")\n",
    "\n",
    "    # GOLD gating (optionally prefer extended if GALAXY_MODE)\n",
    "    base[\"_votes\"] = base[\"_votes\"].fillna(0)\n",
    "    gold_mask = (base[\"_votes\"]>=cfg[\"K_GOLD\"]) & (base[\"W2-W3\"].fillna(-99)>=cfg[\"GOLD_W23_MIN\"])\n",
    "    if cfg[\"GALAXY_MODE\"]:\n",
    "        gold_mask &= ( (base[\"morph_label\"]==\"extended\") | (base.get(\"ext_flg\",\"\").astype(str)!=\"0\") | (base[\"W1-W2\"].fillna(0)>=0.5) )\n",
    "    gold = base[gold_mask].copy().reset_index(drop=True)\n",
    "    gold_path = OUT/f\"strict_gold_candidates_{stamp}.csv\"; gold.to_csv(gold_path, index=False)\n",
    "    print(f\"[save] GOLD set → {gold_path} (N={len(gold)})\")\n",
    "    if gold.empty:\n",
    "        print(\"[note] No gold after morphology/gates—inspect gallery and loosen thresholds if desired.\")\n",
    "\n",
    "    # ID-locked verification at exact AllWISE + SIMBAD/NED labels\n",
    "    Simbad.add_votable_fields(\"otype\",\"otypes\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "    ver_rows=[]\n",
    "    for _, g in gold.iterrows():\n",
    "        wid = sanitize_id(g.get(\"AllWISE\",\"\"))\n",
    "        # Bind by ID; if missing, attempt bind from coords\n",
    "        if not wid:\n",
    "            ra0 = float(g.get(\"ra_deg\", np.nan)); dec0=float(g.get(\"dec\", np.nan))\n",
    "            if pd.notna(ra0) and pd.notna(dec0):\n",
    "                t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "                buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "                try:\n",
    "                    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                                      max_distance=CFG[\"WISE_XMATCH_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "                    xdf = xm.to_pandas().sort_values(\"angDist\")\n",
    "                    if len(xdf):\n",
    "                        wid = sanitize_id(xdf.iloc[0][\"AllWISE\"])\n",
    "                except Exception:\n",
    "                    pass\n",
    "        if not wid:\n",
    "            ver_rows.append({\"wise_id\":\"\", \"status\":\"no-allwise-id\", \"votes_at_exact\":np.nan})\n",
    "            continue\n",
    "        q_exact = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q_exact)==0 or len(q_exact[0])==0:\n",
    "            ver_rows.append({\"wise_id\":wid,\"status\":\"id-not-found\", \"votes_at_exact\":np.nan}); continue\n",
    "        exact = q_exact[0].to_pandas()\n",
    "        wise_ra = float(exact.iloc[0][\"RAJ2000\"]); wise_dec=float(exact.iloc[0][\"DEJ2000\"])\n",
    "        center = SkyCoord(wise_ra*u.deg, wise_dec*u.deg)\n",
    "\n",
    "        env = Vizier(columns=[\"**\"]).query_region(center, radius=(cfg[\"CONE_ENV_ARCMIN\"]*u.arcmin), catalog=\"II/328/allwise\")\n",
    "        env_df = env[0].to_pandas() if len(env)>0 and len(env[0])>0 else pd.DataFrame()\n",
    "        if \"AllWISE\" in env_df.columns:\n",
    "            env_df[\"AllWISE\"] = env_df[\"AllWISE\"].astype(str).map(sanitize_id)\n",
    "        else:\n",
    "            env_df[\"AllWISE\"] = \"\"\n",
    "        if wid not in set(env_df[\"AllWISE\"]):\n",
    "            env_df = pd.concat([env_df, exact], ignore_index=True)\n",
    "\n",
    "        # Build numeric views on AllWISE-only features\n",
    "        # (reusing wise_views_numeric is fine—expects numeric columns)\n",
    "        views_env = wise_views_numeric(env_df.rename(columns={\n",
    "            \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\"\n",
    "        }))\n",
    "        v_arr = votes_from_views(views_env)\n",
    "        if v_arr is None:\n",
    "            ver_rows.append({\"wise_id\":wid,\"status\":\"no-votes\",\"votes_at_exact\":np.nan}); continue\n",
    "\n",
    "        env_df[\"_votes\"] = v_arr\n",
    "        # exact row by ID (fallback nearest)\n",
    "        if \"AllWISE\" in env_df.columns:\n",
    "            idxs = env_df.index[env_df[\"AllWISE\"].astype(str).map(sanitize_id) == wid]\n",
    "            j = int(idxs[0]) if len(idxs)>0 else None\n",
    "        else:\n",
    "            j = None\n",
    "        if j is None:\n",
    "            coords = SkyCoord(env_df[\"RAJ2000\"].astype(float).values*u.deg, env_df[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "            seps = coords.separation(center).arcsec\n",
    "            j = int(np.argmin(seps))\n",
    "            sep_to_exact = float(seps[j])\n",
    "        else:\n",
    "            sep_to_exact = SkyCoord(float(env_df.loc[j,\"RAJ2000\"])*u.deg,\n",
    "                                    float(env_df.loc[j,\"DEJ2000\"])*u.deg).separation(center).arcsec\n",
    "\n",
    "        votes_here = int(env_df.iloc[j][\"_votes\"]) if sep_to_exact <= cfg[\"NEAR_ARCSEC\"] else np.nan\n",
    "\n",
    "        # SIMBAD / NED labels\n",
    "        try:\n",
    "            s = Simbad.query_region(center, radius=5.0*u.arcsec)\n",
    "            if s is not None and len(s)>0:\n",
    "                p = s.to_pandas().iloc[0]; simbad_id = p.get(\"MAIN_ID\",\"\"); simbad_type=p.get(\"OTYPE\",\"\")\n",
    "            else: simbad_id=\"\"; simbad_type=\"\"\n",
    "        except Exception:\n",
    "            simbad_id=\"\"; simbad_type=\"\"\n",
    "        if HAVE_NED:\n",
    "            try:\n",
    "                n = Ned.query_region(center, radius=5.0*u.arcsec)\n",
    "                if n is not None and len(n)>0:\n",
    "                    npd = n.to_pandas().iloc[0]\n",
    "                    ned_name=npd.get(\"Object Name\",\"\"); ned_type=npd.get(\"Type\",\"\"); ned_z=npd.get(\"Redshift\",\"\")\n",
    "                else: ned_name=\"\"; ned_type=\"\"; ned_z=\"\"\n",
    "            except Exception:\n",
    "                ned_name=\"\"; ned_type=\"\"; ned_z=\"\"\n",
    "        else:\n",
    "            ned_name=ned_type=ned_z=\"\"\n",
    "\n",
    "        # morphology at exact\n",
    "        img, msrc = fetch_cutout_planes(wise_ra, wise_dec, fov_arcmin=2.0)\n",
    "        conc, r2, fwhm = morph_metrics(img)\n",
    "        morph_label = \"extended\" if (conc<=0.35) or (fwhm>=6.0) else \"pointlike\"\n",
    "\n",
    "        ver_rows.append({\n",
    "            \"wise_id\": wid, \"wise_ra\": wise_ra, \"wise_dec\": wise_dec,\n",
    "            \"sep_to_exact_arcsec\": sep_to_exact,\n",
    "            \"votes_at_exact\": votes_here,\n",
    "            \"passes_gold_K\": bool(votes_here>=cfg[\"K_GOLD\"]) if pd.notna(votes_here) else False,\n",
    "            \"W1-W2\": env_df.iloc[j].get(\"W1mag\", np.nan) - env_df.iloc[j].get(\"W2mag\", np.nan),\n",
    "            \"W2-W3\": env_df.iloc[j].get(\"W2mag\", np.nan) - env_df.iloc[j].get(\"W3mag\", np.nan),\n",
    "            \"morph\": morph_label, \"conc\": conc, \"fwhm\": fwhm, \"morph_src\": msrc,\n",
    "            \"simbad_id\": simbad_id, \"simbad_type\": simbad_type,\n",
    "            \"ned_name\": ned_name, \"ned_type\": ned_type, \"ned_z\": ned_z,\n",
    "            \"status\": \"ok\" if pd.notna(votes_here) else \"exact-present-but-outside-near-radius\"\n",
    "        })\n",
    "\n",
    "    ver = pd.DataFrame(ver_rows)\n",
    "    ver_path = OUT/f\"gold_verification_idlocked_{stamp}.csv\"; ver.to_csv(ver_path, index=False)\n",
    "    print(f\"[save] ID-locked verification → {ver_path}\")\n",
    "\n",
    "    # Bundle + prereg JSON (default=str to handle Paths)\n",
    "    claim = dict(\n",
    "        when=stamp,\n",
    "        center=(cfg[\"CENTER_RA\"], cfg[\"CENTER_DEC\"]),\n",
    "        tiles=len(tiles),\n",
    "        K_DISC=cfg[\"K_DISC\"], K_GOLD=cfg[\"K_GOLD\"], GOLD_W23_MIN=cfg[\"GOLD_W23_MIN\"],\n",
    "        GALAXY_MODE=cfg[\"GALAXY_MODE\"],\n",
    "        master=str(master_path), enriched=str(enr_path),\n",
    "        strict=str(strict_path), relaxed=str(relaxed_path),\n",
    "        gold=str(gold_path), verify=str(ver_path), gallery=str(html)\n",
    "    )\n",
    "    prereg_path = OUT/f\"preregister_{stamp}.json\"\n",
    "    with open(prereg_path, \"w\") as f: json.dump(claim, f, indent=2, default=str)\n",
    "    print(\"[save] prereg json →\", prereg_path)\n",
    "\n",
    "    # Tiny report\n",
    "    report = OUT/f\"CNT_TechnoAnomaly_Report_{stamp}.md\"\n",
    "    with open(report,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Techno-Anomaly v2 — {stamp}\\n\\n\")\n",
    "        f.write(f\"- Tiles: **{len(tiles)}**\\n- Master stable: **{len(master)}**\\n\")\n",
    "        f.write(f\"- Strict: **{len(strict)}**, Relaxed: **{len(relaxed)}**\\n\")\n",
    "        f.write(f\"- GOLD (pre-verify): **{len(gold)}**\\n\\n\")\n",
    "        if not ver.empty:\n",
    "            gk = int((ver[\"passes_gold_K\"]==True).sum())\n",
    "            f.write(f\"- ID-locked GOLD (K≥{cfg['K_GOLD']}): **{gk}**\\n\\n\")\n",
    "        f.write(\"## Key files\\n\")\n",
    "        for p in [master_path,enr_path,strict_path,relaxed_path,gold_path,ver_path,html,prereg_path]:\n",
    "            f.write(f\"- `{p}`\\n\")\n",
    "    print(\"[save] report →\", report)\n",
    "\n",
    "    # Zip bundle\n",
    "    zip_base = OUT/f\"CNT_TechnoAnomaly_{stamp}\"\n",
    "    with open(OUT/f\"FILES_{stamp}.txt\",\"w\") as idx:\n",
    "        idx.write(\"\\n\".join([str(master_path),str(enr_path),str(strict_path),str(relaxed_path),\n",
    "                             str(gold_path),str(ver_path),str(prereg_path),str(report),str(html)]))\n",
    "    shutil.make_archive(str(zip_base), \"zip\", OUT)\n",
    "    print(f\"[bundle] zip → {zip_base}.zip\")\n",
    "\n",
    "    print(\"\\n== SUMMARY ==\")\n",
    "    print(f\"Tiles: {len(tiles)} | Master: {len(master)} | Strict: {len(strict)} | Relaxed: {len(relaxed)} | Gold: {len(gold)}\")\n",
    "    if not ver.empty:\n",
    "        print(f\"ID-locked Gold passes: {(ver['passes_gold_K']==True).sum()}\")\n",
    "\n",
    "# ================= RUN =================\n",
    "run_pipeline(CFG)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "267c9d94-a54d-4e93-81ea-95d8e391c6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] tolerant id-locked → cnt_anomaly\\out\\gold_verification_idlocked_tolerant.csv\n",
      "            wise_id  near_sep_arcsec  votes6_at_exact  pass_tolerant_gauge  W1-W2  W2-W3          status\n",
      "J135656.78-011722.9              0.0                0                False    NaN    NaN under-threshold\n",
      "J140338.61-011729.7              0.0                0                False    NaN    NaN under-threshold\n"
     ]
    }
   ],
   "source": [
    "# ID-locked tolerant gauge v2.1 — AllWISE colors only, 3/6 votes\n",
    "import os, io, sys, warnings, subprocess, importlib\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold_csvs = sorted(OUT.glob(\"strict_gold_candidates_*.csv\"))\n",
    "assert gold_csvs, \"No gold file found.\"\n",
    "gold = pd.read_csv(gold_csvs[-1])\n",
    "\n",
    "NEAR_ARCSEC = 8.0   # was 5.0\n",
    "CONTAM = 0.02       # slightly more permissive for verifier\n",
    "\n",
    "def fetch_exact(wise_id):\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wise_id))\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    return q[0].to_pandas()\n",
    "\n",
    "def fetch_env(ra, dec, arcmin=8.0):\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    res = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "    return res[0].to_pandas() if len(res)>0 and len(res[0])>0 else pd.DataFrame()\n",
    "\n",
    "def build_views_colors(df):\n",
    "    d = df.copy()\n",
    "    # harmonize names\n",
    "    ren = {\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\"RAJ2000\":\"ra\",\"DEJ2000\":\"dec\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v]=d[k]\n",
    "    # colors only\n",
    "    d[\"W1-W2\"] = d[\"W1\"] - d[\"W2\"]\n",
    "    d[\"W2-W3\"] = d[\"W2\"] - d[\"W3\"]\n",
    "    feats = d[[\"W1-W2\",\"W2-W3\"]].astype(\"float64\")\n",
    "    feats = feats.replace([np.inf,-np.inf], np.nan).fillna(feats.median())\n",
    "    # 3 symbol-preserving transforms\n",
    "    V = {}\n",
    "    V[\"robust\"] = RobustScaler().fit_transform(feats.values)\n",
    "    V[\"std\"]    = StandardScaler().fit_transform(feats.values)\n",
    "    V[\"rankgauss\"] = QuantileTransformer(output_distribution=\"normal\", n_quantiles=min(128,len(feats))).fit_transform(feats.values)\n",
    "    return feats, V\n",
    "\n",
    "def votes_ensemble(V):\n",
    "    rng = np.random.RandomState(42)\n",
    "    votes = np.zeros(len(next(iter(V.values()))), dtype=int)\n",
    "    for name, X in V.items():\n",
    "        iso = IsolationForest(n_estimators=300, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        vf1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=35, contamination=CONTAM)\n",
    "            vf2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            vf2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        votes += vf1.astype(int) + vf2.astype(int)  # two models per view\n",
    "    return votes  # range 0..6\n",
    "\n",
    "rows=[]\n",
    "for _, g in gold.reset_index(drop=True).iterrows():\n",
    "    wid = str(g.get(\"AllWISE\",\"\")).strip()\n",
    "    if not wid:\n",
    "        rows.append({\"wise_id\":\"\",\"status\":\"no-id\"}); continue\n",
    "    ex = fetch_exact(wid)\n",
    "    if ex is None or ex.empty:\n",
    "        rows.append({\"wise_id\":wid,\"status\":\"id-not-found\"}); continue\n",
    "    ra = float(ex.iloc[0][\"RAJ2000\"]); dec = float(ex.iloc[0][\"DEJ2000\"])\n",
    "    env = fetch_env(ra, dec, arcmin=8.0)\n",
    "    if env.empty:\n",
    "        rows.append({\"wise_id\":wid,\"status\":\"no-env\"}); continue\n",
    "    # ensure exact row present\n",
    "    if \"AllWISE\" in env.columns:\n",
    "        env[\"AllWISE\"] = env[\"AllWISE\"].astype(str)\n",
    "        if wid not in set(env[\"AllWISE\"]):\n",
    "            env = pd.concat([env, ex], ignore_index=True)\n",
    "    feats, V = build_views_colors(env)\n",
    "    votes6 = votes_ensemble(V)\n",
    "    env[\"_votes6\"] = votes6\n",
    "    # find exact row\n",
    "    j = None\n",
    "    if \"AllWISE\" in env.columns:\n",
    "        idx = env.index[env[\"AllWISE\"].astype(str) == wid]\n",
    "        if len(idx)>0: j = int(idx[0])\n",
    "    if j is None:\n",
    "        coords = SkyCoord(env[\"RAJ2000\"].astype(float).values*u.deg, env[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "        sep = coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec\n",
    "        j = int(np.argmin(sep)); near = float(sep[j])\n",
    "    else:\n",
    "        near = SkyCoord(float(env.loc[j,\"RAJ2000\"])*u.deg, float(env.loc[j,\"DEJ2000\"])*u.deg).separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec\n",
    "    votes_here = int(env.iloc[j][\"_votes6\"]) if near<=NEAR_ARCSEC else np.nan\n",
    "    pass_tolerant = (votes_here>=3) if pd.notna(votes_here) else False\n",
    "    rows.append({\n",
    "        \"wise_id\": wid, \"near_sep_arcsec\": near, \"votes6_at_exact\": votes_here,\n",
    "        \"pass_tolerant_gauge\": pass_tolerant,\n",
    "        \"W1-W2\": float(env.iloc[j][\"W1\"]) - float(env.iloc[j][\"W2\"]) if all(c in env.columns for c in [\"W1\",\"W2\"]) else np.nan,\n",
    "        \"W2-W3\": float(env.iloc[j][\"W2\"]) - float(env.iloc[j][\"W3\"]) if all(c in env.columns for c in [\"W2\",\"W3\"]) else np.nan,\n",
    "        \"status\":\"ok\" if pass_tolerant else \"under-threshold\"\n",
    "    })\n",
    "\n",
    "ver = pd.DataFrame(rows)\n",
    "out = OUT/\"gold_verification_idlocked_tolerant.csv\"\n",
    "ver.to_csv(out, index=False)\n",
    "print(f\"[save] tolerant id-locked → {out}\")\n",
    "print(ver.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64c6b47-04bb-470a-8cc6-217fe3ed229c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gold] strict_gold_candidates_20251016-200351.csv\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale.csv\n",
      "            AllWISE  best_votes  best_scale_arcmin  sep_to_exact_arcsec  pass_multiscale  W1-W2  W2-W3 status\n",
      "J135656.78-011722.9           5                2.0                  0.0             True  0.349  3.768     ok\n",
      "J140338.61-011729.7           0                2.0                  0.0            False -0.068  2.526     ok\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — ID-locked Multiscale Canonical Gauge v3\n",
    "# Scales: 2', 4', 8' | Features: W1..W4 mags + colors + SED slope | Pass if max K ≥ 4\n",
    "\n",
    "import os, io, sys, warnings, subprocess, importlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "gold_csv = sorted(OUT.glob(\"strict_gold_candidates_*.csv\"))[-1]\n",
    "gold = pd.read_csv(gold_csv)\n",
    "print(\"[gold]\", gold_csv.name)\n",
    "\n",
    "SCALES_ARCMIN = [2.0, 4.0, 8.0]\n",
    "K_BAR = 4\n",
    "CONTAM = 0.01\n",
    "SEED = 42\n",
    "np.random.seed(SEED)\n",
    "Vizier.ROW_LIMIT = -1\n",
    "\n",
    "def fetch_exact_row(wise_id):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wise_id))\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    return q[0].to_pandas().iloc[0]\n",
    "\n",
    "def fetch_env(ra, dec, arcmin):\n",
    "    res = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                              radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "    return res[0].to_pandas() if len(res)>0 and len(res[0])>0 else pd.DataFrame()\n",
    "\n",
    "def canonical_features(df):\n",
    "    d = df.copy()\n",
    "    # harmonize\n",
    "    ren = {\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "           \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v]=d[k]\n",
    "    # colors + slope\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "    if all(c in d for c in [\"W1\",\"W2\",\"W3\"]):\n",
    "        d[\"SED_slope_W1_W3\"] = (d[\"W1\"]-d[\"W3\"])/2.0\n",
    "    # build numeric matrix (float64; median impute)\n",
    "    num = d.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0  = num.fillna(med)\n",
    "    # five symbol-preserving views\n",
    "    views={}\n",
    "    cols1=[c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "    cols2=[c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "    cols3=[c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"]=RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"]=StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"]=X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4=sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        rng=np.random.default_rng(SEED)\n",
    "        X4 = X0[cols4].copy(); X4 += rng.normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"]=X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a=RobustScaler().fit_transform(X0[cols1]); X5b=StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"]=np.concatenate([X5a,X5b],axis=1)\n",
    "    return d, views\n",
    "\n",
    "def votes_from_views(views):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(SEED)\n",
    "    flags={}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=300, contamination=CONTAM, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        # LOF with safe neighbors\n",
    "        nn = min(35, max(10, len(X)//10)) if len(X)>20 else max(5, len(X)-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=nn, contamination=CONTAM)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name]= (f1|f2)\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "rows=[]\n",
    "for _, g in gold.reset_index(drop=True).iterrows():\n",
    "    wid = str(g.get(\"AllWISE\",\"\")).strip()\n",
    "    if not wid:\n",
    "        rows.append({\"AllWISE\":\"\",\"status\":\"no-id\"}); continue\n",
    "    ex = fetch_exact_row(wid)\n",
    "    if ex is None:\n",
    "        rows.append({\"AllWISE\":wid,\"status\":\"id-not-found\"}); continue\n",
    "    ra = float(ex[\"RAJ2000\"]); dec = float(ex[\"DEJ2000\"])\n",
    "    bestK = -1; bestScale = None; bestSep = None\n",
    "    for arcmin in SCALES_ARCMIN:\n",
    "        env = fetch_env(ra, dec, arcmin=arcmin)\n",
    "        if env.empty:\n",
    "            continue\n",
    "        # ensure exact row present\n",
    "        env[\"AllWISE\"] = env.get(\"AllWISE\",\"\").astype(str)\n",
    "        if wid not in set(env[\"AllWISE\"]): env = pd.concat([env, ex.to_frame().T], ignore_index=True)\n",
    "        d, views = canonical_features(env)\n",
    "        K = votes_from_views(views)\n",
    "        if K is None: continue\n",
    "        # locate exact row by ID (fallback nearest)\n",
    "        if \"AllWISE\" in d.columns:\n",
    "            idxs = d.index[d[\"AllWISE\"].astype(str)==wid]\n",
    "            j = int(idxs[0]) if len(idxs)>0 else None\n",
    "        else:\n",
    "            j=None\n",
    "        if j is None:\n",
    "            coords = SkyCoord(d[\"RAJ2000\"].astype(float).values*u.deg, d[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "            sep = coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec\n",
    "            j = int(np.argmin(sep)); sepj = float(sep[j])\n",
    "        else:\n",
    "            sepj = 0.0\n",
    "        Kj = int(K[j])\n",
    "        if Kj > bestK:\n",
    "            bestK = Kj; bestScale = arcmin; bestSep = sepj\n",
    "    # colors at exact (from exact row)\n",
    "    W1, W2, W3 = ex.get(\"W1mag\", np.nan), ex.get(\"W2mag\", np.nan), ex.get(\"W3mag\", np.nan)\n",
    "    w12 = (W1-W2) if pd.notna(W1) and pd.notna(W2) else np.nan\n",
    "    w23 = (W2-W3) if pd.notna(W2) and pd.notna(W3) else np.nan\n",
    "    rows.append({\n",
    "        \"AllWISE\": wid, \"best_votes\": bestK, \"best_scale_arcmin\": bestScale, \"sep_to_exact_arcsec\": bestSep,\n",
    "        \"pass_multiscale\": bool(bestK>=K_BAR) if bestK>=0 else False,\n",
    "        \"W1-W2\": w12, \"W2-W3\": w23, \"status\": \"ok\" if bestK>=0 else \"no-env\"\n",
    "    })\n",
    "\n",
    "ver = pd.DataFrame(rows)\n",
    "out = OUT/\"gold_verification_idlocked_multiscale.csv\"\n",
    "ver.to_csv(out, index=False)\n",
    "print(f\"[save] multiscale verify → {out}\")\n",
    "print(ver.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "558ba1c5-f824-41cc-8d7b-69101014472a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[save] dossier → cnt_anomaly\\out\\CNT_Gold_Dossier_J135656-011722.md\n"
     ]
    }
   ],
   "source": [
    "# CNT Gold Dossier — WISE J135656.78−011722.9\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt, io\n",
    "from pathlib import Path\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.ned import Ned\n",
    "from astroquery.skyview import SkyView\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "WISE_ID = \"J135656.78-011722.9\"\n",
    "\n",
    "Vizier.ROW_LIMIT = -1\n",
    "# Exact AllWISE\n",
    "aw = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=WISE_ID)[0].to_pandas().iloc[0]\n",
    "ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "\n",
    "# SNR fallbacks (from mag errors if needed)\n",
    "def snr_from_emag(e): \n",
    "    try: return 1.0857/float(e) if (e and float(e)>0) else np.nan\n",
    "    except: return np.nan\n",
    "w1snr = aw.get(\"w1snr\", np.nan); w2snr = aw.get(\"w2snr\", np.nan)\n",
    "if pd.isna(w1snr): w1snr = snr_from_emag(aw.get(\"e_W1mag\", np.nan))\n",
    "if pd.isna(w2snr): w2snr = snr_from_emag(aw.get(\"e_W2mag\", np.nan))\n",
    "\n",
    "# SIMBAD + NED\n",
    "coord = SkyCoord(ra*u.deg, dec*u.deg)\n",
    "Simbad.add_votable_fields(\"otype\",\"otypes\",\"sp\",\"flux(V)\",\"flux(B)\")\n",
    "try:\n",
    "    s = Simbad.query_region(coord, radius=5*u.arcsec)\n",
    "    simbad_id = s.to_pandas().iloc[0][\"MAIN_ID\"] if (s is not None and len(s)>0) else \"\"\n",
    "    simbad_type = s.to_pandas().iloc[0][\"OTYPE\"] if (s is not None and len(s)>0) else \"\"\n",
    "except Exception:\n",
    "    simbad_id = simbad_type = \"\"\n",
    "try:\n",
    "    n = Ned.query_region(coord, radius=5*u.arcsec)\n",
    "    if n is not None and len(n)>0:\n",
    "        npd = n.to_pandas().iloc[0]\n",
    "        ned_name = npd.get(\"Object Name\",\"\"); ned_type = npd.get(\"Type\",\"\"); ned_z = npd.get(\"Redshift\",\"\")\n",
    "    else:\n",
    "        ned_name = ned_type = ned_z = \"\"\n",
    "except Exception:\n",
    "    ned_name = ned_type = ned_z = \"\"\n",
    "\n",
    "# Gaia DR3 around target (π, pm) to rule out nearby YSO\n",
    "g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\",\"Gmag\"]).query_region(coord, radius=3*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "gaia = g[0].to_pandas() if (g and len(g)>0 and len(g[0])>0) else pd.DataFrame()\n",
    "\n",
    "# Quick cutout & morphology cue\n",
    "def cutout_png(ra, dec, tag, fov=2.0):\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"PanSTARRS g\",\"PanSTARRS r\",\"PanSTARRS i\"],\n",
    "                                  pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "        if imgs and len(imgs)>=3:\n",
    "            def norm(a): \n",
    "                a = a[0].data.astype(np.float32)\n",
    "                return np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            g = norm(imgs[0]); r = norm(imgs[1]); i = norm(imgs[2])\n",
    "            rgb = np.stack([i,r,g],axis=-1)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(rgb, origin=\"lower\"); plt.axis(\"off\")\n",
    "            out = FIG/f\"{tag}_PS1.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close(); return out\n",
    "    except Exception: pass\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                  pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "        if imgs:\n",
    "            a = imgs[0][0].data.astype(np.float32)\n",
    "            a = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(a, origin=\"lower\", cmap=\"gray\"); plt.axis(\"off\")\n",
    "            out = FIG/f\"{tag}_DSS2.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close(); return out\n",
    "    except Exception: pass\n",
    "    return None\n",
    "\n",
    "png = cutout_png(ra, dec, \"WISE_J135656-011722\")\n",
    "\n",
    "# SED plot\n",
    "mags = [aw.get(\"W1mag\",np.nan), aw.get(\"W2mag\",np.nan), aw.get(\"W3mag\",np.nan), aw.get(\"W4mag\",np.nan)]\n",
    "bands= [\"W1\",\"W2\",\"W3\",\"W4\"]\n",
    "plt.figure(figsize=(4,3))\n",
    "plt.plot(range(len(mags)), mags, marker=\"o\")\n",
    "plt.gca().invert_yaxis(); plt.xticks(range(len(mags)), bands)\n",
    "plt.title(\"WISE J135656.78−011722.9 — SED\")\n",
    "plt.tight_layout()\n",
    "sedpng = FIG/\"WISE_J135656-011722_SED.png\"\n",
    "plt.savefig(sedpng, dpi=150); plt.close()\n",
    "\n",
    "# Dossier markdown\n",
    "md = OUT/\"CNT_Gold_Dossier_J135656-011722.md\"\n",
    "with open(md, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# CNT Gold Dossier — WISE J135656.78−011722.9\\n\\n\")\n",
    "    f.write(f\"**Position (ICRS):** RA {ra:.6f}, Dec {dec:.6f}\\n\\n\")\n",
    "    f.write(\"## AllWISE photometry & flags\\n\")\n",
    "    f.write(f\"- W1={aw.get('W1mag')}, W2={aw.get('W2mag')}, W3={aw.get('W3mag')}, W4={aw.get('W4mag')}\\n\")\n",
    "    f.write(f\"- W1−W2={aw.get('W1mag')-aw.get('W2mag'):.3f}, W2−W3={aw.get('W2mag')-aw.get('W3mag'):.3f}\\n\")\n",
    "    f.write(f\"- ph_qual={aw.get('ph_qual','')}, cc_flags={aw.get('cc_flags','')}, ext_flg={aw.get('ext_flg','')}\\n\")\n",
    "    f.write(f\"- SNR: w1={w1snr:.1f}, w2={w2snr:.1f} (W3/W4 from table if present)\\n\\n\")\n",
    "    f.write(\"## Catalog labels\\n\")\n",
    "    f.write(f\"- SIMBAD: {simbad_id}  ({simbad_type})\\n\")\n",
    "    f.write(f\"- NED: {ned_name}  [{ned_type}]  z={ned_z}\\n\\n\")\n",
    "    f.write(\"## Gaia DR3 (3″)\\n\")\n",
    "    if not gaia.empty:\n",
    "        r0 = gaia.iloc[0]\n",
    "        f.write(f\"- parallax={r0.get('parallax',np.nan)} mas; pmRA={r0.get('pmRA',np.nan)} mas/yr; pmDE={r0.get('pmDE',np.nan)} mas/yr\\n\")\n",
    "    else:\n",
    "        f.write(\"- no Gaia DR3 counterpart within 3″ (supports extragalactic nature)\\n\")\n",
    "    f.write(\"\\n## Files\\n\")\n",
    "    if png: f.write(f\"- Cutout: {png}\\n\")\n",
    "    f.write(f\"- SED: {sedpng}\\n\")\n",
    "print(\"[save] dossier →\", md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "038ea1bd-0a7a-4d53-a1f1-bd7c19876c81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HOTFIX loaded: RA/Dec auto-detection enabled for PS1/SDSS/GALEX. Re-run the multi-survey cell.\n"
     ]
    }
   ],
   "source": [
    "# HOTFIX — robust RA/Dec detection for PS1/SDSS/GALEX + safer helpers\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# Find RA/Dec column names in a dataframe\n",
    "def _find_radec_cols(df):\n",
    "    ra_candidates  = [\"ra\",\"RA\",\"raMean\",\"raStack\",\"raStackMean\",\"objra\",\"RAJ2000\",\"RA_ICRS\",\"posRA\",\"raAp\"]\n",
    "    dec_candidates = [\"dec\",\"DEC\",\"decMean\",\"decStack\",\"decStackMean\",\"objdec\",\"DEJ2000\",\"DE_ICRS\",\"posDec\",\"decAp\"]\n",
    "    ra_col  = next((c for c in ra_candidates  if c in df.columns), None)\n",
    "    dec_col = next((c for c in dec_candidates if c in df.columns), None)\n",
    "    return ra_col, dec_col\n",
    "\n",
    "# Nearest row to (ra0,dec0); auto-detect RA/Dec cols if needed\n",
    "def nearest_row(df, ra_col=None, dec_col=None, ra0=None, dec0=None):\n",
    "    if df is None or len(df)==0:\n",
    "        return pd.Series(dtype=\"float64\"), np.nan\n",
    "    if (ra_col is None) or (ra_col not in df.columns) or (dec_col is None) or (dec_col not in df.columns):\n",
    "        ra_col, dec_col = _find_radec_cols(df)\n",
    "        if ra_col is None or dec_col is None:\n",
    "            raise KeyError(f\"Could not find RA/Dec columns in: {list(df.columns)[:20]}\")\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    j = int(np.argmin(sep))\n",
    "    return df.iloc[j], float(sep[j])\n",
    "\n",
    "# PS1 overdensity with auto-detected RA/Dec cols\n",
    "def ps1_overdensity(ps1_df, ra0, dec0, ra_col=None, dec_col=None):\n",
    "    if ps1_df is None or len(ps1_df)==0:\n",
    "        return np.nan, np.nan, np.nan\n",
    "    if (ra_col is None) or (dec_col is None) or (ra_col not in ps1_df.columns) or (dec_col not in ps1_df.columns):\n",
    "        ra_col, dec_col = _find_radec_cols(ps1_df)\n",
    "        if ra_col is None or dec_col is None:\n",
    "            raise KeyError(f\"[PS1] Could not find RA/Dec columns. Got: {list(ps1_df.columns)[:20]}\")\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(ps1_df[ra_col].astype(float).values*u.deg, ps1_df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    n30  = int((sep <=  30).sum())\n",
    "    n120 = int((sep <= 120).sum())\n",
    "    n240 = int((sep <= 240).sum())\n",
    "    ann  = ((sep > 120) & (sep <= 240)).sum()\n",
    "    od   = (n120 / max(ann, 1)) if ann > 0 else np.nan\n",
    "    return n30, n120, od\n",
    "\n",
    "# PS1 extendedness (still uses PS1's gMeanPSFMag/gMeanKronMag etc if present)\n",
    "def ps1_extendedness(row_like):\n",
    "    row = dict(row_like) if not isinstance(row_like, dict) else row_like\n",
    "    deltas = []\n",
    "    for b in [\"g\",\"r\",\"i\"]:\n",
    "        psf  = row.get(f\"{b}MeanPSFMag\",  np.nan)\n",
    "        kron = row.get(f\"{b}MeanKronMag\", np.nan)\n",
    "        if pd.notna(psf) and pd.notna(kron):\n",
    "            deltas.append(float(psf) - float(kron))\n",
    "    if not deltas:\n",
    "        return np.nan, 0\n",
    "    ext_strength = float(np.nanmean(deltas))\n",
    "    ext_flag = int(any(d > 0.05 for d in deltas))  # loose threshold\n",
    "    return ext_strength, ext_flag\n",
    "\n",
    "print(\"HOTFIX loaded: RA/Dec auto-detection enabled for PS1/SDSS/GALEX. Re-run the multi-survey cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "07a592b6-e19c-4e71-819f-cd192656861f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[info] Checking 1 target(s) across other surveys…\n",
      "[save] cnt_anomaly\\out\\gold_multisurvey_summary.csv\n",
      "\n",
      "== Snapshot ==\n",
      "            AllWISE  WISE_W1-W2  WISE_W2-W3  PS1_extended_flag  PS1_ext_strength  PS1_N_30arcsec  PS1_overdensity_120to240  SDSS_class  SDSS_delta_r_psf_minus_cmodel  GALEX_NUV_mag SIMBAD_otype Structure_verdict\n",
      "J135656.78-011722.9       0.349       3.768                  0               NaN             NaN                       NaN         NaN                            NaN      20.835228                        unclear\n"
     ]
    }
   ],
   "source": [
    "# CNT Multi-Survey Structure Probe — PS1 / SDSS / GALEX / CatWISE\n",
    "# Telos × Aetheron\n",
    "\n",
    "import sys, subprocess, importlib, warnings, io, math\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        try:\n",
    "            importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception:\n",
    "            miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.mast import Catalogs\n",
    "from astroquery.sdss import SDSS\n",
    "from astroquery.simbad import Simbad\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- 0) Choose targets (confirmed gold; fallback to strict gold) ----------\n",
    "targets = []\n",
    "ms_file = OUT/\"gold_verification_idlocked_multiscale.csv\"\n",
    "if ms_file.exists():\n",
    "    ms = pd.read_csv(ms_file)\n",
    "    t = ms[(ms.get(\"pass_multiscale\")==True)]\n",
    "    for _, r in t.iterrows():\n",
    "        targets.append({\"AllWISE\": r[\"AllWISE\"]})\n",
    "if not targets:\n",
    "    # fallback: take strict gold file and use its AllWISE IDs (if present)\n",
    "    stricts = sorted(OUT.glob(\"strict_gold_candidates_*.csv\"))\n",
    "    if stricts:\n",
    "        g = pd.read_csv(stricts[-1])\n",
    "        if \"AllWISE\" in g.columns:\n",
    "            for _, r in g.iterrows():\n",
    "                targets.append({\"AllWISE\": str(r[\"AllWISE\"])})\n",
    "if not targets:\n",
    "    raise SystemExit(\"No gold candidates found. Run the fused pipeline and multiscale verify first.\")\n",
    "\n",
    "print(f\"[info] Checking {len(targets)} target(s) across other surveys…\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "Vizier.ROW_LIMIT = -1\n",
    "Simbad.add_votable_fields(\"otype\",\"otypes\",\"sp\")\n",
    "\n",
    "def fetch_allwise_exact(wise_id):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wise_id))\n",
    "    if len(q)==0 or len(q[0])==0:\n",
    "        return None\n",
    "    row = q[0].to_pandas().iloc[0]\n",
    "    return {\n",
    "        \"ra\": float(row[\"RAJ2000\"]),\n",
    "        \"dec\": float(row[\"DEJ2000\"]),\n",
    "        \"W1\": row.get(\"W1mag\", np.nan),\n",
    "        \"W2\": row.get(\"W2mag\", np.nan),\n",
    "        \"W3\": row.get(\"W3mag\", np.nan),\n",
    "        \"W4\": row.get(\"W4mag\", np.nan),\n",
    "        \"ph_qual\": row.get(\"ph_qual\", \"\"),\n",
    "        \"ext_flg\": row.get(\"ext_flg\", np.nan),\n",
    "        \"cc_flags\": row.get(\"cc_flags\", \"\")\n",
    "    }\n",
    "\n",
    "def nearest_row(df, ra_col=\"ra\", dec_col=\"dec\", ra0=None, dec0=None):\n",
    "    c0 = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    j = int(np.argmin(sep))\n",
    "    return df.iloc[j], float(sep[j])\n",
    "\n",
    "def ps1_query(ra, dec, rad_arcmin=8.0):\n",
    "    # MAST PanSTARRS catalog; returns PSF/Kron mags per band when available\n",
    "    try:\n",
    "        res = Catalogs.query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                    radius=rad_arcmin*u.arcmin, catalog=\"Panstarrs\")\n",
    "        return res.to_pandas() if res is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def sdss_query(ra, dec, rad_arcsec=5.0):\n",
    "    try:\n",
    "        res = SDSS.query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                radius=rad_arcsec*u.arcsec,\n",
    "                                photoobj_fields=['ra','dec','type','class',\n",
    "                                                 'psfMag_r','cModelMag_r','fracDeV_r',\n",
    "                                                 'psfMag_g','cModelMag_g','psfMag_i','cModelMag_i'])\n",
    "        return res.to_pandas() if res is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def galex_query(ra, dec, rad_arcmin=2.0):\n",
    "    try:\n",
    "        res = Catalogs.query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                    radius=rad_arcmin*u.arcmin, catalog=\"GALEX\")\n",
    "        return res.to_pandas() if res is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def catwise_query(ra, dec, rad_arcsec=5.0):\n",
    "    # CatWISE 2020 in VizieR (catalog name stable as II/365/catwise2020)\n",
    "    try:\n",
    "        res = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                                  radius=rad_arcsec*u.arcsec,\n",
    "                                                  catalog=\"II/365/catwise2020\")\n",
    "        return res[0].to_pandas() if len(res)>0 else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def ps1_extendedness(row):\n",
    "    # Use PSF − Kron (positive means extended; use g/r/i when present)\n",
    "    deltas = []\n",
    "    for b in [\"g\",\"r\",\"i\"]:\n",
    "        psf = row.get(f\"{b}MeanPSFMag\", np.nan)\n",
    "        kron= row.get(f\"{b}MeanKronMag\", np.nan)\n",
    "        if pd.notna(psf) and pd.notna(kron):\n",
    "            deltas.append(psf - kron)\n",
    "    if not deltas:\n",
    "        return np.nan, 0\n",
    "    deltas = [d for d in deltas if pd.notna(d)]\n",
    "    ext_strength = float(np.nanmean(deltas))\n",
    "    ext_flag = int(any(d>0.05 for d in deltas))  # loose threshold\n",
    "    return ext_strength, ext_flag\n",
    "\n",
    "def ps1_overdensity(ps1_df, ra0, dec0):\n",
    "    if ps1_df.empty: return np.nan, np.nan, np.nan\n",
    "    c0 = SkyCoord(ra0*u.deg, dec0*u.deg)\n",
    "    cs = SkyCoord(ps1_df[\"ra\"].astype(float).values*u.deg, ps1_df[\"dec\"].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    n30  = int((sep<=30).sum())\n",
    "    n120 = int((sep<=120).sum())\n",
    "    n240 = int((sep<=240).sum())\n",
    "    # crude overdensity ratio: inner / annulus (120–240)\n",
    "    ann = ((sep>120) & (sep<=240)).sum()\n",
    "    od = (n120 / max(ann,1)) if ann>0 else np.nan\n",
    "    return n30, n120, od\n",
    "\n",
    "rows=[]\n",
    "for tgt in targets:\n",
    "    wid = tgt[\"AllWISE\"]\n",
    "    aw = fetch_allwise_exact(wid)\n",
    "    if aw is None:\n",
    "        rows.append({\"AllWISE\": wid, \"status\": \"no_allwise_exact\"})\n",
    "        continue\n",
    "\n",
    "    ra, dec = aw[\"ra\"], aw[\"dec\"]\n",
    "    # ---- Pan-STARRS\n",
    "    ps1 = ps1_query(ra, dec, rad_arcmin=8.0)\n",
    "    if not ps1.empty:\n",
    "        # PS1 uses 'ra','dec' columns; pick nearest object for morphology\n",
    "        try:\n",
    "            nearest, sep_ps1 = nearest_row(ps1, \"ra\", \"dec\", ra, dec)\n",
    "        except Exception:\n",
    "            nearest, sep_ps1 = {}, np.nan\n",
    "        ext_strength, ext_flag = ps1_extendedness(nearest if isinstance(nearest, dict) else nearest.to_dict())\n",
    "        n30, n120, od = ps1_overdensity(ps1, ra, dec)\n",
    "    else:\n",
    "        sep_ps1=ext_strength=ext_flag=n30=n120=od=np.nan\n",
    "\n",
    "    # ---- SDSS\n",
    "    sdss = sdss_query(ra, dec, rad_arcsec=5.0)\n",
    "    if not sdss.empty:\n",
    "        srow, sep_sdss = nearest_row(sdss, \"ra\", \"dec\", ra, dec)\n",
    "        sdss_class = srow.get(\"class\", \"\")\n",
    "        sdss_type  = srow.get(\"type\", np.nan)\n",
    "        # optional r-band PSF vs cModel delta\n",
    "        try:\n",
    "            dr = (float(srow.get(\"psfMag_r\")) - float(srow.get(\"cModelMag_r\"))) if pd.notna(srow.get(\"psfMag_r\")) and pd.notna(srow.get(\"cModelMag_r\")) else np.nan\n",
    "        except Exception:\n",
    "            dr = np.nan\n",
    "    else:\n",
    "        sep_sdss=sdss_class=sdss_type=dr=np.nan\n",
    "\n",
    "    # ---- GALEX\n",
    "    gal = galex_query(ra, dec, rad_arcmin=2.0)\n",
    "    if not gal.empty:\n",
    "        grow, sep_galex = nearest_row(gal, \"ra\", \"dec\", ra, dec)\n",
    "        # GALEX magnitudes may be named 'nuv_mag','fuv_mag' or similar, handle both\n",
    "        nuv = grow.get(\"nuv_mag\", grow.get(\"NUV\", np.nan))\n",
    "        fuv = grow.get(\"fuv_mag\", grow.get(\"FUV\", np.nan))\n",
    "    else:\n",
    "        sep_galex=nuv=fuv=np.nan\n",
    "\n",
    "    # ---- CatWISE2020\n",
    "    cw = catwise_query(ra, dec, rad_arcsec=5.0)\n",
    "    if not cw.empty:\n",
    "        crow, sep_cw = nearest_row(cw, \"RAJ2000\", \"DEJ2000\", ra, dec)\n",
    "        cw_W1 = crow.get(\"W1mpro\", np.nan)\n",
    "        cw_W2 = crow.get(\"W2mpro\", np.nan)\n",
    "        cw_ph = crow.get(\"qph\", crow.get(\"ph_qual\", \"\"))\n",
    "    else:\n",
    "        sep_cw=cw_W1=cw_W2=cw_ph=np.nan\n",
    "\n",
    "    # ---- SIMBAD quick type (optional context)\n",
    "    try:\n",
    "        s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=5*u.arcsec)\n",
    "        simbad_type = s.to_pandas().iloc[0][\"OTYPE\"] if (s is not None and len(s)>0) else \"\"\n",
    "    except Exception:\n",
    "        simbad_type = \"\"\n",
    "\n",
    "    # verdicts\n",
    "    ps1_ext = (ext_flag==1)\n",
    "    sdss_gal = (str(sdss_class).upper()==\"GALAXY\") if isinstance(sdss_class, str) else (sdss_type==3)  # SDSS type 3 ~ GALAXY\n",
    "    uv_detect = pd.notna(nuv) or pd.notna(fuv)\n",
    "\n",
    "    rows.append({\n",
    "        \"AllWISE\": wid,\n",
    "        \"RA_deg\": ra, \"Dec_deg\": dec,\n",
    "        \"WISE_W1\": aw[\"W1\"], \"WISE_W2\": aw[\"W2\"], \"WISE_W3\": aw[\"W3\"], \"WISE_W4\": aw[\"W4\"],\n",
    "        \"WISE_W1-W2\": (aw[\"W1\"]-aw[\"W2\"]) if pd.notna(aw[\"W1\"]) and pd.notna(aw[\"W2\"]) else np.nan,\n",
    "        \"WISE_W2-W3\": (aw[\"W2\"]-aw[\"W3\"]) if pd.notna(aw[\"W2\"]) and pd.notna(aw[\"W3\"]) else np.nan,\n",
    "        \"PS1_sep_arcsec\": sep_ps1, \"PS1_ext_strength\": ext_strength, \"PS1_extended_flag\": int(ps1_ext),\n",
    "        \"PS1_N_30arcsec\": n30, \"PS1_N_2arcmin\": n120, \"PS1_overdensity_120to240\": od,\n",
    "        \"SDSS_sep_arcsec\": sep_sdss, \"SDSS_class\": sdss_class, \"SDSS_delta_r_psf_minus_cmodel\": dr,\n",
    "        \"GALEX_sep_arcsec\": sep_galex, \"GALEX_NUV_mag\": nuv, \"GALEX_FUV_mag\": fuv,\n",
    "        \"CatWISE_sep_arcsec\": sep_cw, \"CatWISE_W1mpro\": cw_W1, \"CatWISE_W2mpro\": cw_W2, \"CatWISE_ph\": cw_ph,\n",
    "        \"SIMBAD_otype\": simbad_type,\n",
    "        \"Structure_verdict\": \"extended/cluster-like\" if (ps1_ext or (od is not np.nan and od>1.2) or sdss_gal) else \"unclear\"\n",
    "    })\n",
    "\n",
    "summary = pd.DataFrame(rows)\n",
    "out_csv = OUT/\"gold_multisurvey_summary.csv\"\n",
    "summary.to_csv(out_csv, index=False)\n",
    "print(f\"[save] {out_csv}\")\n",
    "\n",
    "print(\"\\n== Snapshot ==\")\n",
    "cols = [\"AllWISE\",\"WISE_W1-W2\",\"WISE_W2-W3\",\n",
    "        \"PS1_extended_flag\",\"PS1_ext_strength\",\"PS1_N_30arcsec\",\"PS1_overdensity_120to240\",\n",
    "        \"SDSS_class\",\"SDSS_delta_r_psf_minus_cmodel\",\n",
    "        \"GALEX_NUV_mag\",\"SIMBAD_otype\",\"Structure_verdict\"]\n",
    "print(summary[ [c for c in cols if c in summary.columns] ].to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bd19da0b-dbf8-496f-99ff-d9932b4e777f",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[32m~\\AppData\\Local\\Temp\\ipykernel_31060\\2685107024.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m Exception:\n\u001b[32m    156\u001b[39m     ned = pd.DataFrame()\n\u001b[32m    157\u001b[39m nearby_groups = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28;01mnot\u001b[39;00m ned.empty:\n\u001b[32m--> \u001b[39m\u001b[32m159\u001b[39m     types = (ned.get(\u001b[33m\"Type\"\u001b[39m) \u001b[38;5;28;01mor\u001b[39;00m ned.get(\u001b[33m\"Object Type\"\u001b[39m) \u001b[38;5;28;01mor\u001b[39;00m pd.Series([])).astype(str).str.upper()\n\u001b[32m    160\u001b[39m     nearby_groups = types.str.contains(\u001b[33m\"GCLSTR|CLUSTER|GROUP\"\u001b[39m).any()\n\u001b[32m    161\u001b[39m \n\u001b[32m    162\u001b[39m \u001b[38;5;66;03m# -------- 8) Summarize --------\u001b[39;00m\n",
      "\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py\u001b[39m in \u001b[36m?\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1578\u001b[39m     @final\n\u001b[32m   1579\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m __nonzero__(self) -> NoReturn:\n\u001b[32m-> \u001b[39m\u001b[32m1580\u001b[39m         raise ValueError(\n\u001b[32m   1581\u001b[39m             f\"The truth value of a {type(self).__name__} is ambiguous. \"\n\u001b[32m   1582\u001b[39m             \u001b[33m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[39m\n\u001b[32m   1583\u001b[39m         )\n",
      "\u001b[31mValueError\u001b[39m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "# == CNT Multi-Survey Structure Probe v2 ==\n",
    "# Finds optical/IR structure around WISE J135656.78−011722.9 (or any AllWISE ID you slot in).\n",
    "import sys, subprocess, importlib, warnings, io\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def ensure(pkgs):\n",
    "    miss=[] \n",
    "    for p in pkgs:\n",
    "        try: importlib.import_module(p if p!=\"scikit-learn\" else \"sklearn\")\n",
    "        except Exception: miss.append(p)\n",
    "    if miss: subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.mast import Catalogs\n",
    "from astroquery.sdss import SDSS\n",
    "from astroquery.irsa import Irsa\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.ned import Ned\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# -------- CONFIG ----------\n",
    "WISE_ID = \"J135656.78-011722.9\"     # << your confirmed gold\n",
    "PS1_ARCMIN = 15.0                   # bigger cone to ensure hits\n",
    "SDSS_ARCSEC = 20.0\n",
    "GALEX_ARCMIN = 3.0\n",
    "CATWISE_ARCSEC = 8.0\n",
    "NED_ARCMIN = 10.0                   # look for groups/clusters in 10′\n",
    "\n",
    "# -------- helpers ----------\n",
    "Vizier.ROW_LIMIT = -1\n",
    "Irsa.ROW_LIMIT = 10000\n",
    "Simbad.add_votable_fields(\"otype\",\"otypes\",\"sp\")\n",
    "\n",
    "def _find_radec_cols(df):\n",
    "    ra_candidates  = [\"ra\",\"RA\",\"raMean\",\"raStack\",\"raStackMean\",\"RA_ICRS\",\"RAJ2000\",\"objra\"]\n",
    "    dec_candidates = [\"dec\",\"DEC\",\"decMean\",\"decStack\",\"decStackMean\",\"DE_ICRS\",\"DEJ2000\",\"objdec\"]\n",
    "    ra_col  = next((c for c in ra_candidates  if c in df.columns), None)\n",
    "    dec_col = next((c for c in dec_candidates if c in df.columns), None)\n",
    "    return ra_col, dec_col\n",
    "\n",
    "def nearest_row(df, ra0, dec0, ra_col=None, dec_col=None):\n",
    "    if df is None or len(df)==0: \n",
    "        return pd.Series(dtype=\"float64\"), np.nan\n",
    "    if (ra_col is None) or (ra_col not in df.columns) or (dec_col is None) or (dec_col not in df.columns):\n",
    "        ra_col, dec_col = _find_radec_cols(df)\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    j = int(np.argmin(sep))\n",
    "    return df.iloc[j], float(sep[j])\n",
    "\n",
    "def ps1_extendedness(row_like):\n",
    "    row = dict(row_like) if not isinstance(row_like, dict) else row_like\n",
    "    deltas=[]\n",
    "    for b in [\"g\",\"r\",\"i\"]:\n",
    "        psf  = row.get(f\"{b}MeanPSFMag\",  row.get(f\"{b}PSFMag\",  np.nan))\n",
    "        kron = row.get(f\"{b}MeanKronMag\", row.get(f\"{b}KronMag\", np.nan))\n",
    "        if pd.notna(psf) and pd.notna(kron): deltas.append(float(psf)-float(kron))\n",
    "    if not deltas: return np.nan, 0\n",
    "    ext_strength = float(np.nanmean(deltas))\n",
    "    ext_flag = int(any(d>0.05 for d in deltas))  # loose \"extended\" cue\n",
    "    return ext_strength, ext_flag\n",
    "\n",
    "def neighbor_counts(df, ra0, dec0, radii_arcsec):\n",
    "    if df is None or len(df)==0: return {r: np.nan for r in radii_arcsec}\n",
    "    ra_col, dec_col = _find_radec_cols(df)\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    return {r: int((sep<=r).sum()) for r in radii_arcsec}\n",
    "\n",
    "# -------- 1) Bind to exact AllWISE row to get RA/Dec --------\n",
    "aw = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=WISE_ID)\n",
    "assert len(aw)>0 and len(aw[0])>0, \"AllWISE ID not found.\"\n",
    "aw = aw[0].to_pandas().iloc[0]\n",
    "ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "\n",
    "# -------- 2) Pan-STARRS DR2 (MAST) — extendedness + overdensity --------\n",
    "try:\n",
    "    ps1 = Catalogs.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=PS1_ARCMIN*u.arcmin, catalog=\"Panstarrs\")\n",
    "    ps1 = ps1.to_pandas() if ps1 is not None else pd.DataFrame()\n",
    "except Exception:\n",
    "    ps1 = pd.DataFrame()\n",
    "\n",
    "if not ps1.empty:\n",
    "    nearest, ps1_sep = nearest_row(ps1, ra, dec)\n",
    "    ext_strength, ext_flag = ps1_extendedness(nearest)\n",
    "    nb = neighbor_counts(ps1, ra, dec, radii_arcsec=[30,60,120,240,480])  # 0.5′, 1′, 2′, 4′, 8′\n",
    "else:\n",
    "    ps1_sep=ext_strength=ext_flag=np.nan\n",
    "    nb = {30:np.nan, 60:np.nan, 120:np.nan, 240:np.nan, 480:np.nan}\n",
    "\n",
    "# -------- 3) 2MASS XSC (extended near-IR) via IRSA --------\n",
    "try:\n",
    "    Irsa.TIMEOUT = 60\n",
    "    xsc = Irsa.query_region(SkyCoord(ra*u.deg, dec*u.deg), catalog=\"fp_xsc\", radius=10*u.arcsec)\n",
    "    xsc = xsc.to_pandas() if xsc is not None else pd.DataFrame()\n",
    "except Exception:\n",
    "    xsc = pd.DataFrame()\n",
    "is_2mass_extended = (len(xsc)>0)\n",
    "\n",
    "# -------- 4) CatWISE 2020 (independent W1/W2) --------\n",
    "try:\n",
    "    cw = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=CATWISE_ARCSEC*u.arcsec, catalog=\"II/365/catwise2020\")\n",
    "    cw = cw[0].to_pandas() if len(cw)>0 else pd.DataFrame()\n",
    "except Exception:\n",
    "    cw = pd.DataFrame()\n",
    "if not cw.empty:\n",
    "    crow, cw_sep = nearest_row(cw, ra, dec, ra_col=\"RAJ2000\", dec_col=\"DEJ2000\")\n",
    "    cw_W1 = crow.get(\"W1mpro\", np.nan); cw_W2 = crow.get(\"W2mpro\", np.nan)\n",
    "else:\n",
    "    cw_sep=cw_W1=cw_W2=np.nan\n",
    "\n",
    "# -------- 5) SDSS (if footprint overlaps) --------\n",
    "try:\n",
    "    sdss = SDSS.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SDSS_ARCSEC*u.arcsec,\n",
    "                             photoobj_fields=['ra','dec','type','class','psfMag_r','cModelMag_r'])\n",
    "    sdss = sdss.to_pandas() if sdss is not None else pd.DataFrame()\n",
    "except Exception:\n",
    "    sdss = pd.DataFrame()\n",
    "if not sdss.empty:\n",
    "    srow, sdss_sep = nearest_row(sdss, ra, dec, ra_col=\"ra\", dec_col=\"dec\")\n",
    "    sdss_class = srow.get(\"class\",\"\")\n",
    "    try:\n",
    "        dr = (float(srow.get(\"psfMag_r\")) - float(srow.get(\"cModelMag_r\"))) if pd.notna(srow.get(\"psfMag_r\")) and pd.notna(srow.get(\"cModelMag_r\")) else np.nan\n",
    "    except Exception:\n",
    "        dr = np.nan\n",
    "else:\n",
    "    sdss_sep=sdss_class=dr=np.nan\n",
    "\n",
    "# -------- 6) GALEX (quick UV check) already done, but re-pull small cone --------\n",
    "try:\n",
    "    from astroquery.mast import Catalogs as MASTCat\n",
    "    gal = MASTCat.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=GALEX_ARCMIN*u.arcmin, catalog=\"GALEX\")\n",
    "    gal = gal.to_pandas() if gal is not None else pd.DataFrame()\n",
    "except Exception:\n",
    "    gal = pd.DataFrame()\n",
    "if not gal.empty:\n",
    "    grow, gal_sep = nearest_row(gal, ra, dec)\n",
    "    nuv = grow.get(\"nuv_mag\", grow.get(\"NUV\", np.nan))\n",
    "else:\n",
    "    gal_sep=nuv=np.nan\n",
    "\n",
    "# -------- 7) NED — look for groups/clusters within 10′ --------\n",
    "try:\n",
    "    ned = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=NED_ARCMIN*u.arcmin)\n",
    "    ned = ned.to_pandas() if ned is not None else pd.DataFrame()\n",
    "except Exception:\n",
    "    ned = pd.DataFrame()\n",
    "nearby_groups = False\n",
    "if not ned.empty:\n",
    "    types = (ned.get(\"Type\") or ned.get(\"Object Type\") or pd.Series([])).astype(str).str.upper()\n",
    "    nearby_groups = types.str.contains(\"GCLSTR|CLUSTER|GROUP\").any()\n",
    "\n",
    "# -------- 8) Summarize --------\n",
    "row = {\n",
    "    \"AllWISE\": WISE_ID,\n",
    "    \"RA_deg\": ra, \"Dec_deg\": dec,\n",
    "    \"WISE_W1-W2\": float(aw.get(\"W1mag\",np.nan)-aw.get(\"W2mag\",np.nan)) if pd.notna(aw.get(\"W1mag\",np.nan)) and pd.notna(aw.get(\"W2mag\",np.nan)) else np.nan,\n",
    "    \"WISE_W2-W3\": float(aw.get(\"W2mag\",np.nan)-aw.get(\"W3mag\",np.nan)) if pd.notna(aw.get(\"W2mag\",np.nan)) and pd.notna(aw.get(\"W3mag\",np.nan)) else np.nan,\n",
    "    \"PS1_nearest_sep_arcsec\": ps1_sep, \"PS1_ext_strength\": ext_strength, \"PS1_extended_flag\": int(ext_flag) if pd.notna(ext_flag) else np.nan,\n",
    "    \"PS1_N_30\\\":\": nb[30], \"PS1_N_60\\\"\": nb[60], \"PS1_N_120\\\"\": nb[120], \"PS1_N_240\\\"\": nb[240], \"PS1_N_480\\\"\": nb[480],\n",
    "    \"2MASS_XSC_hit\": bool(is_2mass_extended),\n",
    "    \"CatWISE_sep_arcsec\": cw_sep, \"CatWISE_W1mpro\": cw_W1, \"CatWISE_W2mpro\": cw_W2,\n",
    "    \"SDSS_sep_arcsec\": sdss_sep, \"SDSS_class\": sdss_class, \"SDSS_r_psf-cModel\": dr,\n",
    "    \"GALEX_sep_arcsec\": gal_sep, \"GALEX_NUV_mag\": nuv,\n",
    "    \"NED_groups_within_10'\": bool(nearby_groups)\n",
    "}\n",
    "df = pd.DataFrame([row])\n",
    "out = OUT/\"gold_multisurvey_summary_v2.csv\"\n",
    "df.to_csv(out, index=False)\n",
    "print(\"[save]\", out)\n",
    "print(df.T.to_string(header=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fed948fe-7897-42f9-9aec-ca7c7a83065d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tile 1/9] RA=209.200 Dec=-1.300\n",
      "[tile 2/9] RA=210.000 Dec=-1.300\n",
      "[tile 3/9] RA=210.800 Dec=-1.300\n",
      "[tile 4/9] RA=209.200 Dec=-0.500\n",
      "[tile 5/9] RA=210.000 Dec=-0.500\n",
      "[tile 6/9] RA=210.800 Dec=-0.500\n",
      "[tile 7/9] RA=209.200 Dec=0.300\n",
      "[tile 8/9] RA=210.000 Dec=0.300\n",
      "[tile 9/9] RA=210.800 Dec=0.300\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-005239.csv (N=12)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-005239.csv (N=12)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-005239.csv (N=11)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-005239.csv (N=11)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-005239.csv (N=3)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-005239.csv\n",
      "[confirm] multiscale golds: 3 → ['J135609.55-020432.7', 'J135656.78-011722.9', 'J140455.17-002205.4']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 688\u001b[39m\n\u001b[32m    685\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTiles: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(tiles)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Master: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(master)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Gold: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(gold)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | Confirmed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(confirmed)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    687\u001b[39m \u001b[38;5;66;03m# GO\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m688\u001b[39m \u001b[43mrun_all\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 612\u001b[39m, in \u001b[36mrun_all\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    610\u001b[39m ms_rows=[]\n\u001b[32m    611\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m wid \u001b[38;5;129;01min\u001b[39;00m confirmed:\n\u001b[32m--> \u001b[39m\u001b[32m612\u001b[39m     row = \u001b[43mmultisurvey_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    613\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m row: ms_rows.append(row)\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ms_rows:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 446\u001b[39m, in \u001b[36mmultisurvey_probe\u001b[39m\u001b[34m(allwise_id, stamp)\u001b[39m\n\u001b[32m    444\u001b[39m \u001b[38;5;66;03m# PS1 (15')\u001b[39;00m\n\u001b[32m    445\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m446\u001b[39m     ps1 = \u001b[43mMASTCat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_region\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSkyCoord\u001b[49m\u001b[43m(\u001b[49m\u001b[43mra\u001b[49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m15\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43marcmin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mPanstarrs\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    447\u001b[39m     ps1 = ps1.to_pandas() \u001b[38;5;28;01mif\u001b[39;00m ps1 \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\class_or_instance.py:25\u001b[39m, in \u001b[36mclass_or_instance.__get__.<locals>.f\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(*args, **kwds):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fn(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\process_asyncs.py:28\u001b[39m, in \u001b[36masync_to_sync.<locals>.create_method.<locals>.newmethod\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;129m@class_or_instance\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnewmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     26\u001b[39m     verbose = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     response = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masync_method_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mget_query_payload\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mfield_help\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\class_or_instance.py:25\u001b[39m, in \u001b[36mclass_or_instance.__get__.<locals>.f\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(*args, **kwds):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fn(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\mast\\collections.py:292\u001b[39m, in \u001b[36mCatalogsClass.query_region_async\u001b[39m\u001b[34m(self, coordinates, radius, catalog, version, pagesize, page, **criteria)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;66;03m# Parameters will be passed as JSON objects only when accessing the PANSTARRS API\u001b[39;00m\n\u001b[32m    290\u001b[39m use_json = catalog.lower() == \u001b[33m'\u001b[39m\u001b[33mpanstarrs\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_current_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mservice_request_async\u001b[49m\u001b[43m(\u001b[49m\u001b[43mservice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpagesize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpagesize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpage\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m                                                      \u001b[49m\u001b[43muse_json\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_json\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\class_or_instance.py:25\u001b[39m, in \u001b[36mclass_or_instance.__get__.<locals>.f\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(*args, **kwds):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fn(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astropy\\utils\\decorators.py:620\u001b[39m, in \u001b[36mdeprecated_renamed_argument.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    617\u001b[39m             msg += \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m        Use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00malternative\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    618\u001b[39m         warnings.warn(msg, warning_type, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\mast\\services.py:335\u001b[39m, in \u001b[36mServiceAPI.service_request_async\u001b[39m\u001b[34m(self, service, params, pagesize, page, use_json, **kwargs)\u001b[39m\n\u001b[32m    331\u001b[39m     \u001b[38;5;66;03m# Otherwise, catalogs_request can remain as the original params dict\u001b[39;00m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    333\u001b[39m         catalogs_request = params\n\u001b[32m--> \u001b[39m\u001b[32m335\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequest_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcatalogs_request\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_json\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_json\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\mast\\services.py:198\u001b[39m, in \u001b[36mServiceAPI._request\u001b[39m\u001b[34m(self, method, url, params, data, headers, files, stream, auth, cache, use_json)\u001b[39m\n\u001b[32m    195\u001b[39m start_time = time.time()\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m use_json:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    201\u001b[39m     response = \u001b[38;5;28msuper\u001b[39m()._request(method, url, params=params, data=data, headers=headers,\n\u001b[32m    202\u001b[39m                                 files=files, cache=cache, stream=stream, auth=auth)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\query.py:372\u001b[39m, in \u001b[36mBaseQuery._request\u001b[39m\u001b[34m(self, method, url, params, data, headers, files, save, savedir, timeout, cache, stream, auth, continuation, verify, allow_redirects, json, return_response_on_save)\u001b[39m\n\u001b[32m    370\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache:\n\u001b[32m    371\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m cache_conf.set_temp(\u001b[33m\"\u001b[39m\u001b[33mcache_active\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m372\u001b[39m         response = \u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    377\u001b[39m     response = query.from_cache(\u001b[38;5;28mself\u001b[39m.cache_location, cache_conf.cache_timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\query.py:77\u001b[39m, in \u001b[36mAstroQuery.request\u001b[39m\u001b[34m(self, session, cache_location, stream, auth, verify, allow_redirects, json)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, session, cache_location=\u001b[38;5;28;01mNone\u001b[39;00m, stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     75\u001b[39m             auth=\u001b[38;5;28;01mNone\u001b[39;00m, verify=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_redirects=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     76\u001b[39m             json=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:710\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    707\u001b[39m r.elapsed = timedelta(seconds=elapsed)\n\u001b[32m    709\u001b[39m \u001b[38;5;66;03m# Response manipulation hooks\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m710\u001b[39m r = \u001b[43mdispatch_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mresponse\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhooks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    712\u001b[39m \u001b[38;5;66;03m# Persist cookies\u001b[39;00m\n\u001b[32m    713\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.history:\n\u001b[32m    714\u001b[39m     \u001b[38;5;66;03m# If the hooks create history then we want those cookies too\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\hooks.py:30\u001b[39m, in \u001b[36mdispatch_hook\u001b[39m\u001b[34m(key, hooks, hook_data, **kwargs)\u001b[39m\n\u001b[32m     28\u001b[39m     hooks = [hooks]\n\u001b[32m     29\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m hooks:\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     _hook_data = \u001b[43mhook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhook_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _hook_data \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     32\u001b[39m         hook_data = _hook_data\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\query.py:261\u001b[39m, in \u001b[36mBaseQuery._response_hook\u001b[39m\u001b[34m(self, response, *args, **kwargs)\u001b[39m\n\u001b[32m    249\u001b[39m     response_log = textwrap.indent(\n\u001b[32m    250\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-----------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    251\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    252\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_hdrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    253\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mStreaming Data\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    254\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-----------------------------------------\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    255\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    256\u001b[39m     response_log = textwrap.indent(\n\u001b[32m    257\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-----------------------------------------\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    258\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.reason\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse.url\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    259\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse_hdrs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    260\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    262\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m-----------------------------------------\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m    263\u001b[39m log.log(\u001b[32m5\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mHTTP response\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\models.py:926\u001b[39m, in \u001b[36mResponse.text\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    923\u001b[39m content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    924\u001b[39m encoding = \u001b[38;5;28mself\u001b[39m.encoding\n\u001b[32m--> \u001b[39m\u001b[32m926\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcontent\u001b[49m:\n\u001b[32m    927\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;66;03m# Fallback to auto-detected encoding.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\models.py:902\u001b[39m, in \u001b[36mResponse.content\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    900\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m902\u001b[39m         \u001b[38;5;28mself\u001b[39m._content = \u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    904\u001b[39m \u001b[38;5;28mself\u001b[39m._content_consumed = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    905\u001b[39m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[32m    906\u001b[39m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    818\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m.raw, \u001b[33m\"\u001b[39m\u001b[33mstream\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    819\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    822\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\response.py:1088\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1072\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1073\u001b[39m \u001b[33;03mA generator wrapper for the read() method. A call will block until\u001b[39;00m\n\u001b[32m   1074\u001b[39m \u001b[33;03m``amt`` bytes have been read from the connection or until the\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1085\u001b[39m \u001b[33;03m    'content-encoding' header.\u001b[39;00m\n\u001b[32m   1086\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1087\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunked \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m.supports_chunked_reads():\n\u001b[32m-> \u001b[39m\u001b[32m1088\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.read_chunked(amt, decode_content=decode_content)\n\u001b[32m   1089\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1090\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\response.py:1248\u001b[39m, in \u001b[36mHTTPResponse.read_chunked\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1245\u001b[39m     amt = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1247\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1248\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_update_chunk_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1249\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left == \u001b[32m0\u001b[39m:\n\u001b[32m   1250\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\response.py:1167\u001b[39m, in \u001b[36mHTTPResponse._update_chunk_length\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.chunk_left \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1167\u001b[39m line = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[32m   1168\u001b[39m line = line.split(\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m;\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m1\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m   1169\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    717\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot read from timed out object\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[32m    721\u001b[39m     \u001b[38;5;28mself\u001b[39m._timeout_occurred = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1300\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m flags != \u001b[32m0\u001b[39m:\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1306\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m().recv_into(buffer, nbytes, flags)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1136\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m   1137\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1140\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sslobj.read(\u001b[38;5;28mlen\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Fused v3 (discovery→gold→ID-locked multiscale→multisurvey→bundle)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, sys, time, json, math, warnings, subprocess, importlib, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ========== CONFIG ==========\n",
    "CFG = dict(\n",
    "    CENTER_RA = 210.0,             # deg\n",
    "    CENTER_DEC = -0.5,             # deg\n",
    "    RADIUS_DEG = 0.8,              # per-tile search radius\n",
    "    GRID_SIZE = 3,                 # 1=single tile; 3=3×3 grid\n",
    "    GRID_STEP_DEG = 0.8,           # spacing between tile centers\n",
    "    N_MAX = 3000,                  # Gaia rows cap per tile\n",
    "    XMM_RADIUS_ARCSEC = 1.0,       # Gaia↔AllWISE crossmatch radius\n",
    "    WISE_XMATCH_ARCSEC = 5.0,      # bind Gaia coord to AllWISE ID\n",
    "    CONE_ENV_ARCMIN = 8.0,         # env cone for ID-locked votes\n",
    "    NEAR_ARCSEC = 5.0,             # accept exact row within this distance\n",
    "    K_DISC = 3,                    # discovery votes (stable anomaly)\n",
    "    K_GOLD = 4,                    # gold votes\n",
    "    GOLD_W23_MIN = 1.0,            # color gate for gold (W2−W3)\n",
    "    STRICT_W1W2_QUAL = \"AB\",       # ph_qual allowed for strict\n",
    "    STRICT_SNR_MIN = 5.0,\n",
    "    RELAX_SNR_MIN = 3.0,\n",
    "    ALLOW_C_IF_SNR = 8.0,          # let 'C' through if SNR≥this\n",
    "    CC_EXCLUDE = \"DHOP\",           # reject if cc_flags has any of D/H/O/P\n",
    "    GALAXY_MODE = False,           # if True, prefer extended morphologies\n",
    "    OUTDIR = \"./cnt_anomaly/out\",\n",
    "    CACHEDIR = \"./cnt_anomaly/cache\",\n",
    "    SEED = 42\n",
    ")\n",
    "\n",
    "# ========== ENV ==========\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        mod = p if p!=\"scikit-learn\" else \"sklearn\"\n",
    "        try: importlib.import_module(mod)\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.skyview import SkyView\n",
    "from astroquery.simbad import Simbad\n",
    "from astroquery.mast import Catalogs as MASTCat\n",
    "from astroquery.sdss import SDSS\n",
    "from astroquery.irsa import Irsa\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler, QuantileTransformer\n",
    "\n",
    "np.random.seed(CFG[\"SEED\"])\n",
    "OUT = Path(CFG[\"OUTDIR\"]); OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(CFG[\"CACHEDIR\"]); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "CUT = OUT/\"cutouts\"; CUT.mkdir(parents=True, exist_ok=True)\n",
    "WEB = OUT/\"web\"; WEB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts(): return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "def sanitize_id(s): return str(s).strip()\n",
    "\n",
    "# ========== CORE HELPERS ==========\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=None):\n",
    "    Vizier.ROW_LIMIT = row_limit or CFG[\"N_MAX\"]\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def clean_photometry(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    return d.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"] = d[a] - d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(col in d for col in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "# robust numeric views (floatify first)\n",
    "def wise_views_numeric(df):\n",
    "    num = df.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns:\n",
    "        num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0 = num.fillna(med)\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\",\"MG\",\"pm_norm\",\"G\",\"BP_RP\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\") or c in [\"BP_RP\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        X4 += np.random.default_rng(CFG[\"SEED\"]).normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return views\n",
    "\n",
    "def votes_from_views(views, n_estimators=300, contam=0.01):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(CFG[\"SEED\"])\n",
    "    flags = {}\n",
    "    for name, X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1 = (iso.predict(X)==-1)\n",
    "        try:\n",
    "            nn = min(35, max(10, len(X)//10)) if len(X)>20 else max(5, len(X)-1)\n",
    "            lof = LocalOutlierFactor(n_neighbors=nn, contamination=contam)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = (f1 | f2)\n",
    "    if not flags: return None\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "def triage_class_hint(w12, w23):\n",
    "    if pd.notna(w12) and pd.notna(w23):\n",
    "        if (w12 >= 0.8) and (w23 >= 1.6): return \"AGN/galaxy-like\"\n",
    "        if (w12 >= 0.3) and (w23 >= 1.0): return \"YSO/dusty-star-like\"\n",
    "    return \"ambiguous\"\n",
    "\n",
    "def wise_good_phqual(s, good=\"AB\", allow_c_if_snr=None, w1snr=0, w2snr=0):\n",
    "    s = str(s) if isinstance(s,str) else \"\"\n",
    "    w1 = s[0] if len(s)>0 else \"\"; w2 = s[1] if len(s)>1 else \"\"\n",
    "    ok = (w1 in good) and (w2 in good)\n",
    "    if (not ok) and allow_c_if_snr is not None:\n",
    "        if (w1 in \"ABC\") and (w2 in \"ABC\") and (w1snr>=allow_c_if_snr) and (w2snr>=allow_c_if_snr):\n",
    "            ok = True\n",
    "    return ok\n",
    "\n",
    "def cc_clean(flags, exclude=\"DHOP\"):\n",
    "    s = str(flags) if isinstance(flags, str) else \"\"\n",
    "    return not any(ch in s for ch in exclude)\n",
    "\n",
    "# NED group flag (robust)\n",
    "def ned_group_flag(ned_df) -> bool:\n",
    "    if ned_df is None or ned_df.empty:\n",
    "        return False\n",
    "    candidates = [\"Type\", \"Object Type\", \"Object Type Name\", \"ObjType\", \"Obj Type\"]\n",
    "    col = next((c for c in candidates if c in ned_df.columns), None)\n",
    "    if col is None:\n",
    "        return False\n",
    "    types = ned_df[col].astype(str).str.upper()\n",
    "    pattern = r\"(GCLSTR|CLUSTER|GROUP|GRP|CLUST)\"\n",
    "    return types.str.contains(pattern, regex=True, na=False).any()\n",
    "\n",
    "# RA/Dec auto-detect (for PS1/SDSS/GALEX tables)\n",
    "def _find_radec_cols(df):\n",
    "    ra_candidates  = [\"ra\",\"RA\",\"raMean\",\"raStack\",\"raStackMean\",\"objra\",\"RAJ2000\",\"RA_ICRS\",\"posRA\"]\n",
    "    dec_candidates = [\"dec\",\"DEC\",\"decMean\",\"decStack\",\"decStackMean\",\"objdec\",\"DEJ2000\",\"DE_ICRS\",\"posDec\"]\n",
    "    ra_col  = next((c for c in ra_candidates  if c in df.columns), None)\n",
    "    dec_col = next((c for c in dec_candidates if c in df.columns), None)\n",
    "    return ra_col, dec_col\n",
    "\n",
    "def nearest_row(df, ra0, dec0, ra_col=None, dec_col=None):\n",
    "    if df is None or len(df)==0: return pd.Series(dtype=\"float64\"), np.nan\n",
    "    if (ra_col is None) or (ra_col not in df.columns) or (dec_col is None) or (dec_col not in df.columns):\n",
    "        ra_col, dec_col = _find_radec_cols(df)\n",
    "        if ra_col is None or dec_col is None:\n",
    "            raise KeyError(f\"Could not find RA/Dec columns in: {list(df.columns)[:20]}\")\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    j = int(np.argmin(sep))\n",
    "    return df.iloc[j], float(sep[j])\n",
    "\n",
    "def ps1_extendedness(row_like):\n",
    "    row = dict(row_like) if not isinstance(row_like, dict) else row_like\n",
    "    deltas=[]\n",
    "    for b in [\"g\",\"r\",\"i\"]:\n",
    "        psf  = row.get(f\"{b}MeanPSFMag\",  row.get(f\"{b}PSFMag\",  np.nan))\n",
    "        kron = row.get(f\"{b}MeanKronMag\", row.get(f\"{b}KronMag\", np.nan))\n",
    "        if pd.notna(psf) and pd.notna(kron): deltas.append(float(psf)-float(kron))\n",
    "    if not deltas: return np.nan, 0\n",
    "    ext_strength = float(np.nanmean(deltas))\n",
    "    ext_flag = int(any(d>0.05 for d in deltas))\n",
    "    return ext_strength, ext_flag\n",
    "\n",
    "def neighbor_counts(df, ra0, dec0, radii_arcsec):\n",
    "    if df is None or len(df)==0: return {r: np.nan for r in radii_arcsec}\n",
    "    ra_col, dec_col = _find_radec_cols(df)\n",
    "    c0 = SkyCoord(float(ra0)*u.deg, float(dec0)*u.deg)\n",
    "    cs = SkyCoord(df[ra_col].astype(float).values*u.deg, df[dec_col].astype(float).values*u.deg)\n",
    "    sep = cs.separation(c0).arcsec\n",
    "    return {r: int((sep<=r).sum()) for r in radii_arcsec}\n",
    "\n",
    "# ========== DISCOVERY SWEEP ==========\n",
    "def discovery_sweep():\n",
    "    stamp = ts()\n",
    "    offsets = np.linspace(-CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_SIZE\"])\n",
    "    tiles = [(CFG[\"CENTER_RA\"]+dx, CFG[\"CENTER_DEC\"]+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    st_all=[]\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "        if gaia_cache.exists(): gaia = pd.read_csv(gaia_cache)\n",
    "        else:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, CFG[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=CFG[\"N_MAX\"])\n",
    "            gaia.to_csv(gaia_cache, index=False)\n",
    "        if wise_cache.exists(): gw = pd.read_csv(wise_cache)\n",
    "        else:\n",
    "            gw = xmatch_gaia_allwise(gaia, CFG[\"XMM_RADIUS_ARCSEC\"])\n",
    "            gw.to_csv(wise_cache, index=False)\n",
    "        if gw.empty: \n",
    "            print(\"  [skip] no xmatches\"); continue\n",
    "        df = add_derived_features(clean_photometry(gw))\n",
    "        views = wise_views_numeric(df)\n",
    "        votes = votes_from_views(views)\n",
    "        if votes is None: \n",
    "            print(\"  [skip] no views\"); continue\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= CFG[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            st_all.append(st)\n",
    "\n",
    "    master = pd.concat(st_all, ignore_index=True) if st_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"; master.to_csv(master_path, index=False)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "    return stamp, master, tiles, master_path\n",
    "\n",
    "# ========== ENRICH & GOLD ==========\n",
    "def enrich_allwise(master, stamp):\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    enr_rows=[]\n",
    "    for _, r in master.iterrows():\n",
    "        ra0 = float(r.get(\"ra_deg\", r.get(\"RA_ICRS\", np.nan)))\n",
    "        dec0= float(r.get(\"dec\", r.get(\"DE_ICRS\", np.nan)))\n",
    "        if not (pd.notna(ra0) and pd.notna(dec0)): continue\n",
    "        t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "        buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "        try:\n",
    "            xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                              max_distance=CFG[\"WISE_XMATCH_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "            xdf = xm.to_pandas()\n",
    "        except Exception:\n",
    "            xdf = pd.DataFrame()\n",
    "        if xdf.empty:\n",
    "            row = r.to_dict(); row.update({\"AllWISE\":\"\",\"bind_sep_arcsec\":np.nan})\n",
    "            enr_rows.append(row); continue\n",
    "        xdf = xdf.sort_values(\"angDist\").reset_index(drop=True)\n",
    "        wid = sanitize_id(xdf.loc[0,\"AllWISE\"]); bind_sep = float(xdf.loc[0,\"angDist\"])*3600.0\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            row = r.to_dict(); row.update({\"AllWISE\":wid,\"bind_sep_arcsec\":bind_sep})\n",
    "            enr_rows.append(row); continue\n",
    "        aw = q[0].to_pandas().iloc[0]\n",
    "        def est_snr(emag): \n",
    "            try: return float(1.0857/float(emag)) if (emag and float(emag)>0) else np.nan\n",
    "            except: return np.nan\n",
    "        w1snr = aw.get(\"w1snr\", np.nan) if not pd.isna(aw.get(\"w1snr\", np.nan)) else est_snr(aw.get(\"e_W1mag\", np.nan))\n",
    "        w2snr = aw.get(\"w2snr\", np.nan) if not pd.isna(aw.get(\"w2snr\", np.nan)) else est_snr(aw.get(\"e_W2mag\", np.nan))\n",
    "        row = r.to_dict()\n",
    "        row.update({\n",
    "            \"AllWISE\": wid, \"bind_sep_arcsec\": bind_sep,\n",
    "            \"RAJ2000\": aw.get(\"RAJ2000\",np.nan), \"DEJ2000\": aw.get(\"DEJ2000\",np.nan),\n",
    "            \"ph_qual\": aw.get(\"ph_qual\",np.nan), \"ext_flg\": aw.get(\"ext_flg\",np.nan),\n",
    "            \"cc_flags\": aw.get(\"cc_flags\",np.nan),\n",
    "            \"w1snr\": w1snr, \"w2snr\": w2snr, \"w3snr\": aw.get(\"w3snr\",np.nan), \"w4snr\": aw.get(\"w4snr\",np.nan),\n",
    "            \"W1\": aw.get(\"W1mag\",np.nan), \"W2\": aw.get(\"W2mag\",np.nan),\n",
    "            \"W3\": aw.get(\"W3mag\",np.nan), \"W4\": aw.get(\"W4mag\",np.nan)\n",
    "        })\n",
    "        enr_rows.append(row)\n",
    "    enr = pd.DataFrame(enr_rows)\n",
    "    if \"AllWISE\" in enr.columns:\n",
    "        enr = enr.sort_values([\"AllWISE\",\"_votes\"], ascending=[True,False]).drop_duplicates(subset=[\"AllWISE\"])\n",
    "    enr_path = OUT/f\"stable_enriched_all_{stamp}.csv\"; enr.to_csv(enr_path, index=False)\n",
    "    print(f\"[save] enriched (all): {enr_path} (N={len(enr)})\")\n",
    "\n",
    "    # reasons + gates\n",
    "    def pass_strict(r):\n",
    "        pq = r.get(\"ph_qual\",\"\"); w1s, w2s = float(r.get(\"w1snr\",0) or 0), float(r.get(\"w2snr\",0) or 0)\n",
    "        return (wise_good_phqual(pq, CFG[\"STRICT_W1W2_QUAL\"], CFG[\"ALLOW_C_IF_SNR\"], w1s, w2s)\n",
    "                and (w1s>=CFG[\"STRICT_SNR_MIN\"]) and (w2s>=CFG[\"STRICT_SNR_MIN\"])\n",
    "                and cc_clean(r.get(\"cc_flags\",\"\"), CFG[\"CC_EXCLUDE\"]))\n",
    "    def pass_relaxed(r):\n",
    "        w1s, w2s = float(r.get(\"w1snr\",0) or 0), float(r.get(\"w2snr\",0) or 0)\n",
    "        return (w1s>=CFG[\"RELAX_SNR_MIN\"]) and (w2s>=CFG[\"RELAX_SNR_MIN\"]) and cc_clean(r.get(\"cc_flags\",\"\"), CFG[\"CC_EXCLUDE\"])\n",
    "\n",
    "    strict = enr[[pass_strict(r) for _,r in enr.iterrows()]].copy()\n",
    "    relaxed= enr[[pass_relaxed(r)for _,r in enr.iterrows()]].copy()\n",
    "    strict_path = OUT/f\"stable_enriched_strict_{stamp}.csv\"; strict.to_csv(strict_path, index=False)\n",
    "    relaxed_path= OUT/f\"stable_enriched_relaxed_{stamp}.csv\"; relaxed.to_csv(relaxed_path, index=False)\n",
    "    print(f\"[save] strict shortlist:  {strict_path} (N={len(strict)})\")\n",
    "    print(f\"[save] relaxed shortlist: {relaxed_path} (N={len(relaxed)})\")\n",
    "\n",
    "    base = strict if len(strict)>0 else (relaxed if len(relaxed)>0 else enr.copy())\n",
    "    base[\"W1-W2\"] = base.get(\"W1\",np.nan) - base.get(\"W2\",np.nan)\n",
    "    base[\"W2-W3\"] = base.get(\"W2\",np.nan) - base.get(\"W3\",np.nan)\n",
    "    base[\"class_hint\"] = [triage_class_hint(w12,w23) for w12,w23 in zip(base[\"W1-W2\"], base[\"W2-W3\"])]\n",
    "\n",
    "    # GOLD\n",
    "    base[\"_votes\"] = base[\"_votes\"].fillna(0)\n",
    "    gold_mask = (base[\"_votes\"]>=CFG[\"K_GOLD\"]) & (base[\"W2-W3\"].fillna(-99)>=CFG[\"GOLD_W23_MIN\"])\n",
    "    if CFG[\"GALAXY_MODE\"]:\n",
    "        gold_mask &= ((base.get(\"ext_flg\",\"\").astype(str)!=\"0\") | (base[\"W1-W2\"].fillna(0)>=0.5))\n",
    "    gold = base[gold_mask].copy().reset_index(drop=True)\n",
    "    gold_path = OUT/f\"strict_gold_candidates_{stamp}.csv\"; gold.to_csv(gold_path, index=False)\n",
    "    print(f\"[save] GOLD set → {gold_path} (N={len(gold)})\")\n",
    "    return enr, base, gold, strict_path, relaxed_path, gold_path\n",
    "\n",
    "# ========== ID-LOCKED MULTISCALE VERIFY ==========\n",
    "def multiscale_verify(gold, stamp):\n",
    "    SCALES = [2.0, 4.0, 8.0]   # arcmin\n",
    "    out_rows=[]\n",
    "    for _, g in gold.iterrows():\n",
    "        wid = str(g.get(\"AllWISE\",\"\")).strip()\n",
    "        if not wid: \n",
    "            out_rows.append({\"AllWISE\":\"\",\"status\":\"no-id\"}); continue\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            out_rows.append({\"AllWISE\":wid,\"status\":\"id-not-found\"}); continue\n",
    "        ex = q[0].to_pandas().iloc[0]\n",
    "        ra, dec = float(ex[\"RAJ2000\"]), float(ex[\"DEJ2000\"])\n",
    "        bestK=-1; bestScale=None; bestSep=None\n",
    "        for arcmin in SCALES:\n",
    "            env = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                                      radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "            env = env[0].to_pandas() if len(env)>0 and len(env[0])>0 else pd.DataFrame()\n",
    "            if env.empty: continue\n",
    "            env[\"AllWISE\"] = env.get(\"AllWISE\",\"\").astype(str)\n",
    "            if wid not in set(env[\"AllWISE\"]): env = pd.concat([env, ex.to_frame().T], ignore_index=True)\n",
    "            d = env.copy()\n",
    "            # canonical feature views\n",
    "            ren={\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                 \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "                 \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"}\n",
    "            for k,v in ren.items():\n",
    "                if k in d.columns: d[v]=d[k]\n",
    "            for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "                if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "            if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "            num = d.select_dtypes(include=[np.number]).copy()\n",
    "            for c in num.columns: num[c]=pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "            if \"dist_pc\" in num: num=num.drop(columns=[\"dist_pc\"])\n",
    "            med=num.median(numeric_only=True); X0=num.fillna(med)\n",
    "            views={}\n",
    "            cols1=[c for c in X0.columns if c.startswith((\"W\",\"SED_slope\")) and not c.startswith(\"eW\")]\n",
    "            cols2=[c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\")]\n",
    "            cols3=[c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\"]]\n",
    "            if cols1: views[\"V1\"]=RobustScaler().fit_transform(X0[cols1])\n",
    "            if cols2: views[\"V2\"]=StandardScaler().fit_transform(X0[cols2])\n",
    "            if cols3:\n",
    "                X3=X0[cols3].copy(); X3=X3 - X3.min().min() + 1e-3; X3=np.log1p(X3)\n",
    "                views[\"V3\"]=X3[sorted(X3.columns, reverse=True)].values\n",
    "            if cols1 and cols2:\n",
    "                X5a=RobustScaler().fit_transform(X0[cols1]); X5b=StandardScaler().fit_transform(X0[cols2])\n",
    "                views[\"V5\"]=np.concatenate([X5a,X5b],axis=1)\n",
    "            K = votes_from_views(views, contam=0.01)\n",
    "            if K is None: continue\n",
    "            d[\"_votes\"]=K\n",
    "            if \"AllWISE\" in d.columns:\n",
    "                idxs=d.index[d[\"AllWISE\"].astype(str)==wid]\n",
    "                j=int(idxs[0]) if len(idxs)>0 else None\n",
    "            else:\n",
    "                j=None\n",
    "            if j is None:\n",
    "                coords=SkyCoord(d[\"RAJ2000\"].astype(float).values*u.deg, d[\"DEJ2000\"].astype(float).values*u.deg)\n",
    "                sep=coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec\n",
    "                j=int(np.argmin(sep)); sepj=float(sep[j])\n",
    "            else:\n",
    "                sepj=0.0\n",
    "            Kj=int(d.iloc[j][\"_votes\"])\n",
    "            if Kj>bestK:\n",
    "                bestK=Kj; bestScale=arcmin; bestSep=sepj\n",
    "        W1=ex.get(\"W1mag\",np.nan); W2=ex.get(\"W2mag\",np.nan); W3=ex.get(\"W3mag\",np.nan)\n",
    "        w12=(W1-W2) if pd.notna(W1) and pd.notna(W2) else np.nan\n",
    "        w23=(W2-W3) if pd.notna(W2) and pd.notna(W3) else np.nan\n",
    "        out_rows.append({\n",
    "            \"AllWISE\": wid, \"best_votes\": bestK, \"best_scale_arcmin\": bestScale, \"sep_to_exact_arcsec\": bestSep,\n",
    "            \"pass_multiscale\": bool(bestK>=CFG[\"K_GOLD\"]) if bestK>=0 else False,\n",
    "            \"W1-W2\": w12, \"W2-W3\": w23, \"status\": \"ok\" if bestK>=0 else \"no-env\"\n",
    "        })\n",
    "    ver = pd.DataFrame(out_rows)\n",
    "    ver_path = OUT/f\"gold_verification_idlocked_multiscale_{stamp}.csv\"; ver.to_csv(ver_path, index=False)\n",
    "    print(f\"[save] multiscale verify → {ver_path}\")\n",
    "    return ver, ver_path\n",
    "\n",
    "# ========== MULTI-SURVEY STRUCTURE PROBE ==========\n",
    "def multisurvey_probe(allwise_id, stamp):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=allwise_id)\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    aw = q[0].to_pandas().iloc[0]; ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "    # PS1 (15')\n",
    "    try:\n",
    "        ps1 = MASTCat.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=15*u.arcmin, catalog=\"Panstarrs\")\n",
    "        ps1 = ps1.to_pandas() if ps1 is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        ps1 = pd.DataFrame()\n",
    "    if not ps1.empty:\n",
    "        nearest, ps1_sep = nearest_row(ps1, ra, dec)\n",
    "        ext_strength, ext_flag = ps1_extendedness(nearest)\n",
    "        nb = neighbor_counts(ps1, ra, dec, radii_arcsec=[30,60,120,240,480])\n",
    "    else:\n",
    "        ps1_sep=ext_strength=ext_flag=np.nan\n",
    "        nb = {30:np.nan,60:np.nan,120:np.nan,240:np.nan,480:np.nan}\n",
    "    # 2MASS XSC (10\")\n",
    "    try:\n",
    "        Irsa.TIMEOUT=60\n",
    "        xsc = Irsa.query_region(SkyCoord(ra*u.deg, dec*u.deg), catalog=\"fp_xsc\", radius=10*u.arcsec)\n",
    "        xsc = xsc.to_pandas() if xsc is not None else pd.DataFrame()\n",
    "        is_2mass_extended = (len(xsc)>0)\n",
    "    except Exception:\n",
    "        is_2mass_extended = False\n",
    "    # CatWISE\n",
    "    try:\n",
    "        cw = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=8*u.arcsec, catalog=\"II/365/catwise2020\")\n",
    "        cw = cw[0].to_pandas() if len(cw)>0 else pd.DataFrame()\n",
    "    except Exception:\n",
    "        cw = pd.DataFrame()\n",
    "    if not cw.empty:\n",
    "        crow, cw_sep = nearest_row(cw, ra, dec, ra_col=\"RAJ2000\", dec_col=\"DEJ2000\")\n",
    "        cw_W1 = crow.get(\"W1mpro\", np.nan); cw_W2 = crow.get(\"W2mpro\", np.nan)\n",
    "    else:\n",
    "        cw_sep=cw_W1=cw_W2=np.nan\n",
    "    # SDSS (20\")\n",
    "    try:\n",
    "        sdss = SDSS.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=20*u.arcsec,\n",
    "                                 photoobj_fields=['ra','dec','type','class','psfMag_r','cModelMag_r'])\n",
    "        sdss = sdss.to_pandas() if sdss is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        sdss = pd.DataFrame()\n",
    "    if not sdss.empty:\n",
    "        srow, sdss_sep = nearest_row(sdss, ra, dec, ra_col=\"ra\", dec_col=\"dec\")\n",
    "        sdss_class = srow.get(\"class\",\"\")\n",
    "        try:\n",
    "            dr = (float(srow.get(\"psfMag_r\")) - float(srow.get(\"cModelMag_r\"))) if pd.notna(srow.get(\"psfMag_r\")) and pd.notna(srow.get(\"cModelMag_r\")) else np.nan\n",
    "        except Exception:\n",
    "            dr = np.nan\n",
    "    else:\n",
    "        sdss_sep=sdss_class=dr=np.nan\n",
    "    # GALEX (3')\n",
    "    try:\n",
    "        gal = MASTCat.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=3*u.arcmin, catalog=\"GALEX\")\n",
    "        gal = gal.to_pandas() if gal is not None else pd.DataFrame()\n",
    "    except Exception:\n",
    "        gal = pd.DataFrame()\n",
    "    if not gal.empty:\n",
    "        grow, gal_sep = nearest_row(gal, ra, dec)\n",
    "        nuv = grow.get(\"nuv_mag\", grow.get(\"NUV\", np.nan))\n",
    "    else:\n",
    "        gal_sep=nuv=np.nan\n",
    "    # NED groups (10')\n",
    "    if HAVE_NED:\n",
    "        try:\n",
    "            ned = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=10*u.arcmin)\n",
    "            ned = ned.to_pandas() if ned is not None else pd.DataFrame()\n",
    "        except Exception:\n",
    "            ned = pd.DataFrame()\n",
    "        nearby_groups = ned_group_flag(ned)\n",
    "    else:\n",
    "        nearby_groups = False\n",
    "    row = {\n",
    "        \"AllWISE\": allwise_id, \"RA_deg\": ra, \"Dec_deg\": dec,\n",
    "        \"WISE_W1-W2\": float(aw.get(\"W1mag\",np.nan)-aw.get(\"W2mag\",np.nan)) if pd.notna(aw.get(\"W1mag\",np.nan)) and pd.notna(aw.get(\"W2mag\",np.nan)) else np.nan,\n",
    "        \"WISE_W2-W3\": float(aw.get(\"W2mag\",np.nan)-aw.get(\"W3mag\",np.nan)) if pd.notna(aw.get(\"W2mag\",np.nan)) and pd.notna(aw.get(\"W3mag\",np.nan)) else np.nan,\n",
    "        \"PS1_nearest_sep_arcsec\": ps1_sep, \"PS1_ext_strength\": ext_strength, \"PS1_extended_flag\": int(ext_flag) if pd.notna(ext_flag) else np.nan,\n",
    "        \"PS1_N_30\\\"\": nb[30], \"PS1_N_60\\\"\": nb[60], \"PS1_N_120\\\"\": nb[120], \"PS1_N_240\\\"\": nb[240], \"PS1_N_480\\\"\": nb[480],\n",
    "        \"2MASS_XSC_hit\": bool(is_2mass_extended),\n",
    "        \"CatWISE_sep_arcsec\": cw_sep, \"CatWISE_W1mpro\": cw_W1, \"CatWISE_W2mpro\": cw_W2,\n",
    "        \"SDSS_sep_arcsec\": sdss_sep, \"SDSS_class\": sdss_class, \"SDSS_r_psf-cModel\": dr,\n",
    "        \"GALEX_sep_arcsec\": gal_sep, \"GALEX_NUV_mag\": nuv,\n",
    "        \"NED_groups_within_10'\": bool(nearby_groups)\n",
    "    }\n",
    "    return row\n",
    "\n",
    "# ========== DOSSIER ==========\n",
    "def make_dossier(allwise_id, stamp):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=allwise_id)\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    aw = q[0].to_pandas().iloc[0]; ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "    # Cutout (PS1 rgb or DSS2)\n",
    "    def cutout_png(ra, dec, tag, fov=2.0):\n",
    "        try:\n",
    "            imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"PanSTARRS g\",\"PanSTARRS r\",\"PanSTARRS i\"],\n",
    "                                      pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "            if imgs and len(imgs)>=3:\n",
    "                def norm(hdu): \n",
    "                    a = hdu[0].data.astype(np.float32)\n",
    "                    return np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "                g = norm(imgs[0]); r = norm(imgs[1]); i = norm(imgs[2])\n",
    "                rgb = np.stack([i,r,g],axis=-1)\n",
    "                plt.figure(figsize=(3.2,3.2)); plt.imshow(rgb, origin=\"lower\"); plt.axis(\"off\")\n",
    "                out = FIG/f\"{tag}_PS1.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close(); return out\n",
    "        except Exception: pass\n",
    "        try:\n",
    "            imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                      pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "            if imgs:\n",
    "                a = imgs[0][0].data.astype(np.float32)\n",
    "                a = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "                plt.figure(figsize=(3.2,3.2)); plt.imshow(a, origin=\"lower\", cmap=\"gray\"); plt.axis(\"off\")\n",
    "                out = FIG/f\"{tag}_DSS2.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close(); return out\n",
    "        except Exception: pass\n",
    "        return None\n",
    "    tag = allwise_id.replace(\".\",\"\").replace(\"+\",\"p\").replace(\"-\",\"m\")\n",
    "    png = cutout_png(ra, dec, tag, fov=2.0)\n",
    "    # SED plot\n",
    "    mags = [aw.get(\"W1mag\",np.nan), aw.get(\"W2mag\",np.nan), aw.get(\"W3mag\",np.nan), aw.get(\"W4mag\",np.nan)]\n",
    "    bands= [\"W1\",\"W2\",\"W3\",\"W4\"]\n",
    "    plt.figure(figsize=(4,3))\n",
    "    plt.plot(range(len(mags)), mags, marker=\"o\"); plt.gca().invert_yaxis()\n",
    "    plt.xticks(range(len(mags)), bands); plt.title(f\"{allwise_id} — WISE SED\"); plt.tight_layout()\n",
    "    sedpng = FIG/f\"{tag}_SED.png\"; plt.savefig(sedpng, dpi=150); plt.close()\n",
    "    # SIMBAD / NED (short label)\n",
    "    Simbad.add_votable_fields(\"otype\")\n",
    "    try:\n",
    "        s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=5*u.arcsec)\n",
    "        simbad_type = s.to_pandas().iloc[0][\"OTYPE\"] if (s is not None and len(s)>0) else \"\"\n",
    "    except Exception:\n",
    "        simbad_type = \"\"\n",
    "    if HAVE_NED:\n",
    "        try:\n",
    "            n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=5*u.arcsec)\n",
    "            if n is not None and len(n)>0:\n",
    "                npd = n.to_pandas().iloc[0]\n",
    "                ned_name = npd.get(\"Object Name\",\"\"); ned_type = npd.get(\"Type\",\"\"); ned_z = npd.get(\"Redshift\",\"\")\n",
    "            else:\n",
    "                ned_name = ned_type = ned_z = \"\"\n",
    "        except Exception:\n",
    "            ned_name = ned_type = ned_z = \"\"\n",
    "    else:\n",
    "        ned_name=ned_type=ned_z=\"\"\n",
    "    # dossier md\n",
    "    md = OUT/f\"CNT_Gold_Dossier_{tag}.md\"\n",
    "    with open(md, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Gold Dossier — {allwise_id}\\n\\n\")\n",
    "        f.write(f\"**ICRS:** RA {ra:.6f}, Dec {dec:.6f}\\n\\n\")\n",
    "        f.write(f\"- W1={mags[0]}, W2={mags[1]}, W3={mags[2]}, W4={mags[3]}\\n\")\n",
    "        if pd.notna(mags[0]) and pd.notna(mags[1]) and pd.notna(mags[2]):\n",
    "            f.write(f\"- Colors: W1−W2={mags[0]-mags[1]:.3f}, W2−W3={mags[1]-mags[2]:.3f}\\n\")\n",
    "        f.write(f\"- SIMBAD: {simbad_type}\\n\")\n",
    "        if HAVE_NED: f.write(f\"- NED: {ned_name} [{ned_type}] z={ned_z}\\n\")\n",
    "        if png: f.write(f\"\\nCutout: {png}\\n\")\n",
    "        f.write(f\"\\nSED: {sedpng}\\n\")\n",
    "    print(\"[dossier]\", md)\n",
    "    return {\"md\": md, \"cutout\": png, \"sed\": sedpng}\n",
    "\n",
    "# ========== RUN PIPELINE ==========\n",
    "def run_all():\n",
    "    stamp, master, tiles, master_path = discovery_sweep()\n",
    "    enr, base, gold, strict_path, relaxed_path, gold_path = enrich_allwise(master, stamp)\n",
    "    ver, ver_path = multiscale_verify(gold, stamp)\n",
    "\n",
    "    # confirmed golds (multiscale pass)\n",
    "    confirmed = ver[ver[\"pass_multiscale\"]==True][\"AllWISE\"].tolist()\n",
    "    print(f\"[confirm] multiscale golds: {len(confirmed)} →\", confirmed)\n",
    "\n",
    "    # multisurvey on confirmed\n",
    "    ms_rows=[]\n",
    "    for wid in confirmed:\n",
    "        row = multisurvey_probe(wid, stamp)\n",
    "        if row: ms_rows.append(row)\n",
    "    if ms_rows:\n",
    "        ms_df = pd.DataFrame(ms_rows)\n",
    "        ms_path = OUT/f\"gold_multisurvey_summary_{stamp}.csv\"\n",
    "        ms_df.to_csv(ms_path, index=False)\n",
    "        print(f\"[save] multisurvey summary → {ms_path}\")\n",
    "    else:\n",
    "        ms_df = pd.DataFrame()\n",
    "\n",
    "    # dossiers + gallery\n",
    "    cards=[]\n",
    "    for wid in confirmed:\n",
    "        d = make_dossier(wid, stamp)\n",
    "        cards.append((wid, d))\n",
    "\n",
    "    html = WEB/f\"index_{stamp}.html\"\n",
    "    with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(\"<html><head><meta charset='utf-8'><title>CNT Gold Gallery</title>\"\n",
    "                \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:200px}</style></head><body>\")\n",
    "        f.write(f\"<h1>CNT Gold — {stamp}</h1>\")\n",
    "        for wid, dd in cards:\n",
    "            f.write(\"<div class='card'>\")\n",
    "            if dd and dd.get(\"cutout\") and Path(dd[\"cutout\"]).exists():\n",
    "                f.write(f\"<img src='../{Path(dd['cutout']).relative_to(OUT)}'/>\")\n",
    "            else:\n",
    "                f.write(\"<div style='width:200px;height:150px;background:#eee;border-radius:8px'></div>\")\n",
    "            f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "            if dd and dd.get(\"sed\") and Path(dd[\"sed\"]).exists():\n",
    "                f.write(f\"<div><a href='../{Path(dd['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                        f\"<a href='../{Path(dd['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "            f.write(\"</div></div>\")\n",
    "        f.write(\"</body></html>\")\n",
    "    print(f\"[save] gallery → {html}\")\n",
    "\n",
    "    # prereg JSON (paths as str)\n",
    "    claim = dict(\n",
    "        when=stamp, center=(CFG[\"CENTER_RA\"], CFG[\"CENTER_DEC\"]), tiles=len(tiles),\n",
    "        K_DISC=CFG[\"K_DISC\"], K_GOLD=CFG[\"K_GOLD\"], GOLD_W23_MIN=CFG[\"GOLD_W23_MIN\"], GALAXY_MODE=CFG[\"GALAXY_MODE\"],\n",
    "        master=str(master_path), enriched=str(OUT/f\"stable_enriched_all_{stamp}.csv\"),\n",
    "        strict=str(strict_path), relaxed=str(relaxed_path), gold=str(gold_path),\n",
    "        verify=str(ver_path), gallery=str(html),\n",
    "        confirmed_golds=confirmed,\n",
    "        multisurvey=str(OUT/f\"gold_multisurvey_summary_{stamp}.csv\") if not ms_df.empty else None\n",
    "    )\n",
    "    prereg_path = OUT/f\"preregister_{stamp}.json\"\n",
    "    with open(prereg_path, \"w\") as f: json.dump(claim, f, indent=2, default=str)\n",
    "    print(\"[save] prereg json →\", prereg_path)\n",
    "\n",
    "    # report\n",
    "    report = OUT/f\"CNT_TechnoAnomaly_Report_{stamp}.md\"\n",
    "    with open(report,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Techno-Anomaly v3 — {stamp}\\n\\n\")\n",
    "        f.write(f\"- Tiles: **{len(tiles)}**\\n- Master stable: **{len(master)}**\\n\")\n",
    "        f.write(f\"- Gold (pre-verify): **{len(gold)}**\\n\")\n",
    "        f.write(f\"- ID-locked multiscale confirmed: **{len(confirmed)}**\\n\\n\")\n",
    "        f.write(\"## Key files\\n\")\n",
    "        for p in [master_path, OUT/f\"stable_enriched_all_{stamp}.csv\", strict_path, relaxed_path, gold_path, ver_path, html, prereg_path]:\n",
    "            f.write(f\"- `{p}`\\n\")\n",
    "        if not ms_df.empty:\n",
    "            f.write(f\"- `{OUT/f'gold_multisurvey_summary_{stamp}.csv'}`\\n\")\n",
    "    print(\"[save] report →\", report)\n",
    "\n",
    "    # zip bundle\n",
    "    zip_base = OUT/f\"CNT_TechnoAnomaly_{stamp}\"\n",
    "    with open(OUT/f\"FILES_{stamp}.txt\",\"w\") as idx:\n",
    "        idx.write(\"\\n\".join([str(master_path),str(OUT/f\"stable_enriched_all_{stamp}.csv\"),str(strict_path),\n",
    "                             str(relaxed_path),str(gold_path),str(ver_path),str(prereg_path),str(report),str(html)]))\n",
    "    shutil.make_archive(str(zip_base), \"zip\", OUT)\n",
    "    print(f\"[bundle] zip → {zip_base}.zip\")\n",
    "\n",
    "    print(\"\\n== SUMMARY ==\")\n",
    "    print(f\"Tiles: {len(tiles)} | Master: {len(master)} | Gold: {len(gold)} | Confirmed: {len(confirmed)}\")\n",
    "\n",
    "# GO\n",
    "run_all()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3d7af13a-128c-4f2a-bd08-398713dcddc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop this near the top of your notebook (after imports)\n",
    "from astroquery import log\n",
    "log.setLevel('ERROR')\n",
    "\n",
    "from astroquery.vizier import Vizier; Vizier.TIMEOUT = 20\n",
    "from astroquery.sdss import SDSS; SDSS.TIMEOUT = 20\n",
    "from astroquery.irsa import Irsa; Irsa.TIMEOUT = 20\n",
    "from astroquery.simbad import Simbad; Simbad.TIMEOUT = 20\n",
    "try:\n",
    "    from astroquery.ned import Ned; Ned.TIMEOUT = 20\n",
    "except Exception:\n",
    "    pass\n",
    "try:\n",
    "    from astroquery.mast import conf as mast_conf; mast_conf.timeout = 20\n",
    "except Exception:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "51cb02e2-e7e9-4c55-a48f-874a7dc7afbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tile 1/25] RA=209.000 Dec=-1.500\n",
      "[tile 2/25] RA=209.500 Dec=-1.500\n",
      "[tile 3/25] RA=210.000 Dec=-1.500\n",
      "[tile 4/25] RA=210.500 Dec=-1.500\n",
      "[tile 5/25] RA=211.000 Dec=-1.500\n",
      "[tile 6/25] RA=209.000 Dec=-1.000\n",
      "[tile 7/25] RA=209.500 Dec=-1.000\n",
      "[tile 8/25] RA=210.000 Dec=-1.000\n",
      "[tile 9/25] RA=210.500 Dec=-1.000\n",
      "[tile 10/25] RA=211.000 Dec=-1.000\n",
      "[tile 11/25] RA=209.000 Dec=-0.500\n",
      "[tile 12/25] RA=209.500 Dec=-0.500\n",
      "[tile 13/25] RA=210.000 Dec=-0.500\n",
      "[tile 14/25] RA=210.500 Dec=-0.500\n",
      "[tile 15/25] RA=211.000 Dec=-0.500\n",
      "[tile 16/25] RA=209.000 Dec=0.000\n",
      "[tile 17/25] RA=209.500 Dec=0.000\n",
      "[tile 18/25] RA=210.000 Dec=0.000\n",
      "[tile 19/25] RA=210.500 Dec=0.000\n",
      "[tile 20/25] RA=211.000 Dec=0.000\n",
      "[tile 21/25] RA=209.000 Dec=0.500\n",
      "[tile 22/25] RA=209.500 Dec=0.500\n",
      "[tile 23/25] RA=210.000 Dec=0.500\n",
      "[tile 24/25] RA=210.500 Dec=0.500\n",
      "[tile 25/25] RA=211.000 Dec=0.500\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-012642.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-012642.csv (N=30)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-012642.csv (N=28)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-012642.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-012642.csv (N=3)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-012642.csv\n",
      "[center 210.00,-0.50] no multiscale-confirmed golds.\n",
      "[tile 1/25] RA=199.000 Dec=4.000\n",
      "[tile 2/25] RA=199.500 Dec=4.000\n",
      "[tile 3/25] RA=200.000 Dec=4.000\n",
      "[tile 4/25] RA=200.500 Dec=4.000\n",
      "[tile 5/25] RA=201.000 Dec=4.000\n",
      "[tile 6/25] RA=199.000 Dec=4.500\n",
      "[tile 7/25] RA=199.500 Dec=4.500\n",
      "[tile 8/25] RA=200.000 Dec=4.500\n",
      "[tile 9/25] RA=200.500 Dec=4.500\n",
      "[tile 10/25] RA=201.000 Dec=4.500\n",
      "[tile 11/25] RA=199.000 Dec=5.000\n",
      "[tile 12/25] RA=199.500 Dec=5.000\n",
      "[tile 13/25] RA=200.000 Dec=5.000\n",
      "[tile 14/25] RA=200.500 Dec=5.000\n",
      "[tile 15/25] RA=201.000 Dec=5.000\n",
      "[tile 16/25] RA=199.000 Dec=5.500\n",
      "[tile 17/25] RA=199.500 Dec=5.500\n",
      "[tile 18/25] RA=200.000 Dec=5.500\n",
      "[tile 19/25] RA=200.500 Dec=5.500\n",
      "[tile 20/25] RA=201.000 Dec=5.500\n",
      "[tile 21/25] RA=199.000 Dec=6.000\n",
      "[tile 22/25] RA=199.500 Dec=6.000\n",
      "[tile 23/25] RA=200.000 Dec=6.000\n",
      "[tile 24/25] RA=200.500 Dec=6.000\n",
      "[tile 25/25] RA=201.000 Dec=6.000\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-012942.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-012942.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-012942.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-012942.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-012942.csv (N=6)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-012942.csv\n",
      "[save] novelty candidates → cnt_anomaly\\out\\novelty_candidates_20251017-012942.csv (N=3)\n",
      "[note] confirmed golds here were already cataloged & typed.\n",
      "[tile 1/25] RA=219.000 Dec=4.000\n",
      "[tile 2/25] RA=219.500 Dec=4.000\n",
      "[tile 3/25] RA=220.000 Dec=4.000\n",
      "[tile 4/25] RA=220.500 Dec=4.000\n",
      "[tile 5/25] RA=221.000 Dec=4.000\n",
      "[tile 6/25] RA=219.000 Dec=4.500\n",
      "[tile 7/25] RA=219.500 Dec=4.500\n",
      "[tile 8/25] RA=220.000 Dec=4.500\n",
      "[tile 9/25] RA=220.500 Dec=4.500\n",
      "[tile 10/25] RA=221.000 Dec=4.500\n",
      "[tile 11/25] RA=219.000 Dec=5.000\n",
      "[tile 12/25] RA=219.500 Dec=5.000\n",
      "[tile 13/25] RA=220.000 Dec=5.000\n",
      "[tile 14/25] RA=220.500 Dec=5.000\n",
      "[tile 15/25] RA=221.000 Dec=5.000\n",
      "[tile 16/25] RA=219.000 Dec=5.500\n",
      "[tile 17/25] RA=219.500 Dec=5.500\n",
      "[tile 18/25] RA=220.000 Dec=5.500\n",
      "[tile 19/25] RA=220.500 Dec=5.500\n",
      "[tile 20/25] RA=221.000 Dec=5.500\n",
      "[tile 21/25] RA=219.000 Dec=6.000\n",
      "[tile 22/25] RA=219.500 Dec=6.000\n",
      "[tile 23/25] RA=220.000 Dec=6.000\n",
      "[tile 24/25] RA=220.500 Dec=6.000\n",
      "[tile 25/25] RA=221.000 Dec=6.000\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-013407.csv (N=29)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-013407.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-013407.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-013407.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-013407.csv (N=4)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-013407.csv\n",
      "[save] novelty candidates → cnt_anomaly\\out\\novelty_candidates_20251017-013407.csv (N=1)\n",
      "[note] confirmed golds here were already cataloged & typed.\n",
      "[save] merged novelty → cnt_anomaly\\out\\novelty_candidates_merged.csv (N=4)\n",
      "\n",
      "== NOVELTY HUNT SUMMARY ==\n",
      "centers scanned: 3 | tiles: 75 | runs with novel/semi-novel: 0\n"
     ]
    }
   ],
   "source": [
    "# CNT Novelty Hunter v1 — find unlabeled (or untyped) golds at scale\n",
    "# Reuses v3 helpers: discovery_sweep(), enrich_allwise(), multiscale_verify(), make_dossier(), multisurvey_probe()\n",
    "\n",
    "import os, io, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "# --- tame network timeouts so the run never hangs long ---\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED:\n",
    "    Ned.TIMEOUT = 20\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# === CONFIG you can tweak quickly ===\n",
    "CENTERS = [  # (RA, Dec) in deg\n",
    "    (210.0, -0.5),   # your original patch\n",
    "    (200.0, +5.0),   # add two fresh high-lat fields to raise novelty odds\n",
    "    (220.0, +5.0),\n",
    "]\n",
    "GRID_SIZE   = 5      # 5x5 grid per center (25 tiles each)\n",
    "GRID_STEP   = 1.0    # degrees between tile centers\n",
    "RADIUS_DEG  = 0.8    # per tile radius for the query\n",
    "N_MAX       = 2500   # Gaia cap per tile (balance speed vs. depth)\n",
    "K_DISC      = 3      # discovery bar\n",
    "K_GOLD      = 4      # gold bar\n",
    "W23_MIN     = 1.0    # color gate for gold\n",
    "GALAXY_MODE = False  # set True to bias for extended/redder before verify\n",
    "STOP_AFTER_CONFIRMED = 8  # stop early once we have this many confirmed novel hits\n",
    "\n",
    "# === Novelty criteria ===\n",
    "SIMBAD_NED_RADIUS_ARCSEC = 5.0\n",
    "UNTYPED_KEYS = []  # treat any SIMBAD/NED presence as \"typed\" unless empty; you can put strings like \"Candidate\" to still count as untyped\n",
    "\n",
    "# === Helper: pull AllWISE exact row and novelty verdict ===\n",
    "def allwise_row(wid):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wid))\n",
    "    if len(q)==0 or len(q[0])==0: \n",
    "        return None, None, None, None\n",
    "    r = q[0].to_pandas().iloc[0]\n",
    "    ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "    w12 = (r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if pd.notna(r.get(\"W1mag\",np.nan)) and pd.notna(r.get(\"W2mag\",np.nan)) else np.nan\n",
    "    w23 = (r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if pd.notna(r.get(\"W2mag\",np.nan)) and pd.notna(r.get(\"W3mag\",np.nan)) else np.nan\n",
    "    return r, ra, dec, w12, w23\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD\n",
    "    try:\n",
    "        s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "    except Exception:\n",
    "        s = None\n",
    "    simbad_hit, simbad_type = False, \"\"\n",
    "    if s is not None and len(s)>0:\n",
    "        p = s.to_pandas().iloc[0]\n",
    "        simbad_hit = True\n",
    "        simbad_type = str(p.get(\"OTYPE\",\"\"))\n",
    "    # NED\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try:\n",
    "            n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "        except Exception:\n",
    "            n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]\n",
    "            ned_hit = True\n",
    "            ned_type = str(p.get(\"Type\",\"\"))\n",
    "            ned_z = str(p.get(\"Redshift\",\"\"))\n",
    "    # Novelty logic\n",
    "    if not simbad_hit and not ned_hit:\n",
    "        verdict = \"NOVEL: no SIMBAD/NED within 5″\"\n",
    "        novelty_rank = 2\n",
    "    else:\n",
    "        typed_tokens = (simbad_type + \" \" + ned_type).upper()\n",
    "        untyped = (typed_tokens.strip() == \"\") or any(tok.upper() in typed_tokens for tok in UNTYPED_KEYS)\n",
    "        if untyped:\n",
    "            verdict = \"SEMI-NOVEL: cataloged but untyped/ambiguous\"\n",
    "            novelty_rank = 1\n",
    "        else:\n",
    "            verdict = \"KNOWN: cataloged & typed\"\n",
    "            novelty_rank = 0\n",
    "    return dict(simbad_hit=simbad_hit, simbad_type=simbad_type,\n",
    "                ned_hit=ned_hit, ned_type=ned_type, ned_z=ned_z,\n",
    "                novelty_verdict=verdict, novelty_rank=novelty_rank)\n",
    "\n",
    "# === Runner: for each center → sweep → gold → verify → novelty → save ===\n",
    "def novelty_hunt():\n",
    "    global CFG  # reuse your v3 CFG object\n",
    "    found = []\n",
    "    total_tiles = 0\n",
    "    start_ts = time.time()\n",
    "\n",
    "    for (ra_c, dec_c) in CENTERS:\n",
    "        # patch CFG for this center & grid\n",
    "        CFG[\"CENTER_RA\"] = float(ra_c)\n",
    "        CFG[\"CENTER_DEC\"] = float(dec_c)\n",
    "        CFG[\"GRID_SIZE\"] = int(GRID_SIZE)\n",
    "        CFG[\"GRID_STEP_DEG\"] = float(GRID_STEP)\n",
    "        CFG[\"RADIUS_DEG\"] = float(RADIUS_DEG)\n",
    "        CFG[\"N_MAX\"] = int(N_MAX)\n",
    "        CFG[\"K_DISC\"] = int(K_DISC)\n",
    "        CFG[\"K_GOLD\"] = int(K_GOLD)\n",
    "        CFG[\"GOLD_W23_MIN\"] = float(W23_MIN)\n",
    "        CFG[\"GALAXY_MODE\"] = bool(GALAXY_MODE)\n",
    "\n",
    "        # 1) discovery → master\n",
    "        stamp, master, tiles, master_path = discovery_sweep()\n",
    "        total_tiles += len(tiles)\n",
    "\n",
    "        # 2) enrich & gold gating\n",
    "        enr, base, gold, strict_path, relaxed_path, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(f\"[center {ra_c:.2f},{dec_c:.2f}] no gold at current gates.\")\n",
    "            continue\n",
    "\n",
    "        # 3) multiscale verify (ID-locked) — keep only confirmed\n",
    "        ver, ver_path = multiscale_verify(gold, stamp)\n",
    "        confirmed = ver[ver[\"pass_multiscale\"]==True].copy()\n",
    "        if confirmed.empty:\n",
    "            print(f\"[center {ra_c:.2f},{dec_c:.2f}] no multiscale-confirmed golds.\")\n",
    "            continue\n",
    "\n",
    "        # 4) novelty pass on confirmed\n",
    "        rows=[]\n",
    "        for _, row in confirmed.iterrows():\n",
    "            wid = str(row[\"AllWISE\"])\n",
    "            aw, ra, dec, w12, w23 = allwise_row(wid)\n",
    "            if ra is None:\n",
    "                continue\n",
    "            nov = novelty_check(ra, dec)\n",
    "            rows.append({\n",
    "                \"AllWISE\": wid, \"RA\": ra, \"Dec\": dec,\n",
    "                \"W1-W2\": w12, \"W2-W3\": w23,\n",
    "                \"best_votes\": int(row.get(\"best_votes\", row.get(\"K\", np.nan))) if pd.notna(row.get(\"best_votes\", np.nan)) else np.nan,\n",
    "                \"best_scale_arcmin\": row.get(\"best_scale_arcmin\", np.nan),\n",
    "                **nov\n",
    "            })\n",
    "\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(rows).sort_values([\"novelty_rank\",\"best_votes\"], ascending=[False, False])\n",
    "        out_csv = OUT / f\"novelty_candidates_{stamp}.csv\"\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"[save] novelty candidates → {out_csv} (N={len(df)})\")\n",
    "        # keep only the novel/semi-novel\n",
    "        novel = df[df[\"novelty_rank\"]>=1].copy()\n",
    "        if not novel.empty:\n",
    "            # Make small gallery+dossiers only for novel/semi-novel\n",
    "            cards=[]\n",
    "            for wid in novel[\"AllWISE\"]:\n",
    "                d = make_dossier(wid, stamp)  # from v3 cell\n",
    "                cards.append((wid, d))\n",
    "            html = OUT / f\"novelty_gallery_{stamp}.html\"\n",
    "            with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(\"<html><head><meta charset='utf-8'><title>CNT Novelty Gallery</title>\"\n",
    "                        \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                        \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                f.write(f\"<h1>Novelty Gallery — {stamp}</h1>\")\n",
    "                for wid, dd in cards:\n",
    "                    f.write(\"<div class='card'>\")\n",
    "                    if dd and dd.get(\"cutout\") and Path(dd[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(dd['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if dd and dd.get(\"sed\") and Path(dd[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(dd['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(dd['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div>\")\n",
    "                f.write(\"</body></html>\")\n",
    "            print(f\"[save] novelty gallery → {html}\")\n",
    "            found.append((stamp, out_csv, html))\n",
    "        else:\n",
    "            print(f\"[note] confirmed golds here were already cataloged & typed.\")\n",
    "\n",
    "        if sum(1 for _ in found) >= STOP_AFTER_CONFIRMED:\n",
    "            break\n",
    "\n",
    "    # Merge all novelty CSVs if multiple centers\n",
    "    all_csvs = sorted(OUT.glob(\"novelty_candidates_*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "    if len(all_csvs)>=2:\n",
    "        dfs = [pd.read_csv(p) for p in all_csvs]\n",
    "        merged = pd.concat(dfs, ignore_index=True).drop_duplicates(subset=[\"AllWISE\"])\n",
    "        merged_out = OUT / \"novelty_candidates_merged.csv\"\n",
    "        merged.to_csv(merged_out, index=False)\n",
    "        print(f\"[save] merged novelty → {merged_out} (N={len(merged)})\")\n",
    "\n",
    "    print(f\"\\n== NOVELTY HUNT SUMMARY ==\\ncenters scanned: {len(CENTERS)} | tiles: {total_tiles} | runs with novel/semi-novel: {len(found)}\")\n",
    "    for (s, csvp, htm) in found:\n",
    "        print(f\" - {s}: {csvp.name}  |  {htm.name}\")\n",
    "\n",
    "novelty_hunt()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "de8be211-cabf-4793-bc12-11a72477e5bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[scan] centers=19 (high |b|) …\n",
      "[tile 1/16] RA=-1.200 Dec=-51.200\n",
      "[tile 2/16] RA=-0.400 Dec=-51.200\n",
      "[tile 3/16] RA=0.400 Dec=-51.200\n",
      "[tile 4/16] RA=1.200 Dec=-51.200\n",
      "[tile 5/16] RA=-1.200 Dec=-50.400\n",
      "[tile 6/16] RA=-0.400 Dec=-50.400\n",
      "[tile 7/16] RA=0.400 Dec=-50.400\n",
      "[tile 8/16] RA=1.200 Dec=-50.400\n",
      "[tile 9/16] RA=-1.200 Dec=-49.600\n",
      "[tile 10/16] RA=-0.400 Dec=-49.600\n",
      "[tile 11/16] RA=0.400 Dec=-49.600\n",
      "[tile 12/16] RA=1.200 Dec=-49.600\n",
      "[tile 13/16] RA=-1.200 Dec=-48.800\n",
      "[tile 14/16] RA=-0.400 Dec=-48.800\n",
      "[tile 15/16] RA=0.400 Dec=-48.800\n",
      "[tile 16/16] RA=1.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-014038.csv (N=19)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-014038.csv (N=18)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-014038.csv (N=15)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-014038.csv (N=16)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-014038.csv (N=0)\n",
      "[0.0,-50.0] no gold.\n",
      "[tile 1/16] RA=-1.200 Dec=-41.200\n",
      "[tile 2/16] RA=-0.400 Dec=-41.200\n",
      "[tile 3/16] RA=0.400 Dec=-41.200\n",
      "[tile 4/16] RA=1.200 Dec=-41.200\n",
      "[tile 5/16] RA=-1.200 Dec=-40.400\n",
      "[tile 6/16] RA=-0.400 Dec=-40.400\n",
      "[tile 7/16] RA=0.400 Dec=-40.400\n",
      "[tile 8/16] RA=1.200 Dec=-40.400\n",
      "[tile 9/16] RA=-1.200 Dec=-39.600\n",
      "[tile 10/16] RA=-0.400 Dec=-39.600\n",
      "[tile 11/16] RA=0.400 Dec=-39.600\n",
      "[tile 12/16] RA=1.200 Dec=-39.600\n",
      "[tile 13/16] RA=-1.200 Dec=-38.800\n",
      "[tile 14/16] RA=-0.400 Dec=-38.800\n",
      "[tile 15/16] RA=0.400 Dec=-38.800\n",
      "[tile 16/16] RA=1.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-014228.csv (N=20)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-014228.csv (N=18)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-014228.csv (N=17)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-014228.csv (N=17)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-014228.csv (N=3)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-014228.csv\n",
      "[0.0,-40.0] none multiscale-confirmed.\n",
      "[tile 1/16] RA=28.800 Dec=-51.200\n",
      "[tile 2/16] RA=29.600 Dec=-51.200\n",
      "[tile 3/16] RA=30.400 Dec=-51.200\n",
      "[tile 4/16] RA=31.200 Dec=-51.200\n",
      "[tile 5/16] RA=28.800 Dec=-50.400\n",
      "[tile 6/16] RA=29.600 Dec=-50.400\n",
      "[tile 7/16] RA=30.400 Dec=-50.400\n",
      "[tile 8/16] RA=31.200 Dec=-50.400\n",
      "[tile 9/16] RA=28.800 Dec=-49.600\n",
      "[tile 10/16] RA=29.600 Dec=-49.600\n",
      "[tile 11/16] RA=30.400 Dec=-49.600\n",
      "[tile 12/16] RA=31.200 Dec=-49.600\n",
      "[tile 13/16] RA=28.800 Dec=-48.800\n",
      "[tile 14/16] RA=29.600 Dec=-48.800\n",
      "[tile 15/16] RA=30.400 Dec=-48.800\n",
      "[tile 16/16] RA=31.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-014431.csv (N=20)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-014431.csv (N=20)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-014431.csv (N=20)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-014431.csv (N=20)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-014431.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-014431.csv\n",
      "[30.0,-50.0] none multiscale-confirmed.\n",
      "[tile 1/16] RA=28.800 Dec=-41.200\n",
      "[tile 2/16] RA=29.600 Dec=-41.200\n",
      "[tile 3/16] RA=30.400 Dec=-41.200\n",
      "[tile 4/16] RA=31.200 Dec=-41.200\n",
      "[tile 5/16] RA=28.800 Dec=-40.400\n",
      "[tile 6/16] RA=29.600 Dec=-40.400\n",
      "[tile 7/16] RA=30.400 Dec=-40.400\n",
      "[tile 8/16] RA=31.200 Dec=-40.400\n",
      "[tile 9/16] RA=28.800 Dec=-39.600\n",
      "[tile 10/16] RA=29.600 Dec=-39.600\n",
      "[tile 11/16] RA=30.400 Dec=-39.600\n",
      "[tile 12/16] RA=31.200 Dec=-39.600\n",
      "[tile 13/16] RA=28.800 Dec=-38.800\n",
      "[tile 14/16] RA=29.600 Dec=-38.800\n",
      "[tile 15/16] RA=30.400 Dec=-38.800\n",
      "[tile 16/16] RA=31.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-014634.csv (N=18)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-014634.csv (N=18)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-014634.csv (N=18)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-014634.csv (N=18)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-014634.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-014634.csv\n",
      "[30.0,-40.0] none multiscale-confirmed.\n",
      "[tile 1/16] RA=58.800 Dec=-51.200\n",
      "[tile 2/16] RA=59.600 Dec=-51.200\n",
      "[tile 3/16] RA=60.400 Dec=-51.200\n",
      "[tile 4/16] RA=61.200 Dec=-51.200\n",
      "[tile 5/16] RA=58.800 Dec=-50.400\n",
      "[tile 6/16] RA=59.600 Dec=-50.400\n",
      "[tile 7/16] RA=60.400 Dec=-50.400\n",
      "[tile 8/16] RA=61.200 Dec=-50.400\n",
      "[tile 9/16] RA=58.800 Dec=-49.600\n",
      "[tile 10/16] RA=59.600 Dec=-49.600\n",
      "[tile 11/16] RA=60.400 Dec=-49.600\n",
      "[tile 12/16] RA=61.200 Dec=-49.600\n",
      "[tile 13/16] RA=58.800 Dec=-48.800\n",
      "[tile 14/16] RA=59.600 Dec=-48.800\n",
      "[tile 15/16] RA=60.400 Dec=-48.800\n",
      "[tile 16/16] RA=61.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-014831.csv (N=18)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-014831.csv (N=18)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-014831.csv (N=16)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-014831.csv (N=16)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-014831.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-014831.csv\n",
      "[save] cnt_anomaly\\out\\novelty_hits_20251017-014831.csv (N=1)\n",
      "[dossier] cnt_anomaly\\out\\CNT_Gold_Dossier_J03571444m4932027.md\n",
      "[save] cnt_anomaly\\out\\novelty_gallery_20251017-014831.html\n",
      "\n",
      "== First novel/semi-novel candidate(s) ==\n",
      "            AllWISE    novelty    W1-W2  W2-W3  best_votes SIMBAD_type NED_type    NED_z\n",
      "J035714.44-493202.7 SEMI-NOVEL 0.273001  2.774           4                    G 0.143159\n"
     ]
    }
   ],
   "source": [
    "# CNT Novelty Hunter v2 — high-lat fields, galaxy bias, Gaia star-reject, tighter novelty\n",
    "# Stops as soon as it finds ≥1 truly unlabeled (or untyped) multiscale-confirmed gold.\n",
    "\n",
    "import os, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "# --- tame timeouts to avoid hangs\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED:\n",
    "    Ned.TIMEOUT = 20\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ======= knobs (tuned for \"find me a novel one\") =======\n",
    "SIMBAD_NED_RADIUS_ARCSEC = 3.0     # tighter than before (was 5\")\n",
    "GAIA_STAR_REJECT_ARCSEC  = 2.0\n",
    "GAIA_PARALLAX_MAS_MIN    = 1.0     # >1 mas likely nearby star\n",
    "GAIA_PM_MASYR_MIN        = 20.0    # >20 mas/yr likely star\n",
    "W23_HOT_MIN              = 2.5     # very warm dust → galaxy-ish\n",
    "STOP_AFTER               = 1       # stop at the first novel/semi-novel hit\n",
    "\n",
    "# Field chooser: build a set of high-|b| centers automatically\n",
    "def high_lat_centers():\n",
    "    ras = np.arange(0, 360, 30)           # 12 slices\n",
    "    decs = np.array([-50, -40, +50, +60]) # hemispheres, high-lat\n",
    "    centers=[]\n",
    "    for ra in ras:\n",
    "        for dec in decs:\n",
    "            c = SkyCoord(ra*u.deg, dec*u.deg, frame=\"icrs\")\n",
    "            b = c.galactic.b.deg\n",
    "            if abs(b) >= 45:  # prefer |b|≥45°\n",
    "                centers.append((float(ra), float(dec)))\n",
    "    # a few curated southern extras where PS1/SDSS are sparser\n",
    "    centers += [(30.0,-35.0), (90.0,-30.0), (150.0,-35.0), (270.0,-35.0)]\n",
    "    # de-dup while preserving order\n",
    "    seen=set(); chosen=[]\n",
    "    for c in centers:\n",
    "        if c not in seen: seen.add(c); chosen.append(c)\n",
    "    return chosen\n",
    "\n",
    "# Gaia star-reject around a position\n",
    "def gaia_star_like(ra, dec):\n",
    "    try:\n",
    "        g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\"]).query_region(\n",
    "            SkyCoord(ra*u.deg, dec*u.deg), radius=GAIA_STAR_REJECT_ARCSEC*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    if not g or len(g[0])==0: \n",
    "        return False\n",
    "    df = g[0].to_pandas()\n",
    "    par_ok = (df.get(\"parallax\", pd.Series([])).astype(float) >= GAIA_PARALLAX_MAS_MIN).any()\n",
    "    pm_ok  = (np.hypot(df.get(\"pmRA\", pd.Series([])).astype(float),\n",
    "                       df.get(\"pmDE\", pd.Series([])).astype(float)) >= GAIA_PM_MASYR_MIN).any()\n",
    "    return bool(par_ok or pm_ok)\n",
    "\n",
    "def allwise_exact(wid):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wid))\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    r = q[0].to_pandas().iloc[0]\n",
    "    ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "    w1, w2, w3 = r.get(\"W1mag\", np.nan), r.get(\"W2mag\", np.nan), r.get(\"W3mag\", np.nan)\n",
    "    w12 = (w1 - w2) if pd.notna(w1) and pd.notna(w2) else np.nan\n",
    "    w23 = (w2 - w3) if pd.notna(w2) and pd.notna(w3) else np.nan\n",
    "    ext = str(r.get(\"ext_flg\",\"\"))\n",
    "    return dict(ra=ra, dec=dec, w12=w12, w23=w23, ext_flg=ext)\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD within 3\"\n",
    "    try:\n",
    "        s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "    except Exception:\n",
    "        s = None\n",
    "    sim_hit = (s is not None and len(s)>0)\n",
    "    sim_type = \"\" if not sim_hit else str(s.to_pandas().iloc[0].get(\"OTYPE\",\"\"))\n",
    "    # NED within 3\"\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try:\n",
    "            n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "        except Exception:\n",
    "            n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]\n",
    "            ned_hit = True; ned_type = str(p.get(\"Type\",\"\")); ned_z = str(p.get(\"Redshift\",\"\"))\n",
    "    # verdict\n",
    "    sim_u = sim_type.upper(); ned_u = ned_type.upper()\n",
    "    typed = any(k in (sim_u+\" \"+ned_u) for k in [\"GALAXY\",\"AGN\",\"QSO\"])\n",
    "    if not sim_hit and not ned_hit:\n",
    "        return \"NOVEL\", 2, sim_type, ned_type, ned_z\n",
    "    if not typed:\n",
    "        return \"SEMI-NOVEL\", 1, sim_type, ned_type, ned_z\n",
    "    return \"KNOWN\", 0, sim_type, ned_type, ned_z\n",
    "\n",
    "def novelty_hunt_v2():\n",
    "    global CFG\n",
    "    hits=[]\n",
    "    centers = high_lat_centers()\n",
    "    print(f\"[scan] centers={len(centers)} (high |b|) …\")\n",
    "    for (cra, cdec) in centers:\n",
    "        # fast configuration tweaks for “galaxy-first”\n",
    "        CFG[\"CENTER_RA\"] = float(cra)\n",
    "        CFG[\"CENTER_DEC\"] = float(cdec)\n",
    "        CFG[\"GRID_SIZE\"] = 4            # 4×4 around each center (16 tiles)\n",
    "        CFG[\"GRID_STEP_DEG\"] = 1.2\n",
    "        CFG[\"RADIUS_DEG\"] = 0.8\n",
    "        CFG[\"N_MAX\"] = 2500\n",
    "        CFG[\"K_DISC\"] = 3\n",
    "        CFG[\"K_GOLD\"] = 4\n",
    "        CFG[\"GOLD_W23_MIN\"] = 1.6       # stricter dust gate\n",
    "        CFG[\"GALAXY_MODE\"] = True\n",
    "\n",
    "        stamp, master, tiles, _ = discovery_sweep()\n",
    "        enr, base, gold, *_ = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] no gold.\")\n",
    "            continue\n",
    "\n",
    "        # Pre-verify galaxy bias: keep W2-W3 >= 2.5 or extended flag\n",
    "        gold = gold[(gold[\"W2-W3\"].fillna(-99) >= W23_HOT_MIN) | (gold.get(\"ext_flg\",\"\").astype(str) != \"0\")].copy()\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] gold none after galaxy-bias filter.\")\n",
    "            continue\n",
    "\n",
    "        ver, _ = multiscale_verify(gold, stamp)\n",
    "        conf = ver[ver[\"pass_multiscale\"] == True].copy()\n",
    "        if conf.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] none multiscale-confirmed.\")\n",
    "            continue\n",
    "\n",
    "        # Novelty + Gaia star-reject\n",
    "        out_rows=[]\n",
    "        for _, r in conf.iterrows():\n",
    "            wid = str(r[\"AllWISE\"])\n",
    "            ex = allwise_exact(wid)\n",
    "            if ex is None: \n",
    "                continue\n",
    "            ra, dec = ex[\"ra\"], ex[\"dec\"]\n",
    "            # star-reject\n",
    "            if gaia_star_like(ra, dec):\n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra, dec)\n",
    "            out_rows.append({\n",
    "                \"AllWISE\": wid, \"RA\": ra, \"Dec\": dec,\n",
    "                \"W1-W2\": ex[\"w12\"], \"W2-W3\": ex[\"w23\"], \"ext_flg\": ex[\"ext_flg\"],\n",
    "                \"best_votes\": int(r.get(\"best_votes\", np.nan)) if pd.notna(r.get(\"best_votes\", np.nan)) else np.nan,\n",
    "                \"novelty\": verdict, \"novelty_rank\": rank,\n",
    "                \"SIMBAD_type\": sim_t, \"NED_type\": ned_t, \"NED_z\": ned_z,\n",
    "                \"run_stamp\": stamp\n",
    "            })\n",
    "\n",
    "        if not out_rows:\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(out_rows).sort_values([\"novelty_rank\",\"best_votes\"], ascending=[False,False])\n",
    "        out_csv = OUT / f\"novelty_hits_{stamp}.csv\"\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"[save] {out_csv} (N={len(df)})\")\n",
    "\n",
    "        # stop at first novel/semi-novel\n",
    "        novel = df[df[\"novelty_rank\"] >= 1]\n",
    "        if not novel.empty:\n",
    "            # make quick dossiers + gallery\n",
    "            cards=[]\n",
    "            for wid in novel[\"AllWISE\"].tolist():\n",
    "                d = make_dossier(wid, stamp)\n",
    "                cards.append((wid, d))\n",
    "            html = OUT / f\"novelty_gallery_{stamp}.html\"\n",
    "            with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(\"<html><head><meta charset='utf-8'><title>CNT Novelty Gallery</title>\"\n",
    "                        \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                        \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                f.write(f\"<h1>Novelty — {stamp}</h1>\")\n",
    "                for wid, dd in cards:\n",
    "                    f.write(\"<div class='card'>\")\n",
    "                    if dd and dd.get(\"cutout\") and Path(dd[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(dd['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if dd and dd.get(\"sed\") and Path(dd[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(dd['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(dd['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div>\")\n",
    "                f.write(\"</body></html>\")\n",
    "            print(f\"[save] {html}\")\n",
    "            print(\"\\n== First novel/semi-novel candidate(s) ==\")\n",
    "            print(novel[[\"AllWISE\",\"novelty\",\"W1-W2\",\"W2-W3\",\"best_votes\",\"SIMBAD_type\",\"NED_type\",\"NED_z\"]].to_string(index=False))\n",
    "            break\n",
    "    else:\n",
    "        print(\"\\n[done] Scanned all centers—no novel hits at current gates. Consider raising N_MAX or widening centers.\")\n",
    "\n",
    "novelty_hunt_v2()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b048214d-d09d-4445-8aba-99e22059f105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[JWST] J035714.44-493202.7  RA=59.310192  Dec=-49.534106\n",
      "  no JWST coverage within 60″\n"
     ]
    }
   ],
   "source": [
    "# JWST quicklook for one ID → WISE J035714.44-493202.7\n",
    "import warnings, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import astropy.units as u\n",
    "from astropy.io import fits\n",
    "from astropy.nddata import Cutout2D\n",
    "from astropy.wcs import WCS\n",
    "from astropy.coordinates import SkyCoord\n",
    "import matplotlib.pyplot as plt\n",
    "from astroquery.mast import Observations\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); JW = OUT/\"jwst\"; JW.mkdir(parents=True, exist_ok=True)\n",
    "wid = \"J035714.44-493202.7\"\n",
    "\n",
    "Vizier.ROW_LIMIT = -1\n",
    "aw = Vizier(columns=[\"AllWISE\",\"RAJ2000\",\"DEJ2000\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)[0].to_pandas().iloc[0]\n",
    "ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "coord = SkyCoord(ra*u.deg, dec*u.deg)\n",
    "print(f\"[JWST] {wid}  RA={ra:.6f}  Dec={dec:.6f}\")\n",
    "\n",
    "obs = Observations.query_criteria(coordinates=coord, radius=60*u.arcsec,\n",
    "                                  obs_collection=\"JWST\", dataproduct_type=[\"image\",\"spectrum\"])\n",
    "if len(obs)==0:\n",
    "    print(\"  no JWST coverage within 60″\"); \n",
    "else:\n",
    "    prods = Observations.get_product_list(obs)\n",
    "    prods = Observations.filter_products(prods, productType=[\"SCIENCE\",\"PREVIEW\"], mrp_only=False).to_pandas()\n",
    "    if prods.empty:\n",
    "        print(\"  products none/public-none\")\n",
    "    else:\n",
    "        prods[\"score\"] = prods[\"productFilename\"].str.lower().str.contains(\"i2d|s2d|mosaic|driz\").astype(int)*5 \\\n",
    "                         + prods[\"productFilename\"].str.lower().str.endswith((\"fits\",\"fit\",\"fz\")).astype(int)*3\n",
    "        prods = prods.sort_values(\"score\", ascending=False).head(3)\n",
    "        outdir = JW / wid; outdir.mkdir(exist_ok=True, parents=True)\n",
    "        dl = Observations.download_products(prods, mrp_only=False, download_dir=str(outdir)).to_pandas()\n",
    "        for p in dl.get(\"Local Path\", []):\n",
    "            pth = Path(p)\n",
    "            if pth.suffix.lower() in [\".jpg\",\".jpeg\",\".png\"]:\n",
    "                (outdir/f\"{pth.stem}_preview.png\").write_bytes(pth.read_bytes())\n",
    "                print(\"  saved:\", pth.name)\n",
    "            else:\n",
    "                try:\n",
    "                    with fits.open(p) as hdul:\n",
    "                        sci = next((h for h in hdul if getattr(h, \"data\", None) is not None and WCS(h.header).has_celestial), None)\n",
    "                        if sci is None: \n",
    "                            continue\n",
    "                        w = WCS(sci.header); pix = np.abs(w.proj_plane_pixel_scales()).mean()*3600.0\n",
    "                        size = max(10, int(15.0/pix))\n",
    "                        cut = Cutout2D(sci.data, position=coord, size=(size,size), wcs=w, mode=\"partial\")\n",
    "                        plt.figure(figsize=(3,3)); plt.imshow(cut.data, origin=\"lower\", cmap=\"gray\")\n",
    "                        plt.axis(\"off\"); plt.tight_layout(pad=0)\n",
    "                        outpng = outdir/f\"{pth.stem}_cutout.png\"; plt.savefig(outpng, dpi=180, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "                        print(\"  saved:\", outpng.name)\n",
    "                except Exception as e:\n",
    "                    print(\"  fitscut fail:\", pth.name, e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "afdef2f7-77bc-4d90-9289-5598ae102617",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'WindowsPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mastroquery\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mirsa\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Irsa\n\u001b[32m     11\u001b[39m OUT = Path(\u001b[33m\"\u001b[39m\u001b[33m./cnt_anomaly/out\u001b[39m\u001b[33m\"\u001b[39m); FIG = OUT/\u001b[33m\"\u001b[39m\u001b[33mfigures\u001b[39m\u001b[33m\"\u001b[39m; FIG.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m ra, dec =  (\u001b[38;5;28;01mlambda\u001b[39;00m r: (\u001b[38;5;28mfloat\u001b[39m(r[\u001b[33m\"\u001b[39m\u001b[33mRAJ2000\u001b[39m\u001b[33m\"\u001b[39m]), \u001b[38;5;28mfloat\u001b[39m(r[\u001b[33m\"\u001b[39m\u001b[33mDEJ2000\u001b[39m\u001b[33m\"\u001b[39m])))(pd.read_csv(\u001b[43mOUT\u001b[49m\u001b[43m/\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstable_enriched_all_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m+\u001b[49m\u001b[38;5;28;43msorted\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstem\u001b[49m\u001b[43m.\u001b[49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mOUT\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglob\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstable_enriched_all_*.csv\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43ms\u001b[49m\u001b[43m:\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m+\u001b[33m\"\u001b[39m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m, usecols=[\u001b[33m\"\u001b[39m\u001b[33mRAJ2000\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mDEJ2000\u001b[39m\u001b[33m\"\u001b[39m]).iloc[\u001b[32m0\u001b[39m])\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# DSS2 cutout + crude concentration/FWHM\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfetch_cut\u001b[39m(ra, dec, fov=\u001b[32m2.0\u001b[39m):\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'WindowsPath' and 'str'"
     ]
    }
   ],
   "source": [
    "# Quick morphology + neighborhood for J035714.44-493202.7 (DSS2 + 2MASS XSC)\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "import matplotlib.pyplot as plt\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.irsa import Irsa\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "ra, dec =  (lambda r: (float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])))(pd.read_csv(OUT/\"stable_enriched_all_\"+sorted([p.stem.split(\"_\")[-1] for p in OUT.glob(\"stable_enriched_all_*.csv\")], key=lambda s:s)[-1]+\".csv\", usecols=[\"RAJ2000\",\"DEJ2000\"]).iloc[0])\n",
    "\n",
    "# DSS2 cutout + crude concentration/FWHM\n",
    "def fetch_cut(ra, dec, fov=2.0):\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"], pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "        if imgs:\n",
    "            a = imgs[0][0].data.astype(np.float32)\n",
    "            img = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            H,W = img.shape; y0,x0 = H//2, W//2\n",
    "            yy,xx = np.indices(img.shape); r = np.hypot(yy-y0, xx-x0)\n",
    "            bg = np.median(img[(r>80)&(r<110)]); dat = np.clip(img-bg,0,None)\n",
    "            rin,rout = 6,20; fin = dat[r<=rin].sum(); fout = dat[r<=rout].sum()\n",
    "            conc = fin/max(fout,1e-6); tot = dat.sum(); r2 = ((r**2)*dat).sum()/max(tot,1e-6)\n",
    "            fwhm = 2.355*np.sqrt(r2/2.0)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(img, origin=\"lower\", cmap=\"gray\"); plt.axis(\"off\")\n",
    "            out = FIG/\"J03571444-4932027_DSS2.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "            return conc, fwhm, str(out)\n",
    "    except Exception: pass\n",
    "    return np.nan, np.nan, \"\"\n",
    "\n",
    "conc, fwhm, png = fetch_cut(ra, dec)\n",
    "\n",
    "# 2MASS XSC hit (extended near-IR)\n",
    "Irsa.TIMEOUT=30\n",
    "xsc = Irsa.query_region(SkyCoord(ra*u.deg, dec*u.deg), catalog=\"fp_xsc\", radius=10*u.arcsec)\n",
    "xsc_hit = (xsc is not None and len(xsc)>0)\n",
    "\n",
    "print(f\"Concentration≈{conc:.3f}  FWHM(px)≈{fwhm:.2f}  2MASS_XSC_extended={bool(xsc_hit)}\")\n",
    "print(\"Cutout:\", png if png else \"(none)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "09b37506-0b17-4032-93fe-0c7d8109c8e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RA=59.310192  Dec=-49.534106\n",
      "Concentration ≈ 0.090   FWHM(px) ≈ 333.66   2MASS_XSC_extended = True\n",
      "Cutout: cnt_anomaly\\out\\figures\\J03571444m4932027_DSS2.png\n"
     ]
    }
   ],
   "source": [
    "# Robust morphology + 2MASS check for a specific AllWISE ID\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from astroquery.skyview import SkyView\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.irsa import Irsa\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); FIG = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "WISE_ID = \"J035714.44-493202.7\"  # <- our semi-novel gold\n",
    "\n",
    "def get_ra_dec_from_local_or_vizier(wid: str):\n",
    "    \"\"\"Try latest stable_enriched_all_*.csv for RA/Dec; fallback to Vizier II/328/allwise.\"\"\"\n",
    "    try:\n",
    "        latest = max(OUT.glob(\"stable_enriched_all_*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "        df = pd.read_csv(latest)\n",
    "        if {\"AllWISE\",\"RAJ2000\",\"DEJ2000\"}.issubset(df.columns):\n",
    "            row = df[df[\"AllWISE\"].astype(str).str.strip() == wid].head(1)\n",
    "            if not row.empty:\n",
    "                return float(row[\"RAJ2000\"].iloc[0]), float(row[\"DEJ2000\"].iloc[0])\n",
    "    except Exception:\n",
    "        pass\n",
    "    # fallback to Vizier\n",
    "    Vizier.ROW_LIMIT = 1\n",
    "    q = Vizier(columns=[\"AllWISE\",\"RAJ2000\",\"DEJ2000\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "    if len(q)==0 or len(q[0])==0:\n",
    "        raise RuntimeError(f\"Could not resolve RA/Dec for {wid}\")\n",
    "    r = q[0].to_pandas().iloc[0]\n",
    "    return float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "\n",
    "def fetch_dss2_cutout(ra, dec, fov_arcmin=2.0):\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                  pixels=512, height=fov_arcmin*u.arcmin, width=fov_arcmin*u.arcmin)\n",
    "        if not imgs: return np.nan, np.nan, \"\"\n",
    "        a = imgs[0][0].data.astype(np.float32)\n",
    "        img = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a), 0, 1)\n",
    "        H,W = img.shape; y0,x0 = H//2, W//2\n",
    "        yy,xx = np.indices(img.shape); r = np.hypot(yy-y0, xx-x0)\n",
    "        bg = np.median(img[(r>80)&(r<110)]); dat = np.clip(img-bg, 0, None)\n",
    "        rin, rout = 6, 20\n",
    "        fin  = dat[r<=rin].sum()\n",
    "        fout = dat[r<=rout].sum()\n",
    "        conc = fin / max(fout, 1e-6)\n",
    "        tot = dat.sum()\n",
    "        r2  = ((r**2)*dat).sum() / max(tot, 1e-6)\n",
    "        fwhm = 2.355 * np.sqrt(r2/2.0)\n",
    "        outpng = FIG / f\"{WISE_ID.replace('.','').replace('+','p').replace('-','m')}_DSS2.png\"\n",
    "        plt.figure(figsize=(3.2,3.2)); plt.imshow(img, origin=\"lower\", cmap=\"gray\")\n",
    "        plt.axis(\"off\"); plt.tight_layout(pad=0); plt.savefig(outpng, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "        return conc, fwhm, str(outpng)\n",
    "    except Exception:\n",
    "        return np.nan, np.nan, \"\"\n",
    "\n",
    "# 1) Resolve RA/Dec safely\n",
    "ra, dec = get_ra_dec_from_local_or_vizier(WISE_ID)\n",
    "\n",
    "# 2) DSS2 cutout + crude morphology\n",
    "conc, fwhm, png = fetch_dss2_cutout(ra, dec, fov_arcmin=2.0)\n",
    "\n",
    "# 3) 2MASS XSC extended-source hit\n",
    "Irsa.TIMEOUT = 30\n",
    "try:\n",
    "    xsc = Irsa.query_region(SkyCoord(ra*u.deg, dec*u.deg), catalog=\"fp_xsc\", radius=10*u.arcsec)\n",
    "    xsc_hit = (xsc is not None and len(xsc)>0)\n",
    "except Exception:\n",
    "    xsc_hit = False\n",
    "\n",
    "print(f\"RA={ra:.6f}  Dec={dec:.6f}\")\n",
    "print(f\"Concentration ≈ {conc:.3f}   FWHM(px) ≈ {fwhm:.2f}   2MASS_XSC_extended = {bool(xsc_hit)}\")\n",
    "print(\"Cutout:\", png if png else \"(none)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "adb406f8-341f-4bb4-9f09-776f89cd8b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[southern-deep] centers=18  (δ≤−35°, |b|≥50°)\n",
      "[tile 1/25] RA=-1.200 Dec=-61.200\n",
      "[tile 2/25] RA=-0.600 Dec=-61.200\n",
      "[tile 3/25] RA=0.000 Dec=-61.200\n",
      "[tile 4/25] RA=0.600 Dec=-61.200\n",
      "[tile 5/25] RA=1.200 Dec=-61.200\n",
      "[tile 6/25] RA=-1.200 Dec=-60.600\n",
      "[tile 7/25] RA=-0.600 Dec=-60.600\n",
      "[tile 8/25] RA=0.000 Dec=-60.600\n",
      "[tile 9/25] RA=0.600 Dec=-60.600\n",
      "[tile 10/25] RA=1.200 Dec=-60.600\n",
      "[tile 11/25] RA=-1.200 Dec=-60.000\n",
      "[tile 12/25] RA=-0.600 Dec=-60.000\n",
      "[tile 13/25] RA=0.000 Dec=-60.000\n",
      "[tile 14/25] RA=0.600 Dec=-60.000\n",
      "[tile 15/25] RA=1.200 Dec=-60.000\n",
      "[tile 16/25] RA=-1.200 Dec=-59.400\n",
      "[tile 17/25] RA=-0.600 Dec=-59.400\n",
      "[tile 18/25] RA=0.000 Dec=-59.400\n",
      "[tile 19/25] RA=0.600 Dec=-59.400\n",
      "[tile 20/25] RA=1.200 Dec=-59.400\n",
      "[tile 21/25] RA=-1.200 Dec=-58.800\n",
      "[tile 22/25] RA=-0.600 Dec=-58.800\n",
      "[tile 23/25] RA=0.000 Dec=-58.800\n",
      "[tile 24/25] RA=0.600 Dec=-58.800\n",
      "[tile 25/25] RA=1.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-020054.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-020054.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-020054.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-020054.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-020054.csv (N=1)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-020054.csv\n",
      "[0.0,-60.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=22.800 Dec=-61.200\n",
      "[tile 2/25] RA=23.400 Dec=-61.200\n",
      "[tile 3/25] RA=24.000 Dec=-61.200\n",
      "[tile 4/25] RA=24.600 Dec=-61.200\n",
      "[tile 5/25] RA=25.200 Dec=-61.200\n",
      "[tile 6/25] RA=22.800 Dec=-60.600\n",
      "[tile 7/25] RA=23.400 Dec=-60.600\n",
      "[tile 8/25] RA=24.000 Dec=-60.600\n",
      "[tile 9/25] RA=24.600 Dec=-60.600\n",
      "[tile 10/25] RA=25.200 Dec=-60.600\n",
      "[tile 11/25] RA=22.800 Dec=-60.000\n",
      "[tile 12/25] RA=23.400 Dec=-60.000\n",
      "[tile 13/25] RA=24.000 Dec=-60.000\n",
      "[tile 14/25] RA=24.600 Dec=-60.000\n",
      "[tile 15/25] RA=25.200 Dec=-60.000\n",
      "[tile 16/25] RA=22.800 Dec=-59.400\n",
      "[tile 17/25] RA=23.400 Dec=-59.400\n",
      "[tile 18/25] RA=24.000 Dec=-59.400\n",
      "[tile 19/25] RA=24.600 Dec=-59.400\n",
      "[tile 20/25] RA=25.200 Dec=-59.400\n",
      "[tile 21/25] RA=22.800 Dec=-58.800\n",
      "[tile 22/25] RA=23.400 Dec=-58.800\n",
      "[tile 23/25] RA=24.000 Dec=-58.800\n",
      "[tile 24/25] RA=24.600 Dec=-58.800\n",
      "[tile 25/25] RA=25.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-020346.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-020346.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-020346.csv (N=28)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-020346.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-020346.csv (N=0)\n",
      "[24.0,-60.0] no gold.\n",
      "[tile 1/25] RA=-1.200 Dec=-56.200\n",
      "[tile 2/25] RA=-0.600 Dec=-56.200\n",
      "[tile 3/25] RA=0.000 Dec=-56.200\n",
      "[tile 4/25] RA=0.600 Dec=-56.200\n",
      "[tile 5/25] RA=1.200 Dec=-56.200\n",
      "[tile 6/25] RA=-1.200 Dec=-55.600\n",
      "[tile 7/25] RA=-0.600 Dec=-55.600\n",
      "[tile 8/25] RA=0.000 Dec=-55.600\n",
      "[tile 9/25] RA=0.600 Dec=-55.600\n",
      "[tile 10/25] RA=1.200 Dec=-55.600\n",
      "[tile 11/25] RA=-1.200 Dec=-55.000\n",
      "[tile 12/25] RA=-0.600 Dec=-55.000\n",
      "[tile 13/25] RA=0.000 Dec=-55.000\n",
      "[tile 14/25] RA=0.600 Dec=-55.000\n",
      "[tile 15/25] RA=1.200 Dec=-55.000\n",
      "[tile 16/25] RA=-1.200 Dec=-54.400\n",
      "[tile 17/25] RA=-0.600 Dec=-54.400\n",
      "[tile 18/25] RA=0.000 Dec=-54.400\n",
      "[tile 19/25] RA=0.600 Dec=-54.400\n",
      "[tile 20/25] RA=1.200 Dec=-54.400\n",
      "[tile 21/25] RA=-1.200 Dec=-53.800\n",
      "[tile 22/25] RA=-0.600 Dec=-53.800\n",
      "[tile 23/25] RA=0.000 Dec=-53.800\n",
      "[tile 24/25] RA=0.600 Dec=-53.800\n",
      "[tile 25/25] RA=1.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-020633.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-020633.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-020633.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-020633.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-020633.csv (N=1)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-020633.csv\n",
      "[0.0,-55.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=22.800 Dec=-56.200\n",
      "[tile 2/25] RA=23.400 Dec=-56.200\n",
      "[tile 3/25] RA=24.000 Dec=-56.200\n",
      "[tile 4/25] RA=24.600 Dec=-56.200\n",
      "[tile 5/25] RA=25.200 Dec=-56.200\n",
      "[tile 6/25] RA=22.800 Dec=-55.600\n",
      "[tile 7/25] RA=23.400 Dec=-55.600\n",
      "[tile 8/25] RA=24.000 Dec=-55.600\n",
      "[tile 9/25] RA=24.600 Dec=-55.600\n",
      "[tile 10/25] RA=25.200 Dec=-55.600\n",
      "[tile 11/25] RA=22.800 Dec=-55.000\n",
      "[tile 12/25] RA=23.400 Dec=-55.000\n",
      "[tile 13/25] RA=24.000 Dec=-55.000\n",
      "[tile 14/25] RA=24.600 Dec=-55.000\n",
      "[tile 15/25] RA=25.200 Dec=-55.000\n",
      "[tile 16/25] RA=22.800 Dec=-54.400\n",
      "[tile 17/25] RA=23.400 Dec=-54.400\n",
      "[tile 18/25] RA=24.000 Dec=-54.400\n",
      "[tile 19/25] RA=24.600 Dec=-54.400\n",
      "[tile 20/25] RA=25.200 Dec=-54.400\n",
      "[tile 21/25] RA=22.800 Dec=-53.800\n",
      "[tile 22/25] RA=23.400 Dec=-53.800\n",
      "[tile 23/25] RA=24.000 Dec=-53.800\n",
      "[tile 24/25] RA=24.600 Dec=-53.800\n",
      "[tile 25/25] RA=25.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-020926.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-020926.csv (N=26)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-020926.csv (N=24)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-020926.csv (N=24)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-020926.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-020926.csv\n",
      "[24.0,-55.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=46.800 Dec=-56.200\n",
      "[tile 2/25] RA=47.400 Dec=-56.200\n",
      "[tile 3/25] RA=48.000 Dec=-56.200\n",
      "[tile 4/25] RA=48.600 Dec=-56.200\n",
      "[tile 5/25] RA=49.200 Dec=-56.200\n",
      "[tile 6/25] RA=46.800 Dec=-55.600\n",
      "[tile 7/25] RA=47.400 Dec=-55.600\n",
      "[tile 8/25] RA=48.000 Dec=-55.600\n",
      "[tile 9/25] RA=48.600 Dec=-55.600\n",
      "[tile 10/25] RA=49.200 Dec=-55.600\n",
      "[tile 11/25] RA=46.800 Dec=-55.000\n",
      "[tile 12/25] RA=47.400 Dec=-55.000\n",
      "[tile 13/25] RA=48.000 Dec=-55.000\n",
      "[tile 14/25] RA=48.600 Dec=-55.000\n",
      "[tile 15/25] RA=49.200 Dec=-55.000\n",
      "[tile 16/25] RA=46.800 Dec=-54.400\n",
      "[tile 17/25] RA=47.400 Dec=-54.400\n",
      "[tile 18/25] RA=48.000 Dec=-54.400\n",
      "[tile 19/25] RA=48.600 Dec=-54.400\n",
      "[tile 20/25] RA=49.200 Dec=-54.400\n",
      "[tile 21/25] RA=46.800 Dec=-53.800\n",
      "[tile 22/25] RA=47.400 Dec=-53.800\n",
      "[tile 23/25] RA=48.000 Dec=-53.800\n",
      "[tile 24/25] RA=48.600 Dec=-53.800\n",
      "[tile 25/25] RA=49.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-021222.csv (N=29)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-021222.csv (N=27)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-021222.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-021222.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-021222.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-021222.csv\n",
      "[48.0,-55.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=334.800 Dec=-56.200\n",
      "[tile 2/25] RA=335.400 Dec=-56.200\n",
      "[tile 3/25] RA=336.000 Dec=-56.200\n",
      "[tile 4/25] RA=336.600 Dec=-56.200\n",
      "[tile 5/25] RA=337.200 Dec=-56.200\n",
      "[tile 6/25] RA=334.800 Dec=-55.600\n",
      "[tile 7/25] RA=335.400 Dec=-55.600\n",
      "[tile 8/25] RA=336.000 Dec=-55.600\n",
      "[tile 9/25] RA=336.600 Dec=-55.600\n",
      "[tile 10/25] RA=337.200 Dec=-55.600\n",
      "[tile 11/25] RA=334.800 Dec=-55.000\n",
      "[tile 12/25] RA=335.400 Dec=-55.000\n",
      "[tile 13/25] RA=336.000 Dec=-55.000\n",
      "[tile 14/25] RA=336.600 Dec=-55.000\n",
      "[tile 15/25] RA=337.200 Dec=-55.000\n",
      "[tile 16/25] RA=334.800 Dec=-54.400\n",
      "[tile 17/25] RA=335.400 Dec=-54.400\n",
      "[tile 18/25] RA=336.000 Dec=-54.400\n",
      "[tile 19/25] RA=336.600 Dec=-54.400\n",
      "[tile 20/25] RA=337.200 Dec=-54.400\n",
      "[tile 21/25] RA=334.800 Dec=-53.800\n",
      "[tile 22/25] RA=335.400 Dec=-53.800\n",
      "[tile 23/25] RA=336.000 Dec=-53.800\n",
      "[tile 24/25] RA=336.600 Dec=-53.800\n",
      "[tile 25/25] RA=337.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-021517.csv (N=34)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-021517.csv (N=33)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-021517.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-021517.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-021517.csv (N=0)\n",
      "[336.0,-55.0] no gold.\n",
      "[tile 1/25] RA=-1.200 Dec=-51.200\n",
      "[tile 2/25] RA=-0.600 Dec=-51.200\n",
      "[tile 3/25] RA=0.000 Dec=-51.200\n",
      "[tile 4/25] RA=0.600 Dec=-51.200\n",
      "[tile 5/25] RA=1.200 Dec=-51.200\n",
      "[tile 6/25] RA=-1.200 Dec=-50.600\n",
      "[tile 7/25] RA=-0.600 Dec=-50.600\n",
      "[tile 8/25] RA=0.000 Dec=-50.600\n",
      "  [skip] no xmatches\n",
      "[tile 9/25] RA=0.600 Dec=-50.600\n",
      "[tile 10/25] RA=1.200 Dec=-50.600\n",
      "[tile 11/25] RA=-1.200 Dec=-50.000\n",
      "[tile 12/25] RA=-0.600 Dec=-50.000\n",
      "[tile 13/25] RA=0.000 Dec=-50.000\n",
      "  [skip] no xmatches\n",
      "[tile 14/25] RA=0.600 Dec=-50.000\n",
      "[tile 15/25] RA=1.200 Dec=-50.000\n",
      "[tile 16/25] RA=-1.200 Dec=-49.400\n",
      "[tile 17/25] RA=-0.600 Dec=-49.400\n",
      "[tile 18/25] RA=0.000 Dec=-49.400\n",
      "  [skip] no xmatches\n",
      "[tile 19/25] RA=0.600 Dec=-49.400\n",
      "[tile 20/25] RA=1.200 Dec=-49.400\n",
      "[tile 21/25] RA=-1.200 Dec=-48.800\n",
      "[tile 22/25] RA=-0.600 Dec=-48.800\n",
      "[tile 23/25] RA=0.000 Dec=-48.800\n",
      "[tile 24/25] RA=0.600 Dec=-48.800\n",
      "[tile 25/25] RA=1.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-021811.csv (N=25)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-021811.csv (N=25)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-021811.csv (N=25)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-021811.csv (N=25)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-021811.csv (N=0)\n",
      "[0.0,-50.0] no gold.\n",
      "[tile 1/25] RA=22.800 Dec=-51.200\n",
      "[tile 2/25] RA=23.400 Dec=-51.200\n",
      "[tile 3/25] RA=24.000 Dec=-51.200\n",
      "[tile 4/25] RA=24.600 Dec=-51.200\n",
      "[tile 5/25] RA=25.200 Dec=-51.200\n",
      "[tile 6/25] RA=22.800 Dec=-50.600\n",
      "[tile 7/25] RA=23.400 Dec=-50.600\n",
      "[tile 8/25] RA=24.000 Dec=-50.600\n",
      "[tile 9/25] RA=24.600 Dec=-50.600\n",
      "[tile 10/25] RA=25.200 Dec=-50.600\n",
      "[tile 11/25] RA=22.800 Dec=-50.000\n",
      "[tile 12/25] RA=23.400 Dec=-50.000\n",
      "[tile 13/25] RA=24.000 Dec=-50.000\n",
      "[tile 14/25] RA=24.600 Dec=-50.000\n",
      "[tile 15/25] RA=25.200 Dec=-50.000\n",
      "[tile 16/25] RA=22.800 Dec=-49.400\n",
      "[tile 17/25] RA=23.400 Dec=-49.400\n",
      "[tile 18/25] RA=24.000 Dec=-49.400\n",
      "[tile 19/25] RA=24.600 Dec=-49.400\n",
      "[tile 20/25] RA=25.200 Dec=-49.400\n",
      "[tile 21/25] RA=22.800 Dec=-48.800\n",
      "[tile 22/25] RA=23.400 Dec=-48.800\n",
      "[tile 23/25] RA=24.000 Dec=-48.800\n",
      "[tile 24/25] RA=24.600 Dec=-48.800\n",
      "[tile 25/25] RA=25.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-022024.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-022024.csv (N=31)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-022024.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-022024.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-022024.csv (N=1)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-022024.csv\n",
      "[24.0,-50.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=46.800 Dec=-51.200\n",
      "[tile 2/25] RA=47.400 Dec=-51.200\n",
      "[tile 3/25] RA=48.000 Dec=-51.200\n",
      "[tile 4/25] RA=48.600 Dec=-51.200\n",
      "[tile 5/25] RA=49.200 Dec=-51.200\n",
      "[tile 6/25] RA=46.800 Dec=-50.600\n",
      "[tile 7/25] RA=47.400 Dec=-50.600\n",
      "[tile 8/25] RA=48.000 Dec=-50.600\n",
      "[tile 9/25] RA=48.600 Dec=-50.600\n",
      "[tile 10/25] RA=49.200 Dec=-50.600\n",
      "[tile 11/25] RA=46.800 Dec=-50.000\n",
      "[tile 12/25] RA=47.400 Dec=-50.000\n",
      "[tile 13/25] RA=48.000 Dec=-50.000\n",
      "[tile 14/25] RA=48.600 Dec=-50.000\n",
      "[tile 15/25] RA=49.200 Dec=-50.000\n",
      "[tile 16/25] RA=46.800 Dec=-49.400\n",
      "[tile 17/25] RA=47.400 Dec=-49.400\n",
      "[tile 18/25] RA=48.000 Dec=-49.400\n",
      "[tile 19/25] RA=48.600 Dec=-49.400\n",
      "[tile 20/25] RA=49.200 Dec=-49.400\n",
      "[tile 21/25] RA=46.800 Dec=-48.800\n",
      "[tile 22/25] RA=47.400 Dec=-48.800\n",
      "[tile 23/25] RA=48.000 Dec=-48.800\n",
      "[tile 24/25] RA=48.600 Dec=-48.800\n",
      "[tile 25/25] RA=49.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-022321.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-022321.csv (N=31)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-022321.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-022321.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-022321.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-022321.csv\n",
      "[48.0,-50.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=334.800 Dec=-51.200\n",
      "[tile 2/25] RA=335.400 Dec=-51.200\n",
      "[tile 3/25] RA=336.000 Dec=-51.200\n",
      "[tile 4/25] RA=336.600 Dec=-51.200\n",
      "[tile 5/25] RA=337.200 Dec=-51.200\n",
      "[tile 6/25] RA=334.800 Dec=-50.600\n",
      "[tile 7/25] RA=335.400 Dec=-50.600\n",
      "[tile 8/25] RA=336.000 Dec=-50.600\n",
      "[tile 9/25] RA=336.600 Dec=-50.600\n",
      "[tile 10/25] RA=337.200 Dec=-50.600\n",
      "[tile 11/25] RA=334.800 Dec=-50.000\n",
      "[tile 12/25] RA=335.400 Dec=-50.000\n",
      "[tile 13/25] RA=336.000 Dec=-50.000\n",
      "[tile 14/25] RA=336.600 Dec=-50.000\n",
      "[tile 15/25] RA=337.200 Dec=-50.000\n",
      "[tile 16/25] RA=334.800 Dec=-49.400\n",
      "[tile 17/25] RA=335.400 Dec=-49.400\n",
      "[tile 18/25] RA=336.000 Dec=-49.400\n",
      "[tile 19/25] RA=336.600 Dec=-49.400\n",
      "[tile 20/25] RA=337.200 Dec=-49.400\n",
      "[tile 21/25] RA=334.800 Dec=-48.800\n",
      "[tile 22/25] RA=335.400 Dec=-48.800\n",
      "[tile 23/25] RA=336.000 Dec=-48.800\n",
      "[tile 24/25] RA=336.600 Dec=-48.800\n",
      "[tile 25/25] RA=337.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-022622.csv (N=27)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-022622.csv (N=27)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-022622.csv (N=24)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-022622.csv (N=24)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-022622.csv (N=2)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-022622.csv\n",
      "[336.0,-50.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=-1.200 Dec=-46.200\n",
      "[tile 2/25] RA=-0.600 Dec=-46.200\n",
      "[tile 3/25] RA=0.000 Dec=-46.200\n",
      "[tile 4/25] RA=0.600 Dec=-46.200\n",
      "[tile 5/25] RA=1.200 Dec=-46.200\n",
      "[tile 6/25] RA=-1.200 Dec=-45.600\n",
      "[tile 7/25] RA=-0.600 Dec=-45.600\n",
      "[tile 8/25] RA=0.000 Dec=-45.600\n",
      "[tile 9/25] RA=0.600 Dec=-45.600\n",
      "[tile 10/25] RA=1.200 Dec=-45.600\n",
      "[tile 11/25] RA=-1.200 Dec=-45.000\n",
      "[tile 12/25] RA=-0.600 Dec=-45.000\n",
      "[tile 13/25] RA=0.000 Dec=-45.000\n",
      "[tile 14/25] RA=0.600 Dec=-45.000\n",
      "[tile 15/25] RA=1.200 Dec=-45.000\n",
      "[tile 16/25] RA=-1.200 Dec=-44.400\n",
      "[tile 17/25] RA=-0.600 Dec=-44.400\n",
      "[tile 18/25] RA=0.000 Dec=-44.400\n",
      "[tile 19/25] RA=0.600 Dec=-44.400\n",
      "[tile 20/25] RA=1.200 Dec=-44.400\n",
      "[tile 21/25] RA=-1.200 Dec=-43.800\n",
      "[tile 22/25] RA=-0.600 Dec=-43.800\n",
      "[tile 23/25] RA=0.000 Dec=-43.800\n",
      "[tile 24/25] RA=0.600 Dec=-43.800\n",
      "[tile 25/25] RA=1.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-022919.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-022919.csv (N=32)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-022919.csv (N=31)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-022919.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-022919.csv (N=1)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-022919.csv\n",
      "[0.0,-45.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=22.800 Dec=-46.200\n",
      "[tile 2/25] RA=23.400 Dec=-46.200\n",
      "[tile 3/25] RA=24.000 Dec=-46.200\n",
      "[tile 4/25] RA=24.600 Dec=-46.200\n",
      "[tile 5/25] RA=25.200 Dec=-46.200\n",
      "[tile 6/25] RA=22.800 Dec=-45.600\n",
      "[tile 7/25] RA=23.400 Dec=-45.600\n",
      "[tile 8/25] RA=24.000 Dec=-45.600\n",
      "[tile 9/25] RA=24.600 Dec=-45.600\n",
      "[tile 10/25] RA=25.200 Dec=-45.600\n",
      "[tile 11/25] RA=22.800 Dec=-45.000\n",
      "[tile 12/25] RA=23.400 Dec=-45.000\n",
      "[tile 13/25] RA=24.000 Dec=-45.000\n",
      "[tile 14/25] RA=24.600 Dec=-45.000\n",
      "[tile 15/25] RA=25.200 Dec=-45.000\n",
      "[tile 16/25] RA=22.800 Dec=-44.400\n",
      "[tile 17/25] RA=23.400 Dec=-44.400\n",
      "[tile 18/25] RA=24.000 Dec=-44.400\n",
      "[tile 19/25] RA=24.600 Dec=-44.400\n",
      "[tile 20/25] RA=25.200 Dec=-44.400\n",
      "[tile 21/25] RA=22.800 Dec=-43.800\n",
      "[tile 22/25] RA=23.400 Dec=-43.800\n",
      "[tile 23/25] RA=24.000 Dec=-43.800\n",
      "[tile 24/25] RA=24.600 Dec=-43.800\n",
      "[tile 25/25] RA=25.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-023219.csv (N=33)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-023219.csv (N=32)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-023219.csv (N=32)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-023219.csv (N=32)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-023219.csv (N=0)\n",
      "[24.0,-45.0] no gold.\n",
      "[tile 1/25] RA=46.800 Dec=-46.200\n",
      "[tile 2/25] RA=47.400 Dec=-46.200\n",
      "[tile 3/25] RA=48.000 Dec=-46.200\n",
      "[tile 4/25] RA=48.600 Dec=-46.200\n",
      "[tile 5/25] RA=49.200 Dec=-46.200\n",
      "[tile 6/25] RA=46.800 Dec=-45.600\n",
      "[tile 7/25] RA=47.400 Dec=-45.600\n",
      "[tile 8/25] RA=48.000 Dec=-45.600\n",
      "[tile 9/25] RA=48.600 Dec=-45.600\n",
      "[tile 10/25] RA=49.200 Dec=-45.600\n",
      "[tile 11/25] RA=46.800 Dec=-45.000\n",
      "[tile 12/25] RA=47.400 Dec=-45.000\n",
      "[tile 13/25] RA=48.000 Dec=-45.000\n",
      "[tile 14/25] RA=48.600 Dec=-45.000\n",
      "[tile 15/25] RA=49.200 Dec=-45.000\n",
      "[tile 16/25] RA=46.800 Dec=-44.400\n",
      "[tile 17/25] RA=47.400 Dec=-44.400\n",
      "[tile 18/25] RA=48.000 Dec=-44.400\n",
      "[tile 19/25] RA=48.600 Dec=-44.400\n",
      "[tile 20/25] RA=49.200 Dec=-44.400\n",
      "[tile 21/25] RA=46.800 Dec=-43.800\n",
      "[tile 22/25] RA=47.400 Dec=-43.800\n",
      "[tile 23/25] RA=48.000 Dec=-43.800\n",
      "[tile 24/25] RA=48.600 Dec=-43.800\n",
      "[tile 25/25] RA=49.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-023510.csv (N=28)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-023510.csv (N=26)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-023510.csv (N=24)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-023510.csv (N=25)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-023510.csv (N=0)\n",
      "[48.0,-45.0] no gold.\n",
      "[tile 1/25] RA=334.800 Dec=-46.200\n",
      "[tile 2/25] RA=335.400 Dec=-46.200\n",
      "[tile 3/25] RA=336.000 Dec=-46.200\n",
      "[tile 4/25] RA=336.600 Dec=-46.200\n",
      "[tile 5/25] RA=337.200 Dec=-46.200\n",
      "[tile 6/25] RA=334.800 Dec=-45.600\n",
      "[tile 7/25] RA=335.400 Dec=-45.600\n",
      "[tile 8/25] RA=336.000 Dec=-45.600\n",
      "[tile 9/25] RA=336.600 Dec=-45.600\n",
      "[tile 10/25] RA=337.200 Dec=-45.600\n",
      "[tile 11/25] RA=334.800 Dec=-45.000\n",
      "[tile 12/25] RA=335.400 Dec=-45.000\n",
      "[tile 13/25] RA=336.000 Dec=-45.000\n",
      "[tile 14/25] RA=336.600 Dec=-45.000\n",
      "[tile 15/25] RA=337.200 Dec=-45.000\n",
      "[tile 16/25] RA=334.800 Dec=-44.400\n",
      "[tile 17/25] RA=335.400 Dec=-44.400\n",
      "[tile 18/25] RA=336.000 Dec=-44.400\n",
      "[tile 19/25] RA=336.600 Dec=-44.400\n",
      "[tile 20/25] RA=337.200 Dec=-44.400\n",
      "[tile 21/25] RA=334.800 Dec=-43.800\n",
      "[tile 22/25] RA=335.400 Dec=-43.800\n",
      "[tile 23/25] RA=336.000 Dec=-43.800\n",
      "[tile 24/25] RA=336.600 Dec=-43.800\n",
      "[tile 25/25] RA=337.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-023752.csv (N=33)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-023752.csv (N=32)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-023752.csv (N=31)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-023752.csv (N=32)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-023752.csv (N=0)\n",
      "[336.0,-45.0] no gold.\n",
      "[tile 1/25] RA=-1.200 Dec=-41.200\n",
      "[tile 2/25] RA=-0.600 Dec=-41.200\n",
      "[tile 3/25] RA=0.000 Dec=-41.200\n",
      "[tile 4/25] RA=0.600 Dec=-41.200\n",
      "[tile 5/25] RA=1.200 Dec=-41.200\n",
      "[tile 6/25] RA=-1.200 Dec=-40.600\n",
      "[tile 7/25] RA=-0.600 Dec=-40.600\n",
      "[tile 8/25] RA=0.000 Dec=-40.600\n",
      "[tile 9/25] RA=0.600 Dec=-40.600\n",
      "[tile 10/25] RA=1.200 Dec=-40.600\n",
      "[tile 11/25] RA=-1.200 Dec=-40.000\n",
      "[tile 12/25] RA=-0.600 Dec=-40.000\n",
      "[tile 13/25] RA=0.000 Dec=-40.000\n",
      "[tile 14/25] RA=0.600 Dec=-40.000\n",
      "[tile 15/25] RA=1.200 Dec=-40.000\n",
      "[tile 16/25] RA=-1.200 Dec=-39.400\n",
      "[tile 17/25] RA=-0.600 Dec=-39.400\n",
      "[tile 18/25] RA=0.000 Dec=-39.400\n",
      "[tile 19/25] RA=0.600 Dec=-39.400\n",
      "[tile 20/25] RA=1.200 Dec=-39.400\n",
      "[tile 21/25] RA=-1.200 Dec=-38.800\n",
      "[tile 22/25] RA=-0.600 Dec=-38.800\n",
      "[tile 23/25] RA=0.000 Dec=-38.800\n",
      "[tile 24/25] RA=0.600 Dec=-38.800\n",
      "[tile 25/25] RA=1.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-024044.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-024044.csv (N=28)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-024044.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-024044.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-024044.csv (N=0)\n",
      "[0.0,-40.0] no gold.\n",
      "[tile 1/25] RA=22.800 Dec=-41.200\n",
      "[tile 2/25] RA=23.400 Dec=-41.200\n",
      "[tile 3/25] RA=24.000 Dec=-41.200\n",
      "[tile 4/25] RA=24.600 Dec=-41.200\n",
      "[tile 5/25] RA=25.200 Dec=-41.200\n",
      "[tile 6/25] RA=22.800 Dec=-40.600\n",
      "[tile 7/25] RA=23.400 Dec=-40.600\n",
      "[tile 8/25] RA=24.000 Dec=-40.600\n",
      "[tile 9/25] RA=24.600 Dec=-40.600\n",
      "[tile 10/25] RA=25.200 Dec=-40.600\n",
      "[tile 11/25] RA=22.800 Dec=-40.000\n",
      "[tile 12/25] RA=23.400 Dec=-40.000\n",
      "[tile 13/25] RA=24.000 Dec=-40.000\n",
      "[tile 14/25] RA=24.600 Dec=-40.000\n",
      "[tile 15/25] RA=25.200 Dec=-40.000\n",
      "[tile 16/25] RA=22.800 Dec=-39.400\n",
      "[tile 17/25] RA=23.400 Dec=-39.400\n",
      "[tile 18/25] RA=24.000 Dec=-39.400\n",
      "[tile 19/25] RA=24.600 Dec=-39.400\n",
      "[tile 20/25] RA=25.200 Dec=-39.400\n",
      "[tile 21/25] RA=22.800 Dec=-38.800\n",
      "[tile 22/25] RA=23.400 Dec=-38.800\n",
      "[tile 23/25] RA=24.000 Dec=-38.800\n",
      "[tile 24/25] RA=24.600 Dec=-38.800\n",
      "[tile 25/25] RA=25.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-024312.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-024312.csv (N=31)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-024312.csv (N=31)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-024312.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-024312.csv (N=1)\n",
      "[save] multiscale verify → cnt_anomaly\\out\\gold_verification_idlocked_multiscale_20251017-024312.csv\n",
      "[24.0,-40.0] none multiscale-confirmed.\n",
      "[tile 1/25] RA=46.800 Dec=-41.200\n",
      "[tile 2/25] RA=47.400 Dec=-41.200\n",
      "[tile 3/25] RA=48.000 Dec=-41.200\n",
      "[tile 4/25] RA=48.600 Dec=-41.200\n",
      "[tile 5/25] RA=49.200 Dec=-41.200\n",
      "[tile 6/25] RA=46.800 Dec=-40.600\n",
      "[tile 7/25] RA=47.400 Dec=-40.600\n",
      "[tile 8/25] RA=48.000 Dec=-40.600\n",
      "[tile 9/25] RA=48.600 Dec=-40.600\n",
      "[tile 10/25] RA=49.200 Dec=-40.600\n",
      "[tile 11/25] RA=46.800 Dec=-40.000\n",
      "[tile 12/25] RA=47.400 Dec=-40.000\n",
      "[tile 13/25] RA=48.000 Dec=-40.000\n",
      "[tile 14/25] RA=48.600 Dec=-40.000\n",
      "[tile 15/25] RA=49.200 Dec=-40.000\n",
      "[tile 16/25] RA=46.800 Dec=-39.400\n",
      "[tile 17/25] RA=47.400 Dec=-39.400\n",
      "[tile 18/25] RA=48.000 Dec=-39.400\n",
      "[tile 19/25] RA=48.600 Dec=-39.400\n",
      "[tile 20/25] RA=49.200 Dec=-39.400\n",
      "[tile 21/25] RA=46.800 Dec=-38.800\n",
      "[tile 22/25] RA=47.400 Dec=-38.800\n",
      "[tile 23/25] RA=48.000 Dec=-38.800\n",
      "[tile 24/25] RA=48.600 Dec=-38.800\n",
      "[tile 25/25] RA=49.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-024607.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-024607.csv (N=30)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-024607.csv (N=28)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-024607.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-024607.csv (N=0)\n",
      "[48.0,-40.0] no gold.\n",
      "[tile 1/25] RA=334.800 Dec=-41.200\n",
      "[tile 2/25] RA=335.400 Dec=-41.200\n",
      "[tile 3/25] RA=336.000 Dec=-41.200\n",
      "[tile 4/25] RA=336.600 Dec=-41.200\n",
      "[tile 5/25] RA=337.200 Dec=-41.200\n",
      "[tile 6/25] RA=334.800 Dec=-40.600\n",
      "[tile 7/25] RA=335.400 Dec=-40.600\n",
      "[tile 8/25] RA=336.000 Dec=-40.600\n",
      "[tile 9/25] RA=336.600 Dec=-40.600\n",
      "[tile 10/25] RA=337.200 Dec=-40.600\n",
      "[tile 11/25] RA=334.800 Dec=-40.000\n",
      "[tile 12/25] RA=335.400 Dec=-40.000\n",
      "[tile 13/25] RA=336.000 Dec=-40.000\n",
      "[tile 14/25] RA=336.600 Dec=-40.000\n",
      "[tile 15/25] RA=337.200 Dec=-40.000\n",
      "[tile 16/25] RA=334.800 Dec=-39.400\n",
      "[tile 17/25] RA=335.400 Dec=-39.400\n",
      "[tile 18/25] RA=336.000 Dec=-39.400\n",
      "[tile 19/25] RA=336.600 Dec=-39.400\n",
      "[tile 20/25] RA=337.200 Dec=-39.400\n",
      "[tile 21/25] RA=334.800 Dec=-38.800\n",
      "[tile 22/25] RA=335.400 Dec=-38.800\n",
      "[tile 23/25] RA=336.000 Dec=-38.800\n",
      "[tile 24/25] RA=336.600 Dec=-38.800\n",
      "[tile 25/25] RA=337.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-024855.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-024855.csv (N=28)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-024855.csv (N=28)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-024855.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-024855.csv (N=0)\n",
      "[336.0,-40.0] no gold.\n",
      "\n",
      "[done] scanned southern deep set — no NOVEL at current gates. Consider more centers or relax GOLD W23=2.7.\n"
     ]
    }
   ],
   "source": [
    "# CNT Novelty — Southern Deep v3 (stop on first NOVEL)\n",
    "# High-|b| southern fields; strict galaxy bias; K_GOLD=5; novelty radius=2.5\"\n",
    "# Reuses your v3 helpers: discovery_sweep(), enrich_allwise(), multiscale_verify(), make_dossier()\n",
    "\n",
    "import time, math\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "# --- keep network sane\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED:\n",
    "    Ned.TIMEOUT = 20\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ==== hard knobs for true novelty ====\n",
    "SIMBAD_NED_RADIUS_ARCSEC = 2.5\n",
    "GAIA_STAR_REJECT_ARCSEC  = 2.0\n",
    "GAIA_PARALLAX_MAS_MIN    = 1.0   # likely star if π≥1 mas\n",
    "GAIA_PM_MASYR_MIN        = 20.0  # likely star if μ≥20 mas/yr\n",
    "W23_HOT_MIN              = 3.0   # very dust-bright\n",
    "STOP_AFTER_NOVEL         = 1     # stop at first NOVEL (rank=2)\n",
    "\n",
    "# === field selector: high-|b| southern sky (δ ≤ −35°, |b| ≥ 50°) ===\n",
    "def southern_deep_centers(step_deg=24, decs=(-60.0, -55.0, -50.0, -45.0, -40.0)):\n",
    "    centers=[]\n",
    "    for dec in decs:\n",
    "        for ra in np.arange(0, 360, step_deg):\n",
    "            c = SkyCoord(float(ra)*u.deg, float(dec)*u.deg, frame=\"icrs\")\n",
    "            b = c.galactic.b.deg\n",
    "            if abs(b) >= 50.0:\n",
    "                centers.append((float(ra), float(dec)))\n",
    "    # de-dup & spread\n",
    "    uniq, seen = [], set()\n",
    "    for c in centers:\n",
    "        if c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "# === helpers ===\n",
    "def allwise_exact(wid):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wid))\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    r = q[0].to_pandas().iloc[0]\n",
    "    ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "    w1, w2, w3 = r.get(\"W1mag\", np.nan), r.get(\"W2mag\", np.nan), r.get(\"W3mag\", np.nan)\n",
    "    w12 = (w1 - w2) if pd.notna(w1) and pd.notna(w2) else np.nan\n",
    "    w23 = (w2 - w3) if pd.notna(w2) and pd.notna(w3) else np.nan\n",
    "    ext = str(r.get(\"ext_flg\",\"\"))\n",
    "    return dict(ra=ra, dec=dec, w12=w12, w23=w23, ext_flg=ext)\n",
    "\n",
    "def gaia_star_like(ra, dec):\n",
    "    try:\n",
    "        g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\"]).query_region(\n",
    "            SkyCoord(ra*u.deg, dec*u.deg), radius=GAIA_STAR_REJECT_ARCSEC*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    if not g or len(g[0])==0:\n",
    "        return False\n",
    "    df = g[0].to_pandas()\n",
    "    par_ok = (df.get(\"parallax\", pd.Series([])).astype(float) >= GAIA_PARALLAX_MAS_MIN).any()\n",
    "    pm_ok  = (np.hypot(df.get(\"pmRA\", pd.Series([])).astype(float),\n",
    "                       df.get(\"pmDE\", pd.Series([])).astype(float)) >= GAIA_PM_MASYR_MIN).any()\n",
    "    return bool(par_ok or pm_ok)\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD\n",
    "    try:\n",
    "        s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "    except Exception:\n",
    "        s = None\n",
    "    sim_hit = (s is not None and len(s)>0)\n",
    "    sim_type = \"\" if not sim_hit else str(s.to_pandas().iloc[0].get(\"OTYPE\",\"\"))\n",
    "    # NED\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try:\n",
    "            n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "        except Exception:\n",
    "            n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]\n",
    "            ned_hit = True; ned_type = str(p.get(\"Type\",\"\")); ned_z = str(p.get(\"Redshift\",\"\"))\n",
    "    # verdict\n",
    "    typed = any(k in (sim_type+\" \"+ned_type).upper() for k in [\"GALAXY\",\"AGN\",\"QSO\",\"HII\",\"PN\"])\n",
    "    if not sim_hit and not ned_hit:\n",
    "        return \"NOVEL\", 2, sim_type, ned_type, ned_z\n",
    "    if not typed:\n",
    "        return \"SEMI-NOVEL\", 1, sim_type, ned_type, ned_z\n",
    "    return \"KNOWN\", 0, sim_type, ned_type, ned_z\n",
    "\n",
    "# === main loop (stop on first NOVEL) ===\n",
    "def southern_deep_novel():\n",
    "    global CFG\n",
    "    centers = southern_deep_centers()\n",
    "    print(f\"[southern-deep] centers={len(centers)}  (δ≤−35°, |b|≥50°)\")\n",
    "\n",
    "    for (cra, cdec) in centers:\n",
    "        # configure strict galaxy-first scan\n",
    "        CFG[\"CENTER_RA\"]   = float(cra)\n",
    "        CFG[\"CENTER_DEC\"]  = float(cdec)\n",
    "        CFG[\"GRID_SIZE\"]   = 5           # 5×5 grid (25 tiles)\n",
    "        CFG[\"GRID_STEP_DEG\"]= 1.2\n",
    "        CFG[\"RADIUS_DEG\"]  = 0.8\n",
    "        CFG[\"N_MAX\"]       = 4000        # deeper\n",
    "        CFG[\"K_DISC\"]      = 3\n",
    "        CFG[\"K_GOLD\"]      = 5           # GOLD bar up\n",
    "        CFG[\"GOLD_W23_MIN\"]= 3.0         # very dusty\n",
    "        CFG[\"GALAXY_MODE\"] = True\n",
    "\n",
    "        stamp, master, tiles, _ = discovery_sweep()\n",
    "        enr, base, gold, *_ = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] no gold.\")\n",
    "            continue\n",
    "\n",
    "        # pre-verify galaxy bias (keep extreme dust or extended)\n",
    "        gold = gold[(gold[\"W2-W3\"].fillna(-99) >= W23_HOT_MIN) | (gold.get(\"ext_flg\",\"\").astype(str) != \"0\")].copy()\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] none after galaxy-bias filter.\")\n",
    "            continue\n",
    "\n",
    "        ver, _ = multiscale_verify(gold, stamp)\n",
    "        conf = ver[ver[\"pass_multiscale\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] none multiscale-confirmed.\")\n",
    "            continue\n",
    "\n",
    "        # novelty + star reject\n",
    "        rows=[]\n",
    "        for _, r in conf.iterrows():\n",
    "            wid = str(r[\"AllWISE\"])\n",
    "            ex  = allwise_exact(wid)\n",
    "            if ex is None: \n",
    "                continue\n",
    "            ra, dec, w12, w23 = ex[\"ra\"], ex[\"dec\"], ex[\"w12\"], ex[\"w23\"]\n",
    "            # star veto\n",
    "            if gaia_star_like(ra, dec):\n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra, dec)\n",
    "            rows.append({\n",
    "                \"AllWISE\": wid, \"RA\": ra, \"Dec\": dec,\n",
    "                \"W1-W2\": w12, \"W2-W3\": w23, \"best_votes\": int(r.get(\"best_votes\", np.nan)) if pd.notna(r.get(\"best_votes\", np.nan)) else np.nan,\n",
    "                \"novelty\": verdict, \"novelty_rank\": rank,\n",
    "                \"SIMBAD_type\": sim_t, \"NED_type\": ned_t, \"NED_z\": ned_z,\n",
    "                \"run_stamp\": stamp\n",
    "            })\n",
    "\n",
    "        if not rows:\n",
    "            continue\n",
    "\n",
    "        df = pd.DataFrame(rows).sort_values([\"novelty_rank\",\"best_votes\",\"W2-W3\"], ascending=[False,False,False])\n",
    "        out_csv = OUT / f\"southern_deep_candidates_{stamp}.csv\"\n",
    "        df.to_csv(out_csv, index=False)\n",
    "        print(f\"[save] {out_csv} (N={len(df)})\")\n",
    "\n",
    "        novel = df[df[\"novelty\"]==\"NOVEL\"].copy()\n",
    "        if not novel.empty:\n",
    "            # stop on first NOVEL hit — make dossier + gallery\n",
    "            wid = novel.iloc[0][\"AllWISE\"]\n",
    "            doss = make_dossier(wid, stamp)\n",
    "            html = OUT / f\"novelty_gallery_{stamp}.html\"\n",
    "            with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                f.write(\"<html><head><meta charset='utf-8'><title>CNT Novelty</title>\"\n",
    "                        \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                        \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                f.write(f\"<h1>NOVEL — {stamp}</h1>\")\n",
    "                f.write(\"<div class='card'>\")\n",
    "                if doss and doss.get(\"cutout\") and Path(doss[\"cutout\"]).exists():\n",
    "                    from pathlib import Path as _P\n",
    "                    f.write(f\"<img src='../{_P(doss['cutout']).relative_to(OUT)}'/>\")\n",
    "                else:\n",
    "                    f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                if doss and doss.get(\"sed\") and Path(doss[\"sed\"]).exists():\n",
    "                    from pathlib import Path as _P\n",
    "                    f.write(f\"<div><a href='../{_P(doss['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                            f\"<a href='../{_P(doss['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                f.write(\"</div></div></body></html>\")\n",
    "            print(f\"[save] {html}\")\n",
    "            print(\"\\n== NOVEL ==\\n\", novel.head(1).to_string(index=False))\n",
    "            return\n",
    "\n",
    "        # if no NOVEL, show semi-novel and continue scanning other centers\n",
    "        semi = df[df[\"novelty\"]==\"SEMI-NOVEL\"].head(3)\n",
    "        if not semi.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] semi-novel examples:\\n\", semi[[\"AllWISE\",\"W1-W2\",\"W2-W3\",\"best_votes\",\"SIMBAD_type\",\"NED_type\",\"NED_z\"]].to_string(index=False))\n",
    "\n",
    "    print(\"\\n[done] scanned southern deep set — no NOVEL at current gates. Consider more centers or relax GOLD W23=2.7.\")\n",
    "\n",
    "southern_deep_novel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "53d7c1bd-c1da-4f76-a92c-6d6487dbd298",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[v4] centers=18  (δ<=-40..-60, |b|>=50)\n",
      "[tile 1/25] RA=-1.200 Dec=-61.200\n",
      "[tile 2/25] RA=-0.600 Dec=-61.200\n",
      "[tile 3/25] RA=0.000 Dec=-61.200\n",
      "[tile 4/25] RA=0.600 Dec=-61.200\n",
      "[tile 5/25] RA=1.200 Dec=-61.200\n",
      "[tile 6/25] RA=-1.200 Dec=-60.600\n",
      "[tile 7/25] RA=-0.600 Dec=-60.600\n",
      "[tile 8/25] RA=0.000 Dec=-60.600\n",
      "[tile 9/25] RA=0.600 Dec=-60.600\n",
      "[tile 10/25] RA=1.200 Dec=-60.600\n",
      "[tile 11/25] RA=-1.200 Dec=-60.000\n",
      "[tile 12/25] RA=-0.600 Dec=-60.000\n",
      "[tile 13/25] RA=0.000 Dec=-60.000\n",
      "[tile 14/25] RA=0.600 Dec=-60.000\n",
      "[tile 15/25] RA=1.200 Dec=-60.000\n",
      "[tile 16/25] RA=-1.200 Dec=-59.400\n",
      "[tile 17/25] RA=-0.600 Dec=-59.400\n",
      "[tile 18/25] RA=0.000 Dec=-59.400\n",
      "[tile 19/25] RA=0.600 Dec=-59.400\n",
      "[tile 20/25] RA=1.200 Dec=-59.400\n",
      "[tile 21/25] RA=-1.200 Dec=-58.800\n",
      "[tile 22/25] RA=-0.600 Dec=-58.800\n",
      "[tile 23/25] RA=0.000 Dec=-58.800\n",
      "[tile 24/25] RA=0.600 Dec=-58.800\n",
      "[tile 25/25] RA=1.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-025553.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-025553.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-025553.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-025553.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-025553.csv (N=2)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-025553.csv\n",
      "[0.0,-60.0] soft-verify found none.\n",
      "[tile 1/25] RA=22.800 Dec=-61.200\n",
      "[tile 2/25] RA=23.400 Dec=-61.200\n",
      "[tile 3/25] RA=24.000 Dec=-61.200\n",
      "[tile 4/25] RA=24.600 Dec=-61.200\n",
      "[tile 5/25] RA=25.200 Dec=-61.200\n",
      "[tile 6/25] RA=22.800 Dec=-60.600\n",
      "[tile 7/25] RA=23.400 Dec=-60.600\n",
      "[tile 8/25] RA=24.000 Dec=-60.600\n",
      "[tile 9/25] RA=24.600 Dec=-60.600\n",
      "[tile 10/25] RA=25.200 Dec=-60.600\n",
      "[tile 11/25] RA=22.800 Dec=-60.000\n",
      "[tile 12/25] RA=23.400 Dec=-60.000\n",
      "[tile 13/25] RA=24.000 Dec=-60.000\n",
      "[tile 14/25] RA=24.600 Dec=-60.000\n",
      "[tile 15/25] RA=25.200 Dec=-60.000\n",
      "[tile 16/25] RA=22.800 Dec=-59.400\n",
      "[tile 17/25] RA=23.400 Dec=-59.400\n",
      "[tile 18/25] RA=24.000 Dec=-59.400\n",
      "[tile 19/25] RA=24.600 Dec=-59.400\n",
      "[tile 20/25] RA=25.200 Dec=-59.400\n",
      "[tile 21/25] RA=22.800 Dec=-58.800\n",
      "[tile 22/25] RA=23.400 Dec=-58.800\n",
      "[tile 23/25] RA=24.000 Dec=-58.800\n",
      "[tile 24/25] RA=24.600 Dec=-58.800\n",
      "[tile 25/25] RA=25.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-025730.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-025730.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-025730.csv (N=28)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-025730.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-025730.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-025730.csv\n",
      "[24.0,-60.0] no NOVEL; continuing…\n",
      "[tile 1/25] RA=-1.200 Dec=-56.200\n",
      "[tile 2/25] RA=-0.600 Dec=-56.200\n",
      "[tile 3/25] RA=0.000 Dec=-56.200\n",
      "[tile 4/25] RA=0.600 Dec=-56.200\n",
      "[tile 5/25] RA=1.200 Dec=-56.200\n",
      "[tile 6/25] RA=-1.200 Dec=-55.600\n",
      "[tile 7/25] RA=-0.600 Dec=-55.600\n",
      "[tile 8/25] RA=0.000 Dec=-55.600\n",
      "[tile 9/25] RA=0.600 Dec=-55.600\n",
      "[tile 10/25] RA=1.200 Dec=-55.600\n",
      "[tile 11/25] RA=-1.200 Dec=-55.000\n",
      "[tile 12/25] RA=-0.600 Dec=-55.000\n",
      "[tile 13/25] RA=0.000 Dec=-55.000\n",
      "[tile 14/25] RA=0.600 Dec=-55.000\n",
      "[tile 15/25] RA=1.200 Dec=-55.000\n",
      "[tile 16/25] RA=-1.200 Dec=-54.400\n",
      "[tile 17/25] RA=-0.600 Dec=-54.400\n",
      "[tile 18/25] RA=0.000 Dec=-54.400\n",
      "[tile 19/25] RA=0.600 Dec=-54.400\n",
      "[tile 20/25] RA=1.200 Dec=-54.400\n",
      "[tile 21/25] RA=-1.200 Dec=-53.800\n",
      "[tile 22/25] RA=-0.600 Dec=-53.800\n",
      "[tile 23/25] RA=0.000 Dec=-53.800\n",
      "[tile 24/25] RA=0.600 Dec=-53.800\n",
      "[tile 25/25] RA=1.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-030046.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-030046.csv (N=29)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-030046.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-030046.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-030046.csv (N=4)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-030046.csv\n",
      "[0.0,-55.0] no NOVEL; continuing…\n",
      "[tile 1/25] RA=22.800 Dec=-56.200\n",
      "[tile 2/25] RA=23.400 Dec=-56.200\n",
      "[tile 3/25] RA=24.000 Dec=-56.200\n",
      "[tile 4/25] RA=24.600 Dec=-56.200\n",
      "[tile 5/25] RA=25.200 Dec=-56.200\n",
      "[tile 6/25] RA=22.800 Dec=-55.600\n",
      "[tile 7/25] RA=23.400 Dec=-55.600\n",
      "[tile 8/25] RA=24.000 Dec=-55.600\n",
      "[tile 9/25] RA=24.600 Dec=-55.600\n",
      "[tile 10/25] RA=25.200 Dec=-55.600\n",
      "[tile 11/25] RA=22.800 Dec=-55.000\n",
      "[tile 12/25] RA=23.400 Dec=-55.000\n",
      "[tile 13/25] RA=24.000 Dec=-55.000\n",
      "[tile 14/25] RA=24.600 Dec=-55.000\n",
      "[tile 15/25] RA=25.200 Dec=-55.000\n",
      "[tile 16/25] RA=22.800 Dec=-54.400\n",
      "[tile 17/25] RA=23.400 Dec=-54.400\n",
      "[tile 18/25] RA=24.000 Dec=-54.400\n",
      "[tile 19/25] RA=24.600 Dec=-54.400\n",
      "[tile 20/25] RA=25.200 Dec=-54.400\n",
      "[tile 21/25] RA=22.800 Dec=-53.800\n",
      "[tile 22/25] RA=23.400 Dec=-53.800\n",
      "[tile 23/25] RA=24.000 Dec=-53.800\n",
      "[tile 24/25] RA=24.600 Dec=-53.800\n",
      "[tile 25/25] RA=25.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-030408.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-030408.csv (N=26)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-030408.csv (N=24)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-030408.csv (N=24)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-030408.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-030408.csv\n",
      "[24.0,-55.0] no NOVEL; continuing…\n",
      "[tile 1/25] RA=46.800 Dec=-56.200\n",
      "[tile 2/25] RA=47.400 Dec=-56.200\n",
      "[tile 3/25] RA=48.000 Dec=-56.200\n",
      "[tile 4/25] RA=48.600 Dec=-56.200\n",
      "[tile 5/25] RA=49.200 Dec=-56.200\n",
      "[tile 6/25] RA=46.800 Dec=-55.600\n",
      "[tile 7/25] RA=47.400 Dec=-55.600\n",
      "[tile 8/25] RA=48.000 Dec=-55.600\n",
      "[tile 9/25] RA=48.600 Dec=-55.600\n",
      "[tile 10/25] RA=49.200 Dec=-55.600\n",
      "[tile 11/25] RA=46.800 Dec=-55.000\n",
      "[tile 12/25] RA=47.400 Dec=-55.000\n",
      "[tile 13/25] RA=48.000 Dec=-55.000\n",
      "[tile 14/25] RA=48.600 Dec=-55.000\n",
      "[tile 15/25] RA=49.200 Dec=-55.000\n",
      "[tile 16/25] RA=46.800 Dec=-54.400\n",
      "[tile 17/25] RA=47.400 Dec=-54.400\n",
      "[tile 18/25] RA=48.000 Dec=-54.400\n",
      "[tile 19/25] RA=48.600 Dec=-54.400\n",
      "[tile 20/25] RA=49.200 Dec=-54.400\n",
      "[tile 21/25] RA=46.800 Dec=-53.800\n",
      "[tile 22/25] RA=47.400 Dec=-53.800\n",
      "[tile 23/25] RA=48.000 Dec=-53.800\n",
      "[tile 24/25] RA=48.600 Dec=-53.800\n",
      "[tile 25/25] RA=49.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-030647.csv (N=29)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-030647.csv (N=27)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-030647.csv (N=27)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-030647.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-030647.csv (N=6)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-030647.csv\n",
      "[48.0,-55.0] no NOVEL; continuing…\n",
      "[tile 1/25] RA=334.800 Dec=-56.200\n",
      "[tile 2/25] RA=335.400 Dec=-56.200\n",
      "[tile 3/25] RA=336.000 Dec=-56.200\n",
      "[tile 4/25] RA=336.600 Dec=-56.200\n",
      "[tile 5/25] RA=337.200 Dec=-56.200\n",
      "[tile 6/25] RA=334.800 Dec=-55.600\n",
      "[tile 7/25] RA=335.400 Dec=-55.600\n",
      "[tile 8/25] RA=336.000 Dec=-55.600\n",
      "[tile 9/25] RA=336.600 Dec=-55.600\n",
      "[tile 10/25] RA=337.200 Dec=-55.600\n",
      "[tile 11/25] RA=334.800 Dec=-55.000\n",
      "[tile 12/25] RA=335.400 Dec=-55.000\n",
      "[tile 13/25] RA=336.000 Dec=-55.000\n",
      "[tile 14/25] RA=336.600 Dec=-55.000\n",
      "[tile 15/25] RA=337.200 Dec=-55.000\n",
      "[tile 16/25] RA=334.800 Dec=-54.400\n",
      "[tile 17/25] RA=335.400 Dec=-54.400\n",
      "[tile 18/25] RA=336.000 Dec=-54.400\n",
      "[tile 19/25] RA=336.600 Dec=-54.400\n",
      "[tile 20/25] RA=337.200 Dec=-54.400\n",
      "[tile 21/25] RA=334.800 Dec=-53.800\n",
      "[tile 22/25] RA=335.400 Dec=-53.800\n",
      "[tile 23/25] RA=336.000 Dec=-53.800\n",
      "[tile 24/25] RA=336.600 Dec=-53.800\n",
      "[tile 25/25] RA=337.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-030908.csv (N=34)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-030908.csv (N=33)\n",
      "[save] strict shortlist:  cnt_anomaly\\out\\stable_enriched_strict_20251017-030908.csv (N=29)\n",
      "[save] relaxed shortlist: cnt_anomaly\\out\\stable_enriched_relaxed_20251017-030908.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-030908.csv (N=1)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-030908.csv\n",
      "[336.0,-55.0] soft-verify found none.\n",
      "[tile 1/25] RA=-1.200 Dec=-51.200\n",
      "[tile 2/25] RA=-0.600 Dec=-51.200\n",
      "[tile 3/25] RA=0.000 Dec=-51.200\n",
      "[tile 4/25] RA=0.600 Dec=-51.200\n",
      "[tile 5/25] RA=1.200 Dec=-51.200\n",
      "[tile 6/25] RA=-1.200 Dec=-50.600\n",
      "[tile 7/25] RA=-0.600 Dec=-50.600\n",
      "[tile 8/25] RA=0.000 Dec=-50.600\n"
     ]
    },
    {
     "ename": "EmptyDataError",
     "evalue": "No columns to parse from file",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mEmptyDataError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 181\u001b[39m\n\u001b[32m    178\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcra\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcdec\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] no NOVEL; continuing…\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    179\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[done] v4 scan finished — no NOVEL at these settings. Next: widen centers or nudge W23≥2.6.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m \u001b[43msouthern_deep_v4\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 138\u001b[39m, in \u001b[36msouthern_deep_v4\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    135\u001b[39m CFG[\u001b[33m\"\u001b[39m\u001b[33mN_MAX\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[38;5;28mint\u001b[39m(N_MAX_LOCAL); CFG[\u001b[33m\"\u001b[39m\u001b[33mK_DISC\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[32m3\u001b[39m\n\u001b[32m    136\u001b[39m CFG[\u001b[33m\"\u001b[39m\u001b[33mK_GOLD\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[38;5;28mint\u001b[39m(K_GOLD_SOFT); CFG[\u001b[33m\"\u001b[39m\u001b[33mGOLD_W23_MIN\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[38;5;28mfloat\u001b[39m(W23_MIN_GOLD); CFG[\u001b[33m\"\u001b[39m\u001b[33mGALAXY_MODE\u001b[39m\u001b[33m\"\u001b[39m]=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m stamp, master, tiles, _ = \u001b[43mdiscovery_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m enr, base, gold, *_      = enrich_allwise(master, stamp)\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gold.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 253\u001b[39m, in \u001b[36mdiscovery_sweep\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    251\u001b[39m gaia_cache = CACHE/\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgaia_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mra\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdec\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG[\u001b[33m'\u001b[39m\u001b[33mRADIUS_DEG\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    252\u001b[39m wise_cache = CACHE/\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mgaiaxwise_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mra\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdec\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mCFG[\u001b[33m'\u001b[39m\u001b[33mRADIUS_DEG\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gaia_cache.exists(): gaia = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgaia_cache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    255\u001b[39m     gaia = vizier_query(\u001b[33m\"\u001b[39m\u001b[33mI/355/gaiadr3\u001b[39m\u001b[33m\"\u001b[39m, ra, dec, CFG[\u001b[33m\"\u001b[39m\u001b[33mRADIUS_DEG\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    256\u001b[39m                         columns=[\u001b[33m\"\u001b[39m\u001b[33mRA_ICRS\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mDE_ICRS\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGmag\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mBP-RP\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mparallax\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpmRA\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpmDE\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    257\u001b[39m                         row_limit=CFG[\u001b[33m\"\u001b[39m\u001b[33mN_MAX\u001b[39m\u001b[33m\"\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1895\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[32m   1897\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1898\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmapping\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1899\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[32m   1900\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[39m, in \u001b[36mCParserWrapper.__init__\u001b[39m\u001b[34m(self, src, **kwds)\u001b[39m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[33m\"\u001b[39m\u001b[33mdtype_backend\u001b[39m\u001b[33m\"\u001b[39m] == \u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[32m     92\u001b[39m     import_optional_dependency(\u001b[33m\"\u001b[39m\u001b[33mpyarrow\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m \u001b[38;5;28mself\u001b[39m._reader = \u001b[43mparsers\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTextReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[38;5;28mself\u001b[39m.unnamed_cols = \u001b[38;5;28mself\u001b[39m._reader.unnamed_cols\n\u001b[32m     97\u001b[39m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/parsers.pyx:581\u001b[39m, in \u001b[36mpandas._libs.parsers.TextReader.__cinit__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mEmptyDataError\u001b[39m: No columns to parse from file"
     ]
    }
   ],
   "source": [
    "# CNT Novelty — Southern Deep v4 (gentle verify, stop on first NOVEL)\n",
    "# Reuses: discovery_sweep(), enrich_allwise(), multiscale_verify(), make_dossier()\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED:\n",
    "    Ned.TIMEOUT = 20\n",
    "\n",
    "OUT = Path(\"./cnt_anomaly/out\"); OUT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---- strict-but-gentle knobs ----\n",
    "SIMBAD_NED_RADIUS_ARCSEC = 2.5\n",
    "GAIA_STAR_REJECT_ARCSEC  = 2.0\n",
    "GAIA_PARALLAX_MAS_MIN    = 1.0\n",
    "GAIA_PM_MASYR_MIN        = 20.0\n",
    "W23_MIN_GOLD             = 2.7\n",
    "K_GOLD_SOFT              = 4\n",
    "N_MAX_LOCAL              = 5000\n",
    "SCALES_VERIFY            = (1.5, 3.0, 6.0, 9.0, 12.0)  # arcmin\n",
    "K_VERIFY                 = 4\n",
    "\n",
    "def southern_centers(step_deg=24, decs=(-60,-55,-50,-45,-40)):\n",
    "    centers=[]\n",
    "    for dec in decs:\n",
    "        for ra in np.arange(0,360,step_deg):\n",
    "            c = SkyCoord(float(ra)*u.deg, float(dec)*u.deg)\n",
    "            if abs(c.galactic.b.deg) >= 50.0:\n",
    "                centers.append((float(ra), float(dec)))\n",
    "    # de-dup keep-order\n",
    "    seen=set(); out=[]\n",
    "    for c in centers:\n",
    "        if c not in seen: out.append(c); seen.add(c)\n",
    "    return out\n",
    "\n",
    "def allwise_exact(wid):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=str(wid))\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    r = q[0].to_pandas().iloc[0]\n",
    "    ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "    w1, w2, w3 = r.get(\"W1mag\", np.nan), r.get(\"W2mag\", np.nan), r.get(\"W3mag\", np.nan)\n",
    "    return dict(ra=ra, dec=dec, w12=(w1-w2 if np.isfinite(w1) and np.isfinite(w2) else np.nan),\n",
    "                w23=(w2-w3 if np.isfinite(w2) and np.isfinite(w3) else np.nan))\n",
    "\n",
    "def gaia_star_like(ra, dec):\n",
    "    try:\n",
    "        g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\"]).query_region(\n",
    "            SkyCoord(ra*u.deg, dec*u.deg), radius=GAIA_STAR_REJECT_ARCSEC*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    if not g or len(g[0])==0: return False\n",
    "    df = g[0].to_pandas()\n",
    "    par = df.get(\"parallax\", pd.Series([])).astype(float)\n",
    "    pm  = np.hypot(df.get(\"pmRA\", pd.Series([])).astype(float), df.get(\"pmDE\", pd.Series([])).astype(float))\n",
    "    return bool((par >= GAIA_PARALLAX_MAS_MIN).any() or (pm >= GAIA_PM_MASYR_MIN).any())\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD\n",
    "    try: s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "    except Exception: s = None\n",
    "    sim_hit = (s is not None and len(s)>0); sim_type = \"\" if not sim_hit else str(s.to_pandas().iloc[0].get(\"OTYPE\",\"\"))\n",
    "    # NED\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try: n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=SIMBAD_NED_RADIUS_ARCSEC*u.arcsec)\n",
    "        except Exception: n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]; ned_hit=True; ned_type=str(p.get(\"Type\",\"\")); ned_z=str(p.get(\"Redshift\",\"\"))\n",
    "    typed = any(k in (sim_type+\" \"+ned_type).upper() for k in [\"GALAXY\",\"AGN\",\"QSO\",\"HII\",\"PN\"])\n",
    "    if not sim_hit and not ned_hit: return \"NOVEL\", 2, sim_type, ned_type, ned_z\n",
    "    if not typed:                 return \"SEMI-NOVEL\", 1, sim_type, ned_type, ned_z\n",
    "    return \"KNOWN\", 0, sim_type, ned_type, ned_z\n",
    "\n",
    "def verify_soft(gold, stamp):\n",
    "    # multiscale canonical gauge with K>=K_VERIFY\n",
    "    from astroquery.vizier import Vizier\n",
    "    Vizier.ROW_LIMIT = -1\n",
    "    rows=[]\n",
    "    for wid in gold[\"AllWISE\"].astype(str).tolist():\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0: \n",
    "            rows.append({\"AllWISE\":wid,\"best_votes\":-1,\"pass\":False}); continue\n",
    "        ex = q[0].to_pandas().iloc[0]; ra, dec = float(ex[\"RAJ2000\"]), float(ex[\"DEJ2000\"])\n",
    "        bestK, bestS = -1, None\n",
    "        for arcmin in SCALES_VERIFY:\n",
    "            envq = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "            env = envq[0].to_pandas() if len(envq)>0 and len(envq[0])>0 else pd.DataFrame()\n",
    "            if env.empty: continue\n",
    "            env[\"AllWISE\"] = env.get(\"AllWISE\",\"\").astype(str)\n",
    "            if wid not in set(env[\"AllWISE\"]): env = pd.concat([env, ex.to_frame().T], ignore_index=True)\n",
    "            # canonical views (reuse wise_views_numeric/votes_from_views already loaded)\n",
    "            d = env.copy().rename(columns={\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                                           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "                                           \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"})\n",
    "            for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "                if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "            if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "            # build views with your wise_views_numeric\n",
    "            views = wise_views_numeric(d)  # defined in v3\n",
    "            K = votes_from_views(views, n_estimators=300, contam=0.02)  # slightly more tolerant\n",
    "            if K is None: continue\n",
    "            # locate exact row\n",
    "            idx = d.index[d.get(\"AllWISE\",\"\").astype(str)==wid]\n",
    "            j = int(idx[0]) if len(idx)>0 else None\n",
    "            if j is None:\n",
    "                coords = SkyCoord(d[\"ra_deg\"].astype(float).values*u.deg, d[\"dec\"].astype(float).values*u.deg)\n",
    "                j = int(np.argmin(coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec))\n",
    "            Kj = int(K[j]); \n",
    "            if Kj > bestK: bestK, bestS = Kj, arcmin\n",
    "        rows.append({\"AllWISE\":wid,\"best_votes\":bestK,\"best_scale_arcmin\":bestS,\"pass\":bool(bestK>=K_VERIFY)})\n",
    "    vf = pd.DataFrame(rows)\n",
    "    out = OUT / f\"verify_soft_{stamp}.csv\"; vf.to_csv(out, index=False); print(f\"[save] {out}\")\n",
    "    return vf\n",
    "\n",
    "def southern_deep_v4():\n",
    "    global CFG\n",
    "    centers = southern_centers()\n",
    "    print(f\"[v4] centers={len(centers)}  (δ<=-40..-60, |b|>=50)\")\n",
    "    for (cra,cdec) in centers:\n",
    "        # configure for this center\n",
    "        CFG[\"CENTER_RA\"]=float(cra); CFG[\"CENTER_DEC\"]=float(cdec)\n",
    "        CFG[\"GRID_SIZE\"]=5; CFG[\"GRID_STEP_DEG\"]=1.2; CFG[\"RADIUS_DEG\"]=0.8\n",
    "        CFG[\"N_MAX\"]=int(N_MAX_LOCAL); CFG[\"K_DISC\"]=3\n",
    "        CFG[\"K_GOLD\"]=int(K_GOLD_SOFT); CFG[\"GOLD_W23_MIN\"]=float(W23_MIN_GOLD); CFG[\"GALAXY_MODE\"]=True\n",
    "\n",
    "        stamp, master, tiles, _ = discovery_sweep()\n",
    "        enr, base, gold, *_      = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] no gold at soft gates.\"); continue\n",
    "\n",
    "        # verify with gentler but honest multiscale\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] soft-verify found none.\"); continue\n",
    "\n",
    "        # novelty + star reject — stop on first NOVEL\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            ex = allwise_exact(wid); \n",
    "            if ex is None: continue\n",
    "            ra, dec = ex[\"ra\"], ex[\"dec\"]\n",
    "            if gaia_star_like(ra, dec): \n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra, dec)\n",
    "            if verdict == \"NOVEL\":\n",
    "                doss = make_dossier(wid, stamp)\n",
    "                # tiny gallery\n",
    "                html = OUT / f\"novelty_gallery_{stamp}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp}</h1><div class='card'>\")\n",
    "                    if doss and doss.get(\"cutout\") and Path(doss[\"cutout\"]).exists():\n",
    "                        from pathlib import Path as _P; f.write(f\"<img src='../{_P(doss['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if doss and doss.get(\"sed\") and Path(doss[\"sed\"]).exists():\n",
    "                        from pathlib import Path as _P; f.write(f\"<div><a href='../{_P(doss['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                                               f\"<a href='../{_P(doss['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                print(f\"\\n== NOVEL == {wid}\\nRA={ra:.6f} Dec={dec:.6f}  W2−W3≈{ex['w23']:.2f}  (saved dossier + gallery)\")\n",
    "                print(f\"[open] {html}\")\n",
    "                return\n",
    "        print(f\"[{cra:.1f},{cdec:.1f}] no NOVEL; continuing…\")\n",
    "    print(\"\\n[done] v4 scan finished — no NOVEL at these settings. Next: widen centers or nudge W23≥2.6.\")\n",
    "\n",
    "southern_deep_v4()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e1f61098-b6e5-4f78-aa9a-8aa4fa61d8ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] removed 6 tiny/bad cache files\n"
     ]
    }
   ],
   "source": [
    "# == Cache resilience hotfix for discovery_sweep ==\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "\n",
    "# 0) Scrub obviously bad cache files\n",
    "try:\n",
    "    bad = []\n",
    "    for p in CACHE.glob(\"*.csv\"):\n",
    "        try:\n",
    "            if p.stat().st_size < 32:  # tiny/empty -> junk\n",
    "                bad.append(p)\n",
    "        except Exception:\n",
    "            pass\n",
    "    for p in bad:\n",
    "        p.unlink(missing_ok=True)\n",
    "    print(f\"[cache] removed {len(bad)} tiny/bad cache files\")\n",
    "except NameError:\n",
    "    print(\"[cache] NOTE: CACHE not defined in this kernel scope.\")\n",
    "\n",
    "def _safe_read_csv(path: Path, expect_cols=None):\n",
    "    \"\"\"Return DataFrame or None; delete corrupt/empty cache to force refresh.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df is None:\n",
    "            raise EmptyDataError(\"None DF\")\n",
    "        if df.empty and expect_cols:\n",
    "            raise EmptyDataError(\"empty DF\")\n",
    "        if expect_cols and not set(expect_cols).issubset(df.columns):\n",
    "            raise ParserError(f\"missing columns: {set(expect_cols)-set(df.columns)}\")\n",
    "        return df\n",
    "    except (EmptyDataError, ParserError, OSError, ValueError):\n",
    "        try:\n",
    "            path.unlink(missing_ok=True)\n",
    "        except Exception:\n",
    "            pass\n",
    "        return None\n",
    "\n",
    "def _write_csv_atomic(df: pd.DataFrame, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    df.to_csv(tmp, index=False)\n",
    "    tmp.replace(path)\n",
    "\n",
    "# === Override discovery_sweep with cache-safe IO ===\n",
    "def discovery_sweep():\n",
    "    stamp = ts()\n",
    "    offsets = np.linspace(-CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_SIZE\"])\n",
    "    tiles = [(CFG[\"CENTER_RA\"]+dx, CFG[\"CENTER_DEC\"]+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    st_all=[]\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "\n",
    "        # GAIA: read-safe, else requery\n",
    "        gaia = None\n",
    "        if gaia_cache.exists():\n",
    "            gaia = _safe_read_csv(gaia_cache, expect_cols=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"])\n",
    "        if gaia is None:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, CFG[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=CFG[\"N_MAX\"])\n",
    "            _write_csv_atomic(gaia, gaia_cache)\n",
    "\n",
    "        if gaia.empty:\n",
    "            print(\"  [skip] GAIA=0 rows\")\n",
    "            continue\n",
    "\n",
    "        # XMatch: read-safe, else rebuild\n",
    "        gw = None\n",
    "        if wise_cache.exists():\n",
    "            gw = _safe_read_csv(wise_cache, expect_cols=[\"ra_deg\",\"dec\"])\n",
    "        if gw is None:\n",
    "            try:\n",
    "                gw = xmatch_gaia_allwise(gaia, CFG[\"XMM_RADIUS_ARCSEC\"])\n",
    "            except Exception as e:\n",
    "                print(\"  [warn] xmatch failed:\", e)\n",
    "                gw = pd.DataFrame()\n",
    "            _write_csv_atomic(gw, wise_cache)\n",
    "\n",
    "        if gw.empty:\n",
    "            print(\"  [skip] no xmatches\")\n",
    "            continue\n",
    "\n",
    "        df = add_derived_features(clean_photometry(gw))\n",
    "        views = wise_views_numeric(df)\n",
    "        votes = votes_from_views(views)\n",
    "        if votes is None:\n",
    "            print(\"  [skip] no usable views\")\n",
    "            continue\n",
    "\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= CFG[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            st_all.append(st)\n",
    "\n",
    "    master = pd.concat(st_all, ignore_index=True) if st_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"\n",
    "    _write_csv_atomic(master, master_path)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "    return stamp, master, tiles, master_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55434945-920c-4e83-899e-ab50b2d3710f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] scrubbed 0 tiny/bad files\n"
     ]
    }
   ],
   "source": [
    "# CNT Techno-Anomaly — Fused v5 (cache-safe, AllWISE fallback, multiscale verify, stop-on-NOVEL)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, json, time, warnings, subprocess, importlib, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ================= ENV & DEPS =================\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        mod = p if p!=\"scikit-learn\" else \"sklearn\"\n",
    "        try: importlib.import_module(mod)\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED: Ned.TIMEOUT = 20\n",
    "\n",
    "# ================= PATHS & CFG =================\n",
    "OUT   = Path(\"./cnt_anomaly/out\");   OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "FIG   = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "WEB   = OUT/\"web\";     WEB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts(): return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "def sanitize_id(s): return str(s).strip()\n",
    "\n",
    "CFG = dict(\n",
    "    CENTER_RA = 210.0,            # deg\n",
    "    CENTER_DEC = -0.5,            # deg\n",
    "    GRID_SIZE = 5,                # per-center tiles (5×5)\n",
    "    GRID_STEP_DEG = 1.2,\n",
    "    RADIUS_DEG = 0.8,             # per-tile radius\n",
    "    N_MAX = 7000,                 # deeper local context\n",
    "    XMM_RADIUS_ARCSEC = 2.0,      # Gaia↔AllWISE xmatch radius\n",
    "    K_DISC = 3,                   # discovery bar\n",
    "    GOLD_W23_MIN = 2.7,           # dust gate\n",
    "    K_GOLD = 4,                   # gold bar\n",
    "    GALAXY_MODE = True,           # prefer galaxies in gating\n",
    "    VERIFY_SCALES = (1.5,3,6,9,12), # arcmin\n",
    "    K_VERIFY = 4,                 # verify bar\n",
    "    NOVELTY_ARCSEC = 2.5,         # SIMBAD/NED novelty radius\n",
    "    GAIA_STAR_ARCSEC = 2.0,       # star veto search radius\n",
    "    GAIA_PARALLAX_MIN = 1.0,      # mas\n",
    "    GAIA_PM_MIN = 20.0            # mas/yr\n",
    ")\n",
    "\n",
    "# ================= CACHE RESILIENCE =================\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "\n",
    "def _scrub_cache():\n",
    "    bad=0\n",
    "    for p in CACHE.glob(\"*.csv\"):\n",
    "        try:\n",
    "            if p.stat().st_size < 32: p.unlink(missing_ok=True); bad+=1\n",
    "        except Exception: pass\n",
    "    print(f\"[cache] scrubbed {bad} tiny/bad files\")\n",
    "\n",
    "def _safe_read_csv(path: Path, expect_cols=None):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df is None: raise EmptyDataError(\"None DF\")\n",
    "        if df.empty and expect_cols: raise EmptyDataError(\"empty DF\")\n",
    "        if expect_cols and not set(expect_cols).issubset(df.columns):\n",
    "            raise ParserError(f\"missing cols: {set(expect_cols)-set(df.columns)}\")\n",
    "        return df\n",
    "    except (EmptyDataError, ParserError, OSError, ValueError):\n",
    "        try: path.unlink(missing_ok=True)\n",
    "        except Exception: pass\n",
    "        return None\n",
    "\n",
    "def _write_csv_atomic(df: pd.DataFrame, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    df.to_csv(tmp, index=False)\n",
    "    tmp.replace(path)\n",
    "\n",
    "_scrub_cache()\n",
    "\n",
    "# ================= CORE HELPERS =================\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=None):\n",
    "    Vizier.ROW_LIMIT = row_limit or CFG[\"N_MAX\"]\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def allwise_tile(ra, dec, r_deg):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    try:\n",
    "        q = Vizier(columns=[\"**\"]).query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=\"II/328/allwise\")\n",
    "        return q[0].to_pandas() if len(q)>0 else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def clean_photometry(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    return d.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"]-d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "def wise_views_numeric(df):\n",
    "    num = df.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns: num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0  = num.fillna(med)\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\",\"MG\",\"pm_norm\",\"G\",\"BP_RP\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\") or c in [\"BP_RP\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        X4 += np.random.default_rng(42).normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return views\n",
    "\n",
    "def votes_from_views(views, n_estimators=300, contam=0.02):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(42)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        nn  = min(35, max(10, len(X)//10)) if len(X)>20 else max(5, len(X)-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=nn, contamination=contam)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = (f1|f2)\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "# ================= STAR VETO & NOVELTY =================\n",
    "def gaia_star_like(ra, dec):\n",
    "    try:\n",
    "        g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\"]).query_region(\n",
    "            SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"GAIA_STAR_ARCSEC\"]*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    if not g or len(g[0])==0: return False\n",
    "    df = g[0].to_pandas()\n",
    "    par = df.get(\"parallax\", pd.Series([])).astype(float)\n",
    "    pm  = np.hypot(df.get(\"pmRA\", pd.Series([])).astype(float), df.get(\"pmDE\", pd.Series([])).astype(float))\n",
    "    return bool((par >= CFG[\"GAIA_PARALLAX_MIN\"]).any() or (pm >= CFG[\"GAIA_PM_MIN\"]).any())\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD\n",
    "    try: s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"NOVELTY_ARCSEC\"]*u.arcsec)\n",
    "    except Exception: s = None\n",
    "    sim_hit = (s is not None and len(s)>0)\n",
    "    sim_type = \"\" if not sim_hit else str(s.to_pandas().iloc[0].get(\"OTYPE\",\"\"))\n",
    "    # NED\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try: n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"NOVELTY_ARCSEC\"]*u.arcsec)\n",
    "        except Exception: n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]; ned_hit=True; ned_type=str(p.get(\"Type\",\"\")); ned_z=str(p.get(\"Redshift\",\"\"))\n",
    "    typed = any(k in (sim_type+\" \"+ned_type).upper() for k in [\"GALAXY\",\"AGN\",\"QSO\",\"HII\",\"PN\"])\n",
    "    if not sim_hit and not ned_hit: return \"NOVEL\", 2, sim_type, ned_type, ned_z\n",
    "    if not typed:                 return \"SEMI-NOVEL\", 1, sim_type, ned_type, ned_z\n",
    "    return \"KNOWN\", 0, sim_type, ned_type, ned_z\n",
    "\n",
    "# ================= DISCOVERY SWEEP (cache-safe with AllWISE fallback) =================\n",
    "def discovery_sweep():\n",
    "    stamp = ts()\n",
    "    offsets = np.linspace(-CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_SIZE\"])\n",
    "    tiles = [(CFG[\"CENTER_RA\"]+dx, CFG[\"CENTER_DEC\"]+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    st_all=[]\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "\n",
    "        gaia = None\n",
    "        if gaia_cache.exists():\n",
    "            gaia = _safe_read_csv(gaia_cache, expect_cols=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"])\n",
    "        if gaia is None:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, CFG[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=CFG[\"N_MAX\"])\n",
    "            _write_csv_atomic(gaia, gaia_cache)\n",
    "\n",
    "        if gaia.empty:\n",
    "            print(\"  [skip] GAIA=0 rows\"); continue\n",
    "\n",
    "        gw = None\n",
    "        if wise_cache.exists():\n",
    "            gw = _safe_read_csv(wise_cache, expect_cols=[\"ra_deg\",\"dec\"])\n",
    "        if gw is None:\n",
    "            try:\n",
    "                gw = xmatch_gaia_allwise(gaia, CFG[\"XMM_RADIUS_ARCSEC\"])\n",
    "            except Exception as e:\n",
    "                print(\"  [warn] xmatch failed:\", e); gw = pd.DataFrame()\n",
    "            _write_csv_atomic(gw, wise_cache)\n",
    "\n",
    "        if gw.empty:\n",
    "            print(\"  [fallback] AllWISE-only tile\")\n",
    "            aw = allwise_tile(ra, dec, CFG[\"RADIUS_DEG\"])\n",
    "            if aw.empty: \n",
    "                print(\"  [skip] no AllWISE either\"); continue\n",
    "            aw = aw.rename(columns={\"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\",\n",
    "                                    \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                                    \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"})\n",
    "            df = add_derived_features(clean_photometry(aw))\n",
    "        else:\n",
    "            df = add_derived_features(clean_photometry(gw))\n",
    "\n",
    "        views = wise_views_numeric(df)\n",
    "        votes = votes_from_views(views, contam=0.02)\n",
    "        if votes is None:\n",
    "            print(\"  [skip] no usable views\"); continue\n",
    "\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= CFG[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            st_all.append(st)\n",
    "\n",
    "    master = pd.concat(st_all, ignore_index=True) if st_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"\n",
    "    _write_csv_atomic(master, master_path)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "    return stamp, master, tiles, master_path\n",
    "\n",
    "# ================= ENRICH → GOLD =================\n",
    "def enrich_allwise(master, stamp):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    enr_rows=[]\n",
    "    for _, r in master.iterrows():\n",
    "        ra0 = float(r.get(\"ra_deg\", r.get(\"RA_ICRS\", np.nan))); dec0= float(r.get(\"dec\", r.get(\"DE_ICRS\", np.nan)))\n",
    "        if not (np.isfinite(ra0) and np.isfinite(dec0)): continue\n",
    "        # bind to AllWISE\n",
    "        t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "        buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "        try:\n",
    "            xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                              max_distance=CFG[\"XMM_RADIUS_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "            xdf = xm.to_pandas().sort_values(\"angDist\")\n",
    "        except Exception:\n",
    "            xdf = pd.DataFrame()\n",
    "        if xdf.empty:\n",
    "            wid=\"\"; aw_row={}\n",
    "        else:\n",
    "            wid = sanitize_id(xdf.iloc[0][\"AllWISE\"])\n",
    "            q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            aw_row = q[0].to_pandas().iloc[0] if len(q)>0 and len(q[0])>0 else {}\n",
    "        # SNR fallback\n",
    "        def est_snr(emag):\n",
    "            try: emag=float(emag); return (1.0857/emag) if emag>0 else np.nan\n",
    "            except: return np.nan\n",
    "        w1snr = aw_row.get(\"w1snr\", np.nan); w2snr = aw_row.get(\"w2snr\", np.nan)\n",
    "        if pd.isna(w1snr): w1snr = est_snr(aw_row.get(\"e_W1mag\", np.nan))\n",
    "        if pd.isna(w2snr): w2snr = est_snr(aw_row.get(\"e_W2mag\", np.nan))\n",
    "\n",
    "        row = r.to_dict()\n",
    "        row.update({\n",
    "            \"AllWISE\": wid,\n",
    "            \"RAJ2000\": aw_row.get(\"RAJ2000\", np.nan), \"DEJ2000\": aw_row.get(\"DEJ2000\", np.nan),\n",
    "            \"ph_qual\": aw_row.get(\"ph_qual\", np.nan), \"ext_flg\": aw_row.get(\"ext_flg\", np.nan),\n",
    "            \"cc_flags\": aw_row.get(\"cc_flags\", np.nan),\n",
    "            \"w1snr\": w1snr, \"w2snr\": w2snr,\n",
    "            \"W1\": aw_row.get(\"W1mag\", np.nan), \"W2\": aw_row.get(\"W2mag\", np.nan),\n",
    "            \"W3\": aw_row.get(\"W3mag\", np.nan), \"W4\": aw_row.get(\"W4mag\", np.nan)\n",
    "        })\n",
    "        enr_rows.append(row)\n",
    "\n",
    "    enr = pd.DataFrame(enr_rows)\n",
    "    if \"AllWISE\" in enr.columns:\n",
    "        enr = enr.sort_values([\"AllWISE\",\"_votes\"], ascending=[True,False]).drop_duplicates(subset=[\"AllWISE\"])\n",
    "    enr_path = OUT/f\"stable_enriched_all_{stamp}.csv\"; _write_csv_atomic(enr, enr_path)\n",
    "    print(f\"[save] enriched (all): {enr_path} (N={len(enr)})\")\n",
    "\n",
    "    # gold gating\n",
    "    base = enr.copy()\n",
    "    base[\"W1-W2\"] = base.get(\"W1\",np.nan) - base.get(\"W2\",np.nan)\n",
    "    base[\"W2-W3\"] = base.get(\"W2\",np.nan) - base.get(\"W3\",np.nan)\n",
    "\n",
    "    gold_mask = (base[\"_votes\"].fillna(0) >= CFG[\"K_GOLD\"]) & (base[\"W2-W3\"].fillna(-99) >= CFG[\"GOLD_W23_MIN\"])\n",
    "    if CFG[\"GALAXY_MODE\"]:\n",
    "        gold_mask &= (base.get(\"ext_flg\",\"\").astype(str) != \"0\")\n",
    "    gold = base[gold_mask].copy().reset_index(drop=True)\n",
    "    gold_path = OUT/f\"strict_gold_candidates_{stamp}.csv\"; _write_csv_atomic(gold, gold_path)\n",
    "    print(f\"[save] GOLD set → {gold_path} (N={len(gold)})\")\n",
    "    return enr, base, gold, gold_path\n",
    "\n",
    "# ================= VERIFY (multiscale canonical) =================\n",
    "def verify_soft(gold, stamp):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    rows=[]\n",
    "    for wid in gold[\"AllWISE\"].astype(str).tolist():\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            rows.append({\"AllWISE\":wid,\"best_votes\":-1,\"pass\":False}); continue\n",
    "        ex = q[0].to_pandas().iloc[0]; ra, dec = float(ex[\"RAJ2000\"]), float(ex[\"DEJ2000\"])\n",
    "        bestK, bestS = -1, None\n",
    "        for arcmin in CFG[\"VERIFY_SCALES\"]:\n",
    "            envq = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                                       radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "            env = envq[0].to_pandas() if len(envq)>0 and len(envq[0])>0 else pd.DataFrame()\n",
    "            if env.empty: continue\n",
    "            env[\"AllWISE\"] = env.get(\"AllWISE\",\"\").astype(str)\n",
    "            if wid not in set(env[\"AllWISE\"]): env = pd.concat([env, ex.to_frame().T], ignore_index=True)\n",
    "            d = env.copy().rename(columns={\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                                           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "                                           \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"})\n",
    "            for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "                if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "            if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "            views = wise_views_numeric(d)\n",
    "            K = votes_from_views(views, contam=0.02)\n",
    "            if K is None: continue\n",
    "            idx = d.index[d.get(\"AllWISE\",\"\").astype(str) == wid]\n",
    "            j = int(idx[0]) if len(idx)>0 else None\n",
    "            if j is None:\n",
    "                coords = SkyCoord(d[\"ra_deg\"].astype(float).values*u.deg, d[\"dec\"].astype(float).values*u.deg)\n",
    "                j = int(np.argmin(coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec))\n",
    "            Kj = int(K[j])\n",
    "            if Kj > bestK: bestK, bestS = Kj, arcmin\n",
    "        rows.append({\"AllWISE\":wid,\"best_votes\":bestK,\"best_scale_arcmin\":bestS,\"pass\":bool(bestK>=CFG[\"K_VERIFY\"])})\n",
    "    vf = pd.DataFrame(rows)\n",
    "    out = OUT / f\"verify_soft_{stamp}.csv\"; _write_csv_atomic(vf, out); print(f\"[save] {out}\")\n",
    "    return vf\n",
    "\n",
    "# ================= DOSSIER (cutout + SED) =================\n",
    "def make_dossier(allwise_id, stamp):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=allwise_id)\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    aw = q[0].to_pandas().iloc[0]; ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "    # DSS2 cutout\n",
    "    from astroquery.skyview import SkyView\n",
    "    def cutout_png(ra, dec, tag, fov=2.0):\n",
    "        try:\n",
    "            imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                      pixels=512, height=fov*u.arcmin, width=fov*u.arcmin)\n",
    "            if imgs:\n",
    "                a = imgs[0][0].data.astype(np.float32)\n",
    "                img = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "                plt.figure(figsize=(3.2,3.2)); plt.imshow(img, origin=\"lower\", cmap=\"gray\")\n",
    "                plt.axis(\"off\"); plt.tight_layout(pad=0)\n",
    "                out = FIG/f\"{tag}_DSS2.png\"; plt.savefig(out, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close(); return out\n",
    "        except Exception: pass\n",
    "        return None\n",
    "    tag = allwise_id.replace(\".\",\"\").replace(\"+\",\"p\").replace(\"-\",\"m\")\n",
    "    cpng = cutout_png(ra, dec, tag, fov=2.0)\n",
    "    # SED plot\n",
    "    mags=[aw.get(\"W1mag\",np.nan), aw.get(\"W2mag\",np.nan), aw.get(\"W3mag\",np.nan), aw.get(\"W4mag\",np.nan)]\n",
    "    bands=[\"W1\",\"W2\",\"W3\",\"W4\"]\n",
    "    plt.figure(figsize=(4,3)); plt.plot(range(len(mags)), mags, marker=\"o\")\n",
    "    plt.gca().invert_yaxis(); plt.xticks(range(len(mags)), bands); plt.title(f\"{allwise_id} — WISE SED\")\n",
    "    plt.tight_layout(); sed = FIG/f\"{tag}_SED.png\"; plt.savefig(sed, dpi=150); plt.close()\n",
    "    md = OUT/f\"CNT_Gold_Dossier_{tag}.md\"\n",
    "    with open(md,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Dossier — {allwise_id}\\n\\nICRS: RA {ra:.6f}, Dec {dec:.6f}\\n\\n\")\n",
    "        f.write(f\"W1={mags[0]} W2={mags[1]} W3={mags[2]} W4={mags[3]}\\n\")\n",
    "        if np.isfinite(mags[0]) and np.isfinite(mags[1]) and np.isfinite(mags[2]):\n",
    "            f.write(f\"\\nColors: W1−W2={mags[0]-mags[1]:.3f}, W2−W3={mags[1]-mags[2]:.3f}\\n\")\n",
    "        if cpng: f.write(f\"\\nCutout: {cpng}\\n\")\n",
    "        f.write(f\"\\nSED: {sed}\\n\")\n",
    "    print(\"[dossier]\", md)\n",
    "    return {\"md\": md, \"cutout\": cpng, \"sed\": sed}\n",
    "\n",
    "# ================= DRIVER: NOVELTY SCAN =================\n",
    "def southern_centers():\n",
    "    centers=[]\n",
    "    for dec in (-60,-55,-50,-45,-40):\n",
    "        for ra in np.arange(0,360,24):\n",
    "            c = SkyCoord(float(ra)*u.deg, float(dec)*u.deg)\n",
    "            if abs(c.galactic.b.deg) >= 50.0:\n",
    "                centers.append((float(ra), float(dec)))\n",
    "    # de-dup\n",
    "    seen=set(); out=[]\n",
    "    for c in centers:\n",
    "        if c not in seen: out.append(c); seen.add(c)\n",
    "    return out\n",
    "\n",
    "def fused_v5_scan(stop_on_first=True):\n",
    "    centers = southern_centers()\n",
    "    print(f\"[fused v5] centers={len(centers)} (δ≤−40..−60, |b|≥50°)\")\n",
    "    for (cra,cdec) in centers:\n",
    "        CFG[\"CENTER_RA\"]=float(cra); CFG[\"CENTER_DEC\"]=float(cdec)\n",
    "        stamp, master, tiles, _ = discovery_sweep()\n",
    "        enr, base, gold, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] no gold.\"); continue\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(f\"[{cra:.1f},{cdec:.1f}] no soft-verified gold.\"); continue\n",
    "        # novelty + star veto\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            q = Vizier(columns=[\"RAJ2000\",\"DEJ2000\",\"W1mag\",\"W2mag\",\"W3mag\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            if len(q)==0 or len(q[0])==0: continue\n",
    "            r = q[0].to_pandas().iloc[0]\n",
    "            ra,dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "            if gaia_star_like(ra,dec): continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra,dec)\n",
    "            row = dict(AllWISE=wid, RA=ra, Dec=dec, W1W2=float(r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if np.isfinite(r.get(\"W1mag\",np.nan)) and np.isfinite(r.get(\"W2mag\",np.nan)) else np.nan,\n",
    "                       W2W3=float(r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if np.isfinite(r.get(\"W2mag\",np.nan)) and np.isfinite(r.get(\"W3mag\",np.nan)) else np.nan,\n",
    "                       novelty=verdict, SIMBAD=sim_t, NED=ned_t, z=ned_z, run_stamp=stamp)\n",
    "            nov_path = OUT/f\"novelty_candidates_{stamp}.csv\"\n",
    "            pd.DataFrame([row]).to_csv(nov_path, index=False)\n",
    "            print(f\"[save] {nov_path}  → {verdict}\")\n",
    "            if verdict==\"NOVEL\":\n",
    "                d = make_dossier(wid, stamp)\n",
    "                html = OUT/f\"novelty_gallery_{stamp}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp}</h1><div class='card'>\")\n",
    "                    if d and d.get(\"cutout\") and Path(d[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(d['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if d and d.get(\"sed\") and Path(d[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(d['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(d['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                print(f\"\\n== NOVEL == {wid}\\n  RA={ra:.6f} Dec={dec:.6f}  W2−W3≈{row['W2W3']:.2f}\")\n",
    "                print(\"[open]\", html)\n",
    "                return\n",
    "        print(f\"[{cra:.1f},{cdec:.1f}] no NOVEL; continuing…\")\n",
    "    print(\"\\n[done] v5 scan finished — no NOVEL at these settings.\")\n",
    "\n",
    "# ======== QUICKSTART ========\n",
    "# 1) Just run the scan; it will stop at the first NOVEL and write a dossier+gallery:\n",
    "# fused_v5_scan()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d245a605-fb96-46cb-98b5-010017615cec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cache] scrubbed 0 tiny/bad files\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# CNT Techno-Anomaly — Fused v6 (cache-safe + AllWISE fallback + multiscale verify + stop-on-NOVEL)\n",
    "# Telos × Aetheron\n",
    "\n",
    "import os, io, json, time, warnings, subprocess, importlib, shutil\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# =========== deps ===========\n",
    "def ensure(pkgs):\n",
    "    miss=[]\n",
    "    for p in pkgs:\n",
    "        mod = p if p!=\"scikit-learn\" else \"sklearn\"\n",
    "        try: importlib.import_module(mod)\n",
    "        except Exception: miss.append(p)\n",
    "    if miss:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", *miss])\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "ensure([\"astroquery\",\"astropy\",\"scikit-learn\",\"matplotlib\"])\n",
    "\n",
    "from astroquery import log as aqlog\n",
    "from astroquery.vizier import Vizier\n",
    "from astroquery.xmatch import XMatch\n",
    "from astroquery.simbad import Simbad\n",
    "try:\n",
    "    from astroquery.ned import Ned\n",
    "    HAVE_NED = True\n",
    "except Exception:\n",
    "    HAVE_NED = False\n",
    "\n",
    "import astropy.units as u\n",
    "from astropy.table import Table\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astropy.io import fits\n",
    "from astropy.visualization import (ZScaleInterval, AsinhStretch, ImageNormalize)\n",
    "\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from sklearn.preprocessing import RobustScaler, StandardScaler\n",
    "\n",
    "aqlog.setLevel('ERROR')\n",
    "Vizier.TIMEOUT = 20\n",
    "Simbad.TIMEOUT = 20\n",
    "if HAVE_NED: Ned.TIMEOUT = 20\n",
    "\n",
    "# =========== paths & basics ===========\n",
    "OUT   = Path(\"./cnt_anomaly/out\");   OUT.mkdir(parents=True, exist_ok=True)\n",
    "CACHE = Path(\"./cnt_anomaly/cache\"); CACHE.mkdir(parents=True, exist_ok=True)\n",
    "FIG   = OUT/\"figures\"; FIG.mkdir(parents=True, exist_ok=True)\n",
    "WEB   = OUT/\"web\";     WEB.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def ts(): return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "def sanitize_id(s): return str(s).strip()\n",
    "np.random.seed(42)\n",
    "\n",
    "# ================= MODES =================\n",
    "# pick one: \"strict\", \"balanced\", \"aggressive\"\n",
    "MODE = \"balanced\"\n",
    "\n",
    "MODES = {\n",
    "    \"strict\":   dict(N_MAX=7000, XMM=2.0, K_DISC=3, W23=3.0, K_GOLD=5, K_VERIFY=5),\n",
    "    \"balanced\": dict(N_MAX=9000, XMM=2.0, K_DISC=3, W23=2.7, K_GOLD=4, K_VERIFY=4),\n",
    "    \"aggressive\":dict(N_MAX=12000,XMM=2.2, K_DISC=3, W23=2.6, K_GOLD=4, K_VERIFY=4),\n",
    "}\n",
    "\n",
    "CFG = dict(\n",
    "    GRID_SIZE=5, GRID_STEP_DEG=1.2, RADIUS_DEG=0.8, GALAXY_MODE=True,\n",
    "    VERIFY_SCALES=(1.5,3,6,9,12), NOVELTY_ARCSEC=2.5, GAIA_STAR_ARCSEC=2.0,\n",
    "    GAIA_PARALLAX_MIN=1.0, GAIA_PM_MIN=20.0,\n",
    ")\n",
    "\n",
    "# apply mode\n",
    "CFG.update(dict(N_MAX=MODES[MODE][\"N_MAX\"], XMM_RADIUS_ARCSEC=MODES[MODE][\"XMM\"],\n",
    "                K_DISC=MODES[MODE][\"K_DISC\"], GOLD_W23_MIN=MODES[MODE][\"W23\"],\n",
    "                K_GOLD=MODES[MODE][\"K_GOLD\"], K_VERIFY=MODES[MODE][\"K_VERIFY\"]))\n",
    "\n",
    "# =========== cache resilience ===========\n",
    "from pandas.errors import EmptyDataError, ParserError\n",
    "\n",
    "def _scrub_cache():\n",
    "    bad=0\n",
    "    for p in CACHE.glob(\"*.csv\"):\n",
    "        try:\n",
    "            if p.stat().st_size < 32: p.unlink(missing_ok=True); bad+=1\n",
    "        except Exception: pass\n",
    "    print(f\"[cache] scrubbed {bad} tiny/bad files\")\n",
    "\n",
    "def _safe_read_csv(path: Path, expect_cols=None):\n",
    "    try:\n",
    "        df = pd.read_csv(path)\n",
    "        if df is None: raise EmptyDataError(\"None DF\")\n",
    "        if df.empty and expect_cols: raise EmptyDataError(\"empty DF\")\n",
    "        if expect_cols and not set(expect_cols).issubset(df.columns):\n",
    "            raise ParserError(f\"missing cols: {set(expect_cols)-set(df.columns)}\")\n",
    "        return df\n",
    "    except (EmptyDataError, ParserError, OSError, ValueError):\n",
    "        try: path.unlink(missing_ok=True)\n",
    "        except Exception: pass\n",
    "        return None\n",
    "\n",
    "def _write_csv_atomic(df: pd.DataFrame, path: Path):\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    tmp = path.with_suffix(path.suffix + \".tmp\")\n",
    "    df.to_csv(tmp, index=False)\n",
    "    tmp.replace(path)\n",
    "\n",
    "_scrub_cache()\n",
    "\n",
    "# =========== helpers ===========\n",
    "def vizier_query(catalog, ra, dec, r_deg, columns=None, row_limit=None):\n",
    "    Vizier.ROW_LIMIT = row_limit or CFG[\"N_MAX\"]\n",
    "    v = Vizier(columns=(columns or [\"**\"]))\n",
    "    res = v.query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=[catalog])\n",
    "    return res[0].to_pandas() if len(res) else pd.DataFrame()\n",
    "\n",
    "def xmatch_gaia_allwise(gaia_df, radius_arcsec):\n",
    "    if gaia_df.empty: return pd.DataFrame()\n",
    "    t = Table.from_pandas(gaia_df[[\"RA_ICRS\",\"DE_ICRS\"]].rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}))\n",
    "    buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "    xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise', max_distance=radius_arcsec*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "    xdf = xm.to_pandas()\n",
    "    merged = pd.merge_asof(\n",
    "        xdf.sort_values(\"ra\"),\n",
    "        gaia_df.rename(columns={\"RA_ICRS\":\"ra\",\"DE_ICRS\":\"dec\"}).sort_values(\"ra\"),\n",
    "        on=\"ra\", direction=\"nearest\"\n",
    "    )\n",
    "    merged = merged[np.abs(merged[\"dec_x\"]-merged[\"dec_y\"]) < (radius_arcsec/3600.0)]\n",
    "    return merged.rename(columns={\"dec_y\":\"dec\",\"ra\":\"ra_deg\"})\n",
    "\n",
    "def allwise_tile(ra, dec, r_deg):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    try:\n",
    "        q = Vizier(columns=[\"**\"]).query_region(f\"{ra} {dec}\", radius=r_deg*u.deg, catalog=\"II/328/allwise\")\n",
    "        return q[0].to_pandas() if len(q)>0 else pd.DataFrame()\n",
    "    except Exception:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def clean_photometry(df):\n",
    "    d = df.copy()\n",
    "    ren = {\"Gmag\":\"G\",\"BP-RP\":\"BP_RP\",\"pmRA\":\"pmRA\",\"pmDE\":\"pmDE\",\n",
    "           \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"}\n",
    "    for k,v in ren.items():\n",
    "        if k in d.columns: d[v] = d[k]\n",
    "    return d.replace([np.inf,-np.inf], np.nan)\n",
    "\n",
    "def add_derived_features(d):\n",
    "    d = d.copy()\n",
    "    for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\"),(\"W1\",\"W4\"),(\"W2\",\"W4\")]:\n",
    "        if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "    if \"parallax\" in d and \"G\" in d:\n",
    "        with np.errstate(divide=\"ignore\", invalid=\"ignore\"):\n",
    "            d[\"dist_pc\"] = np.where(d[\"parallax\"]>0, 1000.0/d[\"parallax\"], np.nan)\n",
    "            d[\"MG\"] = d[\"G\"] - 5*np.log10(d[\"dist_pc\"]/10.0)\n",
    "    if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"] = (d[\"W1\"] - d[\"W3\"])/2.0\n",
    "    if \"pmRA\" in d and \"pmDE\" in d: d[\"pm_norm\"] = np.hypot(d[\"pmRA\"], d[\"pmDE\"])\n",
    "    return d\n",
    "\n",
    "def wise_views_numeric(df):\n",
    "    num = df.select_dtypes(include=[np.number]).copy()\n",
    "    for c in num.columns: num[c] = pd.to_numeric(num[c], errors=\"coerce\").astype(\"float64\")\n",
    "    if \"dist_pc\" in num: num = num.drop(columns=[\"dist_pc\"])\n",
    "    med = num.median(numeric_only=True)\n",
    "    X0  = num.fillna(med)\n",
    "    views = {}\n",
    "    cols1 = [c for c in X0.columns if c.startswith((\"W\",\"SED_slope\",\"MG\",\"pm_norm\",\"G\",\"BP_RP\")) and not c.startswith(\"eW\")]\n",
    "    cols2 = [c for c in X0.columns if \"-\" in c or c.startswith(\"SED_slope\") or c in [\"BP_RP\"]]\n",
    "    cols3 = [c for c in X0.columns if c in [\"W1\",\"W2\",\"W3\",\"W4\",\"G\",\"MG\"]]\n",
    "    if cols1: views[\"V1_raw_robust\"] = RobustScaler().fit_transform(X0[cols1])\n",
    "    if cols2: views[\"V2_colors_std\"] = StandardScaler().fit_transform(X0[cols2])\n",
    "    if cols3:\n",
    "        X3 = X0[cols3].copy(); X3 = X3 - X3.min().min() + 1e-3; X3 = np.log1p(X3)\n",
    "        views[\"V3_log_reordered\"] = X3[sorted(X3.columns, reverse=True)].values\n",
    "    cols4 = sorted(set(cols1+cols2))\n",
    "    if cols4:\n",
    "        X4 = X0[cols4].copy()\n",
    "        X4 += np.random.default_rng(42).normal(0,1e-3,size=X4.shape)\n",
    "        views[\"V4_jitter\"] = X4.values\n",
    "    if cols1 and cols2:\n",
    "        X5a = RobustScaler().fit_transform(X0[cols1]); X5b = StandardScaler().fit_transform(X0[cols2])\n",
    "        views[\"V5_mixed\"] = np.concatenate([X5a, X5b], axis=1)\n",
    "    return views\n",
    "\n",
    "def votes_from_views(views, n_estimators=300, contam=0.02):\n",
    "    if not views: return None\n",
    "    rng = np.random.RandomState(42)\n",
    "    flags={}\n",
    "    for name,X in views.items():\n",
    "        if X is None or X.shape[1]==0: continue\n",
    "        iso = IsolationForest(n_estimators=n_estimators, contamination=contam, random_state=rng).fit(X)\n",
    "        f1  = (iso.predict(X)==-1)\n",
    "        nn  = min(35, max(10, len(X)//10)) if len(X)>20 else max(5, len(X)-1)\n",
    "        try:\n",
    "            lof = LocalOutlierFactor(n_neighbors=nn, contamination=contam)\n",
    "            f2 = (lof.fit_predict(X)==-1)\n",
    "        except Exception:\n",
    "            f2 = np.zeros(X.shape[0], dtype=bool)\n",
    "        flags[name] = (f1|f2)\n",
    "    M = np.vstack([v.astype(int) for v in flags.values()])\n",
    "    return M.sum(axis=0)\n",
    "\n",
    "def gaia_star_like(ra, dec):\n",
    "    try:\n",
    "        g = Vizier(columns=[\"RA_ICRS\",\"DE_ICRS\",\"parallax\",\"pmRA\",\"pmDE\"]).query_region(\n",
    "            SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"GAIA_STAR_ARCSEC\"]*u.arcsec, catalog=\"I/355/gaiadr3\")\n",
    "    except Exception:\n",
    "        return False\n",
    "    if not g or len(g[0])==0: return False\n",
    "    df = g[0].to_pandas()\n",
    "    par = df.get(\"parallax\", pd.Series([])).astype(float)\n",
    "    pm  = np.hypot(df.get(\"pmRA\", pd.Series([])).astype(float), df.get(\"pmDE\", pd.Series([])).astype(float))\n",
    "    return bool((par >= CFG[\"GAIA_PARALLAX_MIN\"]).any() or (pm >= CFG[\"GAIA_PM_MIN\"]).any())\n",
    "\n",
    "def novelty_check(ra, dec):\n",
    "    # SIMBAD\n",
    "    try: s = Simbad.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"NOVELTY_ARCSEC\"]*u.arcsec)\n",
    "    except Exception: s = None\n",
    "    sim_hit = (s is not None and len(s)>0)\n",
    "    sim_type = \"\" if not sim_hit else str(s.to_pandas().iloc[0].get(\"OTYPE\",\"\"))\n",
    "    # NED\n",
    "    ned_hit, ned_type, ned_z = False, \"\", \"\"\n",
    "    if HAVE_NED:\n",
    "        try: n = Ned.query_region(SkyCoord(ra*u.deg, dec*u.deg), radius=CFG[\"NOVELTY_ARCSEC\"]*u.arcsec)\n",
    "        except Exception: n = None\n",
    "        if n is not None and len(n)>0:\n",
    "            p = n.to_pandas().iloc[0]; ned_hit=True; ned_type=str(p.get(\"Type\",\"\")); ned_z=str(p.get(\"Redshift\",\"\"))\n",
    "    typed = any(k in (sim_type+\" \"+ned_type).upper() for k in [\"GALAXY\",\"AGN\",\"QSO\",\"HII\",\"PN\"])\n",
    "    if not sim_hit and not ned_hit: return \"NOVEL\", 2, sim_type, ned_type, ned_z\n",
    "    if not typed:                 return \"SEMI-NOVEL\", 1, sim_type, ned_type, ned_z\n",
    "    return \"KNOWN\", 0, sim_type, ned_type, ned_z\n",
    "\n",
    "# =========== discovery (cache-safe + AllWISE fallback) ===========\n",
    "def discovery_sweep(center_ra, center_dec, stamp):\n",
    "    offsets = np.linspace(-CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_STEP_DEG\"], CFG[\"GRID_SIZE\"])\n",
    "    tiles = [(center_ra+dx, center_dec+dy) for dy in offsets for dx in offsets]\n",
    "\n",
    "    st_all=[]\n",
    "    for i,(ra,dec) in enumerate(tiles,1):\n",
    "        print(f\"[tile {i}/{len(tiles)}] RA={ra:.3f} Dec={dec:.3f}\")\n",
    "        gaia_cache = CACHE/f\"gaia_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "        wise_cache = CACHE/f\"gaiaxwise_{ra}_{dec}_{CFG['RADIUS_DEG']}.csv\"\n",
    "\n",
    "        gaia = _safe_read_csv(gaia_cache, expect_cols=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"]) if gaia_cache.exists() else None\n",
    "        if gaia is None:\n",
    "            gaia = vizier_query(\"I/355/gaiadr3\", ra, dec, CFG[\"RADIUS_DEG\"],\n",
    "                                columns=[\"RA_ICRS\",\"DE_ICRS\",\"Gmag\",\"BP-RP\",\"parallax\",\"pmRA\",\"pmDE\"],\n",
    "                                row_limit=CFG[\"N_MAX\"])\n",
    "            _write_csv_atomic(gaia, gaia_cache)\n",
    "        if gaia.empty:\n",
    "            print(\"  [skip] GAIA=0 rows\"); continue\n",
    "\n",
    "        gw = _safe_read_csv(wise_cache, expect_cols=[\"ra_deg\",\"dec\"]) if wise_cache.exists() else None\n",
    "        if gw is None:\n",
    "            try:\n",
    "                gw = xmatch_gaia_allwise(gaia, CFG[\"XMM_RADIUS_ARCSEC\"])\n",
    "            except Exception as e:\n",
    "                print(\"  [warn] xmatch failed:\", e); gw = pd.DataFrame()\n",
    "            _write_csv_atomic(gw, wise_cache)\n",
    "\n",
    "        if gw.empty:\n",
    "            print(\"  [fallback] AllWISE-only tile\")\n",
    "            aw = allwise_tile(ra, dec, CFG[\"RADIUS_DEG\"])\n",
    "            if aw.empty: \n",
    "                print(\"  [skip] no AllWISE either\"); continue\n",
    "            aw = aw.rename(columns={\"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\",\n",
    "                                    \"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                                    \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\"})\n",
    "            df = add_derived_features(clean_photometry(aw))\n",
    "        else:\n",
    "            df = add_derived_features(clean_photometry(gw))\n",
    "\n",
    "        views = wise_views_numeric(df)\n",
    "        votes = votes_from_views(views, contam=0.02)\n",
    "        if votes is None:\n",
    "            print(\"  [skip] no usable views\"); continue\n",
    "\n",
    "        df[\"_votes\"] = votes\n",
    "        df[\"_is_stable_anom\"] = df[\"_votes\"] >= CFG[\"K_DISC\"]\n",
    "        st = df[df[\"_is_stable_anom\"]].copy()\n",
    "        if not st.empty:\n",
    "            st[\"tile_ra\"]=ra; st[\"tile_dec\"]=dec\n",
    "            st_all.append(st)\n",
    "\n",
    "    master = pd.concat(st_all, ignore_index=True) if st_all else pd.DataFrame()\n",
    "    master_path = OUT/f\"stable_anomalies_master_{stamp}.csv\"\n",
    "    _write_csv_atomic(master, master_path)\n",
    "    print(f\"[save] master anomalies: {master_path} (N={len(master)})\")\n",
    "    return master, master_path\n",
    "\n",
    "# =========== enrich → gold ===========\n",
    "def enrich_allwise(master, stamp):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    rows=[]\n",
    "    for _, r in master.iterrows():\n",
    "        ra0 = float(r.get(\"ra_deg\", r.get(\"RA_ICRS\", np.nan))); dec0= float(r.get(\"dec\", r.get(\"DE_ICRS\", np.nan)))\n",
    "        if not (np.isfinite(ra0) and np.isfinite(dec0)): continue\n",
    "        # bind\n",
    "        t = Table(names=(\"ra\",\"dec\"), dtype=(\"f8\",\"f8\")); t.add_row((ra0,dec0))\n",
    "        buf = io.BytesIO(); t.write(buf, format=\"votable\"); buf.seek(0)\n",
    "        try:\n",
    "            xm = XMatch.query(cat1=buf, cat2='vizier:II/328/allwise',\n",
    "                              max_distance=CFG[\"XMM_RADIUS_ARCSEC\"]*u.arcsec, colRA1='ra', colDec1='dec')\n",
    "            xdf = xm.to_pandas().sort_values(\"angDist\")\n",
    "        except Exception:\n",
    "            xdf = pd.DataFrame()\n",
    "        if xdf.empty:\n",
    "            wid=\"\"; aw={}\n",
    "        else:\n",
    "            wid = sanitize_id(xdf.iloc[0][\"AllWISE\"])\n",
    "            q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            aw = q[0].to_pandas().iloc[0] if len(q)>0 and len(q[0])>0 else {}\n",
    "\n",
    "        def est_snr(emag):\n",
    "            try: emag=float(emag); return (1.0857/emag) if emag>0 else np.nan\n",
    "            except: return np.nan\n",
    "        w1snr = aw.get(\"w1snr\", np.nan); w2snr = aw.get(\"w2snr\", np.nan)\n",
    "        if pd.isna(w1snr): w1snr = est_snr(aw.get(\"e_W1mag\", np.nan))\n",
    "        if pd.isna(w2snr): w2snr = est_snr(aw.get(\"e_W2mag\", np.nan))\n",
    "\n",
    "        row = r.to_dict()\n",
    "        row.update({\n",
    "            \"AllWISE\": wid,\n",
    "            \"RAJ2000\": aw.get(\"RAJ2000\", np.nan), \"DEJ2000\": aw.get(\"DEJ2000\", np.nan),\n",
    "            \"ph_qual\": aw.get(\"ph_qual\", np.nan), \"ext_flg\": aw.get(\"ext_flg\", np.nan),\n",
    "            \"cc_flags\": aw.get(\"cc_flags\", np.nan),\n",
    "            \"w1snr\": w1snr, \"w2snr\": w2snr,\n",
    "            \"W1\": aw.get(\"W1mag\", np.nan), \"W2\": aw.get(\"W2mag\", np.nan),\n",
    "            \"W3\": aw.get(\"W3mag\", np.nan), \"W4\": aw.get(\"W4mag\", np.nan)\n",
    "        })\n",
    "        rows.append(row)\n",
    "\n",
    "    enr = pd.DataFrame(rows)\n",
    "    if \"AllWISE\" in enr.columns:\n",
    "        enr = enr.sort_values([\"AllWISE\",\"_votes\"], ascending=[True,False]).drop_duplicates(subset=[\"AllWISE\"])\n",
    "    enr_path = OUT/f\"stable_enriched_all_{stamp}.csv\"; _write_csv_atomic(enr, enr_path)\n",
    "    print(f\"[save] enriched (all): {enr_path} (N={len(enr)})\")\n",
    "\n",
    "    base = enr.copy()\n",
    "    base[\"W1-W2\"] = base.get(\"W1\",np.nan) - base.get(\"W2\",np.nan)\n",
    "    base[\"W2-W3\"] = base.get(\"W2\",np.nan) - base.get(\"W3\",np.nan)\n",
    "    gold_mask = (base[\"_votes\"].fillna(0) >= CFG[\"K_GOLD\"]) & (base[\"W2-W3\"].fillna(-99) >= CFG[\"GOLD_W23_MIN\"])\n",
    "    if CFG[\"GALAXY_MODE\"]:\n",
    "        gold_mask &= (base.get(\"ext_flg\",\"\").astype(str) != \"0\")\n",
    "    gold = base[gold_mask].copy().reset_index(drop=True)\n",
    "    gold_path = OUT/f\"strict_gold_candidates_{stamp}.csv\"; _write_csv_atomic(gold, gold_path)\n",
    "    print(f\"[save] GOLD set → {gold_path} (N={len(gold)})\")\n",
    "    return gold, gold_path\n",
    "\n",
    "# =========== verify ===========\n",
    "def verify_soft(gold, stamp):\n",
    "    Vizier.ROW_LIMIT = CFG[\"N_MAX\"]\n",
    "    rows=[]\n",
    "    for wid in gold[\"AllWISE\"].astype(str).tolist():\n",
    "        q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "        if len(q)==0 or len(q[0])==0:\n",
    "            rows.append({\"AllWISE\":wid,\"best_votes\":-1,\"pass\":False}); continue\n",
    "        ex = q[0].to_pandas().iloc[0]; ra, dec = float(ex[\"RAJ2000\"]), float(ex[\"DEJ2000\"])\n",
    "        bestK, bestS = -1, None\n",
    "        for arcmin in CFG[\"VERIFY_SCALES\"]:\n",
    "            envq = Vizier(columns=[\"**\"]).query_region(SkyCoord(ra*u.deg, dec*u.deg),\n",
    "                                                       radius=arcmin*u.arcmin, catalog=\"II/328/allwise\")\n",
    "            env = envq[0].to_pandas() if len(envq)>0 and len(envq[0])>0 else pd.DataFrame()\n",
    "            if env.empty: continue\n",
    "            env[\"AllWISE\"] = env.get(\"AllWISE\",\"\").astype(str)\n",
    "            if wid not in set(env[\"AllWISE\"]): env = pd.concat([env, ex.to_frame().T], ignore_index=True)\n",
    "            d = env.copy().rename(columns={\"W1mag\":\"W1\",\"W2mag\":\"W2\",\"W3mag\":\"W3\",\"W4mag\":\"W4\",\n",
    "                                           \"e_W1mag\":\"eW1\",\"e_W2mag\":\"eW2\",\"e_W3mag\":\"eW3\",\"e_W4mag\":\"eW4\",\n",
    "                                           \"RAJ2000\":\"ra_deg\",\"DEJ2000\":\"dec\"})\n",
    "            for a,b in [(\"W1\",\"W2\"),(\"W2\",\"W3\"),(\"W3\",\"W4\"),(\"W1\",\"W3\")]:\n",
    "                if a in d and b in d: d[f\"{a}-{b}\"]= d[a]-d[b]\n",
    "            if all(c in d for c in [\"W1\",\"W2\",\"W3\"]): d[\"SED_slope_W1_W3\"]=(d[\"W1\"]-d[\"W3\"])/2.0\n",
    "            views = wise_views_numeric(d)\n",
    "            K = votes_from_views(views, contam=0.02)\n",
    "            if K is None: continue\n",
    "            idx = d.index[d.get(\"AllWISE\",\"\").astype(str) == wid]\n",
    "            j = int(idx[0]) if len(idx)>0 else None\n",
    "            if j is None:\n",
    "                coords = SkyCoord(d[\"ra_deg\"].astype(float).values*u.deg, d[\"dec\"].astype(float).values*u.deg)\n",
    "                j = int(np.argmin(coords.separation(SkyCoord(ra*u.deg, dec*u.deg)).arcsec))\n",
    "            Kj = int(K[j])\n",
    "            if Kj > bestK: bestK, bestS = Kj, arcmin\n",
    "        rows.append({\"AllWISE\":wid,\"best_votes\":bestK,\"best_scale_arcmin\":bestS,\"pass\":bool(bestK>=CFG[\"K_VERIFY\"])})\n",
    "    vf = pd.DataFrame(rows)\n",
    "    out = OUT / f\"verify_soft_{stamp}.csv\"; _write_csv_atomic(vf, out); print(f\"[save] {out}\")\n",
    "    return vf\n",
    "\n",
    "# =========== dossier ===========\n",
    "def make_dossier(allwise_id, stamp):\n",
    "    q = Vizier(columns=[\"**\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=allwise_id)\n",
    "    if len(q)==0 or len(q[0])==0: return None\n",
    "    aw = q[0].to_pandas().iloc[0]; ra, dec = float(aw[\"RAJ2000\"]), float(aw[\"DEJ2000\"])\n",
    "    # DSS2 cutout\n",
    "    from astroquery.skyview import SkyView\n",
    "    try:\n",
    "        imgs = SkyView.get_images(position=f\"{ra} {dec}\", survey=[\"DSS2 Red\"],\n",
    "                                  pixels=512, height=2.0*u.arcmin, width=2.0*u.arcmin)\n",
    "        cpng=None\n",
    "        if imgs:\n",
    "            a = imgs[0][0].data.astype(np.float32)\n",
    "            img = np.clip(ImageNormalize(a, interval=ZScaleInterval(), stretch=AsinhStretch())(a),0,1)\n",
    "            plt.figure(figsize=(3.2,3.2)); plt.imshow(img, origin=\"lower\", cmap=\"gray\")\n",
    "            plt.axis(\"off\"); plt.tight_layout(pad=0)\n",
    "            tag = allwise_id.replace(\".\",\"\").replace(\"+\",\"p\").replace(\"-\",\"m\")\n",
    "            cpng = FIG/f\"{tag}_DSS2.png\"; plt.savefig(cpng, dpi=150, bbox_inches=\"tight\", pad_inches=0); plt.close()\n",
    "    except Exception:\n",
    "        cpng=None\n",
    "    # SED\n",
    "    mags=[aw.get(\"W1mag\",np.nan), aw.get(\"W2mag\",np.nan), aw.get(\"W3mag\",np.nan), aw.get(\"W4mag\",np.nan)]\n",
    "    bands=[\"W1\",\"W2\",\"W3\",\"W4\"]\n",
    "    plt.figure(figsize=(4,3)); plt.plot(range(len(mags)), mags, marker=\"o\")\n",
    "    plt.gca().invert_yaxis(); plt.xticks(range(len(mags)), bands); plt.title(f\"{allwise_id} — WISE SED\")\n",
    "    plt.tight_layout(); sed = FIG/f\"{allwise_id.replace('.','').replace('+','p').replace('-','m')}_SED.png\"\n",
    "    plt.savefig(sed, dpi=150); plt.close()\n",
    "    md = OUT/f\"CNT_Gold_Dossier_{allwise_id.replace('.','').replace('+','p').replace('-','m')}.md\"\n",
    "    with open(md,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Dossier — {allwise_id}\\nICRS: RA {ra:.6f}, Dec {dec:.6f}\\n\")\n",
    "        if np.isfinite(mags[0]) and np.isfinite(mags[1]) and np.isfinite(mags[2]):\n",
    "            f.write(f\"Colors: W1−W2={(mags[0]-mags[1]):.3f}, W2−W3={(mags[1]-mags[2]):.3f}\\n\")\n",
    "        if cpng: f.write(f\"Cutout: {cpng}\\n\")\n",
    "        f.write(f\"SED: {sed}\\n\")\n",
    "    print(\"[dossier]\", md)\n",
    "    return {\"md\": md, \"cutout\": (str(cpng) if cpng else \"\"), \"sed\": str(sed)}\n",
    "\n",
    "# =========== centers ===========\n",
    "def southern_centers():\n",
    "    centers=[]\n",
    "    for dec in (-60,-55,-50,-45,-40):\n",
    "        for ra in np.arange(0,360,24):\n",
    "            c = SkyCoord(float(ra)*u.deg, float(dec)*u.deg)\n",
    "            if abs(c.galactic.b.deg) >= 50.0:\n",
    "                centers.append((float(ra), float(dec)))\n",
    "    # de-dup\n",
    "    seen=set(); out=[]\n",
    "    for c in centers:\n",
    "        if c not in seen: out.append(c); seen.add(c)\n",
    "    return out\n",
    "\n",
    "# =========== main driver ===========\n",
    "def fused_v6_scan(stop_on_first=True):\n",
    "    stamp = ts()\n",
    "    centers = southern_centers()\n",
    "    print(f\"[fused v6 | {MODE}] centers={len(centers)} (δ≤−40..−60, |b|≥50°)\")\n",
    "    first_novel = None\n",
    "\n",
    "    for (cra,cdec) in centers:\n",
    "        print(f\"\\n== Center RA={cra:.1f} Dec={cdec:.1f} ==\")\n",
    "        master, master_path = discovery_sweep(cra, cdec, stamp)\n",
    "        if master.empty: \n",
    "            print(\"  [note] master=0\"); continue\n",
    "\n",
    "        gold, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(\"  [note] gold=0\"); continue\n",
    "\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(\"  [note] soft-verified=0\"); continue\n",
    "\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            q = Vizier(columns=[\"RAJ2000\",\"DEJ2000\",\"W1mag\",\"W2mag\",\"W3mag\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            if len(q)==0 or len(q[0])==0: continue\n",
    "            r = q[0].to_pandas().iloc[0]\n",
    "            ra,dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "            if gaia_star_like(ra,dec): \n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra,dec)\n",
    "            row = dict(AllWISE=wid, RA=ra, Dec=dec,\n",
    "                       W1W2=float(r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if np.isfinite(r.get(\"W1mag\",np.nan)) and np.isfinite(r.get(\"W2mag\",np.nan)) else np.nan,\n",
    "                       W2W3=float(r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if np.isfinite(r.get(\"W2mag\",np.nan)) and np.isfinite(r.get(\"W3mag\",np.nan)) else np.nan,\n",
    "                       novelty=verdict, SIMBAD=sim_t, NED=ned_t, z=ned_z, run_stamp=stamp)\n",
    "            nov_path = OUT/f\"novelty_candidates_{stamp}.csv\"\n",
    "            pd.DataFrame([row]).to_csv(nov_path, mode=(\"a\" if Path(nov_path).exists() else \"w\"), header=not Path(nov_path).exists(), index=False)\n",
    "            print(f\"  → {wid} : {verdict}\")\n",
    "\n",
    "            if verdict==\"NOVEL\":\n",
    "                first_novel = wid\n",
    "                d = make_dossier(wid, stamp)\n",
    "                # small gallery\n",
    "                html = OUT/f\"novelty_gallery_{stamp}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp}</h1><div class='card'>\")\n",
    "                    if d and d.get(\"cutout\") and Path(d[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(d['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if d and d.get(\"sed\") and Path(d[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(d['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(d['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                # prereg + bundle\n",
    "                claim = dict(when=stamp, mode=MODE, center=(cra,cdec), N_MAX=CFG[\"N_MAX\"], GOLD_W23_MIN=CFG[\"GOLD_W23_MIN\"],\n",
    "                             K_GOLD=CFG[\"K_GOLD\"], K_VERIFY=CFG[\"K_VERIFY\"], novelty_radius=CFG[\"NOVELTY_ARCSEC\"],\n",
    "                             master=str(master_path), gold=str(gold_path), verify=str(OUT/f\"verify_soft_{stamp}.csv\"),\n",
    "                             novelty=str(nov_path), gallery=str(html), novel_id=wid)\n",
    "                prereg = OUT/f\"preregister_{stamp}.json\"; \n",
    "                with open(prereg,\"w\") as f: json.dump(claim, f, indent=2, default=str)\n",
    "                report = OUT/f\"CNT_TechnoAnomaly_Report_{stamp}.md\"\n",
    "                with open(report,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(f\"# CNT Techno-Anomaly v6 — {stamp}\\n\\n- Mode: **{MODE}**\\n- Novel: **{wid}**\\n\")\n",
    "                    f.write(f\"- Files: master / gold / verify / novelty / gallery / dossier / prereg in `cnt_anomaly/out/`\\n\")\n",
    "                zip_base = OUT/f\"CNT_TechnoAnomaly_{stamp}\"\n",
    "                shutil.make_archive(str(zip_base), \"zip\", OUT)\n",
    "                print(f\"[NOVEL] {wid}  → prereg+bundle saved. Open {html}\")\n",
    "                if stop_on_first: return wid\n",
    "\n",
    "        print(\"  [center] no NOVEL; continuing…\")\n",
    "\n",
    "    print(\"\\n[done] v6 scan finished — no NOVEL at current settings.\")\n",
    "    return first_novel\n",
    "\n",
    "# ===== run it =====\n",
    "# fused_v6_scan()   # ← uncomment to launch (stops at first NOVEL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "675210a8-614d-4281-87af-0427b441656e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[go] mode: aggresive | N_MAX: 12000 | W23 gate: 2.6 | K_VERIFY: 4\n",
      "[fused v6 | aggresive] centers=18 (δ≤−40..−60, |b|≥50°)\n",
      "\n",
      "== Center RA=0.0 Dec=-60.0 ==\n",
      "[tile 1/25] RA=-1.200 Dec=-61.200\n",
      "[tile 2/25] RA=-0.600 Dec=-61.200\n",
      "[tile 3/25] RA=0.000 Dec=-61.200\n",
      "[tile 4/25] RA=0.600 Dec=-61.200\n",
      "[tile 5/25] RA=1.200 Dec=-61.200\n",
      "[tile 6/25] RA=-1.200 Dec=-60.600\n",
      "[tile 7/25] RA=-0.600 Dec=-60.600\n",
      "[tile 8/25] RA=0.000 Dec=-60.600\n",
      "[tile 9/25] RA=0.600 Dec=-60.600\n",
      "[tile 10/25] RA=1.200 Dec=-60.600\n",
      "[tile 11/25] RA=-1.200 Dec=-60.000\n",
      "[tile 12/25] RA=-0.600 Dec=-60.000\n",
      "[tile 13/25] RA=0.000 Dec=-60.000\n",
      "[tile 14/25] RA=0.600 Dec=-60.000\n",
      "[tile 15/25] RA=1.200 Dec=-60.000\n",
      "[tile 16/25] RA=-1.200 Dec=-59.400\n",
      "[tile 17/25] RA=-0.600 Dec=-59.400\n",
      "[tile 18/25] RA=0.000 Dec=-59.400\n",
      "[tile 19/25] RA=0.600 Dec=-59.400\n",
      "[tile 20/25] RA=1.200 Dec=-59.400\n",
      "[tile 21/25] RA=-1.200 Dec=-58.800\n",
      "[tile 22/25] RA=-0.600 Dec=-58.800\n",
      "[tile 23/25] RA=0.000 Dec=-58.800\n",
      "[tile 24/25] RA=0.600 Dec=-58.800\n",
      "[tile 25/25] RA=1.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=2)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=24.0 Dec=-60.0 ==\n",
      "[tile 1/25] RA=22.800 Dec=-61.200\n",
      "[tile 2/25] RA=23.400 Dec=-61.200\n",
      "[tile 3/25] RA=24.000 Dec=-61.200\n",
      "[tile 4/25] RA=24.600 Dec=-61.200\n",
      "[tile 5/25] RA=25.200 Dec=-61.200\n",
      "[tile 6/25] RA=22.800 Dec=-60.600\n",
      "[tile 7/25] RA=23.400 Dec=-60.600\n",
      "[tile 8/25] RA=24.000 Dec=-60.600\n",
      "[tile 9/25] RA=24.600 Dec=-60.600\n",
      "[tile 10/25] RA=25.200 Dec=-60.600\n",
      "[tile 11/25] RA=22.800 Dec=-60.000\n",
      "[tile 12/25] RA=23.400 Dec=-60.000\n",
      "[tile 13/25] RA=24.000 Dec=-60.000\n",
      "[tile 14/25] RA=24.600 Dec=-60.000\n",
      "[tile 15/25] RA=25.200 Dec=-60.000\n",
      "[tile 16/25] RA=22.800 Dec=-59.400\n",
      "[tile 17/25] RA=23.400 Dec=-59.400\n",
      "[tile 18/25] RA=24.000 Dec=-59.400\n",
      "[tile 19/25] RA=24.600 Dec=-59.400\n",
      "[tile 20/25] RA=25.200 Dec=-59.400\n",
      "[tile 21/25] RA=22.800 Dec=-58.800\n",
      "[tile 22/25] RA=23.400 Dec=-58.800\n",
      "[tile 23/25] RA=24.000 Dec=-58.800\n",
      "[tile 24/25] RA=24.600 Dec=-58.800\n",
      "[tile 25/25] RA=25.200 Dec=-58.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J012940.57-604558.1 : SEMI-NOVEL\n",
      "  → J013212.38-612002.3 : SEMI-NOVEL\n",
      "  → J013506.56-593416.1 : SEMI-NOVEL\n",
      "  → J013716.13-600737.6 : SEMI-NOVEL\n",
      "  → J014040.43-611820.1 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=0.0 Dec=-55.0 ==\n",
      "[tile 1/25] RA=-1.200 Dec=-56.200\n",
      "[tile 2/25] RA=-0.600 Dec=-56.200\n",
      "[tile 3/25] RA=0.000 Dec=-56.200\n",
      "[tile 4/25] RA=0.600 Dec=-56.200\n",
      "[tile 5/25] RA=1.200 Dec=-56.200\n",
      "[tile 6/25] RA=-1.200 Dec=-55.600\n",
      "[tile 7/25] RA=-0.600 Dec=-55.600\n",
      "[tile 8/25] RA=0.000 Dec=-55.600\n",
      "[tile 9/25] RA=0.600 Dec=-55.600\n",
      "[tile 10/25] RA=1.200 Dec=-55.600\n",
      "[tile 11/25] RA=-1.200 Dec=-55.000\n",
      "[tile 12/25] RA=-0.600 Dec=-55.000\n",
      "[tile 13/25] RA=0.000 Dec=-55.000\n",
      "[tile 14/25] RA=0.600 Dec=-55.000\n",
      "[tile 15/25] RA=1.200 Dec=-55.000\n",
      "[tile 16/25] RA=-1.200 Dec=-54.400\n",
      "[tile 17/25] RA=-0.600 Dec=-54.400\n",
      "[tile 18/25] RA=0.000 Dec=-54.400\n",
      "[tile 19/25] RA=0.600 Dec=-54.400\n",
      "[tile 20/25] RA=1.200 Dec=-54.400\n",
      "[tile 21/25] RA=-1.200 Dec=-53.800\n",
      "[tile 22/25] RA=-0.600 Dec=-53.800\n",
      "[tile 23/25] RA=0.000 Dec=-53.800\n",
      "[tile 24/25] RA=0.600 Dec=-53.800\n",
      "[tile 25/25] RA=1.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=29)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J000156.65-565659.3 : SEMI-NOVEL\n",
      "  → J000321.47-543337.1 : SEMI-NOVEL\n",
      "  → J000346.71-550739.4 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=24.0 Dec=-55.0 ==\n",
      "[tile 1/25] RA=22.800 Dec=-56.200\n",
      "[tile 2/25] RA=23.400 Dec=-56.200\n",
      "[tile 3/25] RA=24.000 Dec=-56.200\n",
      "[tile 4/25] RA=24.600 Dec=-56.200\n",
      "[tile 5/25] RA=25.200 Dec=-56.200\n",
      "[tile 6/25] RA=22.800 Dec=-55.600\n",
      "[tile 7/25] RA=23.400 Dec=-55.600\n",
      "[tile 8/25] RA=24.000 Dec=-55.600\n",
      "[tile 9/25] RA=24.600 Dec=-55.600\n",
      "[tile 10/25] RA=25.200 Dec=-55.600\n",
      "[tile 11/25] RA=22.800 Dec=-55.000\n",
      "[tile 12/25] RA=23.400 Dec=-55.000\n",
      "[tile 13/25] RA=24.000 Dec=-55.000\n",
      "[tile 14/25] RA=24.600 Dec=-55.000\n",
      "[tile 15/25] RA=25.200 Dec=-55.000\n",
      "[tile 16/25] RA=22.800 Dec=-54.400\n",
      "[tile 17/25] RA=23.400 Dec=-54.400\n",
      "[tile 18/25] RA=24.000 Dec=-54.400\n",
      "[tile 19/25] RA=24.600 Dec=-54.400\n",
      "[tile 20/25] RA=25.200 Dec=-54.400\n",
      "[tile 21/25] RA=22.800 Dec=-53.800\n",
      "[tile 22/25] RA=23.400 Dec=-53.800\n",
      "[tile 23/25] RA=24.000 Dec=-53.800\n",
      "[tile 24/25] RA=24.600 Dec=-53.800\n",
      "[tile 25/25] RA=25.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=26)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=6)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J013143.01-554745.6 : SEMI-NOVEL\n",
      "  → J014404.49-550200.2 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=48.0 Dec=-55.0 ==\n",
      "[tile 1/25] RA=46.800 Dec=-56.200\n",
      "[tile 2/25] RA=47.400 Dec=-56.200\n",
      "[tile 3/25] RA=48.000 Dec=-56.200\n",
      "[tile 4/25] RA=48.600 Dec=-56.200\n",
      "[tile 5/25] RA=49.200 Dec=-56.200\n",
      "[tile 6/25] RA=46.800 Dec=-55.600\n",
      "[tile 7/25] RA=47.400 Dec=-55.600\n",
      "[tile 8/25] RA=48.000 Dec=-55.600\n",
      "[tile 9/25] RA=48.600 Dec=-55.600\n",
      "[tile 10/25] RA=49.200 Dec=-55.600\n",
      "[tile 11/25] RA=46.800 Dec=-55.000\n",
      "[tile 12/25] RA=47.400 Dec=-55.000\n",
      "[tile 13/25] RA=48.000 Dec=-55.000\n",
      "[tile 14/25] RA=48.600 Dec=-55.000\n",
      "[tile 15/25] RA=49.200 Dec=-55.000\n",
      "[tile 16/25] RA=46.800 Dec=-54.400\n",
      "[tile 17/25] RA=47.400 Dec=-54.400\n",
      "[tile 18/25] RA=48.000 Dec=-54.400\n",
      "[tile 19/25] RA=48.600 Dec=-54.400\n",
      "[tile 20/25] RA=49.200 Dec=-54.400\n",
      "[tile 21/25] RA=46.800 Dec=-53.800\n",
      "[tile 22/25] RA=47.400 Dec=-53.800\n",
      "[tile 23/25] RA=48.000 Dec=-53.800\n",
      "[tile 24/25] RA=48.600 Dec=-53.800\n",
      "[tile 25/25] RA=49.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=29)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=6)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J030542.55-553329.6 : SEMI-NOVEL\n",
      "  → J031703.18-553953.9 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=336.0 Dec=-55.0 ==\n",
      "[tile 1/25] RA=334.800 Dec=-56.200\n",
      "[tile 2/25] RA=335.400 Dec=-56.200\n",
      "[tile 3/25] RA=336.000 Dec=-56.200\n",
      "[tile 4/25] RA=336.600 Dec=-56.200\n",
      "[tile 5/25] RA=337.200 Dec=-56.200\n",
      "[tile 6/25] RA=334.800 Dec=-55.600\n",
      "[tile 7/25] RA=335.400 Dec=-55.600\n",
      "[tile 8/25] RA=336.000 Dec=-55.600\n",
      "[tile 9/25] RA=336.600 Dec=-55.600\n",
      "[tile 10/25] RA=337.200 Dec=-55.600\n",
      "[tile 11/25] RA=334.800 Dec=-55.000\n",
      "[tile 12/25] RA=335.400 Dec=-55.000\n",
      "[tile 13/25] RA=336.000 Dec=-55.000\n",
      "[tile 14/25] RA=336.600 Dec=-55.000\n",
      "[tile 15/25] RA=337.200 Dec=-55.000\n",
      "[tile 16/25] RA=334.800 Dec=-54.400\n",
      "[tile 17/25] RA=335.400 Dec=-54.400\n",
      "[tile 18/25] RA=336.000 Dec=-54.400\n",
      "[tile 19/25] RA=336.600 Dec=-54.400\n",
      "[tile 20/25] RA=337.200 Dec=-54.400\n",
      "[tile 21/25] RA=334.800 Dec=-53.800\n",
      "[tile 22/25] RA=335.400 Dec=-53.800\n",
      "[tile 23/25] RA=336.000 Dec=-53.800\n",
      "[tile 24/25] RA=336.600 Dec=-53.800\n",
      "[tile 25/25] RA=337.200 Dec=-53.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=34)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=33)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=1)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=0.0 Dec=-50.0 ==\n",
      "[tile 1/25] RA=-1.200 Dec=-51.200\n",
      "[tile 2/25] RA=-0.600 Dec=-51.200\n",
      "[tile 3/25] RA=0.000 Dec=-51.200\n",
      "[tile 4/25] RA=0.600 Dec=-51.200\n",
      "[tile 5/25] RA=1.200 Dec=-51.200\n",
      "[tile 6/25] RA=-1.200 Dec=-50.600\n",
      "[tile 7/25] RA=-0.600 Dec=-50.600\n",
      "[tile 8/25] RA=0.000 Dec=-50.600\n",
      "  [skip] GAIA=0 rows\n",
      "[tile 9/25] RA=0.600 Dec=-50.600\n",
      "[tile 10/25] RA=1.200 Dec=-50.600\n",
      "[tile 11/25] RA=-1.200 Dec=-50.000\n",
      "[tile 12/25] RA=-0.600 Dec=-50.000\n",
      "[tile 13/25] RA=0.000 Dec=-50.000\n",
      "  [skip] GAIA=0 rows\n",
      "[tile 14/25] RA=0.600 Dec=-50.000\n",
      "[tile 15/25] RA=1.200 Dec=-50.000\n",
      "[tile 16/25] RA=-1.200 Dec=-49.400\n",
      "[tile 17/25] RA=-0.600 Dec=-49.400\n",
      "[tile 18/25] RA=0.000 Dec=-49.400\n",
      "  [skip] GAIA=0 rows\n",
      "[tile 19/25] RA=0.600 Dec=-49.400\n",
      "[tile 20/25] RA=1.200 Dec=-49.400\n",
      "[tile 21/25] RA=-1.200 Dec=-48.800\n",
      "[tile 22/25] RA=-0.600 Dec=-48.800\n",
      "[tile 23/25] RA=0.000 Dec=-48.800\n",
      "[tile 24/25] RA=0.600 Dec=-48.800\n",
      "[tile 25/25] RA=1.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=25)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=25)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=1)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=24.0 Dec=-50.0 ==\n",
      "[tile 1/25] RA=22.800 Dec=-51.200\n",
      "[tile 2/25] RA=23.400 Dec=-51.200\n",
      "[tile 3/25] RA=24.000 Dec=-51.200\n",
      "[tile 4/25] RA=24.600 Dec=-51.200\n",
      "[tile 5/25] RA=25.200 Dec=-51.200\n",
      "[tile 6/25] RA=22.800 Dec=-50.600\n",
      "[tile 7/25] RA=23.400 Dec=-50.600\n",
      "[tile 8/25] RA=24.000 Dec=-50.600\n",
      "[tile 9/25] RA=24.600 Dec=-50.600\n",
      "[tile 10/25] RA=25.200 Dec=-50.600\n",
      "[tile 11/25] RA=22.800 Dec=-50.000\n",
      "[tile 12/25] RA=23.400 Dec=-50.000\n",
      "[tile 13/25] RA=24.000 Dec=-50.000\n",
      "[tile 14/25] RA=24.600 Dec=-50.000\n",
      "[tile 15/25] RA=25.200 Dec=-50.000\n",
      "[tile 16/25] RA=22.800 Dec=-49.400\n",
      "[tile 17/25] RA=23.400 Dec=-49.400\n",
      "[tile 18/25] RA=24.000 Dec=-49.400\n",
      "[tile 19/25] RA=24.600 Dec=-49.400\n",
      "[tile 20/25] RA=25.200 Dec=-49.400\n",
      "[tile 21/25] RA=22.800 Dec=-48.800\n",
      "[tile 22/25] RA=23.400 Dec=-48.800\n",
      "[tile 23/25] RA=24.000 Dec=-48.800\n",
      "[tile 24/25] RA=24.600 Dec=-48.800\n",
      "[tile 25/25] RA=25.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J013809.29-515753.8 : SEMI-NOVEL\n",
      "  → J013834.57-492519.0 : SEMI-NOVEL\n",
      "  → J014002.72-500909.9 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=48.0 Dec=-50.0 ==\n",
      "[tile 1/25] RA=46.800 Dec=-51.200\n",
      "[tile 2/25] RA=47.400 Dec=-51.200\n",
      "[tile 3/25] RA=48.000 Dec=-51.200\n",
      "[tile 4/25] RA=48.600 Dec=-51.200\n",
      "[tile 5/25] RA=49.200 Dec=-51.200\n",
      "[tile 6/25] RA=46.800 Dec=-50.600\n",
      "[tile 7/25] RA=47.400 Dec=-50.600\n",
      "[tile 8/25] RA=48.000 Dec=-50.600\n",
      "[tile 9/25] RA=48.600 Dec=-50.600\n",
      "[tile 10/25] RA=49.200 Dec=-50.600\n",
      "[tile 11/25] RA=46.800 Dec=-50.000\n",
      "[tile 12/25] RA=47.400 Dec=-50.000\n",
      "[tile 13/25] RA=48.000 Dec=-50.000\n",
      "[tile 14/25] RA=48.600 Dec=-50.000\n",
      "[tile 15/25] RA=49.200 Dec=-50.000\n",
      "[tile 16/25] RA=46.800 Dec=-49.400\n",
      "[tile 17/25] RA=47.400 Dec=-49.400\n",
      "[tile 18/25] RA=48.000 Dec=-49.400\n",
      "[tile 19/25] RA=48.600 Dec=-49.400\n",
      "[tile 20/25] RA=49.200 Dec=-49.400\n",
      "[tile 21/25] RA=46.800 Dec=-48.800\n",
      "[tile 22/25] RA=47.400 Dec=-48.800\n",
      "[tile 23/25] RA=48.000 Dec=-48.800\n",
      "[tile 24/25] RA=48.600 Dec=-48.800\n",
      "[tile 25/25] RA=49.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=7)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J031005.57-512023.4 : SEMI-NOVEL\n",
      "  → J031429.61-492659.1 : SEMI-NOVEL\n",
      "  → J031507.18-500733.5 : SEMI-NOVEL\n",
      "  → J031810.85-504428.4 : SEMI-NOVEL\n",
      "  → J031833.09-500458.1 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=336.0 Dec=-50.0 ==\n",
      "[tile 1/25] RA=334.800 Dec=-51.200\n",
      "[tile 2/25] RA=335.400 Dec=-51.200\n",
      "[tile 3/25] RA=336.000 Dec=-51.200\n",
      "[tile 4/25] RA=336.600 Dec=-51.200\n",
      "[tile 5/25] RA=337.200 Dec=-51.200\n",
      "[tile 6/25] RA=334.800 Dec=-50.600\n",
      "[tile 7/25] RA=335.400 Dec=-50.600\n",
      "[tile 8/25] RA=336.000 Dec=-50.600\n",
      "[tile 9/25] RA=336.600 Dec=-50.600\n",
      "[tile 10/25] RA=337.200 Dec=-50.600\n",
      "[tile 11/25] RA=334.800 Dec=-50.000\n",
      "[tile 12/25] RA=335.400 Dec=-50.000\n",
      "[tile 13/25] RA=336.000 Dec=-50.000\n",
      "[tile 14/25] RA=336.600 Dec=-50.000\n",
      "[tile 15/25] RA=337.200 Dec=-50.000\n",
      "[tile 16/25] RA=334.800 Dec=-49.400\n",
      "[tile 17/25] RA=335.400 Dec=-49.400\n",
      "[tile 18/25] RA=336.000 Dec=-49.400\n",
      "[tile 19/25] RA=336.600 Dec=-49.400\n",
      "[tile 20/25] RA=337.200 Dec=-49.400\n",
      "[tile 21/25] RA=334.800 Dec=-48.800\n",
      "[tile 22/25] RA=335.400 Dec=-48.800\n",
      "[tile 23/25] RA=336.000 Dec=-48.800\n",
      "[tile 24/25] RA=336.600 Dec=-48.800\n",
      "[tile 25/25] RA=337.200 Dec=-48.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=27)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=27)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=6)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J222125.09-492912.6 : SEMI-NOVEL\n",
      "  → J222407.08-492814.1 : SEMI-NOVEL\n",
      "  → J222656.32-515931.1 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=0.0 Dec=-45.0 ==\n",
      "[tile 1/25] RA=-1.200 Dec=-46.200\n",
      "[tile 2/25] RA=-0.600 Dec=-46.200\n",
      "[tile 3/25] RA=0.000 Dec=-46.200\n",
      "[tile 4/25] RA=0.600 Dec=-46.200\n",
      "[tile 5/25] RA=1.200 Dec=-46.200\n",
      "[tile 6/25] RA=-1.200 Dec=-45.600\n",
      "[tile 7/25] RA=-0.600 Dec=-45.600\n",
      "[tile 8/25] RA=0.000 Dec=-45.600\n",
      "[tile 9/25] RA=0.600 Dec=-45.600\n",
      "[tile 10/25] RA=1.200 Dec=-45.600\n",
      "[tile 11/25] RA=-1.200 Dec=-45.000\n",
      "[tile 12/25] RA=-0.600 Dec=-45.000\n",
      "[tile 13/25] RA=0.000 Dec=-45.000\n",
      "[tile 14/25] RA=0.600 Dec=-45.000\n",
      "[tile 15/25] RA=1.200 Dec=-45.000\n",
      "[tile 16/25] RA=-1.200 Dec=-44.400\n",
      "[tile 17/25] RA=-0.600 Dec=-44.400\n",
      "[tile 18/25] RA=0.000 Dec=-44.400\n",
      "[tile 19/25] RA=0.600 Dec=-44.400\n",
      "[tile 20/25] RA=1.200 Dec=-44.400\n",
      "[tile 21/25] RA=-1.200 Dec=-43.800\n",
      "[tile 22/25] RA=-0.600 Dec=-43.800\n",
      "[tile 23/25] RA=0.000 Dec=-43.800\n",
      "[tile 24/25] RA=0.600 Dec=-43.800\n",
      "[tile 25/25] RA=1.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=32)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=4)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J000516.49-465943.9 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=24.0 Dec=-45.0 ==\n",
      "[tile 1/25] RA=22.800 Dec=-46.200\n",
      "[tile 2/25] RA=23.400 Dec=-46.200\n",
      "[tile 3/25] RA=24.000 Dec=-46.200\n",
      "[tile 4/25] RA=24.600 Dec=-46.200\n",
      "[tile 5/25] RA=25.200 Dec=-46.200\n",
      "[tile 6/25] RA=22.800 Dec=-45.600\n",
      "[tile 7/25] RA=23.400 Dec=-45.600\n",
      "[tile 8/25] RA=24.000 Dec=-45.600\n",
      "[tile 9/25] RA=24.600 Dec=-45.600\n",
      "[tile 10/25] RA=25.200 Dec=-45.600\n",
      "[tile 11/25] RA=22.800 Dec=-45.000\n",
      "[tile 12/25] RA=23.400 Dec=-45.000\n",
      "[tile 13/25] RA=24.000 Dec=-45.000\n",
      "[tile 14/25] RA=24.600 Dec=-45.000\n",
      "[tile 15/25] RA=25.200 Dec=-45.000\n",
      "[tile 16/25] RA=22.800 Dec=-44.400\n",
      "[tile 17/25] RA=23.400 Dec=-44.400\n",
      "[tile 18/25] RA=24.000 Dec=-44.400\n",
      "[tile 19/25] RA=24.600 Dec=-44.400\n",
      "[tile 20/25] RA=25.200 Dec=-44.400\n",
      "[tile 21/25] RA=22.800 Dec=-43.800\n",
      "[tile 22/25] RA=23.400 Dec=-43.800\n",
      "[tile 23/25] RA=24.000 Dec=-43.800\n",
      "[tile 24/25] RA=24.600 Dec=-43.800\n",
      "[tile 25/25] RA=25.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=33)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=32)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=1)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=48.0 Dec=-45.0 ==\n",
      "[tile 1/25] RA=46.800 Dec=-46.200\n",
      "[tile 2/25] RA=47.400 Dec=-46.200\n",
      "[tile 3/25] RA=48.000 Dec=-46.200\n",
      "[tile 4/25] RA=48.600 Dec=-46.200\n",
      "[tile 5/25] RA=49.200 Dec=-46.200\n",
      "[tile 6/25] RA=46.800 Dec=-45.600\n",
      "[tile 7/25] RA=47.400 Dec=-45.600\n",
      "[tile 8/25] RA=48.000 Dec=-45.600\n",
      "[tile 9/25] RA=48.600 Dec=-45.600\n",
      "[tile 10/25] RA=49.200 Dec=-45.600\n",
      "[tile 11/25] RA=46.800 Dec=-45.000\n",
      "[tile 12/25] RA=47.400 Dec=-45.000\n",
      "[tile 13/25] RA=48.000 Dec=-45.000\n",
      "[tile 14/25] RA=48.600 Dec=-45.000\n",
      "[tile 15/25] RA=49.200 Dec=-45.000\n",
      "[tile 16/25] RA=46.800 Dec=-44.400\n",
      "[tile 17/25] RA=47.400 Dec=-44.400\n",
      "[tile 18/25] RA=48.000 Dec=-44.400\n",
      "[tile 19/25] RA=48.600 Dec=-44.400\n",
      "[tile 20/25] RA=49.200 Dec=-44.400\n",
      "[tile 21/25] RA=46.800 Dec=-43.800\n",
      "[tile 22/25] RA=47.400 Dec=-43.800\n",
      "[tile 23/25] RA=48.000 Dec=-43.800\n",
      "[tile 24/25] RA=48.600 Dec=-43.800\n",
      "[tile 25/25] RA=49.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=28)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=26)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=1)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=336.0 Dec=-45.0 ==\n",
      "[tile 1/25] RA=334.800 Dec=-46.200\n",
      "[tile 2/25] RA=335.400 Dec=-46.200\n",
      "[tile 3/25] RA=336.000 Dec=-46.200\n",
      "[tile 4/25] RA=336.600 Dec=-46.200\n",
      "[tile 5/25] RA=337.200 Dec=-46.200\n",
      "[tile 6/25] RA=334.800 Dec=-45.600\n",
      "[tile 7/25] RA=335.400 Dec=-45.600\n",
      "[tile 8/25] RA=336.000 Dec=-45.600\n",
      "[tile 9/25] RA=336.600 Dec=-45.600\n",
      "[tile 10/25] RA=337.200 Dec=-45.600\n",
      "[tile 11/25] RA=334.800 Dec=-45.000\n",
      "[tile 12/25] RA=335.400 Dec=-45.000\n",
      "[tile 13/25] RA=336.000 Dec=-45.000\n",
      "[tile 14/25] RA=336.600 Dec=-45.000\n",
      "[tile 15/25] RA=337.200 Dec=-45.000\n",
      "[tile 16/25] RA=334.800 Dec=-44.400\n",
      "[tile 17/25] RA=335.400 Dec=-44.400\n",
      "[tile 18/25] RA=336.000 Dec=-44.400\n",
      "[tile 19/25] RA=336.600 Dec=-44.400\n",
      "[tile 20/25] RA=337.200 Dec=-44.400\n",
      "[tile 21/25] RA=334.800 Dec=-43.800\n",
      "[tile 22/25] RA=335.400 Dec=-43.800\n",
      "[tile 23/25] RA=336.000 Dec=-43.800\n",
      "[tile 24/25] RA=336.600 Dec=-43.800\n",
      "[tile 25/25] RA=337.200 Dec=-43.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=33)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=32)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J222141.21-443558.2 : SEMI-NOVEL\n",
      "  → J222415.52-451123.9 : SEMI-NOVEL\n",
      "  → J222913.19-465932.6 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=0.0 Dec=-40.0 ==\n",
      "[tile 1/25] RA=-1.200 Dec=-41.200\n",
      "[tile 2/25] RA=-0.600 Dec=-41.200\n",
      "[tile 3/25] RA=0.000 Dec=-41.200\n",
      "[tile 4/25] RA=0.600 Dec=-41.200\n",
      "[tile 5/25] RA=1.200 Dec=-41.200\n",
      "[tile 6/25] RA=-1.200 Dec=-40.600\n",
      "[tile 7/25] RA=-0.600 Dec=-40.600\n",
      "[tile 8/25] RA=0.000 Dec=-40.600\n",
      "[tile 9/25] RA=0.600 Dec=-40.600\n",
      "[tile 10/25] RA=1.200 Dec=-40.600\n",
      "[tile 11/25] RA=-1.200 Dec=-40.000\n",
      "[tile 12/25] RA=-0.600 Dec=-40.000\n",
      "[tile 13/25] RA=0.000 Dec=-40.000\n",
      "[tile 14/25] RA=0.600 Dec=-40.000\n",
      "[tile 15/25] RA=1.200 Dec=-40.000\n",
      "[tile 16/25] RA=-1.200 Dec=-39.400\n",
      "[tile 17/25] RA=-0.600 Dec=-39.400\n",
      "[tile 18/25] RA=0.000 Dec=-39.400\n",
      "[tile 19/25] RA=0.600 Dec=-39.400\n",
      "[tile 20/25] RA=1.200 Dec=-39.400\n",
      "[tile 21/25] RA=-1.200 Dec=-38.800\n",
      "[tile 22/25] RA=-0.600 Dec=-38.800\n",
      "[tile 23/25] RA=0.000 Dec=-38.800\n",
      "[tile 24/25] RA=0.600 Dec=-38.800\n",
      "[tile 25/25] RA=1.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=30)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=2)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J000125.56-404539.8 : SEMI-NOVEL\n",
      "  → J000221.83-392233.7 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=24.0 Dec=-40.0 ==\n",
      "[tile 1/25] RA=22.800 Dec=-41.200\n",
      "[tile 2/25] RA=23.400 Dec=-41.200\n",
      "[tile 3/25] RA=24.000 Dec=-41.200\n",
      "[tile 4/25] RA=24.600 Dec=-41.200\n",
      "[tile 5/25] RA=25.200 Dec=-41.200\n",
      "[tile 6/25] RA=22.800 Dec=-40.600\n",
      "[tile 7/25] RA=23.400 Dec=-40.600\n",
      "[tile 8/25] RA=24.000 Dec=-40.600\n",
      "[tile 9/25] RA=24.600 Dec=-40.600\n",
      "[tile 10/25] RA=25.200 Dec=-40.600\n",
      "[tile 11/25] RA=22.800 Dec=-40.000\n",
      "[tile 12/25] RA=23.400 Dec=-40.000\n",
      "[tile 13/25] RA=24.000 Dec=-40.000\n",
      "[tile 14/25] RA=24.600 Dec=-40.000\n",
      "[tile 15/25] RA=25.200 Dec=-40.000\n",
      "[tile 16/25] RA=22.800 Dec=-39.400\n",
      "[tile 17/25] RA=23.400 Dec=-39.400\n",
      "[tile 18/25] RA=24.000 Dec=-39.400\n",
      "[tile 19/25] RA=24.600 Dec=-39.400\n",
      "[tile 20/25] RA=25.200 Dec=-39.400\n",
      "[tile 21/25] RA=22.800 Dec=-38.800\n",
      "[tile 22/25] RA=23.400 Dec=-38.800\n",
      "[tile 23/25] RA=24.000 Dec=-38.800\n",
      "[tile 24/25] RA=24.600 Dec=-38.800\n",
      "[tile 25/25] RA=25.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=32)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=31)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=4)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J013128.01-404503.0 : SEMI-NOVEL\n",
      "  → J013504.75-415654.0 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=48.0 Dec=-40.0 ==\n",
      "[tile 1/25] RA=46.800 Dec=-41.200\n",
      "[tile 2/25] RA=47.400 Dec=-41.200\n",
      "[tile 3/25] RA=48.000 Dec=-41.200\n",
      "[tile 4/25] RA=48.600 Dec=-41.200\n",
      "[tile 5/25] RA=49.200 Dec=-41.200\n",
      "[tile 6/25] RA=46.800 Dec=-40.600\n",
      "[tile 7/25] RA=47.400 Dec=-40.600\n",
      "[tile 8/25] RA=48.000 Dec=-40.600\n",
      "[tile 9/25] RA=48.600 Dec=-40.600\n",
      "[tile 10/25] RA=49.200 Dec=-40.600\n",
      "[tile 11/25] RA=46.800 Dec=-40.000\n",
      "[tile 12/25] RA=47.400 Dec=-40.000\n",
      "[tile 13/25] RA=48.000 Dec=-40.000\n",
      "[tile 14/25] RA=48.600 Dec=-40.000\n",
      "[tile 15/25] RA=49.200 Dec=-40.000\n",
      "[tile 16/25] RA=46.800 Dec=-39.400\n",
      "[tile 17/25] RA=47.400 Dec=-39.400\n",
      "[tile 18/25] RA=48.000 Dec=-39.400\n",
      "[tile 19/25] RA=48.600 Dec=-39.400\n",
      "[tile 20/25] RA=49.200 Dec=-39.400\n",
      "[tile 21/25] RA=46.800 Dec=-38.800\n",
      "[tile 22/25] RA=47.400 Dec=-38.800\n",
      "[tile 23/25] RA=48.000 Dec=-38.800\n",
      "[tile 24/25] RA=48.600 Dec=-38.800\n",
      "[tile 25/25] RA=49.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=30)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=3)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-205529.csv\n",
      "  → J031136.22-415424.3 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=336.0 Dec=-40.0 ==\n",
      "[tile 1/25] RA=334.800 Dec=-41.200\n",
      "[tile 2/25] RA=335.400 Dec=-41.200\n",
      "[tile 3/25] RA=336.000 Dec=-41.200\n",
      "[tile 4/25] RA=336.600 Dec=-41.200\n",
      "[tile 5/25] RA=337.200 Dec=-41.200\n",
      "[tile 6/25] RA=334.800 Dec=-40.600\n",
      "[tile 7/25] RA=335.400 Dec=-40.600\n",
      "[tile 8/25] RA=336.000 Dec=-40.600\n",
      "[tile 9/25] RA=336.600 Dec=-40.600\n",
      "[tile 10/25] RA=337.200 Dec=-40.600\n",
      "[tile 11/25] RA=334.800 Dec=-40.000\n",
      "[tile 12/25] RA=335.400 Dec=-40.000\n",
      "[tile 13/25] RA=336.000 Dec=-40.000\n",
      "[tile 14/25] RA=336.600 Dec=-40.000\n",
      "[tile 15/25] RA=337.200 Dec=-40.000\n",
      "[tile 16/25] RA=334.800 Dec=-39.400\n",
      "[tile 17/25] RA=335.400 Dec=-39.400\n",
      "[tile 18/25] RA=336.000 Dec=-39.400\n",
      "[tile 19/25] RA=336.600 Dec=-39.400\n",
      "[tile 20/25] RA=337.200 Dec=-39.400\n",
      "[tile 21/25] RA=334.800 Dec=-38.800\n",
      "[tile 22/25] RA=335.400 Dec=-38.800\n",
      "[tile 23/25] RA=336.000 Dec=-38.800\n",
      "[tile 24/25] RA=336.600 Dec=-38.800\n",
      "[tile 25/25] RA=337.200 Dec=-38.800\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-205529.csv (N=31)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-205529.csv (N=28)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-205529.csv (N=0)\n",
      "  [note] gold=0\n",
      "\n",
      "[done] v6 scan finished — no NOVEL at current settings.\n",
      "\n",
      "[result] NOVEL = None\n"
     ]
    }
   ],
   "source": [
    "# Launch CNT Fused v6 (balanced). It stops at the FIRST NOVEL and writes dossier + gallery.\n",
    "MODE = \"aggresive\"  # try \"aggressive\" if you want a wider net\n",
    "CFG.update({\n",
    "    \"N_MAX\": 9000 if MODE==\"balanced\" else 12000,\n",
    "    \"XMM_RADIUS_ARCSEC\": 2.0 if MODE==\"balanced\" else 2.2,\n",
    "    \"K_DISC\": 3,\n",
    "    \"GOLD_W23_MIN\": 2.7 if MODE==\"balanced\" else 2.6,\n",
    "    \"K_GOLD\": 4,\n",
    "    \"VERIFY_SCALES\": (1.5,3,6,9,12),\n",
    "    \"K_VERIFY\": 4,\n",
    "    \"GALAXY_MODE\": True,\n",
    "    \"NOVELTY_ARCSEC\": 2.5,\n",
    "    \"GAIA_STAR_ARCSEC\": 2.0,\n",
    "    \"GAIA_PARALLAX_MIN\": 1.0,\n",
    "    \"GAIA_PM_MIN\": 20.0,\n",
    "})\n",
    "\n",
    "print(\"[go] mode:\", MODE, \"| N_MAX:\", CFG[\"N_MAX\"], \"| W23 gate:\", CFG[\"GOLD_W23_MIN\"], \"| K_VERIFY:\", CFG[\"K_VERIFY\"])\n",
    "wid = fused_v6_scan()  # ← this actually runs the search\n",
    "print(\"\\n[result] NOVEL =\", wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8ddda83e-2629-4aeb-a796-03d4cb1a17da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[go] v6 Polar Blitz | mode=balanced | N_MAX=9000 | W23 gate=2.7 | K_VERIFY=4\n",
      "[polar-blitz] ring around SEP: 0 centers  (Dec≈−66.6°, |b|≥50°)\n",
      "\n",
      "[polar-blitz] no NOVEL — suggest MODE='aggressive' or W23≥2.6 and rerun fused_v6_scan().\n",
      "\n",
      "[result] NOVEL = None\n"
     ]
    }
   ],
   "source": [
    "# === Polar Blitz upgrade for v6 (South Ecliptic Pole + deeper verify scale) ===\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "# 1) Add an 18′ ring to verify scales (more local context → steadier K)\n",
    "CFG[\"VERIFY_SCALES\"] = (1.5, 3.0, 6.0, 9.0, 12.0, 18.0)  # keep K_VERIFY = 4\n",
    "\n",
    "# 2) Polar Blitz centers around the South Ecliptic Pole (RA≈90°, Dec≈−66.56°), high-|b| ring\n",
    "def polar_blitz_centers(radius_deg=6.0, n_pts=24):\n",
    "    ra0, dec0 = 90.0, -66.56  # South Ecliptic Pole (ICRS, approx)\n",
    "    centers = []\n",
    "    for th in np.linspace(0, 2*np.pi, n_pts, endpoint=False):\n",
    "        dra = radius_deg * np.cos(th)\n",
    "        ddec= radius_deg * np.sin(th)\n",
    "        ra  = (ra0 + dra) % 360.0\n",
    "        dec = np.clip(dec0 + ddec, -89.5, 89.5)\n",
    "        # keep high-|b| only\n",
    "        b = SkyCoord(ra*u.deg, dec*u.deg).galactic.b.deg\n",
    "        if abs(b) >= 50.0:\n",
    "            centers.append((float(ra), float(dec)))\n",
    "    # de-dup\n",
    "    seen, uniq = set(), []\n",
    "    for c in centers:\n",
    "        if c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "# 3) Launcher: run Polar Blitz first; if no NOVEL, fall back to your southern scan\n",
    "def fused_v6_polar_blitz():\n",
    "    stamp = ts()\n",
    "    polars = polar_blitz_centers(radius_deg=6.0, n_pts=24)\n",
    "    print(f\"[polar-blitz] ring around SEP: {len(polars)} centers  (Dec≈−66.6°, |b|≥50°)\")\n",
    "    for (cra, cdec) in polars:\n",
    "        print(f\"\\n== Polar Center RA={cra:.2f} Dec={cdec:.2f} ==\")\n",
    "        master, master_path = discovery_sweep(cra, cdec, stamp)\n",
    "        if master.empty: \n",
    "            print(\"  [note] master=0\"); continue\n",
    "        gold, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(\"  [note] gold=0\"); continue\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(\"  [note] soft-verified=0\"); continue\n",
    "        # novelty + star veto; stop on first NOVEL\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            q = Vizier(columns=[\"RAJ2000\",\"DEJ2000\",\"W1mag\",\"W2mag\",\"W3mag\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            if len(q)==0 or len(q[0])==0: continue\n",
    "            r = q[0].to_pandas().iloc[0]\n",
    "            ra,dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "            if gaia_star_like(ra,dec): \n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra,dec)\n",
    "            print(f\"  → {wid} : {verdict}\")\n",
    "            # record row\n",
    "            row = dict(AllWISE=wid, RA=ra, Dec=dec,\n",
    "                       W1W2=float(r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if np.isfinite(r.get(\"W1mag\",np.nan)) and np.isfinite(r.get(\"W2mag\",np.nan)) else np.nan,\n",
    "                       W2W3=float(r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if np.isfinite(r.get(\"W2mag\",np.nan)) and np.isfinite(r.get(\"W3mag\",np.nan)) else np.nan,\n",
    "                       novelty=verdict, SIMBAD=sim_t, NED=ned_t, z=ned_z, run_stamp=stamp)\n",
    "            nov_path = OUT/f\"novelty_candidates_{stamp}.csv\"\n",
    "            pd.DataFrame([row]).to_csv(nov_path, mode=(\"a\" if Path(nov_path).exists() else \"w\"),\n",
    "                                       header=not Path(nov_path).exists(), index=False)\n",
    "            if verdict == \"NOVEL\":\n",
    "                d = make_dossier(wid, stamp)\n",
    "                html = OUT/f\"novelty_gallery_{stamp}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp}</h1><div class='card'>\")\n",
    "                    if d and d.get(\"cutout\") and Path(d[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(d['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if d and d.get(\"sed\") and Path(d[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(d['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(d['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                print(f\"\\n== NOVEL == {wid}\\n  [open] {html}\")\n",
    "                return wid\n",
    "    print(\"\\n[polar-blitz] no NOVEL — suggest MODE='aggressive' or W23≥2.6 and rerun fused_v6_scan().\")\n",
    "    return None\n",
    "\n",
    "# === Launch Polar Blitz first (balanced). If it returns None, switch MODE and rerun fused_v6_scan().\n",
    "print(f\"[go] v6 Polar Blitz | mode={MODE} | N_MAX={CFG['N_MAX']} | W23 gate={CFG['GOLD_W23_MIN']} | K_VERIFY={CFG['K_VERIFY']}\")\n",
    "wid = fused_v6_polar_blitz()\n",
    "print(\"\\n[result] NOVEL =\", wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "370633a7-98f8-4d62-82c8-ada3f27d5879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[AutoNOVEL v7] strategy=galaxy-balanced  centers=0  N_MAX=9000 W23_gate=2.7  K_GOLD=4 K_VERIFY=4  GALAXY_MODE=True\n",
      "\n",
      "[AutoNOVEL v7] strategy=agn-wedge  centers=0  N_MAX=12000 W23_gate=2.6  K_GOLD=4 K_VERIFY=4  GALAXY_MODE=False\n",
      "\n",
      "[AutoNOVEL v7] strategy=faint-agn  centers=0  N_MAX=12000 W23_gate=2.6  K_GOLD=4 K_VERIFY=4  GALAXY_MODE=False\n",
      "\n",
      "[AutoNOVEL v7] Done. NOVEL = None\n"
     ]
    }
   ],
   "source": [
    "# === AutoNOVEL v7 — escalate strategies until a NOVEL is found (dossier+gallery auto-written) ===\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "# 0) Helpers: Ecliptic pole rings (north & south), high-|b|\n",
    "def ecliptic_pole_ring(north=True, radius_deg=6.0, n_pts=24):\n",
    "    ra0, dec0 = (270.0, +66.56) if north else (90.0, -66.56)\n",
    "    centers=[]\n",
    "    for th in np.linspace(0, 2*np.pi, n_pts, endpoint=False):\n",
    "        dra = radius_deg * np.cos(th)\n",
    "        ddc = radius_deg * np.sin(th)\n",
    "        ra  = (ra0 + dra) % 360.0\n",
    "        dec = np.clip(dec0 + ddc, -89.5, 89.5)\n",
    "        b = SkyCoord(ra*u.deg, dec*u.deg).galactic.b.deg\n",
    "        if abs(b) >= 50.0:\n",
    "            centers.append((float(ra), float(dec)))\n",
    "    # de-dup\n",
    "    uniq, seen = [], set()\n",
    "    for c in centers:\n",
    "        if c not in seen: uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "def run_strategy(name, cfg_overrides, post_gold_filter=None):\n",
    "    \"\"\"Apply overrides, sweep both ecliptic poles, stop on NOVEL.\"\"\"\n",
    "    # apply config overrides\n",
    "    for k,v in cfg_overrides.items():\n",
    "        CFG[k] = v\n",
    "    stamp = ts()\n",
    "    centers = ecliptic_pole_ring(north=False, radius_deg=6.0, n_pts=24) + \\\n",
    "              ecliptic_pole_ring(north=True,  radius_deg=6.0, n_pts=24)\n",
    "    print(f\"\\n[AutoNOVEL v7] strategy={name}  centers={len(centers)}  \"\n",
    "          f\"N_MAX={CFG['N_MAX']} W23_gate={CFG.get('GOLD_W23_MIN','—')}  \"\n",
    "          f\"K_GOLD={CFG['K_GOLD']} K_VERIFY={CFG['K_VERIFY']}  GALAXY_MODE={CFG['GALAXY_MODE']}\")\n",
    "\n",
    "    for (cra,cdec) in centers:\n",
    "        print(f\"\\n== Center RA={cra:.2f} Dec={cdec:.2f} ==\")\n",
    "        master, master_path = discovery_sweep(cra, cdec, stamp)\n",
    "        if master.empty: \n",
    "            print(\"  [note] master=0\"); continue\n",
    "\n",
    "        # enrich→gold\n",
    "        gold, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(\"  [note] gold=0\"); continue\n",
    "\n",
    "        # optional post-filter (e.g., AGN wedge, faintness)\n",
    "        if post_gold_filter is not None:\n",
    "            gold = post_gold_filter(gold)\n",
    "            gold_path = OUT/f\"strict_gold_candidates_{stamp}_{name}.csv\"\n",
    "            if gold.empty:\n",
    "                print(\"  [note] gold=0 after post-filter\"); continue\n",
    "            gold.to_csv(gold_path, index=False)\n",
    "\n",
    "        # verify (multiscale)\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(\"  [note] soft-verified=0\"); continue\n",
    "\n",
    "        # novelty + star veto — STOP ON FIRST NOVEL\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            q = Vizier(columns=[\"RAJ2000\",\"DEJ2000\",\"W1mag\",\"W2mag\",\"W3mag\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            if len(q)==0 or len(q[0])==0: continue\n",
    "            r = q[0].to_pandas().iloc[0]\n",
    "            ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "            if gaia_star_like(ra, dec): \n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra, dec)\n",
    "            print(f\"  → {wid} : {verdict}\")\n",
    "            row = dict(AllWISE=wid, RA=ra, Dec=dec,\n",
    "                       W1W2=float(r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if np.isfinite(r.get(\"W1mag\",np.nan)) and np.isfinite(r.get(\"W2mag\",np.nan)) else np.nan,\n",
    "                       W2W3=float(r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if np.isfinite(r.get(\"W2mag\",np.nan)) and np.isfinite(r.get(\"W3mag\",np.nan)) else np.nan,\n",
    "                       novelty=verdict, SIMBAD=sim_t, NED=ned_t, z=ned_z, run_stamp=stamp, strategy=name)\n",
    "            nov_path = OUT/f\"novelty_candidates_{stamp}.csv\"\n",
    "            pd.DataFrame([row]).to_csv(nov_path, mode=(\"a\" if Path(nov_path).exists() else \"w\"),\n",
    "                                       header=not Path(nov_path).exists(), index=False)\n",
    "            if verdict == \"NOVEL\":\n",
    "                d = make_dossier(wid, stamp)\n",
    "                html = OUT/f\"novelty_gallery_{stamp}_{name}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp} — {name}</h1><div class='card'>\")\n",
    "                    if d and d.get(\"cutout\") and Path(d[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(d['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if d and d.get(\"sed\") and Path(d[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(d['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(d['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                print(f\"\\n== NOVEL == {wid}  [open] {html}\")\n",
    "                return wid\n",
    "        print(\"  [center] no NOVEL; continuing…\")\n",
    "    return None\n",
    "\n",
    "# 1) Strategy list (ordered)\n",
    "def agn_wedge(df):  # Stern-like wedge: W1−W2≥0.8 AND W2−W3≥2.3\n",
    "    keep = df[(df[\"W1-W2\"].fillna(-99)>=0.8) & (df[\"W2-W3\"].fillna(-99)>=2.3)].copy()\n",
    "    return keep\n",
    "\n",
    "def faint_agn(df):  # faint IR where labeling thins: W1>16, W2>15 plus AGN wedge\n",
    "    keep = df[(df[\"W1\"].fillna(99)>16.0) & (df[\"W2\"].fillna(99)>15.0) &\n",
    "              (df[\"W1-W2\"].fillna(-99)>=0.8) & (df[\"W2-W3\"].fillna(-99)>=2.3)].copy()\n",
    "    return keep\n",
    "\n",
    "STRATS = [\n",
    "    # Galaxy-biased but gentler\n",
    "    (\"galaxy-balanced\", dict(N_MAX=9000, XMM_RADIUS_ARCSEC=2.0, GOLD_W23_MIN=2.7, K_GOLD=4, K_VERIFY=4, GALAXY_MODE=True), None),\n",
    "    # AGN wedge (allow point-like; drop galaxy-only constraint)\n",
    "    (\"agn-wedge\",       dict(N_MAX=12000, XMM_RADIUS_ARCSEC=2.2, GOLD_W23_MIN=2.6, K_GOLD=4, K_VERIFY=4, GALAXY_MODE=False), agn_wedge),\n",
    "    # Faint AGN (catalogs thinnest)\n",
    "    (\"faint-agn\",       dict(N_MAX=12000, XMM_RADIUS_ARCSEC=2.2, GOLD_W23_MIN=2.6, K_GOLD=4, K_VERIFY=4, GALAXY_MODE=False), faint_agn),\n",
    "]\n",
    "\n",
    "# 2) Run through strategies until NOVEL or exhaustion\n",
    "wid = None\n",
    "for name, overrides, postf in STRATS:\n",
    "    wid = run_strategy(name, overrides, post_gold_filter=postf)\n",
    "    if wid:\n",
    "        break\n",
    "\n",
    "print(\"\\n[AutoNOVEL v7] Done. NOVEL =\", wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13783058-7c0f-4904-8fb2-1e8695600f15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[targets] ecliptic rings+grids: 146 centers\n",
      "\n",
      "== Center RA=93.00 Dec=-66.56 ==\n",
      "[tile 1/25] RA=91.800 Dec=-67.760\n",
      "[tile 2/25] RA=92.400 Dec=-67.760\n",
      "[tile 3/25] RA=93.000 Dec=-67.760\n",
      "[tile 4/25] RA=93.600 Dec=-67.760\n",
      "[tile 5/25] RA=94.200 Dec=-67.760\n",
      "[tile 6/25] RA=91.800 Dec=-67.160\n",
      "[tile 7/25] RA=92.400 Dec=-67.160\n",
      "[tile 8/25] RA=93.000 Dec=-67.160\n",
      "[tile 9/25] RA=93.600 Dec=-67.160\n",
      "[tile 10/25] RA=94.200 Dec=-67.160\n",
      "[tile 11/25] RA=91.800 Dec=-66.560\n",
      "[tile 12/25] RA=92.400 Dec=-66.560\n",
      "[tile 13/25] RA=93.000 Dec=-66.560\n",
      "[tile 14/25] RA=93.600 Dec=-66.560\n",
      "[tile 15/25] RA=94.200 Dec=-66.560\n",
      "[tile 16/25] RA=91.800 Dec=-65.960\n",
      "[tile 17/25] RA=92.400 Dec=-65.960\n",
      "[tile 18/25] RA=93.000 Dec=-65.960\n",
      "[tile 19/25] RA=93.600 Dec=-65.960\n",
      "[tile 20/25] RA=94.200 Dec=-65.960\n",
      "[tile 21/25] RA=91.800 Dec=-65.360\n",
      "[tile 22/25] RA=92.400 Dec=-65.360\n",
      "[tile 23/25] RA=93.000 Dec=-65.360\n",
      "[tile 24/25] RA=93.600 Dec=-65.360\n",
      "[tile 25/25] RA=94.200 Dec=-65.360\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=40)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=40)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=6)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=92.90 Dec=-65.78 ==\n",
      "[tile 1/25] RA=91.698 Dec=-66.984\n",
      "[tile 2/25] RA=92.298 Dec=-66.984\n",
      "[tile 3/25] RA=92.898 Dec=-66.984\n",
      "[tile 4/25] RA=93.498 Dec=-66.984\n",
      "[tile 5/25] RA=94.098 Dec=-66.984\n",
      "[tile 6/25] RA=91.698 Dec=-66.384\n",
      "[tile 7/25] RA=92.298 Dec=-66.384\n",
      "[tile 8/25] RA=92.898 Dec=-66.384\n",
      "[tile 9/25] RA=93.498 Dec=-66.384\n",
      "[tile 10/25] RA=94.098 Dec=-66.384\n",
      "[tile 11/25] RA=91.698 Dec=-65.784\n",
      "[tile 12/25] RA=92.298 Dec=-65.784\n",
      "[tile 13/25] RA=92.898 Dec=-65.784\n",
      "[tile 14/25] RA=93.498 Dec=-65.784\n",
      "[tile 15/25] RA=94.098 Dec=-65.784\n",
      "[tile 16/25] RA=91.698 Dec=-65.184\n",
      "[tile 17/25] RA=92.298 Dec=-65.184\n",
      "[tile 18/25] RA=92.898 Dec=-65.184\n",
      "[tile 19/25] RA=93.498 Dec=-65.184\n",
      "[tile 20/25] RA=94.098 Dec=-65.184\n",
      "[tile 21/25] RA=91.698 Dec=-64.584\n",
      "[tile 22/25] RA=92.298 Dec=-64.584\n",
      "[tile 23/25] RA=92.898 Dec=-64.584\n",
      "[tile 24/25] RA=93.498 Dec=-64.584\n",
      "[tile 25/25] RA=94.098 Dec=-64.584\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=42)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=40)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=3)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=92.60 Dec=-65.06 ==\n",
      "[tile 1/25] RA=91.398 Dec=-66.260\n",
      "[tile 2/25] RA=91.998 Dec=-66.260\n",
      "[tile 3/25] RA=92.598 Dec=-66.260\n",
      "[tile 4/25] RA=93.198 Dec=-66.260\n",
      "[tile 5/25] RA=93.798 Dec=-66.260\n",
      "[tile 6/25] RA=91.398 Dec=-65.660\n",
      "[tile 7/25] RA=91.998 Dec=-65.660\n",
      "[tile 8/25] RA=92.598 Dec=-65.660\n",
      "[tile 9/25] RA=93.198 Dec=-65.660\n",
      "[tile 10/25] RA=93.798 Dec=-65.660\n",
      "[tile 11/25] RA=91.398 Dec=-65.060\n",
      "[tile 12/25] RA=91.998 Dec=-65.060\n",
      "[tile 13/25] RA=92.598 Dec=-65.060\n",
      "[tile 14/25] RA=93.198 Dec=-65.060\n",
      "[tile 15/25] RA=93.798 Dec=-65.060\n",
      "[tile 16/25] RA=91.398 Dec=-64.460\n",
      "[tile 17/25] RA=91.998 Dec=-64.460\n",
      "[tile 18/25] RA=92.598 Dec=-64.460\n",
      "[tile 19/25] RA=93.198 Dec=-64.460\n",
      "[tile 20/25] RA=93.798 Dec=-64.460\n",
      "[tile 21/25] RA=91.398 Dec=-63.860\n",
      "[tile 22/25] RA=91.998 Dec=-63.860\n",
      "[tile 23/25] RA=92.598 Dec=-63.860\n",
      "[tile 24/25] RA=93.198 Dec=-63.860\n",
      "[tile 25/25] RA=93.798 Dec=-63.860\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=39)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=39)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=8)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=92.12 Dec=-64.44 ==\n",
      "[tile 1/25] RA=90.921 Dec=-65.639\n",
      "[tile 2/25] RA=91.521 Dec=-65.639\n",
      "[tile 3/25] RA=92.121 Dec=-65.639\n",
      "[tile 4/25] RA=92.721 Dec=-65.639\n",
      "[tile 5/25] RA=93.321 Dec=-65.639\n",
      "[tile 6/25] RA=90.921 Dec=-65.039\n",
      "[tile 7/25] RA=91.521 Dec=-65.039\n",
      "[tile 8/25] RA=92.121 Dec=-65.039\n",
      "[tile 9/25] RA=92.721 Dec=-65.039\n",
      "[tile 10/25] RA=93.321 Dec=-65.039\n",
      "[tile 11/25] RA=90.921 Dec=-64.439\n",
      "[tile 12/25] RA=91.521 Dec=-64.439\n",
      "[tile 13/25] RA=92.121 Dec=-64.439\n",
      "[tile 14/25] RA=92.721 Dec=-64.439\n",
      "[tile 15/25] RA=93.321 Dec=-64.439\n",
      "[tile 16/25] RA=90.921 Dec=-63.839\n",
      "[tile 17/25] RA=91.521 Dec=-63.839\n",
      "[tile 18/25] RA=92.121 Dec=-63.839\n",
      "[tile 19/25] RA=92.721 Dec=-63.839\n",
      "[tile 20/25] RA=93.321 Dec=-63.839\n",
      "[tile 21/25] RA=90.921 Dec=-63.239\n",
      "[tile 22/25] RA=91.521 Dec=-63.239\n",
      "[tile 23/25] RA=92.121 Dec=-63.239\n",
      "[tile 24/25] RA=92.721 Dec=-63.239\n",
      "[tile 25/25] RA=93.321 Dec=-63.239\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=39)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=39)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=7)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=91.50 Dec=-63.96 ==\n",
      "[tile 1/25] RA=90.300 Dec=-65.162\n",
      "[tile 2/25] RA=90.900 Dec=-65.162\n",
      "[tile 3/25] RA=91.500 Dec=-65.162\n",
      "[tile 4/25] RA=92.100 Dec=-65.162\n",
      "[tile 5/25] RA=92.700 Dec=-65.162\n",
      "[tile 6/25] RA=90.300 Dec=-64.562\n",
      "[tile 7/25] RA=90.900 Dec=-64.562\n",
      "[tile 8/25] RA=91.500 Dec=-64.562\n",
      "[tile 9/25] RA=92.100 Dec=-64.562\n",
      "[tile 10/25] RA=92.700 Dec=-64.562\n",
      "[tile 11/25] RA=90.300 Dec=-63.962\n",
      "[tile 12/25] RA=90.900 Dec=-63.962\n",
      "[tile 13/25] RA=91.500 Dec=-63.962\n",
      "[tile 14/25] RA=92.100 Dec=-63.962\n",
      "[tile 15/25] RA=92.700 Dec=-63.962\n",
      "[tile 16/25] RA=90.300 Dec=-63.362\n",
      "[tile 17/25] RA=90.900 Dec=-63.362\n",
      "[tile 18/25] RA=91.500 Dec=-63.362\n",
      "[tile 19/25] RA=92.100 Dec=-63.362\n",
      "[tile 20/25] RA=92.700 Dec=-63.362\n",
      "[tile 21/25] RA=90.300 Dec=-62.762\n",
      "[tile 22/25] RA=90.900 Dec=-62.762\n",
      "[tile 23/25] RA=91.500 Dec=-62.762\n",
      "[tile 24/25] RA=92.100 Dec=-62.762\n",
      "[tile 25/25] RA=92.700 Dec=-62.762\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=41)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=39)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  → J055950.66-632508.8 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=90.78 Dec=-63.66 ==\n",
      "[tile 1/25] RA=89.576 Dec=-64.862\n",
      "[tile 2/25] RA=90.176 Dec=-64.862\n",
      "[tile 3/25] RA=90.776 Dec=-64.862\n",
      "[tile 4/25] RA=91.376 Dec=-64.862\n",
      "[tile 5/25] RA=91.976 Dec=-64.862\n",
      "[tile 6/25] RA=89.576 Dec=-64.262\n",
      "  [fallback] AllWISE-only tile\n",
      "[tile 7/25] RA=90.176 Dec=-64.262\n",
      "[tile 8/25] RA=90.776 Dec=-64.262\n",
      "[tile 9/25] RA=91.376 Dec=-64.262\n",
      "[tile 10/25] RA=91.976 Dec=-64.262\n",
      "[tile 11/25] RA=89.576 Dec=-63.662\n",
      "[tile 12/25] RA=90.176 Dec=-63.662\n",
      "[tile 13/25] RA=90.776 Dec=-63.662\n",
      "[tile 14/25] RA=91.376 Dec=-63.662\n",
      "[tile 15/25] RA=91.976 Dec=-63.662\n",
      "[tile 16/25] RA=89.576 Dec=-63.062\n",
      "[tile 17/25] RA=90.176 Dec=-63.062\n",
      "[tile 18/25] RA=90.776 Dec=-63.062\n",
      "[tile 19/25] RA=91.376 Dec=-63.062\n",
      "[tile 20/25] RA=91.976 Dec=-63.062\n",
      "[tile 21/25] RA=89.576 Dec=-62.462\n",
      "[tile 22/25] RA=90.176 Dec=-62.462\n",
      "[tile 23/25] RA=90.776 Dec=-62.462\n",
      "[tile 24/25] RA=91.376 Dec=-62.462\n",
      "[tile 25/25] RA=91.976 Dec=-62.462\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=44)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=44)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=9)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=90.00 Dec=-63.56 ==\n",
      "[tile 1/25] RA=88.800 Dec=-64.760\n",
      "[tile 2/25] RA=89.400 Dec=-64.760\n",
      "[tile 3/25] RA=90.000 Dec=-64.760\n",
      "[tile 4/25] RA=90.600 Dec=-64.760\n",
      "[tile 5/25] RA=91.200 Dec=-64.760\n",
      "[tile 6/25] RA=88.800 Dec=-64.160\n",
      "[tile 7/25] RA=89.400 Dec=-64.160\n",
      "[tile 8/25] RA=90.000 Dec=-64.160\n",
      "[tile 9/25] RA=90.600 Dec=-64.160\n",
      "[tile 10/25] RA=91.200 Dec=-64.160\n",
      "[tile 11/25] RA=88.800 Dec=-63.560\n",
      "[tile 12/25] RA=89.400 Dec=-63.560\n",
      "[tile 13/25] RA=90.000 Dec=-63.560\n",
      "[tile 14/25] RA=90.600 Dec=-63.560\n",
      "[tile 15/25] RA=91.200 Dec=-63.560\n",
      "[tile 16/25] RA=88.800 Dec=-62.960\n",
      "[tile 17/25] RA=89.400 Dec=-62.960\n",
      "[tile 18/25] RA=90.000 Dec=-62.960\n",
      "[tile 19/25] RA=90.600 Dec=-62.960\n",
      "[tile 20/25] RA=91.200 Dec=-62.960\n",
      "[tile 21/25] RA=88.800 Dec=-62.360\n",
      "[tile 22/25] RA=89.400 Dec=-62.360\n",
      "[tile 23/25] RA=90.000 Dec=-62.360\n",
      "[tile 24/25] RA=90.600 Dec=-62.360\n",
      "[tile 25/25] RA=91.200 Dec=-62.360\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=41)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=41)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=8)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=89.22 Dec=-63.66 ==\n",
      "[tile 1/25] RA=88.024 Dec=-64.862\n",
      "[tile 2/25] RA=88.624 Dec=-64.862\n",
      "[tile 3/25] RA=89.224 Dec=-64.862\n",
      "[tile 4/25] RA=89.824 Dec=-64.862\n",
      "[tile 5/25] RA=90.424 Dec=-64.862\n",
      "[tile 6/25] RA=88.024 Dec=-64.262\n",
      "[tile 7/25] RA=88.624 Dec=-64.262\n",
      "[tile 8/25] RA=89.224 Dec=-64.262\n",
      "[tile 9/25] RA=89.824 Dec=-64.262\n",
      "[tile 10/25] RA=90.424 Dec=-64.262\n",
      "[tile 11/25] RA=88.024 Dec=-63.662\n",
      "[tile 12/25] RA=88.624 Dec=-63.662\n",
      "[tile 13/25] RA=89.224 Dec=-63.662\n",
      "[tile 14/25] RA=89.824 Dec=-63.662\n",
      "[tile 15/25] RA=90.424 Dec=-63.662\n",
      "[tile 16/25] RA=88.024 Dec=-63.062\n",
      "[tile 17/25] RA=88.624 Dec=-63.062\n",
      "[tile 18/25] RA=89.224 Dec=-63.062\n",
      "[tile 19/25] RA=89.824 Dec=-63.062\n",
      "[tile 20/25] RA=90.424 Dec=-63.062\n",
      "[tile 21/25] RA=88.024 Dec=-62.462\n",
      "[tile 22/25] RA=88.624 Dec=-62.462\n",
      "[tile 23/25] RA=89.224 Dec=-62.462\n",
      "[tile 24/25] RA=89.824 Dec=-62.462\n",
      "[tile 25/25] RA=90.424 Dec=-62.462\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=41)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=41)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=9)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=88.50 Dec=-63.96 ==\n",
      "[tile 1/25] RA=87.300 Dec=-65.162\n",
      "[tile 2/25] RA=87.900 Dec=-65.162\n",
      "[tile 3/25] RA=88.500 Dec=-65.162\n",
      "[tile 4/25] RA=89.100 Dec=-65.162\n",
      "[tile 5/25] RA=89.700 Dec=-65.162\n",
      "[tile 6/25] RA=87.300 Dec=-64.562\n",
      "[tile 7/25] RA=87.900 Dec=-64.562\n",
      "[tile 8/25] RA=88.500 Dec=-64.562\n",
      "[tile 9/25] RA=89.100 Dec=-64.562\n",
      "[tile 10/25] RA=89.700 Dec=-64.562\n",
      "[tile 11/25] RA=87.300 Dec=-63.962\n",
      "[tile 12/25] RA=87.900 Dec=-63.962\n",
      "[tile 13/25] RA=88.500 Dec=-63.962\n",
      "[tile 14/25] RA=89.100 Dec=-63.962\n",
      "[tile 15/25] RA=89.700 Dec=-63.962\n",
      "[tile 16/25] RA=87.300 Dec=-63.362\n",
      "[tile 17/25] RA=87.900 Dec=-63.362\n",
      "[tile 18/25] RA=88.500 Dec=-63.362\n",
      "[tile 19/25] RA=89.100 Dec=-63.362\n",
      "[tile 20/25] RA=89.700 Dec=-63.362\n",
      "[tile 21/25] RA=87.300 Dec=-62.762\n",
      "[tile 22/25] RA=87.900 Dec=-62.762\n",
      "[tile 23/25] RA=88.500 Dec=-62.762\n",
      "[tile 24/25] RA=89.100 Dec=-62.762\n",
      "[tile 25/25] RA=89.700 Dec=-62.762\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=40)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=39)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=7)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=87.88 Dec=-64.44 ==\n",
      "[tile 1/25] RA=86.679 Dec=-65.639\n",
      "[tile 2/25] RA=87.279 Dec=-65.639\n",
      "[tile 3/25] RA=87.879 Dec=-65.639\n",
      "[tile 4/25] RA=88.479 Dec=-65.639\n",
      "[tile 5/25] RA=89.079 Dec=-65.639\n",
      "[tile 6/25] RA=86.679 Dec=-65.039\n",
      "[tile 7/25] RA=87.279 Dec=-65.039\n",
      "[tile 8/25] RA=87.879 Dec=-65.039\n",
      "[tile 9/25] RA=88.479 Dec=-65.039\n",
      "[tile 10/25] RA=89.079 Dec=-65.039\n",
      "[tile 11/25] RA=86.679 Dec=-64.439\n",
      "[tile 12/25] RA=87.279 Dec=-64.439\n",
      "[tile 13/25] RA=87.879 Dec=-64.439\n",
      "[tile 14/25] RA=88.479 Dec=-64.439\n",
      "[tile 15/25] RA=89.079 Dec=-64.439\n",
      "[tile 16/25] RA=86.679 Dec=-63.839\n",
      "[tile 17/25] RA=87.279 Dec=-63.839\n",
      "[tile 18/25] RA=87.879 Dec=-63.839\n",
      "[tile 19/25] RA=88.479 Dec=-63.839\n",
      "[tile 20/25] RA=89.079 Dec=-63.839\n",
      "[tile 21/25] RA=86.679 Dec=-63.239\n",
      "[tile 22/25] RA=87.279 Dec=-63.239\n",
      "[tile 23/25] RA=87.879 Dec=-63.239\n",
      "[tile 24/25] RA=88.479 Dec=-63.239\n",
      "[tile 25/25] RA=89.079 Dec=-63.239\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=44)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=43)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=5)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=87.40 Dec=-65.06 ==\n",
      "[tile 1/25] RA=86.202 Dec=-66.260\n",
      "[tile 2/25] RA=86.802 Dec=-66.260\n",
      "[tile 3/25] RA=87.402 Dec=-66.260\n",
      "[tile 4/25] RA=88.002 Dec=-66.260\n",
      "[tile 5/25] RA=88.602 Dec=-66.260\n",
      "[tile 6/25] RA=86.202 Dec=-65.660\n",
      "[tile 7/25] RA=86.802 Dec=-65.660\n",
      "[tile 8/25] RA=87.402 Dec=-65.660\n",
      "[tile 9/25] RA=88.002 Dec=-65.660\n",
      "[tile 10/25] RA=88.602 Dec=-65.660\n",
      "[tile 11/25] RA=86.202 Dec=-65.060\n",
      "[tile 12/25] RA=86.802 Dec=-65.060\n",
      "[tile 13/25] RA=87.402 Dec=-65.060\n",
      "[tile 14/25] RA=88.002 Dec=-65.060\n",
      "[tile 15/25] RA=88.602 Dec=-65.060\n",
      "[tile 16/25] RA=86.202 Dec=-64.460\n",
      "[tile 17/25] RA=86.802 Dec=-64.460\n",
      "[tile 18/25] RA=87.402 Dec=-64.460\n",
      "[tile 19/25] RA=88.002 Dec=-64.460\n",
      "[tile 20/25] RA=88.602 Dec=-64.460\n",
      "[tile 21/25] RA=86.202 Dec=-63.860\n",
      "[tile 22/25] RA=86.802 Dec=-63.860\n",
      "[tile 23/25] RA=87.402 Dec=-63.860\n",
      "[tile 24/25] RA=88.002 Dec=-63.860\n",
      "[tile 25/25] RA=88.602 Dec=-63.860\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=43)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=42)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=10)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=87.10 Dec=-65.78 ==\n",
      "[tile 1/25] RA=85.902 Dec=-66.984\n",
      "[tile 2/25] RA=86.502 Dec=-66.984\n",
      "[tile 3/25] RA=87.102 Dec=-66.984\n",
      "[tile 4/25] RA=87.702 Dec=-66.984\n",
      "[tile 5/25] RA=88.302 Dec=-66.984\n",
      "[tile 6/25] RA=85.902 Dec=-66.384\n",
      "[tile 7/25] RA=86.502 Dec=-66.384\n",
      "[tile 8/25] RA=87.102 Dec=-66.384\n",
      "[tile 9/25] RA=87.702 Dec=-66.384\n",
      "[tile 10/25] RA=88.302 Dec=-66.384\n",
      "[tile 11/25] RA=85.902 Dec=-65.784\n",
      "[tile 12/25] RA=86.502 Dec=-65.784\n",
      "[tile 13/25] RA=87.102 Dec=-65.784\n",
      "[tile 14/25] RA=87.702 Dec=-65.784\n",
      "[tile 15/25] RA=88.302 Dec=-65.784\n",
      "[tile 16/25] RA=85.902 Dec=-65.184\n",
      "[tile 17/25] RA=86.502 Dec=-65.184\n",
      "[tile 18/25] RA=87.102 Dec=-65.184\n",
      "[tile 19/25] RA=87.702 Dec=-65.184\n",
      "[tile 20/25] RA=88.302 Dec=-65.184\n",
      "[tile 21/25] RA=85.902 Dec=-64.584\n",
      "[tile 22/25] RA=86.502 Dec=-64.584\n",
      "[tile 23/25] RA=87.102 Dec=-64.584\n",
      "[tile 24/25] RA=87.702 Dec=-64.584\n",
      "[tile 25/25] RA=88.302 Dec=-64.584\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=44)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=43)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=9)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=87.00 Dec=-66.56 ==\n",
      "[tile 1/25] RA=85.800 Dec=-67.760\n",
      "[tile 2/25] RA=86.400 Dec=-67.760\n",
      "[tile 3/25] RA=87.000 Dec=-67.760\n",
      "[tile 4/25] RA=87.600 Dec=-67.760\n",
      "[tile 5/25] RA=88.200 Dec=-67.760\n",
      "[tile 6/25] RA=85.800 Dec=-67.160\n",
      "[tile 7/25] RA=86.400 Dec=-67.160\n",
      "[tile 8/25] RA=87.000 Dec=-67.160\n",
      "[tile 9/25] RA=87.600 Dec=-67.160\n",
      "[tile 10/25] RA=88.200 Dec=-67.160\n",
      "[tile 11/25] RA=85.800 Dec=-66.560\n",
      "[tile 12/25] RA=86.400 Dec=-66.560\n",
      "[tile 13/25] RA=87.000 Dec=-66.560\n",
      "[tile 14/25] RA=87.600 Dec=-66.560\n",
      "[tile 15/25] RA=88.200 Dec=-66.560\n",
      "[tile 16/25] RA=85.800 Dec=-65.960\n",
      "[tile 17/25] RA=86.400 Dec=-65.960\n",
      "[tile 18/25] RA=87.000 Dec=-65.960\n",
      "[tile 19/25] RA=87.600 Dec=-65.960\n",
      "[tile 20/25] RA=88.200 Dec=-65.960\n",
      "[tile 21/25] RA=85.800 Dec=-65.360\n",
      "[tile 22/25] RA=86.400 Dec=-65.360\n",
      "[tile 23/25] RA=87.000 Dec=-65.360\n",
      "[tile 24/25] RA=87.600 Dec=-65.360\n",
      "[tile 25/25] RA=88.200 Dec=-65.360\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=42)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=42)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=8)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  [note] soft-verified=0\n",
      "\n",
      "== Center RA=87.10 Dec=-67.34 ==\n",
      "[tile 1/25] RA=85.902 Dec=-68.536\n",
      "[tile 2/25] RA=86.502 Dec=-68.536\n",
      "[tile 3/25] RA=87.102 Dec=-68.536\n",
      "[tile 4/25] RA=87.702 Dec=-68.536\n",
      "[tile 5/25] RA=88.302 Dec=-68.536\n",
      "[tile 6/25] RA=85.902 Dec=-67.936\n",
      "[tile 7/25] RA=86.502 Dec=-67.936\n",
      "[tile 8/25] RA=87.102 Dec=-67.936\n",
      "[tile 9/25] RA=87.702 Dec=-67.936\n",
      "[tile 10/25] RA=88.302 Dec=-67.936\n",
      "[tile 11/25] RA=85.902 Dec=-67.336\n",
      "[tile 12/25] RA=86.502 Dec=-67.336\n",
      "[tile 13/25] RA=87.102 Dec=-67.336\n",
      "[tile 14/25] RA=87.702 Dec=-67.336\n",
      "[tile 15/25] RA=88.302 Dec=-67.336\n",
      "[tile 16/25] RA=85.902 Dec=-66.736\n",
      "[tile 17/25] RA=86.502 Dec=-66.736\n",
      "[tile 18/25] RA=87.102 Dec=-66.736\n",
      "[tile 19/25] RA=87.702 Dec=-66.736\n",
      "[tile 20/25] RA=88.302 Dec=-66.736\n",
      "[tile 21/25] RA=85.902 Dec=-66.136\n",
      "[tile 22/25] RA=86.502 Dec=-66.136\n",
      "[tile 23/25] RA=87.102 Dec=-66.136\n",
      "[tile 24/25] RA=87.702 Dec=-66.136\n",
      "[tile 25/25] RA=88.302 Dec=-66.136\n",
      "[save] master anomalies: cnt_anomaly\\out\\stable_anomalies_master_20251017-224713.csv (N=40)\n",
      "[save] enriched (all): cnt_anomaly\\out\\stable_enriched_all_20251017-224713.csv (N=39)\n",
      "[save] GOLD set → cnt_anomaly\\out\\strict_gold_candidates_20251017-224713.csv (N=12)\n",
      "[save] cnt_anomaly\\out\\verify_soft_20251017-224713.csv\n",
      "  → J054803.94-684239.0 : SEMI-NOVEL\n",
      "  [center] no NOVEL; continuing…\n",
      "\n",
      "== Center RA=87.40 Dec=-68.06 ==\n",
      "[tile 1/25] RA=86.202 Dec=-69.260\n",
      "[tile 2/25] RA=86.802 Dec=-69.260\n",
      "[tile 3/25] RA=87.402 Dec=-69.260\n",
      "[tile 4/25] RA=88.002 Dec=-69.260\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 108\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[targets] ecliptic rings+grids: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(centers)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m centers\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    107\u001b[39m \u001b[38;5;66;03m# 3) Launch — stops at first NOVEL and writes dossier/gallery\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m wid = \u001b[43mfused_v6_scan_centers\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenters\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_on_first\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[result] NOVEL =\u001b[39m\u001b[33m\"\u001b[39m, wid)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mfused_v6_scan_centers\u001b[39m\u001b[34m(centers, stop_on_first)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m (cra,cdec) \u001b[38;5;129;01min\u001b[39;00m centers:\n\u001b[32m     50\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m== Center RA=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcra\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m Dec=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcdec\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     master, master_path = \u001b[43mdiscovery_sweep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstamp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m master.empty:\n\u001b[32m     53\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m  [note] master=0\u001b[39m\u001b[33m\"\u001b[39m); \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 248\u001b[39m, in \u001b[36mdiscovery_sweep\u001b[39m\u001b[34m(center_ra, center_dec, stamp)\u001b[39m\n\u001b[32m    246\u001b[39m gaia = _safe_read_csv(gaia_cache, expect_cols=[\u001b[33m\"\u001b[39m\u001b[33mRA_ICRS\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mDE_ICRS\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mGmag\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mBP-RP\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mparallax\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpmRA\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mpmDE\u001b[39m\u001b[33m\"\u001b[39m]) \u001b[38;5;28;01mif\u001b[39;00m gaia_cache.exists() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gaia \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m248\u001b[39m     gaia = \u001b[43mvizier_query\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mI/355/gaiadr3\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mra\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRADIUS_DEG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRA_ICRS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDE_ICRS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGmag\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mBP-RP\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mparallax\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpmRA\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpmDE\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mrow_limit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mN_MAX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    251\u001b[39m     _write_csv_atomic(gaia, gaia_cache)\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m gaia.empty:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[40]\u001b[39m\u001b[32m, line 116\u001b[39m, in \u001b[36mvizier_query\u001b[39m\u001b[34m(catalog, ra, dec, r_deg, columns, row_limit)\u001b[39m\n\u001b[32m    114\u001b[39m Vizier.ROW_LIMIT = row_limit \u001b[38;5;129;01mor\u001b[39;00m CFG[\u001b[33m\"\u001b[39m\u001b[33mN_MAX\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    115\u001b[39m v = Vizier(columns=(columns \u001b[38;5;129;01mor\u001b[39;00m [\u001b[33m\"\u001b[39m\u001b[33m**\u001b[39m\u001b[33m\"\u001b[39m]))\n\u001b[32m--> \u001b[39m\u001b[32m116\u001b[39m res = \u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquery_region\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mra\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mdec\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mradius\u001b[49m\u001b[43m=\u001b[49m\u001b[43mr_deg\u001b[49m\u001b[43m*\u001b[49m\u001b[43mu\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdeg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcatalog\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m res[\u001b[32m0\u001b[39m].to_pandas() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(res) \u001b[38;5;28;01melse\u001b[39;00m pd.DataFrame()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\class_or_instance.py:25\u001b[39m, in \u001b[36mclass_or_instance.__get__.<locals>.f\u001b[39m\u001b[34m(*args, **kwds)\u001b[39m\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mf\u001b[39m(*args, **kwds):\n\u001b[32m     24\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m obj \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     26\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     27\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.fn(\u001b[38;5;28mcls\u001b[39m, *args, **kwds)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\utils\\process_asyncs.py:28\u001b[39m, in \u001b[36masync_to_sync.<locals>.create_method.<locals>.newmethod\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;129m@class_or_instance\u001b[39m\n\u001b[32m     25\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnewmethod\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m     26\u001b[39m     verbose = kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mverbose\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     response = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43masync_method_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mget_query_payload\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m kwargs.get(\u001b[33m'\u001b[39m\u001b[33mfield_help\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m     30\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\vizier\\core.py:540\u001b[39m, in \u001b[36mVizierClass.query_region_async\u001b[39m\u001b[34m(self, coordinates, radius, inner_radius, width, height, catalog, get_query_payload, cache, return_type, column_filters, frame)\u001b[39m\n\u001b[32m    537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m get_query_payload:\n\u001b[32m    538\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m data_payload\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    541\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_server_to_url\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_type\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    542\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata_payload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mTIMEOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    543\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\query.py:379\u001b[39m, in \u001b[36mBaseQuery._request\u001b[39m\u001b[34m(self, method, url, params, data, headers, files, save, savedir, timeout, cache, stream, auth, continuation, verify, allow_redirects, json, return_response_on_save)\u001b[39m\n\u001b[32m    377\u001b[39m     response = query.from_cache(\u001b[38;5;28mself\u001b[39m.cache_location, cache_conf.cache_timeout)\n\u001b[32m    378\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m response:\n\u001b[32m--> \u001b[39m\u001b[32m379\u001b[39m         response = \u001b[43mquery\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_session\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    380\u001b[39m \u001b[43m                                 \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcache_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    381\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    382\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    383\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    385\u001b[39m \u001b[43m                                 \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    386\u001b[39m         to_cache(response, query.request_file(\u001b[38;5;28mself\u001b[39m.cache_location))\n\u001b[32m    388\u001b[39m \u001b[38;5;28mself\u001b[39m._last_query = query\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\astroquery\\query.py:77\u001b[39m, in \u001b[36mAstroQuery.request\u001b[39m\u001b[34m(self, session, cache_location, stream, auth, verify, allow_redirects, json)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrequest\u001b[39m(\u001b[38;5;28mself\u001b[39m, session, cache_location=\u001b[38;5;28;01mNone\u001b[39;00m, stream=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m     75\u001b[39m             auth=\u001b[38;5;28;01mNone\u001b[39;00m, verify=\u001b[38;5;28;01mTrue\u001b[39;00m, allow_redirects=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     76\u001b[39m             json=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfiles\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverify\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverify\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     82\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connection.py:790\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    787\u001b[39m     \u001b[38;5;66;03m# Remove trailing '.' from fqdn hostnames to allow certificate validation\u001b[39;00m\n\u001b[32m    788\u001b[39m     server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m790\u001b[39m     sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m        \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    801\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    803\u001b[39m \u001b[43m        \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    804\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    805\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    806\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    807\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    808\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n\u001b[32m    810\u001b[39m \u001b[38;5;66;03m# If an error occurs during connection/handshake we may need to release\u001b[39;00m\n\u001b[32m    811\u001b[39m \u001b[38;5;66;03m# our lock so another connection can probe the origin.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connection.py:969\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    966\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m is_ipaddress(normalized):\n\u001b[32m    967\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m969\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    970\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    971\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    972\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    973\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    974\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    975\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    976\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    977\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    978\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    979\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    982\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    983\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m assert_fingerprint:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    476\u001b[39m         context.load_cert_chain(certfile, keyfile, key_password)\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    521\u001b[39m     SSLTransport._validate_ssl_context_for_tls_in_tls(ssl_context)\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1073\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m:\n\u001b[32m   1074\u001b[39m                 \u001b[38;5;66;03m# non-blocking\u001b[39;00m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[32m   1078\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1370\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout == \u001b[32m0.0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m block:\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m   1374\u001b[39m     \u001b[38;5;28mself\u001b[39m.settimeout(timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === Ecliptic Polar Hunt — no |b| filter, deeper verify (18′, 24′), stop-on-NOVEL ===\n",
    "import numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import astropy.units as u\n",
    "from astropy.coordinates import SkyCoord\n",
    "from astroquery.vizier import Vizier\n",
    "\n",
    "# 1) Open up verification neighborhood (more stable K at poles)\n",
    "CFG[\"VERIFY_SCALES\"] = (1.5, 3.0, 6.0, 9.0, 12.0, 18.0, 24.0)\n",
    "# Favor a wider net (keeps rigor: K_VERIFY=4)\n",
    "CFG.update({\n",
    "    \"N_MAX\": max(CFG.get(\"N_MAX\", 7000), 12000),\n",
    "    \"XMM_RADIUS_ARCSEC\": max(CFG.get(\"XMM_RADIUS_ARCSEC\", 2.0), 2.2),\n",
    "    \"GOLD_W23_MIN\": min(CFG.get(\"GOLD_W23_MIN\", 2.7), 2.6),\n",
    "    \"K_GOLD\": 4,\n",
    "    \"K_VERIFY\": 4,\n",
    "    \"GALAXY_MODE\": False,  # allow AGN-like (point-like) too\n",
    "})\n",
    "\n",
    "def ecliptic_pole_targets(north=True, ring_radii=(3.0, 6.0), n_ring=24, grid_span=2.0, grid_step=1.0):\n",
    "    \"\"\"Ring(s) + grid around ecliptic pole; NO galactic |b| gating.\"\"\"\n",
    "    ra0, dec0 = (270.0, +66.56) if north else (90.0, -66.56)\n",
    "    targets=[]\n",
    "    # rings\n",
    "    for rad in ring_radii:\n",
    "        for th in np.linspace(0, 2*np.pi, n_ring, endpoint=False):\n",
    "            ra  = (ra0 + rad*np.cos(th)) % 360.0\n",
    "            dec = np.clip(dec0 + rad*np.sin(th), -89.5, 89.5)\n",
    "            targets.append((float(ra), float(dec)))\n",
    "    # grid\n",
    "    xs = np.arange(-grid_span, grid_span+1e-9, grid_step)\n",
    "    ys = np.arange(-grid_span, grid_span+1e-9, grid_step)\n",
    "    for dx in xs:\n",
    "        for dy in ys:\n",
    "            ra  = (ra0 + dx) % 360.0\n",
    "            dec = np.clip(dec0 + dy, -89.5, 89.5)\n",
    "            targets.append((float(ra), float(dec)))\n",
    "    # de-dup keep-order\n",
    "    seen, uniq = set(), []\n",
    "    for c in targets:\n",
    "        if c not in seen:\n",
    "            uniq.append(c); seen.add(c)\n",
    "    return uniq\n",
    "\n",
    "def fused_v6_scan_centers(centers, stop_on_first=True):\n",
    "    \"\"\"Use your v6 helpers over an explicit list of centers; stop on first NOVEL.\"\"\"\n",
    "    stamp = ts()\n",
    "    first = None\n",
    "    for (cra,cdec) in centers:\n",
    "        print(f\"\\n== Center RA={cra:.2f} Dec={cdec:.2f} ==\")\n",
    "        master, master_path = discovery_sweep(cra, cdec, stamp)\n",
    "        if master.empty:\n",
    "            print(\"  [note] master=0\"); continue\n",
    "        gold, gold_path = enrich_allwise(master, stamp)\n",
    "        if gold.empty:\n",
    "            print(\"  [note] gold=0\"); continue\n",
    "        vf = verify_soft(gold, stamp)\n",
    "        conf = vf[vf[\"pass\"]==True].copy()\n",
    "        if conf.empty:\n",
    "            print(\"  [note] soft-verified=0\"); continue\n",
    "        # novelty + star veto\n",
    "        for wid in conf[\"AllWISE\"].astype(str).tolist():\n",
    "            q = Vizier(columns=[\"RAJ2000\",\"DEJ2000\",\"W1mag\",\"W2mag\",\"W3mag\"]).query_constraints(catalog=\"II/328/allwise\", AllWISE=wid)\n",
    "            if len(q)==0 or len(q[0])==0: continue\n",
    "            r = q[0].to_pandas().iloc[0]\n",
    "            ra, dec = float(r[\"RAJ2000\"]), float(r[\"DEJ2000\"])\n",
    "            if gaia_star_like(ra, dec): \n",
    "                continue\n",
    "            verdict, rank, sim_t, ned_t, ned_z = novelty_check(ra, dec)\n",
    "            print(f\"  → {wid} : {verdict}\")\n",
    "            row = dict(AllWISE=wid, RA=ra, Dec=dec,\n",
    "                       W1W2=float(r.get(\"W1mag\",np.nan)-r.get(\"W2mag\",np.nan)) if np.isfinite(r.get(\"W1mag\",np.nan)) and np.isfinite(r.get(\"W2mag\",np.nan)) else np.nan,\n",
    "                       W2W3=float(r.get(\"W2mag\",np.nan)-r.get(\"W3mag\",np.nan)) if np.isfinite(r.get(\"W2mag\",np.nan)) and np.isfinite(r.get(\"W3mag\",np.nan)) else np.nan,\n",
    "                       novelty=verdict, SIMBAD=sim_t, NED=ned_t, z=ned_z, run_stamp=stamp)\n",
    "            nov_path = OUT/f\"novelty_candidates_{stamp}.csv\"\n",
    "            pd.DataFrame([row]).to_csv(nov_path, mode=(\"a\" if Path(nov_path).exists() else \"w\"),\n",
    "                                       header=not Path(nov_path).exists(), index=False)\n",
    "            if verdict == \"NOVEL\":\n",
    "                first = wid\n",
    "                d = make_dossier(wid, stamp)\n",
    "                html = OUT/f\"novelty_gallery_{stamp}.html\"\n",
    "                with open(html,\"w\",encoding=\"utf-8\") as f:\n",
    "                    f.write(\"<html><head><meta charset='utf-8'><title>CNT NOVEL</title>\"\n",
    "                            \"<style>body{font-family:system-ui;margin:24px} .card{display:flex;gap:16px;align-items:center;\"\n",
    "                            \"border:1px solid #eee;border-radius:12px;padding:12px;margin:10px 0;} img{border-radius:8px;max-width:220px}</style></head><body>\")\n",
    "                    f.write(f\"<h1>NOVEL — {stamp}</h1><div class='card'>\")\n",
    "                    if d and d.get(\"cutout\") and Path(d[\"cutout\"]).exists():\n",
    "                        f.write(f\"<img src='../{Path(d['cutout']).relative_to(OUT)}'/>\")\n",
    "                    else:\n",
    "                        f.write(\"<div style='width:220px;height:160px;background:#eee;border-radius:8px'></div>\")\n",
    "                    f.write(f\"<div><div><b>AllWISE:</b> {wid}</div>\")\n",
    "                    if d and d.get(\"sed\") and Path(d[\"sed\"]).exists():\n",
    "                        f.write(f\"<div><a href='../{Path(d['sed']).relative_to(OUT)}'>SED</a> · \"\n",
    "                                f\"<a href='../{Path(d['md']).relative_to(OUT)}'>Dossier</a></div>\")\n",
    "                    f.write(\"</div></div></body></html>\")\n",
    "                print(f\"\\n== NOVEL == {wid}  [open] {html}\")\n",
    "                if stop_on_first: return wid\n",
    "        print(\"  [center] no NOVEL; continuing…\")\n",
    "    print(\"\\n[done] polar hunt finished — no NOVEL at these settings.\")\n",
    "    return first\n",
    "\n",
    "# 2) Build combined target set: SEP & NEP rings + 5×5 grids\n",
    "centers = ecliptic_pole_targets(north=False, ring_radii=(3.0,6.0), n_ring=24, grid_span=2.0, grid_step=1.0) \\\n",
    "        + ecliptic_pole_targets(north=True,  ring_radii=(3.0,6.0), n_ring=24, grid_span=2.0, grid_step=1.0)\n",
    "print(f\"[targets] ecliptic rings+grids: {len(centers)} centers\")\n",
    "\n",
    "# 3) Launch — stops at first NOVEL and writes dossier/gallery\n",
    "wid = fused_v6_scan_centers(centers, stop_on_first=True)\n",
    "print(\"\\n[result] NOVEL =\", wid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4f3eba-78c3-43bd-8c98-ac5fe8866a01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
