{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fc6ba6d3",
   "metadata": {},
   "source": [
    "# CNT 3D Genomic Correlate Field — Clean Notebook\n",
    "Minimal, robust pipeline to render a 3D field of genes with threads across correlates.\n",
    "- Works with **scored multivariate tables** (e.g., `resonance_score`, `cnt_score`, degrees, tissues)\n",
    "- Avoids full n^2 correlation matrices (memory-safe)\n",
    "- Produces: a static **PNG** and optional interactive **HTML**\n",
    "\n",
    "**Pipeline**\n",
    "1. Config & imports  \n",
    "2. Load table → build one feature vector per gene  \n",
    "3. kNN graph in cosine space (correlate threads)  \n",
    "4. Mutual-kNN + light pruning (de-spike)  \n",
    "5. 3D layout & render (PNG + HTML)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a0054816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook ready. Edit DATA_PATH if needed and run all cells ↓\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 1) Config & imports ==================================================\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# Path to your CSV/TSV\n",
    "DATA_PATH = r\"C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\"  # <- change if needed\n",
    "\n",
    "# Outputs (written next to the notebook by default)\n",
    "PNG_PATH  = \"CNT_genomic_network_3D.png\"\n",
    "HTML_PATH = \"CNT_genomic_network_3D.html\"\n",
    "\n",
    "# Feature selection & behavior\n",
    "INDEX_COL      = \"gene_name\"  # fallback to 'rsid' or first non-numeric if missing\n",
    "FEATURE_WISHLIST = [\n",
    "    \"resonance_score\", \"cnt_score\", \"structure_score\",\n",
    "    \"gene_deg\", \"ccre_deg\", \"tissue_hits\", \"tissues\"\n",
    "]\n",
    "\n",
    "# Graph/Render knobs\n",
    "SEED           = 42\n",
    "MAX_GENES      = 12000     # cap by variance (raise/lower for density/speed)\n",
    "K_NEIGHBORS    = 10        # edges per node before filtering\n",
    "EDGE_CAP       = 200_000   # absolute safety cap\n",
    "MUTUAL_K       = 8         # keep edge only if mutual top-K (de-spike)\n",
    "PRUNE_FRACTION = 0.25      # drop weakest 25% edges\n",
    "USE_SPRING     = True      # False -> instant random 3D\n",
    "SPRING_ITERS   = 180       # iterations for 3D spring\n",
    "SPRING_LIMIT   = 6000      # if nodes > limit, auto-skip spring\n",
    "\n",
    "print(\"Notebook ready. Edit DATA_PATH if needed and run all cells ↓\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50d001f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index column: gene_name\n",
      "Features used: ['resonance_score', 'cnt_score', 'structure_score', 'gene_deg', 'ccre_deg', 'tissue_hits', 'tissues']\n",
      "Genes (rows): 12000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>resonance_score</th>\n",
       "      <th>cnt_score</th>\n",
       "      <th>structure_score</th>\n",
       "      <th>gene_deg</th>\n",
       "      <th>ccre_deg</th>\n",
       "      <th>tissue_hits</th>\n",
       "      <th>tissues</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gene_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Y_RNA</th>\n",
       "      <td>1.0</td>\n",
       "      <td>7.808606</td>\n",
       "      <td>6.808606</td>\n",
       "      <td>404.0</td>\n",
       "      <td>1.245467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HLA-DQA1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.894240</td>\n",
       "      <td>5.894240</td>\n",
       "      <td>96.0</td>\n",
       "      <td>7.184971</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Metazoa_SRP</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.147494</td>\n",
       "      <td>5.147494</td>\n",
       "      <td>85.0</td>\n",
       "      <td>1.228758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000298426</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.542753</td>\n",
       "      <td>5.542753</td>\n",
       "      <td>76.0</td>\n",
       "      <td>6.417178</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ENSG00000271581</th>\n",
       "      <td>1.0</td>\n",
       "      <td>6.711916</td>\n",
       "      <td>5.711916</td>\n",
       "      <td>65.0</td>\n",
       "      <td>12.461538</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 resonance_score  cnt_score  structure_score  gene_deg  \\\n",
       "gene_name                                                                \n",
       "Y_RNA                        1.0   7.808606         6.808606     404.0   \n",
       "HLA-DQA1                     1.0   6.894240         5.894240      96.0   \n",
       "Metazoa_SRP                  1.0   6.147494         5.147494      85.0   \n",
       "ENSG00000298426              1.0   6.542753         5.542753      76.0   \n",
       "ENSG00000271581              1.0   6.711916         5.711916      65.0   \n",
       "\n",
       "                  ccre_deg  tissue_hits  tissues  \n",
       "gene_name                                         \n",
       "Y_RNA             1.245467          0.0      NaN  \n",
       "HLA-DQA1          7.184971          0.0      NaN  \n",
       "Metazoa_SRP       1.228758          0.0      NaN  \n",
       "ENSG00000298426   6.417178          0.0      NaN  \n",
       "ENSG00000271581  12.461538          0.0      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# === 2) Load table & assemble per-gene feature matrix =====================\n",
    "def load_feature_table(path, index_col, wishlist):\n",
    "    # Robust read\n",
    "    try:\n",
    "        df = pd.read_csv(path, sep=None, engine=\"python\")\n",
    "    except Exception:\n",
    "        try:\n",
    "            df = pd.read_csv(path, sep=\"\\t\", engine=\"python\")\n",
    "        except Exception:\n",
    "            df = pd.read_csv(path, sep=\",\", engine=\"python\")\n",
    "    # Pick index\n",
    "    if index_col not in df.columns:\n",
    "        for fallback in (\"rsid\",):\n",
    "            if fallback in df.columns:\n",
    "                index_col = fallback; break\n",
    "        else:\n",
    "            nonnum = [c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "            index_col = nonnum[0] if nonnum else df.columns[0]\n",
    "    df = df.dropna(subset=[index_col])\n",
    "    # Feature columns\n",
    "    numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    feat_cols = [c for c in wishlist if c in df.columns]\n",
    "    if not feat_cols:\n",
    "        feat_cols = numeric_cols\n",
    "    use_cols = [index_col] + feat_cols\n",
    "    F = df[use_cols].copy()\n",
    "    # Aggregate\n",
    "    agg = {c: \"mean\" for c in feat_cols}\n",
    "    for key in (\"resonance_score\", \"cnt_score\", \"structure_score\"):\n",
    "        if key in agg: agg[key] = \"max\"\n",
    "    GDF = F.groupby(index_col).agg(agg)\n",
    "    GDF = GDF.dropna(how=\"all\")\n",
    "    GDF = GDF.fillna(GDF.median(numeric_only=True))\n",
    "    if GDF.shape[0] > MAX_GENES:\n",
    "        var = GDF.var(axis=1, numeric_only=True).sort_values(ascending=False)\n",
    "        GDF = GDF.loc[var.index[:MAX_GENES]]\n",
    "    return index_col, feat_cols, GDF\n",
    "\n",
    "INDEX_COL, FEATURES_USED, GDF = load_feature_table(DATA_PATH, INDEX_COL, FEATURE_WISHLIST)\n",
    "print(\"Index column:\", INDEX_COL)\n",
    "print(\"Features used:\", FEATURES_USED)\n",
    "print(\"Genes (rows):\", GDF.shape[0])\n",
    "GDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2941e1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_24044\\2963150066.py:4: RuntimeWarning: Mean of empty slice\n",
      "  mu = np.nanmean(M, axis=0, keepdims=True)\n",
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2015: RuntimeWarning: Degrees of freedom <= 0 for slice.\n",
      "  var = nanvar(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial graph: {'nodes': 12000, 'edges': 112087}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 3) Build kNN graph in cosine space (memory-safe) =====================\n",
    "def standardize_rows(M):\n",
    "    M = M.astype(\"float32\")\n",
    "    mu = np.nanmean(M, axis=0, keepdims=True)\n",
    "    sd = np.nanstd(M, axis=0, ddof=1, keepdims=True); sd[sd==0]=1.0\n",
    "    Z = (M - mu) / sd\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    norms = np.linalg.norm(Z, axis=1, keepdims=True); norms[norms==0]=1.0\n",
    "    return Z / norms\n",
    "\n",
    "def knn_graph_cosine(Z, genes, k=10, edge_cap=200_000):\n",
    "    try:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nn = NearestNeighbors(n_neighbors=min(k+1, Z.shape[0]), metric=\"cosine\", algorithm=\"brute\")\n",
    "        nn.fit(Z); dists, idxs = nn.kneighbors(Z, return_distance=True)\n",
    "        dists, idxs = dists[:,1:], idxs[:,1:]; sims = 1.0 - dists\n",
    "    except Exception:\n",
    "        K = min(k, Z.shape[0]-1)\n",
    "        sims = np.empty((Z.shape[0], K), dtype=\"float32\")\n",
    "        idxs = np.empty((Z.shape[0], K), dtype=np.int32)\n",
    "        bs = 1024\n",
    "        for i0 in range(0, Z.shape[0], bs):\n",
    "            i1 = min(i0+bs, Z.shape[0])\n",
    "            block = Z[i0:i1] @ Z.T\n",
    "            for i in range(i1-i0): block[i, i0+i] = -np.inf\n",
    "            topk = np.argpartition(-block, K, axis=1)[:, :K]\n",
    "            vals = np.take_along_axis(block, topk, axis=1)\n",
    "            order = np.argsort(-vals, axis=1); r = np.arange(vals.shape[0])[:, None]\n",
    "            sims[i0:i1] = vals[r, order].astype(\"float32\")\n",
    "            idxs[i0:i1] = topk[r, order].astype(np.int32)\n",
    "    G = nx.Graph(); G.add_nodes_from(genes.tolist()); added = 0\n",
    "    for i, u in enumerate(genes):\n",
    "        for j, w in zip(idxs[i], sims[i]):\n",
    "            v = genes[int(j)]\n",
    "            if u == v: continue\n",
    "            wt = float(max(0.0, w))\n",
    "            if G.has_edge(u, v):\n",
    "                if wt > G[u][v][\"weight\"]: G[u][v][\"weight\"] = wt\n",
    "            else:\n",
    "                G.add_edge(u, v, weight=wt); added += 1\n",
    "        if added >= edge_cap: break\n",
    "    return G\n",
    "\n",
    "genes = GDF.index.to_numpy()\n",
    "Z = standardize_rows(GDF.to_numpy())\n",
    "G = knn_graph_cosine(Z, genes, k=K_NEIGHBORS, edge_cap=EDGE_CAP)\n",
    "print(\"Initial graph:\", {\"nodes\": G.number_of_nodes(), \"edges\": G.number_of_edges()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef3f4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Refined graph: {'nodes': 12000, 'edges': 4846}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 4) De-spike: mutual-kNN + prune weakest ==============================\n",
    "def mutual_knn_prune(G, mutual_k=8, prune_fraction=0.25):\n",
    "    nbrs = {u: sorted(G[u].items(), key=lambda x: x[1].get(\"weight\",0.0), reverse=True)\n",
    "            for u in G.nodes()}\n",
    "    topk = {u: set(v for v,_ in nbrs[u][:mutual_k]) for u in G.nodes()}\n",
    "    H = nx.Graph(); H.add_nodes_from(G.nodes())\n",
    "    for u,v,d in G.edges(data=True):\n",
    "        if v in topk[u] and u in topk[v]:\n",
    "            H.add_edge(u, v, **d)\n",
    "    if H.number_of_edges()>0 and prune_fraction>0:\n",
    "        w = np.array([H[u][v].get(\"weight\",0.0) for u,v in H.edges()])\n",
    "        thr = float(np.quantile(w, prune_fraction))\n",
    "        H.remove_edges_from([(u,v) for u,v in H.edges() if H[u][v].get(\"weight\",0.0) <= thr])\n",
    "    return H\n",
    "\n",
    "H = mutual_knn_prune(G, mutual_k=MUTUAL_K, prune_fraction=PRUNE_FRACTION)\n",
    "print(\"Refined graph:\", {\"nodes\": H.number_of_nodes(), \"edges\": H.number_of_edges()})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a82a5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'png': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.png', 'html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.html'}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 5) 3D layout & render (PNG + HTML) ===================================\n",
    "def layout_positions(G, use_spring=True, seed=42, iterations=180, limit=6000):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    if use_spring and G.number_of_nodes()<=limit and G.number_of_edges()>0:\n",
    "        return nx.spring_layout(G, dim=3, seed=seed, weight=\"weight\", iterations=iterations)\n",
    "    pos = {n: (float(v[0]), float(v[1]), float(v[2]))\n",
    "           for n, v in zip(G.nodes(), rng.normal(size=(G.number_of_nodes(),3)))}\n",
    "    for n in pos:\n",
    "        x,y,z = pos[n]; r = (x*x+y*y+z*z)**0.5 or 1.0\n",
    "        pos[n] = (x/r, y/r, z/r)\n",
    "    return pos\n",
    "\n",
    "pos = layout_positions(H, use_spring=USE_SPRING, seed=SEED, iterations=SPRING_ITERS, limit=SPRING_LIMIT)\n",
    "\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for u,v,d in H.edges(data=True):\n",
    "    x=[pos[u][0],pos[v][0]]; y=[pos[u][1],pos[v][1]]; z=[pos[u][2],pos[v][2]]\n",
    "    ax.plot(x,y,z, linewidth=0.5 + 2.0*float(d.get(\"weight\",0.0)), alpha=0.35)\n",
    "xs=[pos[n][0] for n in H.nodes()]; ys=[pos[n][1] for n in H.nodes()]; zs=[pos[n][2] for n in H.nodes()]\n",
    "ax.scatter(xs,ys,zs, s=14, alpha=0.85)\n",
    "ax.set_title(f\"CNT 3D Genomic Correlate Field — clean (nodes={H.number_of_nodes()}, edges={H.number_of_edges()})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "fig.tight_layout(); fig.savefig(PNG_PATH, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    edge_x=edge_y=edge_z=[]; edge_x=[]; edge_y=[]; edge_z=[]\n",
    "    for u,v,d in H.edges(data=True):\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    node_x=[pos[n][0] for n in H.nodes()]\n",
    "    node_y=[pos[n][1] for n in H.nodes()]\n",
    "    node_z=[pos[n][2] for n in H.nodes()]\n",
    "    node_text=[str(n) for n in H.nodes()]\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode='lines', line=dict(width=1), hoverinfo='none'),\n",
    "        go.Scatter3d(x=node_x,y=node_y,z=node_z,mode='markers', marker=dict(size=3), text=node_text, hoverinfo='text'),\n",
    "    ])\n",
    "    fig.update_layout(title=\"CNT 3D Genomic Correlate Field — clean\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)))\n",
    "    fig.write_html(HTML_PATH, include_plotlyjs='cdn')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print({\"png\": os.path.abspath(PNG_PATH), \"html\": os.path.abspath(HTML_PATH)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4251a1b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote CNT_genomic_modules.csv with 12000 rows and 10420 modules.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# === 6) (Optional) Community detection & CSV legend =======================\n",
    "try:\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    comms = list(greedy_modularity_communities(H, weight=\"weight\"))\n",
    "    module_of = {}\n",
    "    for idx, cset in enumerate(comms):\n",
    "        for n in cset:\n",
    "            module_of[n] = idx\n",
    "    out = pd.DataFrame({\"gene\": list(H.nodes()), \"module\": [module_of.get(n, -1) for n in H.nodes()]})\n",
    "    out.to_csv(\"CNT_genomic_modules.csv\", index=False)\n",
    "    print(\"Wrote CNT_genomic_modules.csv with\", len(out), \"rows and\", len(comms), \"modules.\")\n",
    "except Exception as e:\n",
    "    print(\"Community detection skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7923d423-8f9f-48a3-8933-68d426dfa67c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'module' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cm\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ------- 0) Gather modules, colors, and quick stats -------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m mod_ids = \u001b[38;5;28msorted\u001b[39m(\u001b[43m{\u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mH\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnodes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mm\u001b[49m\u001b[43m \u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m}\u001b[49m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod_ids:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo module mapping found. Build `module` (gene->module) first.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 9\u001b[39m, in \u001b[36m<genexpr>\u001b[39m\u001b[34m(.0)\u001b[39m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m cm\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# ------- 0) Gather modules, colors, and quick stats -------\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m mod_ids = \u001b[38;5;28msorted\u001b[39m({m \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m (\u001b[43mmodule\u001b[49m.get(n, -\u001b[32m1\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m H.nodes()) \u001b[38;5;28;01mif\u001b[39;00m m >= \u001b[32m0\u001b[39m})\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mod_ids:\n\u001b[32m     11\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo module mapping found. Build `module` (gene->module) first.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'module' is not defined"
     ]
    }
   ],
   "source": [
    "# === CNT Colored Correlate Maps: per-module colors + inter-module links ===\n",
    "# Requires: H (NetworkX graph), pos (node -> (x,y,z)), module dict (gene -> module)\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from matplotlib import cm\n",
    "\n",
    "# ------- 0) Gather modules, colors, and quick stats -------\n",
    "mod_ids = sorted({m for m in (module.get(n, -1) for n in H.nodes()) if m >= 0})\n",
    "if not mod_ids:\n",
    "    raise ValueError(\"No module mapping found. Build `module` (gene->module) first.\")\n",
    "\n",
    "mod_index = {m:i for i,m in enumerate(mod_ids)}\n",
    "n_mod = len(mod_ids)\n",
    "\n",
    "# colors (distinct & repeat-safe)\n",
    "cmap = cm.get_cmap(\"tab20\", max(20, n_mod))\n",
    "MOD_COLOR = {m: cmap(mod_index[m] % cmap.N) for m in mod_ids}\n",
    "\n",
    "# node arrays for rendering\n",
    "node_colors = [MOD_COLOR.get(module.get(n, -1), (0.6,0.6,0.6,1.0)) for n in H.nodes()]\n",
    "node_sizes  = [10 + 6*H.degree(n) for n in H.nodes()]\n",
    "\n",
    "# ------- 1) 3D field: colored by module, inter-module links emphasized -------\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# draw edges (intra faint, inter highlighted)\n",
    "for u,v,d in H.edges(data=True):\n",
    "    mu, mv = module.get(u,-1), module.get(v,-1)\n",
    "    x=[pos[u][0], pos[v][0]]; y=[pos[u][1], pos[v][1]]; z=[pos[u][2], pos[v][2]]\n",
    "    w = float(d.get(\"weight\",0.0))\n",
    "    if mu == mv and mu >= 0:\n",
    "        ax.plot(x,y,z, linewidth=0.5 + 1.2*w, alpha=0.15, color=MOD_COLOR[mu])\n",
    "    else:\n",
    "        ax.plot(x,y,z, linewidth=0.6 + 2.0*w, alpha=0.45, color=(0.2,0.2,0.2,1.0))\n",
    "\n",
    "# nodes (colored by module)\n",
    "xs=[pos[n][0] for n in H.nodes()]; ys=[pos[n][1] for n in H.nodes()]; zs=[pos[n][2] for n in H.nodes()]\n",
    "_ = ax.scatter(xs,ys,zs, s=node_sizes, c=node_colors, alpha=0.95)\n",
    "\n",
    "ax.set_title(f\"CNT Colored 3D Field — modules colored; inter-module links bold (modules={n_mod})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"CNT_colored_3D_field.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "print({\"png_3d\": os.path.abspath(\"CNT_colored_3D_field.png\")})\n",
    "\n",
    "# ------- 2) Module-level graph: one node per module, edge width = cross-talk -------\n",
    "# build module→size and module↔module weight matrix\n",
    "mod_size = {m: 0 for m in mod_ids}\n",
    "for n in H.nodes():\n",
    "    m = module.get(n,-1)\n",
    "    if m >= 0: mod_size[m] += 1\n",
    "\n",
    "# aggregate edge weights by module pair\n",
    "W = pd.DataFrame(0.0, index=mod_ids, columns=mod_ids)\n",
    "for u,v,d in H.edges(data=True):\n",
    "    mu, mv = module.get(u,-1), module.get(v,-1)\n",
    "    if mu < 0 or mv < 0: continue\n",
    "    w = float(d.get(\"weight\",0.0))\n",
    "    if mu == mv:\n",
    "        W.at[mu, mv] += w  # intra (diagonal)\n",
    "    else:\n",
    "        W.at[mu, mv] += w\n",
    "        W.at[mv, mu] += w\n",
    "\n",
    "# module graph\n",
    "Gm = nx.Graph()\n",
    "for m in mod_ids:\n",
    "    Gm.add_node(m, size=mod_size[m])\n",
    "for i in mod_ids:\n",
    "    for j in mod_ids:\n",
    "        if j <= i: continue\n",
    "        w = W.at[i,j]\n",
    "        if w > 0:\n",
    "            Gm.add_edge(i, j, weight=w)\n",
    "\n",
    "# layout & draw (2D)\n",
    "pos2 = nx.spring_layout(Gm, seed=42, weight=\"weight\")\n",
    "fig2 = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax2  = fig2.add_subplot(111)\n",
    "\n",
    "# edges: width ∝ cross-talk weight\n",
    "max_w = max((d[\"weight\"] for *_, d in Gm.edges(data=True)), default=1.0)\n",
    "for u,v,d in Gm.edges(data=True):\n",
    "    lw = 0.5 + 8.0*(d[\"weight\"]/max_w)\n",
    "    ax2.plot([pos2[u][0], pos2[v][0]], [pos2[u][1], pos2[v][1]], linewidth=lw, alpha=0.35, color=\"black\")\n",
    "\n",
    "# nodes: size ∝ module size, color per module\n",
    "sizes2 = [40 + 8*Gm.nodes[m][\"size\"] for m in Gm.nodes()]\n",
    "cols2  = [MOD_COLOR[m] for m in Gm.nodes()]\n",
    "ax2.scatter([pos2[m][0] for m in Gm.nodes()], [pos2[m][1] for m in Gm.nodes()],\n",
    "            s=sizes2, c=cols2, alpha=0.95)\n",
    "\n",
    "# labels\n",
    "for m,(x,y) in pos2.items():\n",
    "    ax2.text(x, y, f\"{m}\\n(n={mod_size[m]})\", ha=\"center\", va=\"center\")\n",
    "\n",
    "ax2.set_title(\"CNT Module Map — node size = module size; edge width = cross-talk\")\n",
    "ax2.set_xticks([]); ax2.set_yticks([])\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"CNT_module_map.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig2)\n",
    "\n",
    "print({\"png_module_map\": os.path.abspath(\"CNT_module_map.png\")})\n",
    "\n",
    "# ------- 3) Module×Module heatmap (weights) -------\n",
    "fig3 = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax3  = fig3.add_subplot(111)\n",
    "im = ax3.imshow(W.values, interpolation=\"nearest\", aspect=\"auto\")\n",
    "ax3.set_title(\"Module × Module cross-talk (sum of edge weights)\")\n",
    "ax3.set_xlabel(\"Module\"); ax3.set_ylabel(\"Module\")\n",
    "ax3.set_xticks(range(n_mod)); ax3.set_yticks(range(n_mod))\n",
    "ax3.set_xticklabels(mod_ids, rotation=90); ax3.set_yticklabels(mod_ids)\n",
    "cb = plt.colorbar(im)\n",
    "cb.set_label(\"weight\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"CNT_module_heatmap.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig3)\n",
    "\n",
    "print({\n",
    "    \"png_heatmap\": os.path.abspath(\"CNT_module_heatmap.png\"),\n",
    "    \"modules\": n_mod,\n",
    "    \"largest_modules\": sorted([(m, mod_size[m])], key=lambda x: x[1], reverse=True)[:5]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ce3bf674-b30b-42fc-8908-d34b868b9840",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x191032a6e90>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Color by module (if modules CSV exists) ===\n",
    "import os, pandas as pd\n",
    "mod_map = None\n",
    "if os.path.exists(\"CNT_genomic_modules.csv\"):\n",
    "    dfm = pd.read_csv(\"CNT_genomic_modules.csv\")\n",
    "    mod_map = dict(zip(dfm[\"gene\"], dfm[\"module\"]))\n",
    "\n",
    "# sizes and (optional) colors by module\n",
    "sizes = []\n",
    "colors = []\n",
    "for n in H.nodes():\n",
    "    sizes.append(8 + 6*H.degree(n))              # degree-scaled nodes (subtle)\n",
    "    if mod_map is None:\n",
    "        colors.append(0)\n",
    "    else:\n",
    "        colors.append(mod_map.get(n, -1))\n",
    "\n",
    "# re-render nodes (replace the scatter in your render block)\n",
    "ax.scatter([pos[n][0] for n in H.nodes()],\n",
    "           [pos[n][1] for n in H.nodes()],\n",
    "           [pos[n][2] for n in H.nodes()],\n",
    "           s=sizes, alpha=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a002e934-eec3-4d1d-b2ea-23e19410c813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<mpl_toolkits.mplot3d.art3d.Path3DCollection at 0x191032a6ad0>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Color by module (if modules CSV exists) ===\n",
    "import os, pandas as pd\n",
    "mod_map = None\n",
    "if os.path.exists(\"CNT_genomic_modules.csv\"):\n",
    "    dfm = pd.read_csv(\"CNT_genomic_modules.csv\")\n",
    "    mod_map = dict(zip(dfm[\"gene\"], dfm[\"module\"]))\n",
    "\n",
    "# sizes and (optional) colors by module\n",
    "sizes = []\n",
    "colors = []\n",
    "for n in H.nodes():\n",
    "    sizes.append(8 + 6*H.degree(n))              # degree-scaled nodes (subtle)\n",
    "    if mod_map is None:\n",
    "        colors.append(0)\n",
    "    else:\n",
    "        colors.append(mod_map.get(n, -1))\n",
    "\n",
    "# re-render nodes (replace the scatter in your render block)\n",
    "ax.scatter([pos[n][0] for n in H.nodes()],\n",
    "           [pos[n][1] for n in H.nodes()],\n",
    "           [pos[n][2] for n in H.nodes()],\n",
    "           s=sizes, alpha=0.85)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf188f9-5abc-49ee-826d-a339d498b544",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_24044\\3671477730.py:64: RuntimeWarning:\n",
      "\n",
      "Mean of empty slice\n",
      "\n",
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\numpy\\lib\\_nanfunctions_impl.py:2015: RuntimeWarning:\n",
      "\n",
      "Degrees of freedom <= 0 for slice.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'nodes': 288, 'edges': 987, 'png': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.png', 'html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.html'}\n"
     ]
    }
   ],
   "source": [
    "# === CNT 3D Genomic Correlate Field — one-cell generate ===================\n",
    "# Uses multivariate features (resonance_score, cnt_score, structure_score, etc.)\n",
    "# to connect nearest \"correlates\" in cosine space (z-scored features).\n",
    "# De-spikes with mutual-kNN, prunes weak threads, and lays out via\n",
    "# coarse spring (top hubs) + barycentric for the rest, then a short polish.\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# ---- Paths ----\n",
    "DATA_PATH = r\"C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\"\n",
    "PNG_PATH  = \"CNT_genomic_network_3D.png\"\n",
    "HTML_PATH = \"CNT_genomic_network_3D.html\"\n",
    "\n",
    "# ---- Settings (tweak to taste) ----\n",
    "INDEX_COL       = \"gene_name\"                # fallback to 'rsid' if missing\n",
    "FEATURES_WISH   = [\"resonance_score\",\"cnt_score\",\"structure_score\",\"gene_deg\",\"ccre_deg\",\"tissue_hits\",\"tissues\"]\n",
    "\n",
    "SEED            = 42\n",
    "MAX_GENES       = 12000                      # cap by variance\n",
    "K_NEIGHBORS     = 12                         # base kNN threads per node\n",
    "MUTUAL_K        = 10                         # require mutual top-K (de-spike)\n",
    "PRUNE_FRACTION  = 0.15                       # drop weakest 15% edges (after mutual)\n",
    "MIN_W           = 0.12                       # and drop edges with weight below this\n",
    "EDGE_CAP        = 300_000                    # absolute edge cap\n",
    "\n",
    "COARSE_N        = 6000                       # nodes for coarse spring scaffold\n",
    "COARSE_ITERS    = 220                        # spring iters on scaffold\n",
    "POLISH_ITERS    = 60                         # short spring polish with scaffold fixed\n",
    "\n",
    "# ---- Load + per-gene feature matrix ----\n",
    "def _read_table(p):\n",
    "    for sep in (None, \"\\t\", \",\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, sep=sep, engine=\"python\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise FileNotFoundError(p)\n",
    "\n",
    "df = _read_table(DATA_PATH)\n",
    "if INDEX_COL not in df.columns:\n",
    "    INDEX_COL = \"rsid\" if \"rsid\" in df.columns else (next((c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)), df.columns[0]))\n",
    "\n",
    "feat_cols = [c for c in FEATURES_WISH if c in df.columns]\n",
    "if not feat_cols:\n",
    "    feat_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "use_cols = [INDEX_COL] + feat_cols\n",
    "\n",
    "F = df[use_cols].dropna(subset=[INDEX_COL]).copy()\n",
    "agg = {c:\"mean\" for c in feat_cols}\n",
    "for k in (\"resonance_score\",\"cnt_score\",\"structure_score\"):\n",
    "    if k in agg: agg[k] = \"max\"\n",
    "GDF = F.groupby(INDEX_COL).agg(agg).dropna(how=\"all\")\n",
    "GDF = GDF.fillna(GDF.median(numeric_only=True))\n",
    "\n",
    "if GDF.shape[0] > MAX_GENES:\n",
    "    keep = GDF.var(axis=1, numeric_only=True).sort_values(ascending=False).index[:MAX_GENES]\n",
    "    GDF = GDF.loc[keep]\n",
    "\n",
    "genes = GDF.index.to_numpy()\n",
    "X = GDF.to_numpy().astype(\"float32\")\n",
    "\n",
    "# ---- Standardize rows; cosine kNN (≈ correlation on z-scores) ----\n",
    "mu = np.nanmean(X, axis=0, keepdims=True)\n",
    "sd = np.nanstd(X, axis=0, ddof=1, keepdims=True); sd[sd==0]=1.0\n",
    "Z = (X - mu) / sd\n",
    "Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "rn = np.linalg.norm(Z, axis=1, keepdims=True); rn[rn==0]=1.0\n",
    "Z = Z / rn\n",
    "\n",
    "try:\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    nn = NearestNeighbors(n_neighbors=min(K_NEIGHBORS+1, Z.shape[0]), metric=\"cosine\", algorithm=\"brute\")\n",
    "    nn.fit(Z)\n",
    "    dists, idxs = nn.kneighbors(Z, return_distance=True)\n",
    "    dists, idxs = dists[:,1:], idxs[:,1:]           # drop self\n",
    "    sims = 1.0 - dists                              # similarity ∈ [0,1]\n",
    "except Exception:\n",
    "    # NumPy fallback (chunked top-K)\n",
    "    K = min(K_NEIGHBORS, Z.shape[0]-1)\n",
    "    sims = np.empty((Z.shape[0], K), dtype=\"float32\")\n",
    "    idxs = np.empty((Z.shape[0], K), dtype=np.int32)\n",
    "    bs = 1024\n",
    "    for i0 in range(0, Z.shape[0], bs):\n",
    "        i1 = min(i0+bs, Z.shape[0])\n",
    "        block = Z[i0:i1] @ Z.T\n",
    "        for i in range(i1-i0): block[i, i0+i] = -np.inf\n",
    "        topk = np.argpartition(-block, K, axis=1)[:, :K]\n",
    "        vals = np.take_along_axis(block, topk, axis=1)\n",
    "        order = np.argsort(-vals, axis=1)\n",
    "        r = np.arange(vals.shape[0])[:, None]\n",
    "        sims[i0:i1] = vals[r, order].astype(\"float32\")\n",
    "        idxs[i0:i1] = topk[r, order].astype(np.int32)\n",
    "\n",
    "# ---- Build graph; de-spike with mutual-kNN; prune weak fibers ----\n",
    "G = nx.Graph(); G.add_nodes_from(genes.tolist())\n",
    "added = 0\n",
    "for i, u in enumerate(genes):\n",
    "    for j, w in zip(idxs[i], sims[i]):\n",
    "        v = genes[int(j)]\n",
    "        if u == v: continue\n",
    "        wt = float(max(0.0, w))\n",
    "        if G.has_edge(u, v):\n",
    "            if wt > G[u][v][\"weight\"]: G[u][v][\"weight\"] = wt\n",
    "        else:\n",
    "            G.add_edge(u, v, weight=wt); added += 1\n",
    "    if added >= EDGE_CAP: break\n",
    "\n",
    "# mutual-kNN filter\n",
    "nbrs = {u: sorted(G[u].items(), key=lambda x: x[1].get(\"weight\",0.0), reverse=True) for u in G.nodes()}\n",
    "topk = {u: set(v for v,_ in nbrs[u][:MUTUAL_K]) for u in G.nodes()}\n",
    "H = nx.Graph(); H.add_nodes_from(G.nodes())\n",
    "for u,v,d in G.edges(data=True):\n",
    "    if v in topk[u] and u in topk[v]:\n",
    "        H.add_edge(u, v, **d)\n",
    "\n",
    "# prune weakest fraction + absolute floor\n",
    "if H.number_of_edges() > 0 and PRUNE_FRACTION > 0:\n",
    "    w = np.array([H[u][v].get(\"weight\",0.0) for u,v in H.edges()], dtype=float)\n",
    "    thr = float(np.quantile(w, PRUNE_FRACTION))\n",
    "    thr = max(thr, MIN_W)\n",
    "    H.remove_edges_from([(u,v) for u,v in H.edges() if float(H[u][v].get(\"weight\",0.0)) < thr])\n",
    "\n",
    "# keep the giant component (clarity)\n",
    "if H.number_of_nodes() > 0:\n",
    "    giant = max(nx.connected_components(H), key=len)\n",
    "    H = H.subgraph(giant).copy()\n",
    "\n",
    "# ---- Coarse spring + barycentric; short polish ----\n",
    "rng = np.random.default_rng(SEED)\n",
    "deg = sorted(H.degree(weight=\"weight\"), key=lambda x: x[1], reverse=True)\n",
    "coarse_nodes = set([n for n,_ in deg[:min(COARSE_N, H.number_of_nodes())]])\n",
    "fine_nodes   = [n for n in H.nodes() if n not in coarse_nodes]\n",
    "\n",
    "Hc = H.subgraph(coarse_nodes).copy()\n",
    "pos = nx.spring_layout(Hc, dim=3, seed=SEED, weight=\"weight\", iterations=COARSE_ITERS)\n",
    "\n",
    "for n in fine_nodes:\n",
    "    nbrs = [v for v in H.neighbors(n) if v in pos]\n",
    "    if nbrs:\n",
    "        arr = np.array([pos[v] for v in nbrs], float)\n",
    "        pos[n] = tuple(arr.mean(axis=0))\n",
    "    else:\n",
    "        v = rng.normal(size=3); pos[n] = tuple(v/np.linalg.norm(v))\n",
    "\n",
    "pos = nx.spring_layout(H, dim=3, seed=SEED, weight=\"weight\",\n",
    "                       pos=pos, fixed=list(coarse_nodes), iterations=POLISH_ITERS)\n",
    "\n",
    "# ---- Render (Matplotlib; policy-compliant) ----\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for u,v,d in H.edges(data=True):\n",
    "    x=[pos[u][0],pos[v][0]]; y=[pos[u][1],pos[v][1]]; z=[pos[u][2],pos[v][2]]\n",
    "    ax.plot(x,y,z, linewidth=0.5 + 2.0*float(d.get(\"weight\",0.0)), alpha=0.35)\n",
    "xs=[pos[n][0] for n in H.nodes()]; ys=[pos[n][1] for n in H.nodes()]; zs=[pos[n][2] for n in H.nodes()]\n",
    "_ = ax.scatter(xs,ys,zs, s=14, alpha=0.85)  # silence artist repr\n",
    "ax.set_title(f\"CNT 3D Genomic Correlate Field — clean (nodes={H.number_of_nodes()}, edges={H.number_of_edges()})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "fig.tight_layout(); fig.savefig(PNG_PATH, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "# ---- Optional interactive (Plotly) ----\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    edge_x=[]; edge_y=[]; edge_z=[]\n",
    "    for u,v,d in H.edges(data=True):\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    node_x=[pos[n][0] for n in H.nodes()]\n",
    "    node_y=[pos[n][1] for n in H.nodes()]\n",
    "    node_z=[pos[n][2] for n in H.nodes()]\n",
    "    node_text=[str(n) for n in H.nodes()]\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode='lines', line=dict(width=1), hoverinfo='none'),\n",
    "        go.Scatter3d(x=node_x,y=node_y,z=node_z,mode='markers', marker=dict(size=3), text=node_text, hoverinfo='text'),\n",
    "    ])\n",
    "    fig.update_layout(title=\"CNT 3D Genomic Correlate Field — clean\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)))\n",
    "    fig.write_html(HTML_PATH, include_plotlyjs='cdn')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print({\"nodes\": H.number_of_nodes(), \"edges\": H.number_of_edges(),\n",
    "       \"png\": os.path.abspath(PNG_PATH), \"html\": os.path.abspath(HTML_PATH)})\n",
    "# ======================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5e926ff-41c9-4fdf-b88e-f9bbcb2e11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[profile] Spine → {'K_NEIGHBORS': 10, 'MUTUAL_K': 10, 'PRUNE_FRACTION': 0.18, 'MIN_W': 0.14, 'COARSE_N': 6000, 'COARSE_ITERS': 240, 'POLISH_ITERS': 80, 'EDGE_CAP': 250000, 'USE_SPRING': True, 'SPRING_LIMIT': 20000}\n"
     ]
    }
   ],
   "source": [
    "# === CNT Field Profile Switch ==========================================\n",
    "PROFILE = \"Spine\"   # options: \"Spine\", \"Veil\", \"Atlas\"\n",
    "\n",
    "_profiles = {\n",
    "    \"Spine\": {   # crisp structure\n",
    "        \"K_NEIGHBORS\": 10, \"MUTUAL_K\": 10, \"PRUNE_FRACTION\": 0.18, \"MIN_W\": 0.14,\n",
    "        \"COARSE_N\": 6000, \"COARSE_ITERS\": 240, \"POLISH_ITERS\": 80,\n",
    "        \"EDGE_CAP\": 250_000, \"USE_SPRING\": True, \"SPRING_LIMIT\": 20000\n",
    "    },\n",
    "    \"Veil\": {    # denser fabric\n",
    "        \"K_NEIGHBORS\": 14, \"MUTUAL_K\": 8,  \"PRUNE_FRACTION\": 0.10, \"MIN_W\": 0.10,\n",
    "        \"COARSE_N\": 5000, \"COARSE_ITERS\": 200, \"POLISH_ITERS\": 60,\n",
    "        \"EDGE_CAP\": 350_000, \"USE_SPRING\": True, \"SPRING_LIMIT\": 20000\n",
    "    },\n",
    "    \"Atlas\": {   # publication layout; balanced + exports\n",
    "        \"K_NEIGHBORS\": 12, \"MUTUAL_K\": 10, \"PRUNE_FRACTION\": 0.15, \"MIN_W\": 0.12,\n",
    "        \"COARSE_N\": 6000, \"COARSE_ITERS\": 260, \"POLISH_ITERS\": 100,\n",
    "        \"EDGE_CAP\": 300_000, \"USE_SPRING\": True, \"SPRING_LIMIT\": 20000\n",
    "    },\n",
    "}\n",
    "locals().update(_profiles[PROFILE])\n",
    "print(f\"[profile] {PROFILE} →\", _profiles[PROFILE])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c7433ed8-4d7f-4bd5-ad58-344f06f96412",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[load] rows=119718 index_col=gene_name feats=6\n",
      "[post-agg] genes=12000 feats=6\n",
      "[graph] mode=multivariate-kNN(6 feats) nodes=12000 edges=134127\n",
      "[refined] nodes=288 edges=987\n",
      "{'png': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.png', 'html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_genomic_network_3D.html'}\n"
     ]
    }
   ],
   "source": [
    "# === CNT 3D Genomic Correlate Field — Hardened Generator ==================\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# ---- Paths ----\n",
    "DATA_PATH = r\"C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\"\n",
    "PNG_PATH  = \"CNT_genomic_network_3D.png\"\n",
    "HTML_PATH = \"CNT_genomic_network_3D.html\"\n",
    "\n",
    "# ---- Settings ----\n",
    "INDEX_COL       = \"gene_name\"   # fallback to 'rsid' or first non-numeric\n",
    "FEATURES_WISH   = [\"resonance_score\",\"cnt_score\",\"structure_score\",\n",
    "                   \"gene_deg\",\"ccre_deg\",\"tissue_hits\",\"tissues\"]\n",
    "\n",
    "SEED            = 42\n",
    "MAX_GENES       = 12000\n",
    "MIN_GENES_REQ   = 200           # fail fast if we have fewer\n",
    "MIN_FEATS_REQ   = 2             # need ≥2 features for multivariate; else auto-fallback to score-kNN\n",
    "K_NEIGHBORS     = 12\n",
    "MUTUAL_K        = 10\n",
    "PRUNE_FRACTION  = 0.15\n",
    "MIN_W           = 0.12\n",
    "EDGE_CAP        = 300_000\n",
    "\n",
    "COARSE_N        = 6000\n",
    "COARSE_ITERS    = 220\n",
    "POLISH_ITERS    = 60\n",
    "\n",
    "def _read_table(p):\n",
    "    for sep in (None, \"\\t\", \",\"):\n",
    "        try:\n",
    "            return pd.read_csv(p, sep=sep, engine=\"python\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    raise FileNotFoundError(p)\n",
    "\n",
    "def _pipeline_report(stage, **kw):\n",
    "    print(f\"[{stage}]\", \" \".join(f\"{k}={v}\" for k,v in kw.items()))\n",
    "\n",
    "# ---- Load ----\n",
    "df = _read_table(DATA_PATH)\n",
    "if INDEX_COL not in df.columns:\n",
    "    INDEX_COL = \"rsid\" if \"rsid\" in df.columns else (next((c for c in df.columns\n",
    "                    if not np.issubdtype(df[c].dtype, np.number)), df.columns[0]))\n",
    "df = df.dropna(subset=[INDEX_COL])\n",
    "feat_cols = [c for c in FEATURES_WISH if c in df.columns]\n",
    "if not feat_cols:\n",
    "    feat_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "\n",
    "# Drop all-NaN requested features\n",
    "non_empty_feats = [c for c in feat_cols if df[c].notna().any()]\n",
    "feat_cols = non_empty_feats\n",
    "_pipeline_report(\"load\", rows=len(df), index_col=INDEX_COL, feats=len(feat_cols))\n",
    "\n",
    "if len(feat_cols) == 0:\n",
    "    raise ValueError(\"No usable numeric feature columns found (all empty). Check column names or file.\")\n",
    "\n",
    "# ---- Aggregate to one row per gene ----\n",
    "agg = {c:\"mean\" for c in feat_cols}\n",
    "for k in (\"resonance_score\",\"cnt_score\",\"structure_score\"):\n",
    "    if k in agg: agg[k] = \"max\"\n",
    "GDF = df[[INDEX_COL] + feat_cols].groupby(INDEX_COL).agg(agg)\n",
    "\n",
    "# Drop all-NaN genes; drop all-NaN columns (again, post-agg)\n",
    "GDF = GDF.dropna(how=\"all\")\n",
    "GDF = GDF.dropna(axis=1, how=\"all\")\n",
    "# Fill remaining NaNs by column median (keeps geometry sane)\n",
    "if not GDF.empty:\n",
    "    GDF = GDF.fillna(GDF.median(numeric_only=True))\n",
    "\n",
    "# Cap by variance\n",
    "if GDF.shape[0] > MAX_GENES:\n",
    "    var = GDF.var(axis=1, numeric_only=True).sort_values(ascending=False)\n",
    "    GDF = GDF.loc[var.index[:MAX_GENES]]\n",
    "\n",
    "# Final sanity checks\n",
    "_pipeline_report(\"post-agg\", genes=GDF.shape[0], feats=GDF.shape[1])\n",
    "if GDF.shape[0] < MIN_GENES_REQ:\n",
    "    raise ValueError(f\"Too few genes after cleaning: {GDF.shape[0]} < {MIN_GENES_REQ}. \"\n",
    "                     \"Lower MIN_GENES_REQ or check filters.\")\n",
    "if GDF.shape[1] < MIN_FEATS_REQ:\n",
    "    # ---- SCORE-ONLY FALLBACK ------------------------------------------------\n",
    "    # Pick the most informative single feature\n",
    "    num = GDF.select_dtypes(include=[np.number])\n",
    "    score_col = (next((c for c in [\"resonance_score\",\"cnt_score\",\"structure_score\",\"phi\",\"psi\"] if c in num.columns),\n",
    "                      num.var().sort_values(ascending=False).index[0]))\n",
    "    s = num[score_col].dropna()\n",
    "    s = s.reindex(s.abs().sort_values(ascending=False).index)\n",
    "    genes = s.index.to_numpy(); vals = s.values.astype(float)\n",
    "\n",
    "    G = nx.Graph(); G.add_nodes_from(genes)\n",
    "    for i in range(len(genes)):\n",
    "        diffs = np.abs(vals - vals[i]); diffs[i] = np.inf\n",
    "        k = min(K_NEIGHBORS, max(1, len(genes)-1))\n",
    "        nn = np.argpartition(diffs, k)[:k]\n",
    "        for j in nn:\n",
    "            u,v = genes[i], genes[j]\n",
    "            if u == v: continue\n",
    "            w = float(np.exp(-diffs[j]))\n",
    "            if G.has_edge(u,v):\n",
    "                if w > G[u][v]['weight']: G[u][v]['weight'] = w\n",
    "            else:\n",
    "                G.add_edge(u,v,weight=w)\n",
    "        if G.number_of_edges() >= EDGE_CAP: break\n",
    "    mode = f\"score-kNN('{score_col}')\"\n",
    "else:\n",
    "    # ---- MULTIVARIATE kNN (cosine on z-scores) -----------------------------\n",
    "    X = GDF.to_numpy().astype(\"float32\")\n",
    "    # Standardize columns safely\n",
    "    mu = np.nanmean(X, axis=0, keepdims=True)\n",
    "    sd = np.nanstd(X, axis=0, ddof=1, keepdims=True)\n",
    "    sd[sd == 0] = 1.0\n",
    "    Z = (X - mu) / sd\n",
    "    Z = np.nan_to_num(Z, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    rn = np.linalg.norm(Z, axis=1, keepdims=True); rn[rn==0]=1.0\n",
    "    Z = Z / rn\n",
    "\n",
    "    genes = GDF.index.to_numpy()\n",
    "    try:\n",
    "        from sklearn.neighbors import NearestNeighbors\n",
    "        nn = NearestNeighbors(n_neighbors=min(K_NEIGHBORS+1, Z.shape[0]), metric=\"cosine\", algorithm=\"brute\")\n",
    "        nn.fit(Z); dists, idxs = nn.kneighbors(Z, return_distance=True)\n",
    "        dists, idxs = dists[:,1:], idxs[:,1:]\n",
    "        sims = 1.0 - dists\n",
    "    except Exception:\n",
    "        # Chunked NumPy fallback\n",
    "        K = min(K_NEIGHBORS, Z.shape[0]-1)\n",
    "        sims = np.empty((Z.shape[0], K), dtype=\"float32\")\n",
    "        idxs = np.empty((Z.shape[0], K), dtype=np.int32)\n",
    "        bs = 1024\n",
    "        for i0 in range(0, Z.shape[0], bs):\n",
    "            i1 = min(i0+bs, Z.shape[0])\n",
    "            block = Z[i0:i1] @ Z.T\n",
    "            for i in range(i1-i0): block[i, i0+i] = -np.inf\n",
    "            topk = np.argpartition(-block, K, axis=1)[:, :K]\n",
    "            vals = np.take_along_axis(block, topk, axis=1)\n",
    "            order = np.argsort(-vals, axis=1)\n",
    "            r = np.arange(vals.shape[0])[:, None]\n",
    "            sims[i0:i1] = vals[r, order].astype(\"float32\")\n",
    "            idxs[i0:i1] = topk[r, order].astype(np.int32)\n",
    "\n",
    "    G = nx.Graph(); G.add_nodes_from(genes.tolist())\n",
    "    added = 0\n",
    "    for i, u in enumerate(genes):\n",
    "        for j, w in zip(idxs[i], sims[i]):\n",
    "            v = genes[int(j)]\n",
    "            if u == v: continue\n",
    "            wt = float(max(0.0, w))\n",
    "            if G.has_edge(u, v):\n",
    "                if wt > G[u][v][\"weight\"]: G[u][v][\"weight\"] = wt\n",
    "            else:\n",
    "                G.add_edge(u, v, weight=wt); added += 1\n",
    "        if added >= EDGE_CAP: break\n",
    "    mode = f\"multivariate-kNN({GDF.shape[1]} feats)\"\n",
    "\n",
    "_pipeline_report(\"graph\", mode=mode, nodes=G.number_of_nodes(), edges=G.number_of_edges())\n",
    "\n",
    "# ---- mutual-kNN + pruning ----\n",
    "nbrs = {u: sorted(G[u].items(), key=lambda x: x[1].get(\"weight\",0.0), reverse=True) for u in G.nodes()}\n",
    "topk = {u: set(v for v,_ in nbrs[u][:MUTUAL_K]) for u in G.nodes()}\n",
    "H = nx.Graph(); H.add_nodes_from(G.nodes())\n",
    "for u,v,d in G.edges(data=True):\n",
    "    if v in topk[u] and u in topk[v]:\n",
    "        H.add_edge(u, v, **d)\n",
    "\n",
    "if H.number_of_edges() > 0 and PRUNE_FRACTION > 0:\n",
    "    w = np.array([H[u][v].get(\"weight\",0.0) for u,v in H.edges()], dtype=float)\n",
    "    thr = float(np.quantile(w, PRUNE_FRACTION))\n",
    "    thr = max(thr, MIN_W)\n",
    "    H.remove_edges_from([(u,v) for u,v in H.edges() if float(H[u][v].get(\"weight\",0.0)) < thr])\n",
    "\n",
    "if H.number_of_nodes() > 0:\n",
    "    giant = max(nx.connected_components(H), key=len)\n",
    "    H = H.subgraph(giant).copy()\n",
    "\n",
    "_pipeline_report(\"refined\", nodes=H.number_of_nodes(), edges=H.number_of_edges())\n",
    "\n",
    "# ---- layout: coarse spring + barycentric + short polish ----\n",
    "rng = np.random.default_rng(SEED)\n",
    "deg = sorted(H.degree(weight=\"weight\"), key=lambda x: x[1], reverse=True)\n",
    "coarse_nodes = set([n for n,_ in deg[:min(COARSE_N, H.number_of_nodes())]])\n",
    "fine_nodes   = [n for n in H.nodes() if n not in coarse_nodes]\n",
    "\n",
    "Hc = H.subgraph(coarse_nodes).copy()\n",
    "pos = nx.spring_layout(Hc, dim=3, seed=SEED, weight=\"weight\", iterations=COARSE_ITERS)\n",
    "\n",
    "for n in fine_nodes:\n",
    "    neigh = [v for v in H.neighbors(n) if v in pos]\n",
    "    if neigh:\n",
    "        arr = np.array([pos[v] for v in neigh], float)\n",
    "        pos[n] = tuple(arr.mean(axis=0))\n",
    "    else:\n",
    "        v = rng.normal(size=3); pos[n] = tuple(v/np.linalg.norm(v))\n",
    "\n",
    "pos = nx.spring_layout(H, dim=3, seed=SEED, weight=\"weight\",\n",
    "                       pos=pos, fixed=list(coarse_nodes), iterations=POLISH_ITERS)\n",
    "\n",
    "# ---- render ----\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "for u,v,d in H.edges(data=True):\n",
    "    x=[pos[u][0],pos[v][0]]; y=[pos[u][1],pos[v][1]]; z=[pos[u][2],pos[v][2]]\n",
    "    ax.plot(x,y,z, linewidth=0.5 + 2.0*float(d.get(\"weight\",0.0)), alpha=0.35)\n",
    "xs=[pos[n][0] for n in H.nodes()]; ys=[pos[n][1] for n in H.nodes()]; zs=[pos[n][2] for n in H.nodes()]\n",
    "_ = ax.scatter(xs,ys,zs, s=14, alpha=0.85)\n",
    "ax.set_title(f\"CNT 3D Genomic Correlate Field — {mode} (nodes={H.number_of_nodes()}, edges={H.number_of_edges()})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "fig.tight_layout(); fig.savefig(PNG_PATH, bbox_inches=\"tight\"); plt.close(fig)\n",
    "\n",
    "# ---- HTML (optional) ----\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    edge_x=[]; edge_y=[]; edge_z=[]\n",
    "    for u,v,d in H.edges(data=True):\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    node_x=[pos[n][0] for n in H.nodes()]\n",
    "    node_y=[pos[n][1] for n in H.nodes()]\n",
    "    node_z=[pos[n][2] for n in H.nodes()]\n",
    "    node_text=[str(n) for n in H.nodes()]\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode='lines', line=dict(width=1), hoverinfo='none'),\n",
    "        go.Scatter3d(x=node_x,y=node_y,z=node_z,mode='markers', marker=dict(size=3), text=node_text, hoverinfo='text'),\n",
    "    ])\n",
    "    fig.update_layout(title=f\"CNT 3D Genomic Correlate Field — {mode}\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False), yaxis=dict(visible=False), zaxis=dict(visible=False)))\n",
    "    fig.write_html(HTML_PATH, include_plotlyjs='cdn')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print({\"png\": os.path.abspath(PNG_PATH), \"html\": os.path.abspath(HTML_PATH)})\n",
    "# ======================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1011039c-b0f5-4ca9-8820-2512c147eb7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[modules] 12 communities → CNT_genomic_modules.csv\n",
      "[export] wrote CNT_nodes_3D.csv and CNT_edges.csv\n",
      "[html] CNT_genomic_network_3D_modules.html\n"
     ]
    }
   ],
   "source": [
    "# === CNT 3D Field — modules, exports, and a touch more fabric ============\n",
    "# Requires: H (NetworkX graph with edge[\"weight\"]) and pos (dict: node->(x,y,z))\n",
    "# produced by the generator cell you just ran.\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# --- (A) Optional: soften pruning a little to add fabric ------------------\n",
    "# If your H is too sparse, uncomment the next two lines to re-add some edges:\n",
    "# MIN_W_RESTORE = 0.10              # lower floor\n",
    "# H = nx.Graph((u,v,d) for u,v,d in H.edges(data=True) if float(d.get(\"weight\",0.0)) >= MIN_W_RESTORE)\n",
    "\n",
    "# --- (B) Community detection (greedy modularity) -------------------------\n",
    "try:\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    comms = list(greedy_modularity_communities(H, weight=\"weight\"))\n",
    "    module = {}\n",
    "    for i, cset in enumerate(comms):\n",
    "        for n in cset:\n",
    "            module[n] = i\n",
    "    modules_df = pd.DataFrame({\"gene\": list(H.nodes()), \"module\": [module.get(n, -1) for n in H.nodes()]})\n",
    "    modules_df.to_csv(\"CNT_genomic_modules.csv\", index=False)\n",
    "    print(f\"[modules] {len(comms)} communities → CNT_genomic_modules.csv\")\n",
    "except Exception as e:\n",
    "    module = {}\n",
    "    print(\"[modules] skipped:\", e)\n",
    "\n",
    "# --- (C) Export node positions and edges ---------------------------------\n",
    "nodes_out = []\n",
    "for n in H.nodes():\n",
    "    x,y,z = pos[n]\n",
    "    nodes_out.append({\"gene\": n, \"x\": x, \"y\": y, \"z\": z, \"degree\": H.degree(n), \"module\": module.get(n, -1)})\n",
    "pd.DataFrame(nodes_out).to_csv(\"CNT_nodes_3D.csv\", index=False)\n",
    "\n",
    "edges_out = []\n",
    "for u,v,d in H.edges(data=True):\n",
    "    edges_out.append({\"u\": u, \"v\": v, \"weight\": float(d.get(\"weight\", 0.0))})\n",
    "pd.DataFrame(edges_out).to_csv(\"CNT_edges.csv\", index=False)\n",
    "print(\"[export] wrote CNT_nodes_3D.csv and CNT_edges.csv\")\n",
    "\n",
    "# --- (D) Render with module colors and degree-based node sizes -----------\n",
    "sizes  = [8 + 6*H.degree(n) for n in H.nodes()]\n",
    "colors = [module.get(n, -1) for n in H.nodes()]  # integers; HTML hover shows labels\n",
    "\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax  = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# edges\n",
    "for u,v,d in H.edges(data=True):\n",
    "    x=[pos[u][0],pos[v][0]]; y=[pos[u][1],pos[v][1]]; z=[pos[u][2],pos[v][2]]\n",
    "    ax.plot(x,y,z, linewidth=0.6 + 2.0*float(d.get(\"weight\",0.0)), alpha=0.35)\n",
    "\n",
    "# nodes\n",
    "xs=[pos[n][0] for n in H.nodes()]\n",
    "ys=[pos[n][1] for n in H.nodes()]\n",
    "zs=[pos[n][2] for n in H.nodes()]\n",
    "_ = ax.scatter(xs, ys, zs, s=sizes, alpha=0.88)  # artist muted\n",
    "\n",
    "ax.set_title(f\"CNT 3D Genomic Correlate Field — modules (nodes={H.number_of_nodes()}, edges={H.number_of_edges()})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"CNT_genomic_network_3D_modules.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# --- (E) Interactive HTML with hover gene names --------------------------\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    edge_x=edge_y=edge_z=[]\n",
    "    edge_x=[]; edge_y=[]; edge_z=[]\n",
    "    for u,v,d in H.edges(data=True):\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    node_x=[pos[n][0] for n in H.nodes()]\n",
    "    node_y=[pos[n][1] for n in H.nodes()]\n",
    "    node_z=[pos[n][2] for n in H.nodes()]\n",
    "    node_text=[f\"{n} | deg={H.degree(n)} | mod={module.get(n,-1)}\" for n in H.nodes()]\n",
    "    fig = go.Figure(data=[\n",
    "        go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode=\"lines\", line=dict(width=1), hoverinfo=\"none\"),\n",
    "        go.Scatter3d(x=node_x,y=node_y,z=node_z,mode=\"markers\",\n",
    "                     marker=dict(size=3), text=node_text, hoverinfo=\"text\")\n",
    "    ])\n",
    "    fig.update_layout(title=\"CNT 3D Genomic Correlate Field — modules\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False),\n",
    "                                 yaxis=dict(visible=False),\n",
    "                                 zaxis=dict(visible=False)))\n",
    "    fig.write_html(\"CNT_genomic_network_3D_modules.html\", include_plotlyjs=\"cdn\")\n",
    "    print(\"[html] CNT_genomic_network_3D_modules.html\")\n",
    "except Exception as e:\n",
    "    print(\"[html] skipped:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9ec2b26-00a0-44be-84fe-ddd5aa3197e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top modules by size:\n",
      "    module  nodes\n",
      "0       0     50\n",
      "1       1     41\n",
      "2       2     30\n",
      "3       4     29\n",
      "4       3     29\n",
      "5       5     26\n",
      "6       6     25\n",
      "7       7     16\n",
      "\n",
      "Saved: CNT_top_hubs.csv, CNT_top_bridges.csv\n",
      "\n",
      "Top hubs:\n",
      "                  degree\n",
      "ENSG00000261294      10\n",
      "RELB                 10\n",
      "ENSG00000226957      10\n",
      "IL37                 10\n",
      "ENSG00000253824      10\n",
      "ENSG00000267743      10\n",
      "SARDH                10\n",
      "HNRNPA1P23           10\n",
      "ST14                 10\n",
      "ENSG00000280143      10\n",
      "\n",
      "Top bridges:\n",
      "                  betweenness\n",
      "KDM4B               0.451037\n",
      "TP53INP1            0.443971\n",
      "ADAMTS14            0.432811\n",
      "ENSG00000301269     0.419191\n",
      "EDN1                0.393411\n",
      "ENSG00000306145     0.367705\n",
      "KCNH2               0.279501\n",
      "STN1                0.260788\n",
      "JRK                 0.259716\n",
      "ENSG00000294410     0.255647\n"
     ]
    }
   ],
   "source": [
    "# === CNT Field: quick insights (modules, hubs, bridges) ================\n",
    "import pandas as pd, networkx as nx\n",
    "\n",
    "# Top modules by size\n",
    "mod_series = pd.Series({n: module.get(n, -1) for n in H.nodes()})\n",
    "mod_counts = mod_series.value_counts().rename_axis(\"module\").reset_index(name=\"nodes\")\n",
    "print(\"\\nTop modules by size:\\n\", mod_counts.head(8))\n",
    "\n",
    "# Top hubs (degree) and bridges (betweenness)\n",
    "deg = pd.Series(dict(H.degree())).sort_values(ascending=False)\n",
    "btw = pd.Series(nx.betweenness_centrality(H, weight=\"weight\")).sort_values(ascending=False)\n",
    "\n",
    "hubs = deg.head(25).rename(\"degree\").to_frame()\n",
    "bridges = btw.head(25).rename(\"betweenness\").to_frame()\n",
    "\n",
    "hubs.to_csv(\"CNT_top_hubs.csv\")\n",
    "bridges.to_csv(\"CNT_top_bridges.csv\")\n",
    "print(\"\\nSaved: CNT_top_hubs.csv, CNT_top_bridges.csv\")\n",
    "print(\"\\nTop hubs:\\n\", hubs.head(10))\n",
    "print(\"\\nTop bridges:\\n\", bridges.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "481cefc4-02ac-4595-adb0-26df34940afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'png': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_module_lens.png', 'html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_module_lens.html'}\n"
     ]
    }
   ],
   "source": [
    "# === CNT Module Lens — focus on one (or many) modules, with soft context ===\n",
    "# Requirements: H (graph), pos (node->(x,y,z)), and `module` dict from your modules cell.\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "# ---- choose which modules to spotlight ----\n",
    "FOCUS_MODULES = [0]          # e.g., [0] or [0, 3]; change to target different modules\n",
    "CONTEXT_ALPHA = 0.08         # how faint to draw non-focus nodes/edges\n",
    "EDGE_W_SCALE  = 2.0          # visual thickness scale for edges\n",
    "NODE_BASE     = 10           # base node size\n",
    "NODE_HUB_BUMP = 6            # degree-based size bump\n",
    "\n",
    "# ---- build masks ----\n",
    "mod_of = module  # from previous cell (gene -> module id)\n",
    "focus_nodes = {n for n in H if mod_of.get(n, -1) in FOCUS_MODULES}\n",
    "context_nodes = [n for n in H if n not in focus_nodes]\n",
    "\n",
    "# Subgraph for focused edges (both ends in focus)\n",
    "focus_edges = [(u,v,d) for u,v,d in H.edges(data=True) if u in focus_nodes and v in focus_nodes]\n",
    "context_edges = [(u,v,d) for u,v,d in H.edges(data=True) if not (u in focus_nodes and v in focus_nodes)]\n",
    "\n",
    "# ---- render ----\n",
    "fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "ax = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "# context edges (faint)\n",
    "for u,v,d in context_edges:\n",
    "    x = [pos[u][0], pos[v][0]]; y = [pos[u][1], pos[v][1]]; z = [pos[u][2], pos[v][2]]\n",
    "    ax.plot(x, y, z, linewidth=0.5 + EDGE_W_SCALE*float(d.get(\"weight\",0.0)), alpha=CONTEXT_ALPHA)\n",
    "\n",
    "# focus edges (strong)\n",
    "for u,v,d in focus_edges:\n",
    "    x = [pos[u][0], pos[v][0]]; y = [pos[u][1], pos[v][1]]; z = [pos[u][2], pos[v][2]]\n",
    "    ax.plot(x, y, z, linewidth=0.6 + EDGE_W_SCALE*float(d.get(\"weight\",0.0)), alpha=0.45)\n",
    "\n",
    "# context nodes (faint)\n",
    "if context_nodes:\n",
    "    xs=[pos[n][0] for n in context_nodes]; ys=[pos[n][1] for n in context_nodes]; zs=[pos[n][2] for n in context_nodes]\n",
    "    sizes=[NODE_BASE + NODE_HUB_BUMP*H.degree(n) for n in context_nodes]\n",
    "    _ = ax.scatter(xs, ys, zs, s=sizes, alpha=CONTEXT_ALPHA)\n",
    "\n",
    "# focus nodes (bold)\n",
    "if focus_nodes:\n",
    "    xs=[pos[n][0] for n in focus_nodes]; ys=[pos[n][1] for n in focus_nodes]; zs=[pos[n][2] for n in focus_nodes]\n",
    "    sizes=[NODE_BASE + NODE_HUB_BUMP*H.degree(n) for n in focus_nodes]\n",
    "    _ = ax.scatter(xs, ys, zs, s=sizes, alpha=0.92)\n",
    "\n",
    "ax.set_title(f\"CNT 3D Module Lens — modules {FOCUS_MODULES} (nodes={len(focus_nodes)})\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "fig.tight_layout()\n",
    "fig.savefig(\"CNT_module_lens.png\", bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ---- interactive HTML (hover shows node) ----\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    # edges first (context faint)\n",
    "    edge_x=[]; edge_y=[]; edge_z=[]; edge_alpha=[]\n",
    "    for u,v,d in context_edges:\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    ctx_edges = go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode='lines',\n",
    "                             line=dict(width=1), hoverinfo='none', opacity=CONTEXT_ALPHA)\n",
    "\n",
    "    # focus edges strong\n",
    "    edge_x=[]; edge_y=[]; edge_z=[]\n",
    "    for u,v,d in focus_edges:\n",
    "        edge_x += [pos[u][0], pos[v][0], None]\n",
    "        edge_y += [pos[u][1], pos[v][1], None]\n",
    "        edge_z += [pos[u][2], pos[v][2], None]\n",
    "    foc_edges = go.Scatter3d(x=edge_x,y=edge_y,z=edge_z,mode='lines',\n",
    "                             line=dict(width=2), hoverinfo='none', opacity=0.55)\n",
    "\n",
    "    # nodes\n",
    "    ctx = go.Scatter3d(x=[pos[n][0] for n in context_nodes],\n",
    "                       y=[pos[n][1] for n in context_nodes],\n",
    "                       z=[pos[n][2] for n in context_nodes],\n",
    "                       mode='markers', marker=dict(size=2),\n",
    "                       text=[str(n) for n in context_nodes], hoverinfo='text', opacity=CONTEXT_ALPHA)\n",
    "\n",
    "    foc = go.Scatter3d(x=[pos[n][0] for n in focus_nodes],\n",
    "                       y=[pos[n][1] for n in focus_nodes],\n",
    "                       z=[pos[n][2] for n in focus_nodes],\n",
    "                       mode='markers', marker=dict(size=4),\n",
    "                       text=[f\"{n} | deg={H.degree(n)} | mod={mod_of.get(n,-1)}\" for n in focus_nodes],\n",
    "                       hoverinfo='text', opacity=0.95)\n",
    "\n",
    "    fig = go.Figure(data=[ctx_edges, foc_edges, ctx, foc])\n",
    "    fig.update_layout(title=f\"CNT 3D Module Lens — modules {FOCUS_MODULES}\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False),\n",
    "                                 yaxis=dict(visible=False),\n",
    "                                 zaxis=dict(visible=False)))\n",
    "    fig.write_html(\"CNT_module_lens.html\", include_plotlyjs='cdn')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print({\"png\": os.path.abspath(\"CNT_module_lens.png\"),\n",
    "       \"html\": os.path.abspath(\"CNT_module_lens.html\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "59fe566d-6934-479e-b616-2a3fea0658bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'modules': 12, 'largest': [{'module': 0, 'nodes': 50, 'png': 'CNT_module_0.png', 'html': 'CNT_module_0.html'}, {'module': 1, 'nodes': 41, 'png': 'CNT_module_1.png', 'html': 'CNT_module_1.html'}, {'module': 2, 'nodes': 30, 'png': 'CNT_module_2.png', 'html': 'CNT_module_2.html'}], 'index_csv': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_module_index.csv', 'gallery_html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_module_gallery.html'}\n"
     ]
    }
   ],
   "source": [
    "# === CNT Module Atlas — render all modules as separate 3D plates ==========\n",
    "# Requires: H (networkx graph), pos (node->(x,y,z)), module dict (gene->module)\n",
    "# Creates:\n",
    "#   - CNT_module_<k>.png / CNT_module_<k>.html (one per module)\n",
    "#   - CNT_module_index.csv (module size & filenames)\n",
    "#   - CNT_module_gallery.html (simple index page)\n",
    "\n",
    "import os, math, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "\n",
    "OUT_INDEX_CSV = \"CNT_module_index.csv\"\n",
    "OUT_GALLERY   = \"CNT_module_gallery.html\"\n",
    "\n",
    "# ---------- collect module sets ----------\n",
    "if 'module' not in globals() or not isinstance(module, dict):\n",
    "    # build from greedy modularity if not provided\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    comms = list(greedy_modularity_communities(H, weight=\"weight\"))\n",
    "    module = {}\n",
    "    for i, cset in enumerate(comms):\n",
    "        for n in cset:\n",
    "            module[n] = i\n",
    "\n",
    "mods = pd.Series({n: module.get(n, -1) for n in H.nodes()})\n",
    "mods = mods[mods >= 0]\n",
    "mod_ids = sorted(mods.unique().tolist())\n",
    "\n",
    "rows = []\n",
    "for k in mod_ids:\n",
    "    focus = [n for n in H.nodes() if module.get(n, -1) == k]\n",
    "    ctx   = [n for n in H.nodes() if module.get(n, -1) != k]\n",
    "\n",
    "    # edges: focus-only (both ends in focus), context (everything else, faint)\n",
    "    e_focus = [(u,v,d) for u,v,d in H.edges(data=True) if u in focus and v in focus]\n",
    "    e_ctx   = [(u,v,d) for u,v,d in H.edges(data=True) if not (u in focus and v in focus)]\n",
    "\n",
    "    # --- Matplotlib render ---\n",
    "    fig = plt.figure(figsize=(10,8), dpi=160)\n",
    "    ax  = fig.add_subplot(111, projection=\"3d\")\n",
    "\n",
    "    # context edges (faint)\n",
    "    for u,v,d in e_ctx:\n",
    "        x=[pos[u][0], pos[v][0]]; y=[pos[u][1], pos[v][1]]; z=[pos[u][2], pos[v][2]]\n",
    "        ax.plot(x,y,z, linewidth=0.7 + 1.8*float(d.get(\"weight\",0.0)), alpha=0.08)\n",
    "\n",
    "    # focus edges (strong)\n",
    "    for u,v,d in e_focus:\n",
    "        x=[pos[u][0], pos[v][0]]; y=[pos[u][1], pos[v][1]]; z=[pos[u][2], pos[v][2]]\n",
    "        ax.plot(x,y,z, linewidth=0.8 + 2.0*float(d.get(\"weight\",0.0)), alpha=0.50)\n",
    "\n",
    "    # context nodes (faint)\n",
    "    if ctx:\n",
    "        xs=[pos[n][0] for n in ctx]; ys=[pos[n][1] for n in ctx]; zs=[pos[n][2] for n in ctx]\n",
    "        sizes=[10 + 6*H.degree(n) for n in ctx]\n",
    "        _ = ax.scatter(xs,ys,zs, s=sizes, alpha=0.08)\n",
    "\n",
    "    # focus nodes (bold)\n",
    "    xs=[pos[n][0] for n in focus]; ys=[pos[n][1] for n in focus]; zs=[pos[n][2] for n in focus]\n",
    "    sizes=[10 + 6*H.degree(n) for n in focus]\n",
    "    _ = ax.scatter(xs,ys,zs, s=sizes, alpha=0.95)\n",
    "\n",
    "    ax.set_title(f\"CNT 3D Module Lens — module {k} (nodes={len(focus)})\")\n",
    "    ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "    plt.tight_layout()\n",
    "\n",
    "    png_path = f\"CNT_module_{k}.png\"\n",
    "    fig.savefig(png_path, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "\n",
    "    # --- optional interactive HTML ---\n",
    "    html_path = None\n",
    "    try:\n",
    "        import plotly.graph_objects as go\n",
    "        # context edges\n",
    "        ex,ey,ez=[],[],[]\n",
    "        for u,v,d in e_ctx:\n",
    "            ex += [pos[u][0], pos[v][0], None]\n",
    "            ey += [pos[u][1], pos[v][1], None]\n",
    "            ez += [pos[u][2], pos[v][2], None]\n",
    "        ctx_edges = go.Scatter3d(x=ex,y=ey,z=ez,mode='lines',line=dict(width=1),hoverinfo='none',opacity=0.08)\n",
    "\n",
    "        # focus edges\n",
    "        ex,ey,ez=[],[],[]\n",
    "        for u,v,d in e_focus:\n",
    "            ex += [pos[u][0], pos[v][0], None]\n",
    "            ey += [pos[u][1], pos[v][1], None]\n",
    "            ez += [pos[u][2], pos[v][2], None]\n",
    "        foc_edges = go.Scatter3d(x=ex,y=ey,z=ez,mode='lines',line=dict(width=2),hoverinfo='none',opacity=0.55)\n",
    "\n",
    "        ctx_nodes = go.Scatter3d(\n",
    "            x=[pos[n][0] for n in ctx], y=[pos[n][1] for n in ctx], z=[pos[n][2] for n in ctx],\n",
    "            mode='markers', marker=dict(size=2), text=[str(n) for n in ctx], hoverinfo='text', opacity=0.08\n",
    "        )\n",
    "        foc_nodes = go.Scatter3d(\n",
    "            x=[pos[n][0] for n in focus], y=[pos[n][1] for n in focus], z=[pos[n][2] for n in focus],\n",
    "            mode='markers', marker=dict(size=4),\n",
    "            text=[f\"{n} | deg={H.degree(n)} | mod={k}\" for n in focus], hoverinfo='text', opacity=0.95\n",
    "        )\n",
    "        fig3d = go.Figure(data=[ctx_edges, foc_edges, ctx_nodes, foc_nodes])\n",
    "        fig3d.update_layout(title=f\"CNT 3D Module Lens — module {k}\",\n",
    "                            showlegend=False,\n",
    "                            scene=dict(xaxis=dict(visible=False),\n",
    "                                       yaxis=dict(visible=False),\n",
    "                                       zaxis=dict(visible=False)))\n",
    "        html_path = f\"CNT_module_{k}.html\"\n",
    "        fig3d.write_html(html_path, include_plotlyjs='cdn')\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    rows.append({\"module\": k, \"nodes\": len(focus), \"png\": png_path, \"html\": html_path})\n",
    "\n",
    "# ---------- write index + gallery ----------\n",
    "idx = pd.DataFrame(rows).sort_values([\"nodes\",\"module\"], ascending=[False, True])\n",
    "idx.to_csv(OUT_INDEX_CSV, index=False)\n",
    "\n",
    "with open(OUT_GALLERY, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"<html><head><meta charset='utf-8'><title>CNT Module Gallery</title></head><body>\")\n",
    "    f.write(\"<h2>CNT Module Gallery</h2><ul>\")\n",
    "    for _, r in idx.iterrows():\n",
    "        f.write(\"<li>\")\n",
    "        if pd.notna(r[\"html\"]):\n",
    "            f.write(f\"<a href='{r['html']}' target='_blank'>Module {int(r['module'])} (n={int(r['nodes'])})</a> \")\n",
    "        f.write(f\"— <a href='{r['png']}' target='_blank'>PNG</a></li>\")\n",
    "    f.write(\"</ul></body></html>\")\n",
    "\n",
    "print({\"modules\": len(idx), \"largest\": idx.head(3).to_dict(orient=\"records\"),\n",
    "       \"index_csv\": os.path.abspath(OUT_INDEX_CSV),\n",
    "       \"gallery_html\": os.path.abspath(OUT_GALLERY)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "930e12f0-c973-48f1-a931-92ffd3d3fae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_24044\\3702151614.py:28: MatplotlibDeprecationWarning:\n",
      "\n",
      "The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'png': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_one_field_atlas.png', 'html': 'C:\\\\Users\\\\caleb\\\\cnt_genome\\\\CNT_one_field_atlas.html'}\n"
     ]
    }
   ],
   "source": [
    "# === CNT One-Field Atlas: modules, bridges, and centroids in one 3D scene ===\n",
    "# Requires: H (NetworkX graph), pos (node -> (x,y,z))\n",
    "# Optional: module dict (gene -> module id). If absent, we compute communities.\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx, matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
    "from matplotlib import cm\n",
    "\n",
    "PNG_PATH  = \"CNT_one_field_atlas.png\"\n",
    "HTML_PATH = \"CNT_one_field_atlas.html\"\n",
    "\n",
    "# ---- 0) Module map (build if missing) -------------------------------------\n",
    "if 'module' not in globals() or not isinstance(module, dict) or len(module)==0:\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    comms = list(greedy_modularity_communities(H, weight=\"weight\"))\n",
    "    module = {}\n",
    "    for i, cset in enumerate(comms):\n",
    "        for n in cset:\n",
    "            module[n] = i\n",
    "\n",
    "# module ids present\n",
    "mod_ids = sorted({m for m in (module.get(n, -1) for n in H.nodes()) if m >= 0})\n",
    "if not mod_ids:\n",
    "    raise ValueError(\"No modules found. Run community detection first.\")\n",
    "\n",
    "# ---- 1) Colors, sizes, and helper stats -----------------------------------\n",
    "mod_index = {m:i for i,m in enumerate(mod_ids)}\n",
    "cmap = cm.get_cmap(\"tab20\", max(20, len(mod_ids)))  # distinct palette\n",
    "MOD_COLOR = {m: cmap(mod_index[m] % cmap.N) for m in mod_ids}\n",
    "\n",
    "node_colors = [MOD_COLOR.get(module.get(n, -1), (0.6,0.6,0.6,1.0)) for n in H.nodes()]\n",
    "node_sizes  = [10 + 6*H.degree(n) for n in H.nodes()]\n",
    "\n",
    "# module centroids (mean of node positions per module)\n",
    "centroid = {}\n",
    "for m in mod_ids:\n",
    "    nodes_m = [n for n in H.nodes() if module.get(n,-1)==m]\n",
    "    if nodes_m:\n",
    "        pts = np.array([pos[n] for n in nodes_m], float)\n",
    "        centroid[m] = pts.mean(axis=0)\n",
    "    else:\n",
    "        centroid[m] = np.zeros(3)\n",
    "\n",
    "# module sizes\n",
    "mod_size = {m: sum(1 for n in H.nodes() if module.get(n,-1)==m) for m in mod_ids}\n",
    "\n",
    "# ---- 2) Cross-talk matrix (sum of inter-module edge weights) --------------\n",
    "W = pd.DataFrame(0.0, index=mod_ids, columns=mod_ids)\n",
    "for u,v,d in H.edges(data=True):\n",
    "    mu, mv = module.get(u,-1), module.get(v,-1)\n",
    "    if mu < 0 or mv < 0: \n",
    "        continue\n",
    "    w = float(d.get(\"weight\",0.0))\n",
    "    if mu == mv:\n",
    "        W.at[mu, mv] += w\n",
    "    else:\n",
    "        W.at[mu, mv] += w\n",
    "        W.at[mv, mu] += w\n",
    "\n",
    "# for centroid links scaling\n",
    "max_w = float(W.values.max()) if W.values.size else 1.0\n",
    "if max_w == 0.0: max_w = 1.0\n",
    "\n",
    "# ---- 3) One scene: nodes colored, intra faint, inter bold, centroids + links\n",
    "fig = plt.figure(figsize=(11,9), dpi=170)\n",
    "ax  = fig.add_subplot(111, projection='3d')\n",
    "\n",
    "# 3a) draw edges\n",
    "for u,v,d in H.edges(data=True):\n",
    "    mu, mv = module.get(u,-1), module.get(v,-1)\n",
    "    x=[pos[u][0], pos[v][0]]; y=[pos[u][1], pos[v][1]]; z=[pos[u][2], pos[v][2]]\n",
    "    w = float(d.get(\"weight\",0.0))\n",
    "    if mu == mv and mu >= 0:\n",
    "        # intra-module: faint, colored by module\n",
    "        ax.plot(x,y,z, linewidth=0.5 + 1.2*w, alpha=0.15, color=MOD_COLOR[mu])\n",
    "    else:\n",
    "        # inter-module: bold, dark\n",
    "        ax.plot(x,y,z, linewidth=0.6 + 2.0*w, alpha=0.45, color=(0.15,0.15,0.15,1.0))\n",
    "\n",
    "# 3b) draw nodes\n",
    "xs=[pos[n][0] for n in H.nodes()]; ys=[pos[n][1] for n in H.nodes()]; zs=[pos[n][2] for n in H.nodes()]\n",
    "_ = ax.scatter(xs,ys,zs, s=node_sizes, c=node_colors, alpha=0.95)\n",
    "\n",
    "# 3c) centroid markers (scaled by module size)\n",
    "for m in mod_ids:\n",
    "    cx,cy,cz = centroid[m]\n",
    "    size = 60 + 10*mod_size[m]\n",
    "    _ = ax.scatter([cx],[cy],[cz], s=size, alpha=0.95)  # centroid dots (neutral style)\n",
    "\n",
    "# 3d) centroid-to-centroid links (width ∝ cross-talk)\n",
    "for i in mod_ids:\n",
    "    for j in mod_ids:\n",
    "        if j <= i: \n",
    "            continue\n",
    "        w = W.at[i,j]\n",
    "        if w <= 0: \n",
    "            continue\n",
    "        ci, cj = centroid[i], centroid[j]\n",
    "        lw = 0.6 + 6.5*(w/max_w)   # emphasize strong cross-talk\n",
    "        ax.plot([ci[0],cj[0]],[ci[1],cj[1]],[ci[2],cj[2]], linewidth=lw, alpha=0.55, color=(0,0,0,1))\n",
    "\n",
    "# cosmetics\n",
    "ax.set_title(\"CNT One-Field Atlas — modules (color), bridges (bold), centroids (dots)\")\n",
    "ax.set_xticks([]); ax.set_yticks([]); ax.set_zticks([])\n",
    "plt.tight_layout()\n",
    "fig.savefig(PNG_PATH, bbox_inches=\"tight\")\n",
    "plt.close(fig)\n",
    "\n",
    "# ---- 4) Optional interactive HTML ----------------------------------------\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    # edges (two layers)\n",
    "    edge_x_i=edge_y_i=edge_z_i=[]; edge_x_i=[]; edge_y_i=[]; edge_z_i=[]\n",
    "    edge_x_e=edge_y_e=edge_z_e=[]; edge_x_e=[]; edge_y_e=[]; edge_z_e=[]\n",
    "    for u,v,d in H.edges(data=True):\n",
    "        mu, mv = module.get(u,-1), module.get(v,-1)\n",
    "        if mu==mv and mu>=0:\n",
    "            edge_x_i += [pos[u][0], pos[v][0], None]\n",
    "            edge_y_i += [pos[u][1], pos[v][1], None]\n",
    "            edge_z_i += [pos[u][2], pos[v][2], None]\n",
    "        else:\n",
    "            edge_x_e += [pos[u][0], pos[v][0], None]\n",
    "            edge_y_e += [pos[u][1], pos[v][1], None]\n",
    "            edge_z_e += [pos[u][2], pos[v][2], None]\n",
    "    intra_edges = go.Scatter3d(x=edge_x_i,y=edge_y_i,z=edge_z_i,mode='lines',\n",
    "                               line=dict(width=1), hoverinfo='none', opacity=0.15)\n",
    "    inter_edges = go.Scatter3d(x=edge_x_e,y=edge_y_e,z=edge_z_e,mode='lines',\n",
    "                               line=dict(width=2), hoverinfo='none', opacity=0.45)\n",
    "\n",
    "    # nodes\n",
    "    node_x=xs; node_y=ys; node_z=zs\n",
    "    node_text=[f\"{n} | mod={module.get(n,-1)} | deg={H.degree(n)}\" for n in H.nodes()]\n",
    "    nodes3d = go.Scatter3d(x=node_x,y=node_y,z=node_z,mode='markers',\n",
    "                           marker=dict(size=3), text=node_text, hoverinfo='text', opacity=0.95)\n",
    "\n",
    "    # centroid links (meta-edges)\n",
    "    cx=[]; cy=[]; cz=[]; cx2=[]; cy2=[]; cz2=[]\n",
    "    for i in mod_ids:\n",
    "        for j in mod_ids:\n",
    "            if j<=i: continue\n",
    "            if W.at[i,j] > 0:\n",
    "                ci, cj = centroid[i], centroid[j]\n",
    "                cx += [ci[0], cj[0], None]\n",
    "                cy += [ci[1], cj[1], None]\n",
    "                cz += [ci[2], cj[2], None]\n",
    "    cent_links = go.Scatter3d(x=cx,y=cy,z=cz,mode='lines',\n",
    "                              line=dict(width=4), hoverinfo='none', opacity=0.55)\n",
    "\n",
    "    # centroid markers\n",
    "    cen_x=[centroid[m][0] for m in mod_ids]\n",
    "    cen_y=[centroid[m][1] for m in mod_ids]\n",
    "    cen_z=[centroid[m][2] for m in mod_ids]\n",
    "    cen_text=[f\"Module {m} (n={mod_size[m]})\" for m in mod_ids]\n",
    "    cents = go.Scatter3d(x=cen_x,y=cen_y,z=cen_z,mode='markers',\n",
    "                         marker=dict(size=6), text=cen_text, hoverinfo='text', opacity=0.95)\n",
    "\n",
    "    fig = go.Figure(data=[intra_edges, inter_edges, nodes3d, cent_links, cents])\n",
    "    fig.update_layout(title=\"CNT One-Field Atlas — colored modules + bridges + centroids\",\n",
    "                      showlegend=False,\n",
    "                      scene=dict(xaxis=dict(visible=False),\n",
    "                                 yaxis=dict(visible=False),\n",
    "                                 zaxis=dict(visible=False)))\n",
    "    fig.write_html(HTML_PATH, include_plotlyjs='cdn')\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "print({\"png\": os.path.abspath(PNG_PATH), \"html\": os.path.abspath(HTML_PATH)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a6f1232e-bd26-483c-971d-43644d968d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SNAPSHOT: {'nodes': 288, 'edges': 987, 'giant_nodes': 288, 'giant_edges': 987, 'avg_degree': np.float64(6.854166666666667)}\n"
     ]
    }
   ],
   "source": [
    "# === TEST PACK v1 — Setup & Snapshot ======================================\n",
    "# Assumes you already built: H (graph), pos (layout), module (gene→module), and GDF (per-gene features).\n",
    "# If any are missing, this cell will reconstruct the minimal pieces from your CSV.\n",
    "\n",
    "import os, numpy as np, pandas as pd, networkx as nx\n",
    "\n",
    "DATA_PATH = r\"C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\"  # edit if needed\n",
    "OUTDIR = \"CNT_TESTS\"; os.makedirs(OUTDIR, exist_ok=True)\n",
    "\n",
    "def read_table(p):\n",
    "    for sep in (None, \"\\t\", \",\"):\n",
    "        try: return pd.read_csv(p, sep=sep, engine=\"python\")\n",
    "        except Exception: pass\n",
    "    raise FileNotFoundError(p)\n",
    "\n",
    "# Rebuild GDF if absent\n",
    "if 'GDF' not in globals():\n",
    "    df = read_table(DATA_PATH)\n",
    "    idx_col = \"gene_name\" if \"gene_name\" in df.columns else (\"rsid\" if \"rsid\" in df.columns else df.columns[0])\n",
    "    feat_wish = [\"resonance_score\",\"cnt_score\",\"structure_score\",\"gene_deg\",\"ccre_deg\",\"tissue_hits\",\"tissues\"]\n",
    "    feats = [c for c in feat_wish if c in df.columns]\n",
    "    if not feats: feats = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    tmp = df[[idx_col] + feats].dropna(subset=[idx_col]).copy()\n",
    "    agg = {c:\"mean\" for c in feats}\n",
    "    for k in (\"resonance_score\",\"cnt_score\",\"structure_score\"):\n",
    "        if k in agg: agg[k] = \"max\"\n",
    "    GDF = tmp.groupby(idx_col).agg(agg).dropna(how=\"all\").fillna(tmp.median(numeric_only=True))\n",
    "    GDF.index.name = \"gene\"\n",
    "\n",
    "# Rebuild module map if absent\n",
    "if 'module' not in globals():\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    # Need a small graph: use cosine kNN on standardized features (same as build path)\n",
    "    X = GDF.to_numpy().astype(\"float32\")\n",
    "    X = (X - np.nanmean(X,0)) / (np.nanstd(X,0,ddof=1) + 1e-9)\n",
    "    X = np.nan_to_num(X)\n",
    "    X = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-9)\n",
    "    from sklearn.neighbors import NearestNeighbors\n",
    "    k = min(10, max(2, X.shape[0]-1))\n",
    "    nn = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\", algorithm=\"brute\").fit(X)\n",
    "    d, idx = nn.kneighbors(X); d, idx = d[:,1:], idx[:,1:]\n",
    "    genes = GDF.index.to_numpy()\n",
    "    Gtmp = nx.Graph(); Gtmp.add_nodes_from(genes)\n",
    "    for i,u in enumerate(genes):\n",
    "        for j,dist in zip(idx[i], d[i]):\n",
    "            v = genes[int(j)]; w = float(1.0 - dist)\n",
    "            if u!=v:\n",
    "                if Gtmp.has_edge(u,v): Gtmp[u][v]['weight'] = max(Gtmp[u][v]['weight'], w)\n",
    "                else: Gtmp.add_edge(u,v,weight=w)\n",
    "    comms = list(greedy_modularity_communities(Gtmp, weight=\"weight\"))\n",
    "    module = {n:i for i,c in enumerate(comms) for n in c}\n",
    "\n",
    "# Persist current artifacts for tests\n",
    "pd.DataFrame({\"gene\": list(GDF.index)} | {c: GDF[c].values for c in GDF.columns}).to_csv(f\"{OUTDIR}/GDF_snapshot.csv\", index=False)\n",
    "pd.DataFrame({\"gene\": list(module.keys()), \"module\": list(module.values())}).to_csv(f\"{OUTDIR}/modules_snapshot.csv\", index=False)\n",
    "\n",
    "# Basic graph metrics\n",
    "if 'H' in globals():\n",
    "    giant = max(nx.connected_components(H), key=len) if H.number_of_nodes() else set()\n",
    "    Gg = H.subgraph(giant).copy() if giant else H\n",
    "    summary = {\n",
    "        \"nodes\": H.number_of_nodes(), \"edges\": H.number_of_edges(),\n",
    "        \"giant_nodes\": Gg.number_of_nodes(), \"giant_edges\": Gg.number_of_edges(),\n",
    "        \"avg_degree\": np.mean([d for _,d in H.degree()]) if H.number_of_nodes() else 0.0,\n",
    "    }\n",
    "else:\n",
    "    summary = {\"warning\":\"No H present; stability & null tests will rebuild ephemeral graphs.\"}\n",
    "\n",
    "print(\"SNAPSHOT:\", summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c90035f5-2f57-45c9-b6b3-cb0774fa1423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "STABILITY (ARI vs base, 1.0 is perfect agreement):\n",
      "noise   0.00   0.02   0.05   0.10\n",
      "k                                \n",
      "8      0.016  0.012  0.002  0.000\n",
      "10     0.014  0.009  0.008 -0.004\n",
      "12     0.014  0.005  0.008 -0.004\n",
      "14     0.013  0.005  0.008 -0.003\n"
     ]
    }
   ],
   "source": [
    "# === TEST PACK v1 — Stability & Sensitivity ===============================\n",
    "# We perturb the build knobs and data a bit, recluster, and compare to your current modules with ARI.\n",
    "\n",
    "import numpy as np, pandas as pd, networkx as nx\n",
    "from sklearn.metrics import adjusted_rand_score as ARI\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "def build_knn_modules(GDF, k=10, noise=0.0, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    X = GDF.to_numpy().astype(\"float32\")\n",
    "    # standardize columns\n",
    "    X = (X - np.nanmean(X,0)) / (np.nanstd(X,0,ddof=1) + 1e-9)\n",
    "    X = np.nan_to_num(X)\n",
    "    if noise>0: X = X + noise*rng.normal(size=X.shape).astype(\"float32\")\n",
    "    X = X / (np.linalg.norm(X, axis=1, keepdims=True) + 1e-9)\n",
    "    k = min(k, max(2, X.shape[0]-1))\n",
    "    nn = NearestNeighbors(n_neighbors=k+1, metric=\"cosine\", algorithm=\"brute\").fit(X)\n",
    "    d, idx = nn.kneighbors(X); d, idx = d[:,1:], idx[:,1:]\n",
    "    genes = GDF.index.to_numpy()\n",
    "    G = nx.Graph(); G.add_nodes_from(genes)\n",
    "    for i,u in enumerate(genes):\n",
    "        for j,dist in zip(idx[i], d[i]):\n",
    "            v = genes[int(j)]; w = float(1.0 - dist)\n",
    "            if u!=v:\n",
    "                if G.has_edge(u,v): G[u][v]['weight'] = max(G[u][v]['weight'], w)\n",
    "                else: G.add_edge(u,v,weight=w)\n",
    "    from networkx.algorithms.community import greedy_modularity_communities\n",
    "    comms = list(greedy_modularity_communities(G, weight=\"weight\"))\n",
    "    return {n:i for i,c in enumerate(comms) for n in c}\n",
    "\n",
    "base_map = dict(pd.read_csv(\"CNT_TESTS/modules_snapshot.csv\").values)\n",
    "genes = list(GDF.index)\n",
    "base_labels = np.array([base_map.get(g, -1) for g in genes])\n",
    "\n",
    "grid = []\n",
    "for k in (8,10,12,14):\n",
    "    for noise in (0.0, 0.02, 0.05, 0.10):\n",
    "        m = build_knn_modules(GDF, k=k, noise=noise, seed=42)\n",
    "        labels = np.array([m.get(g, -1) for g in genes])\n",
    "        grid.append({\"k\":k, \"noise\":noise, \"ARI\": float(ARI(base_labels, labels))})\n",
    "\n",
    "stability = pd.DataFrame(grid).sort_values([\"k\",\"noise\"])\n",
    "stability.to_csv(\"CNT_TESTS/stability_grid.csv\", index=False)\n",
    "print(\"STABILITY (ARI vs base, 1.0 is perfect agreement):\")\n",
    "print(stability.pivot(index=\"k\", columns=\"noise\", values=\"ARI\").round(3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ae7b4acd-f9bc-4c04-9cbb-3055ba93088b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MODULARITY: Q_obs=0.830, null_mean=-0.002, z=82.90\n",
      "ENRICHMENT: wrote CNT_TESTS/enrichment.csv (fields: tissues/trait).\n",
      "DONE → see CNT_TESTS/: stability_grid.csv, null_modularity.csv, enrichment.csv, anova.csv, report.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:579: ConstantInputWarning:\n",
      "\n",
      "Each of the input arrays is constant; the F statistic is not defined or infinite\n",
      "\n",
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\scipy\\stats\\_axis_nan_policy.py:579: ConstantInputWarning:\n",
      "\n",
      "Each of the input arrays is constant; the F statistic is not defined or infinite\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === TEST PACK v1 — Nulls, Enrichment, Report ============================\n",
    "# (A) Modularity vs degree-preserving nulls\n",
    "# (B) Over-representation of 'tissues' or 'trait' per module\n",
    "# (C) Continuous-score separation by module (ANOVA)\n",
    "# Writes: CNT_TESTS/null_modularity.csv, CNT_TESTS/enrichment.csv, CNT_TESTS/report.txt\n",
    "\n",
    "import re, numpy as np, pandas as pd, networkx as nx\n",
    "from math import comb\n",
    "from scipy.stats import hypergeom, f_oneway\n",
    "\n",
    "mods_df = pd.read_csv(\"CNT_TESTS/modules_snapshot.csv\")\n",
    "mod_of = dict(mods_df.values)\n",
    "modules = sorted(mods_df[\"module\"].unique())\n",
    "\n",
    "# (A) Modularity vs degree-preserving nulls\n",
    "if 'H' in globals() and H.number_of_edges()>0:\n",
    "    giant = max(nx.connected_components(H), key=len)\n",
    "    Gg = H.subgraph(giant).copy()\n",
    "    part = {n: mod_of.get(n, -1) for n in Gg.nodes()}\n",
    "    # compute modularity for current partition\n",
    "    from networkx.algorithms.community.quality import modularity\n",
    "    current_Q = modularity(Gg, [ [n for n in part if part[n]==m] for m in modules ], weight=\"weight\")\n",
    "    # nulls: degree-preserving swaps\n",
    "    Qs = []\n",
    "    for r in range(30):\n",
    "        Gn = Gg.copy()\n",
    "        try:\n",
    "            nx.double_edge_swap(Gn, nswap=min(5*Gn.number_of_edges(), 50000), max_tries=200000)\n",
    "        except Exception:\n",
    "            pass\n",
    "        Qs.append(modularity(Gn, [ [n for n in part if part[n]==m] for m in modules ], weight=\"weight\"))\n",
    "    null = pd.DataFrame({\"Q_null\": Qs})\n",
    "    null[\"Q_obs\"] = current_Q\n",
    "    null[\"z\"] = (current_Q - null[\"Q_null\"].mean()) / (null[\"Q_null\"].std(ddof=1) + 1e-9)\n",
    "    null.to_csv(\"CNT_TESTS/null_modularity.csv\", index=False)\n",
    "    print(f\"MODULARITY: Q_obs={current_Q:.3f}, null_mean={null.Q_null.mean():.3f}, z={null['z'].iloc[0]:.2f}\")\n",
    "else:\n",
    "    print(\"MODULARITY: skipped (no H).\")\n",
    "\n",
    "# (B) Enrichment on 'tissues' and 'trait' (if present)\n",
    "df = read_table(DATA_PATH)\n",
    "idx_col = \"gene_name\" if \"gene_name\" in df.columns else (\"rsid\" if \"rsid\" in df.columns else df.columns[0])\n",
    "universe = set(GDF.index)\n",
    "df = df[df[idx_col].isin(universe)]\n",
    "\n",
    "def split_tokens(series):\n",
    "    toks = []\n",
    "    for x in series.dropna().astype(str).values:\n",
    "        toks += [t.strip().lower() for t in re.split(r\"[;,/|]\", x) if t.strip()]\n",
    "    return toks\n",
    "\n",
    "enrich_rows = []\n",
    "for col in [\"tissues\",\"trait\"]:\n",
    "    if col not in df.columns: \n",
    "        continue\n",
    "    # build background counts\n",
    "    all_tokens = split_tokens(df[col])\n",
    "    if not all_tokens:\n",
    "        continue\n",
    "    vocab = pd.Series(all_tokens).value_counts()\n",
    "    for m in modules:\n",
    "        genes_m = set(mods_df.query(\"module==@m\")[\"gene\"])\n",
    "        toks_m = split_tokens(df[df[idx_col].isin(genes_m)][col])\n",
    "        counts = pd.Series(toks_m).value_counts()\n",
    "        for term, k in counts.items():\n",
    "            K = int(vocab.get(term,0))\n",
    "            N = int(len(all_tokens))\n",
    "            n = int(len(toks_m))\n",
    "            # hypergeometric p (over-representation)\n",
    "            p = hypergeom.sf(k-1, N, K, n)\n",
    "            enrich_rows.append({\"module\": m, \"field\": col, \"term\": term, \"k_in_module\": int(k),\n",
    "                                \"K_in_all\": int(K), \"n_module_tokens\": n, \"N_all_tokens\": N, \"p\": p})\n",
    "\n",
    "if enrich_rows:\n",
    "    enr = pd.DataFrame(enrich_rows)\n",
    "    # FDR (Benjamini–Hochberg)\n",
    "    enr = enr.sort_values(\"p\").reset_index(drop=True)\n",
    "    m = len(enr); enr[\"q\"] = enr[\"p\"] * m / (np.arange(m)+1)\n",
    "    enr[\"q\"] = np.minimum.accumulate(enr[\"q\"][::-1])[::-1]\n",
    "    enr.to_csv(\"CNT_TESTS/enrichment.csv\", index=False)\n",
    "    print(\"ENRICHMENT: wrote CNT_TESTS/enrichment.csv (fields: tissues/trait).\")\n",
    "else:\n",
    "    print(\"ENRICHMENT: skipped (no tissues/trait tokens).\")\n",
    "\n",
    "# (C) ANOVA: do modules separate continuous scores?\n",
    "cont_cols = [c for c in [\"resonance_score\",\"cnt_score\",\"structure_score\",\"gene_deg\",\"ccre_deg\",\"tissue_hits\"] if c in GDF.columns]\n",
    "anova_rows = []\n",
    "for c in cont_cols:\n",
    "    groups = [GDF.loc[mods_df.query(\"module==@m\")[\"gene\"]][c].dropna().values for m in modules]\n",
    "    if sum(len(g) for g in groups) and sum(len(g)>1 for g in groups) > 1:\n",
    "        F, p = f_oneway(*[g for g in groups if len(g)>1])\n",
    "        anova_rows.append({\"feature\": c, \"F\": float(F), \"p\": float(p)})\n",
    "anova = pd.DataFrame(anova_rows)\n",
    "anova.to_csv(\"CNT_TESTS/anova.csv\", index=False)\n",
    "\n",
    "# Write a compact report\n",
    "with open(f\"{OUTDIR}/report.txt\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"=== CNT TEST PACK v1 — REPORT ===\\n\")\n",
    "    if 'null' in locals():\n",
    "        f.write(f\"Modularity Q_obs={current_Q:.3f}, null_mean={null.Q_null.mean():.3f}, z={null['z'].iloc[0]:.2f}\\n\")\n",
    "    if not anova.empty:\n",
    "        f.write(\"\\nANOVA (module separation on continuous features):\\n\")\n",
    "        for _,r in anova.sort_values(\"p\").iterrows():\n",
    "            f.write(f\"  {r.feature}: F={r.F:.2f}, p={r.p:.2e}\\n\")\n",
    "    if enrich_rows:\n",
    "        sig = enr[enr[\"q\"]<=0.05]\n",
    "        f.write(f\"\\nEnrichment (BH q<=0.05): {len(sig)} rows\\n\")\n",
    "        f.write(\"  Example top terms:\\n\")\n",
    "        for _,r in sig.head(10).iterrows():\n",
    "            f.write(f\"   - mod {int(r.module)} | {r.field}:{r.term} (k={r.k_in_module}/{r.n_module_tokens}, q={r.q:.2e})\\n\")\n",
    "print(\"DONE → see CNT_TESTS/: stability_grid.csv, null_modularity.csv, enrichment.csv, anova.csv, report.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "82e10b61-ffd3-4d7a-b810-e93f1695610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using: C:\\Users\\caleb\\cnt_genome\\out\\CNT_genomic_resonance_scored.csv\n",
      "Out: C:\\Users\\caleb\\cnt_genome\\CNT_TESTS\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "# === EDIT THIS ===\n",
    "CSV = Path(r\"C:\\\\Users\\\\caleb\\\\cnt_genome\\\\out\\\\CNT_genomic_resonance_scored.csv\")  # change if needed\n",
    "OUTDIR = Path(\"CNT_TESTS\")\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "print(\"Using:\", CSV)\n",
    "print(\"Out:\", OUTDIR.resolve())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8e027ebb-a1c9-4935-b391-8b565a5f1f37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(119718, 14)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rsid</th>\n",
       "      <th>Chromosome</th>\n",
       "      <th>pos</th>\n",
       "      <th>trait</th>\n",
       "      <th>ccre_id</th>\n",
       "      <th>gene_id</th>\n",
       "      <th>gene_name</th>\n",
       "      <th>tissue_hits</th>\n",
       "      <th>tissues</th>\n",
       "      <th>resonance_score</th>\n",
       "      <th>gene_deg</th>\n",
       "      <th>ccre_deg</th>\n",
       "      <th>structure_score</th>\n",
       "      <th>cnt_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>esv2676630</td>\n",
       "      <td>chr16</td>\n",
       "      <td>173448</td>\n",
       "      <td>Glycated hemoglobin levels</td>\n",
       "      <td>EH38E1794437</td>\n",
       "      <td>ENSG00000294455.1</td>\n",
       "      <td>ENSG00000294455</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.039721</td>\n",
       "      <td>2.039721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rs10000702</td>\n",
       "      <td>chr4</td>\n",
       "      <td>156771179</td>\n",
       "      <td>Glucose (fasting status unknown, maximum, inv-...</td>\n",
       "      <td>EH38E2338838</td>\n",
       "      <td>ENSG00000248629.1</td>\n",
       "      <td>ENSG00000248629</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>2.426015</td>\n",
       "      <td>3.426015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rs1000113</td>\n",
       "      <td>chr5</td>\n",
       "      <td>150860514</td>\n",
       "      <td>Crohn's disease</td>\n",
       "      <td>EH38E2421397</td>\n",
       "      <td>ENSG00000237693.6</td>\n",
       "      <td>IRGM</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.039721</td>\n",
       "      <td>2.039721</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rsid Chromosome        pos  \\\n",
       "0  esv2676630      chr16     173448   \n",
       "1  rs10000702       chr4  156771179   \n",
       "2   rs1000113       chr5  150860514   \n",
       "\n",
       "                                               trait       ccre_id  \\\n",
       "0                         Glycated hemoglobin levels  EH38E1794437   \n",
       "1  Glucose (fasting status unknown, maximum, inv-...  EH38E2338838   \n",
       "2                                    Crohn's disease  EH38E2421397   \n",
       "\n",
       "             gene_id        gene_name  tissue_hits  tissues  resonance_score  \\\n",
       "0  ENSG00000294455.1  ENSG00000294455            0      NaN              1.0   \n",
       "1  ENSG00000248629.1  ENSG00000248629            0      NaN              1.0   \n",
       "2  ENSG00000237693.6             IRGM            0      NaN              1.0   \n",
       "\n",
       "   gene_deg  ccre_deg  structure_score  cnt_score  \n",
       "0         1         1         1.039721   2.039721  \n",
       "1         7         1         2.426015   3.426015  \n",
       "2         1         1         1.039721   2.039721  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "df = pd.read_csv(CSV)\n",
    "print(df.shape)\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d723d434-f981-40d5-9a38-a26bd4ea8d2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1144: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1149: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n",
      "C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\extmath.py:1169: RuntimeWarning:\n",
      "\n",
      "invalid value encountered in divide\n",
      "\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      8\u001b[39m     X = df[num_cols].fillna(df[num_cols].median()).to_numpy()\n\u001b[32m      9\u001b[39m     X = StandardScaler().fit_transform(X)\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m     emb = \u001b[43mUMAP\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_components\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_neighbors\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_dist\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcosine\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     11\u001b[39m     df[\u001b[33m'\u001b[39m\u001b[33mx2d\u001b[39m\u001b[33m'\u001b[39m], df[\u001b[33m'\u001b[39m\u001b[33my2d\u001b[39m\u001b[33m'\u001b[39m] = emb[:,\u001b[32m0\u001b[39m], emb[:,\u001b[32m1\u001b[39m]\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mHas 2D cols:\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mall\u001b[39m(c \u001b[38;5;129;01min\u001b[39;00m df.columns \u001b[38;5;28;01mfor\u001b[39;00m c \u001b[38;5;129;01min\u001b[39;00m [\u001b[33m'\u001b[39m\u001b[33mx2d\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33my2d\u001b[39m\u001b[33m'\u001b[39m]))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\umap\\umap_.py:2935\u001b[39m, in \u001b[36mUMAP.fit_transform\u001b[39m\u001b[34m(self, X, y, ensure_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2897\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfit_transform\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y=\u001b[38;5;28;01mNone\u001b[39;00m, ensure_all_finite=\u001b[38;5;28;01mTrue\u001b[39;00m, **kwargs):\n\u001b[32m   2898\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Fit X into an embedded space and return that transformed\u001b[39;00m\n\u001b[32m   2899\u001b[39m \u001b[33;03m    output.\u001b[39;00m\n\u001b[32m   2900\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   2933\u001b[39m \u001b[33;03m        Local radii of data points in the embedding (log-transformed).\u001b[39;00m\n\u001b[32m   2934\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m2935\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2936\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.transform_mode == \u001b[33m\"\u001b[39m\u001b[33membedding\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m   2937\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.output_dens:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\umap\\umap_.py:2372\u001b[39m, in \u001b[36mUMAP.fit\u001b[39m\u001b[34m(self, X, y, ensure_all_finite, **kwargs)\u001b[39m\n\u001b[32m   2368\u001b[39m     X = check_array(\n\u001b[32m   2369\u001b[39m         X, dtype=np.uint8, order=\u001b[33m\"\u001b[39m\u001b[33mC\u001b[39m\u001b[33m\"\u001b[39m, ensure_all_finite=ensure_all_finite\n\u001b[32m   2370\u001b[39m     )\n\u001b[32m   2371\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2372\u001b[39m     X = \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2374\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfloat32\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2375\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccept_sparse\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcsr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2376\u001b[39m \u001b[43m        \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mC\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2377\u001b[39m \u001b[43m        \u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2378\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2379\u001b[39m \u001b[38;5;28mself\u001b[39m._raw_data = X\n\u001b[32m   2381\u001b[39m \u001b[38;5;66;03m# Handle all the optional arguments, setting default\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:1105\u001b[39m, in \u001b[36mcheck_array\u001b[39m\u001b[34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[39m\n\u001b[32m   1099\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1100\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFound array with dim \u001b[39m\u001b[38;5;132;01m{\u001b[39;00marray.ndim\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1101\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m while dim <= 2 is required\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcontext\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1102\u001b[39m     )\n\u001b[32m   1104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ensure_all_finite:\n\u001b[32m-> \u001b[39m\u001b[32m1105\u001b[39m     \u001b[43m_assert_all_finite\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1106\u001b[39m \u001b[43m        \u001b[49m\u001b[43marray\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1107\u001b[39m \u001b[43m        \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1108\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1109\u001b[39m \u001b[43m        \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_all_finite\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mallow-nan\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1110\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1112\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m copy:\n\u001b[32m   1113\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m _is_numpy_namespace(xp):\n\u001b[32m   1114\u001b[39m         \u001b[38;5;66;03m# only make a copy if `array` and `array_orig` may share memory`\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:120\u001b[39m, in \u001b[36m_assert_all_finite\u001b[39m\u001b[34m(X, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    117\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m first_pass_isfinite:\n\u001b[32m    118\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m \u001b[43m_assert_all_finite_element_wise\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    121\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    122\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    124\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmsg_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    125\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    126\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\sklearn\\utils\\validation.py:169\u001b[39m, in \u001b[36m_assert_all_finite_element_wise\u001b[39m\u001b[34m(X, xp, allow_nan, msg_dtype, estimator_name, input_name)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m estimator_name \u001b[38;5;129;01mand\u001b[39;00m input_name == \u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m has_nan_error:\n\u001b[32m    153\u001b[39m     \u001b[38;5;66;03m# Improve the error message on how to handle missing values in\u001b[39;00m\n\u001b[32m    154\u001b[39m     \u001b[38;5;66;03m# scikit-learn.\u001b[39;00m\n\u001b[32m    155\u001b[39m     msg_err += (\n\u001b[32m    156\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mestimator_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m does not accept missing values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    157\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m encoded as NaN natively. For supervised learning, you might want\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    167\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33m#estimators-that-handle-nan-values\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    168\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m169\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg_err)\n",
      "\u001b[31mValueError\u001b[39m: Input contains NaN."
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "numeric_candidates = [c for c in df.columns if df[c].dtype.kind in \"if\"]\n",
    "preferred = [c for c in ['pos','tissue_hits','tissues','resonance_score','gene_deg','ccre_deg','structure_score','cnt_score'] if c in df.columns]\n",
    "num_cols = preferred if len(preferred)>=3 else numeric_candidates\n",
    "assert 'resonance_score' in df.columns, \"Need resonance_score\"\n",
    "if not all(c in df.columns for c in ['x2d','y2d']):\n",
    "    from umap import UMAP\n",
    "    X = df[num_cols].fillna(df[num_cols].median()).to_numpy()\n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    emb = UMAP(n_components=2, n_neighbors=30, min_dist=0.1, metric='cosine', random_state=42).fit_transform(X)\n",
    "    df['x2d'], df['y2d'] = emb[:,0], emb[:,1]\n",
    "print('Has 2D cols:', all(c in df.columns for c in ['x2d','y2d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7bdc830-cd10-4cd3-8284-cc3e52debb12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Replacement cell: robust UMAP builder (handles NaN/±inf/constant cols) ===\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, normalize\n",
    "\n",
    "def _build_umap_input(df, preferred_cols=None):\n",
    "    numeric_candidates = [c for c in df.columns if df[c].dtype.kind in \"if\"]\n",
    "    if preferred_cols is None:\n",
    "        preferred_cols = ['pos','tissue_hits','tissues','resonance_score','gene_deg','ccre_deg','structure_score','cnt_score']\n",
    "    cols = [c for c in preferred_cols if c in df.columns]\n",
    "    if len(cols) < 3:\n",
    "        cols = numeric_candidates\n",
    "\n",
    "    X = df[cols].copy()\n",
    "\n",
    "    # 1) replace ±inf with NaN\n",
    "    X = X.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "    # 2) drop all-NaN columns\n",
    "    all_nan_cols = list(X.columns[X.isna().all(axis=0)])\n",
    "    if all_nan_cols:\n",
    "        print(\"Dropping all-NaN columns:\", all_nan_cols)\n",
    "        X = X.drop(columns=all_nan_cols)\n",
    "\n",
    "    # 3) median impute; if still NaN, fill 0\n",
    "    med = X.median(axis=0, skipna=True)\n",
    "    X = X.fillna(med).fillna(0.0)\n",
    "\n",
    "    # 4) drop constant columns (avoid zero variance)\n",
    "    const_cols = [c for c in X.columns if X[c].nunique(dropna=True) <= 1]\n",
    "    if const_cols:\n",
    "        print(\"Dropping constant columns:\", const_cols)\n",
    "        X = X.drop(columns=const_cols)\n",
    "\n",
    "    if X.shape[1] < 2:\n",
    "        raise ValueError(\"Not enough informative numeric columns remain for UMAP.\")\n",
    "\n",
    "    Xa = X.to_numpy(np.float32)\n",
    "    Xa[~np.isfinite(Xa)] = 0.0\n",
    "\n",
    "    # protect against zero-norm rows (for cosine metric)\n",
    "    row_norm = np.linalg.norm(Xa, axis=1)\n",
    "    zero_rows = (row_norm == 0)\n",
    "    if zero_rows.any():\n",
    "        Xa[zero_rows, 0] = 1e-6\n",
    "        print(f\"Zero-norm rows nudged: {int(zero_rows.sum())}\")\n",
    "\n",
    "    Xa = StandardScaler(with_mean=True, with_std=True).fit_transform(Xa)\n",
    "    Xa = normalize(Xa, norm='l2')\n",
    "    return Xa\n",
    "\n",
    "# Only compute if missing\n",
    "if not all(c in df.columns for c in [\"x2d\",\"y2d\"]):\n",
    "    from umap import UMAP\n",
    "    Xa = _build_umap_input(df)\n",
    "    emb = UMAP(\n",
    "        n_components=2,\n",
    "        n_neighbors=30,   # reduce to 15 if memory is tight\n",
    "        min_dist=0.1,\n",
    "        metric='cosine',\n",
    "        random_state=42\n",
    "    ).fit_transform(Xa)\n",
    "    df[\"x2d\"], df[\"y2d\"] = emb[:,0], emb[:,1]\n",
    "\n",
    "print(\"Has 2D cols:\", all(c in df.columns for c in [\"x2d\",\"y2d\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ab6c11-d5cd-4418-b484-26bf1caff51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.graph_objects as go\n",
    "x, y, z = df['x2d'].to_numpy(), df['y2d'].to_numpy(), df['resonance_score'].to_numpy()\n",
    "name_col = 'gene_name' if 'gene_name' in df.columns else df.columns[0]\n",
    "q = np.quantile(z, [0.0, 0.5, 0.75, 0.9, 0.97, 1.0])\n",
    "bands = list(zip(q[:-1], q[1:]))\n",
    "frames = []\n",
    "for i,(lo,hi) in enumerate(bands):\n",
    "    m = (z>=lo)&(z<=hi)\n",
    "    frames.append(go.Frame(name=f\"Band {i+1}: {lo:.3f}-{hi:.3f}\",\n",
    "                           data=[go.Scatter3d(x=x[m], y=y[m], z=z[m], mode='markers',\n",
    "                                               marker=dict(size=2, opacity=0.85), text=df[name_col][m],\n",
    "                                               hovertemplate='<b>%{text}</b><br>x=%{x:.2f} y=%{y:.2f}<br>res=%{z:.4f}<extra></extra>')]))\n",
    "fig = go.Figure(\n",
    "    data=[go.Scatter3d(x=x, y=y, z=z, mode='markers', marker=dict(size=2, opacity=0.25), text=df[name_col],\n",
    "                       hovertemplate='<b>%{text}</b><br>x=%{x:.2f} y=%{y:.2f}<br>res=%{z:.4f}<extra></extra>')],\n",
    "    frames=frames,\n",
    ")\n",
    "fig.update_layout(title='CNT 3D Genomic Field • z = resonance_score',\n",
    "                  scene=dict(xaxis_title='field‑x', yaxis_title='field‑y', zaxis_title='resonance'),\n",
    "                  sliders=[dict(active=0, steps=[dict(label=f.name, method='animate', args=[[f.name], {'frame': {'duration': 0, 'redraw': True}, 'mode':'immediate', 'fromcurrent': True}]) for f in frames])])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5779c459-0621-40ec-a31d-f5318a7978b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import igraph as ig, leidenalg as la\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.metrics import normalized_mutual_info_score as NMI\n",
    "from scipy.sparse import csr_matrix, tril\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree, dijkstra\n",
    "\n",
    "coords3 = np.c_[df['x2d'].to_numpy(), df['y2d'].to_numpy(), df['resonance_score'].to_numpy()]\n",
    "coords2 = np.c_[df['x2d'].to_numpy(), df['y2d'].to_numpy()]\n",
    "\n",
    "def leiden_labels(coords, k=12, res=0.8):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(coords)\n",
    "    idx = nbrs.kneighbors(return_distance=False)\n",
    "    edges = []\n",
    "    n = coords.shape[0]\n",
    "    for i in range(n):\n",
    "        for j in idx[i,1:]:\n",
    "            edges.append((int(i), int(j)))\n",
    "    G = ig.Graph(n=n, edges=edges, directed=False)\n",
    "    part = la.find_partition(G, la.RBConfigurationVertexPartition, resolution_parameter=res)\n",
    "    return np.array(part.membership)\n",
    "\n",
    "def morans_I(values, coords, k=12):\n",
    "    nbrs = NearestNeighbors(n_neighbors=k).fit(coords)\n",
    "    idx = nbrs.kneighbors(return_distance=False)\n",
    "    n = len(values)\n",
    "    mu = values.mean()\n",
    "    num = 0.0; den = ((values - mu)**2).sum(); w = 0\n",
    "    for i in range(n):\n",
    "        for j in idx[i,1:]:\n",
    "            num += (values[i]-mu)*(values[j]-mu); w += 1\n",
    "    return float((n/w) * (num/den)), int(w)\n",
    "\n",
    "# 1) layer persistence via HDBSCAN on z‑bands\n",
    "layer_persistence_index = None\n",
    "try:\n",
    "    import hdbscan\n",
    "    z = df['resonance_score'].to_numpy()\n",
    "    q = np.quantile(z, [0.0, 0.5, 0.75, 0.9, 0.97, 1.0])\n",
    "    bands = list(zip(q[:-1], q[1:]))\n",
    "    entropies = []\n",
    "    for lo,hi in bands:\n",
    "        m = (z>=lo)&(z<=hi)\n",
    "        if m.sum()<50:\n",
    "            entropies.append(0.0)\n",
    "            continue\n",
    "        X3 = coords3[m]\n",
    "        cl = hdbscan.HDBSCAN(min_cluster_size=25, min_samples=10).fit_predict(X3)\n",
    "        labs = cl[cl>=0]\n",
    "        if labs.size==0:\n",
    "            entropies.append(0.0)\n",
    "        else:\n",
    "            p = np.bincount(labs)/labs.size\n",
    "            ent = -(p*np.log(p+1e-9)).sum()\n",
    "            entropies.append(ent)\n",
    "    layer_persistence_index = float(np.mean(entropies))\n",
    "except Exception as e:\n",
    "    print('[warn] HDBSCAN not available or failed:', e)\n",
    "\n",
    "# 2) Leiden communities 3D vs 2D\n",
    "labs3 = leiden_labels(coords3)\n",
    "labs2 = leiden_labels(coords2)\n",
    "community_NMI_2Dvs3D = float(NMI(labs2, labs3))\n",
    "\n",
    "# 3) Moran's I on resonance\n",
    "morI, w_edges = morans_I(df['resonance_score'].to_numpy(), coords3, k=12)\n",
    "\n",
    "# 4) MST geodesic stretch on top‑N resonance\n",
    "z = df['resonance_score'].to_numpy()\n",
    "topN = min(600, len(df))\n",
    "sel = np.argsort(-z)[:topN]\n",
    "C = coords3[sel]\n",
    "nbrs = NearestNeighbors(n_neighbors=8).fit(C)\n",
    "dist, inds = nbrs.kneighbors(return_distance=True)\n",
    "rows=[]; cols=[]; data=[]\n",
    "for i,(d,idxs) in enumerate(zip(dist, inds)):\n",
    "    for dd,j in zip(d[1:], idxs[1:]):\n",
    "        rows.append(i); cols.append(int(j)); data.append(float(dd))\n",
    "from scipy import sparse as sp\n",
    "W = sp.csr_matrix((data,(rows,cols)), shape=(C.shape[0], C.shape[0]))\n",
    "W = sp.tril(W) + sp.tril(W, -1).T\n",
    "M = minimum_spanning_tree(W).tocsr()\n",
    "rng = np.random.default_rng(42)\n",
    "pairs = rng.choice(C.shape[0], size=(300,2), replace=False)\n",
    "geo = dijkstra(M, indices=pairs[:,0], directed=False)[np.arange(pairs.shape[0]), pairs[:,1]]\n",
    "eu = np.linalg.norm(C[pairs[:,0]]-C[pairs[:,1]], axis=1)\n",
    "mst_stretch_mean = float(np.nanmean(np.clip(geo/eu, 1.0, None)))\n",
    "\n",
    "# 5) Optional homology (ripser)\n",
    "betti_signal = None\n",
    "try:\n",
    "    from ripser import ripser\n",
    "    r = ripser(C, maxdim=1)\n",
    "    H1 = r['dgms'][1]\n",
    "    if H1.size:\n",
    "        pers = (H1[:,1]-H1[:,0])\n",
    "        betti_signal = float(np.median(pers[np.isfinite(pers)]))\n",
    "except Exception as e:\n",
    "    print('[warn] ripser not available or failed:', e)\n",
    "\n",
    "summary = {\n",
    "    'layer_persistence_index': layer_persistence_index,\n",
    "    'community_NMI_2D_vs_3D': community_NMI_2Dvs3D,\n",
    "    'morans_I_resonance': morI,\n",
    "    'knn_edge_count': w_edges,\n",
    "    'mst_geodesic_stretch_mean': mst_stretch_mean,\n",
    "    'H1_loop_persistence_median(optional)': betti_signal,\n",
    "}\n",
    "pd.Series(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad63da2e-44b7-4d71-9b68-2bb8cf7049b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 100\n",
    "votes = np.zeros((len(df), B), dtype=int)\n",
    "rng = np.random.default_rng(42)\n",
    "for b in range(B):\n",
    "    jitter = rng.uniform(0, 0.02, size=coords3.shape)\n",
    "    labs_b = leiden_labels(coords3 + jitter, k=16, res=0.8)\n",
    "    votes[:, b] = labs_b\n",
    "mode = np.array([np.bincount(votes[i]).argmax() for i in range(len(df))])\n",
    "stab = (votes == mode[:, None]).mean(1)\n",
    "df['consensus_label'] = mode\n",
    "df['stability'] = stab\n",
    "df[['gene_name','consensus_label','stability']].head(5) if 'gene_name' in df.columns else df[['consensus_label','stability']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a9d98-6a5e-4745-8c5f-5d87e70366e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency, kruskal\n",
    "enrich = {}\n",
    "if 'tissues' in df.columns:\n",
    "    tab = pd.crosstab(df['consensus_label'], df['tissues'])\n",
    "    chi2, p, dof, exp = chi2_contingency(tab)\n",
    "    enrich['tissues_chi2_p'] = float(p)\n",
    "if 'trait' in df.columns:\n",
    "    tab2 = pd.crosstab(df['consensus_label'], df['trait'])\n",
    "    chi2, p, dof, exp = chi2_contingency(tab2)\n",
    "    enrich['trait_chi2_p'] = float(p)\n",
    "groups = [df.loc[df['consensus_label']==c, 'resonance_score'].values for c in sorted(df['consensus_label'].unique())]\n",
    "H, p_kw = kruskal(*groups)\n",
    "enrich['resonance_KW_p'] = float(p_kw)\n",
    "pd.Series(enrich)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459df8b2-9f3a-46ac-9815-82b29a754c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = df.query('stability >= 0.7')\n",
    "by_comm = core.groupby('consensus_label')\n",
    "for c, g in by_comm:\n",
    "    g.sort_values('resonance_score', ascending=False).to_csv(OUTDIR/f'attractor_comm{c}_core.csv', index=False)\n",
    "\n",
    "summary_path = OUTDIR/\"report.txt\"\n",
    "with open(summary_path, 'w') as f:\n",
    "    f.write(\"CNT 3D Genomic Field — UPGRADE Summary\\n\")\n",
    "    for k,v in summary.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "    for k,v in enrich.items():\n",
    "        f.write(f\"{k}: {v}\\n\")\n",
    "print('Wrote', summary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f88cfba-7762-408b-abd3-8292035ea882",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "    is_core = df['stability']>=0.7\n",
    "    fig2 = go.Figure()\n",
    "    fig2.add_trace(go.Scatter3d(x=df.loc[~is_core,'x2d'], y=df.loc[~is_core,'y2d'], z=df.loc[~is_core,'resonance_score'], mode='markers', marker=dict(size=2, opacity=0.2), name='rim'))\n",
    "    fig2.add_trace(go.Scatter3d(x=df.loc[is_core,'x2d'],  y=df.loc[is_core,'y2d'],  z=df.loc[is_core,'resonance_score'], mode='markers', marker=dict(size=3, opacity=0.9), name='core'))\n",
    "    fig2.update_layout(title='Stable cores (≥0.7) vs rims', scene=dict(xaxis_title='x2d', yaxis_title='y2d', zaxis_title='resonance'))\n",
    "    fig2.show()\n",
    "except Exception as e:\n",
    "    print('[warn] plotly overlay skipped:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ec0eec-5f04-4c47-a775-e042e8ce9b31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
