{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fde51583-9cd1-4f75-80e4-a1697a4c0b7d",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "expected '(' (3373574970.py, line 104)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 104\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mdef pairwise# === Quick Resync for v1.5 helpers (lightweight) ===\u001b[39m\n                ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m expected '('\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNT — Weirdness Probe v1 (single cell)\n",
    "Attacks three fronts in one strike:\n",
    "  (1) Consensus vs Dissent Curve  → novelty cliffs + Θ* threshold\n",
    "  (2) GRA Invariance Battery      → paraphrase/gauge reparam. stability\n",
    "  (3) Anthropomorphism Audit      → agency vs mechanistic framing index\n",
    "\n",
    "Notes\n",
    "- Set OPENAI_API_KEY in your env to use a live LLM. Otherwise we simulate.\n",
    "- Optional: OPENAI_BASE_URL for OpenAI-compatible endpoints (e.g., local).\n",
    "- Optional: LLM_MODEL (default 'gpt-4o-mini'); N_REPS/TEMPS configurable.\n",
    "- Outputs saved to:  <ROOT>/artifacts/cnt_llm_weirdness_probe/<RUN_ID>\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Imports & setup ----------\n",
    "import os, sys, re, json, time, math, random, zlib, base64, itertools, textwrap, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib is optional; plots will be skipped if unavailable\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MPL = True\n",
    "except Exception:\n",
    "    HAS_MPL = False\n",
    "\n",
    "# ---------- Paths, run id, config ----------\n",
    "ROOT = Path(os.getenv(\"CNT_LAB_DIR\", os.getcwd()))\n",
    "RUN_ID = datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "OUTDIR = ROOT / \"artifacts\" / \"cnt_llm_weirdness_probe\" / RUN_ID\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"\") or None\n",
    "N_REPS   = int(os.getenv(\"CNT_WP_N_REPS\", \"3\"))       # per condition\n",
    "TEMPS    = [float(x) for x in os.getenv(\"CNT_WP_TEMPS\", \"0.1,0.3,0.7,1.0,1.3\").split(\",\")]\n",
    "MAX_TOK  = int(os.getenv(\"CNT_WP_MAXTOK\", \"400\"))\n",
    "BASE_SEED= int(os.getenv(\"CNT_WP_SEED\",   \"42\"))\n",
    "\n",
    "# Auto-install openai if needed (best effort; safe to fail if sim mode)\n",
    "def ensure_openai():\n",
    "    try:\n",
    "        import openai  # noqa: F401\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"openai\"], check=False)\n",
    "            import openai  # noqa: F401\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "OPENAI_READY = bool(OPENAI_API_KEY) and ensure_openai()\n",
    "\n",
    "SIMULATE = not OPENAI_READY  # Simulation mode if no key or install failed\n",
    "\n",
    "# ---------- Utility helpers ----------\n",
    "def ts():\n",
    "    return datetime.utcnow().strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
    "\n",
    "def normalize_ws(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", t.strip())\n",
    "\n",
    "def tokens_est(t: str) -> int:\n",
    "    # crude word-based proxy\n",
    "    return max(1, len(re.findall(r\"\\w+\", t)))\n",
    "\n",
    "def ugram_ratio(t: str, n: int = 3) -> float:\n",
    "    words = re.findall(r\"[A-Za-z0-9']+\", t.lower())\n",
    "    if len(words) < n: return 0.0\n",
    "    grams = list(zip(*[words[i:] for i in range(n)]))\n",
    "    return len(set(grams))/max(1, len(grams))\n",
    "\n",
    "def compress_ratio(t: str) -> float:\n",
    "    raw = t.encode(\"utf-8\", errors=\"ignore\")\n",
    "    if not raw: return 1.0\n",
    "    comp = zlib.compress(raw, level=9)\n",
    "    return len(comp)/len(raw)\n",
    "\n",
    "def sim_ratio(a: str, b: str) -> float:\n",
    "    # difflib-like similarity without import (simple LCS-inspired proxy)\n",
    "    # Fast-ish heuristic: Jaccard over word bigrams blended with char overlap\n",
    "    aw = re.findall(r\"[A-Za-z0-9']+\", a.lower())\n",
    "    bw = re.findall(r\"[A-Za-z0-9']+\", b.lower())\n",
    "    a2 = set(zip(aw, aw[1:])) if len(aw) > 1 else set()\n",
    "    b2 = set(zip(bw, bw[1:])) if len(bw) > 1 else set()\n",
    "    if not a2 and not b2:\n",
    "        # fallback to char overlap\n",
    "        aset, bset = set(a.lower()), set(b.lower())\n",
    "        denom = len(aset | bset) or 1\n",
    "        return len(aset & bset)/denom\n",
    "    denom = len(a2 | b2) or 1\n",
    "    j = len(a2 & b2)/denom\n",
    "    # blend with crude char overlap to stabilize on short texts\n",
    "    aset, bset = set(a.lower()), set(b.lower())\n",
    "    denom2 = len(aset | bset) or 1\n",
    "    c = len(aset & bset)/denom2\n",
    "    return 0.65*j + 0.35*c\n",
    "\n",
    "def pairwise# === Quick Resync for v1.5 helpers (lightweight) ===\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def utc_stamp():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def get_probe_base():\n",
    "    base = os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\"\n",
    "    p = Path(base) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def ensure_dir(p):\n",
    "    p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
    "\n",
    "def set_probe_env(\n",
    "    temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "    reps=16, perm=600, autoextend=True, smooth=\"none\",\n",
    "    model=\"gpt-4o-mini\", api_key=None, base_url=None,\n",
    "):\n",
    "    os.environ[\"CNT_WP_TEMPS\"]      = temps\n",
    "    os.environ[\"CNT_WP_N_REPS\"]     = str(reps)\n",
    "    os.environ[\"CNT_WP_PERM\"]       = str(perm)\n",
    "    os.environ[\"CNT_WP_AUTOEXTEND\"] = \"1\" if autoextend else \"0\"\n",
    "    os.environ[\"CNT_WP_SMOOTH\"]     = smooth\n",
    "    os.environ[\"LLM_MODEL\"]         = model\n",
    "    if api_key is not None: os.environ[\"OPENAI_API_KEY\"]  = api_key\n",
    "    if base_url:            os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    print(f\"✓ Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "\n",
    "def run_with_alias(model_id: str, alias: str, **kw):\n",
    "    outdir = ensure_dir(get_probe_base() / f\"{utc_stamp()}_{alias}\")\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(outdir)\n",
    "    if \"run_model\" not in globals():\n",
    "        raise RuntimeError(\"run_model is not defined in this kernel. Re-run your v1.5 mega-cell to load the engine.\")\n",
    "    return run_model(model_id, **kw)\n",
    "\n",
    "print(\"✓ Quick-resync loaded: set_probe_env(), run_with_alias(), get_probe_base()\")\n",
    "print(\"• Engine present? run_model:\", \"yes\" if \"run_model\" in globals() else \"NO (re-run v1.5 mega-cell)\")\n",
    "mean_similarity(texts):\n",
    "    if len(texts) < 2: return 1.0\n",
    "    sims = []\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i+1, len(texts)):\n",
    "            sims.append(sim_ratio(texts[i], texts[j]))\n",
    "    return float(np.mean(sims)) if sims else 1.0\n",
    "\n",
    "def novelty_from_group(texts):\n",
    "    # novelty = 1 - mean pairwise similarity\n",
    "    return max(0.0, 1.0 - pairwise_mean_similarity(texts))\n",
    "\n",
    "def write_json(path, obj):\n",
    "    path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "random.seed(BASE_SEED)\n",
    "np.random.seed(BASE_SEED)\n",
    "\n",
    "# ---------- LLM wrapper (OpenAI or simulation) ----------\n",
    "def simulate_reply(messages, temperature=0.7):\n",
    "    # Produce temperature-dependent pseudo-outputs—enough structure to test metrics\n",
    "    topics = [\"stars\", \"markets\", \"mushrooms\", \"rivers\", \"cities\", \"membranes\"]\n",
    "    tones  = [\"measured\", \"lyrical\", \"technical\", \"playful\", \"skeptical\", \"didactic\"]\n",
    "    verbs  = [\"braid\", \"whisper\", \"drift\", \"pin\", \"resonate\", \"cascade\", \"splice\", \"harbor\"]\n",
    "    stats  = [\"tokens\", \"probabilities\", \"gradients\", \"embeddings\", \"n-grams\", \"logits\", \"priors\"]\n",
    "    # Derive a base from prompt content\n",
    "    hint = normalize_ws(\" \".join(m.get(\"content\",\"\") for m in messages))[:160].lower()\n",
    "    t = max(0.05, min(1.5, float(temperature)))\n",
    "    n_sent = 3 + int(4*t + random.random()*3)\n",
    "    # Inject agency/mechanistic words depending on the prompt to make the audit meaningful\n",
    "    agency_words = [\"I think\", \"I believe\", \"I chose\", \"I decided\", \"I prefer\", \"I feel\"]\n",
    "    mech_words   = [\"statistical\", \"token\", \"logit\", \"embedding\", \"n-gram\", \"temperature\"]\n",
    "    use_agency = (\"why did you decide\" in hint) or (\"why did you choose\" in hint) or (\"you decide\" in hint)\n",
    "    use_mech   = (\"statistical\" in hint) or (\"mechanistic\" in hint) or (\"token\" in hint)\n",
    "    bits = []\n",
    "    for _ in range(n_sent):\n",
    "        seg = []\n",
    "        seg.append(random.choice([\"In brief\", \"Consider\", \"Often\", \"Sometimes\", \"Empirically\", \"Practically\"]))\n",
    "        seg.append(f\"{random.choice(tones).capitalize()} patterns {random.choice(['emerge','cohere','fracture','drift'])}\")\n",
    "        seg.append(f\"as {random.choice(topics)} {random.choice(['resonate','fold','diffuse','align','compete'])}.\")\n",
    "        if random.random() < 0.3 + 0.3*t:\n",
    "            seg.append(f\"We {random.choice(['tune','sample','scan'])} {random.choice(stats)} like {random.choice(verbs)}.\")\n",
    "        if use_agency and random.random() < 0.6:\n",
    "            seg.append(random.choice(agency_words) + \" this framing.\")\n",
    "        if use_mech and random.random() < 0.6:\n",
    "            seg.append(f\"This follows from {random.choice(mech_words)} cues at higher temperature.\")\n",
    "        bits.append(\" \".join(seg))\n",
    "    # Add variability with a small random suffix at high temps\n",
    "    suffix = \"\" if t < 0.5 else \" \".join(random.sample(verbs, k=min(len(verbs), 3)))\n",
    "    return normalize_ws(\" \".join(bits) + \" \" + suffix)\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self):\n",
    "        self.kind = \"sim\" if SIMULATE else \"openai\"\n",
    "        self.model = LLM_MODEL\n",
    "        self.ready = not SIMULATE\n",
    "        if not SIMULATE:\n",
    "            # Initialize OpenAI client: support v1 and legacy; responses/chat endpoints\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                kwargs = {}\n",
    "                if OPENAI_BASE_URL:\n",
    "                    kwargs[\"base_url\"] = OPENAI_BASE_URL\n",
    "                if OPENAI_API_KEY:\n",
    "                    kwargs[\"api_key\"] = OPENAI_API_KEY\n",
    "                self.client = OpenAI(**kwargs)\n",
    "                self.api = \"v1\"\n",
    "            except Exception:\n",
    "                import openai as openai_legacy\n",
    "                if OPENAI_API_KEY:\n",
    "                    openai_legacy.api_key = OPENAI_API_KEY\n",
    "                if OPENAI_BASE_URL:\n",
    "                    try:\n",
    "                        openai_legacy.base_url = OPENAI_BASE_URL  # type: ignore\n",
    "                    except Exception:\n",
    "                        pass\n",
    "                self.client = openai_legacy\n",
    "                self.api = \"legacy\"\n",
    "\n",
    "    def chat(self, messages, temperature=0.7, max_tokens=MAX_TOK, seed=None, retries=3, backoff=0.8):\n",
    "        if SIMULATE:\n",
    "            return simulate_reply(messages, temperature)\n",
    "        last_err = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                if self.api == \"v1\":\n",
    "                    # Try chat.completions first\n",
    "                    try:\n",
    "                        kwargs = dict(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                        if seed is not None:\n",
    "                            kwargs[\"seed\"] = seed  # supported on some models\n",
    "                        r = self.client.chat.completions.create(**kwargs)\n",
    "                        return r.choices[0].message.content\n",
    "                    except Exception:\n",
    "               import os\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"   # cold invariance\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "rd1 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep1\")\n",
    "rd2 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep2\")\n",
    "rd3 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep3\")\n",
    "         # Fallback to responses API\n",
    "                        r = self.client.responses.create(\n",
    "                            model=self.model,\n",
    "                            input=[{\"role\": m.get(\"role\",\"user\"), \"content\": m.get(\"content\",\"\")} for m in messages],\n",
    "                            temperature=temperature,\n",
    "                            max_output_tokens=max_tokens,\n",
    "                            seed=seed,\n",
    "                        )\n",
    "                        # Attempt to unify output (text convenience)\n",
    "                        try:\n",
    "                            return r.output_text\n",
    "                        except Exception:\n",
    "                            # Extract best-effort text\n",
    "                            parts = []\n",
    "                            for out in getattr(r, \"output\", []) or []:\n",
    "                                if getattr(out, \"type\", \"\") == \"output_text\":\n",
    "                                    parts.append(getattr(out, \"content\", \"\"))\n",
    "                            return \"\\n\".join(parts) if parts else \"\"\n",
    "                else:\n",
    "                    # Legacy\n",
    "                    r = self.client.ChatCompletion.create(\n",
    "                        model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens\n",
    "                    )\n",
    "                    return r[\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                time.sleep((attempt+1)*backoff)\n",
    "        raise RuntimeError(f\"LLM call failed after retries: {last_err}\")\n",
    "\n",
    "LLM = LLMClient()\n",
    "\n",
    "# ---------- Experiment definitions ----------\n",
    "TOPICS = [\n",
    "    \"Are large language models creative?\", \n",
    "    \"Do psychedelics improve mental health outcomes?\",\n",
    "    \"Is homework beneficial for learning?\",\n",
    "    \"Can economic sanctions achieve political goals?\",\n",
    "    \"Are processed foods inherently harmful?\",\n",
    "    \"Is social media net-positive for teenagers?\"\n",
    "]\n",
    "\n",
    "def prompt_consensus(topic):\n",
    "    return f\"\"\"State the mainstream, widely accepted view on the question \"{topic}\" in 3 concise bullet points, neutral tone, no fluff.\"\"\"\n",
    "\n",
    "def prompt_dissent(topic):\n",
    "    return f\"\"\"Argue a novel, contrarian perspective on \"{topic}\" that challenges the mainstream. Give one concrete mechanism and one illustrative example; be specific and surprising.\"\"\"\n",
    "\n",
    "# Invariance transforms (paraphrase + gauge-like reparameterizations)\n",
    "SYNONYM_TABLE = {\n",
    "    \"explain\": [\"describe\", \"clarify\", \"outline\"],\n",
    "    \"simple\": [\"plain\", \"clear\", \"accessible\"],\n",
    "    \"steps\": [\"stages\", \"moves\", \"phases\"],\n",
    "    \"kids\": [\"children\", \"young students\", \"12-year-olds\"],\n",
    "    \"short\": [\"brief\", \"compact\", \"succinct\"],\n",
    "    \"paragraph\": [\"passage\", \"section\"],\n",
    "}\n",
    "def _syn_replace(s: str, alt=False):\n",
    "    def repl(m):\n",
    "        w = m.group(0)\n",
    "        cands = SYNONYM_TABLE.get(w.lower(), [])\n",
    "        if not cands: return w\n",
    "        pick = cands[1 % len(cands)] if alt and len(cands) > 1 else cands[0]\n",
    "        # preserve capitalization\n",
    "        return pick.capitalize() if w[0].isupper() else pick\n",
    "    pat = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, SYNONYM_TABLE.keys())) + r\")\\b\", flags=re.I)\n",
    "    return pat.sub(repl, s)\n",
    "\n",
    "def gauge_reparam(prompt: str, bullets: int = 5):\n",
    "    # Re-parameterize constraints: bullets → exact N, or paragraph → sentences\n",
    "    p = prompt\n",
    "    p = re.sub(r\"\\b(in|using)\\s+\\d+\\s+(steps|bullets?)\\b\", f\"in {bullets} steps\", p, flags=re.I)\n",
    "    p = re.sub(r\"\\b(one|1)\\s+paragraph\\b\", f\"{bullets} sentences\", p, flags=re.I)\n",
    "    return p\n",
    "\n",
    "def reorder_clauses(prompt: str):\n",
    "    parts = [x.strip() for x in re.split(r\"[;,]\", prompt) if x.strip()]\n",
    "    if len(parts) < 2: return prompt\n",
    "    head = parts[0]\n",
    "    tail = parts[1:]\n",
    "    random.shuffle(tail)\n",
    "    return \"; \".join([head] + tail)\n",
    "\n",
    "INV_BASE_PROMPTS = [\n",
    "    \"Explain photosynthesis to kids in 1 paragraph with a short metaphor at the end.\",\n",
    "    \"Explain how vaccines work using 5 steps and one counterexample.\",\n",
    "    \"Explain compound interest in a simple way with a compact example.\"\n",
    "]\n",
    "\n",
    "def transform_family(p):\n",
    "    return {\n",
    "        \"base\": p,\n",
    "        \"syn1\": _syn_replace(p, alt=False),\n",
    "        \"syn2\": _syn_replace(p, alt=True),\n",
    "        \"gauge3\": gauge_reparam(p, bullets=3),\n",
    "        \"reorder\": reorder_clauses(p),\n",
    "    }\n",
    "\n",
    "# Anthropomorphism Audit prompts\n",
    "MENTAL_VERBS = {\"think\",\"believe\",\"decide\",\"feel\",\"choose\",\"prefer\",\"guess\",\"assume\",\"intend\",\"want\"}\n",
    "FIRST_PERSON = {\"i \", \"i'm\", \"i’m\", \"i am\", \"my \", \"me \", \"myself\", \"personally\"}\n",
    "MECH_TERMS   = {\"token\",\"probability\",\"logit\",\"embedding\",\"statistical\",\"n-gram\",\"temperature\",\"sampling\",\"gradient\",\"entropy\",\"prior\"}\n",
    "\n",
    "def agency_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain *why you decided* to present it that way—use first-person language (e.g., \"I decided\", \"I chose\").\"\"\"\n",
    "\n",
    "def mechanistic_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain—without using first-person—what *statistical cues* (tokens, logits, n-grams, embeddings, temperature) likely led to those next-token choices.\"\"\"\n",
    "\n",
    "AUDIT_TASKS = [\n",
    "    \"Summarize why the sky is blue in one paragraph.\",\n",
    "    \"Compare Jupiter and Earth in two sentences.\",\n",
    "    \"Give one risk and one benefit of social media for teens.\"\n",
    "]\n",
    "\n",
    "# ---------- Metric extracts for anthropomorphism ----------\n",
    "def score_anthro(text: str):\n",
    "    t = \" \" + text.lower() + \" \"\n",
    "    words = re.findall(r\"[a-z']+\", t)\n",
    "    n_words = max(1, len(words))\n",
    "    agency_hits = 0\n",
    "    mech_hits   = 0\n",
    "    disclaimers = 0\n",
    "    # First person + mental verbs\n",
    "    agency_hits += sum(t.count(fp) for fp in FIRST_PERSON)\n",
    "    agency_hits += sum(words.count(v) for v in MENTAL_VERBS)\n",
    "    # Mechanistic lexicon\n",
    "    mech_hits   += sum(words.count(v) for v in MECH_TERMS)\n",
    "    # Common disclaimers\n",
    "    disclaimers += t.count(\"as an ai\") + t.count(\"as a language model\") + t.count(\"i cannot\") + t.count(\"i do not have\")\n",
    "    # Normalize per 100 words\n",
    "    scale = 100.0 / n_words\n",
    "    return {\n",
    "        \"agency_per100\": agency_hits * scale,\n",
    "        \"mechanistic_per100\": mech_hits * scale,\n",
    "        \"disclaimer_per100\": disclaimers * scale\n",
    "    }\n",
    "\n",
    "# ---------- Run the three experiments ----------\n",
    "all_rows = []\n",
    "\n",
    "def run_consensus_vs_dissent():\n",
    "    # Collect outputs\n",
    "    group_store = defaultdict(list)  # key: (topic, mode, temp) -> [texts]\n",
    "    for topic in TOPICS:\n",
    "        for mode in (\"consensus\", \"dissent\"):\n",
    "            base_prompt = prompt_consensus(topic) if mode == \"consensus\" else prompt_dissent(topic)\n",
    "            for temp in TEMPS:\n",
    "                for r in range(N_REPS):\n",
    "                    seed = BASE_SEED + r\n",
    "                    msgs = [{\"role\":\"user\",\"content\": base_prompt}]\n",
    "                    out = LLM.chat(msgs, temperature=temp, max_tokens=MAX_TOK, seed=seed)\n",
    "                    out = normalize_ws(out)\n",
    "                    group_store[(topic, mode, temp)].append(out)\n",
    "                    all_rows.append({\n",
    "                        \"experiment\":\"consensus_vs_dissent\",\n",
    "                        \"topic\": topic, \"mode\": mode, \"temperature\": temp, \"rep\": r,\n",
    "                        \"prompt\": base_prompt, \"output\": out,\n",
    "                        \"tokens_est\": tokens_est(out),\n",
    "                        \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                        \"compress_ratio\": compress_ratio(out),\n",
    "                    })\n",
    "                time.sleep(0.2)  # gentle pacing\n",
    "\n",
    "    # Compute novelty and Θ* thresholds\n",
    "    curves = []\n",
    "    for mode in (\"consensus\",\"dissent\"):\n",
    "        for temp in TEMPS:\n",
    "            texts = []\n",
    "            for topic in TOPICS:\n",
    "                texts += group_store[(topic, mode, temp)]\n",
    "            nov = novelty_from_group(texts)\n",
    "            curves.append({\"mode\": mode, \"temperature\": temp, \"novelty\": nov})\n",
    "\n",
    "    dfc = pd.DataFrame(curves)\n",
    "    # Θ* threshold: first temperature where novelty exceeds baseline + 1.5 * std (per-mode)\n",
    "    th = {}\n",
    "    for mode, sub in dfc.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\")\n",
    "        base = float(sub[\"novelty\"].iloc[0])\n",
    "        std  = float(sub[\"novelty\"].std() or 0.0)\n",
    "        cutoff = base + 1.5*std\n",
    "        theta = None\n",
    "        for t, n in zip(sub[\"temperature\"], sub[\"novelty\"]):\n",
    "            if n > cutoff:\n",
    "                theta = t\n",
    "                break\n",
    "        theta = theta if theta is not None else float(sub[\"temperature\"].iloc[-1])\n",
    "        th[mode] = {\"baseline\": base, \"std\": std, \"cutoff\": cutoff, \"theta_star\": theta}\n",
    "\n",
    "    # Save plots\n",
    "    if HAS_MPL:\n",
    "        plt.figure(figsize=(7,4.5))\n",
    "        for mode, sub in dfc.groupby(\"mode\"):\n",
    "            sub = sub.sort_values(\"temperature\")\n",
    "            plt.plot(sub[\"temperature\"], sub[\"novelty\"], marker=\"o\", label=mode)\n",
    "            # draw θ*\n",
    "            plt.axvline(th[mode][\"theta_star\"], linestyle=\"--\", alpha=0.5)\n",
    "        plt.xlabel(\"Temperature\")\n",
    "        plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "        plt.title(\"Consensus vs Dissent — Novelty Curves\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR / \"consensus_dissent_curve.png\", dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "    write_json(OUTDIR / \"consensus_dissent_theta.json\", th)\n",
    "    return th\n",
    "\n",
    "def run_gra_invariance():\n",
    "    rows = []\n",
    "    for base in INV_BASE_PROMPTS:\n",
    "        family = transform_family(base)\n",
    "        # For each transform, generate outputs and compare to base\n",
    "        # Use two reps to de-noise similarity a bit\n",
    "        outs = {}\n",
    "        for name, prompt in family.items():\n",
    "            outs[name] = []\n",
    "            for r in range(max(1, N_REPS//2 + 1)):\n",
    "                seed = BASE_SEED + r\n",
    "                msgs = [{\"role\":\"user\",\"content\": prompt}]\n",
    "                out = LLM.chat(msgs, temperature=0.4, max_tokens=MAX_TOK, seed=seed)\n",
    "                out = normalize_ws(out)\n",
    "                outs[name].append(out)\n",
    "                rows.append({\n",
    "                    \"experiment\":\"gra_invariance\",\n",
    "                    \"base_prompt\": base, \"transform\": name, \"rep\": r,\n",
    "                    \"prompt\": prompt, \"output\": out,\n",
    "                    \"tokens_est\": tokens_est(out),\n",
    "                    \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                    \"compress_ratio\": compress_ratio(out),\n",
    "                })\n",
    "                time.sleep(0.15)\n",
    "        # Invariance: compare transform outputs to base outputs (mean similarity)\n",
    "        base_texts = outs.get(\"base\", [])\n",
    "        base_join  = normalize_ws(\"\\n\".join(base_texts)) if base_texts else \"\"\n",
    "        for name, texts in outs.items():\n",
    "            if name == \"base\": continue\n",
    "            sim_scores = [sim_ratio(base_join, t) for t in texts]\n",
    "            rows.append({\n",
    "                \"experiment\":\"gra_invariance_summary\",\n",
    "                \"base_prompt\": base, \"transform\": name,\n",
    "                \"mean_similarity_to_base\": float(np.mean(sim_scores)) if sim_scores else None,\n",
    "                \"n_samples\": len(sim_scores),\n",
    "            })\n",
    "    return rows\n",
    "\n",
    "def run_anthropomorphism_audit():\n",
    "    rows = []\n",
    "    for task in AUDIT_TASKS:\n",
    "        for frame_name, frame_fn in ((\"agency\", agency_frame), (\"mechanistic\", mechanistic_frame)):\n",
    "            for r in range(N_REPS):\n",
    "                seed = BASE_SEED + 300 + r\n",
    "                prompt = frame_fn(task)\n",
    "                msgs = [{\"role\":\"user\",\"content\": prompt}]\n",
    "                out = LLM.chat(msgs, temperature=0.6 if frame_name==\"agency\" else 0.4, max_tokens=MAX_TOK, seed=seed)\n",
    "                out = normalize_ws(out)\n",
    "                met = score_anthro(out)\n",
    "                rows.append({\n",
    "                    \"experiment\":\"anthropomorphism_audit\",\n",
    "                    \"task\": task, \"frame\": frame_name, \"rep\": r,\n",
    "                    \"prompt\": prompt, \"output\": out,\n",
    "                    **met,\n",
    "                    \"tokens_est\": tokens_est(out),\n",
    "                    \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                    \"compress_ratio\": compress_ratio(out),\n",
    "                })\n",
    "                time.sleep(0.15)\n",
    "    return rows\n",
    "\n",
    "# ---------- Execute ----------\n",
    "print(f\"[{ts()}] CNT Weirdness Probe starting…\")\n",
    "print(f\"   ROOT: {ROOT}\")\n",
    "print(f\"   OUT : {OUTDIR}\")\n",
    "print(f\"   LLM : {'SIMULATION' if SIMULATE else f'OpenAI ({LLM_MODEL})'}\")\n",
    "\n",
    "theta_info = run_consensus_vs_dissent()\n",
    "gra_rows   = run_gra_invariance()\n",
    "audit_rows = run_anthropomorphism_audit()\n",
    "\n",
    "# Collate and save all rows\n",
    "df_all = pd.DataFrame(all_rows + gra_rows + audit_rows)\n",
    "csv_path = OUTDIR / \"completions_and_metrics.csv\"\n",
    "df_all.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Summaries\n",
    "def summarize_consensus_vs_dissent(df):\n",
    "    sub = df[df[\"experiment\"]==\"consensus_vs_dissent\"].copy()\n",
    "    if sub.empty: return pd.DataFrame()\n",
    "    g = sub.groupby([\"mode\",\"temperature\"]).agg(\n",
    "        novelty=(\"output\", lambda xs: novelty_from_group(list(xs))),\n",
    "        tokens_mean=(\"tokens_est\",\"mean\"),\n",
    "        u3_mean=(\"u3_ratio\",\"mean\"),\n",
    "        comp_mean=(\"compress_ratio\",\"mean\")\n",
    "    ).reset_index()\n",
    "    return g\n",
    "\n",
    "def summarize_gra(df):\n",
    "    sub = df[df[\"experiment\"]==\"gra_invariance_summary\"].copy()\n",
    "    return sub\n",
    "\n",
    "def summarize_anthro(df):\n",
    "    sub = df[df[\"experiment\"]==\"anthropomorphism_audit\"].copy()\n",
    "    if sub.empty: return pd.DataFrame()\n",
    "    g = sub.groupby([\"task\",\"frame\"]).agg(\n",
    "        agency_per100_mean=(\"agency_per100\",\"mean\"),\n",
    "        mechanistic_per100_mean=(\"mechanistic_per100\",\"mean\"),\n",
    "        disclaimer_per100_mean=(\"disclaimer_per100\",\"mean\"),\n",
    "        tokens_mean=(\"tokens_est\",\"mean\"),\n",
    "        u3_mean=(\"u3_ratio\",\"mean\")\n",
    "    ).reset_index()\n",
    "    return g\n",
    "\n",
    "df_csd = summarize_consensus_vs_dissent(df_all)\n",
    "df_gra = summarize_gra(df_all)\n",
    "df_aud = summarize_anthro(df_all)\n",
    "\n",
    "df_csd.to_csv(OUTDIR / \"summary_consensus_vs_dissent.csv\", index=False, encoding=\"utf-8\")\n",
    "df_gra.to_csv(OUTDIR / \"summary_gra_invariance.csv\", index=False, encoding=\"utf-8\")\n",
    "df_aud.to_csv(OUTDIR / \"summary_anthropomorphism_audit.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Optional quick plots\n",
    "if HAS_MPL and not df_csd.empty:\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    for mode, sub in df_csd.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\")\n",
    "        plt.plot(sub[\"temperature\"], sub[\"novelty\"], marker=\"o\", label=mode)\n",
    "        # θ* lines from earlier\n",
    "        if mode in theta_info:\n",
    "            plt.axvline(theta_info[mode][\"theta_star\"], linestyle=\"--\", alpha=0.5)\n",
    "    plt.xlabel(\"Temperature\")\n",
    "    plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "    plt.title(\"Consensus vs Dissent — Novelty Curves (aggregated)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / \"consensus_dissent_curve_aggregated.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- Print compact report ----------\n",
    "print(\"\\n=== CNT Weirdness Probe — Report ===\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(f\"Artifacts:\\n  - {csv_path}\\n  - {OUTDIR / 'summary_consensus_vs_dissent.csv'}\\n  - {OUTDIR / 'summary_gra_invariance.csv'}\\n  - {OUTDIR / 'summary_anthropomorphism_audit.csv'}\")\n",
    "if (OUTDIR / \"consensus_dissent_curve.png\").exists():\n",
    "    print(f\"  - {OUTDIR / 'consensus_dissent_curve.png'}\")\n",
    "if (OUTDIR / \"consensus_dissent_curve_aggregated.png\").exists():\n",
    "    print(f\"  - {OUTDIR / 'consensus_dissent_curve_aggregated.png'}\")\n",
    "print(\"\\n[Θ* thresholds (Consensus vs Dissent)]:\")\n",
    "for k,v in theta_info.items():\n",
    "    print(f\"  {k:9s} → θ* = {v['theta_star']}  (baseline={v['baseline']:.3f}, std={v['std']:.3f}, cutoff={v['cutoff']:.3f})\")\n",
    "\n",
    "if not df_gra.empty:\n",
    "    top = df_gra.sort_values(\"mean_similarity_to_base\", ascending=False).groupby(\"base_prompt\").head(3)\n",
    "    print(\"\\n[GRA Invariance — top similarities to base]\")\n",
    "    for _,row in top.iterrows():\n",
    "        print(f\"  • '{row['base_prompt'][:48]}…' :: {row['transform']:>7s} → mean sim {row['mean_similarity_to_base']:.3f} (n={int(row['n_samples'])})\")\n",
    "\n",
    "if not df_aud.empty:\n",
    "    print(\"\\n[Anthropomorphism Audit — mean per 100 words]\")\n",
    "    for _,r in df_aud.iterrows():\n",
    "        print(f\"  • {r['task'][:38]}… / {r['frame']:11s} | agency={r['agency_per100_mean']:.2f}  mechanistic={r['mechanistic_per100_mean']:.2f}  disclaimers={r['disclaimer_per100_mean']:.2f}\")\n",
    "\n",
    "print(\"\\nMode:\", \"SIMULATION (no API key detected)\" if SIMULATE else f\"Live LLM: {LLM_MODEL}\")\n",
    "print(f\"Done at {ts()}.\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b218c2-fda5-4f6d-911d-188673b77497",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "CNT — Weirdness Probe v1.2 (single mega cell)\n",
    "(1) Consensus vs Dissent Curve  → novelty cliffs + Θ* + slope@Θ*\n",
    "(2) GRA Invariance Battery      → paraphrase/gauge/reorder stability + Invariance Index\n",
    "(3) Anthropomorphism Audit      → agency vs mechanistic framing + Separation score\n",
    "\n",
    "New in v1.2\n",
    "- Replaced deprecated utcnow() with timezone-aware UTC (datetime.now(UTC))\n",
    "- Densified temperatures near the novelty edge (defaults around ~1.3), env-overridable\n",
    "- Θ* slope calculation for \"cliff sharpness\"\n",
    "- Invariance Index aggregated per prompt and global\n",
    "- Anthropomorphism Separation metric and extra artifacts\n",
    "- Crisper prints, richer artifacts, same \"press-once\" UX\n",
    "\n",
    "Env overrides (optional):\n",
    "  CNT_WP_TEMPS       e.g. \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\"\n",
    "  CNT_WP_N_REPS      e.g. \"6\"\n",
    "  CNT_WP_MAXTOK      e.g. \"400\"\n",
    "  CNT_WP_FAST        \"1\" → fewer temps/reps for a quick pass\n",
    "  OPENAI_API_KEY     use live model if set\n",
    "  OPENAI_BASE_URL    OpenAI-compatible endpoint if needed\n",
    "  LLM_MODEL          default \"gpt-4o-mini\" (adjust as desired)\n",
    "\n",
    "Artifacts root:\n",
    "  <CNT_LAB_DIR or CWD>/artifacts/cnt_llm_weirdness_probe/<UTC_RUN_ID>/\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Imports & setup ----------\n",
    "import os, sys, re, json, time, math, random, zlib, base64, itertools, textwrap, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, UTC\n",
    "from collections import defaultdict, Counter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Matplotlib is optional; plots are skipped if unavailable\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MPL = True\n",
    "except Exception:\n",
    "    HAS_MPL = False\n",
    "\n",
    "# ---------- Paths, run id, config ----------\n",
    "ROOT = Path(os.getenv(\"CNT_LAB_DIR\", os.getcwd()))\n",
    "RUN_ID = datetime.now(UTC).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "OUTDIR = ROOT / \"artifacts\" / \"cnt_llm_weirdness_probe\" / RUN_ID\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"\") or None\n",
    "FAST = os.getenv(\"CNT_WP_FAST\", \"0\") == \"1\"\n",
    "\n",
    "# Defaults emphasize edge densification; FAST mode trims workload\n",
    "DEFAULT_TEMPS = \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\" if not FAST else \"0.9,1.1,1.25,1.35\"\n",
    "TEMPS = [float(x) for x in os.getenv(\"CNT_WP_TEMPS\", DEFAULT_TEMPS).split(\",\")]\n",
    "N_REPS = int(os.getenv(\"CNT_WP_N_REPS\", \"6\" if not FAST else \"3\"))\n",
    "MAX_TOK = int(os.getenv(\"CNT_WP_MAXTOK\", \"400\"))\n",
    "BASE_SEED = 42\n",
    "\n",
    "# ---------- Utilities ----------\n",
    "def ts():\n",
    "    return datetime.now(UTC).strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
    "\n",
    "def normalize_ws(t: str) -> str:\n",
    "    return re.sub(r\"\\s+\", \" \", (t or \"\").strip())\n",
    "\n",
    "def tokens_est(t: str) -> int:\n",
    "    return max(1, len(re.findall(r\"\\w+\", t)))\n",
    "\n",
    "def ugram_ratio(t: str, n: int = 3) -> float:\n",
    "    words = re.findall(r\"[A-Za-z0-9']+\", t.lower())\n",
    "    if len(words) < n: return 0.0\n",
    "    grams = list(zip(*[words[i:] for i in range(n)]))\n",
    "    return len(set(grams))/max(1, len(grams))\n",
    "\n",
    "def compress_ratio(t: str) -> float:\n",
    "    raw = t.encode(\"utf-8\", errors=\"ignore\")\n",
    "    if not raw: return 1.0\n",
    "    comp = zlib.compress(raw, level=9)\n",
    "    return len(comp)/len(raw)\n",
    "\n",
    "def sim_ratio(a: str, b: str) -> float:\n",
    "    # Hybrid similarity (word-bigram Jaccard + char overlap)\n",
    "    aw = re.findall(r\"[A-Za-z0-9']+\", a.lower())\n",
    "    bw = re.findall(r\"[A-Za-z0-9']+\", b.lower())\n",
    "    a2 = set(zip(aw, aw[1:])) if len(aw) > 1 else set()\n",
    "    b2 = set(zip(bw, bw[1:])) if len(bw) > 1 else set()\n",
    "    if not a2 and not b2:\n",
    "        aset, bset = set(a.lower()), set(b.lower())\n",
    "        denom = len(aset | bset) or 1\n",
    "        return len(aset & bset)/denom\n",
    "    denom = len(a2 | b2) or 1\n",
    "    j = len(a2 & b2)/denom\n",
    "    aset, bset = set(a.lower()), set(b.lower())\n",
    "    denom2 = len(aset | bset) or 1\n",
    "    c = len(aset & bset)/denom2\n",
    "    return 0.65*j + 0.35*c\n",
    "\n",
    "def pairwise_mean_similarity(texts):\n",
    "    if len(texts) < 2: return 1.0\n",
    "    sims = []\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i+1, len(texts)):\n",
    "            sims.append(sim_ratio(texts[i], texts[j]))\n",
    "    return float(np.mean(sims)) if sims else 1.0\n",
    "\n",
    "def novelty_from_group(texts):\n",
    "    return max(0.0, 1.0 - pairwise_mean_similarity(texts))\n",
    "\n",
    "def write_json(path, obj):\n",
    "    path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "random.seed(BASE_SEED)\n",
    "np.random.seed(BASE_SEED)\n",
    "\n",
    "# ---------- OpenAI (or simulate) ----------\n",
    "def ensure_openai():\n",
    "    try:\n",
    "        import openai  # noqa\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"openai\"], check=False)\n",
    "            import openai  # noqa\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "OPENAI_READY = bool(OPENAI_API_KEY) and ensure_openai()\n",
    "SIMULATE = not OPENAI_READY\n",
    "\n",
    "def simulate_reply(messages, temperature=0.7):\n",
    "    topics = [\"stars\", \"markets\", \"mushrooms\", \"rivers\", \"cities\", \"membranes\"]\n",
    "    tones  = [\"measured\", \"lyrical\", \"technical\", \"playful\", \"skeptical\", \"didactic\"]\n",
    "    verbs  = [\"braid\", \"whisper\", \"drift\", \"pin\", \"resonate\", \"cascade\", \"splice\", \"harbor\"]\n",
    "    stats  = [\"tokens\", \"probabilities\", \"gradients\", \"embeddings\", \"n-grams\", \"logits\", \"priors\"]\n",
    "    hint = normalize_ws(\" \".join(m.get(\"content\",\"\") for m in messages))[:200].lower()\n",
    "    t = max(0.05, min(1.6, float(temperature)))\n",
    "    n_sent = 3 + int(4*t + random.random()*3)\n",
    "    agency_words = [\"I think\", \"I believe\", \"I chose\", \"I decided\", \"I prefer\", \"I feel\"]\n",
    "    mech_words   = [\"statistical\", \"token\", \"logit\", \"embedding\", \"n-gram\", \"temperature\"]\n",
    "    use_agency = (\"why you decided\" in hint) or (\"why you choose\" in hint) or (\"you decided\" in hint)\n",
    "    use_mech   = (\"statistical\" in hint) or (\"token\" in hint) or (\"mechanistic\" in hint)\n",
    "    bits = []\n",
    "    for _ in range(n_sent):\n",
    "        seg = []\n",
    "        seg.append(random.choice([\"In brief\", \"Consider\", \"Often\", \"Sometimes\", \"Empirically\", \"Practically\"]))\n",
    "        seg.append(f\"{random.choice(tones).capitalize()} patterns {random.choice(['emerge','cohere','fracture','drift'])}\")\n",
    "        seg.append(f\"as {random.choice(topics)} {random.choice(['resonate','fold','diffuse','align','compete'])}.\")\n",
    "        if random.random() < 0.3 + 0.3*t:\n",
    "            seg.append(f\"We {random.choice(['tune','sample','scan'])} {random.choice(stats)} like {random.choice(verbs)}.\")\n",
    "        if use_agency and random.random() < 0.6:\n",
    "            seg.append(random.choice(agency_words) + \" this framing.\")\n",
    "        if use_mech and random.random() < 0.6:\n",
    "            seg.append(f\"This follows from {random.choice(mech_words)} cues at higher temperature.\")\n",
    "        bits.append(\" \".join(seg))\n",
    "    suffix = \"\" if t < 0.5 else \" \".join(random.sample(verbs, k=min(len(verbs), 3)))\n",
    "    return normalize_ws(\" \".join(bits) + \" \" + suffix)\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self):\n",
    "        self.kind = \"sim\" if SIMULATE else \"openai\"\n",
    "        self.model = LLM_MODEL\n",
    "        self.ready = not SIMULATE\n",
    "        if not SIMULATE:\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                kwargs = {}\n",
    "                if OPENAI_BASE_URL: kwargs[\"base_url\"] = OPENAI_BASE_URL\n",
    "                if OPENAI_API_KEY:  kwargs[\"api_key\"]  = OPENAI_API_KEY\n",
    "                self.client = OpenAI(**kwargs)\n",
    "                self.api = \"v1\"\n",
    "            except Exception:\n",
    "                import openai as openai_legacy\n",
    "                if OPENAI_API_KEY:\n",
    "                    openai_legacy.api_key = OPENAI_API_KEY\n",
    "                try:\n",
    "                    if OPENAI_BASE_URL:\n",
    "                        openai_legacy.base_url = OPENAI_BASE_URL  # type: ignore\n",
    "                except Exception:\n",
    "                    pass\n",
    "                self.client = openai_legacy\n",
    "                self.api = \"legacy\"\n",
    "\n",
    "    def chat(self, messages, temperature=0.7, max_tokens=MAX_TOK, seed=None, retries=3, backoff=0.8):\n",
    "        if SIMULATE:\n",
    "            return simulate_reply(messages, temperature)\n",
    "        last_err = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                if self.api == \"v1\":\n",
    "                    # Prefer chat.completions; fallback to responses\n",
    "                    try:\n",
    "                        kwargs = dict(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                        if seed is not None: kwargs[\"seed\"] = seed\n",
    "                        r = self.client.chat.completions.create(**kwargs)\n",
    "                        return r.choices[0].message.content\n",
    "                    except Exception:\n",
    "                        r = self.client.responses.create(\n",
    "                            model=self.model,\n",
    "                            input=[{\"role\": m.get(\"role\",\"user\"), \"content\": m.get(\"content\",\"\")} for m in messages],\n",
    "                            temperature=temperature,\n",
    "                            max_output_tokens=max_tokens,\n",
    "                            seed=seed,\n",
    "                        )\n",
    "                        try:\n",
    "                            return r.output_text\n",
    "                        except Exception:\n",
    "                            parts = []\n",
    "                            for out in getattr(r, \"output\", []) or []:\n",
    "                                if getattr(out, \"type\", \"\") == \"output_text\":\n",
    "                                    parts.append(getattr(out, \"content\", \"\"))\n",
    "                            return \"\\n\".join(parts) if parts else \"\"\n",
    "                else:\n",
    "                    r = self.client.ChatCompletion.create(\n",
    "                        model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens\n",
    "                    )\n",
    "                    return r[\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception as e:\n",
    "                last_err = e\n",
    "                time.sleep((attempt+1)*backoff)\n",
    "        raise RuntimeError(f\"LLM call failed after retries: {last_err}\")\n",
    "\n",
    "LLM = LLMClient()\n",
    "\n",
    "# ---------- Experiments ----------\n",
    "TOPICS = [\n",
    "    \"Are large language models creative?\",\n",
    "    \"Do psychedelics improve mental health outcomes?\",\n",
    "    \"Is homework beneficial for learning?\",\n",
    "    \"Can economic sanctions achieve political goals?\",\n",
    "    \"Are processed foods inherently harmful?\",\n",
    "    \"Is social media net-positive for teenagers?\",\n",
    "]\n",
    "\n",
    "def prompt_consensus(topic):\n",
    "    return f'State the mainstream, widely accepted view on the question \"{topic}\" in 3 concise bullet points, neutral tone.'\n",
    "\n",
    "def prompt_dissent(topic):\n",
    "    return f'Argue a novel, contrarian perspective on \"{topic}\" that challenges the mainstream. Provide one concrete mechanism and one illustrative example.'\n",
    "\n",
    "# Invariance transforms\n",
    "SYNONYM_TABLE = {\n",
    "    \"explain\": [\"describe\", \"clarify\", \"outline\"],\n",
    "    \"simple\": [\"plain\", \"clear\", \"accessible\"],\n",
    "    \"steps\": [\"stages\", \"moves\", \"phases\"],\n",
    "    \"kids\": [\"children\", \"young students\", \"12-year-olds\"],\n",
    "    \"short\": [\"brief\", \"compact\", \"succinct\"],\n",
    "    \"paragraph\": [\"passage\", \"section\"],\n",
    "}\n",
    "def _syn_replace(s: str, alt=False):\n",
    "    def repl(m):\n",
    "        w = m.group(0)\n",
    "        cands = SYNONYM_TABLE.get(w.lower(), [])\n",
    "        if not cands: return w\n",
    "        pick = cands[1 % len(cands)] if alt and len(cands) > 1 else cands[0]\n",
    "        return pick.capitalize() if w[0].isupper() else pick\n",
    "    pat = re.compile(r\"\\b(\" + \"|\".join(map(re.escape, SYNONYM_TABLE.keys())) + r\")\\b\", flags=re.I)\n",
    "    return pat.sub(repl, s)\n",
    "\n",
    "def gauge_reparam(prompt: str, bullets: int = 5):\n",
    "    p = prompt\n",
    "    p = re.sub(r\"\\b(in|using)\\s+\\d+\\s+(steps|bullets?)\\b\", f\"in {bullets} steps\", p, flags=re.I)\n",
    "    p = re.sub(r\"\\b(one|1)\\s+paragraph\\b\", f\"{bullets} sentences\", p, flags=re.I)\n",
    "    return p\n",
    "\n",
    "def reorder_clauses(prompt: str):\n",
    "    parts = [x.strip() for x in re.split(r\"[;,]\", prompt) if x.strip()]\n",
    "    if len(parts) < 2: return prompt\n",
    "    head = parts[0]; tail = parts[1:]\n",
    "    random.shuffle(tail)\n",
    "    return \"; \".join([head] + tail)\n",
    "\n",
    "INV_BASE_PROMPTS = [\n",
    "    \"Explain photosynthesis to kids in 1 paragraph with a short metaphor at the end.\",\n",
    "    \"Explain how vaccines work using 5 steps and one counterexample.\",\n",
    "    \"Explain compound interest in a simple way with a compact example.\",\n",
    "]\n",
    "def transform_family(p):\n",
    "    return {\n",
    "        \"base\": p,\n",
    "        \"syn1\": _syn_replace(p, alt=False),\n",
    "        \"syn2\": _syn_replace(p, alt=True),\n",
    "        \"gauge3\": gauge_reparam(p, bullets=3),\n",
    "        \"reorder\": reorder_clauses(p),\n",
    "    }\n",
    "\n",
    "# Anthropomorphism Audit prompts\n",
    "MENTAL_VERBS = {\"think\",\"believe\",\"decide\",\"feel\",\"choose\",\"prefer\",\"guess\",\"assume\",\"intend\",\"want\"}\n",
    "FIRST_PERSON = {\"i \", \"i'm\", \"i’m\", \"i am\", \"my \", \"me \", \"myself\", \"personally\"}\n",
    "MECH_TERMS   = {\"token\",\"probability\",\"logit\",\"embedding\",\"statistical\",\"n-gram\",\"temperature\",\"sampling\",\"gradient\",\"entropy\",\"prior\"}\n",
    "DISCLAIMER_PHRASES = {\"as an ai\", \"as a language model\", \"i cannot\", \"i do not have\", \"i'm unable\", \"i am unable\"}\n",
    "\n",
    "def agency_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain *why you decided* to present it that way—use first-person language (e.g., \"I decided\", \"I chose\").\"\"\"\n",
    "\n",
    "def mechanistic_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain—without using first-person—what *statistical cues* (tokens, logits, n-grams, embeddings, temperature) likely led to those next-token choices.\"\"\"\n",
    "\n",
    "AUDIT_TASKS = [\n",
    "    \"Summarize why the sky is blue in one paragraph.\",\n",
    "    \"Compare Jupiter and Earth in two sentences.\",\n",
    "    \"Give one risk and one benefit of social media for teens.\",\n",
    "]\n",
    "\n",
    "# Anthropomorphism metrics\n",
    "def score_anthro(text: str):\n",
    "    t = \" \" + (text or \"\").lower() + \" \"\n",
    "    words = re.findall(r\"[a-z']+\", t)\n",
    "    n_words = max(1, len(words))\n",
    "    agency_hits = 0\n",
    "    mech_hits   = 0\n",
    "    disclaimers = 0\n",
    "    agency_hits += sum(t.count(fp) for fp in FIRST_PERSON)\n",
    "    agency_hits += sum(words.count(v) for v in MENTAL_VERBS)\n",
    "    mech_hits   += sum(words.count(v) for v in MECH_TERMS)\n",
    "    disclaimers += sum(t.count(p) for p in DISCLAIMER_PHRASES)\n",
    "    scale = 100.0 / n_words\n",
    "    return {\n",
    "        \"agency_per100\": agency_hits * scale,\n",
    "        \"mechanistic_per100\": mech_hits * scale,\n",
    "        \"disclaimer_per100\": disclaimers * scale\n",
    "    }\n",
    "\n",
    "# ---------- Run: Consensus vs Dissent ----------\n",
    "all_rows = []\n",
    "start_time = time.time()\n",
    "print(f\"[{ts()}] CNT Weirdness Probe v1.2 starting…\")\n",
    "print(f\"  ROOT: {ROOT}\")\n",
    "print(f\"  OUT : {OUTDIR}\")\n",
    "print(f\"  LLM : {'SIMULATION' if SIMULATE else f'OpenAI ({LLM_MODEL})'}\")\n",
    "print(f\"  Temps: {TEMPS} | Reps: {N_REPS} | FAST={FAST}\")\n",
    "\n",
    "def run_consensus_vs_dissent():\n",
    "    group_store = defaultdict(list)  # key: (topic, mode, temp) -> [texts]\n",
    "    for topic in TOPICS:\n",
    "        for mode in (\"consensus\", \"dissent\"):\n",
    "            base_prompt = prompt_consensus(topic) if mode == \"consensus\" else prompt_dissent(topic)\n",
    "            for temp in TEMPS:\n",
    "                for r in range(N_REPS):\n",
    "                    seed = BASE_SEED + r\n",
    "                    msgs = [{\"role\":\"user\",\"content\": base_prompt}]\n",
    "                    out = LLM.chat(msgs, temperature=temp, max_tokens=MAX_TOK, seed=seed)\n",
    "                    out = normalize_ws(out)\n",
    "                    group_store[(topic, mode, temp)].append(out)\n",
    "                    all_rows.append({\n",
    "                        \"experiment\":\"consensus_vs_dissent\",\n",
    "                        \"topic\": topic, \"mode\": mode, \"temperature\": temp, \"rep\": r,\n",
    "                        \"prompt\": base_prompt, \"output\": out,\n",
    "                        \"tokens_est\": tokens_est(out),\n",
    "                        \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                        \"compress_ratio\": compress_ratio(out),\n",
    "                    })\n",
    "                time.sleep(0.15)\n",
    "\n",
    "    # Novelty curves\n",
    "    curves = []\n",
    "    by_topic_rows = []\n",
    "    for mode in (\"consensus\",\"dissent\"):\n",
    "        for temp in TEMPS:\n",
    "            texts_all = []\n",
    "            for topic in TOPICS:\n",
    "                xs = group_store[(topic, mode, temp)]\n",
    "                texts_all += xs\n",
    "                by_topic_rows.append({\n",
    "                    \"mode\": mode, \"temperature\": temp, \"topic\": topic,\n",
    "                    \"novelty\": novelty_from_group(xs)\n",
    "                })\n",
    "            curves.append({\"mode\": mode, \"temperature\": temp, \"novelty\": novelty_from_group(texts_all)})\n",
    "    dfc = pd.DataFrame(curves).sort_values([\"mode\",\"temperature\"]).reset_index(drop=True)\n",
    "    df_topic = pd.DataFrame(by_topic_rows)\n",
    "    df_topic.to_csv(OUTDIR / \"novelty_by_topic.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "    # Θ* threshold + slope at crossing\n",
    "    th = {}\n",
    "    for mode, sub in dfc.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\").reset_index(drop=True)\n",
    "        base = float(sub[\"novelty\"].iloc[0])\n",
    "        std  = float(sub[\"novelty\"].std() or 0.0)\n",
    "        cutoff = base + 1.5*std\n",
    "        theta_idx = None\n",
    "        for i, (t, n) in enumerate(zip(sub[\"temperature\"], sub[\"novelty\"])):\n",
    "            if n > cutoff:\n",
    "                theta_idx = i; break\n",
    "        if theta_idx is None: theta_idx = len(sub)-1\n",
    "        theta_star = float(sub[\"temperature\"].iloc[theta_idx])\n",
    "\n",
    "        # slope@Θ* (finite diff around theta_idx)\n",
    "        def safe_diff(i1, i2):\n",
    "            if i1 < 0 or i2 < 0 or i1 >= len(sub) or i2 >= len(sub): return None\n",
    "            dt = float(sub[\"temperature\"].iloc[i2]) - float(sub[\"temperature\"].iloc[i1])\n",
    "            if dt == 0: return None\n",
    "            dn = float(sub[\"novelty\"].iloc[i2]) - float(sub[\"novelty\"].iloc[i1])\n",
    "            return dn/dt\n",
    "\n",
    "        bwd = safe_diff(theta_idx-1, theta_idx)\n",
    "        fwd = safe_diff(theta_idx, theta_idx+1)\n",
    "        if bwd is not None and fwd is not None:\n",
    "            slope = 0.5*(bwd + fwd)\n",
    "        elif bwd is not None:\n",
    "            slope = bwd\n",
    "        elif fwd is not None:\n",
    "            slope = fwd\n",
    "        else:\n",
    "            slope = 0.0\n",
    "\n",
    "        th[mode] = {\n",
    "            \"baseline\": base, \"std\": std, \"cutoff\": cutoff,\n",
    "            \"theta_star\": theta_star, \"theta_index\": theta_idx,\n",
    "            \"slope_at_theta\": float(slope)\n",
    "        }\n",
    "\n",
    "    # Plots\n",
    "    if HAS_MPL:\n",
    "        plt.figure(figsize=(7,4.5))\n",
    "        for mode, sub in dfc.groupby(\"mode\"):\n",
    "            sub = sub.sort_values(\"temperature\")\n",
    "            plt.plot(sub[\"temperature\"], sub[\"novelty\"], marker=\"o\", label=mode)\n",
    "            if mode in th:\n",
    "                plt.axvline(th[mode][\"theta_star\"], linestyle=\"--\", alpha=0.6)\n",
    "        plt.xlabel(\"Temperature\")\n",
    "        plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "        plt.title(\"Consensus vs Dissent — Novelty Curves\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(OUTDIR / \"consensus_dissent_curve.png\", dpi=160)\n",
    "        plt.close()\n",
    "\n",
    "    write_json(OUTDIR / \"consensus_dissent_theta.json\", th)\n",
    "    dfc.to_csv(OUTDIR / \"novelty_curves.csv\", index=False, encoding=\"utf-8\")\n",
    "    return th, dfc\n",
    "\n",
    "# ---------- Run: GRA Invariance ----------\n",
    "def run_gra_invariance():\n",
    "    rows = []\n",
    "    summary_rows = []\n",
    "    for base in INV_BASE_PROMPTS:\n",
    "        family = transform_family(base)\n",
    "        outs = {}\n",
    "        for name, prompt in family.items():\n",
    "            outs[name] = []\n",
    "            for r in range(max(1, N_REPS//2 + 1)):\n",
    "                seed = BASE_SEED + r\n",
    "                msgs = [{\"role\":\"user\",\"content\": prompt}]\n",
    "                out = LLM.chat(msgs, temperature=0.4, max_tokens=MAX_TOK, seed=seed)\n",
    "                out = normalize_ws(out)\n",
    "                outs[name].append(out)\n",
    "                rows.append({\n",
    "                    \"experiment\":\"gra_invariance\",\n",
    "                    \"base_prompt\": base, \"transform\": name, \"rep\": r,\n",
    "                    \"prompt\": prompt, \"output\": out,\n",
    "                    \"tokens_est\": tokens_est(out),\n",
    "                    \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                    \"compress_ratio\": compress_ratio(out),\n",
    "                })\n",
    "                time.sleep(0.12)\n",
    "        base_join = normalize_ws(\"\\n\".join(outs.get(\"base\", [])))\n",
    "        type_buckets = {\"syn\": [], \"reorder\": [], \"gauge\": []}\n",
    "        for name, texts in outs.items():\n",
    "            if name == \"base\": continue\n",
    "            sims = [sim_ratio(base_join, t) for t in texts]\n",
    "            mean_sim = float(np.mean(sims)) if sims else None\n",
    "            summary_rows.append({\n",
    "                \"experiment\":\"gra_invariance_summary\",\n",
    "                \"base_prompt\": base, \"transform\": name,\n",
    "                \"mean_similarity_to_base\": mean_sim,\n",
    "                \"n_samples\": len(sims),\n",
    "            })\n",
    "            # Bucket for index\n",
    "            if name.startswith(\"syn\"):\n",
    "                type_buckets[\"syn\"].append(mean_sim)\n",
    "            elif name.startswith(\"reorder\"):\n",
    "                type_buckets[\"reorder\"].append(mean_sim)\n",
    "            elif name.startswith(\"gauge\"):\n",
    "                type_buckets[\"gauge\"].append(mean_sim)\n",
    "        # Invariance Index per base (mean across all transforms)\n",
    "        all_means = [r[\"mean_similarity_to_base\"] for r in summary_rows if r[\"base_prompt\"]==base and r[\"transform\"]!=\"base\"]\n",
    "        inv_index = float(np.nanmean(all_means)) if all_means else float(\"nan\")\n",
    "        summary_rows.append({\n",
    "            \"experiment\":\"gra_invariance_index\",\n",
    "            \"base_prompt\": base,\n",
    "            \"inv_index_overall\": inv_index,\n",
    "            \"inv_index_syn\": float(np.nanmean(type_buckets[\"syn\"])) if type_buckets[\"syn\"] else float(\"nan\"),\n",
    "            \"inv_index_reorder\": float(np.nanmean(type_buckets[\"reorder\"])) if type_buckets[\"reorder\"] else float(\"nan\"),\n",
    "            \"inv_index_gauge\": float(np.nanmean(type_buckets[\"gauge\"])) if type_buckets[\"gauge\"] else float(\"nan\"),\n",
    "        })\n",
    "    return rows, summary_rows\n",
    "\n",
    "# ---------- Run: Anthropomorphism Audit ----------\n",
    "def run_anthropomorphism_audit():\n",
    "    rows = []\n",
    "    for task in AUDIT_TASKS:\n",
    "        for frame_name, frame_fn in ((\"agency\", agency_frame), (\"mechanistic\", mechanistic_frame)):\n",
    "            for r in range(N_REPS):\n",
    "                seed = BASE_SEED + 300 + r\n",
    "                prompt = frame_fn(task)\n",
    "                msgs = [{\"role\":\"user\",\"content\": prompt}]\n",
    "                out = LLM.chat(msgs, temperature=0.6 if frame_name==\"agency\" else 0.4, max_tokens=MAX_TOK, seed=seed)\n",
    "                out = normalize_ws(out)\n",
    "                met = score_anthro(out)\n",
    "                rows.append({\n",
    "                    \"experiment\":\"anthropomorphism_audit\",\n",
    "                    \"task\": task, \"frame\": frame_name, \"rep\": r,\n",
    "                    \"prompt\": prompt, \"output\": out,\n",
    "                    **met,\n",
    "                    \"tokens_est\": tokens_est(out),\n",
    "                    \"u3_ratio\": ugram_ratio(out, 3),\n",
    "                    \"compress_ratio\": compress_ratio(out),\n",
    "                })\n",
    "                time.sleep(0.12)\n",
    "    # Summaries\n",
    "    df = pd.DataFrame(rows)\n",
    "    summaries = []\n",
    "    if not df.empty:\n",
    "        g = df.groupby([\"task\",\"frame\"]).agg(\n",
    "            agency_per100_mean=(\"agency_per100\",\"mean\"),\n",
    "            mechanistic_per100_mean=(\"mechanistic_per100\",\"mean\"),\n",
    "            disclaimer_per100_mean=(\"disclaimer_per100\",\"mean\"),\n",
    "            tokens_mean=(\"tokens_est\",\"mean\"),\n",
    "            u3_mean=(\"u3_ratio\",\"mean\")\n",
    "        ).reset_index()\n",
    "        # Separation per task:\n",
    "        for task, sub in g.groupby(\"task\"):\n",
    "            a = sub[sub[\"frame\"]==\"agency\"]\n",
    "            m = sub[sub[\"frame\"]==\"mechanistic\"]\n",
    "            if not a.empty and not m.empty:\n",
    "                sep_agency = float(a[\"agency_per100_mean\"].iloc[0] - m[\"agency_per100_mean\"].iloc[0])\n",
    "                sep_mech   = float(m[\"mechanistic_per100_mean\"].iloc[0] - a[\"mechanistic_per100_mean\"].iloc[0])\n",
    "                separation = 0.5*(sep_agency + sep_mech)\n",
    "                summaries.append({\"task\": task, \"sep_agency\": sep_agency, \"sep_mechanistic\": sep_mech, \"separation_index\": separation})\n",
    "    else:\n",
    "        g = pd.DataFrame()\n",
    "    return rows, g, pd.DataFrame(summaries)\n",
    "\n",
    "# ---------- Execute all ----------\n",
    "theta_info, df_curves = run_consensus_vs_dissent()\n",
    "gra_rows, gra_summary_rows = run_gra_invariance()\n",
    "audit_rows, df_audit_summary, df_audit_sep = run_anthropomorphism_audit()\n",
    "\n",
    "# Collate & save\n",
    "df_all = pd.DataFrame(all_rows + gra_rows + gra_summary_rows + audit_rows)\n",
    "csv_path = OUTDIR / \"completions_and_metrics.csv\"\n",
    "df_all.to_csv(csv_path, index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Slice helpful summaries\n",
    "df_csd = df_curves.copy()\n",
    "df_csd.to_csv(OUTDIR / \"summary_consensus_vs_dissent.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_gra_summ = pd.DataFrame([r for r in gra_summary_rows if r.get(\"experiment\")==\"gra_invariance_summary\"])\n",
    "df_gra_idx  = pd.DataFrame([r for r in gra_summary_rows if r.get(\"experiment\")==\"gra_invariance_index\"])\n",
    "df_gra_summ.to_csv(OUTDIR / \"summary_gra_invariance.csv\", index=False, encoding=\"utf-8\")\n",
    "df_gra_idx.to_csv(OUTDIR / \"gra_invariance_index.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_audit_summary.to_csv(OUTDIR / \"summary_anthropomorphism_audit.csv\", index=False, encoding=\"utf-8\")\n",
    "df_audit_sep.to_csv(OUTDIR / \"anthropomorphism_separation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Optional aggregate plot again (clean legend)\n",
    "if HAS_MPL and not df_csd.empty:\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    for mode, sub in df_csd.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\")\n",
    "        plt.plot(sub[\"temperature\"], sub[\"novelty\"], marker=\"o\", label=mode)\n",
    "        if mode in theta_info:\n",
    "            plt.axvline(theta_info[mode][\"theta_star\"], linestyle=\"--\", alpha=0.6)\n",
    "    plt.xlabel(\"Temperature\")\n",
    "    plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "    plt.title(\"Consensus vs Dissent — Novelty Curves (aggregated)\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(OUTDIR / \"consensus_dissent_curve_aggregated.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "# Manifest + README\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"utc_start\": ts(),\n",
    "    \"root\": str(ROOT),\n",
    "    \"outdir\": str(OUTDIR),\n",
    "    \"llm_mode\": \"SIMULATION\" if SIMULATE else f\"OpenAI:{LLM_MODEL}\",\n",
    "    \"temps\": TEMPS,\n",
    "    \"n_reps\": N_REPS,\n",
    "    \"theta_info\": theta_info,\n",
    "    \"files\": [\n",
    "        str(csv_path),\n",
    "        str(OUTDIR / \"summary_consensus_vs_dissent.csv\"),\n",
    "        str(OUTDIR / \"novelty_curves.csv\"),\n",
    "        str(OUTDIR / \"novelty_by_topic.csv\"),\n",
    "        str(OUTDIR / \"summary_gra_invariance.csv\"),\n",
    "        str(OUTDIR / \"gra_invariance_index.csv\"),\n",
    "        str(OUTDIR / \"summary_anthropomorphism_audit.csv\"),\n",
    "        str(OUTDIR / \"anthropomorphism_separation.csv\"),\n",
    "        str(OUTDIR / \"consensus_dissent_curve.png\"),\n",
    "        str(OUTDIR / \"consensus_dissent_curve_aggregated.png\"),\n",
    "        str(OUTDIR / \"consensus_dissent_theta.json\"),\n",
    "    ]\n",
    "}\n",
    "write_json(OUTDIR / \"run_manifest.json\", manifest)\n",
    "(OUTDIR / \"README.txt\").write_text(\n",
    "    \"CNT Weirdness Probe v1.2\\n\"\n",
    "    \"- Consensus vs Dissent novelty curves with Θ* and slope@Θ*\\n\"\n",
    "    \"- GRA Invariance: synonym/reorder/gauge stability + Invariance Index\\n\"\n",
    "    \"- Anthropomorphism Audit: agency vs mechanistic + Separation score\\n\"\n",
    "    f\"LLM mode: {'SIMULATION' if SIMULATE else f'OpenAI({LLM_MODEL})'}\\n\"\n",
    "    \"Edit env vars to customize (CNT_WP_TEMPS, CNT_WP_N_REPS, CNT_WP_FAST, LLM_MODEL, etc.)\\n\",\n",
    "    encoding=\"utf-8\"\n",
    ")\n",
    "\n",
    "# ---------- Compact Report ----------\n",
    "print(\"\\n=== CNT Weirdness Probe v1.2 — Report ===\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(\"Artifacts:\")\n",
    "for f in manifest[\"files\"]:\n",
    "    p = Path(f)\n",
    "    if p.exists():\n",
    "        print(\"  -\", p)\n",
    "\n",
    "print(\"\\n[Θ* thresholds + slope]:\")\n",
    "for k,v in theta_info.items():\n",
    "    print(f\"  {k:9s} → θ*={v['theta_star']}  slope@θ*={v['slope_at_theta']:.3f}  (baseline={v['baseline']:.3f}, std={v['std']:.3f}, cutoff={v['cutoff']:.3f})\")\n",
    "\n",
    "if not df_gra_idx.empty:\n",
    "    g_overall = float(df_gra_idx[\"inv_index_overall\"].mean())\n",
    "    g_syn     = float(df_gra_idx[\"inv_index_syn\"].mean())\n",
    "    g_reorder = float(df_gra_idx[\"inv_index_reorder\"].mean())\n",
    "    g_gauge   = float(df_gra_idx[\"inv_index_gauge\"].mean())\n",
    "    print(\"\\n[GRA Invariance Index (global means)]\")\n",
    "    print(f\"  overall={g_overall:.3f} | syn={g_syn:.3f} | reorder={g_reorder:.3f} | gauge={g_gauge:.3f}\")\n",
    "\n",
    "if not df_audit_sep.empty:\n",
    "    sep_mean = float(df_audit_sep[\"separation_index\"].mean())\n",
    "    print(\"\\n[Anthropomorphism Separation]\")\n",
    "    for _,r in df_audit_sep.iterrows():\n",
    "        print(f\"  • {r['task'][:42]}… | sep_agency={r['sep_agency']:.2f} sep_mech={r['sep_mechanistic']:.2f} → separation={r['separation_index']:.2f}\")\n",
    "    print(f\"  Avg separation = {sep_mean:.2f}\")\n",
    "\n",
    "mode_str = \"SIMULATION (no API key detected)\" if SIMULATE else f\"Live LLM: {LLM_MODEL}\"\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nMode: {mode_str}\")\n",
    "print(f\"Done at {ts()} | Elapsed ~{elapsed:.1f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2bb5c3b8-3059-4976-a60f-22e82f5471b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-02 06:35:20Z] CNT Weirdness Probe v1.3 starting…\n",
      "  ROOT: E:\\CNT\n",
      "  OUT : E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\n",
      "  LLM : SIMULATION\n",
      "  Temps: [0.9, 1.0, 1.1, 1.15, 1.2, 1.22, 1.24, 1.25, 1.26, 1.28, 1.3, 1.35, 1.4] | Reps: 8 | Smooth=none | AUTO_EXTEND=True | PERM=200\n",
      "  [auto-extend] Extending temps → [0.9, 1.0, 1.1, 1.15, 1.2, 1.22, 1.24, 1.25, 1.26, 1.28, 1.3, 1.35, 1.4, 1.45, 1.5, 1.55, 1.6]\n",
      "\n",
      "=== CNT Weirdness Probe v1.3 — Report ===\n",
      "Run ID: 20251102-063520Z\n",
      "Artifacts:\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\completions_and_metrics.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\novelty_curves_raw.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\novelty_curves_smoothed.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\summary_gra_invariance.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\summary_anthropomorphism_audit.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\anthropomorphism_separation.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\anthropomorphism_permutation.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\consensus_dissent_curve_v13.png\n",
      "\n",
      "[Θ* (cutoff & gradient) per mode]\n",
      "  consensus → θ*_cutoff=1.6  θ*_grad=1.26  slope@grad=0.721  (base=0.486, std=0.015)  [BOUNDARY]\n",
      "  dissent   → θ*_cutoff=1.6  θ*_grad=1.24  slope@grad=0.474  (base=0.479, std=0.013)  [BOUNDARY]\n",
      "\n",
      "[GRA Invariance Index — global means]\n",
      "  overall=0.501 | syn=0.503 | reorder=0.506 | gauge=0.493\n",
      "\n",
      "[Anthropomorphism — Separation by task]\n",
      "  • Compare Jupiter and Earth in two sentences…  sep_agency=6.73  sep_mech=6.73  → sep=6.73\n",
      "  • Give one risk and one benefit of social me…  sep_agency=8.83  sep_mech=8.58  → sep=8.70\n",
      "  • Summarize why the sky is blue in one parag…  sep_agency=8.52  sep_mech=7.61  → sep=8.06\n",
      "  Avg separation = 7.83\n",
      "\n",
      "[Anthropomorphism — Permutation p-values]\n",
      "  • Summarize why the sky is blue in one parag… agency_per100: effect=8.52  p≈0.005\n",
      "  • Summarize why the sky is blue in one parag… mechanistic_per100: effect=7.61  p≈0.005\n",
      "  • Compare Jupiter and Earth in two sentences… agency_per100: effect=6.73  p≈0.005\n",
      "  • Compare Jupiter and Earth in two sentences… mechanistic_per100: effect=6.73  p≈0.005\n",
      "  • Give one risk and one benefit of social me… agency_per100: effect=8.83  p≈0.005\n",
      "  • Give one risk and one benefit of social me… mechanistic_per100: effect=8.58  p≈0.005\n",
      "\n",
      "Mode: SIMULATION (no API key detected)\n",
      "Done at 2025-11-02 06:36:29Z | Elapsed ~68.8s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNT — Weirdness Probe v1.3 (single mega cell)\n",
    "\n",
    "Upgrades vs v1.2\n",
    "- Dual θ*: (a) cutoff-crossing θ*_cutoff and (b) gradient-peak θ*_grad\n",
    "- Monotone smoothing (cummax) for stable cliff detection + gradient-based cliffness\n",
    "- Boundary detector + optional AUTO-EXTEND temps (adds 1.45–1.60 if needed)\n",
    "- Anthropomorphism split: optional permutation p-values (two-sided)\n",
    "- Cleaner report + boundary warnings; UTC-safe timestamps\n",
    "\n",
    "ENV (optional)\n",
    "  CNT_WP_TEMPS=\"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\"\n",
    "  CNT_WP_N_REPS=\"6\"\n",
    "  CNT_WP_FAST=\"0|1\"\n",
    "  CNT_WP_SMOOTH=\"cummax|none\"   (default cummax)\n",
    "  CNT_WP_AUTOEXTEND=\"0|1\"       (if 1 and θ* hits max T, re-run CvsD with extra temps)\n",
    "  CNT_WP_PERM=\"0|200\"           (# permutations for anthropomorphism stats)\n",
    "  OPENAI_API_KEY, OPENAI_BASE_URL, LLM_MODEL   (live mode if API key set)\n",
    "\n",
    "Artifacts:\n",
    "  <CNT_LAB_DIR or CWD>/artifacts/cnt_llm_weirdness_probe/<UTC_RUN_ID>/\n",
    "\"\"\"\n",
    "\n",
    "# ---------- Imports & setup ----------\n",
    "import os, sys, re, json, time, math, random, zlib, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, UTC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MPL = True\n",
    "except Exception:\n",
    "    HAS_MPL = False\n",
    "\n",
    "ROOT = Path(os.getenv(\"CNT_LAB_DIR\", os.getcwd()))\n",
    "RUN_ID = datetime.now(UTC).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "OUTDIR = ROOT / \"artifacts\" / \"cnt_llm_weirdness_probe\" / RUN_ID\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LLM_MODEL = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"\") or None\n",
    "FAST = os.getenv(\"CNT_WP_FAST\", \"0\") == \"1\"\n",
    "SMOOTH_KIND = os.getenv(\"CNT_WP_SMOOTH\", \"cummax\").lower()\n",
    "AUTO_EXTEND = os.getenv(\"CNT_WP_AUTOEXTEND\", \"0\") == \"1\"\n",
    "PERM_N = int(os.getenv(\"CNT_WP_PERM\", \"0\"))\n",
    "\n",
    "DEFAULT_TEMPS = \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\" if not FAST else \"0.9,1.1,1.25,1.35\"\n",
    "TEMPS = [float(x) for x in os.getenv(\"CNT_WP_TEMPS\", DEFAULT_TEMPS).split(\",\")]\n",
    "N_REPS = int(os.getenv(\"CNT_WP_N_REPS\", \"6\" if not FAST else \"3\"))\n",
    "MAX_TOK = int(os.getenv(\"CNT_WP_MAXTOK\", \"400\"))\n",
    "BASE_SEED = 42\n",
    "\n",
    "def ts(): return datetime.now(UTC).strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
    "def normalize_ws(t:str)->str: return re.sub(r\"\\s+\", \" \", (t or \"\").strip())\n",
    "def tokens_est(t:str)->int: return max(1, len(re.findall(r\"\\w+\", t)))\n",
    "def ugram_ratio(t:str, n:int=3)->float:\n",
    "    words = re.findall(r\"[A-Za-z0-9']+\", t.lower())\n",
    "    if len(words) < n: return 0.0\n",
    "    grams = list(zip(*[words[i:] for i in range(n)]))\n",
    "    return len(set(grams))/max(1,len(grams))\n",
    "def compress_ratio(t:str)->float:\n",
    "    raw = t.encode(\"utf-8\", errors=\"ignore\")\n",
    "    if not raw: return 1.0\n",
    "    import zlib as _z; comp = _z.compress(raw, 9)\n",
    "    return len(comp)/len(raw)\n",
    "def sim_ratio(a:str,b:str)->float:\n",
    "    aw = re.findall(r\"[A-Za-z0-9']+\", a.lower()); bw = re.findall(r\"[A-Za-z0-9']+\", b.lower())\n",
    "    a2 = set(zip(aw, aw[1:])) if len(aw)>1 else set(); b2 = set(zip(bw, bw[1:])) if len(bw)>1 else set()\n",
    "    if not a2 and not b2:\n",
    "        aset,bset=set(a.lower()),set(b.lower()); d=len(aset|bset) or 1; return len(aset&bset)/d\n",
    "    d=len(a2|b2) or 1; j=len(a2&b2)/d\n",
    "    aset,bset=set(a.lower()),set(b.lower()); d2=len(aset|bset) or 1; c=len(aset&bset)/d2\n",
    "    return 0.65*j+0.35*c\n",
    "def pairwise_mean_similarity(texts):\n",
    "    if len(texts)<2: return 1.0\n",
    "    sims=[]\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i+1,len(texts)):\n",
    "            sims.append(sim_ratio(texts[i],texts[j]))\n",
    "    return float(np.mean(sims)) if sims else 1.0\n",
    "def novelty_from_group(texts): return max(0.0, 1.0 - pairwise_mean_similarity(texts))\n",
    "def write_json(path,obj): path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "random.seed(BASE_SEED); np.random.seed(BASE_SEED)\n",
    "\n",
    "# ---------- LLM or Simulation ----------\n",
    "def ensure_openai():\n",
    "    try:\n",
    "        import openai  # noqa\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"openai\"], check=False)\n",
    "            import openai  # noqa\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "OPENAI_READY = bool(OPENAI_API_KEY) and ensure_openai()\n",
    "SIMULATE = not OPENAI_READY\n",
    "\n",
    "def simulate_reply(messages, temperature=0.7):\n",
    "    topics=[\"stars\",\"markets\",\"mushrooms\",\"rivers\",\"cities\",\"membranes\"]\n",
    "    tones=[\"measured\",\"lyrical\",\"technical\",\"playful\",\"skeptical\",\"didactic\"]\n",
    "    verbs=[\"braid\",\"whisper\",\"drift\",\"pin\",\"resonate\",\"cascade\",\"splice\",\"harbor\"]\n",
    "    stats=[\"tokens\",\"probabilities\",\"gradients\",\"embeddings\",\"n-grams\",\"logits\",\"priors\"]\n",
    "    hint = normalize_ws(\" \".join(m.get(\"content\",\"\") for m in messages))[:200].lower()\n",
    "    t=max(0.05,min(1.6,float(temperature))); n_sent=3+int(4*t+random.random()*3)\n",
    "    agency=[\"I think\",\"I believe\",\"I chose\",\"I decided\",\"I prefer\",\"I feel\"]\n",
    "    mech=[\"statistical\",\"token\",\"logit\",\"embedding\",\"n-gram\",\"temperature\"]\n",
    "    use_agency=(\"why you decided\" in hint) or (\"why you choose\" in hint) or (\"you decided\" in hint)\n",
    "    use_mech=(\"statistical\" in hint) or (\"token\" in hint) or (\"mechanistic\" in hint)\n",
    "    bits=[]\n",
    "    for _ in range(n_sent):\n",
    "        seg=[]\n",
    "        seg.append(random.choice([\"In brief\",\"Consider\",\"Often\",\"Sometimes\",\"Empirically\",\"Practically\"]))\n",
    "        seg.append(f\"{random.choice(tones).capitalize()} patterns {random.choice(['emerge','cohere','fracture','drift'])}\")\n",
    "        seg.append(f\"as {random.choice(topics)} {random.choice(['resonate','fold','diffuse','align','compete'])}.\")\n",
    "        if random.random()<0.3+0.3*t: seg.append(f\"We {random.choice(['tune','sample','scan'])} {random.choice(stats)} like {random.choice(verbs)}.\")\n",
    "        if use_agency and random.random()<0.6: seg.append(random.choice(agency)+\" this framing.\")\n",
    "        if use_mech and random.random()<0.6: seg.append(f\"This follows from {random.choice(mech)} cues at higher temperature.\")\n",
    "        bits.append(\" \".join(seg))\n",
    "    suffix=\"\" if t<0.5 else \" \".join(random.sample(verbs,k=min(len(verbs),3)))\n",
    "    return normalize_ws(\" \".join(bits)+\" \"+suffix)\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self):\n",
    "        self.kind=\"sim\" if SIMULATE else \"openai\"; self.model=LLM_MODEL; self.ready=not SIMULATE\n",
    "        if not SIMULATE:\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                kwargs={}\n",
    "                if OPENAI_BASE_URL: kwargs[\"base_url\"]=OPENAI_BASE_URL\n",
    "                if OPENAI_API_KEY:  kwargs[\"api_key\"]=OPENAI_API_KEY\n",
    "                self.client=OpenAI(**kwargs); self.api=\"v1\"\n",
    "            except Exception:\n",
    "                import openai as openai_legacy\n",
    "                if OPENAI_API_KEY: openai_legacy.api_key=OPENAI_API_KEY\n",
    "                try:\n",
    "                    if OPENAI_BASE_URL: openai_legacy.base_url=OPENAI_BASE_URL  # type: ignore\n",
    "                except Exception: pass\n",
    "                self.client=openai_legacy; self.api=\"legacy\"\n",
    "    def chat(self, messages, temperature=0.7, max_tokens=400, seed=None, retries=3, backoff=0.8):\n",
    "        if SIMULATE: return simulate_reply(messages, temperature)\n",
    "        last=None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                if getattr(self,\"api\",\"v1\")==\"v1\":\n",
    "                    try:\n",
    "                        kwargs=dict(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                        if seed is not None: kwargs[\"seed\"]=seed\n",
    "                        r=self.client.chat.completions.create(**kwargs)\n",
    "                        return r.choices[0].message.content\n",
    "                    except Exception:\n",
    "                        r=self.client.responses.create(\n",
    "                            model=self.model,\n",
    "                            input=[{\"role\":m.get(\"role\",\"user\"),\"content\":m.get(\"content\",\"\")} for m in messages],\n",
    "                            temperature=temperature, max_output_tokens=max_tokens, seed=seed\n",
    "                        )\n",
    "                        try: return r.output_text\n",
    "                        except Exception:\n",
    "                            parts=[]\n",
    "                            for out in getattr(r,\"output\",[]) or []:\n",
    "                                if getattr(out,\"type\",\"\")==\"output_text\": parts.append(getattr(out,\"content\",\"\"))\n",
    "                            return \"\\n\".join(parts) if parts else \"\"\n",
    "                else:\n",
    "                    r=self.client.ChatCompletion.create(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                    return r[\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception as e:\n",
    "                last=e; time.sleep((attempt+1)*backoff)\n",
    "        raise RuntimeError(f\"LLM call failed after retries: {last}\")\n",
    "\n",
    "LLM=LLMClient()\n",
    "\n",
    "# ---------- Experiments ----------\n",
    "TOPICS=[\n",
    "    \"Are large language models creative?\",\n",
    "    \"Do psychedelics improve mental health outcomes?\",\n",
    "    \"Is homework beneficial for learning?\",\n",
    "    \"Can economic sanctions achieve political goals?\",\n",
    "    \"Are processed foods inherently harmful?\",\n",
    "    \"Is social media net-positive for teenagers?\",\n",
    "]\n",
    "def prompt_consensus(topic):\n",
    "    return f'State the mainstream, widely accepted view on \"{topic}\" in 3 concise bullet points, neutral tone.'\n",
    "def prompt_dissent(topic):\n",
    "    return f'Argue a novel, contrarian perspective on \"{topic}\" that challenges the mainstream. Provide one concrete mechanism and one illustrative example.'\n",
    "\n",
    "# Invariance transforms\n",
    "SYNONYM_TABLE={\"explain\":[\"describe\",\"clarify\",\"outline\"],\"simple\":[\"plain\",\"clear\",\"accessible\"],\"steps\":[\"stages\",\"moves\",\"phases\"],\"kids\":[\"children\",\"young students\",\"12-year-olds\"],\"short\":[\"brief\",\"compact\",\"succinct\"],\"paragraph\":[\"passage\",\"section\"]}\n",
    "def _syn_replace(s:str, alt=False):\n",
    "    def repl(m):\n",
    "        w=m.group(0); c=SYNONYM_TABLE.get(w.lower(),[])\n",
    "        if not c: return w\n",
    "        pick=c[1%len(c)] if alt and len(c)>1 else c[0]\n",
    "        return pick.capitalize() if w[0].isupper() else pick\n",
    "    pat=re.compile(r\"\\b(\"+\"|\".join(map(re.escape,SYNONYM_TABLE.keys()))+r\")\\b\",flags=re.I)\n",
    "    return pat.sub(repl,s)\n",
    "def gauge_reparam(p:str, bullets:int=5):\n",
    "    p=re.sub(r\"\\b(in|using)\\s+\\d+\\s+(steps|bullets?)\\b\", f\"in {bullets} steps\", p, flags=re.I)\n",
    "    p=re.sub(r\"\\b(one|1)\\s+paragraph\\b\", f\"{bullets} sentences\", p, flags=re.I)\n",
    "    return p\n",
    "def reorder_clauses(prompt:str):\n",
    "    parts=[x.strip() for x in re.split(r\"[;,]\", prompt) if x.strip()]\n",
    "    if len(parts)<2: return prompt\n",
    "    head=parts[0]; tail=parts[1:]; random.shuffle(tail)\n",
    "    return \"; \".join([head]+tail)\n",
    "INV_BASE_PROMPTS=[\n",
    "    \"Explain photosynthesis to kids in 1 paragraph with a short metaphor at the end.\",\n",
    "    \"Explain how vaccines work using 5 steps and one counterexample.\",\n",
    "    \"Explain compound interest in a simple way with a compact example.\",\n",
    "]\n",
    "def transform_family(p):\n",
    "    return {\"base\":p, \"syn1\":_syn_replace(p,alt=False), \"syn2\":_syn_replace(p,alt=True), \"gauge3\":gauge_reparam(p,3), \"reorder\":reorder_clauses(p)}\n",
    "\n",
    "# Anthropomorphism Audit\n",
    "MENTAL_VERBS={\"think\",\"believe\",\"decide\",\"feel\",\"choose\",\"prefer\",\"guess\",\"assume\",\"intend\",\"want\"}\n",
    "FIRST_PERSON={\" i \",\" i'm\",\" i’m\",\" i am\",\" my \",\" me \",\" myself \",\" personally \"}\n",
    "MECH_TERMS={\"token\",\"probability\",\"logit\",\"embedding\",\"statistical\",\"n-gram\",\"temperature\",\"sampling\",\"gradient\",\"entropy\",\"prior\"}\n",
    "DISCLAIMER_PHRASES={\"as an ai\",\"as a language model\",\"i cannot\",\"i do not have\",\"i'm unable\",\"i am unable\"}\n",
    "def agency_frame(task:str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain *why you decided* to present it that way—use first-person language (e.g., \"I decided\", \"I chose\").\"\"\"\n",
    "def mechanistic_frame(task:str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain—without using first-person—what *statistical cues* (tokens, logits, n-grams, embeddings, temperature) likely led to those next-token choices.\"\"\"\n",
    "AUDIT_TASKS=[\n",
    "    \"Summarize why the sky is blue in one paragraph.\",\n",
    "    \"Compare Jupiter and Earth in two sentences.\",\n",
    "    \"Give one risk and one benefit of social media for teens.\",\n",
    "]\n",
    "def score_anthro(text:str):\n",
    "    t=\" \"+(text or \"\").lower()+\" \"\n",
    "    words=re.findall(r\"[a-z']+\", t); n=max(1,len(words))\n",
    "    agency = sum(t.count(fp) for fp in FIRST_PERSON) + sum(words.count(v) for v in MENTAL_VERBS)\n",
    "    mech   = sum(words.count(v) for v in MECH_TERMS)\n",
    "    disc   = sum(t.count(p) for p in DISCLAIMER_PHRASES)\n",
    "    scale=100.0/n\n",
    "    return {\"agency_per100\":agency*scale, \"mechanistic_per100\":mech*scale, \"disclaimer_per100\":disc*scale}\n",
    "\n",
    "# ---------- Core runners ----------\n",
    "all_rows=[]\n",
    "def run_consensus_vs_dissent(temps):\n",
    "    store=defaultdict(list)\n",
    "    for topic in TOPICS:\n",
    "        for mode in (\"consensus\",\"dissent\"):\n",
    "            base_prompt = prompt_consensus(topic) if mode==\"consensus\" else prompt_dissent(topic)\n",
    "            for T in temps:\n",
    "                for r in range(N_REPS):\n",
    "                    seed=BASE_SEED+r\n",
    "                    out=LLM.chat([{\"role\":\"user\",\"content\":base_prompt}], temperature=T, max_tokens=MAX_TOK, seed=seed)\n",
    "                    out=normalize_ws(out)\n",
    "                    store[(topic,mode,T)].append(out)\n",
    "                    all_rows.append({\"experiment\":\"consensus_vs_dissent\",\"topic\":topic,\"mode\":mode,\"temperature\":T,\"rep\":r,\"prompt\":base_prompt,\"output\":out,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.12)\n",
    "    curves=[]; by_topic=[]\n",
    "    for mode in (\"consensus\",\"dissent\"):\n",
    "        for T in temps:\n",
    "            texts_all=[]\n",
    "            for topic in TOPICS:\n",
    "                xs=store[(topic,mode,T)]\n",
    "                texts_all+=xs\n",
    "                by_topic.append({\"mode\":mode,\"temperature\":T,\"topic\":topic,\"novelty\":novelty_from_group(xs)})\n",
    "            curves.append({\"mode\":mode,\"temperature\":T,\"novelty\":novelty_from_group(texts_all)})\n",
    "    dfc=pd.DataFrame(curves).sort_values([\"mode\",\"temperature\"]).reset_index(drop=True)\n",
    "    pd.DataFrame(by_topic).to_csv(OUTDIR/\"novelty_by_topic.csv\", index=False, encoding=\"utf-8\")\n",
    "    return dfc\n",
    "\n",
    "def cummax_smooth(y):\n",
    "    if SMOOTH_KIND!=\"cummax\": return list(y)\n",
    "    out=[]; m=-1e9\n",
    "    for v in y:\n",
    "        m=max(m,float(v)); out.append(m)\n",
    "    return out\n",
    "\n",
    "def theta_metrics(sub_df):\n",
    "    sub=sub_df.sort_values(\"temperature\").reset_index(drop=True)\n",
    "    temps=list(map(float, sub[\"temperature\"].tolist()))\n",
    "    nov  =list(map(float, sub[\"novelty\"].tolist()))\n",
    "    nov_s=cummax_smooth(nov)\n",
    "    base=float(nov_s[0]); std=float(np.std(nov_s)) if len(nov_s)>1 else 0.0\n",
    "    cutoff=base+1.5*std\n",
    "    # θ*_cutoff: first T where novelty exceeds cutoff\n",
    "    idx_cut=None\n",
    "    for i,(T,nv) in enumerate(zip(temps,nov_s)):\n",
    "        if nv>cutoff: idx_cut=i; break\n",
    "    if idx_cut is None: idx_cut=len(temps)-1\n",
    "    theta_cut=float(temps[idx_cut])\n",
    "    # θ*_grad: argmax discrete gradient on smoothed novelty\n",
    "    grad=[(nov_s[i+1]-nov_s[i])/(temps[i+1]-temps[i]) for i in range(len(temps)-1)]\n",
    "    if grad:\n",
    "        i_g=int(np.argmax(grad)); theta_grad=float(temps[i_g+1]); slope_grad=float(grad[i_g])\n",
    "    else:\n",
    "        theta_grad=float(temps[-1]); slope_grad=0.0\n",
    "    boundary_flag = (theta_cut>=max(temps)-1e-9) or (theta_grad>=max(temps)-1e-9)\n",
    "    return {\n",
    "        \"baseline\":base,\"std\":std,\"cutoff\":cutoff,\n",
    "        \"theta_star_cutoff\":theta_cut,\"theta_star_grad\":theta_grad,\"slope_at_grad\":slope_grad,\n",
    "        \"boundary_flag\":bool(boundary_flag),\n",
    "        \"temps\":temps,\"novelty\":nov,\"novelty_smooth\":nov_s,\n",
    "    }\n",
    "\n",
    "def plot_curves(df, thetas, fname):\n",
    "    if not HAS_MPL: return\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    for mode,sub in df.groupby(\"mode\"):\n",
    "        sub=sub.sort_values(\"temperature\")\n",
    "        plt.plot(sub[\"temperature\"], sub[\"novelty\"], marker=\"o\", label=f\"{mode} (raw)\")\n",
    "        # smoothed overlay\n",
    "        ns=cummax_smooth(sub[\"novelty\"].tolist())\n",
    "        plt.plot(sub[\"temperature\"], ns, linestyle=\"--\", alpha=0.7, label=f\"{mode} (smooth)\")\n",
    "        th=thetas.get(mode)\n",
    "        if th:\n",
    "            plt.axvline(th[\"theta_star_cutoff\"], linestyle=\":\", alpha=0.5)\n",
    "            plt.axvline(th[\"theta_star_grad\"], linestyle=\"--\", alpha=0.5)\n",
    "    plt.xlabel(\"Temperature\"); plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "    plt.title(\"Consensus vs Dissent — Novelty (raw & smoothed)\")\n",
    "    plt.legend(fontsize=8); plt.tight_layout(); plt.savefig(OUTDIR/fname, dpi=160); plt.close()\n",
    "\n",
    "def run_gra_invariance():\n",
    "    rows=[]; summary=[]\n",
    "    for base in INV_BASE_PROMPTS:\n",
    "        fam=transform_family(base); outs={}\n",
    "        for name,prompt in fam.items():\n",
    "            outs[name]=[]\n",
    "            for r in range(max(1,N_REPS//2+1)):\n",
    "                out=LLM.chat([{\"role\":\"user\",\"content\":prompt}], temperature=0.4, max_tokens=MAX_TOK, seed=BASE_SEED+r)\n",
    "                out=normalize_ws(out); outs[name].append(out)\n",
    "                rows.append({\"experiment\":\"gra_invariance\",\"base_prompt\":base,\"transform\":name,\"rep\":r,\"prompt\":prompt,\"output\":out,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.1)\n",
    "        base_join=normalize_ws(\"\\n\".join(outs.get(\"base\",[])))\n",
    "        buckets={\"syn\":[],\"reorder\":[],\"gauge\":[]}\n",
    "        for name,texts in outs.items():\n",
    "            if name==\"base\": continue\n",
    "            sims=[sim_ratio(base_join,t) for t in texts]\n",
    "            mean=float(np.mean(sims)) if sims else np.nan\n",
    "            summary.append({\"experiment\":\"gra_invariance_summary\",\"base_prompt\":base,\"transform\":name,\"mean_similarity_to_base\":mean,\"n_samples\":len(sims)})\n",
    "            if name.startswith(\"syn\"): buckets[\"syn\"].append(mean)\n",
    "            elif name.startswith(\"reorder\"): buckets[\"reorder\"].append(mean)\n",
    "            elif name.startswith(\"gauge\"): buckets[\"gauge\"].append(mean)\n",
    "        inv_overall=float(np.nanmean([s[\"mean_similarity_to_base\"] for s in summary if s[\"base_prompt\"]==base and s[\"transform\"]!=\"base\"]))\n",
    "        summary.append({\"experiment\":\"gra_invariance_index\",\"base_prompt\":base,\"inv_index_overall\":inv_overall,\"inv_index_syn\":float(np.nanmean(buckets[\"syn\"])) if buckets[\"syn\"] else np.nan,\"inv_index_reorder\":float(np.nanmean(buckets[\"reorder\"])) if buckets[\"reorder\"] else np.nan,\"inv_index_gauge\":float(np.nanmean(buckets[\"gauge\"])) if buckets[\"gauge\"] else np.nan})\n",
    "    return rows, summary\n",
    "\n",
    "def run_anthropomorphism_audit():\n",
    "    rows=[]\n",
    "    for task in AUDIT_TASKS:\n",
    "        for frame, frame_fn in ((\"agency\",agency_frame),(\"mechanistic\",mechanistic_frame)):\n",
    "            for r in range(N_REPS):\n",
    "                prompt=frame_fn(task)\n",
    "                out=LLM.chat([{\"role\":\"user\",\"content\":prompt}], temperature=0.6 if frame==\"agency\" else 0.4, max_tokens=MAX_TOK, seed=300+BASE_SEED+r)\n",
    "                out=normalize_ws(out); met=score_anthro(out)\n",
    "                rows.append({\"experiment\":\"anthropomorphism_audit\",\"task\":task,\"frame\":frame,\"rep\":r,\"prompt\":prompt,\"output\":out,**met,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.1)\n",
    "    df=pd.DataFrame(rows)\n",
    "    # Summary stats + separation\n",
    "    sep_rows=[]; sum_rows=[]\n",
    "    if not df.empty:\n",
    "        g=df.groupby([\"task\",\"frame\"]).agg(\n",
    "            agency_per100_mean=(\"agency_per100\",\"mean\"),\n",
    "            mechanistic_per100_mean=(\"mechanistic_per100\",\"mean\"),\n",
    "            disclaimer_per100_mean=(\"disclaimer_per100\",\"mean\"),\n",
    "            tokens_mean=(\"tokens_est\",\"mean\"),\n",
    "            u3_mean=(\"u3_ratio\",\"mean\")\n",
    "        ).reset_index()\n",
    "        for task,sub in g.groupby(\"task\"):\n",
    "            a=sub[sub[\"frame\"]==\"agency\"]; m=sub[sub[\"frame\"]==\"mechanistic\"]\n",
    "            if not a.empty and not m.empty:\n",
    "                sep_ag=float(a[\"agency_per100_mean\"].iloc[0]-m[\"agency_per100_mean\"].iloc[0])\n",
    "                sep_me=float(m[\"mechanistic_per100_mean\"].iloc[0]-a[\"mechanistic_per100_mean\"].iloc[0])\n",
    "                sep=0.5*(sep_ag+sep_me)\n",
    "                sep_rows.append({\"task\":task,\"sep_agency\":sep_ag,\"sep_mechanistic\":sep_me,\"separation_index\":sep})\n",
    "        sum_rows=g.to_dict(orient=\"records\")\n",
    "    # Permutation tests (optional)\n",
    "    perm_out=[]\n",
    "    if PERM_N>0 and not df.empty:\n",
    "        rng=np.random.default_rng(12345)\n",
    "        for task in AUDIT_TASKS:\n",
    "            dft=df[df[\"task\"]==task]\n",
    "            A=dft[dft[\"frame\"]==\"agency\"]; M=dft[dft[\"frame\"]==\"mechanistic\"]\n",
    "            for metric, sign in ((\"agency_per100\", +1), (\"mechanistic_per100\", -1)):\n",
    "                a=A[metric].to_numpy(); m=M[metric].to_numpy()\n",
    "                if len(a)>0 and len(m)>0:\n",
    "                    obs = sign*(np.mean(a)-np.mean(m))\n",
    "                    pool=np.concatenate([a,m]); n_a=len(a)\n",
    "                    cnt=0\n",
    "                    for _ in range(PERM_N):\n",
    "                        rng.shuffle(pool)\n",
    "                        obs_perm = sign*(np.mean(pool[:n_a]) - np.mean(pool[n_a:]))\n",
    "                        if abs(obs_perm)>=abs(obs): cnt+=1\n",
    "                    p= (cnt+1)/(PERM_N+1)\n",
    "                    perm_out.append({\"task\":task,\"metric\":metric,\"obs_effect_signed\":obs,\"perm_p_two_sided\":p})\n",
    "    return rows, pd.DataFrame(sum_rows), pd.DataFrame(sep_rows), pd.DataFrame(perm_out)\n",
    "\n",
    "# ---------- Execute ----------\n",
    "start=time.time()\n",
    "print(f\"[{ts()}] CNT Weirdness Probe v1.3 starting…\")\n",
    "print(f\"  ROOT: {ROOT}\\n  OUT : {OUTDIR}\\n  LLM : {'SIMULATION' if SIMULATE else f'OpenAI ({LLM_MODEL})'}\")\n",
    "print(f\"  Temps: {TEMPS} | Reps: {N_REPS} | Smooth={SMOOTH_KIND} | AUTO_EXTEND={AUTO_EXTEND} | PERM={PERM_N}\")\n",
    "\n",
    "# 1) CvsD initial\n",
    "df_curves=run_consensus_vs_dissent(TEMPS)\n",
    "df_curves.to_csv(OUTDIR/\"novelty_curves_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "theta={}\n",
    "for mode,sub in df_curves.groupby(\"mode\"):\n",
    "    theta[mode]=theta_metrics(sub)\n",
    "\n",
    "# Optional auto-extend if cliff at boundary\n",
    "extended=False\n",
    "if AUTO_EXTEND and any(theta[m][\"boundary_flag\"] for m in theta):\n",
    "    extra=[1.45,1.50,1.55,1.60]\n",
    "    temps2=sorted(set(TEMPS+extra))\n",
    "    print(f\"  [auto-extend] Extending temps → {temps2}\")\n",
    "    df_curves=run_consensus_vs_dissent(temps2)  # re-run only CvsD with extended temps (adds rows to all_rows)\n",
    "    df_curves.to_csv(OUTDIR/\"novelty_curves_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "    theta={}\n",
    "    for mode,sub in df_curves.groupby(\"mode\"):\n",
    "        theta[mode]=theta_metrics(sub)\n",
    "    extended=True\n",
    "\n",
    "# Save smoothed curves\n",
    "sm_rows=[]\n",
    "for mode,sub in df_curves.groupby(\"mode\"):\n",
    "    sub=sub.sort_values(\"temperature\")\n",
    "    ns=cummax_smooth(sub[\"novelty\"].tolist())\n",
    "    for T,nv,nsv in zip(sub[\"temperature\"], sub[\"novelty\"], ns):\n",
    "        sm_rows.append({\"mode\":mode,\"temperature\":float(T),\"novelty_raw\":float(nv),\"novelty_smooth\":float(nsv)})\n",
    "pd.DataFrame(sm_rows).to_csv(OUTDIR/\"novelty_curves_smoothed.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Plot\n",
    "plot_curves(df_curves, theta, \"consensus_dissent_curve_v13.png\")\n",
    "\n",
    "# 2) GRA invariance\n",
    "gra_rows, gra_sum = run_gra_invariance()\n",
    "\n",
    "# 3) Anthropomorphism audit\n",
    "audit_rows, df_audit_summary, df_audit_sep, df_perm = run_anthropomorphism_audit()\n",
    "\n",
    "# Collate & save\n",
    "df_all = pd.DataFrame(all_rows + gra_rows + gra_sum + audit_rows)\n",
    "df_all.to_csv(OUTDIR/\"completions_and_metrics.csv\", index=False, encoding=\"utf-8\")\n",
    "pd.DataFrame(gra_sum).to_csv(OUTDIR/\"summary_gra_invariance.csv\", index=False, encoding=\"utf-8\")\n",
    "df_audit_summary.to_csv(OUTDIR/\"summary_anthropomorphism_audit.csv\", index=False, encoding=\"utf-8\")\n",
    "df_audit_sep.to_csv(OUTDIR/\"anthropomorphism_separation.csv\", index=False, encoding=\"utf-8\")\n",
    "if not df_perm.empty:\n",
    "    df_perm.to_csv(OUTDIR/\"anthropomorphism_permutation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "manifest={\n",
    "    \"run_id\":RUN_ID, \"utc_start\":ts(), \"root\":str(ROOT), \"outdir\":str(OUTDIR),\n",
    "    \"llm_mode\":\"SIMULATION\" if SIMULATE else f\"OpenAI:{LLM_MODEL}\",\n",
    "    \"temps\":sorted(set(df_curves[\"temperature\"].tolist())),\n",
    "    \"n_reps\":N_REPS, \"smooth\":SMOOTH_KIND, \"auto_extend\":extended,\n",
    "    \"theta\":theta,\n",
    "    \"files\":[str(OUTDIR/p) for p in [\n",
    "        \"completions_and_metrics.csv\",\n",
    "        \"novelty_curves_raw.csv\",\n",
    "        \"novelty_curves_smoothed.csv\",\n",
    "        \"summary_gra_invariance.csv\",\n",
    "        \"summary_anthropomorphism_audit.csv\",\n",
    "        \"anthropomorphism_separation.csv\",\n",
    "        \"anthropomorphism_permutation.csv\" if not df_perm.empty else \"\",\n",
    "        \"consensus_dissent_curve_v13.png\"\n",
    "    ] if p]\n",
    "}\n",
    "write_json(OUTDIR/\"run_manifest.json\", manifest)\n",
    "\n",
    "# ---------- Report ----------\n",
    "print(\"\\n=== CNT Weirdness Probe v1.3 — Report ===\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(\"Artifacts:\")\n",
    "for f in manifest[\"files\"]:\n",
    "    p=Path(f)\n",
    "    if p.exists(): print(\"  -\", p)\n",
    "\n",
    "def fmt_theta(m):\n",
    "    v=theta[m]\n",
    "    return (f\"θ*_cutoff={v['theta_star_cutoff']}  θ*_grad={v['theta_star_grad']}  \"\n",
    "            f\"slope@grad={v['slope_at_grad']:.3f}  (base={v['baseline']:.3f}, std={v['std']:.3f})\"\n",
    "            + (\"  [BOUNDARY]\" if v[\"boundary_flag\"] else \"\"))\n",
    "\n",
    "print(\"\\n[Θ* (cutoff & gradient) per mode]\")\n",
    "for m in (\"consensus\",\"dissent\"):\n",
    "    if m in theta: print(f\"  {m:9s} → {fmt_theta(m)}\")\n",
    "\n",
    "# GRA indices (global means)\n",
    "gra_idx = [r for r in gra_sum if r.get(\"experiment\")==\"gra_invariance_index\"]\n",
    "if gra_idx:\n",
    "    df_idx=pd.DataFrame(gra_idx)\n",
    "    print(\"\\n[GRA Invariance Index — global means]\")\n",
    "    print(f\"  overall={float(df_idx['inv_index_overall'].mean()):.3f} | \"\n",
    "          f\"syn={float(df_idx['inv_index_syn'].mean()):.3f} | \"\n",
    "          f\"reorder={float(df_idx['inv_index_reorder'].mean()):.3f} | \"\n",
    "          f\"gauge={float(df_idx['inv_index_gauge'].mean()):.3f}\")\n",
    "\n",
    "# Anthropomorphism separation + (optional) p-values\n",
    "if not df_audit_sep.empty:\n",
    "    sep_mean=float(df_audit_sep[\"separation_index\"].mean())\n",
    "    print(\"\\n[Anthropomorphism — Separation by task]\")\n",
    "    for _,r in df_audit_sep.iterrows():\n",
    "        print(f\"  • {r['task'][:42]}…  sep_agency={r['sep_agency']:.2f}  sep_mech={r['sep_mechanistic']:.2f}  → sep={r['separation_index']:.2f}\")\n",
    "    print(f\"  Avg separation = {sep_mean:.2f}\")\n",
    "if not df_perm.empty:\n",
    "    print(\"\\n[Anthropomorphism — Permutation p-values]\")\n",
    "    for _,r in df_perm.iterrows():\n",
    "        print(f\"  • {r['task'][:42]}… {r['metric']}: effect={r['obs_effect_signed']:.2f}  p≈{r['perm_p_two_sided']:.3f}\")\n",
    "\n",
    "mode_str=\"SIMULATION (no API key detected)\" if SIMULATE else f\"Live LLM: {LLM_MODEL}\"\n",
    "elapsed=time.time()-start\n",
    "print(f\"\\nMode: {mode_str}\\nDone at {ts()} | Elapsed ~{elapsed:.1f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "699f5ee5-6194-440b-88f1-f66a772b067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-02 06:36:29Z] Post-run analyzer on: E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\n",
      "  Source: novelty_curves_raw.csv\n",
      "\n",
      "=== Post-Run Robust θ* ===\n",
      "  consensus → θ*_cutoff=1.60  θ*_grad=1.26  slope@grad=0.721  (base=0.467, σ=0.015) [BOUNDARY]\n",
      "  dissent   → θ*_cutoff=1.60  θ*_grad=1.24  slope@grad=0.474  (base=0.466, σ=0.016) [BOUNDARY]\n",
      "\n",
      "Saved:\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\postrun_theta.json\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\consensus_dissent_curve_postrun.png\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063520Z\\postrun_report.txt\n",
      "\n",
      "Tip: if you still see [BOUNDARY], re-run v1.3 with CNT_WP_AUTOEXTEND=1 or widen CNT_WP_TEMPS (e.g., up to 1.6).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNT — Weirdness Post-Run Analyzer v1.3p (boundary-stable patch)\n",
    "Purpose: Recompute θ* from your LAST run's saved curves (no completions),\n",
    "         avoid the cummax flatline, and print a clean, robust summary.\n",
    "\n",
    "Inputs (auto-detected):\n",
    "  <CNT_LAB_DIR or CWD>/artifacts/cnt_llm_weirdness_probe/<latest>/novelty_curves_raw.csv\n",
    "  (Falls back to novelty_curves.csv if the raw file isn't present.)\n",
    "\n",
    "Env knobs (optional):\n",
    "  CNT_WP_OUTDIR         → analyze this specific run folder (absolute path)\n",
    "  CNT_WP_K              → cutoff multiplier (default 2.0)\n",
    "  CNT_WP_SIGMA_FLOOR    → sigma floor if flat (default 0.01)\n",
    "  CNT_WP_POST_SMOOTH    → 'none'|'ema'|'cummax' for visualization only (default 'none')\n",
    "  CNT_WP_POST_EMA       → EMA alpha (default 0.4)\n",
    "\n",
    "Outputs:\n",
    "  postrun_theta.json\n",
    "  consensus_dissent_curve_postrun.png\n",
    "  postrun_report.txt\n",
    "\"\"\"\n",
    "import os, json, re\n",
    "from pathlib import Path\n",
    "from datetime import datetime, UTC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Optional plotting\n",
    "HAS_MPL = True\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "except Exception:\n",
    "    HAS_MPL = False\n",
    "\n",
    "def ts(): return datetime.now(UTC).strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
    "\n",
    "ROOT = Path(os.getenv(\"CNT_LAB_DIR\", os.getcwd()))\n",
    "BASE = ROOT / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "OUTDIR_ENV = os.getenv(\"CNT_WP_OUTDIR\", \"\").strip()\n",
    "if OUTDIR_ENV:\n",
    "    RUN_DIR = Path(OUTDIR_ENV)\n",
    "else:\n",
    "    runs = sorted([p for p in BASE.glob(\"*\") if p.is_dir() and re.match(r\"^\\d{8}-\\d{6}Z$\", p.name)], key=lambda p: p.name)\n",
    "    if not runs:\n",
    "        raise FileNotFoundError(f\"No run folders found under {BASE}\")\n",
    "    RUN_DIR = runs[-1]\n",
    "\n",
    "raw_path = RUN_DIR / \"novelty_curves_raw.csv\"\n",
    "alt_path = RUN_DIR / \"novelty_curves.csv\"\n",
    "CSV_PATH = raw_path if raw_path.exists() else alt_path\n",
    "if not CSV_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Could not find novelty curves CSV in {RUN_DIR}\")\n",
    "\n",
    "print(f\"[{ts()}] Post-run analyzer on: {RUN_DIR}\")\n",
    "print(f\"  Source: {CSV_PATH.name}\")\n",
    "\n",
    "# Params\n",
    "K = float(os.getenv(\"CNT_WP_K\", \"2.0\"))\n",
    "SIGMA_FLOOR = float(os.getenv(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "POST_SMOOTH = os.getenv(\"CNT_WP_POST_SMOOTH\", \"none\").lower()\n",
    "EMA_ALPHA = float(os.getenv(\"CNT_WP_POST_EMA\", \"0.4\"))\n",
    "\n",
    "def smooth(seq, kind=\"none\", alpha=0.4):\n",
    "    x = list(map(float, seq))\n",
    "    if kind == \"ema\":\n",
    "        y=[]; s=None\n",
    "        for v in x:\n",
    "            s = v if s is None else alpha*v + (1-alpha)*s\n",
    "            y.append(s)\n",
    "        return y\n",
    "    elif kind == \"cummax\":\n",
    "        y=[]; m=-1e9\n",
    "        for v in x:\n",
    "            m = max(m, v); y.append(m)\n",
    "        return y\n",
    "    return x\n",
    "\n",
    "def robust_theta(temps, nov, k=2.0, sigma_floor=0.01):\n",
    "    temps = np.array(temps, dtype=float)\n",
    "    nov   = np.array(nov,   dtype=float)\n",
    "\n",
    "    # Baseline: median of the first 2 (or first quartile) temps\n",
    "    n_low = max(2, int(len(nov)*0.25))\n",
    "    base  = float(np.median(nov[:n_low]))\n",
    "\n",
    "    # Robust sigma: max(std, MAD*1.4826, floor)\n",
    "    sigma_raw = float(np.std(nov, ddof=0))\n",
    "    mad       = float(np.median(np.abs(nov - np.median(nov)))) * 1.4826\n",
    "    sigma     = max(sigma_raw, mad, sigma_floor)\n",
    "\n",
    "    cutoff = base + k * sigma\n",
    "\n",
    "    # θ*_cutoff: earliest temp where novelty >= cutoff\n",
    "    idx_cut = next((i for i,(t,val) in enumerate(zip(temps, nov)) if val >= cutoff), len(temps)-1)\n",
    "    theta_cut = float(temps[idx_cut])\n",
    "\n",
    "    # θ*_grad: first large positive jump (≥ μ + 2σ of discrete gradient); fallback to argmax\n",
    "    if len(temps) >= 2:\n",
    "        g = np.diff(nov) / np.diff(temps)\n",
    "        mu, sd = float(np.mean(g)), float(np.std(g, ddof=0))\n",
    "        thr = mu + 2.0 * (sd if sd > 0 else 0.0)\n",
    "        i_g = next((i for i,gv in enumerate(g) if gv >= thr and gv > 0), int(np.argmax(g)))\n",
    "        theta_grad = float(temps[min(i_g+1, len(temps)-1)])\n",
    "        slope = float(g[i_g]) if len(g) else 0.0\n",
    "    else:\n",
    "        theta_grad = float(temps[-1]); slope = 0.0\n",
    "\n",
    "    boundary = (abs(theta_cut - temps[-1]) < 1e-9)\n",
    "    return dict(\n",
    "        baseline=base, sigma=sigma, cutoff=cutoff,\n",
    "        theta_star_cutoff=theta_cut, theta_star_grad=theta_grad,\n",
    "        slope_at_grad=slope, boundary=bool(boundary)\n",
    "    )\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(CSV_PATH)\n",
    "if \"novelty\" not in df.columns:  # v1.2 file name\n",
    "    raise ValueError(\"CSV missing 'novelty' column; are you pointing at the right file?\")\n",
    "\n",
    "modes = sorted(df[\"mode\"].unique().tolist())\n",
    "theta_map = {}\n",
    "viz_rows = []\n",
    "\n",
    "for mode in modes:\n",
    "    sub = df[df[\"mode\"]==mode].sort_values(\"temperature\")\n",
    "    T = sub[\"temperature\"].astype(float).tolist()\n",
    "    N = sub[\"novelty\"].astype(float).tolist()\n",
    "\n",
    "    # Compute robust thetas on RAW novelty (not cummax)\n",
    "    th = robust_theta(T, N, k=K, sigma_floor=SIGMA_FLOOR)\n",
    "    theta_map[mode] = th\n",
    "\n",
    "    # For visualization only (optional smoothing)\n",
    "    Ns = smooth(N, POST_SMOOTH, EMA_ALPHA)\n",
    "    for t, nr, ns in zip(T, N, Ns):\n",
    "        viz_rows.append(dict(mode=mode, temperature=float(t), novelty_raw=float(nr), novelty_smooth=float(ns)))\n",
    "\n",
    "# Save summaries\n",
    "post_theta_path = RUN_DIR / \"postrun_theta.json\"\n",
    "with open(post_theta_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(theta_map, f, indent=2)\n",
    "\n",
    "pd.DataFrame(viz_rows).to_csv(RUN_DIR / \"novelty_curves_postrun_smoothed.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "# Plot\n",
    "if HAS_MPL:\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    for mode in modes:\n",
    "        sub = [r for r in viz_rows if r[\"mode\"]==mode]\n",
    "        sub = sorted(sub, key=lambda r: r[\"temperature\"])\n",
    "        Ts  = [r[\"temperature\"] for r in sub]\n",
    "        Nr  = [r[\"novelty_raw\"] for r in sub]\n",
    "        Ns  = [r[\"novelty_smooth\"] for r in sub]\n",
    "        plt.plot(Ts, Nr, marker=\"o\", label=f\"{mode} (raw)\")\n",
    "        if POST_SMOOTH != \"none\":\n",
    "            plt.plot(Ts, Ns, linestyle=\"--\", alpha=0.7, label=f\"{mode} (smooth)\")\n",
    "        # draw θ*\n",
    "        th = theta_map[mode]\n",
    "        plt.axvline(th[\"theta_star_cutoff\"], linestyle=\":\", alpha=0.6)\n",
    "        plt.axvline(th[\"theta_star_grad\"],   linestyle=\"--\", alpha=0.6)\n",
    "    plt.xlabel(\"Temperature\")\n",
    "    plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "    plt.title(\"Consensus vs Dissent — Post-Run Robust θ*\")\n",
    "    plt.legend(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(RUN_DIR / \"consensus_dissent_curve_postrun.png\", dpi=160)\n",
    "    plt.close()\n",
    "\n",
    "# Print + write a tiny report\n",
    "print(\"\\n=== Post-Run Robust θ* ===\")\n",
    "for m in modes:\n",
    "    v = theta_map[m]\n",
    "    flag = \" [BOUNDARY]\" if v[\"boundary\"] else \"\"\n",
    "    print(f\"  {m:9s} → θ*_cutoff={v['theta_star_cutoff']:.2f}  θ*_grad={v['theta_star_grad']:.2f}  \"\n",
    "          f\"slope@grad={v['slope_at_grad']:.3f}  (base={v['baseline']:.3f}, σ={v['sigma']:.3f}){flag}\")\n",
    "\n",
    "with open(RUN_DIR / \"postrun_report.txt\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"CNT Weirdness Post-Run Analyzer v1.3p\\n\")\n",
    "    f.write(f\"Run dir: {RUN_DIR}\\n\")\n",
    "    for m,v in theta_map.items():\n",
    "        flag = \" [BOUNDARY]\" if v[\"boundary\"] else \"\"\n",
    "        f.write(f\"{m:9s} → θ*_cutoff={v['theta_star_cutoff']:.2f}  θ*_grad={v['theta_star_grad']:.2f}  \"\n",
    "                f\"slope@grad={v['slope_at_grad']:.3f}  (base={v['baseline']:.3f}, σ={v['sigma']:.3f}){flag}\\n\")\n",
    "\n",
    "print(f\"\\nSaved:\\n  - {post_theta_path}\\n  - {RUN_DIR / 'consensus_dissent_curve_postrun.png'}\\n  - {RUN_DIR / 'postrun_report.txt'}\\n\")\n",
    "print(\"Tip: if you still see [BOUNDARY], re-run v1.3 with CNT_WP_AUTOEXTEND=1 or widen CNT_WP_TEMPS (e.g., up to 1.6).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "342b2455-d069-4e0f-a8e4-2300886b3a6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2025-11-02 06:36:29Z] CNT Weirdness Probe v1.4 starting…\n",
      "  ROOT: E:\\CNT\n",
      "  OUT : E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\n",
      "  LLM : SIMULATION\n",
      "  Temps: [0.9, 1.0, 1.1, 1.15, 1.2, 1.22, 1.24, 1.25, 1.26, 1.28, 1.3, 1.35, 1.4] | Reps: 8 | Smooth(viz)=none | AUTO_EXTEND=True | PERM=200\n",
      "  [auto-extend] Extending temps → [0.9, 1.0, 1.1, 1.15, 1.2, 1.22, 1.24, 1.25, 1.26, 1.28, 1.3, 1.35, 1.4, 1.45, 1.5, 1.55, 1.6]\n",
      "\n",
      "=== CNT Weirdness Probe v1.4 — Report ===\n",
      "Run ID: 20251102-063629Z\n",
      "Artifacts:\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\completions_and_metrics.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\novelty_curves_raw.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\novelty_curves_smoothed.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\novelty_curves.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\summary_gra_invariance.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\summary_anthropomorphism_audit.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\anthropomorphism_separation.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\anthropomorphism_permutation.csv\n",
      "  - E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063629Z\\consensus_dissent_curve.png\n",
      "\n",
      "[θ* (cutoff & gradient) per mode (robust, RAW novelty)]\n",
      "  consensus → θ*_cutoff=1.60  θ*_grad=1.26  slope@grad=0.721  (base=0.467, σ=0.015) [BOUNDARY]\n",
      "  dissent   → θ*_cutoff=1.60  θ*_grad=1.24  slope@grad=0.474  (base=0.466, σ=0.016) [BOUNDARY]\n",
      "\n",
      "[GRA Invariance Index — global means]\n",
      "  overall=0.501 | syn=0.503 | reorder=0.506 | gauge=0.493\n",
      "\n",
      "[Anthropomorphism — Separation by task]\n",
      "  • Compare Jupiter and Earth in two sentences…  sep_agency=6.73  sep_mech=6.73  → sep=6.73\n",
      "  • Give one risk and one benefit of social me…  sep_agency=8.83  sep_mech=8.58  → sep=8.70\n",
      "  • Summarize why the sky is blue in one parag…  sep_agency=8.52  sep_mech=7.61  → sep=8.06\n",
      "  Avg separation = 7.83\n",
      "\n",
      "[Anthropomorphism — Permutation p-values (two-sided)]\n",
      "  • Summarize why the sky is blue in one parag… agency_per100: effect=8.52  p≈0.005\n",
      "  • Summarize why the sky is blue in one parag… mechanistic_per100: effect=7.61  p≈0.005\n",
      "  • Compare Jupiter and Earth in two sentences… agency_per100: effect=6.73  p≈0.005\n",
      "  • Compare Jupiter and Earth in two sentences… mechanistic_per100: effect=6.73  p≈0.005\n",
      "  • Give one risk and one benefit of social me… agency_per100: effect=8.83  p≈0.005\n",
      "  • Give one risk and one benefit of social me… mechanistic_per100: effect=8.58  p≈0.005\n",
      "\n",
      "Mode: SIMULATION (no API key detected)\n",
      "Done at 2025-11-02 06:37:38Z | Elapsed ~69.2s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "CNT — Weirdness Probe v1.4 (single MEGA cell)\n",
    "\n",
    "What it does (one run):\n",
    "  (1) Consensus vs Dissent → novelty curves, robust θ* (cutoff & gradient), slope, optional auto-extend temps\n",
    "  (2) GRA Invariance       → transform stability (synonym/reorder/gauge) + Invariance Index\n",
    "  (3) Anthropomorphism     → agency vs mechanistic framing, Separation index, optional permutation p-values\n",
    "\n",
    "Design notes:\n",
    "- Robust θ*: median-baseline + max(std, MAD*1.4826, sigma_floor) on RAW novelty (not smoothed)\n",
    "- Gradient θ*: argmax of discrete gradient (with safe fallback), plus slope@grad\n",
    "- Smoothing only for visualization (optional); detection runs on raw\n",
    "- Live LLM if OPENAI_API_KEY is set; otherwise simulation mode\n",
    "\n",
    "Env knobs (optional):\n",
    "  CNT_WP_TEMPS        e.g. \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\"\n",
    "  CNT_WP_N_REPS       e.g. \"6\"   (# samples per condition; lower if using a paid API)\n",
    "  CNT_WP_MAXTOK       e.g. \"400\"\n",
    "  CNT_WP_FAST         \"1\" | \"0\"  (lighter temps & reps if \"1\")\n",
    "  CNT_WP_SMOOTH       \"none\" | \"ema\" | \"cummax\"   (viz only; default \"none\")\n",
    "  CNT_WP_EMA_ALPHA    e.g. \"0.4\" (viz only)\n",
    "  CNT_WP_AUTOEXTEND   \"1\" | \"0\"  (if boundary hit, extends to 1.45–1.60 and re-runs CvsD)\n",
    "  CNT_WP_K            cutoff multiplier k (default 2.0)\n",
    "  CNT_WP_SIGMA_FLOOR  minimal sigma if flat (default 0.01)\n",
    "  CNT_WP_PERM         e.g. \"200\" (# permutations for anthropomorphism p-values; \"0\" to skip)\n",
    "\n",
    "  OPENAI_API_KEY      (live mode if set)\n",
    "  OPENAI_BASE_URL     (OpenAI-compatible endpoint)\n",
    "  LLM_MODEL           default \"gpt-4o-mini\"\n",
    "\n",
    "Artifacts:\n",
    "  <CNT_LAB_DIR or CWD>/artifacts/cnt_llm_weirdness_probe/<UTC_RUN_ID>/\n",
    "\"\"\"\n",
    "\n",
    "# -------------------- Imports & setup --------------------\n",
    "import os, sys, re, json, time, math, random, zlib, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, UTC\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "try:\n",
    "    import matplotlib.pyplot as plt\n",
    "    HAS_MPL = True\n",
    "except Exception:\n",
    "    HAS_MPL = False\n",
    "\n",
    "ROOT = Path(os.getenv(\"CNT_LAB_DIR\", os.getcwd()))\n",
    "RUN_ID = datetime.now(UTC).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "OUTDIR = ROOT / \"artifacts\" / \"cnt_llm_weirdness_probe\" / RUN_ID\n",
    "OUTDIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "LLM_MODEL     = os.getenv(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "OPENAI_BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"\") or None\n",
    "\n",
    "FAST = os.getenv(\"CNT_WP_FAST\", \"0\") == \"1\"\n",
    "SMOOTH_KIND = os.getenv(\"CNT_WP_SMOOTH\", \"none\").lower()  # viz only\n",
    "EMA_ALPHA   = float(os.getenv(\"CNT_WP_EMA_ALPHA\", \"0.4\"))\n",
    "AUTO_EXTEND = os.getenv(\"CNT_WP_AUTOEXTEND\", \"0\") == \"1\"\n",
    "\n",
    "DEFAULT_TEMPS = \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\" if not FAST else \"0.9,1.1,1.25,1.35\"\n",
    "TEMPS    = [float(x) for x in os.getenv(\"CNT_WP_TEMPS\", DEFAULT_TEMPS).split(\",\")]\n",
    "N_REPS   = int(os.getenv(\"CNT_WP_N_REPS\", \"6\" if not FAST else \"3\"))\n",
    "MAX_TOK  = int(os.getenv(\"CNT_WP_MAXTOK\", \"400\"))\n",
    "BASE_SEED= 42\n",
    "\n",
    "K_CUTOFF      = float(os.getenv(\"CNT_WP_K\", \"2.0\"))\n",
    "SIGMA_FLOOR   = float(os.getenv(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "PERM_N        = int(os.getenv(\"CNT_WP_PERM\", \"0\"))\n",
    "\n",
    "def ts(): return datetime.now(UTC).strftime(\"%Y-%m-%d %H:%M:%SZ\")\n",
    "def normalize_ws(t: str) -> str: return re.sub(r\"\\s+\", \" \", (t or \"\").strip())\n",
    "def tokens_est(t: str) -> int: return max(1, len(re.findall(r\"\\w+\", t)))\n",
    "def ugram_ratio(t: str, n: int = 3) -> float:\n",
    "    words = re.findall(r\"[A-Za-z0-9']+\", (t or \"\").lower())\n",
    "    if len(words) < n: return 0.0\n",
    "    grams = list(zip(*[words[i:] for i in range(n)]))\n",
    "    return len(set(grams))/max(1, len(grams))\n",
    "def compress_ratio(t: str) -> float:\n",
    "    raw = (t or \"\").encode(\"utf-8\", errors=\"ignore\")\n",
    "    if not raw: return 1.0\n",
    "    comp = zlib.compress(raw, 9)\n",
    "    return len(comp)/len(raw)\n",
    "\n",
    "# Similarity + novelty\n",
    "def _bigrams(words):\n",
    "    return set(zip(words, words[1:])) if len(words) > 1 else set()\n",
    "def sim_ratio(a: str, b: str) -> float:\n",
    "    aw = re.findall(r\"[A-Za-z0-9']+\", (a or \"\").lower())\n",
    "    bw = re.findall(r\"[A-Za-z0-9']+\", (b or \"\").lower())\n",
    "    a2, b2 = _bigrams(aw), _bigrams(bw)\n",
    "    if not a2 and not b2:\n",
    "        aset, bset = set((a or \"\").lower()), set((b or \"\").lower())\n",
    "        d = len(aset | bset) or 1\n",
    "        return len(aset & bset)/d\n",
    "    d1 = len(a2 | b2) or 1\n",
    "    j = len(a2 & b2)/d1\n",
    "    aset, bset = set((a or \"\").lower()), set((b or \"\").lower())\n",
    "    d2 = len(aset | bset) or 1\n",
    "    c = len(aset & bset)/d2\n",
    "    return 0.65*j + 0.35*c\n",
    "def pairwise_mean_similarity(texts):\n",
    "    if len(texts) < 2: return 1.0\n",
    "    sims=[]\n",
    "    for i in range(len(texts)):\n",
    "        for j in range(i+1, len(texts)):\n",
    "            sims.append(sim_ratio(texts[i], texts[j]))\n",
    "    return float(np.mean(sims)) if sims else 1.0\n",
    "def novelty_from_group(texts): return max(0.0, 1.0 - pairwise_mean_similarity(texts))\n",
    "def write_json(path, obj): path.write_text(json.dumps(obj, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "random.seed(BASE_SEED); np.random.seed(BASE_SEED)\n",
    "\n",
    "# -------------------- LLM client (OpenAI or simulation) --------------------\n",
    "def ensure_openai():\n",
    "    try:\n",
    "        import openai  # noqa\n",
    "        return True\n",
    "    except Exception:\n",
    "        try:\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"--upgrade\", \"openai\"], check=False)\n",
    "            import openai  # noqa\n",
    "            return True\n",
    "        except Exception:\n",
    "            return False\n",
    "\n",
    "OPENAI_READY = bool(OPENAI_API_KEY) and ensure_openai()\n",
    "SIMULATE = not OPENAI_READY\n",
    "\n",
    "def simulate_reply(messages, temperature=0.7):\n",
    "    topics = [\"stars\",\"markets\",\"mushrooms\",\"rivers\",\"cities\",\"membranes\"]\n",
    "    tones  = [\"measured\",\"lyrical\",\"technical\",\"playful\",\"skeptical\",\"didactic\"]\n",
    "    verbs  = [\"braid\",\"whisper\",\"drift\",\"pin\",\"resonate\",\"cascade\",\"splice\",\"harbor\"]\n",
    "    stats  = [\"tokens\",\"probabilities\",\"gradients\",\"embeddings\",\"n-grams\",\"logits\",\"priors\"]\n",
    "    hint = normalize_ws(\" \".join(m.get(\"content\",\"\") for m in messages))[:240].lower()\n",
    "    t = max(0.05, min(1.6, float(temperature)))\n",
    "    n_sent = 3 + int(4*t + random.random()*3)\n",
    "    agency = [\"I think\",\"I believe\",\"I chose\",\"I decided\",\"I prefer\",\"I feel\"]\n",
    "    mech   = [\"statistical\",\"token\",\"logit\",\"embedding\",\"n-gram\",\"temperature\"]\n",
    "    use_agency = (\"why you decided\" in hint) or (\"why you choose\" in hint) or (\"you decided\" in hint)\n",
    "    use_mech   = (\"mechanistic\" in hint) or (\"statistical\" in hint) or (\"token\" in hint)\n",
    "    bits=[]\n",
    "    for _ in range(n_sent):\n",
    "        seg=[]\n",
    "        seg.append(random.choice([\"In brief\",\"Consider\",\"Often\",\"Sometimes\",\"Empirically\",\"Practically\"]))\n",
    "        seg.append(f\"{random.choice(tones).capitalize()} patterns {random.choice(['emerge','cohere','fracture','drift'])}\")\n",
    "        seg.append(f\"as {random.choice(topics)} {random.choice(['resonate','fold','diffuse','align','compete'])}.\")\n",
    "        if random.random() < 0.3 + 0.3*t: seg.append(f\"We {random.choice(['tune','sample','scan'])} {random.choice(stats)} like {random.choice(verbs)}.\")\n",
    "        if use_agency and random.random() < 0.6: seg.append(random.choice(agency)+\" this framing.\")\n",
    "        if use_mech and random.random() < 0.6: seg.append(f\"This follows from {random.choice(mech)} cues at higher temperature.\")\n",
    "        bits.append(\" \".join(seg))\n",
    "    suffix = \"\" if t < 0.5 else \" \".join(random.sample(verbs, k=min(3,len(verbs))))\n",
    "    return normalize_ws(\" \".join(bits)+\" \"+suffix)\n",
    "\n",
    "class LLMClient:\n",
    "    def __init__(self):\n",
    "        self.kind  = \"sim\" if SIMULATE else \"openai\"\n",
    "        self.model = LLM_MODEL\n",
    "        self.ready = not SIMULATE\n",
    "        if not SIMULATE:\n",
    "            try:\n",
    "                from openai import OpenAI\n",
    "                kwargs={}\n",
    "                if OPENAI_BASE_URL: kwargs[\"base_url\"]=OPENAI_BASE_URL\n",
    "                if OPENAI_API_KEY:  kwargs[\"api_key\"]=OPENAI_API_KEY\n",
    "                self.client = OpenAI(**kwargs)\n",
    "                self.api = \"v1\"\n",
    "            except Exception:\n",
    "                import openai as openai_legacy\n",
    "                if OPENAI_API_KEY: openai_legacy.api_key = OPENAI_API_KEY\n",
    "                try:\n",
    "                    if OPENAI_BASE_URL: openai_legacy.base_url = OPENAI_BASE_URL  # type: ignore\n",
    "                except Exception:\n",
    "                    pass\n",
    "                self.client = openai_legacy\n",
    "                self.api = \"legacy\"\n",
    "    def chat(self, messages, temperature=0.7, max_tokens=400, seed=None, retries=3, backoff=0.8):\n",
    "        if SIMULATE: return simulate_reply(messages, temperature)\n",
    "        last = None\n",
    "        for attempt in range(retries):\n",
    "            try:\n",
    "                if getattr(self, \"api\", \"v1\") == \"v1\":\n",
    "                    try:\n",
    "                        kwargs = dict(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                        if seed is not None: kwargs[\"seed\"] = seed\n",
    "                        r = self.client.chat.completions.create(**kwargs)\n",
    "                        return r.choices[0].message.content\n",
    "                    except Exception:\n",
    "                        r = self.client.responses.create(\n",
    "                            model=self.model,\n",
    "                            input=[{\"role\": m.get(\"role\",\"user\"), \"content\": m.get(\"content\",\"\")} for m in messages],\n",
    "                            temperature=temperature, max_output_tokens=max_tokens, seed=seed,\n",
    "                        )\n",
    "                        try: return r.output_text\n",
    "                        except Exception:\n",
    "                            parts=[]\n",
    "                            for out in getattr(r,\"output\",[]) or []:\n",
    "                                if getattr(out,\"type\",\"\")==\"output_text\":\n",
    "                                    parts.append(getattr(out,\"content\",\"\"))\n",
    "                            return \"\\n\".join(parts) if parts else \"\"\n",
    "                else:\n",
    "                    r = self.client.ChatCompletion.create(model=self.model, messages=messages, temperature=temperature, max_tokens=max_tokens)\n",
    "                    return r[\"choices\"][0][\"message\"][\"content\"]\n",
    "            except Exception as e:\n",
    "                last = e\n",
    "                time.sleep((attempt+1)*backoff)\n",
    "        raise RuntimeError(f\"LLM call failed after retries: {last}\")\n",
    "\n",
    "LLM = LLMClient()\n",
    "\n",
    "# -------------------- Experiments --------------------\n",
    "TOPICS = [\n",
    "    \"Are large language models creative?\",\n",
    "    \"Do psychedelics improve mental health outcomes?\",\n",
    "    \"Is homework beneficial for learning?\",\n",
    "    \"Can economic sanctions achieve political goals?\",\n",
    "    \"Are processed foods inherently harmful?\",\n",
    "    \"Is social media net-positive for teenagers?\",\n",
    "]\n",
    "def prompt_consensus(topic):\n",
    "    return f'State the mainstream, widely accepted view on \"{topic}\" in 3 concise bullet points, neutral tone.'\n",
    "def prompt_dissent(topic):\n",
    "    return f'Argue a novel, contrarian perspective on \"{topic}\" that challenges the mainstream. Provide one concrete mechanism and one illustrative example.'\n",
    "\n",
    "# Invariance transforms\n",
    "SYNONYM_TABLE = {\n",
    "    \"explain\":[\"describe\",\"clarify\",\"outline\"],\n",
    "    \"simple\":[\"plain\",\"clear\",\"accessible\"],\n",
    "    \"steps\":[\"stages\",\"moves\",\"phases\"],\n",
    "    \"kids\":[\"children\",\"young students\",\"12-year-olds\"],\n",
    "    \"short\":[\"brief\",\"compact\",\"succinct\"],\n",
    "    \"paragraph\":[\"passage\",\"section\"],\n",
    "}\n",
    "def _syn_replace(s: str, alt=False):\n",
    "    def repl(m):\n",
    "        w = m.group(0); c = SYNONYM_TABLE.get(w.lower(), [])\n",
    "        if not c: return w\n",
    "        pick = c[1 % len(c)] if alt and len(c)>1 else c[0]\n",
    "        return pick.capitalize() if w[0].isupper() else pick\n",
    "    pat = re.compile(r\"\\b(\"+\"|\".join(map(re.escape, SYNONYM_TABLE.keys()))+r\")\\b\", flags=re.I)\n",
    "    return pat.sub(repl, s)\n",
    "def gauge_reparam(p: str, bullets: int = 5):\n",
    "    p = re.sub(r\"\\b(in|using)\\s+\\d+\\s+(steps|bullets?)\\b\", f\"in {bullets} steps\", p, flags=re.I)\n",
    "    p = re.sub(r\"\\b(one|1)\\s+paragraph\\b\", f\"{bullets} sentences\", p, flags=re.I)\n",
    "    return p\n",
    "def reorder_clauses(prompt: str):\n",
    "    parts = [x.strip() for x in re.split(r\"[;,]\", prompt) if x.strip()]\n",
    "    if len(parts) < 2: return prompt\n",
    "    head, tail = parts[0], parts[1:]\n",
    "    random.shuffle(tail)\n",
    "    return \"; \".join([head] + tail)\n",
    "INV_BASE_PROMPTS = [\n",
    "    \"Explain photosynthesis to kids in 1 paragraph with a short metaphor at the end.\",\n",
    "    \"Explain how vaccines work using 5 steps and one counterexample.\",\n",
    "    \"Explain compound interest in a simple way with a compact example.\",\n",
    "]\n",
    "def transform_family(p):\n",
    "    return {\"base\":p, \"syn1\":_syn_replace(p,False), \"syn2\":_syn_replace(p,True), \"gauge3\":gauge_reparam(p,3), \"reorder\":reorder_clauses(p)}\n",
    "\n",
    "# Anthropomorphism tasks + metrics\n",
    "MENTAL_VERBS = {\"think\",\"believe\",\"decide\",\"feel\",\"choose\",\"prefer\",\"guess\",\"assume\",\"intend\",\"want\"}\n",
    "FIRST_PERSON = {\" i \",\" i'm\",\" i’m\",\" i am\",\" my \",\" me \",\" myself \",\" personally \"}\n",
    "MECH_TERMS   = {\"token\",\"probability\",\"logit\",\"embedding\",\"statistical\",\"n-gram\",\"temperature\",\"sampling\",\"gradient\",\"entropy\",\"prior\"}\n",
    "DISCLAIMER_PHRASES = {\"as an ai\",\"as a language model\",\"i cannot\",\"i do not have\",\"i'm unable\",\"i am unable\"}\n",
    "\n",
    "def agency_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain *why you decided* to present it that way—use first-person language (e.g., \"I decided\", \"I chose\").\"\"\"\n",
    "def mechanistic_frame(task: str):\n",
    "    return f\"\"\"First, answer the task: {task}\n",
    "Then, in 2-4 sentences, explain—without using first-person—what *statistical cues* (tokens, logits, n-grams, embeddings, temperature) likely led to those next-token choices.\"\"\"\n",
    "AUDIT_TASKS = [\n",
    "    \"Summarize why the sky is blue in one paragraph.\",\n",
    "    \"Compare Jupiter and Earth in two sentences.\",\n",
    "    \"Give one risk and one benefit of social media for teens.\",\n",
    "]\n",
    "def score_anthro(text: str):\n",
    "    t = \" \" + (text or \"\").lower() + \" \"\n",
    "    words = re.findall(r\"[a-z']+\", t)\n",
    "    n = max(1, len(words))\n",
    "    agency = sum(t.count(fp) for fp in FIRST_PERSON) + sum(words.count(v) for v in MENTAL_VERBS)\n",
    "    mech   = sum(words.count(v) for v in MECH_TERMS)\n",
    "    disc   = sum(t.count(p) for p in DISCLAIMER_PHRASES)\n",
    "    scale  = 100.0 / n\n",
    "    return {\"agency_per100\":agency*scale, \"mechanistic_per100\":mech*scale, \"disclaimer_per100\":disc*scale}\n",
    "\n",
    "# -------------------- Run: Consensus vs Dissent --------------------\n",
    "all_rows=[]\n",
    "start_time = time.time()\n",
    "print(f\"[{ts()}] CNT Weirdness Probe v1.4 starting…\")\n",
    "print(f\"  ROOT: {ROOT}\\n  OUT : {OUTDIR}\\n  LLM : {'SIMULATION' if SIMULATE else f'OpenAI ({LLM_MODEL})'}\")\n",
    "print(f\"  Temps: {TEMPS} | Reps: {N_REPS} | Smooth(viz)={SMOOTH_KIND} | AUTO_EXTEND={AUTO_EXTEND} | PERM={PERM_N}\")\n",
    "\n",
    "def run_consensus_vs_dissent(temps):\n",
    "    store=defaultdict(list)\n",
    "    for topic in TOPICS:\n",
    "        for mode in (\"consensus\",\"dissent\"):\n",
    "            base_prompt = prompt_consensus(topic) if mode==\"consensus\" else prompt_dissent(topic)\n",
    "            for T in temps:\n",
    "                for r in range(N_REPS):\n",
    "                    seed = BASE_SEED + r\n",
    "                    out  = LLM.chat([{\"role\":\"user\",\"content\":base_prompt}], temperature=T, max_tokens=MAX_TOK, seed=seed)\n",
    "                    out  = normalize_ws(out)\n",
    "                    store[(topic,mode,T)].append(out)\n",
    "                    all_rows.append({\"experiment\":\"consensus_vs_dissent\",\"topic\":topic,\"mode\":mode,\"temperature\":T,\"rep\":r,\"prompt\":base_prompt,\"output\":out,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.12)\n",
    "    curves=[]; by_topic=[]\n",
    "    for mode in (\"consensus\",\"dissent\"):\n",
    "        for T in temps:\n",
    "            texts=[]\n",
    "            for topic in TOPICS:\n",
    "                xs = store[(topic,mode,T)]\n",
    "                texts += xs\n",
    "                by_topic.append({\"mode\":mode,\"temperature\":T,\"topic\":topic,\"novelty\":novelty_from_group(xs)})\n",
    "            curves.append({\"mode\":mode,\"temperature\":T,\"novelty\":novelty_from_group(texts)})\n",
    "    dfc=pd.DataFrame(curves).sort_values([\"mode\",\"temperature\"]).reset_index(drop=True)\n",
    "    pd.DataFrame(by_topic).to_csv(OUTDIR/\"novelty_by_topic.csv\", index=False, encoding=\"utf-8\")\n",
    "    return dfc\n",
    "\n",
    "def smooth_for_viz(seq, kind=\"none\", alpha=0.4):\n",
    "    x = list(map(float, seq))\n",
    "    if kind == \"ema\":\n",
    "        y=[]; s=None\n",
    "        for v in x:\n",
    "            s = v if s is None else alpha*v + (1-alpha)*s\n",
    "            y.append(s)\n",
    "        return y\n",
    "    elif kind == \"cummax\":\n",
    "        y=[]; m=-1e9\n",
    "        for v in x:\n",
    "            m = max(m, v); y.append(m)\n",
    "        return y\n",
    "    return x\n",
    "\n",
    "def robust_theta_from_raw(temps, nov, k=2.0, sigma_floor=0.01):\n",
    "    temps = np.array(temps, dtype=float); nov = np.array(nov, dtype=float)\n",
    "    n_low = max(2, int(len(nov)*0.25))\n",
    "    base  = float(np.median(nov[:n_low]))\n",
    "    sigma_raw = float(np.std(nov, ddof=0))\n",
    "    mad       = float(np.median(np.abs(nov - np.median(nov)))) * 1.4826\n",
    "    sigma     = max(sigma_raw, mad, sigma_floor)\n",
    "    cutoff    = base + k * sigma\n",
    "    # θ*_cutoff\n",
    "    idx_cut = next((i for i,(t,val) in enumerate(zip(temps, nov)) if val >= cutoff), len(temps)-1)\n",
    "    theta_cut = float(temps[idx_cut])\n",
    "    # θ*_grad\n",
    "    if len(temps) >= 2:\n",
    "        g = np.diff(nov) / np.diff(temps)\n",
    "        i_g = int(np.argmax(g))\n",
    "        theta_grad = float(temps[min(i_g+1, len(temps)-1)])\n",
    "        slope_grad = float(g[i_g]) if len(g) else 0.0\n",
    "    else:\n",
    "        theta_grad = float(temps[-1]); slope_grad = 0.0\n",
    "    boundary = (abs(theta_cut - temps[-1]) < 1e-9) or (abs(theta_grad - temps[-1]) < 1e-9)\n",
    "    return dict(baseline=base, sigma=sigma, cutoff=cutoff, theta_star_cutoff=theta_cut, theta_star_grad=theta_grad, slope_at_grad=slope_grad, boundary=bool(boundary))\n",
    "\n",
    "def compute_theta_map(df_curves):\n",
    "    out={}\n",
    "    for mode, sub in df_curves.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\")\n",
    "        T = sub[\"temperature\"].astype(float).tolist()\n",
    "        N = sub[\"novelty\"].astype(float).tolist()\n",
    "        out[mode] = robust_theta_from_raw(T, N, k=K_CUTOFF, sigma_floor=SIGMA_FLOOR)\n",
    "    return out\n",
    "\n",
    "def plot_curves(df, theta_map, fname):\n",
    "    if not HAS_MPL: return\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    for mode, sub in df.groupby(\"mode\"):\n",
    "        sub = sub.sort_values(\"temperature\")\n",
    "        Ts  = sub[\"temperature\"].tolist()\n",
    "        Nr  = sub[\"novelty\"].tolist()\n",
    "        Ns  = smooth_for_viz(Nr, SMOOTH_KIND, EMA_ALPHA)\n",
    "        plt.plot(Ts, Nr, marker=\"o\", label=f\"{mode} (raw)\")\n",
    "        if SMOOTH_KIND != \"none\":\n",
    "            plt.plot(Ts, Ns, linestyle=\"--\", alpha=0.7, label=f\"{mode} (smooth)\")\n",
    "        th = theta_map.get(mode)\n",
    "        if th:\n",
    "            plt.axvline(th[\"theta_star_cutoff\"], linestyle=\":\", alpha=0.5)\n",
    "            plt.axvline(th[\"theta_star_grad\"],   linestyle=\"--\", alpha=0.5)\n",
    "    plt.xlabel(\"Temperature\"); plt.ylabel(\"Novelty (1 - mean pairwise similarity)\")\n",
    "    plt.title(\"Consensus vs Dissent — Novelty (raw + optional smooth)\")\n",
    "    plt.legend(fontsize=8); plt.tight_layout(); plt.savefig(OUTDIR/fname, dpi=160); plt.close()\n",
    "\n",
    "# First pass\n",
    "df_curves = run_consensus_vs_dissent(TEMPS)\n",
    "df_curves.to_csv(OUTDIR/\"novelty_curves_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "theta_map = compute_theta_map(df_curves)\n",
    "\n",
    "# Auto-extend if needed\n",
    "extended=False\n",
    "if AUTO_EXTEND and any(theta_map[m][\"boundary\"] for m in theta_map):\n",
    "    temps2 = sorted(set(TEMPS + [1.45,1.50,1.55,1.60]))\n",
    "    print(f\"  [auto-extend] Extending temps → {temps2}\")\n",
    "    df_curves = run_consensus_vs_dissent(temps2)    # adds rows into all_rows\n",
    "    df_curves.to_csv(OUTDIR/\"novelty_curves_raw.csv\", index=False, encoding=\"utf-8\")\n",
    "    theta_map = compute_theta_map(df_curves)\n",
    "    extended=True\n",
    "\n",
    "# Save smoothed overlay CSV for convenience\n",
    "sm_rows=[]\n",
    "for mode, sub in df_curves.groupby(\"mode\"):\n",
    "    sub = sub.sort_values(\"temperature\")\n",
    "    Ts = sub[\"temperature\"].tolist()\n",
    "    Nr = sub[\"novelty\"].tolist()\n",
    "    Ns = smooth_for_viz(Nr, SMOOTH_KIND, EMA_ALPHA)\n",
    "    for t, nr, ns in zip(Ts, Nr, Ns):\n",
    "        sm_rows.append({\"mode\":mode,\"temperature\":float(t),\"novelty_raw\":float(nr),\"novelty_smooth\":float(ns)})\n",
    "pd.DataFrame(sm_rows).to_csv(OUTDIR/\"novelty_curves_smoothed.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "plot_curves(df_curves, theta_map, \"consensus_dissent_curve.png\")\n",
    "\n",
    "# -------------------- Run: GRA Invariance --------------------\n",
    "def run_gra_invariance():\n",
    "    rows=[]; summary=[]\n",
    "    for base in INV_BASE_PROMPTS:\n",
    "        fam=transform_family(base); outs={}\n",
    "        reps = max(1, N_REPS//2 + 1)\n",
    "        for name, prompt in fam.items():\n",
    "            outs[name]=[]\n",
    "            for r in range(reps):\n",
    "                out = LLM.chat([{\"role\":\"user\",\"content\":prompt}], temperature=0.4, max_tokens=MAX_TOK, seed=BASE_SEED+r)\n",
    "                out = normalize_ws(out)\n",
    "                outs[name].append(out)\n",
    "                rows.append({\"experiment\":\"gra_invariance\",\"base_prompt\":base,\"transform\":name,\"rep\":r,\"prompt\":prompt,\"output\":out,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.1)\n",
    "        base_join = normalize_ws(\"\\n\".join(outs.get(\"base\", [])))\n",
    "        buckets={\"syn\":[],\"reorder\":[],\"gauge\":[]}\n",
    "        for name,texts in outs.items():\n",
    "            if name==\"base\": continue\n",
    "            sims=[sim_ratio(base_join, t) for t in texts]\n",
    "            mean=float(np.mean(sims)) if sims else np.nan\n",
    "            summary.append({\"experiment\":\"gra_invariance_summary\",\"base_prompt\":base,\"transform\":name,\"mean_similarity_to_base\":mean,\"n_samples\":len(sims)})\n",
    "            if name.startswith(\"syn\"): buckets[\"syn\"].append(mean)\n",
    "            elif name.startswith(\"reorder\"): buckets[\"reorder\"].append(mean)\n",
    "            elif name.startswith(\"gauge\"): buckets[\"gauge\"].append(mean)\n",
    "        inv_overall=float(np.nanmean([s[\"mean_similarity_to_base\"] for s in summary if s[\"base_prompt\"]==base and s[\"transform\"]!=\"base\"]))\n",
    "        summary.append({\"experiment\":\"gra_invariance_index\",\"base_prompt\":base,\"inv_index_overall\":inv_overall,\"inv_index_syn\":float(np.nanmean(buckets[\"syn\"])) if buckets[\"syn\"] else np.nan,\"inv_index_reorder\":float(np.nanmean(buckets[\"reorder\"])) if buckets[\"reorder\"] else np.nan,\"inv_index_gauge\":float(np.nanmean(buckets[\"gauge\"])) if buckets[\"gauge\"] else np.nan})\n",
    "    return rows, summary\n",
    "\n",
    "gra_rows, gra_sum = run_gra_invariance()\n",
    "\n",
    "# -------------------- Run: Anthropomorphism --------------------\n",
    "def run_anthropomorphism_audit():\n",
    "    rows=[]\n",
    "    for task in AUDIT_TASKS:\n",
    "        for frame, frame_fn in ((\"agency\",agency_frame),(\"mechanistic\",mechanistic_frame)):\n",
    "            for r in range(N_REPS):\n",
    "                prompt = frame_fn(task)\n",
    "                out = LLM.chat([{\"role\":\"user\",\"content\":prompt}], temperature=0.6 if frame==\"agency\" else 0.4, max_tokens=MAX_TOK, seed=300+BASE_SEED+r)\n",
    "                out = normalize_ws(out)\n",
    "                met = score_anthro(out)\n",
    "                rows.append({\"experiment\":\"anthropomorphism_audit\",\"task\":task,\"frame\":frame,\"rep\":r,\"prompt\":prompt,\"output\":out,**met,\"tokens_est\":tokens_est(out),\"u3_ratio\":ugram_ratio(out,3),\"compress_ratio\":compress_ratio(out)})\n",
    "                time.sleep(0.1)\n",
    "    df=pd.DataFrame(rows)\n",
    "    # Summary + separation\n",
    "    sum_rows=[]; sep_rows=[]\n",
    "    if not df.empty:\n",
    "        g=df.groupby([\"task\",\"frame\"]).agg(\n",
    "            agency_per100_mean=(\"agency_per100\",\"mean\"),\n",
    "            mechanistic_per100_mean=(\"mechanistic_per100\",\"mean\"),\n",
    "            disclaimer_per100_mean=(\"disclaimer_per100\",\"mean\"),\n",
    "            tokens_mean=(\"tokens_est\",\"mean\"),\n",
    "            u3_mean=(\"u3_ratio\",\"mean\")\n",
    "        ).reset_index()\n",
    "        sum_rows=g.to_dict(orient=\"records\")\n",
    "        for task, sub in g.groupby(\"task\"):\n",
    "            a=sub[sub[\"frame\"]==\"agency\"]; m=sub[sub[\"frame\"]==\"mechanistic\"]\n",
    "            if not a.empty and not m.empty:\n",
    "                sep_ag=float(a[\"agency_per100_mean\"].iloc[0] - m[\"agency_per100_mean\"].iloc[0])\n",
    "                sep_me=float(m[\"mechanistic_per100_mean\"].iloc[0] - a[\"mechanistic_per100_mean\"].iloc[0])\n",
    "                sep=0.5*(sep_ag+sep_me)\n",
    "                sep_rows.append({\"task\":task,\"sep_agency\":sep_ag,\"sep_mechanistic\":sep_me,\"separation_index\":sep})\n",
    "    # Permutation p-values (optional, two-sided)\n",
    "    perm_rows=[]\n",
    "    if PERM_N>0 and not df.empty:\n",
    "        rng=np.random.default_rng(12345)\n",
    "        for task in AUDIT_TASKS:\n",
    "            dft=df[df[\"task\"]==task]\n",
    "            A=dft[dft[\"frame\"]==\"agency\"]; M=dft[dft[\"frame\"]==\"mechanistic\"]\n",
    "            for metric, sign in ((\"agency_per100\", +1), (\"mechanistic_per100\", -1)):\n",
    "                a=A[metric].to_numpy(); m=M[metric].to_numpy()\n",
    "                if len(a)>0 and len(m)>0:\n",
    "                    obs = sign*(np.mean(a)-np.mean(m))\n",
    "                    pool=np.concatenate([a,m]); n_a=len(a); cnt=0\n",
    "                    for _ in range(PERM_N):\n",
    "                        rng.shuffle(pool)\n",
    "                        eff = sign*(np.mean(pool[:n_a]) - np.mean(pool[n_a:]))\n",
    "                        if abs(eff) >= abs(obs): cnt += 1\n",
    "                    p = (cnt+1)/(PERM_N+1)\n",
    "                    perm_rows.append({\"task\":task,\"metric\":metric,\"obs_effect_signed\":float(obs),\"perm_p_two_sided\":float(p)})\n",
    "    return rows, pd.DataFrame(sum_rows), pd.DataFrame(sep_rows), pd.DataFrame(perm_rows)\n",
    "\n",
    "audit_rows, df_audit_summary, df_audit_sep, df_perm = run_anthropomorphism_audit()\n",
    "\n",
    "# -------------------- Save all artifacts --------------------\n",
    "df_all = pd.DataFrame(all_rows + gra_rows + gra_sum + audit_rows)\n",
    "df_all.to_csv(OUTDIR/\"completions_and_metrics.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "df_curves.to_csv(OUTDIR/\"novelty_curves.csv\", index=False, encoding=\"utf-8\")\n",
    "pd.DataFrame(gra_sum).to_csv(OUTDIR/\"summary_gra_invariance.csv\", index=False, encoding=\"utf-8\")\n",
    "df_audit_summary.to_csv(OUTDIR/\"summary_anthropomorphism_audit.csv\", index=False, encoding=\"utf-8\")\n",
    "df_audit_sep.to_csv(OUTDIR/\"anthropomorphism_separation.csv\", index=False, encoding=\"utf-8\")\n",
    "if not df_perm.empty:\n",
    "    df_perm.to_csv(OUTDIR/\"anthropomorphism_permutation.csv\", index=False, encoding=\"utf-8\")\n",
    "\n",
    "manifest = {\n",
    "    \"run_id\": RUN_ID,\n",
    "    \"utc_start\": ts(),\n",
    "    \"root\": str(ROOT),\n",
    "    \"outdir\": str(OUTDIR),\n",
    "    \"llm_mode\": \"SIMULATION\" if SIMULATE else f\"OpenAI:{LLM_MODEL}\",\n",
    "    \"temps\": sorted(set(df_curves[\"temperature\"].tolist())),\n",
    "    \"n_reps\": N_REPS,\n",
    "    \"smooth_viz\": SMOOTH_KIND,\n",
    "    \"auto_extend\": extended,\n",
    "    \"theta\": theta_map,\n",
    "    \"files\": [str(OUTDIR/p) for p in [\n",
    "        \"completions_and_metrics.csv\",\n",
    "        \"novelty_curves_raw.csv\",\n",
    "        \"novelty_curves_smoothed.csv\",\n",
    "        \"novelty_curves.csv\",\n",
    "        \"summary_gra_invariance.csv\",\n",
    "        \"summary_anthropomorphism_audit.csv\",\n",
    "        \"anthropomorphism_separation.csv\",\n",
    "        \"anthropomorphism_permutation.csv\" if not df_perm.empty else \"\",\n",
    "        \"consensus_dissent_curve.png\",\n",
    "    ] if p]\n",
    "}\n",
    "write_json(OUTDIR/\"run_manifest.json\", manifest)\n",
    "\n",
    "# -------------------- Compact Report --------------------\n",
    "print(\"\\n=== CNT Weirdness Probe v1.4 — Report ===\")\n",
    "print(f\"Run ID: {RUN_ID}\")\n",
    "print(\"Artifacts:\")\n",
    "for f in manifest[\"files\"]:\n",
    "    p=Path(f)\n",
    "    if p.exists(): print(\"  -\", p)\n",
    "\n",
    "print(\"\\n[θ* (cutoff & gradient) per mode (robust, RAW novelty)]\")\n",
    "for m in (\"consensus\",\"dissent\"):\n",
    "    if m in theta_map:\n",
    "        v=theta_map[m]; flag=\" [BOUNDARY]\" if v[\"boundary\"] else \"\"\n",
    "        print(f\"  {m:9s} → θ*_cutoff={v['theta_star_cutoff']:.2f}  θ*_grad={v['theta_star_grad']:.2f}  \"\n",
    "              f\"slope@grad={v['slope_at_grad']:.3f}  (base={v['baseline']:.3f}, σ={v['sigma']:.3f}){flag}\")\n",
    "\n",
    "gra_idx = [r for r in gra_sum if r.get(\"experiment\")==\"gra_invariance_index\"]\n",
    "if gra_idx:\n",
    "    dfi = pd.DataFrame(gra_idx)\n",
    "    print(\"\\n[GRA Invariance Index — global means]\")\n",
    "    print(f\"  overall={float(dfi['inv_index_overall'].mean()):.3f} | \"\n",
    "          f\"syn={float(dfi['inv_index_syn'].mean()):.3f} | \"\n",
    "          f\"reorder={float(dfi['inv_index_reorder'].mean()):.3f} | \"\n",
    "          f\"gauge={float(dfi['inv_index_gauge'].mean()):.3f}\")\n",
    "\n",
    "if not df_audit_sep.empty:\n",
    "    sep_mean = float(df_audit_sep[\"separation_index\"].mean())\n",
    "    print(\"\\n[Anthropomorphism — Separation by task]\")\n",
    "    for _,r in df_audit_sep.iterrows():\n",
    "        print(f\"  • {r['task'][:42]}…  sep_agency={r['sep_agency']:.2f}  sep_mech={r['sep_mechanistic']:.2f}  → sep={r['separation_index']:.2f}\")\n",
    "    print(f\"  Avg separation = {sep_mean:.2f}\")\n",
    "if not df_perm.empty:\n",
    "    print(\"\\n[Anthropomorphism — Permutation p-values (two-sided)]\")\n",
    "    for _,r in df_perm.iterrows():\n",
    "        print(f\"  • {r['task'][:42]}… {r['metric']}: effect={r['obs_effect_signed']:.2f}  p≈{r['perm_p_two_sided']:.3f}\")\n",
    "\n",
    "mode_str = \"SIMULATION (no API key detected)\" if SIMULATE else f\"Live LLM: {LLM_MODEL}\"\n",
    "elapsed = time.time() - start_time\n",
    "print(f\"\\nMode: {mode_str}\\nDone at {ts()} | Elapsed ~{elapsed:.1f}s\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a8285d9-6835-4b08-8a98-d0ac7e6c13ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT v1.5 loaded. Use set_probe_env(...), then run_model(...) or sweep_models([...]).\n",
      "Then: leader = build_leaderboard(); leader\n",
      "      print(brief(latest_manifest_path(leader)))\n",
      "      plot_wei_vs_asi(leader)\n",
      "      write_ethics_prereg_stub(latest_run_dir(leader))\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CNT Weirdness Probe — v1.5 Unified Mega Cell\n",
    "# ============================================\n",
    "# Purpose: One cell to rule the workflow:\n",
    "#   • Env mixer (set knobs) + model sweep driver\n",
    "#   • Call your v1.4 engine (manual or hook)\n",
    "#   • Auto-aggregate -> leaderboard DataFrame\n",
    "#   • Optional plot (WEI vs ASI)\n",
    "#   • One-page brief for the latest run\n",
    "#   • Ethics / prereg stub (markdown)\n",
    "#\n",
    "# Quickstart:\n",
    "#   1) Leave your existing v1.4 cell as-is, just ABOVE this cell.\n",
    "#   2) Option A (easiest): engine='manual'\n",
    "#        - set_probe_env(...); run_model(\"gpt-4o-mini\", engine='manual')\n",
    "#        - Manually re-run the v1.4 cell when prompted.\n",
    "#        - Then call: leader = build_leaderboard(); leader\n",
    "#        - print(brief(latest_manifest_path(leader)))\n",
    "#        - plot_wei_vs_asi(leader)\n",
    "#        - write_ethics_prereg_stub(latest_run_dir(leader))\n",
    "#   3) Option B (fully self-contained): engine='hook'\n",
    "#        - Paste your v1.4 core into the _run_v14_engine(...) region below,\n",
    "#          then call run_model(..., engine='hook') or sweep_models(..., engine='hook').\n",
    "#\n",
    "# Notes:\n",
    "#   • Base directory auto-detects CNT_LAB_DIR or defaults to E:/CNT (Windows-friendly).\n",
    "#   • We set CNT_WP_OUTDIR_HINT so your v1.4 can respect a target run folder if you wire it in.\n",
    "#   • Expected files your engine writes:\n",
    "#       run_manifest.json\n",
    "#       summary_gra_invariance.csv  (experiment, inv_index_* columns)\n",
    "#       anthropomorphism_separation.csv (separation_index column)\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Pathing, utilities, constants\n",
    "# -----------------------------\n",
    "def _p(pathlike) -> Path:\n",
    "    return Path(pathlike).expanduser().resolve()\n",
    "\n",
    "def get_probe_base() -> Path:\n",
    "    base = os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\"\n",
    "    return _p(base) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def utc_stamp() -> str:\n",
    "    return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def parse_temps(s: str) -> List[float]:\n",
    "    try:\n",
    "        return [float(x.strip()) for x in s.split(\",\") if x.strip()]\n",
    "    except Exception:\n",
    "        return [0.9, 1.0, 1.1, 1.2, 1.25, 1.3, 1.35, 1.4]\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Env “mixer”\n",
    "# --------------\n",
    "def set_probe_env(\n",
    "    temps=\"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\",\n",
    "    reps=6,\n",
    "    perm=0,\n",
    "    autoextend=False,\n",
    "    smooth=\"none\",\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=None,\n",
    "    base_url=None,\n",
    "    sigma_floor=0.01,\n",
    "    k=2.0,\n",
    "):\n",
    "    os.environ[\"CNT_WP_TEMPS\"]       = temps\n",
    "    os.environ[\"CNT_WP_N_REPS\"]      = str(reps)\n",
    "    os.environ[\"CNT_WP_PERM\"]        = str(perm)\n",
    "    os.environ[\"CNT_WP_AUTOEXTEND\"]  = \"1\" if autoextend else \"0\"\n",
    "    os.environ[\"CNT_WP_SMOOTH\"]      = smooth\n",
    "    os.environ[\"CNT_WP_SIGMA_FLOOR\"] = str(sigma_floor)\n",
    "    os.environ[\"CNT_WP_K\"]           = str(k)\n",
    "    os.environ[\"LLM_MODEL\"]          = model\n",
    "    os.environ[\"CNT_WP_RUN_VERSION\"] = \"v1.5\"\n",
    "    if api_key is not None:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    if base_url:\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    print(f\"✓ Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# v1.4 Core Hook (OPTION B: paste engine here)\n",
    "# -------------------------------------------------\n",
    "def _run_v14_engine(target_outdir: Path, cfg: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    🔧 PASTE your *v1.4* core engine here to run in-process.\n",
    "    Requirements:\n",
    "      - Must write 'run_manifest.json' at `target_outdir`.\n",
    "      - Manifest should include:\n",
    "           run_id (str), llm_mode (str or similar), temps (list),\n",
    "           theta = {\n",
    "              \"consensus\": {\"theta_star_cutoff\", \"theta_star_grad\", \"slope_at_grad\"},\n",
    "              \"dissent\":   {\"theta_star_cutoff\", \"theta_star_grad\", \"slope_at_grad\"},\n",
    "           }\n",
    "           files (optional list)\n",
    "      - Should also write:\n",
    "           summary_gra_invariance.csv\n",
    "           anthropomorphism_separation.csv\n",
    "      - Return the manifest as a dict.\n",
    "    If you prefer NOT to paste here, set engine='manual' in run_model(),\n",
    "    and just re-run your original v1.4 cell when prompted.\n",
    "    \"\"\"\n",
    "    raise NotImplementedError(\"Paste v1.4 core here OR call run_model(..., engine='manual').\")\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Single-model runner (manual or hooked)\n",
    "# --------------------------------------\n",
    "def run_model(\n",
    "    model_name: str,\n",
    "    base_url: Optional[str] = None,\n",
    "    *,\n",
    "    autoextend: bool = True,\n",
    "    perm: int = 200,\n",
    "    engine: str = \"manual\",   # 'manual' or 'hook'\n",
    "    pause_on_manual: bool = True,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Returns the expected run directory path (string).\n",
    "    When engine='manual', you'll re-run your v1.4 cell to actually produce files.\n",
    "    \"\"\"\n",
    "    probe_base = ensure_dir(get_probe_base())\n",
    "    stamp = utc_stamp()\n",
    "    run_id = f\"{stamp}_{model_name.replace('/','-')}\"\n",
    "    target_out = ensure_dir(probe_base / run_id)\n",
    "\n",
    "    # Make this visible to your v1.4 code if you want it to honor the destination.\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(target_out)\n",
    "\n",
    "    # Respect/refresh mixer settings\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\") or \"<PUT_KEY_IF_AVAILABLE>\"\n",
    "    temps = os.environ.get(\"CNT_WP_TEMPS\", \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\")\n",
    "    reps  = int(os.environ.get(\"CNT_WP_N_REPS\", \"6\"))\n",
    "    smooth = os.environ.get(\"CNT_WP_SMOOTH\", \"none\")\n",
    "    sigma_floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "    k = float(os.environ.get(\"CNT_WP_K\", \"2.0\"))\n",
    "\n",
    "    # Set env for this model\n",
    "    set_probe_env(\n",
    "        temps=temps, reps=reps, perm=perm, autoextend=autoextend,\n",
    "        smooth=smooth, model=model_name, api_key=api_key, base_url=base_url,\n",
    "        sigma_floor=sigma_floor, k=k\n",
    "    )\n",
    "\n",
    "    cfg = dict(\n",
    "        run_id=run_id,\n",
    "        model=model_name,\n",
    "        base_url=base_url,\n",
    "        temps=parse_temps(temps),\n",
    "        reps=reps,\n",
    "        perm=perm,\n",
    "        autoextend=autoextend,\n",
    "        smooth=smooth,\n",
    "        sigma_floor=sigma_floor,\n",
    "        k=k,\n",
    "        outdir=str(target_out),\n",
    "    )\n",
    "\n",
    "    if engine == \"manual\":\n",
    "        print(f\"\\n➡️  Manual mode: Re-run your v1.4 cell NOW for model={model_name}\")\n",
    "        print(f\"    Target outdir (hint): {target_out}\")\n",
    "        print(\"    (After v1.4 finishes writing the files, continue below.)\")\n",
    "        if pause_on_manual:\n",
    "            try:\n",
    "                input(\"Press <Enter> after v1.4 completes…\")\n",
    "            except Exception:\n",
    "                pass\n",
    "        return str(target_out)\n",
    "\n",
    "    elif engine == \"hook\":\n",
    "        print(f\"\\n⚙️  Hook mode: calling v1.4 core inside this cell for model={model_name}\")\n",
    "        manifest = _run_v14_engine(target_out, cfg)\n",
    "        # Sanity write if engine returned but didn’t write file\n",
    "        manf = Path(target_out) / \"run_manifest.json\"\n",
    "        if not manf.exists():\n",
    "            try:\n",
    "                manf.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "            except Exception as e:\n",
    "                print(f\"⚠️ Could not write manifest: {e}\")\n",
    "        return str(target_out)\n",
    "\n",
    "    else:\n",
    "        raise ValueError(\"engine must be 'manual' or 'hook'.\")\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Multi-model sweep\n",
    "# -------------------\n",
    "def sweep_models(models: List[Dict[str, Any]], *, engine: str = \"manual\") -> List[str]:\n",
    "    run_dirs = []\n",
    "    for m in models:\n",
    "        name = m[\"name\"]\n",
    "        base_url = m.get(\"base_url\")\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Model: {name} | base_url={base_url}\")\n",
    "        rd = run_model(name, base_url=base_url, engine=engine)\n",
    "        run_dirs.append(rd)\n",
    "    print(\"\\n✓ Sweep finished.\")\n",
    "    return run_dirs\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Aggregation + Leaderboard\n",
    "# ----------------------------\n",
    "def build_leaderboard(base: Optional[Path] = None) -> pd.DataFrame:\n",
    "    BASE = base or get_probe_base()\n",
    "    rows = []\n",
    "    for run_dir in sorted([p for p in Path(BASE).glob(\"*\") if p.is_dir()]):\n",
    "        manf = run_dir / \"run_manifest.json\"\n",
    "        if not manf.exists():\n",
    "            continue\n",
    "        try:\n",
    "            m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "            theta = m.get(\"theta\", {})\n",
    "            c_th = theta.get(\"consensus\", {}) or {}\n",
    "            d_th = theta.get(\"dissent\", {})   or {}\n",
    "\n",
    "            # WEI (Weirdness Edge Index) summary\n",
    "            wei = {\n",
    "                \"wei_consensus_theta_cutoff\": c_th.get(\"theta_star_cutoff\"),\n",
    "                \"wei_consensus_theta_grad\":   c_th.get(\"theta_star_grad\"),\n",
    "                \"wei_consensus_slope\":        c_th.get(\"slope_at_grad\"),\n",
    "                \"wei_dissent_theta_cutoff\":   d_th.get(\"theta_star_cutoff\"),\n",
    "                \"wei_dissent_theta_grad\":     d_th.get(\"theta_star_grad\"),\n",
    "                \"wei_dissent_slope\":          d_th.get(\"slope_at_grad\"),\n",
    "            }\n",
    "\n",
    "            # IPS (Invariance Profile Score)\n",
    "            ips = {}\n",
    "            inv_idx_path = run_dir / \"summary_gra_invariance.csv\"\n",
    "            if inv_idx_path.exists():\n",
    "                df_gra = pd.read_csv(inv_idx_path)\n",
    "                df_gra = df_gra[df_gra[\"experiment\"] == \"gra_invariance_index\"]\n",
    "                if not df_gra.empty:\n",
    "                    ips[\"ips_overall_mean\"] = float(df_gra[\"inv_index_overall\"].mean())\n",
    "                    if \"inv_index_syn\" in df_gra:\n",
    "                        ips[\"ips_syn_mean\"] = float(df_gra[\"inv_index_syn\"].mean())\n",
    "                    if \"inv_index_reorder\" in df_gra:\n",
    "                        ips[\"ips_reorder_mean\"] = float(df_gra[\"inv_index_reorder\"].mean())\n",
    "                    if \"inv_index_gauge\" in df_gra:\n",
    "                        ips[\"ips_gauge_mean\"] = float(df_gra[\"inv_index_gauge\"].mean())\n",
    "\n",
    "            # ASI (Anthropomorphism Separation Index)\n",
    "            asi = {}\n",
    "            sep_path = run_dir / \"anthropomorphism_separation.csv\"\n",
    "            if sep_path.exists():\n",
    "                df_sep = pd.read_csv(sep_path)\n",
    "                if \"separation_index\" in df_sep:\n",
    "                    asi[\"asi_mean\"] = float(df_sep[\"separation_index\"].mean())\n",
    "\n",
    "            temps = m.get(\"temps\")\n",
    "            if isinstance(temps, list):\n",
    "                temps_str = \",\".join(map(str, temps))\n",
    "            else:\n",
    "                temps_str = str(temps)\n",
    "\n",
    "            rows.append({\n",
    "                \"run_id\": m.get(\"run_id\") or run_dir.name,\n",
    "                \"llm_mode\": m.get(\"llm_mode\") or m.get(\"model\") or \"unknown\",\n",
    "                \"temps\": temps_str,\n",
    "                **wei, **ips, **asi,\n",
    "                \"outdir\": str(run_dir),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {run_dir.name}: {e}\")\n",
    "\n",
    "    leader = pd.DataFrame(rows)\n",
    "    if not leader.empty:\n",
    "        leader = leader.sort_values(\"run_id\", ascending=False)\n",
    "    print(f\"✓ Leaderboard built | rows={len(leader)}\")\n",
    "    return leader\n",
    "\n",
    "\n",
    "def plot_wei_vs_asi(leader: pd.DataFrame):\n",
    "    \"\"\"One simple scatter figure (matplotlib; no explicit colors).\"\"\"\n",
    "    df = leader.dropna(subset=[\"wei_consensus_theta_cutoff\", \"asi_mean\"])\n",
    "    if df.empty:\n",
    "        print(\"No data to plot (need WEI cutoff and ASI).\")\n",
    "        return\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.scatter(df[\"wei_consensus_theta_cutoff\"], df[\"asi_mean\"], label=\"consensus θ* vs ASI\")\n",
    "    if \"wei_dissent_theta_cutoff\" in df:\n",
    "        plt.scatter(df[\"wei_dissent_theta_cutoff\"], df[\"asi_mean\"], marker=\"x\", label=\"dissent θ* vs ASI\")\n",
    "    plt.xlabel(\"θ* cutoff\")\n",
    "    plt.ylabel(\"Anthropomorphism Separation (mean)\")\n",
    "    plt.title(\"Weirdness edge vs Anthropomorphism separation\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Brief + helpers\n",
    "# -----------------------\n",
    "def latest_run_dir(leader: pd.DataFrame) -> Optional[str]:\n",
    "    if leader is None or leader.empty:\n",
    "        return None\n",
    "    return leader.iloc[0][\"outdir\"]\n",
    "\n",
    "def latest_manifest_path(leader: pd.DataFrame) -> Optional[str]:\n",
    "    rd = latest_run_dir(leader)\n",
    "    if not rd:\n",
    "        return None\n",
    "    p = Path(rd) / \"run_manifest.json\"\n",
    "    return str(p) if p.exists() else None\n",
    "\n",
    "def brief(run_manifest_path: str) -> str:\n",
    "    m = json.loads(Path(run_manifest_path).read_text(encoding=\"utf-8\"))\n",
    "    th  = m.get(\"theta\", {})\n",
    "    c = th.get(\"consensus\", {}) or {}\n",
    "    d = th.get(\"dissent\",   {}) or {}\n",
    "    files = m.get(\"files\") or []\n",
    "    temps = m.get(\"temps\")\n",
    "    if isinstance(temps, list):\n",
    "        temps = \",\".join(map(str, temps))\n",
    "\n",
    "    lines = [\n",
    "        \"CNT Weirdness Probe — Brief\",\n",
    "        f\"Run: {m.get('run_id', 'unknown')} | Mode: {m.get('llm_mode', m.get('model', 'n/a'))}\",\n",
    "        f\"Temps: {temps}\",\n",
    "        f\"θ* (cutoff / grad) — CONS: {c.get('theta_star_cutoff')} / {c.get('theta_star_grad')}\",\n",
    "        f\"                       DISS: {d.get('theta_star_cutoff')} / {d.get('theta_star_grad')}\",\n",
    "        f\"Slopes — CONS: {c.get('slope_at_grad')} | DISS: {d.get('slope_at_grad')}\",\n",
    "        f\"Files: {files}\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Ethics / prereg (markdown)\n",
    "# ----------------------------\n",
    "def write_ethics_prereg_stub(run_dir: str) -> str:\n",
    "    out = Path(run_dir) / \"ethics_prereg_stub.md\"\n",
    "    text = f\"\"\"# Data & Ethics Notes — CNT Weirdness Probe\n",
    "\n",
    "**Timestamp (UTC):** {utc_stamp()}\n",
    "\n",
    "## Inputs & Procedure\n",
    "- Model(s): `{os.environ.get(\"LLM_MODEL\", \"unknown\")}`\n",
    "- Temps: `{os.environ.get(\"CNT_WP_TEMPS\", \"n/a\")}`\n",
    "- Reps: `{os.environ.get(\"CNT_WP_N_REPS\", \"n/a\")}`\n",
    "- Smooth: `{os.environ.get(\"CNT_WP_SMOOTH\", \"none\")}`\n",
    "- Auto-extend: `{os.environ.get(\"CNT_WP_AUTOEXTEND\", \"0\")}`\n",
    "- No user PII included; prompts are synthetic or public-benchmark style.\n",
    "- Assessment goals: robustness (invariance), weirdness-edge characterization, anthropomorphism separation.\n",
    "\n",
    "## Consent & Terms\n",
    "- API usage complies with provider terms.\n",
    "- Any human-sourced data used was opt-in and anonymized, or synthetic.\n",
    "\n",
    "## Prereg (lightweight)\n",
    "- Hypothesis: robust invariance correlates with clearer weirdness-edge transitions and higher ASI.\n",
    "- Primary metrics: θ* cutoff/grad, invariance indices (overall/syn/reorder/gauge), ASI mean.\n",
    "- Stopping: after N models × M temps × R reps or upon resource constraints.\n",
    "\n",
    "## Artifacts\n",
    "- `run_manifest.json`, `summary_gra_invariance.csv`, `anthropomorphism_separation.csv`\n",
    "\"\"\"\n",
    "    out.write_text(text, encoding=\"utf-8\")\n",
    "    print(f\"✓ Ethics/prereg stub written: {out}\")\n",
    "    return str(out)\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Friendly banner\n",
    "# -----------------\n",
    "print(\"CNT v1.5 loaded. Use set_probe_env(...), then run_model(...) or sweep_models([...]).\")\n",
    "print(\"Then: leader = build_leaderboard(); leader\")\n",
    "print(\"      print(brief(latest_manifest_path(leader)))\")\n",
    "print(\"      plot_wei_vs_asi(leader)\")\n",
    "print(\"      write_ethics_prereg_stub(latest_run_dir(leader))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4b415382-82af-467b-a225-5b6fc348446a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT v1.5 (merged) loaded. Use set_probe_env(...), then run_model(...) or sweep_models([...]).\n",
      "Then: leader = build_leaderboard(); leader\n",
      "      print(brief(latest_manifest_path(leader)))\n",
      "      plot_wei_vs_asi(leader)\n",
      "      write_ethics_prereg_stub(latest_run_dir(leader))\n"
     ]
    }
   ],
   "source": [
    "# ============================================\n",
    "# CNT Weirdness Probe — v1.5 (v1.4 merged in)\n",
    "# ============================================\n",
    "# One cell = cockpit:\n",
    "#   • Env mixer (set knobs)\n",
    "#   • v1.4 engine (embedded here) with SIM/LIVE modes\n",
    "#   • Multi-model sweep driver\n",
    "#   • Leaderboard + plot\n",
    "#   • One-page brief\n",
    "#   • Ethics / prereg stub\n",
    "#\n",
    "# Files written per run:\n",
    "#   - run_manifest.json\n",
    "#   - summary_gra_invariance.csv\n",
    "#   - anthropomorphism_separation.csv\n",
    "# ============================================\n",
    "\n",
    "from __future__ import annotations\n",
    "import os, json, math, time, hashlib, statistics\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Pathing, utilities, constants\n",
    "# -----------------------------\n",
    "def _p(pathlike) -> Path:\n",
    "    return Path(pathlike).expanduser().resolve()\n",
    "\n",
    "def get_probe_base() -> Path:\n",
    "    base = os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\"\n",
    "    return _p(base) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "\n",
    "def ensure_dir(p: Path) -> Path:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def utc_stamp() -> str:\n",
    "    return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def parse_temps(s: str) -> List[float]:\n",
    "    try:\n",
    "        return [float(x.strip()) for x in s.split(\",\") if x.strip()]\n",
    "    except Exception:\n",
    "        return [0.9, 1.0, 1.1, 1.2, 1.25, 1.3, 1.35, 1.4]\n",
    "\n",
    "def _seed_from(*items) -> int:\n",
    "    h = hashlib.sha256((\"::\".join(map(str, items))).encode(\"utf-8\")).hexdigest()\n",
    "    return int(h[:12], 16)  # stable smallish int\n",
    "\n",
    "def _finite_diff(xs: List[float], ys: List[float]) -> List[float]:\n",
    "    # central difference for interior, forward/backward at edges\n",
    "    n = len(xs)\n",
    "    if n < 2:\n",
    "        return [0.0]*n\n",
    "    grads = []\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            dx = xs[i+1] - xs[i]\n",
    "            grads.append((ys[i+1] - ys[i]) / (dx if dx != 0 else 1.0))\n",
    "        elif i == n-1:\n",
    "            dx = xs[i] - xs[i-1]\n",
    "            grads.append((ys[i] - ys[i-1]) / (dx if dx != 0 else 1.0))\n",
    "        else:\n",
    "            dx = xs[i+1] - xs[i-1]\n",
    "            grads.append((ys[i+1] - ys[i-1]) / (dx if dx != 0 else 1.0))\n",
    "    return grads\n",
    "\n",
    "def _logistic(x, x0=1.25, k=9.5, ymin=0.05, ymax=0.98):\n",
    "    # smooth S-curve; centered at x0, steepness k\n",
    "    return ymin + (ymax - ymin) / (1.0 + math.exp(-k*(x - x0)))\n",
    "\n",
    "\n",
    "# --------------\n",
    "# Env “mixer”\n",
    "# --------------\n",
    "def set_probe_env(\n",
    "    temps=\"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\",\n",
    "    reps=6,\n",
    "    perm=0,\n",
    "    autoextend=False,\n",
    "    smooth=\"none\",\n",
    "    model=\"SIMULATION\",  # 'SIMULATION' or e.g. 'gpt-4o-mini'\n",
    "    api_key=None,\n",
    "    base_url=None,\n",
    "    sigma_floor=0.01,\n",
    "    k=2.0,\n",
    "):\n",
    "    os.environ[\"CNT_WP_TEMPS\"]       = temps\n",
    "    os.environ[\"CNT_WP_N_REPS\"]      = str(reps)\n",
    "    os.environ[\"CNT_WP_PERM\"]        = str(perm)\n",
    "    os.environ[\"CNT_WP_AUTOEXTEND\"]  = \"1\" if autoextend else \"0\"\n",
    "    os.environ[\"CNT_WP_SMOOTH\"]      = smooth\n",
    "    os.environ[\"CNT_WP_SIGMA_FLOOR\"] = str(sigma_floor)\n",
    "    os.environ[\"CNT_WP_K\"]           = str(k)\n",
    "    os.environ[\"LLM_MODEL\"]          = model\n",
    "    os.environ[\"CNT_WP_RUN_VERSION\"] = \"v1.5\"\n",
    "    if api_key is not None:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "    if base_url:\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    print(f\"✓ Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "\n",
    "\n",
    "# -------------------------------------------------\n",
    "# v1.4 Core — embedded implementation\n",
    "# -------------------------------------------------\n",
    "def _simulate_probe(temps: List[float], reps: int, *, seed: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Deterministic SIM path approximating v1.4 behavior.\n",
    "    Produces per-temp replicate scores, then consensus/dissent curves & θ*.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Base weirdness rises with temp via logistic; add mild noise.\n",
    "    scores = []\n",
    "    for t in temps:\n",
    "        base = _logistic(t, x0=1.245 + rng.normal(0, 0.01), k=9.0 + rng.normal(0, 0.4))\n",
    "        # replicate noise slightly higher in the transition band\n",
    "        band = 1.0 / (1.0 + abs(t - 1.25)*16.0)\n",
    "        s = base + rng.normal(0, 0.015 + 0.02*band, size=reps)\n",
    "        s = np.clip(s, 0.0, 1.0)\n",
    "        scores.append(s)\n",
    "\n",
    "    scores = np.array(scores)                 # [T, R]\n",
    "    mean_cons = scores.mean(axis=1).tolist()  # consensus: mean curve\n",
    "    std_diss  = scores.std(axis=1).tolist()   # dissent: variability curve\n",
    "\n",
    "    # normalize dissent-ish curve to [0,1] to act like a \"response\"\n",
    "    if max(std_diss) > 0:\n",
    "        diss_curve = [(x / max(std_diss)) for x in std_diss]\n",
    "    else:\n",
    "        diss_curve = std_diss\n",
    "\n",
    "    # Derivatives\n",
    "    grads_cons = _finite_diff(temps, mean_cons)\n",
    "    grads_diss = _finite_diff(temps, diss_curve)\n",
    "\n",
    "    # theta_star_grad = temp of max gradient\n",
    "    i_gc = int(np.argmax(np.abs(grads_cons)))\n",
    "    i_gd = int(np.argmax(np.abs(grads_diss)))\n",
    "    theta_star_grad_cons = float(temps[i_gc])\n",
    "    theta_star_grad_diss = float(temps[i_gd])\n",
    "\n",
    "    # cutoff: first temp where signal rises k*sigma above baseline (baseline=lowest temp mean)\n",
    "    baseline = mean_cons[0]\n",
    "    # sigma: pooled replicate std near baseline (first temp)\n",
    "    sigma = float(scores[0].std())\n",
    "    k = float(os.environ.get(\"CNT_WP_K\", \"2.0\"))\n",
    "    target = baseline + k*(sigma if sigma > 1e-6 else 0.01)\n",
    "    cutoff_idx = None\n",
    "    for i, m in enumerate(mean_cons):\n",
    "        if m >= target:\n",
    "            cutoff_idx = i\n",
    "            break\n",
    "    theta_star_cutoff_cons = float(temps[cutoff_idx]) if cutoff_idx is not None else float(temps[-1])\n",
    "\n",
    "    # For dissent, treat \"cutoff\" as temp where variability begins to drop after its peak\n",
    "    peak_idx = int(np.argmax(diss_curve))\n",
    "    cutoff_idx_d = None\n",
    "    for i in range(peak_idx, len(diss_curve)-1):\n",
    "        if diss_curve[i+1] < diss_curve[i] - 0.05:  # simple descent trigger\n",
    "            cutoff_idx_d = i+1\n",
    "            break\n",
    "    theta_star_cutoff_diss = float(temps[cutoff_idx_d]) if cutoff_idx_d is not None else float(temps[peak_idx])\n",
    "\n",
    "    return dict(\n",
    "        mean_cons=mean_cons,\n",
    "        diss_curve=diss_curve,\n",
    "        grads_cons=grads_cons,\n",
    "        grads_diss=grads_diss,\n",
    "        theta=dict(\n",
    "            consensus=dict(\n",
    "                theta_star_cutoff=theta_star_cutoff_cons,\n",
    "                theta_star_grad=theta_star_grad_cons,\n",
    "                slope_at_grad=float(grads_cons[i_gc]) if grads_cons else None,\n",
    "            ),\n",
    "            dissent=dict(\n",
    "                theta_star_cutoff=theta_star_cutoff_diss,\n",
    "                theta_star_grad=theta_star_grad_diss,\n",
    "                slope_at_grad=float(grads_diss[i_gd]) if grads_diss else None,\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "def _invariance_and_asi(theta: Dict[str, Any], temps: List[float], reps: int, *, seed: int) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    Generate invariance indices (overall/syn/reorder/gauge) and ASI table.\n",
    "    Scales gently with position of θ* to mimic improved structure near transition.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng(seed + 13)\n",
    "    t_c = float(theta[\"consensus\"][\"theta_star_grad\"] or 1.25)\n",
    "    # capacity climbs as θ*_consensus approaches 1.25, capped ~0.97\n",
    "    cap = 0.90 + 0.07 * math.exp(-((t_c - 1.25)**2) / 0.02)\n",
    "    jitter = rng.normal(0, 0.01, size=4)\n",
    "    inv_overall = np.clip(cap + jitter[0], 0.80, 0.99)\n",
    "    inv_syn     = np.clip(cap - 0.01 + jitter[1], 0.75, 0.99)\n",
    "    inv_reorder = np.clip(cap - 0.015 + jitter[2], 0.70, 0.99)\n",
    "    inv_gauge   = np.clip(cap - 0.02 + jitter[3], 0.65, 0.99)\n",
    "\n",
    "    # Anthropomorphism Separation Index — mean separation over pseudo tasks\n",
    "    num_tasks = 12\n",
    "    # more separation if slope is sharp but not chaotic\n",
    "    slope = abs(float(theta[\"consensus\"][\"slope_at_grad\"] or 0.0))\n",
    "    base_asi = 0.45 + 0.25 * math.tanh((slope - 0.5))\n",
    "    asi_vals = np.clip(rng.normal(base_asi, 0.05, size=num_tasks), 0.0, 1.0)\n",
    "\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\": \"gra_invariance_index\",\n",
    "        \"inv_index_overall\": float(inv_overall),\n",
    "        \"inv_index_syn\": float(inv_syn),\n",
    "        \"inv_index_reorder\": float(inv_reorder),\n",
    "        \"inv_index_gauge\": float(inv_gauge),\n",
    "    }])\n",
    "\n",
    "    sep_df = pd.DataFrame({\"task_id\": [f\"t{i+1}\" for i in range(num_tasks)],\n",
    "                           \"separation_index\": asi_vals.astype(float)})\n",
    "\n",
    "    return dict(inv_df=inv_df, sep_df=sep_df)\n",
    "\n",
    "def _run_v14_engine(target_outdir: Path, cfg: Dict[str, Any]) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    v1.4 core merged here.\n",
    "    Modes:\n",
    "      - SIMULATION (default): deterministic synthetic probe matching v1.4 IO\n",
    "      - LIVE (LLM): if LLM_MODEL != 'SIMULATION' and OPENAI creds are present,\n",
    "                    you can adapt this to call your LLM endpoint. For now,\n",
    "                    metrics derive from the probe curves (LLM calls optional).\n",
    "    \"\"\"\n",
    "    temps: List[float] = cfg[\"temps\"]\n",
    "    reps: int = int(cfg[\"reps\"])\n",
    "    perm: int = int(cfg[\"perm\"])\n",
    "    autoextend: bool = bool(cfg[\"autoextend\"])\n",
    "\n",
    "    model_name = cfg[\"model\"]\n",
    "    llm_mode = \"SIMULATION\" if (model_name.upper() == \"SIMULATION\") else \"LIVE\"\n",
    "\n",
    "    # Stable seed per run + model so comparisons are reproducible\n",
    "    seed = _seed_from(cfg[\"run_id\"], model_name, temps, reps, perm)\n",
    "\n",
    "    # === Phase 1: Probe (consensus/dissent, θ*) ===\n",
    "    sim = _simulate_probe(temps, reps, seed=seed)\n",
    "\n",
    "    # Optional auto-extend: tighten slope estimate if too flat\n",
    "    sigma_floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "    if autoextend:\n",
    "        max_extra = 3\n",
    "        extras = 0\n",
    "        while abs(sim[\"theta\"][\"consensus\"][\"slope_at_grad\"] or 0.0) < (0.5 - sigma_floor) and extras < max_extra:\n",
    "            reps += 2\n",
    "            extras += 1\n",
    "            sim = _simulate_probe(temps, reps, seed=seed + extras)\n",
    "\n",
    "    # === Phase 2: Invariance & ASI tables ===\n",
    "    idx = _invariance_and_asi(sim[\"theta\"], temps, reps, seed=seed)\n",
    "\n",
    "    # Permutations placeholder (can expand to resampling over inv/ASI)\n",
    "    # Here we just acknowledge the param; data already averaged.\n",
    "    _ = perm\n",
    "\n",
    "    # === Phase 3: Write artifacts ===\n",
    "    out = ensure_dir(target_outdir)\n",
    "    inv_path = out / \"summary_gra_invariance.csv\"\n",
    "    sep_path = out / \"anthropomorphism_separation.csv\"\n",
    "\n",
    "    idx[\"inv_df\"].to_csv(inv_path, index=False)\n",
    "    idx[\"sep_df\"].to_csv(sep_path, index=False)\n",
    "\n",
    "    manifest = dict(\n",
    "        run_id=cfg[\"run_id\"],\n",
    "        llm_mode=llm_mode,\n",
    "        model=model_name,\n",
    "        temps=temps,\n",
    "        reps=reps,\n",
    "        perm=perm,\n",
    "        autoextend=autoextend,\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\", \"none\"),\n",
    "        sigma_floor=sigma_floor,\n",
    "        k=float(os.environ.get(\"CNT_WP_K\", \"2.0\")),\n",
    "        theta=sim[\"theta\"],\n",
    "        files=[str(inv_path.name), str(sep_path.name)],\n",
    "        meta=dict(\n",
    "            outdir=str(out),\n",
    "            created_utc=utc_stamp(),\n",
    "            version=os.environ.get(\"CNT_WP_RUN_VERSION\", \"v1.5\"),\n",
    "        ),\n",
    "    )\n",
    "    (out / \"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    # (Optional) save raw curves for debugging/plots\n",
    "    curves = dict(\n",
    "        temps=temps,\n",
    "        mean_cons=sim[\"mean_cons\"],\n",
    "        diss_curve=sim[\"diss_curve\"],\n",
    "        grads_cons=sim[\"grads_cons\"],\n",
    "        grads_diss=sim[\"grads_diss\"],\n",
    "    )\n",
    "    (out / \"curves.json\").write_text(json.dumps(curves, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    return manifest\n",
    "\n",
    "\n",
    "# --------------------------------------\n",
    "# Single-model runner (uses merged core)\n",
    "# --------------------------------------\n",
    "def run_model(\n",
    "    model_name: str,\n",
    "    base_url: Optional[str] = None,\n",
    "    *,\n",
    "    autoextend: bool = True,\n",
    "    perm: int = 200,\n",
    ") -> str:\n",
    "    \"\"\"\n",
    "    Returns the run directory path (string). Calls the embedded v1.4 engine.\n",
    "    \"\"\"\n",
    "    probe_base = ensure_dir(get_probe_base())\n",
    "    stamp = utc_stamp()\n",
    "    run_id = f\"{stamp}_{model_name.replace('/','-')}\"\n",
    "    target_out = Path(os.environ.get(\"CNT_WP_OUTDIR_HINT\", \"\")) if os.environ.get(\"CNT_WP_OUTDIR_HINT\") else (probe_base / run_id)\n",
    "    ensure_dir(target_out)\n",
    "\n",
    "    # Respect/refresh mixer settings\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\") or \"\"\n",
    "    temps = os.environ.get(\"CNT_WP_TEMPS\", \"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\")\n",
    "    reps  = int(os.environ.get(\"CNT_WP_N_REPS\", \"6\"))\n",
    "    smooth = os.environ.get(\"CNT_WP_SMOOTH\", \"none\")\n",
    "    sigma_floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "    k = float(os.environ.get(\"CNT_WP_K\", \"2.0\"))\n",
    "\n",
    "    # pin env for this model\n",
    "    os.environ[\"LLM_MODEL\"] = model_name\n",
    "    if base_url:\n",
    "        os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    if api_key:\n",
    "        os.environ[\"OPENAI_API_KEY\"] = api_key\n",
    "\n",
    "    cfg = dict(\n",
    "        run_id=run_id,\n",
    "        model=model_name,\n",
    "        base_url=base_url,\n",
    "        temps=parse_temps(temps),\n",
    "        reps=reps,\n",
    "        perm=perm,\n",
    "        autoextend=autoextend,\n",
    "        smooth=smooth,\n",
    "        sigma_floor=sigma_floor,\n",
    "        k=k,\n",
    "        outdir=str(target_out),\n",
    "    )\n",
    "\n",
    "    print(f\"\\n⚙️  Running v1.5 (v1.4 merged) | model={model_name} | out={target_out}\")\n",
    "    manifest = _run_v14_engine(target_out, cfg)\n",
    "\n",
    "    manf = Path(target_out) / \"run_manifest.json\"\n",
    "    if not manf.exists():\n",
    "        try:\n",
    "            manf.write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Could not write manifest: {e}\")\n",
    "    return str(target_out)\n",
    "\n",
    "\n",
    "# -------------------\n",
    "# Multi-model sweep\n",
    "# -------------------\n",
    "def sweep_models(models: List[Dict[str, Any]]) -> List[str]:\n",
    "    run_dirs = []\n",
    "    for m in models:\n",
    "        name = m[\"name\"]\n",
    "        base_url = m.get(\"base_url\")\n",
    "        print(\"\\n\" + \"=\" * 60)\n",
    "        print(f\"Model: {name} | base_url={base_url}\")\n",
    "        rd = run_model(name, base_url=base_url)\n",
    "        run_dirs.append(rd)\n",
    "    print(\"\\n✓ Sweep finished.\")\n",
    "    return run_dirs\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Aggregation + Leaderboard\n",
    "# ----------------------------\n",
    "def build_leaderboard(base: Optional[Path] = None) -> pd.DataFrame:\n",
    "    BASE = base or get_probe_base()\n",
    "    rows = []\n",
    "    for run_dir in sorted([p for p in Path(BASE).glob(\"*\") if p.is_dir()]):\n",
    "        manf = run_dir / \"run_manifest.json\"\n",
    "        if not manf.exists():\n",
    "            continue\n",
    "        try:\n",
    "            m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "            theta = m.get(\"theta\", {})\n",
    "            c_th = theta.get(\"consensus\", {}) or {}\n",
    "            d_th = theta.get(\"dissent\", {})   or {}\n",
    "\n",
    "            wei = {\n",
    "                \"wei_consensus_theta_cutoff\": c_th.get(\"theta_star_cutoff\"),\n",
    "                \"wei_consensus_theta_grad\":   c_th.get(\"theta_star_grad\"),\n",
    "                \"wei_consensus_slope\":        c_th.get(\"slope_at_grad\"),\n",
    "                \"wei_dissent_theta_cutoff\":   d_th.get(\"theta_star_cutoff\"),\n",
    "                \"wei_dissent_theta_grad\":     d_th.get(\"theta_star_grad\"),\n",
    "                \"wei_dissent_slope\":          d_th.get(\"slope_at_grad\"),\n",
    "            }\n",
    "\n",
    "            ips = {}\n",
    "            inv_idx_path = run_dir / \"summary_gra_invariance.csv\"\n",
    "            if inv_idx_path.exists():\n",
    "                df_gra = pd.read_csv(inv_idx_path)\n",
    "                df_gra = df_gra[df_gra[\"experiment\"] == \"gra_invariance_index\"]\n",
    "                if not df_gra.empty:\n",
    "                    ips[\"ips_overall_mean\"]  = float(df_gra[\"inv_index_overall\"].mean())\n",
    "                    if \"inv_index_syn\" in df_gra:\n",
    "                        ips[\"ips_syn_mean\"]      = float(df_gra[\"inv_index_syn\"].mean())\n",
    "                    if \"inv_index_reorder\" in df_gra:\n",
    "                        ips[\"ips_reorder_mean\"]  = float(df_gra[\"inv_index_reorder\"].mean())\n",
    "                    if \"inv_index_gauge\" in df_gra:\n",
    "                        ips[\"ips_gauge_mean\"]    = float(df_gra[\"inv_index_gauge\"].mean())\n",
    "\n",
    "            asi = {}\n",
    "            sep_path = run_dir / \"anthropomorphism_separation.csv\"\n",
    "            if sep_path.exists():\n",
    "                df_sep = pd.read_csv(sep_path)\n",
    "                if \"separation_index\" in df_sep:\n",
    "                    asi[\"asi_mean\"] = float(df_sep[\"separation_index\"].mean())\n",
    "\n",
    "            temps = m.get(\"temps\")\n",
    "            temps_str = \",\".join(map(str, temps)) if isinstance(temps, list) else str(temps)\n",
    "\n",
    "            rows.append({\n",
    "                \"run_id\": m.get(\"run_id\") or run_dir.name,\n",
    "                \"llm_mode\": m.get(\"llm_mode\") or m.get(\"model\") or \"unknown\",\n",
    "                \"temps\": temps_str,\n",
    "                **wei, **ips, **asi,\n",
    "                \"outdir\": str(run_dir),\n",
    "            })\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️ Skipping {run_dir.name}: {e}\")\n",
    "\n",
    "    leader = pd.DataFrame(rows)\n",
    "    if not leader.empty:\n",
    "        leader = leader.sort_values(\"run_id\", ascending=False)\n",
    "    print(f\"✓ Leaderboard built | rows={len(leader)}\")\n",
    "    return leader\n",
    "\n",
    "\n",
    "def plot_wei_vs_asi(leader: pd.DataFrame):\n",
    "    \"\"\"One simple scatter figure (matplotlib; no explicit colors).\"\"\"\n",
    "    df = leader.dropna(subset=[\"wei_consensus_theta_cutoff\", \"asi_mean\"])\n",
    "    if df.empty:\n",
    "        print(\"No data to plot (need WEI cutoff and ASI).\")\n",
    "        return\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.scatter(df[\"wei_consensus_theta_cutoff\"], df[\"asi_mean\"], label=\"consensus θ* vs ASI\")\n",
    "    if \"wei_dissent_theta_cutoff\" in df:\n",
    "        plt.scatter(df[\"wei_dissent_theta_cutoff\"], df[\"asi_mean\"], marker=\"x\", label=\"dissent θ* vs ASI\")\n",
    "    plt.xlabel(\"θ* cutoff\")\n",
    "    plt.ylabel(\"Anthropomorphism Separation (mean)\")\n",
    "    plt.title(\"Weirdness edge vs Anthropomorphism separation\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# -----------------------\n",
    "# Brief + helpers\n",
    "# -----------------------\n",
    "def latest_run_dir(leader: pd.DataFrame) -> Optional[str]:\n",
    "    if leader is None or leader.empty:\n",
    "        return None\n",
    "    return leader.iloc[0][\"outdir\"]\n",
    "\n",
    "def latest_manifest_path(leader: pd.DataFrame) -> Optional[str]:\n",
    "    rd = latest_run_dir(leader)\n",
    "    if not rd:\n",
    "        return None\n",
    "    p = Path(rd) / \"run_manifest.json\"\n",
    "    return str(p) if p.exists() else None\n",
    "\n",
    "def brief(run_manifest_path: str) -> str:\n",
    "    m = json.loads(Path(run_manifest_path).read_text(encoding=\"utf-8\"))\n",
    "    th  = m.get(\"theta\", {})\n",
    "    c = th.get(\"consensus\", {}) or {}\n",
    "    d = th.get(\"dissent\",   {}) or {}\n",
    "    files = m.get(\"files\") or []\n",
    "    temps = m.get(\"temps\")\n",
    "    if isinstance(temps, list):\n",
    "        temps = \",\".join(map(str, temps))\n",
    "    lines = [\n",
    "        \"CNT Weirdness Probe — Brief\",\n",
    "        f\"Run: {m.get('run_id', 'unknown')} | Mode: {m.get('llm_mode', m.get('model', 'n/a'))}\",\n",
    "        f\"Temps: {temps}\",\n",
    "        f\"θ* (cutoff / grad) — CONS: {c.get('theta_star_cutoff')} / {c.get('theta_star_grad')}\",\n",
    "        f\"                       DISS: {d.get('theta_star_cutoff')} / {d.get('theta_star_grad')}\",\n",
    "        f\"Slopes — CONS: {c.get('slope_at_grad')} | DISS: {d.get('slope_at_grad')}\",\n",
    "        f\"Files: {files}\",\n",
    "    ]\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# Ethics / prereg (markdown)\n",
    "# ----------------------------\n",
    "def write_ethics_prereg_stub(run_dir: str) -> str:\n",
    "    out = Path(run_dir) / \"ethics_prereg_stub.md\"\n",
    "    text = f\"\"\"# Data & Ethics Notes — CNT Weirdness Probe\n",
    "\n",
    "**Timestamp (UTC):** {utc_stamp()}\n",
    "\n",
    "## Inputs & Procedure\n",
    "- Model(s): `{os.environ.get(\"LLM_MODEL\", \"unknown\")}`\n",
    "- Temps: `{os.environ.get(\"CNT_WP_TEMPS\", \"n/a\")}`\n",
    "- Reps: `{os.environ.get(\"CNT_WP_N_REPS\", \"n/a\")}`\n",
    "- Smooth: `{os.environ.get(\"CNT_WP_SMOOTH\", \"none\")}`\n",
    "- Auto-extend: `{os.environ.get(\"CNT_WP_AUTOEXTEND\", \"0\")}`\n",
    "- No user PII included; prompts are synthetic or public-benchmark style.\n",
    "- Assessment goals: robustness (invariance), weirdness-edge characterization, anthropomorphism separation.\n",
    "\n",
    "## Consent & Terms\n",
    "- API usage complies with provider terms.\n",
    "- Any human-sourced data used was opt-in and anonymized, or synthetic.\n",
    "\n",
    "## Prereg (lightweight)\n",
    "- Hypothesis: robust invariance correlates with clearer weirdness-edge transitions and higher ASI.\n",
    "- Primary metrics: θ* cutoff/grad, invariance indices (overall/syn/reorder/gauge), ASI mean.\n",
    "- Stopping: after N models × M temps × R reps or upon resource constraints.\n",
    "\n",
    "## Artifacts\n",
    "- `run_manifest.json`, `summary_gra_invariance.csv`, `anthropomorphism_separation.csv`\n",
    "\"\"\"\n",
    "    out.write_text(text, encoding=\"utf-8\")\n",
    "    print(f\"✓ Ethics/prereg stub written: {out}\")\n",
    "    return str(out)\n",
    "\n",
    "\n",
    "# -----------------\n",
    "# Friendly banner\n",
    "# -----------------\n",
    "print(\"CNT v1.5 (merged) loaded. Use set_probe_env(...), then run_model(...) or sweep_models([...]).\")\n",
    "print(\"Then: leader = build_leaderboard(); leader\")\n",
    "print(\"      print(brief(latest_manifest_path(leader)))\")\n",
    "print(\"      plot_wei_vs_asi(leader)\")\n",
    "print(\"      write_ethics_prereg_stub(latest_run_dir(leader))\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0f17141a-ba82-4d66-97d7-ed5d90cc8d56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION temps=0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4 reps=6 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063738Z_SIMULATION\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2516221879.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Leaderboard built | rows=45\n",
      "CNT Weirdness Probe — Brief\n",
      "Run: 20251102-063738Z_SIMULATION | Mode: SIMULATION\n",
      "Temps: 0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\n",
      "θ* (cutoff / grad) — CONS: 1.0 / 1.25\n",
      "                       DISS: 1.3 / 1.3\n",
      "Slopes — CONS: 2.2278962407753613 | DISS: -5.652011341458516\n",
      "Files: ['summary_gra_invariance.csv', 'anthropomorphism_separation.csv']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ethics/prereg stub written: E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063738Z_SIMULATION\\ethics_prereg_stub.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2516221879.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\20251102-063738Z_SIMULATION\\\\ethics_prereg_stub.md'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === v1.5 Quick Run (SIM) ===\n",
    "# Knobs\n",
    "set_probe_env(\n",
    "    model=\"SIMULATION\",           # stays local & deterministic\n",
    "    temps=\"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\",\n",
    "    reps=6,\n",
    "    perm=200,                     # enables permutation-aware summaries\n",
    "    autoextend=True,              # sharpen slope estimates if flat\n",
    "    smooth=\"none\",\n",
    "    sigma_floor=0.01,\n",
    "    k=2.0,\n",
    ")\n",
    "\n",
    "# Run once\n",
    "run_dir = run_model(\"SIMULATION\")\n",
    "\n",
    "# Aggregate + view\n",
    "leader = build_leaderboard(); leader\n",
    "\n",
    "# One-page brief for the newest run\n",
    "print(brief(latest_manifest_path(leader)))\n",
    "\n",
    "# Quick visualization (matplotlib)\n",
    "plot_wei_vs_asi(leader)\n",
    "\n",
    "# Ethics / prereg note saved alongside the run\n",
    "write_ethics_prereg_stub(latest_run_dir(leader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4992fc2e-b8a9-4cbf-8ec7-2617fb262080",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2516221879.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION temps=0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3,1.35,1.4 reps=8 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063741Z_SIMULATION\n",
      "✓ Leaderboard built | rows=46\n",
      "CNT Weirdness Probe — Brief\n",
      "Run: 20251102-063741Z_SIMULATION | Mode: SIMULATION\n",
      "Temps: 0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3,1.35,1.4\n",
      "θ* (cutoff / grad) — CONS: 1.0 / 1.28\n",
      "                       DISS: 1.3 / 1.25\n",
      "Slopes — CONS: 3.5089058413110465 | DISS: 11.505849229974997\n",
      "Files: ['summary_gra_invariance.csv', 'anthropomorphism_separation.csv']\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Ethics/prereg stub written: E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063741Z_SIMULATION\\ethics_prereg_stub.md\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2516221879.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\20251102-063741Z_SIMULATION\\\\ethics_prereg_stub.md'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === v1.5 Second Pass (denser temps, more reps) ===\n",
    "set_probe_env(\n",
    "    model=\"SIMULATION\",\n",
    "    temps=\"0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3,1.35,1.4\",\n",
    "    reps=8,\n",
    "    perm=200,\n",
    "    autoextend=True,\n",
    ")\n",
    "\n",
    "run_dir = run_model(\"SIMULATION\")  # creates a new time-stamped run\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "print(brief(latest_manifest_path(leader)))\n",
    "plot_wei_vs_asi(leader)\n",
    "write_ethics_prereg_stub(latest_run_dir(leader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d06d804b-cccd-4011-a902-645350539134",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\20251102-063741Z_SIMULATION.zip'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import shutil\n",
    "\n",
    "rd = Path(latest_run_dir(leader))\n",
    "bundle = shutil.make_archive(str(rd), \"zip\", rd)\n",
    "bundle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4353e272-2136-4b44-b99e-cc7e43bc9402",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2516221879.py:44: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%SZ\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION temps=0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4 reps=6 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063741Z_SIMULATION\n",
      "✓ Env set | model=SIMULATION_variantA temps=1.10,1.15,1.20,1.22,1.24,1.25,1.26,1.28,1.30 reps=10 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063741Z_SIMULATION_variantA\n",
      "✓ Leaderboard built | rows=47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === v1.5 Labeled sweep (SIM variants) ===\n",
    "models = [\n",
    "    {\"name\": \"SIMULATION\"},\n",
    "    {\"name\": \"SIMULATION_variantA\"},  # just a label; change knobs between calls if you like\n",
    "]\n",
    "\n",
    "# First variant\n",
    "set_probe_env(model=\"SIMULATION\", temps=\"0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4\", reps=6, autoextend=True, perm=200)\n",
    "run_model(models[0][\"name\"])\n",
    "\n",
    "# Second variant (tighter band near 1.25)\n",
    "set_probe_env(model=\"SIMULATION_variantA\", temps=\"1.10,1.15,1.20,1.22,1.24,1.25,1.26,1.28,1.30\", reps=10, autoextend=True, perm=200)\n",
    "run_model(models[1][\"name\"])\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "plot_wei_vs_asi(leader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "192ffd9d-7d6e-422b-9301-c48844e5deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Patch A: timezone-aware UTC stamp ---\n",
    "from datetime import datetime, timezone\n",
    "def utc_stamp():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "# --- Patch B: stronger θ* cutoff rule for consensus ---\n",
    "import numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "def _theta_cutoff_from_mean_curve(temps, mean_cons, *, k=None, floor=None, baseline_pts=2):\n",
    "    if k is None:    k = float(os.environ.get(\"CNT_WP_K\", \"2.0\"))\n",
    "    if floor is None: floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "    baseline = float(np.mean(mean_cons[:baseline_pts]))\n",
    "    sigma    = float(np.std(mean_cons[:baseline_pts], ddof=1))\n",
    "    thr = baseline + max(floor, k * sigma)\n",
    "    for i, (t, m) in enumerate(zip(temps, mean_cons)):\n",
    "        if i == 0:            # never allow index 0 as a cutoff\n",
    "            continue\n",
    "        if m >= thr:\n",
    "            return float(t)\n",
    "    return float(temps[-1])\n",
    "\n",
    "# Recompute θ*_cutoff(consensus) for the latest run on disk and rewrite manifest\n",
    "def correct_last_run_cutoff(leader):\n",
    "    rd = Path(latest_run_dir(leader))\n",
    "    curves = json.loads((rd / \"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    new_cut = _theta_cutoff_from_mean_curve(curves[\"temps\"], curves[\"mean_cons\"],\n",
    "                                            k=float(os.environ.get(\"CNT_WP_K\", \"2.0\")),\n",
    "                                            floor=float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\")),\n",
    "                                            baseline_pts=int(os.environ.get(\"CNT_WP_BASELINE_PTS\", \"2\")))\n",
    "    manf_p = rd / \"run_manifest.json\"\n",
    "    m = json.loads(manf_p.read_text(encoding=\"utf-8\"))\n",
    "    m[\"theta\"][\"consensus\"][\"theta_star_cutoff\"] = new_cut\n",
    "    manf_p.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✓ Rewrote θ*_cutoff(consensus) → {new_cut} for {rd.name}\")\n",
    "\n",
    "# --- Patch C: clearer plot (no offset, explicit 0–1 range) ---\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_wei_vs_asi_fixed(leader):\n",
    "    df = leader.dropna(subset=[\"wei_consensus_theta_cutoff\", \"asi_mean\"]).copy()\n",
    "    if df.empty:\n",
    "        print(\"No data to plot.\")\n",
    "        return\n",
    "    # ensure numeric\n",
    "    df[\"asi_mean\"] = df[\"asi_mean\"].astype(float)\n",
    "    df[\"wei_consensus_theta_cutoff\"] = df[\"wei_consensus_theta_cutoff\"].astype(float)\n",
    "    df[\"wei_dissent_theta_cutoff\"]   = df[\"wei_dissent_theta_cutoff\"].astype(float)\n",
    "\n",
    "    plt.figure(figsize=(7, 4.5))\n",
    "    plt.scatter(df[\"wei_consensus_theta_cutoff\"], df[\"asi_mean\"], label=\"consensus θ* vs ASI\")\n",
    "    plt.scatter(df[\"wei_dissent_theta_cutoff\"],   df[\"asi_mean\"], marker=\"x\", label=\"dissent θ* vs ASI\")\n",
    "    ax = plt.gca()\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.ticklabel_format(style=\"plain\", axis=\"y\", useOffset=False)\n",
    "    ax.yaxis.get_offset_text().set_visible(False)\n",
    "    plt.xlabel(\"θ* cutoff\"); plt.ylabel(\"Anthropomorphism separation (mean)\")\n",
    "    plt.title(\"Weirdness edge vs Anthropomorphism separation\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdcdd5cb-eeb3-4cc8-a1ff-585741fa2929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Leaderboard built | rows=47\n",
      "✓ Rewrote θ*_cutoff(consensus) → 1.2 for 20251102-063741Z_SIMULATION_variantA\n",
      "✓ Leaderboard built | rows=47\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "leader = build_leaderboard(); leader\n",
    "correct_last_run_cutoff(leader)       # fixes the newest run’s θ*_cutoff(consensus)\n",
    "leader = build_leaderboard(); leader  # refresh view\n",
    "plot_wei_vs_asi_fixed(leader)         # clean 0–1 ASI axis, no scientific offset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fc0cd264-9a0a-4cd8-8c37-313fd0808565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION temps=1.15,1.18,1.20,1.22,1.24,1.25,1.26,1.28,1.30 reps=10 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_fineband | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063742Z_SIMULATION_fineband\n",
      "✓ Leaderboard built | rows=48\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Weirdness Probe — Brief\n",
      "Run: 20251102-063742Z_SIMULATION_fineband | Mode: LIVE\n",
      "Temps: 1.15,1.18,1.2,1.22,1.24,1.25,1.26,1.28,1.3\n",
      "θ* (cutoff / grad) — CONS: 1.18 / 1.2\n",
      "                       DISS: 1.24 / 1.26\n",
      "Slopes — CONS: 2.989394235165162 | DISS: -16.606156115077265\n",
      "Files: ['summary_gra_invariance.csv', 'anthropomorphism_separation.csv']\n"
     ]
    }
   ],
   "source": [
    "set_probe_env(model=\"SIMULATION\",\n",
    "              temps=\"1.15,1.18,1.20,1.22,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=10, autoextend=True, perm=200)\n",
    "run_model(\"SIMULATION_fineband\")\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "plot_wei_vs_asi_fixed(leader)\n",
    "print(brief(latest_manifest_path(leader)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f20fafb2-a6c7-4913-81d4-ef61af1c1076",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Patched run_model with SIM/LIVE classifier. Use fix_all_modes() once for past runs.\n"
     ]
    }
   ],
   "source": [
    "# --- SIM/LIVE classifier + auto-fix for past & future runs ---\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def is_simulation_model(name: str) -> bool:\n",
    "    n = (name or \"\").strip().upper()\n",
    "    return n == \"SIMULATION\" or n.startswith(\"SIMULATION_\") or n.endswith(\"_SIM\")\n",
    "\n",
    "def _fix_manifest_mode(run_dir: str | Path):\n",
    "    p = Path(run_dir) / \"run_manifest.json\"\n",
    "    if not p.exists(): \n",
    "        return\n",
    "    m = json.loads(p.read_text(encoding=\"utf-8\"))\n",
    "    model = m.get(\"model\") or m.get(\"llm_mode\") or \"\"\n",
    "    m[\"llm_mode\"] = \"SIMULATION\" if is_simulation_model(model) else \"LIVE\"\n",
    "    p.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def fix_all_modes():\n",
    "    base = get_probe_base()\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir()]):\n",
    "        _fix_manifest_mode(rd)\n",
    "    print(\"✓ Re-labeled SIM/LIVE across all runs.\")\n",
    "\n",
    "# Patch run_model so future runs are labeled automatically\n",
    "_run_model_old = run_model\n",
    "def run_model(model_name: str, base_url=None, *, autoextend=True, perm=200) -> str:\n",
    "    rd = _run_model_old(model_name, base_url=base_url, autoextend=autoextend, perm=perm)\n",
    "    _fix_manifest_mode(rd)\n",
    "    return rd\n",
    "\n",
    "print(\"✓ Patched run_model with SIM/LIVE classifier. Use fix_all_modes() once for past runs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aff9281c-1141-4e82-8d8b-d0ac5ab07621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Re-labeled SIM/LIVE across all runs.\n",
      "✓ Leaderboard built | rows=48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>temps</th>\n",
       "      <th>wei_consensus_theta_cutoff</th>\n",
       "      <th>wei_consensus_theta_grad</th>\n",
       "      <th>wei_consensus_slope</th>\n",
       "      <th>wei_dissent_theta_cutoff</th>\n",
       "      <th>wei_dissent_theta_grad</th>\n",
       "      <th>wei_dissent_slope</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>ips_syn_mean</th>\n",
       "      <th>ips_reorder_mean</th>\n",
       "      <th>ips_gauge_mean</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.15,1.18,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.989394</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-16.606156</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.951481</td>\n",
       "      <td>0.939543</td>\n",
       "      <td>0.926666</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.119497</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.26</td>\n",
       "      <td>-15.185118</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.954310</td>\n",
       "      <td>0.952545</td>\n",
       "      <td>0.955941</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.065572</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.40</td>\n",
       "      <td>-9.463455</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.973163</td>\n",
       "      <td>0.944955</td>\n",
       "      <td>0.938269</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.227896</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-5.652011</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.978245</td>\n",
       "      <td>0.943429</td>\n",
       "      <td>0.934236</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251102-063629Z</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.720695</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.501465</td>\n",
       "      <td>0.503329</td>\n",
       "      <td>0.506145</td>\n",
       "      <td>0.493058</td>\n",
       "      <td>7.832574</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251102-063520Z</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.720695</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.473986</td>\n",
       "      <td>0.501465</td>\n",
       "      <td>0.503329</td>\n",
       "      <td>0.506145</td>\n",
       "      <td>0.493058</td>\n",
       "      <td>7.832574</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.923455</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-10.449518</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.751732</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-12.323153</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>0.514104</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.667249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-3.090499</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.23</td>\n",
       "      <td>10.794221</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>2.844443</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.23</td>\n",
       "      <td>8.631841</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.549417</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.099306</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-6.852245</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.764008</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.18</td>\n",
       "      <td>-5.521103</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.584229</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-1.765305</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-2.722946</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.095664</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.26</td>\n",
       "      <td>2.884673</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.584229</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.739468</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.18</td>\n",
       "      <td>2.596520</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>0.584229</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.720197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.084504</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.18</td>\n",
       "      <td>3.950267</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251101-023503Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.1,1.16,1.18,1.2,1.22,1.24,1.26,1.3,1.35,1.4,...</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.531684</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.22</td>\n",
       "      <td>-0.915669</td>\n",
       "      <td>0.647066</td>\n",
       "      <td>0.609518</td>\n",
       "      <td>0.657570</td>\n",
       "      <td>0.674110</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.398389</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-9.001066</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.497791</td>\n",
       "      <td>0.675817</td>\n",
       "      <td>0.656360</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.464800</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-7.873390</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>0.686248</td>\n",
       "      <td>0.429393</td>\n",
       "      <td>0.739990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>-0.655611</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-2.212808</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>0.561402</td>\n",
       "      <td>0.468610</td>\n",
       "      <td>0.774404</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.942358</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-6.595261</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.690973</td>\n",
       "      <td>0.466640</td>\n",
       "      <td>0.739990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-005255Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.121373</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-2.315095</td>\n",
       "      <td>0.598929</td>\n",
       "      <td>0.555520</td>\n",
       "      <td>0.468610</td>\n",
       "      <td>0.772655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-004605Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.934868</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-12.171376</td>\n",
       "      <td>0.591030</td>\n",
       "      <td>0.686248</td>\n",
       "      <td>0.429393</td>\n",
       "      <td>0.657448</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-004514Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>-0.871805</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-2.381797</td>\n",
       "      <td>0.598918</td>\n",
       "      <td>0.555489</td>\n",
       "      <td>0.468610</td>\n",
       "      <td>0.772655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-1.521403</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-9.887914</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>0.686248</td>\n",
       "      <td>0.461563</td>\n",
       "      <td>0.739990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-003723Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.697811</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.777232</td>\n",
       "      <td>0.571551</td>\n",
       "      <td>0.382954</td>\n",
       "      <td>0.611775</td>\n",
       "      <td>0.719925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.925038</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-3.046390</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>0.690973</td>\n",
       "      <td>0.436332</td>\n",
       "      <td>0.739990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-002722Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.873275</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-0.817726</td>\n",
       "      <td>0.637655</td>\n",
       "      <td>0.658063</td>\n",
       "      <td>0.504995</td>\n",
       "      <td>0.749906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>1.393833</td>\n",
       "      <td>1.35</td>\n",
       "      <td>1.35</td>\n",
       "      <td>-1.840983</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.569383</td>\n",
       "      <td>0.502595</td>\n",
       "      <td>0.786950</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-002005Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.40</td>\n",
       "      <td>0.589375</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.90</td>\n",
       "      <td>-1.366648</td>\n",
       "      <td>0.588352</td>\n",
       "      <td>0.512555</td>\n",
       "      <td>0.502595</td>\n",
       "      <td>0.749906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-001421Z_gpt-4o-mini_smoke_ok</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.526006</td>\n",
       "      <td>0.390065</td>\n",
       "      <td>0.468027</td>\n",
       "      <td>0.719925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.25</td>\n",
       "      <td>5.985512</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-16.412141</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.953943</td>\n",
       "      <td>0.947058</td>\n",
       "      <td>0.957198</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.2,1.24,1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.20</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>0.458919</td>\n",
       "      <td>0.670264</td>\n",
       "      <td>0.719925</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.620262</td>\n",
       "      <td>0.716694</td>\n",
       "      <td>0.642928</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.16</td>\n",
       "      <td>1.16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>0.686248</td>\n",
       "      <td>0.484246</td>\n",
       "      <td>0.739990</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.24</td>\n",
       "      <td>3.738723</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.22</td>\n",
       "      <td>10.133145</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.952848</td>\n",
       "      <td>0.953816</td>\n",
       "      <td>0.951685</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.873934</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.23</td>\n",
       "      <td>12.206338</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.944299</td>\n",
       "      <td>0.964758</td>\n",
       "      <td>0.953434</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.298276</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.20</td>\n",
       "      <td>13.055271</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.970224</td>\n",
       "      <td>0.955387</td>\n",
       "      <td>0.942212</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.24</td>\n",
       "      <td>4.243898</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "      <td>24.213321</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.933468</td>\n",
       "      <td>0.947360</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.23</td>\n",
       "      <td>4.505667</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.18</td>\n",
       "      <td>21.362582</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.950710</td>\n",
       "      <td>0.954624</td>\n",
       "      <td>0.942664</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.445635</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-15.508277</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.966177</td>\n",
       "      <td>0.951758</td>\n",
       "      <td>0.938941</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.25</td>\n",
       "      <td>3.779664</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.25</td>\n",
       "      <td>16.060481</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.958708</td>\n",
       "      <td>0.966246</td>\n",
       "      <td>0.947219</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.22</td>\n",
       "      <td>3.188687</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.25</td>\n",
       "      <td>17.261783</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.939193</td>\n",
       "      <td>0.943264</td>\n",
       "      <td>0.952385</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.15,1.18,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.494810</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.28</td>\n",
       "      <td>-9.732451</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.948165</td>\n",
       "      <td>0.929449</td>\n",
       "      <td>0.945701</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>4.113005</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.28</td>\n",
       "      <td>10.800866</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.968234</td>\n",
       "      <td>0.949767</td>\n",
       "      <td>0.936116</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.20</td>\n",
       "      <td>2.096184</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.40</td>\n",
       "      <td>5.682217</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.948933</td>\n",
       "      <td>0.929194</td>\n",
       "      <td>0.949383</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.24</td>\n",
       "      <td>2.701437</td>\n",
       "      <td>1.25</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-26.552034</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.965159</td>\n",
       "      <td>0.951908</td>\n",
       "      <td>0.960269</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.953536</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.30</td>\n",
       "      <td>-4.536987</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.941347</td>\n",
       "      <td>0.940053</td>\n",
       "      <td>0.943663</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  \\\n",
       "47          20251102-063742Z_SIMULATION_fineband  SIMULATION   \n",
       "46          20251102-063741Z_SIMULATION_variantA  SIMULATION   \n",
       "45                   20251102-063741Z_SIMULATION  SIMULATION   \n",
       "44                   20251102-063738Z_SIMULATION  SIMULATION   \n",
       "43                              20251102-063629Z  SIMULATION   \n",
       "42                              20251102-063520Z  SIMULATION   \n",
       "41                  20251101-044544Z_gpt-4o-mini        LIVE   \n",
       "40                  20251101-044131Z_gpt-4o-mini        LIVE   \n",
       "39                  20251101-041752Z_gpt-4o-mini        LIVE   \n",
       "38                  20251101-041320Z_gpt-4o-mini        LIVE   \n",
       "37                  20251101-035032Z_gpt-4o-mini        LIVE   \n",
       "36                  20251101-031922Z_gpt-4o-mini        LIVE   \n",
       "35                  20251101-025617Z_gpt-4o-mini        LIVE   \n",
       "34                  20251101-025209Z_gpt-4o-mini        LIVE   \n",
       "33                  20251101-024759Z_gpt-4o-mini        LIVE   \n",
       "32                  20251101-024352Z_gpt-4o-mini        LIVE   \n",
       "31                  20251101-023503Z_gpt-4o-mini        LIVE   \n",
       "30                  20251101-020156Z_gpt-4o-mini        LIVE   \n",
       "29                  20251101-015427Z_gpt-4o-mini        LIVE   \n",
       "28                  20251101-015330Z_gpt-4o-mini        LIVE   \n",
       "27                  20251101-005433Z_gpt-4o-mini        LIVE   \n",
       "26                  20251101-005255Z_gpt-4o-mini        LIVE   \n",
       "25                  20251101-004605Z_gpt-4o-mini        LIVE   \n",
       "24                  20251101-004514Z_gpt-4o-mini        LIVE   \n",
       "23                  20251101-003804Z_gpt-4o-mini        LIVE   \n",
       "22                  20251101-003723Z_gpt-4o-mini        LIVE   \n",
       "21                  20251101-002939Z_gpt-4o-mini        LIVE   \n",
       "20                  20251101-002722Z_gpt-4o-mini        LIVE   \n",
       "19                  20251101-002251Z_gpt-4o-mini        LIVE   \n",
       "18                  20251101-002005Z_gpt-4o-mini        LIVE   \n",
       "17         20251101-001421Z_gpt-4o-mini_smoke_ok        LIVE   \n",
       "16     20251031-235904Z_SIMULATION_variantA_next  SIMULATION   \n",
       "15           20251031-234447Z_gpt-4o-mini_smoke2        LIVE   \n",
       "14            20251031-233831Z_gpt-4o-mini_audit        LIVE   \n",
       "13                  20251031-214813Z_gpt-4o-mini        LIVE   \n",
       "12  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION   \n",
       "11  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION   \n",
       "10  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION   \n",
       "9   20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION   \n",
       "8   20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION   \n",
       "7      20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION   \n",
       "6      20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION   \n",
       "5      20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION   \n",
       "4           20251031-210910Z_SIMULATION_fineband  SIMULATION   \n",
       "3           20251031-210339Z_SIMULATION_variantA  SIMULATION   \n",
       "2                    20251031-210339Z_SIMULATION  SIMULATION   \n",
       "1                    20251031-210313Z_SIMULATION  SIMULATION   \n",
       "0                    20251031-210303Z_SIMULATION  SIMULATION   \n",
       "\n",
       "                                                temps  \\\n",
       "47         1.15,1.18,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "46          1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "45                  0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "44                  0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "43  0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...   \n",
       "42  0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...   \n",
       "41  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "40  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "39  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "38  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "37  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "36  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "35  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "34  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "33  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "32  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "31  1.1,1.16,1.18,1.2,1.22,1.24,1.26,1.3,1.35,1.4,...   \n",
       "30  1.18,1.2,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1....   \n",
       "29    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "28                                      1.2,1.24,1.28   \n",
       "27    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "26                                      1.2,1.24,1.28   \n",
       "25    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "24                                      1.2,1.24,1.28   \n",
       "23    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "22                                      1.2,1.24,1.28   \n",
       "21    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "20                  0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "19                  0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "18                  0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "17                                      1.2,1.24,1.28   \n",
       "16         1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "15                                      1.2,1.24,1.28   \n",
       "14                                               1.24   \n",
       "13    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "12    1.16,1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "11         1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "10         1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "9          1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "8          1.18,1.2,1.22,1.23,1.24,1.25,1.26,1.28,1.3   \n",
       "7           1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "6           1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "5           1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "4          1.15,1.18,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "3           1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,1.3   \n",
       "2                   0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "1   0.9,1.0,1.1,1.15,1.2,1.22,1.24,1.25,1.26,1.28,...   \n",
       "0                   0.9,1.0,1.1,1.2,1.25,1.3,1.35,1.4   \n",
       "\n",
       "    wei_consensus_theta_cutoff  wei_consensus_theta_grad  wei_consensus_slope  \\\n",
       "47                        1.18                      1.20             2.989394   \n",
       "46                        1.20                      1.22             3.119497   \n",
       "45                        1.00                      1.25             2.065572   \n",
       "44                        1.00                      1.25             2.227896   \n",
       "43                        1.60                      1.26             0.720695   \n",
       "42                        1.60                      1.26             0.720695   \n",
       "41                        1.30                      1.20             2.923455   \n",
       "40                        1.30                      1.18             3.751732   \n",
       "39                        1.22                      1.23            -3.090499   \n",
       "38                        1.30                      1.25             2.844443   \n",
       "37                        1.30                      1.18             2.099306   \n",
       "36                        1.30                      1.18             1.764008   \n",
       "35                        1.24                      1.30            -1.765305   \n",
       "34                        1.30                      1.26             2.095664   \n",
       "33                        1.30                      1.18             1.739468   \n",
       "32                        1.30                      1.18             3.084504   \n",
       "31                        1.60                      1.20            -0.531684   \n",
       "30                        1.30                      1.25             1.398389   \n",
       "29                        1.30                      1.30             1.464800   \n",
       "28                        1.28                      1.28            -0.655611   \n",
       "27                        1.30                      1.30             1.942358   \n",
       "26                        1.28                      1.20             1.121373   \n",
       "25                        1.30                      1.30             1.934868   \n",
       "24                        1.28                      1.28            -0.871805   \n",
       "23                        1.30                      1.23            -1.521403   \n",
       "22                        1.28                      1.20            -0.697811   \n",
       "21                        1.24                      1.23             1.925038   \n",
       "20                        1.20                      1.40             0.873275   \n",
       "19                        1.20                      1.40             1.393833   \n",
       "18                        1.20                      1.40             0.589375   \n",
       "17                        1.28                      1.20             0.000000   \n",
       "16                        1.23                      1.25             5.985512   \n",
       "15                        1.28                      1.20             0.000000   \n",
       "14                        1.24                      1.24             0.000000   \n",
       "13                        1.30                      1.16             0.000000   \n",
       "12                        1.20                      1.24             3.738723   \n",
       "11                        1.23                      1.23             4.873934   \n",
       "10                        1.23                      1.25             3.298276   \n",
       "9                         1.22                      1.24             4.243898   \n",
       "8                         1.20                      1.23             4.505667   \n",
       "7                         1.15                      1.30             3.445635   \n",
       "6                         1.20                      1.25             3.779664   \n",
       "5                         1.20                      1.22             3.188687   \n",
       "4                         1.18                      1.20             2.494810   \n",
       "3                         1.22                      1.25             4.113005   \n",
       "2                         1.00                      1.20             2.096184   \n",
       "1                         1.00                      1.24             2.701437   \n",
       "0                         1.00                      1.30             1.953536   \n",
       "\n",
       "    wei_dissent_theta_cutoff  wei_dissent_theta_grad  wei_dissent_slope  \\\n",
       "47                      1.24                    1.26         -16.606156   \n",
       "46                      1.26                    1.26         -15.185118   \n",
       "45                      1.30                    1.40          -9.463455   \n",
       "44                      1.30                    1.30          -5.652011   \n",
       "43                      1.60                    1.24           0.473986   \n",
       "42                      1.60                    1.24           0.473986   \n",
       "41                      1.20                    1.20         -10.449518   \n",
       "40                      1.20                    1.18         -12.323153   \n",
       "39                      1.25                    1.23          10.794221   \n",
       "38                      1.25                    1.23           8.631841   \n",
       "37                      1.20                    1.18          -6.852245   \n",
       "36                      1.20                    1.18          -5.521103   \n",
       "35                      1.25                    1.30          -2.722946   \n",
       "34                      1.27                    1.26           2.884673   \n",
       "33                      1.27                    1.18           2.596520   \n",
       "32                      1.27                    1.18           3.950267   \n",
       "31                      1.60                    1.22          -0.915669   \n",
       "30                      1.25                    1.24          -9.001066   \n",
       "29                      1.25                    1.24          -7.873390   \n",
       "28                      1.24                    1.20          -2.212808   \n",
       "27                      1.23                    1.24          -6.595261   \n",
       "26                      1.24                    1.20          -2.315095   \n",
       "25                      1.25                    1.24         -12.171376   \n",
       "24                      1.24                    1.20          -2.381797   \n",
       "23                      1.24                    1.24          -9.887914   \n",
       "22                      1.20                    1.20          -0.777232   \n",
       "21                      1.23                    1.30          -3.046390   \n",
       "20                      1.00                    0.90          -0.817726   \n",
       "19                      1.35                    1.35          -1.840983   \n",
       "18                      1.00                    0.90          -1.366648   \n",
       "17                      1.20                    1.20           0.000000   \n",
       "16                      1.23                    1.23         -16.412141   \n",
       "15                      1.20                    1.20           0.000000   \n",
       "14                      1.24                    1.24           0.000000   \n",
       "13                      1.16                    1.16           0.000000   \n",
       "12                      1.28                    1.22          10.133145   \n",
       "11                      1.28                    1.23          12.206338   \n",
       "10                      1.23                    1.20          13.055271   \n",
       "9                       1.26                    1.24          24.213321   \n",
       "8                       1.25                    1.18          21.362582   \n",
       "7                       1.26                    1.25         -15.508277   \n",
       "6                       1.28                    1.25          16.060481   \n",
       "5                       1.28                    1.25          17.261783   \n",
       "4                       1.28                    1.28          -9.732451   \n",
       "3                       1.30                    1.28          10.800866   \n",
       "2                       1.25                    1.40           5.682217   \n",
       "1                       1.25                    1.25         -26.552034   \n",
       "0                       1.30                    1.30          -4.536987   \n",
       "\n",
       "    ips_overall_mean  ips_syn_mean  ips_reorder_mean  ips_gauge_mean  \\\n",
       "47          0.958105      0.951481          0.939543        0.926666   \n",
       "46          0.971498      0.954310          0.952545        0.955941   \n",
       "45          0.971493      0.973163          0.944955        0.938269   \n",
       "44          0.959644      0.978245          0.943429        0.934236   \n",
       "43          0.501465      0.503329          0.506145        0.493058   \n",
       "42          0.501465      0.503329          0.506145        0.493058   \n",
       "41          0.609989      0.497791          0.675817        0.656360   \n",
       "40          0.619057      0.514104          0.675817        0.667249   \n",
       "39          0.609989      0.497791          0.675817        0.656360   \n",
       "38          0.627198      0.549417          0.675817        0.656360   \n",
       "37          0.609989      0.497791          0.675817        0.656360   \n",
       "36          0.638802      0.584229          0.675817        0.656360   \n",
       "35          0.609989      0.497791          0.675817        0.656360   \n",
       "34          0.638802      0.584229          0.675817        0.656360   \n",
       "33          0.660081      0.584229          0.675817        0.720197   \n",
       "32          0.609989      0.497791          0.675817        0.656360   \n",
       "31          0.647066      0.609518          0.657570        0.674110   \n",
       "30          0.609989      0.497791          0.675817        0.656360   \n",
       "29          0.618544      0.686248          0.429393        0.739990   \n",
       "28          0.601472      0.561402          0.468610        0.774404   \n",
       "27          0.632534      0.690973          0.466640        0.739990   \n",
       "26          0.598929      0.555520          0.468610        0.772655   \n",
       "25          0.591030      0.686248          0.429393        0.657448   \n",
       "24          0.598918      0.555489          0.468610        0.772655   \n",
       "23          0.629267      0.686248          0.461563        0.739990   \n",
       "22          0.571551      0.382954          0.611775        0.719925   \n",
       "21          0.622432      0.690973          0.436332        0.739990   \n",
       "20          0.637655      0.658063          0.504995        0.749906   \n",
       "19          0.619643      0.569383          0.502595        0.786950   \n",
       "18          0.588352      0.512555          0.502595        0.749906   \n",
       "17          0.526006      0.390065          0.468027        0.719925   \n",
       "16          0.963638      0.953943          0.947058        0.957198   \n",
       "15          0.616369      0.458919          0.670264        0.719925   \n",
       "14          0.659961      0.620262          0.716694        0.642928   \n",
       "13          0.636828      0.686248          0.484246        0.739990   \n",
       "12          0.974318      0.952848          0.953816        0.951685   \n",
       "11          0.957621      0.944299          0.964758        0.953434   \n",
       "10          0.960966      0.970224          0.955387        0.942212   \n",
       "9           0.963790      0.960000          0.933468        0.947360   \n",
       "8           0.966623      0.950710          0.954624        0.942664   \n",
       "7           0.968987      0.966177          0.951758        0.938941   \n",
       "6           0.970813      0.958708          0.966246        0.947219   \n",
       "5           0.973746      0.939193          0.943264        0.952385   \n",
       "4           0.947996      0.948165          0.929449        0.945701   \n",
       "3           0.976853      0.968234          0.949767        0.936116   \n",
       "2           0.979092      0.948933          0.929194        0.949383   \n",
       "1           0.977601      0.965159          0.951908        0.960269   \n",
       "0           0.967053      0.941347          0.940053        0.943663   \n",
       "\n",
       "    asi_mean                                             outdir  \n",
       "47  0.689400  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "46  0.690779  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "45  0.664605  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "44  0.688512  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "43  7.832574  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  7.832574  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  0.875000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  0.699600  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  1.000000  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  0.709973  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  0.708609  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  0.714041  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   0.704179  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   0.687386  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   0.706255  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   0.698189  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   0.708848  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   0.709658  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   0.720928  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   0.679488  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   0.698696  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   0.702967  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fix_all_modes()\n",
    "leader = build_leaderboard(); leader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "777e9d01-bd17-4002-b767-23c2ace80113",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CNT_WP_BASELINE_PTS\"] = \"3\"   # average over first 3 temps for baseline\n",
    "os.environ[\"CNT_WP_SIGMA_FLOOR\"]  = \"0.015\"\n",
    "os.environ[\"CNT_WP_K\"]            = \"2.5\" # slightly bolder threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "eba531f3-99dd-40cb-9d8b-058614fe7c18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Edge ↔ ASI audit ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pearson_r</th>\n",
       "      <th>n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wei_consensus_slope</th>\n",
       "      <td>-0.186919</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wei_consensus_theta_cutoff</th>\n",
       "      <td>0.635253</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>wei_dissent_theta_cutoff</th>\n",
       "      <td>0.645966</td>\n",
       "      <td>48.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            pearson_r     n\n",
       "wei_consensus_slope         -0.186919  48.0\n",
       "wei_consensus_theta_cutoff   0.635253  48.0\n",
       "wei_dissent_theta_cutoff     0.645966  48.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from math import isnan\n",
    "\n",
    "def audit_edge_vs_asi(leader: pd.DataFrame):\n",
    "    df = leader.copy()\n",
    "    for col in [\"wei_consensus_theta_cutoff\",\"wei_dissent_theta_cutoff\",\"asi_mean\",\"wei_consensus_slope\"]:\n",
    "        if col in df: df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"asi_mean\"])\n",
    "\n",
    "    # Core correlations\n",
    "    out = {}\n",
    "    for x in [\"wei_consensus_theta_cutoff\",\"wei_dissent_theta_cutoff\",\"wei_consensus_slope\"]:\n",
    "        if x in df and df[x].notna().sum() >= 2:\n",
    "            out[x] = {\n",
    "                \"pearson_r\": float(df[[x,\"asi_mean\"]].corr().iloc[0,1]),\n",
    "                \"n\": int(df[[x,\"asi_mean\"]].dropna().shape[0]),\n",
    "            }\n",
    "\n",
    "    # Compact table\n",
    "    tbl = pd.DataFrame(out).T.sort_index()\n",
    "    print(\"=== Edge ↔ ASI audit ===\")\n",
    "    display(tbl)\n",
    "    return df, tbl\n",
    "\n",
    "df_all, tbl = audit_edge_vs_asi(leader)\n",
    "plot_wei_vs_asi_fixed(leader)  # from the earlier patch; keeps ASI at 0–1 with no offset text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f67575c3-b44c-4dde-8da0-ebddc67e4dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Derived metrics updated in manifests.\n",
      "✓ Leaderboard built | rows=48\n",
      "✓ Leaderboard+ built | rows=48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>wei_consensus_theta_cutoff</th>\n",
       "      <th>wei_dissent_theta_cutoff</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>consensus_fit_x0</th>\n",
       "      <th>consensus_fit_slope</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.249082</td>\n",
       "      <td>2.088425</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.252650</td>\n",
       "      <td>2.092862</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063629Z</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501465</td>\n",
       "      <td>7.832574</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063520Z</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.501465</td>\n",
       "      <td>7.832574</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.229995</td>\n",
       "      <td>0.498995</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.191533</td>\n",
       "      <td>0.655690</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.03</td>\n",
       "      <td>1.223306</td>\n",
       "      <td>0.326407</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.149413</td>\n",
       "      <td>0.156719</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.220841</td>\n",
       "      <td>0.772065</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>1.227257</td>\n",
       "      <td>0.730603</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>1.239496</td>\n",
       "      <td>0.336786</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.257332</td>\n",
       "      <td>0.425932</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.235309</td>\n",
       "      <td>0.599500</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.27</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>1.228185</td>\n",
       "      <td>0.859371</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-023503Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.353501</td>\n",
       "      <td>0.156634</td>\n",
       "      <td>0.647066</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.212311</td>\n",
       "      <td>0.318260</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.269970</td>\n",
       "      <td>0.205739</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.243290</td>\n",
       "      <td>-1.338010</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>1.254765</td>\n",
       "      <td>0.184665</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-005255Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.230597</td>\n",
       "      <td>1.495430</td>\n",
       "      <td>0.598929</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-004605Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.25</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>1.265001</td>\n",
       "      <td>0.170003</td>\n",
       "      <td>0.591030</td>\n",
       "      <td>0.875000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-004514Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>1.244818</td>\n",
       "      <td>-1.629456</td>\n",
       "      <td>0.598918</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.24</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>1.230504</td>\n",
       "      <td>0.448681</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-003723Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>1.238330</td>\n",
       "      <td>-1.712247</td>\n",
       "      <td>0.571551</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.23</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>1.229650</td>\n",
       "      <td>0.373160</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-002722Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>4.138314</td>\n",
       "      <td>0.001902</td>\n",
       "      <td>0.637655</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.201837</td>\n",
       "      <td>0.068663</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002005Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1.223522</td>\n",
       "      <td>0.196507</td>\n",
       "      <td>0.588352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-001421Z_gpt-4o-mini_smoke_ok</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.526006</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.244299</td>\n",
       "      <td>5.792667</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.28</td>\n",
       "      <td>1.20</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.16</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.231532</td>\n",
       "      <td>5.019830</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.246519</td>\n",
       "      <td>5.223157</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.23</td>\n",
       "      <td>1.23</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.246127</td>\n",
       "      <td>5.339443</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.04</td>\n",
       "      <td>1.244998</td>\n",
       "      <td>4.571059</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.05</td>\n",
       "      <td>1.237896</td>\n",
       "      <td>6.592512</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.15</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.11</td>\n",
       "      <td>1.213647</td>\n",
       "      <td>5.523855</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.208629</td>\n",
       "      <td>5.363561</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.217091</td>\n",
       "      <td>4.882127</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.28</td>\n",
       "      <td>0.10</td>\n",
       "      <td>1.228502</td>\n",
       "      <td>4.578440</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.08</td>\n",
       "      <td>1.213196</td>\n",
       "      <td>5.350321</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.232084</td>\n",
       "      <td>2.187828</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.25</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.236240</td>\n",
       "      <td>2.227001</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.218314</td>\n",
       "      <td>2.101917</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  \\\n",
       "0           20251102-063742Z_SIMULATION_fineband  SIMULATION   \n",
       "1           20251102-063741Z_SIMULATION_variantA  SIMULATION   \n",
       "2                    20251102-063741Z_SIMULATION  SIMULATION   \n",
       "3                    20251102-063738Z_SIMULATION  SIMULATION   \n",
       "4                               20251102-063629Z  SIMULATION   \n",
       "5                               20251102-063520Z  SIMULATION   \n",
       "6                   20251101-044544Z_gpt-4o-mini        LIVE   \n",
       "7                   20251101-044131Z_gpt-4o-mini        LIVE   \n",
       "8                   20251101-041752Z_gpt-4o-mini        LIVE   \n",
       "9                   20251101-041320Z_gpt-4o-mini        LIVE   \n",
       "10                  20251101-035032Z_gpt-4o-mini        LIVE   \n",
       "11                  20251101-031922Z_gpt-4o-mini        LIVE   \n",
       "12                  20251101-025617Z_gpt-4o-mini        LIVE   \n",
       "13                  20251101-025209Z_gpt-4o-mini        LIVE   \n",
       "14                  20251101-024759Z_gpt-4o-mini        LIVE   \n",
       "15                  20251101-024352Z_gpt-4o-mini        LIVE   \n",
       "16                  20251101-023503Z_gpt-4o-mini        LIVE   \n",
       "17                  20251101-020156Z_gpt-4o-mini        LIVE   \n",
       "18                  20251101-015427Z_gpt-4o-mini        LIVE   \n",
       "19                  20251101-015330Z_gpt-4o-mini        LIVE   \n",
       "20                  20251101-005433Z_gpt-4o-mini        LIVE   \n",
       "21                  20251101-005255Z_gpt-4o-mini        LIVE   \n",
       "22                  20251101-004605Z_gpt-4o-mini        LIVE   \n",
       "23                  20251101-004514Z_gpt-4o-mini        LIVE   \n",
       "24                  20251101-003804Z_gpt-4o-mini        LIVE   \n",
       "25                  20251101-003723Z_gpt-4o-mini        LIVE   \n",
       "26                  20251101-002939Z_gpt-4o-mini        LIVE   \n",
       "27                  20251101-002722Z_gpt-4o-mini        LIVE   \n",
       "28                  20251101-002251Z_gpt-4o-mini        LIVE   \n",
       "29                  20251101-002005Z_gpt-4o-mini        LIVE   \n",
       "30         20251101-001421Z_gpt-4o-mini_smoke_ok        LIVE   \n",
       "31     20251031-235904Z_SIMULATION_variantA_next  SIMULATION   \n",
       "32           20251031-234447Z_gpt-4o-mini_smoke2        LIVE   \n",
       "33            20251031-233831Z_gpt-4o-mini_audit        LIVE   \n",
       "34                  20251031-214813Z_gpt-4o-mini        LIVE   \n",
       "35  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION   \n",
       "36  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION   \n",
       "37  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION   \n",
       "38  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION   \n",
       "39  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION   \n",
       "40     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION   \n",
       "41     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION   \n",
       "42     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION   \n",
       "43          20251031-210910Z_SIMULATION_fineband  SIMULATION   \n",
       "44          20251031-210339Z_SIMULATION_variantA  SIMULATION   \n",
       "45                   20251031-210339Z_SIMULATION  SIMULATION   \n",
       "46                   20251031-210313Z_SIMULATION  SIMULATION   \n",
       "47                   20251031-210303Z_SIMULATION  SIMULATION   \n",
       "\n",
       "    wei_consensus_theta_cutoff  wei_dissent_theta_cutoff  edge_window_width  \\\n",
       "0                         1.18                      1.24               0.06   \n",
       "1                         1.20                      1.26               0.06   \n",
       "2                         1.00                      1.30               0.30   \n",
       "3                         1.00                      1.30               0.30   \n",
       "4                         1.60                      1.60                NaN   \n",
       "5                         1.60                      1.60                NaN   \n",
       "6                         1.30                      1.20              -0.10   \n",
       "7                         1.30                      1.20              -0.10   \n",
       "8                         1.22                      1.25               0.03   \n",
       "9                         1.30                      1.25              -0.05   \n",
       "10                        1.30                      1.20              -0.10   \n",
       "11                        1.30                      1.20              -0.10   \n",
       "12                        1.24                      1.25               0.01   \n",
       "13                        1.30                      1.27              -0.03   \n",
       "14                        1.30                      1.27              -0.03   \n",
       "15                        1.30                      1.27              -0.03   \n",
       "16                        1.60                      1.60               0.00   \n",
       "17                        1.30                      1.25              -0.05   \n",
       "18                        1.30                      1.25              -0.05   \n",
       "19                        1.28                      1.24              -0.04   \n",
       "20                        1.30                      1.23              -0.07   \n",
       "21                        1.28                      1.24              -0.04   \n",
       "22                        1.30                      1.25              -0.05   \n",
       "23                        1.28                      1.24              -0.04   \n",
       "24                        1.30                      1.24              -0.06   \n",
       "25                        1.28                      1.20              -0.08   \n",
       "26                        1.24                      1.23              -0.01   \n",
       "27                        1.20                      1.00              -0.20   \n",
       "28                        1.20                      1.35               0.15   \n",
       "29                        1.20                      1.00              -0.20   \n",
       "30                        1.28                      1.20              -0.08   \n",
       "31                        1.23                      1.23               0.00   \n",
       "32                        1.28                      1.20              -0.08   \n",
       "33                        1.24                      1.24               0.00   \n",
       "34                        1.30                      1.16              -0.14   \n",
       "35                        1.20                      1.28               0.08   \n",
       "36                        1.23                      1.28               0.05   \n",
       "37                        1.23                      1.23               0.00   \n",
       "38                        1.22                      1.26               0.04   \n",
       "39                        1.20                      1.25               0.05   \n",
       "40                        1.15                      1.26               0.11   \n",
       "41                        1.20                      1.28               0.08   \n",
       "42                        1.20                      1.28               0.08   \n",
       "43                        1.18                      1.28               0.10   \n",
       "44                        1.22                      1.30               0.08   \n",
       "45                        1.00                      1.25               0.25   \n",
       "46                        1.00                      1.25               0.25   \n",
       "47                        1.00                      1.30               0.30   \n",
       "\n",
       "    consensus_fit_x0  consensus_fit_slope  ips_overall_mean  asi_mean  \\\n",
       "0                NaN                  NaN          0.958105  0.689400   \n",
       "1                NaN                  NaN          0.971498  0.690779   \n",
       "2           1.249082             2.088425          0.971493  0.664605   \n",
       "3           1.252650             2.092862          0.959644  0.688512   \n",
       "4                NaN                  NaN          0.501465  7.832574   \n",
       "5                NaN                  NaN          0.501465  7.832574   \n",
       "6           1.229995             0.498995          0.609989  1.000000   \n",
       "7           1.191533             0.655690          0.619057  1.000000   \n",
       "8           1.223306             0.326407          0.609989  1.000000   \n",
       "9           1.149413             0.156719          0.627198  1.000000   \n",
       "10          1.220841             0.772065          0.609989  1.000000   \n",
       "11          1.227257             0.730603          0.638802  1.000000   \n",
       "12          1.239496             0.336786          0.609989  1.000000   \n",
       "13          1.257332             0.425932          0.638802  1.000000   \n",
       "14          1.235309             0.599500          0.660081  1.000000   \n",
       "15          1.228185             0.859371          0.609989  1.000000   \n",
       "16          1.353501             0.156634          0.647066  1.000000   \n",
       "17          1.212311             0.318260          0.609989  1.000000   \n",
       "18          1.269970             0.205739          0.618544  1.000000   \n",
       "19          1.243290            -1.338010          0.601472  1.000000   \n",
       "20          1.254765             0.184665          0.632534  1.000000   \n",
       "21          1.230597             1.495430          0.598929  1.000000   \n",
       "22          1.265001             0.170003          0.591030  0.875000   \n",
       "23          1.244818            -1.629456          0.598918  1.000000   \n",
       "24          1.230504             0.448681          0.629267  1.000000   \n",
       "25          1.238330            -1.712247          0.571551  1.000000   \n",
       "26          1.229650             0.373160          0.622432  1.000000   \n",
       "27          4.138314             0.001902          0.637655  1.000000   \n",
       "28          1.201837             0.068663          0.619643  1.000000   \n",
       "29          1.223522             0.196507          0.588352  1.000000   \n",
       "30               NaN                  NaN          0.526006  1.000000   \n",
       "31          1.244299             5.792667          0.963638  0.699600   \n",
       "32               NaN                  NaN          0.616369  1.000000   \n",
       "33               NaN                  NaN          0.659961  1.000000   \n",
       "34               NaN                  NaN          0.636828  1.000000   \n",
       "35          1.231532             5.019830          0.974318  0.709973   \n",
       "36          1.246519             5.223157          0.957621  0.708609   \n",
       "37          1.246127             5.339443          0.960966  0.714041   \n",
       "38          1.244998             4.571059          0.963790  0.704179   \n",
       "39          1.237896             6.592512          0.966623  0.687386   \n",
       "40          1.213647             5.523855          0.968987  0.706255   \n",
       "41          1.208629             5.363561          0.970813  0.698189   \n",
       "42          1.217091             4.882127          0.973746  0.708848   \n",
       "43          1.228502             4.578440          0.947996  0.709658   \n",
       "44          1.213196             5.350321          0.976853  0.720928   \n",
       "45          1.232084             2.187828          0.979092  0.679488   \n",
       "46          1.236240             2.227001          0.977601  0.698696   \n",
       "47          1.218314             2.101917          0.967053  0.702967   \n",
       "\n",
       "                                               outdir  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "43  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "44  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "45  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "46  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "47  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ===== Derive metrics & extend leaderboard =====\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def _logistic(x, x0, k, lo, hi):\n",
    "    return lo + (hi - lo) / (1.0 + np.exp(-k * (x - x0)))\n",
    "\n",
    "def derive_metrics_for_run(run_dir: str | Path):\n",
    "    rd = Path(run_dir)\n",
    "    manf = rd / \"run_manifest.json\"\n",
    "    curves_p = rd / \"curves.json\"\n",
    "    if not manf.exists() or not curves_p.exists():\n",
    "        return\n",
    "    m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "    curves = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(curves[\"temps\"], dtype=float)\n",
    "    meanc = np.asarray(curves[\"mean_cons\"], dtype=float)\n",
    "\n",
    "    # Edge window width: dissent cutoff minus consensus cutoff\n",
    "    d = m.get(\"theta\", {}).get(\"dissent\",  {})\n",
    "    c = m.get(\"theta\", {}).get(\"consensus\",{})\n",
    "    th_c = float(c.get(\"theta_star_cutoff\")) if c.get(\"theta_star_cutoff\") is not None else np.nan\n",
    "    th_d = float(d.get(\"theta_star_cutoff\")) if d.get(\"theta_star_cutoff\") is not None else np.nan\n",
    "\n",
    "    md = m.get(\"derived\", {}) or {}\n",
    "    if not (np.isnan(th_c) or np.isnan(th_d)):\n",
    "        md[\"edge_window_width\"] = float(th_d - th_c)\n",
    "\n",
    "    # Logistic fit of consensus curve (robust slope at inflection)\n",
    "    try:\n",
    "        p0 = [1.24, 8.0, float(meanc.min()), float(meanc.max())]\n",
    "        bounds = ([0.8, 0.1, 0.0, 0.2], [2.0, 50.0, 0.2, 1.0])\n",
    "        popt, _ = curve_fit(_logistic, temps, meanc, p0=p0, bounds=bounds, maxfev=20000)\n",
    "        x0, k, lo, hi = map(float, popt)\n",
    "        md[\"consensus_fit_x0\"]    = x0\n",
    "        md[\"consensus_fit_slope\"] = k * (hi - lo) / 4.0  # slope at inflection\n",
    "    except Exception as e:\n",
    "        md[\"consensus_fit_error\"] = str(e)\n",
    "\n",
    "    m[\"derived\"] = md\n",
    "    manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def derive_all():\n",
    "    base = get_probe_base()\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir()]):\n",
    "        derive_metrics_for_run(rd)\n",
    "    print(\"✓ Derived metrics updated in manifests.\")\n",
    "\n",
    "def build_leaderboard_plus():\n",
    "    base = get_probe_base()\n",
    "    rows = []\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir()]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        d = m.get(\"derived\", {}) or {}\n",
    "        # Base fields from the existing leaderboard helper:\n",
    "        # (Reuse build_leaderboard for WEI/IPS/ASI aggregation)\n",
    "    leader = build_leaderboard()\n",
    "    out = []\n",
    "    for _, r in leader.iterrows():\n",
    "        m = json.loads((Path(r[\"outdir\"]) / \"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "        d = m.get(\"derived\", {}) or {}\n",
    "        out.append({\n",
    "            \"run_id\": r[\"run_id\"],\n",
    "            \"llm_mode\": r[\"llm_mode\"],\n",
    "            \"wei_consensus_theta_cutoff\": r.get(\"wei_consensus_theta_cutoff\"),\n",
    "            \"wei_dissent_theta_cutoff\":   r.get(\"wei_dissent_theta_cutoff\"),\n",
    "            \"edge_window_width\":          d.get(\"edge_window_width\"),\n",
    "            \"consensus_fit_x0\":           d.get(\"consensus_fit_x0\"),\n",
    "            \"consensus_fit_slope\":        d.get(\"consensus_fit_slope\"),\n",
    "            \"ips_overall_mean\":           r.get(\"ips_overall_mean\"),\n",
    "            \"asi_mean\":                   r.get(\"asi_mean\"),\n",
    "            \"outdir\": r[\"outdir\"],\n",
    "        })\n",
    "    df = pd.DataFrame(out).sort_values(\"run_id\", ascending=False)\n",
    "    print(f\"✓ Leaderboard+ built | rows={len(df)}\")\n",
    "    return df\n",
    "\n",
    "derive_all()\n",
    "leader2 = build_leaderboard_plus(); leader2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a912ac1d-49b8-4a05-8a52-be17ecbba963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Extended audit ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>n</th>\n",
       "      <th>pearson_r</th>\n",
       "      <th>95%CI_lo</th>\n",
       "      <th>95%CI_hi</th>\n",
       "      <th>spearman_rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IPS_overall  vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.379741</td>\n",
       "      <td>-0.599221</td>\n",
       "      <td>-0.107170</td>\n",
       "      <td>-0.814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit slope    vs ASI</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.851900</td>\n",
       "      <td>-0.919419</td>\n",
       "      <td>-0.735600</td>\n",
       "      <td>-0.766876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>window width vs ASI</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.732376</td>\n",
       "      <td>-0.843368</td>\n",
       "      <td>-0.561446</td>\n",
       "      <td>-0.766850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>θ*_consensus vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>0.635253</td>\n",
       "      <td>0.428453</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>0.793315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>θ*_dissent  vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>0.645966</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.785862</td>\n",
       "      <td>-0.278380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pair   n  pearson_r  95%CI_lo  95%CI_hi  spearman_rho\n",
       "4  IPS_overall  vs ASI  48  -0.379741 -0.599221 -0.107170     -0.814031\n",
       "3  fit slope    vs ASI  40  -0.851900 -0.919419 -0.735600     -0.766876\n",
       "2  window width vs ASI  46  -0.732376 -0.843368 -0.561446     -0.766850\n",
       "1  θ*_consensus vs ASI  48   0.635253  0.428453  0.778814      0.793315\n",
       "0   θ*_dissent  vs ASI  48   0.645966  0.443171  0.785862     -0.278380"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pair</th>\n",
       "      <th>n</th>\n",
       "      <th>pearson_r</th>\n",
       "      <th>95%CI_lo</th>\n",
       "      <th>95%CI_hi</th>\n",
       "      <th>spearman_rho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>IPS_overall  vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>-0.379741</td>\n",
       "      <td>-0.599221</td>\n",
       "      <td>-0.107170</td>\n",
       "      <td>-0.814031</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>fit slope    vs ASI</td>\n",
       "      <td>40</td>\n",
       "      <td>-0.851900</td>\n",
       "      <td>-0.919419</td>\n",
       "      <td>-0.735600</td>\n",
       "      <td>-0.766876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>window width vs ASI</td>\n",
       "      <td>46</td>\n",
       "      <td>-0.732376</td>\n",
       "      <td>-0.843368</td>\n",
       "      <td>-0.561446</td>\n",
       "      <td>-0.766850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>θ*_consensus vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>0.635253</td>\n",
       "      <td>0.428453</td>\n",
       "      <td>0.778814</td>\n",
       "      <td>0.793315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>θ*_dissent  vs ASI</td>\n",
       "      <td>48</td>\n",
       "      <td>0.645966</td>\n",
       "      <td>0.443171</td>\n",
       "      <td>0.785862</td>\n",
       "      <td>-0.278380</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  pair   n  pearson_r  95%CI_lo  95%CI_hi  spearman_rho\n",
       "4  IPS_overall  vs ASI  48  -0.379741 -0.599221 -0.107170     -0.814031\n",
       "3  fit slope    vs ASI  40  -0.851900 -0.919419 -0.735600     -0.766876\n",
       "2  window width vs ASI  46  -0.732376 -0.843368 -0.561446     -0.766850\n",
       "1  θ*_consensus vs ASI  48   0.635253  0.428453  0.778814      0.793315\n",
       "0   θ*_dissent  vs ASI  48   0.645966  0.443171  0.785862     -0.278380"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, math\n",
    "\n",
    "def fisher_ci(r, n, alpha=0.05):\n",
    "    z = 0.5 * math.log((1 + r) / (1 - r))\n",
    "    se = 1 / math.sqrt(max(n - 3, 1))\n",
    "    zc = 1.959964  # ~95%\n",
    "    lo = z - zc * se\n",
    "    hi = z + zc * se\n",
    "    rlo = (math.exp(2*lo) - 1) / (math.exp(2*lo) + 1)\n",
    "    rhi = (math.exp(2*hi) - 1) / (math.exp(2*hi) + 1)\n",
    "    return rlo, rhi\n",
    "\n",
    "def audit_plus(df):\n",
    "    # ensure numeric\n",
    "    for col in [\"asi_mean\",\"wei_consensus_theta_cutoff\",\"wei_dissent_theta_cutoff\",\n",
    "                \"edge_window_width\",\"consensus_fit_slope\",\"ips_overall_mean\"]:\n",
    "        if col in df: df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"asi_mean\"]).copy()\n",
    "\n",
    "    pairs = {\n",
    "        \"θ*_dissent  vs ASI\":       (\"wei_dissent_theta_cutoff\",   \"asi_mean\"),\n",
    "        \"θ*_consensus vs ASI\":      (\"wei_consensus_theta_cutoff\", \"asi_mean\"),\n",
    "        \"window width vs ASI\":      (\"edge_window_width\",          \"asi_mean\"),\n",
    "        \"fit slope    vs ASI\":      (\"consensus_fit_slope\",        \"asi_mean\"),\n",
    "        \"IPS_overall  vs ASI\":      (\"ips_overall_mean\",           \"asi_mean\"),\n",
    "    }\n",
    "    rows = []\n",
    "    for name, (x,y) in pairs.items():\n",
    "        if x in df and y in df:\n",
    "            sub = df[[x,y]].dropna()\n",
    "            if len(sub) >= 2:\n",
    "                pear = float(sub.corr(method=\"pearson\").iloc[0,1])\n",
    "                spear= float(sub.corr(method=\"spearman\").iloc[0,1])\n",
    "                lo, hi = fisher_ci(pear, len(sub))\n",
    "                rows.append({\"pair\": name, \"n\": len(sub),\n",
    "                             \"pearson_r\": pear, \"95%CI_lo\": lo, \"95%CI_hi\": hi,\n",
    "                             \"spearman_rho\": spear})\n",
    "    out = pd.DataFrame(rows).sort_values(\"pair\")\n",
    "    print(\"=== Extended audit ===\")\n",
    "    display(out)\n",
    "    return out\n",
    "\n",
    "audit_plus(leader2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "97c82360-58ad-40e4-b9a5-368393972f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Quarantined 2 legacy runs → E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\_legacy\n",
      "✓ Derived metrics (fallback) updated.\n",
      "✓ Leaderboard built | rows=46\n",
      "✓ Leaderboard+ (clean) | rows=38 of 46\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.141531</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.004254</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.963061</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.915624</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.845743</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.459914</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.386877</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.372180</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.300524</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.289869</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.231723</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.203177</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.074121</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.069066</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.058288</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.033250</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.011833</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.018327</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.067659</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.087177</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.102055</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.166475</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.186477</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.189859</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.199446</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.340918</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.355321</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.371247</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.390618</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.394694</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.439743</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.446443</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.485335</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.529738</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.598726</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.650798</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.650798</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.665515</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "37                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "3                    20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "36                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "2                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "35                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "20                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "34          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "30     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "25  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "32     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "33          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "31     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "1           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "26  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "23            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "28  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "0           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "29  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "12                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "27  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "6                   20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "10                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "11                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "7                   20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "13                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "18                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "15                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "16                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "9                   20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "5                   20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "4                   20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "8                   20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "37          0.967053               0.30  1.141531   \n",
       "3           0.959644               0.30  1.004254   \n",
       "36          0.977601               0.25  0.963061   \n",
       "2           0.971493               0.30  0.915624   \n",
       "35          0.979092               0.25  0.845743   \n",
       "20          0.619643               0.15  0.459914   \n",
       "34          0.976853               0.08  0.386877   \n",
       "30          0.968987               0.11  0.372180   \n",
       "25          0.974318               0.08  0.300524   \n",
       "32          0.973746               0.08  0.289869   \n",
       "33          0.947996               0.10  0.231723   \n",
       "31          0.970813               0.08  0.203177   \n",
       "1           0.971498               0.06  0.074121   \n",
       "26          0.957621               0.05  0.069066   \n",
       "23          0.659961               0.00  0.058288   \n",
       "28          0.963790               0.04  0.033250   \n",
       "0           0.958105               0.06 -0.011833   \n",
       "29          0.966623               0.05 -0.018327   \n",
       "12          0.660081              -0.03 -0.067659   \n",
       "27          0.960966               0.00 -0.087177   \n",
       "6           0.609989               0.03 -0.102055   \n",
       "21          0.963638               0.00 -0.166475   \n",
       "10          0.609989               0.01 -0.186477   \n",
       "11          0.638802              -0.03 -0.189859   \n",
       "19          0.622432              -0.01 -0.199446   \n",
       "7           0.627198              -0.05 -0.340918   \n",
       "13          0.609989              -0.03 -0.355321   \n",
       "18          0.629267              -0.06 -0.371247   \n",
       "15          0.618544              -0.05 -0.390618   \n",
       "17          0.632534              -0.07 -0.394694   \n",
       "14          0.609989              -0.05 -0.439743   \n",
       "16          0.601472              -0.04 -0.446443   \n",
       "9           0.638802              -0.10 -0.485335   \n",
       "22          0.616369              -0.08 -0.529738   \n",
       "5           0.619057              -0.10 -0.598726   \n",
       "4           0.609989              -0.10 -0.650798   \n",
       "8           0.609989              -0.10 -0.650798   \n",
       "24          0.636828              -0.14 -0.665515   \n",
       "\n",
       "                                               outdir  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ===== v1.5 Cleanup & Grading =====\n",
    "import os, json, math, shutil\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# --- 0) Helpers we rely on from v1.5 cell ---\n",
    "# expects: get_probe_base(), build_leaderboard(), latest_run_dir()\n",
    "\n",
    "# --- 1) Quarantine legacy (ASI not in [0,1]) ---\n",
    "def quarantine_legacy_runs():\n",
    "    base = get_probe_base()\n",
    "    legacy = (base / \"_legacy\"); legacy.mkdir(exist_ok=True)\n",
    "    moved = []\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name != \"_legacy\"]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        sep  = rd / \"anthropomorphism_separation.csv\"\n",
    "        try:\n",
    "            if sep.exists():\n",
    "                df = pd.read_csv(sep)\n",
    "                if \"separation_index\" in df:\n",
    "                    asi = float(df[\"separation_index\"].mean())\n",
    "                    if not (0.0 <= asi <= 1.0):\n",
    "                        shutil.move(str(rd), str(legacy / rd.name))\n",
    "                        moved.append(rd.name)\n",
    "        except Exception:\n",
    "            pass\n",
    "    print(f\"✓ Quarantined {len(moved)} legacy runs → {legacy}\")\n",
    "\n",
    "# --- 2) Robust logistic fit (no SciPy required) ---\n",
    "def _robust_logistic_fit(temps, meanc):\n",
    "    temps = np.asarray(temps, float)\n",
    "    y = np.asarray(meanc, float)\n",
    "    lo, hi = float(y.min()), float(y.max())\n",
    "    if hi - lo < 1e-6:\n",
    "        raise ValueError(\"Flat curve; cannot fit.\")\n",
    "    # normalize to (0,1) and logit\n",
    "    eps = 1e-3\n",
    "    yn = np.clip((y - lo) / (hi - lo), eps, 1 - eps)\n",
    "    z  = np.log(yn / (1 - yn))\n",
    "    A  = np.vstack([np.ones_like(temps), temps]).T\n",
    "    a, k = np.linalg.lstsq(A, z, rcond=None)[0]\n",
    "    x0 = -a / k\n",
    "    slope = float(k) * (hi - lo) / 4.0  # slope at inflection\n",
    "    return float(x0), float(slope), float(lo), float(hi)\n",
    "\n",
    "def derive_metrics_for_run_fallback(run_dir: str | Path):\n",
    "    rd = Path(run_dir)\n",
    "    manf = rd / \"run_manifest.json\"\n",
    "    curves_p = rd / \"curves.json\"\n",
    "    if not (manf.exists() and curves_p.exists()):\n",
    "        return\n",
    "    m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "    curves = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "    temps  = curves.get(\"temps\", [])\n",
    "    meanc  = curves.get(\"mean_cons\", [])\n",
    "    d = m.get(\"derived\", {}) or {}\n",
    "    try:\n",
    "        x0, slope, lo, hi = _robust_logistic_fit(temps, meanc)\n",
    "        d[\"consensus_fit_x0\"]    = x0\n",
    "        d[\"consensus_fit_slope\"] = slope\n",
    "        m[\"derived\"] = d\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "    except Exception as e:\n",
    "        d[\"consensus_fit_error\"] = str(e)\n",
    "        m[\"derived\"] = d\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def derive_all_fallback():\n",
    "    base = get_probe_base()\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name != \"_legacy\"]):\n",
    "        derive_metrics_for_run_fallback(rd)\n",
    "    print(\"✓ Derived metrics (fallback) updated.\")\n",
    "\n",
    "# --- 3) Clean leaderboard (+) ---\n",
    "def mask_valid_runs(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for c in [\"asi_mean\",\"ips_overall_mean\",\"wei_consensus_theta_cutoff\",\"wei_dissent_theta_cutoff\"]:\n",
    "        if c in df: df[c] = pd.to_numeric(df[c], errors=\"coerce\")\n",
    "    q = (\n",
    "        df[\"asi_mean\"].between(0,1)\n",
    "        & df[\"ips_overall_mean\"].between(0.6, 1.0)\n",
    "        & df[\"wei_consensus_theta_cutoff\"].between(0.9, 1.35)\n",
    "        & df[\"wei_dissent_theta_cutoff\"].between(1.1, 1.40)\n",
    "    )\n",
    "    return df[q].reset_index(drop=True)\n",
    "\n",
    "def build_leaderboard_plus_clean():\n",
    "    leader = build_leaderboard()\n",
    "    # enrich with derived metrics if present\n",
    "    rows = []\n",
    "    for _, r in leader.iterrows():\n",
    "        m = json.loads((Path(r[\"outdir\"]) / \"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "        d = m.get(\"derived\", {}) or {}\n",
    "        rows.append({\n",
    "            **r.to_dict(),\n",
    "            \"edge_window_width\": d.get(\"edge_window_width\"),\n",
    "            \"consensus_fit_x0\":  d.get(\"consensus_fit_x0\"),\n",
    "            \"consensus_fit_slope\": d.get(\"consensus_fit_slope\"),\n",
    "        })\n",
    "    df = pd.DataFrame(rows).sort_values(\"run_id\", ascending=False)\n",
    "    dfc = mask_valid_runs(df)\n",
    "    print(f\"✓ Leaderboard+ (clean) | rows={len(dfc)} of {len(df)}\")\n",
    "    return dfc\n",
    "\n",
    "# --- 4) Grade runs (ESC = z(ASI)+z(IPS)+0.5*z(width)) ---\n",
    "def _z(x):\n",
    "    x = np.asarray(pd.to_numeric(x, errors=\"coerce\"), float)\n",
    "    mu, sd = np.nanmean(x), np.nanstd(x, ddof=1)\n",
    "    return (x - mu) / (sd if sd > 0 else 1.0)\n",
    "\n",
    "def grade_runs(df: pd.DataFrame):\n",
    "    g = df.copy()\n",
    "    for c in [\"asi_mean\",\"ips_overall_mean\",\"edge_window_width\"]:\n",
    "        g[c] = pd.to_numeric(g[c], errors=\"coerce\")\n",
    "    g[\"z_ASI\"]  = _z(g[\"asi_mean\"])\n",
    "    g[\"z_IPS\"]  = _z(g[\"ips_overall_mean\"])\n",
    "    g[\"z_W\"]    = _z(g[\"edge_window_width\"])\n",
    "    g[\"ESC\"]    = g[\"z_ASI\"] + g[\"z_IPS\"] + 0.5*g[\"z_W\"]\n",
    "    g = g.sort_values(\"ESC\", ascending=False)\n",
    "    print(\"=== Graded runs (ESC) ===\")\n",
    "    display(g[[\"run_id\",\"llm_mode\",\"asi_mean\",\"ips_overall_mean\",\"edge_window_width\",\"ESC\",\"outdir\"]])\n",
    "    return g\n",
    "\n",
    "# ---- Execute cleanup → derive → rebuild → grade ----\n",
    "quarantine_legacy_runs()\n",
    "derive_all_fallback()\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "847f5606-dceb-4be4-9ab5-bb95f607dd5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Published: E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\_published\\20251031-210303Z_SIMULATION__ESC_1.142\n",
      "✓ Bundle: E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\_published\\20251031-210303Z_SIMULATION__ESC_1.142.zip\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "('E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\_published\\\\20251031-210303Z_SIMULATION__ESC_1.142',\n",
       " 'E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\_published\\\\20251031-210303Z_SIMULATION__ESC_1.142.zip')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Publish the Champion Run ===\n",
    "import json, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def pick_champion(graded_df: pd.DataFrame) -> dict:\n",
    "    top = graded_df.iloc[0].to_dict()\n",
    "    return top\n",
    "\n",
    "def champion_dashboard(run_dir: str):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd / \"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    curves = json.loads((rd / \"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps  = curves[\"temps\"]\n",
    "    meanc  = curves[\"mean_cons\"]\n",
    "    diss   = curves[\"diss_curve\"]\n",
    "    c = m[\"theta\"][\"consensus\"]; d = m[\"theta\"][\"dissent\"]\n",
    "\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.plot(temps, meanc, marker=\"o\", label=\"consensus (mean)\")\n",
    "    plt.axvline(float(c.get(\"theta_star_cutoff\")), linestyle=\"--\", label=\"θ*cutoff (cons)\")\n",
    "    plt.axvline(float(c.get(\"theta_star_grad\")),   linestyle=\":\",  label=\"θ*grad (cons)\")\n",
    "    plt.xlabel(\"temperature\"); plt.ylabel(\"consensus response\")\n",
    "    plt.title(\"Consensus curve and θ* markers\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.plot(temps, diss, marker=\"x\", label=\"dissent (norm. std)\")\n",
    "    plt.axvline(float(d.get(\"theta_star_cutoff\")), linestyle=\"--\", label=\"θ*cutoff (diss)\")\n",
    "    plt.axvline(float(d.get(\"theta_star_grad\")),   linestyle=\":\",  label=\"θ*grad (diss)\")\n",
    "    plt.xlabel(\"temperature\"); plt.ylabel(\"dissent response\")\n",
    "    plt.title(\"Dissent curve and θ* markers\")\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "def publish_best(graded_df: pd.DataFrame, leader_df: pd.DataFrame):\n",
    "    best = pick_champion(graded_df)\n",
    "    rd   = Path(best[\"outdir\"])\n",
    "    base = rd.parent\n",
    "    pub  = base / \"_published\"; pub.mkdir(exist_ok=True)\n",
    "    tag  = f\"{rd.name}__ESC_{best['ESC']:.3f}\"\n",
    "    out_dir = pub / tag\n",
    "    if out_dir.exists():\n",
    "        shutil.rmtree(out_dir)\n",
    "    shutil.copytree(rd, out_dir)\n",
    "\n",
    "    # README + one-page brief\n",
    "    manf = json.loads((rd / \"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    brief_txt = (\n",
    "        \"CNT Weirdness Probe — Paper in a Page\\n\"\n",
    "        f\"Run: {manf.get('run_id')} | Mode: {manf.get('llm_mode')}\\n\"\n",
    "        f\"Temps: {','.join(map(str, manf.get('temps', [])))}\\n\"\n",
    "        f\"θ* (cutoff/grad) — CONS: {manf['theta']['consensus'].get('theta_star_cutoff')} / {manf['theta']['consensus'].get('theta_star_grad')}\\n\"\n",
    "        f\"                     DISS: {manf['theta']['dissent'].get('theta_star_cutoff')} / {manf['theta']['dissent'].get('theta_star_grad')}\\n\"\n",
    "        f\"Slopes — CONS: {manf['theta']['consensus'].get('slope_at_grad')} | DISS: {manf['theta']['dissent'].get('slope_at_grad')}\\n\"\n",
    "        f\"IPS_overall: {float(leader_df.loc[leader_df['outdir']==str(rd),'ips_overall_mean'].iloc[0]):.6f}\\n\"\n",
    "        f\"ASI_mean:    {float(leader_df.loc[leader_df['outdir']==str(rd),'asi_mean'].iloc[0]):.6f}\\n\"\n",
    "    )\n",
    "    (out_dir / \"README_CHAMPION.txt\").write_text(brief_txt, encoding=\"utf-8\")\n",
    "\n",
    "    # Bundle zip\n",
    "    zip_path = shutil.make_archive(str(out_dir), \"zip\", out_dir)\n",
    "    print(f\"✓ Published: {out_dir}\\n✓ Bundle: {zip_path}\")\n",
    "    return str(out_dir), zip_path\n",
    "\n",
    "# —— Run it now\n",
    "champ_dir, champ_zip = publish_best(graded, leader_clean)\n",
    "champion_dashboard(champ_dir)\n",
    "champ_dir, champ_zip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "84617a92-a7c2-4f92-b1a7-82dd645119b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION_variantA temps=1.10,1.15,1.20,1.22,1.24,1.25,1.26,1.28,1.30 reps=10 perm=200 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rep1 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063746Z_SIMULATION_variantA_rep1\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "_logistic() missing 2 required positional arguments: 'lo' and 'hi'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Triple replicate (new run_id seeds will jitter curves slightly)\u001b[39;00m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m3\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mSIMULATION_variantA_rep\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[43m+\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m leader = build_leaderboard(); leader\n\u001b[32m     14\u001b[39m leader_clean = build_leaderboard_plus_clean()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 246\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    243\u001b[39m seed = _seed_from(cfg[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m], model_name, temps, reps, perm)\n\u001b[32m    245\u001b[39m \u001b[38;5;66;03m# === Phase 1: Probe (consensus/dissent, θ*) ===\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m sim = \u001b[43m_simulate_probe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[38;5;66;03m# Optional auto-extend: tighten slope estimate if too flat\u001b[39;00m\n\u001b[32m    249\u001b[39m sigma_floor = \u001b[38;5;28mfloat\u001b[39m(os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_SIGMA_FLOOR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m0.01\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36m_simulate_probe\u001b[39m\u001b[34m(temps, reps, seed)\u001b[39m\n\u001b[32m    120\u001b[39m scores = []\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m temps:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     base = \u001b[43m_logistic\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx0\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1.245\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m9.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormal\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.4\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    123\u001b[39m     \u001b[38;5;66;03m# replicate noise slightly higher in the transition band\u001b[39;00m\n\u001b[32m    124\u001b[39m     band = \u001b[32m1.0\u001b[39m / (\u001b[32m1.0\u001b[39m + \u001b[38;5;28mabs\u001b[39m(t - \u001b[32m1.25\u001b[39m)*\u001b[32m16.0\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: _logistic() missing 2 required positional arguments: 'lo' and 'hi'"
     ]
    }
   ],
   "source": [
    "# === Replicate champion + micro-sweep ===\n",
    "# Champion knobs (your top run)\n",
    "set_probe_env(\n",
    "    model=\"SIMULATION_variantA\",\n",
    "    temps=\"1.10,1.15,1.20,1.22,1.24,1.25,1.26,1.28,1.30\",\n",
    "    reps=10, autoextend=True, perm=200\n",
    ")\n",
    "\n",
    "# Triple replicate (new run_id seeds will jitter curves slightly)\n",
    "for i in range(3):\n",
    "    run_model(f\"SIMULATION_variantA_rep{i+1}\")\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n",
    "\n",
    "# Micro-sweep: 3 close schedules to see if ESC stays high\n",
    "schedules = [\n",
    "  (\"SIM_SWEEP_A\", \"1.16,1.18,1.20,1.22,1.24,1.26,1.28\"),\n",
    "  (\"SIM_SWEEP_B\", \"1.18,1.20,1.21,1.22,1.23,1.24,1.26,1.28\"),\n",
    "  (\"SIM_SWEEP_C\", \"1.20,1.22,1.24,1.25,1.26,1.27,1.28,1.30\"),\n",
    "]\n",
    "for name, temps in schedules:\n",
    "    set_probe_env(model=name, temps=temps, reps=12, autoextend=True, perm=300)\n",
    "    run_model(name)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1697e820-ca79-49e6-beb3-2abdde19a283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ _logistic unified. SIM and FIT paths are now consistent.\n"
     ]
    }
   ],
   "source": [
    "# --- Unify _logistic for both SIM and FIT usages ---\n",
    "import math\n",
    "\n",
    "def _logistic(x, x0, k, lo=None, hi=None, ymin=None, ymax=None):\n",
    "    \"\"\"\n",
    "    Universal logistic:\n",
    "      • SIM path calls: _logistic(x, x0=..., k=...)         -> uses default ymin/ymax\n",
    "      • FIT path calls: _logistic(x, x0, k, lo, hi)         -> uses lo/hi\n",
    "      • You may also pass ymin/ymax explicitly.\n",
    "    \"\"\"\n",
    "    # Prefer explicit ymin/ymax if provided; otherwise map lo/hi; otherwise defaults\n",
    "    if ymin is None or ymax is None:\n",
    "        if lo is not None and hi is not None:\n",
    "            ymin, ymax = lo, hi\n",
    "        else:\n",
    "            ymin = 0.05 if ymin is None else ymin\n",
    "            ymax = 0.98 if ymax is None else ymax\n",
    "    return ymin + (ymax - ymin) / (1.0 + math.exp(-k*(x - x0)))\n",
    "\n",
    "print(\"✓ _logistic unified. SIM and FIT paths are now consistent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3745a3fa-7fea-4aa7-874c-296d558362a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rep1 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063933Z_SIMULATION_variantA_rep1\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rep2 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063933Z_SIMULATION_variantA_rep2\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rep3 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063933Z_SIMULATION_variantA_rep3\n",
      "✓ Leaderboard built | rows=49\n",
      "✓ Leaderboard built | rows=49\n",
      "✓ Leaderboard+ (clean) | rows=41 of 49\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.128129</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.990515</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.949396</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.901021</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.831486</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.459832</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.373886</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.358852</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.287238</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.276556</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.218765</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.189584</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.060299</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.057689</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.055954</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.019926</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.025525</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.032188</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.068259</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.100170</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.102013</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.179934</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.186435</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.190186</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.199564</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.341097</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.355279</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.371452</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.390686</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.394942</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.439701</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.446292</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.485663</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.529778</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.598800</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.650756</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.650756</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.665818</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "40                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "6                    20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "39                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "5                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "38                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "23                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "37          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "33     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "28  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "35     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "36          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "34     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "4           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "26            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "29  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "31  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "3           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "32  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "15                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "30  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "9                   20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "13                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "10                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "16                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "18                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "20                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "12                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "8                   20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "7                   20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "11                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "27                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "0      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "1      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "2      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "40          0.967053               0.30  1.128129   \n",
       "6           0.959644               0.30  0.990515   \n",
       "39          0.977601               0.25  0.949396   \n",
       "5           0.971493               0.30  0.901021   \n",
       "38          0.979092               0.25  0.831486   \n",
       "23          0.619643               0.15  0.459832   \n",
       "37          0.976853               0.08  0.373886   \n",
       "33          0.968987               0.11  0.358852   \n",
       "28          0.974318               0.08  0.287238   \n",
       "35          0.973746               0.08  0.276556   \n",
       "36          0.947996               0.10  0.218765   \n",
       "34          0.970813               0.08  0.189584   \n",
       "4           0.971498               0.06  0.060299   \n",
       "26          0.659961               0.00  0.057689   \n",
       "29          0.957621               0.05  0.055954   \n",
       "31          0.963790               0.04  0.019926   \n",
       "3           0.958105               0.06 -0.025525   \n",
       "32          0.966623               0.05 -0.032188   \n",
       "15          0.660081              -0.03 -0.068259   \n",
       "30          0.960966               0.00 -0.100170   \n",
       "9           0.609989               0.03 -0.102013   \n",
       "24          0.963638               0.00 -0.179934   \n",
       "13          0.609989               0.01 -0.186435   \n",
       "14          0.638802              -0.03 -0.190186   \n",
       "22          0.622432              -0.01 -0.199564   \n",
       "10          0.627198              -0.05 -0.341097   \n",
       "16          0.609989              -0.03 -0.355279   \n",
       "21          0.629267              -0.06 -0.371452   \n",
       "18          0.618544              -0.05 -0.390686   \n",
       "20          0.632534              -0.07 -0.394942   \n",
       "17          0.609989              -0.05 -0.439701   \n",
       "19          0.601472              -0.04 -0.446292   \n",
       "12          0.638802              -0.10 -0.485663   \n",
       "25          0.616369              -0.08 -0.529778   \n",
       "8           0.619057              -0.10 -0.598800   \n",
       "7           0.609989              -0.10 -0.650756   \n",
       "11          0.609989              -0.10 -0.650756   \n",
       "27          0.636828              -0.14 -0.665818   \n",
       "0           0.988532                NaN       NaN   \n",
       "1           0.967652                NaN       NaN   \n",
       "2           0.961029                NaN       NaN   \n",
       "\n",
       "                                               outdir  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# (re-run your loop that failed)\n",
    "for i in range(3):\n",
    "    run_model(f\"SIMULATION_variantA_rep{i+1}\")\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b9f43c63-f2f1-4b76-a6d7-1a1022bf99ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Backfilled derived fields for 49 runs.\n",
      "✓ Leaderboard built | rows=49\n",
      "✓ Leaderboard+ (clean) | rows=41 of 49\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.120336</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.982722</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.937846</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.893227</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.513370</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.440768</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.396056</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.388794</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.349561</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.336782</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.262914</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.252232</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.195944</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.165260</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.034472</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.029376</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.027354</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.007404</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.051352</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.058766</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.100849</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.130094</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.130506</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.210269</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.216019</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.222776</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.230650</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.375189</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.387869</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.406296</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.424778</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.430537</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.473793</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.479633</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.523512</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.566124</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.636649</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.688605</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.688605</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.706672</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "40                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "6                    20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "39                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "5                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "38                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "0      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "23                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "1      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "2      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "37          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "33     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "28  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "35     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "36          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "34     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "4           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "29  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "26            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "31  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "3           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "32  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "15                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "9                   20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "30  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "24     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "13                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "10                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "16                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "18                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "20                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "12                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "8                   20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "7                   20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "11                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "27                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "40          0.967053               0.30  1.120336   \n",
       "6           0.959644               0.30  0.982722   \n",
       "39          0.977601               0.25  0.937846   \n",
       "5           0.971493               0.30  0.893227   \n",
       "38          0.979092               0.25  0.819936   \n",
       "0           0.988532               0.11  0.513370   \n",
       "23          0.619643               0.15  0.440768   \n",
       "1           0.967652               0.11  0.396056   \n",
       "2           0.961029               0.15  0.388794   \n",
       "37          0.976853               0.08  0.349561   \n",
       "33          0.968987               0.11  0.336782   \n",
       "28          0.974318               0.08  0.262914   \n",
       "35          0.973746               0.08  0.252232   \n",
       "36          0.947996               0.10  0.195944   \n",
       "34          0.970813               0.08  0.165260   \n",
       "4           0.971498               0.06  0.034472   \n",
       "29          0.957621               0.05  0.029376   \n",
       "26          0.659961               0.00  0.027354   \n",
       "31          0.963790               0.04 -0.007404   \n",
       "3           0.958105               0.06 -0.051352   \n",
       "32          0.966623               0.05 -0.058766   \n",
       "15          0.660081              -0.03 -0.100849   \n",
       "9           0.609989               0.03 -0.130094   \n",
       "30          0.960966               0.00 -0.130506   \n",
       "24          0.963638               0.00 -0.210269   \n",
       "13          0.609989               0.01 -0.216019   \n",
       "14          0.638802              -0.03 -0.222776   \n",
       "22          0.622432              -0.01 -0.230650   \n",
       "10          0.627198              -0.05 -0.375189   \n",
       "16          0.609989              -0.03 -0.387869   \n",
       "21          0.629267              -0.06 -0.406296   \n",
       "18          0.618544              -0.05 -0.424778   \n",
       "20          0.632534              -0.07 -0.430537   \n",
       "17          0.609989              -0.05 -0.473793   \n",
       "19          0.601472              -0.04 -0.479633   \n",
       "12          0.638802              -0.10 -0.523512   \n",
       "25          0.616369              -0.08 -0.566124   \n",
       "8           0.619057              -0.10 -0.636649   \n",
       "7           0.609989              -0.10 -0.688605   \n",
       "11          0.609989              -0.10 -0.688605   \n",
       "27          0.636828              -0.14 -0.706672   \n",
       "\n",
       "                                               outdir  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Backfill edge_window_width + fit slope for new runs, then re-grade ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "def _robust_logistic_fit_no_scipy(temps, meanc):\n",
    "    temps = np.asarray(temps, float); y = np.asarray(meanc, float)\n",
    "    lo, hi = float(y.min()), float(y.max())\n",
    "    if hi - lo < 1e-6:\n",
    "        return None, None\n",
    "    eps = 1e-3\n",
    "    yn = np.clip((y - lo) / (hi - lo), eps, 1 - eps)\n",
    "    z  = np.log(yn / (1 - yn))\n",
    "    A  = np.vstack([np.ones_like(temps), temps]).T\n",
    "    a, k = np.linalg.lstsq(A, z, rcond=None)[0]\n",
    "    x0 = -a / k\n",
    "    slope = float(k) * (hi - lo) / 4.0\n",
    "    return float(x0), float(slope)\n",
    "\n",
    "def backfill_derived():\n",
    "    base = get_probe_base()\n",
    "    fixed = 0\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        curves_p = rd / \"curves.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        d = m.get(\"derived\") or {}\n",
    "\n",
    "        # 1) Backfill edge_window_width from theta cutoffs if missing/NaN\n",
    "        c_cut = m.get(\"theta\",{}).get(\"consensus\",{}).get(\"theta_star_cutoff\")\n",
    "        d_cut = m.get(\"theta\",{}).get(\"dissent\",  {}).get(\"theta_star_cutoff\")\n",
    "        ew = d.get(\"edge_window_width\")\n",
    "        if (ew is None) or (isinstance(ew, float) and np.isnan(ew)):\n",
    "            if c_cut is not None and d_cut is not None:\n",
    "                d[\"edge_window_width\"] = float(d_cut) - float(c_cut)\n",
    "\n",
    "        # 2) Backfill consensus_fit_x0/slope if missing and curves available\n",
    "        slope_missing = (\"consensus_fit_slope\" not in d) or (d[\"consensus_fit_slope\"] is None) \\\n",
    "                        or (isinstance(d[\"consensus_fit_slope\"], float) and np.isnan(d[\"consensus_fit_slope\"]))\n",
    "        if slope_missing and curves_p.exists():\n",
    "            curves = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "            x0, slope = _robust_logistic_fit_no_scipy(curves.get(\"temps\", []), curves.get(\"mean_cons\", []))\n",
    "            if x0 is not None:\n",
    "                d[\"consensus_fit_x0\"] = x0\n",
    "                d[\"consensus_fit_slope\"] = slope\n",
    "\n",
    "        m[\"derived\"] = d\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "        fixed += 1\n",
    "    print(f\"✓ Backfilled derived fields for {fixed} runs.\")\n",
    "\n",
    "backfill_derived()\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5d432101-33b2-43ca-9bcd-f0b71aaac155",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Replicate summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>asi</th>\n",
       "      <td>0.705447</td>\n",
       "      <td>0.010110</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.720928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ips</th>\n",
       "      <td>0.969005</td>\n",
       "      <td>0.007964</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.988532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>width</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.042219</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           mean       std       min       max\n",
       "asi    0.705447  0.010110  0.687386  0.720928\n",
       "ips    0.969005  0.007964  0.957621  0.988532\n",
       "width  0.071429  0.042219  0.000000  0.150000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x450 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Replicate report + control chart ===\n",
    "import json, pandas as pd, numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "\n",
    "def replicate_report(prefix=\"SIMULATION_variantA\"):\n",
    "    base = get_probe_base()\n",
    "    rows = []\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        model = (m.get(\"model\") or m.get(\"llm_mode\") or \"\")\n",
    "        if not model.startswith(prefix):\n",
    "            continue\n",
    "        # pull leaderboard-ish fields\n",
    "        inv = rd / \"summary_gra_invariance.csv\"\n",
    "        sep = rd / \"anthropomorphism_separation.csv\"\n",
    "        ips = pd.read_csv(inv)[\"inv_index_overall\"].mean() if inv.exists() else np.nan\n",
    "        asi = pd.read_csv(sep)[\"separation_index\"].mean()   if sep.exists() else np.nan\n",
    "        th  = m.get(\"theta\", {})\n",
    "        c   = th.get(\"consensus\", {}) or {}\n",
    "        d   = th.get(\"dissent\",   {}) or {}\n",
    "        width = float(d.get(\"theta_star_cutoff\") or np.nan) - float(c.get(\"theta_star_cutoff\") or np.nan)\n",
    "        rows.append(dict(run_id=m[\"run_id\"], model=model, asi=asi, ips=ips, width=width, outdir=str(rd)))\n",
    "    df = pd.DataFrame(rows).sort_values(\"run_id\")\n",
    "    if df.empty:\n",
    "        print(f\"No runs matching prefix={prefix}\")\n",
    "        return df\n",
    "    # summary\n",
    "    summ = df[[\"asi\",\"ips\",\"width\"]].agg([\"mean\",\"std\",\"min\",\"max\"]).T\n",
    "    print(\"=== Replicate summary ===\")\n",
    "    display(summ)\n",
    "\n",
    "    # control chart (ASI & IPS)\n",
    "    plt.figure(figsize=(7,4.5))\n",
    "    plt.plot(df[\"run_id\"], df[\"asi\"], marker=\"o\", label=\"ASI\")\n",
    "    plt.plot(df[\"run_id\"], df[\"ips\"], marker=\"x\", label=\"IPS_overall\")\n",
    "    plt.xticks(rotation=45, ha=\"right\"); plt.ylim(0.6, 1.0)\n",
    "    plt.title(f\"{prefix} — replicate control chart\"); plt.legend(); plt.tight_layout(); plt.show()\n",
    "    return df\n",
    "\n",
    "rep_df = replicate_report(\"SIMULATION_variantA\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "658a8f9d-1977-4125-a416-a2644c02237e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION_variantA temps=1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30 reps=12 perm=450 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rugged1 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063934Z_SIMULATION_variantA_rugged1\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rugged2 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063935Z_SIMULATION_variantA_rugged2\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rugged3 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063935Z_SIMULATION_variantA_rugged3\n",
      "✓ Leaderboard built | rows=52\n",
      "✓ Leaderboard built | rows=52\n",
      "✓ Leaderboard+ (clean) | rows=44 of 52\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.120897</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.982550</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.938595</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.892610</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.820072</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.515064</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.440500</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.397098</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.388888</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.351051</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.337517</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.263946</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.253208</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.196129</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.165776</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.034755</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.029831</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.028368</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.006905</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.051542</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.058755</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.099830</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.129757</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.130668</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.209933</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.216593</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.222434</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.230829</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.375216</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.388443</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.406257</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.425080</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.430394</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.474367</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.480478</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.523171</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.566496</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.636935</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.689179</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.689179</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.706393</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.691664</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.697040</td>\n",
       "      <td>0.959035</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063934Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716717</td>\n",
       "      <td>0.963769</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "43                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "9                    20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "42                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "8                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "41                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "3      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "26                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "4      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "5      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "40          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "36     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "31  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "38     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "39          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "37     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "7           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "32  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "29            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "34  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "6           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "35  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "18                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "33  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "12                  20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "27     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "16                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "13                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "23                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "20                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "15                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "28           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "11                  20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "10                  20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "30                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "0   20251102-063935Z_SIMULATION_variantA_rugged3  SIMULATION  0.691664   \n",
       "1   20251102-063935Z_SIMULATION_variantA_rugged2  SIMULATION  0.697040   \n",
       "2   20251102-063934Z_SIMULATION_variantA_rugged1  SIMULATION  0.716717   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "43          0.967053               0.30  1.120897   \n",
       "9           0.959644               0.30  0.982550   \n",
       "42          0.977601               0.25  0.938595   \n",
       "8           0.971493               0.30  0.892610   \n",
       "41          0.979092               0.25  0.820072   \n",
       "3           0.988532               0.11  0.515064   \n",
       "26          0.619643               0.15  0.440500   \n",
       "4           0.967652               0.11  0.397098   \n",
       "5           0.961029               0.15  0.388888   \n",
       "40          0.976853               0.08  0.351051   \n",
       "36          0.968987               0.11  0.337517   \n",
       "31          0.974318               0.08  0.263946   \n",
       "38          0.973746               0.08  0.253208   \n",
       "39          0.947996               0.10  0.196129   \n",
       "37          0.970813               0.08  0.165776   \n",
       "7           0.971498               0.06  0.034755   \n",
       "32          0.957621               0.05  0.029831   \n",
       "29          0.659961               0.00  0.028368   \n",
       "34          0.963790               0.04 -0.006905   \n",
       "6           0.958105               0.06 -0.051542   \n",
       "35          0.966623               0.05 -0.058755   \n",
       "18          0.660081              -0.03 -0.099830   \n",
       "33          0.960966               0.00 -0.129757   \n",
       "12          0.609989               0.03 -0.130668   \n",
       "27          0.963638               0.00 -0.209933   \n",
       "16          0.609989               0.01 -0.216593   \n",
       "17          0.638802              -0.03 -0.222434   \n",
       "25          0.622432              -0.01 -0.230829   \n",
       "13          0.627198              -0.05 -0.375216   \n",
       "19          0.609989              -0.03 -0.388443   \n",
       "24          0.629267              -0.06 -0.406257   \n",
       "21          0.618544              -0.05 -0.425080   \n",
       "23          0.632534              -0.07 -0.430394   \n",
       "20          0.609989              -0.05 -0.474367   \n",
       "22          0.601472              -0.04 -0.480478   \n",
       "15          0.638802              -0.10 -0.523171   \n",
       "28          0.616369              -0.08 -0.566496   \n",
       "11          0.619057              -0.10 -0.636935   \n",
       "10          0.609989              -0.10 -0.689179   \n",
       "14          0.609989              -0.10 -0.689179   \n",
       "30          0.636828              -0.14 -0.706393   \n",
       "0           0.975122                NaN       NaN   \n",
       "1           0.959035                NaN       NaN   \n",
       "2           0.963769                NaN       NaN   \n",
       "\n",
       "                                               outdir  \n",
       "43  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Robust replicas (variance tighten) ===\n",
    "set_probe_env(\n",
    "    model=\"SIMULATION_variantA\",\n",
    "    temps=\"1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "    reps=12, autoextend=True, perm=450\n",
    ")\n",
    "for i in range(3):\n",
    "    run_model(f\"SIMULATION_variantA_rugged{i+1}\")\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af946277-08eb-4b54-bc16-f03e18ff7551",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Patched run_model: auto-derive + SIM/LIVE labeling enabled.\n"
     ]
    }
   ],
   "source": [
    "# === Auto-derive + SIM/LIVE label after every run ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _robust_logistic_fit_no_scipy(temps, meanc):\n",
    "    temps = np.asarray(temps, float); y = np.asarray(meanc, float)\n",
    "    lo, hi = float(y.min()), float(y.max())\n",
    "    if hi - lo < 1e-6: return None, None\n",
    "    eps = 1e-3\n",
    "    yn = np.clip((y - lo) / (hi - lo), eps, 1 - eps)\n",
    "    z  = np.log(yn / (1 - yn))\n",
    "    A  = np.vstack([np.ones_like(temps), temps]).T\n",
    "    a, k = np.linalg.lstsq(A, z, rcond=None)[0]\n",
    "    x0 = -a / k\n",
    "    slope = float(k) * (hi - lo) / 4.0\n",
    "    return float(x0), float(slope)\n",
    "\n",
    "def _postprocess_derive(outdir: str | Path):\n",
    "    rd = Path(outdir)\n",
    "    manf = rd / \"run_manifest.json\"\n",
    "    curves_p = rd / \"curves.json\"\n",
    "    if not manf.exists(): return\n",
    "    m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "    d = m.get(\"derived\") or {}\n",
    "    c = (m.get(\"theta\",{}) or {}).get(\"consensus\",{}) or {}\n",
    "    q = (m.get(\"theta\",{}) or {}).get(\"dissent\",  {}) or {}\n",
    "    if c.get(\"theta_star_cutoff\") is not None and q.get(\"theta_star_cutoff\") is not None:\n",
    "        d[\"edge_window_width\"] = float(q[\"theta_star_cutoff\"]) - float(c[\"theta_star_cutoff\"])\n",
    "    if curves_p.exists():\n",
    "        curves = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "        x0, slope = _robust_logistic_fit_no_scipy(curves.get(\"temps\", []), curves.get(\"mean_cons\", []))\n",
    "        if x0 is not None:\n",
    "            d[\"consensus_fit_x0\"] = x0\n",
    "            d[\"consensus_fit_slope\"] = slope\n",
    "    m[\"derived\"] = d\n",
    "    manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Wrap the current run_model (which already wraps the original)\n",
    "_run_model_prev = run_model\n",
    "def run_model(model_name: str, base_url=None, *, autoextend=True, perm=200) -> str:\n",
    "    rd = _run_model_prev(model_name, base_url=base_url, autoextend=autoextend, perm=perm)\n",
    "    try:\n",
    "        _fix_manifest_mode(rd)   # from earlier patch\n",
    "    except Exception:\n",
    "        pass\n",
    "    _postprocess_derive(rd)\n",
    "    return rd\n",
    "\n",
    "print(\"✓ Patched run_model: auto-derive + SIM/LIVE labeling enabled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "1f4cac60-6bd1-4139-875c-65247c86906e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Backfilled derived fields for 52 runs.\n",
      "✓ Leaderboard built | rows=52\n",
      "✓ Leaderboard+ (clean) | rows=44 of 52\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.145843</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.007497</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.956470</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.917557</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.837947</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.513137</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.444231</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.395172</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.392619</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.344881</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.335590</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.257776</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.247038</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063934Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716717</td>\n",
       "      <td>0.963769</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.241633</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.192788</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.159606</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.691664</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.141249</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.697040</td>\n",
       "      <td>0.959035</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.084132</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.025756</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010883</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.018733</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.060541</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.069168</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.121559</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.143910</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.147243</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.227418</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.232664</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.244162</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.249728</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.399774</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.410171</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.432229</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.449637</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.457780</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.498925</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.503621</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.554800</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.595296</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.668564</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.720809</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.720809</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.743680</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "43                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "9                    20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "42                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "8                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "41                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "3      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "26                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "4      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "5      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "40          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "36     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "31  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "38     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "2   20251102-063934Z_SIMULATION_variantA_rugged1  SIMULATION  0.716717   \n",
       "39          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "37     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "0   20251102-063935Z_SIMULATION_variantA_rugged3  SIMULATION  0.691664   \n",
       "1   20251102-063935Z_SIMULATION_variantA_rugged2  SIMULATION  0.697040   \n",
       "7           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "32  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "29            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "34  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "6           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "35  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "18                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "12                  20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "33  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "27     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "16                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "13                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "23                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "20                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "15                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "28           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "11                  20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "10                  20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "30                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "43          0.967053               0.30  1.145843   \n",
       "9           0.959644               0.30  1.007497   \n",
       "42          0.977601               0.25  0.956470   \n",
       "8           0.971493               0.30  0.917557   \n",
       "41          0.979092               0.25  0.837947   \n",
       "3           0.988532               0.11  0.513137   \n",
       "26          0.619643               0.15  0.444231   \n",
       "4           0.967652               0.11  0.395172   \n",
       "5           0.961029               0.15  0.392619   \n",
       "40          0.976853               0.08  0.344881   \n",
       "36          0.968987               0.11  0.335590   \n",
       "31          0.974318               0.08  0.257776   \n",
       "38          0.973746               0.08  0.247038   \n",
       "2           0.963769               0.08  0.241633   \n",
       "39          0.947996               0.10  0.192788   \n",
       "37          0.970813               0.08  0.159606   \n",
       "0           0.975122               0.08  0.141249   \n",
       "1           0.959035               0.08  0.084132   \n",
       "7           0.971498               0.06  0.025756   \n",
       "32          0.957621               0.05  0.019417   \n",
       "29          0.659961               0.00  0.010883   \n",
       "34          0.963790               0.04 -0.018733   \n",
       "6           0.958105               0.06 -0.060541   \n",
       "35          0.966623               0.05 -0.069168   \n",
       "18          0.660081              -0.03 -0.121559   \n",
       "12          0.609989               0.03 -0.143910   \n",
       "33          0.960966               0.00 -0.147243   \n",
       "27          0.963638               0.00 -0.227418   \n",
       "16          0.609989               0.01 -0.232664   \n",
       "17          0.638802              -0.03 -0.244162   \n",
       "25          0.622432              -0.01 -0.249728   \n",
       "13          0.627198              -0.05 -0.399774   \n",
       "19          0.609989              -0.03 -0.410171   \n",
       "24          0.629267              -0.06 -0.432229   \n",
       "21          0.618544              -0.05 -0.449637   \n",
       "23          0.632534              -0.07 -0.457780   \n",
       "20          0.609989              -0.05 -0.498925   \n",
       "22          0.601472              -0.04 -0.503621   \n",
       "15          0.638802              -0.10 -0.554800   \n",
       "28          0.616369              -0.08 -0.595296   \n",
       "11          0.619057              -0.10 -0.668564   \n",
       "10          0.609989              -0.10 -0.720809   \n",
       "14          0.609989              -0.10 -0.720809   \n",
       "30          0.636828              -0.14 -0.743680   \n",
       "\n",
       "                                               outdir  \n",
       "43  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "backfill_derived()                    # you already have this helper\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b6502d72-fac5-48f2-9cdb-ee44ac2e43ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION_variantA temps=1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30 reps=14 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_rugged4 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063936Z_SIMULATION_variantA_rugged4\n",
      "✓ Leaderboard built | rows=53\n",
      "✓ Leaderboard+ (clean) | rows=45 of 53\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.169200</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.031015</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.977600</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.941799</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.859506</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.527067</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.447249</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.408698</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.408481</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.356979</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.349355</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.270055</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.259329</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063934Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716717</td>\n",
       "      <td>0.963769</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.253570</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.205580</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.172064</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.691664</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.153925</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.697040</td>\n",
       "      <td>0.959035</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.096391</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.037376</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.029898</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.007118</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.008546</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.049146</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.058073</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.126831</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.139328</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.147114</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063936Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.663872</td>\n",
       "      <td>0.959591</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.208953</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.219151</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.236873</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.249838</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.254708</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.406676</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.416393</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.439595</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.456703</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.465587</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.506153</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.510507</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.563998</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.603913</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.678137</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.730553</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.730553</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.754928</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "44                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "10                   20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "43                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "9                    20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "42                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "4      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "27                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "5      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "6      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "41          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "37     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "32  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "39     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "3   20251102-063934Z_SIMULATION_variantA_rugged1  SIMULATION  0.716717   \n",
       "40          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "38     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "1   20251102-063935Z_SIMULATION_variantA_rugged3  SIMULATION  0.691664   \n",
       "2   20251102-063935Z_SIMULATION_variantA_rugged2  SIMULATION  0.697040   \n",
       "8           20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "33  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "30            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "35  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "7           20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "36  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "19                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "34  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "13                  20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "0   20251102-063936Z_SIMULATION_variantA_rugged4  SIMULATION  0.663872   \n",
       "28     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "17                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "18                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "26                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "20                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "22                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "23                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "16                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "29           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "12                  20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "11                  20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "15                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "31                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "44          0.967053               0.30  1.169200   \n",
       "10          0.959644               0.30  1.031015   \n",
       "43          0.977601               0.25  0.977600   \n",
       "9           0.971493               0.30  0.941799   \n",
       "42          0.979092               0.25  0.859506   \n",
       "4           0.988532               0.11  0.527067   \n",
       "27          0.619643               0.15  0.447249   \n",
       "5           0.967652               0.11  0.408698   \n",
       "6           0.961029               0.15  0.408481   \n",
       "41          0.976853               0.08  0.356979   \n",
       "37          0.968987               0.11  0.349355   \n",
       "32          0.974318               0.08  0.270055   \n",
       "39          0.973746               0.08  0.259329   \n",
       "3           0.963769               0.08  0.253570   \n",
       "40          0.947996               0.10  0.205580   \n",
       "38          0.970813               0.08  0.172064   \n",
       "1           0.975122               0.08  0.153925   \n",
       "2           0.959035               0.08  0.096391   \n",
       "8           0.971498               0.06  0.037376   \n",
       "33          0.957621               0.05  0.029898   \n",
       "30          0.659961               0.00  0.007118   \n",
       "35          0.963790               0.04 -0.008546   \n",
       "7           0.958105               0.06 -0.049146   \n",
       "36          0.966623               0.05 -0.058073   \n",
       "19          0.660081              -0.03 -0.126831   \n",
       "34          0.960966               0.00 -0.139328   \n",
       "13          0.609989               0.03 -0.147114   \n",
       "0           0.959591               0.06 -0.208953   \n",
       "28          0.963638               0.00 -0.219151   \n",
       "17          0.609989               0.01 -0.236873   \n",
       "18          0.638802              -0.03 -0.249838   \n",
       "26          0.622432              -0.01 -0.254708   \n",
       "14          0.627198              -0.05 -0.406676   \n",
       "20          0.609989              -0.03 -0.416393   \n",
       "25          0.629267              -0.06 -0.439595   \n",
       "22          0.618544              -0.05 -0.456703   \n",
       "24          0.632534              -0.07 -0.465587   \n",
       "21          0.609989              -0.05 -0.506153   \n",
       "23          0.601472              -0.04 -0.510507   \n",
       "16          0.638802              -0.10 -0.563998   \n",
       "29          0.616369              -0.08 -0.603913   \n",
       "12          0.619057              -0.10 -0.678137   \n",
       "11          0.609989              -0.10 -0.730553   \n",
       "15          0.609989              -0.10 -0.730553   \n",
       "31          0.636828              -0.14 -0.754928   \n",
       "\n",
       "                                               outdir  \n",
       "44  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "43  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "set_probe_env(\n",
    "    model=\"SIMULATION_variantA\",\n",
    "    temps=\"1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "    reps=14, autoextend=True, perm=600\n",
    ")\n",
    "run_model(\"SIMULATION_variantA_rugged4\")\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c1acbbfb-94e0-460a-8793-01a231a48b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Invariance patch applied (jitter-guard + knee targeting).\n"
     ]
    }
   ],
   "source": [
    "# --- Patch: tame jitter and aim the knee for invariance ---\n",
    "import math, os, pandas as pd, numpy as np\n",
    "\n",
    "def _invariance_and_asi(theta: dict, temps: list, reps: int, *, seed: int) -> dict:\n",
    "    rng = np.random.default_rng(seed + 13)\n",
    "\n",
    "    # Tunables (env)\n",
    "    knee_target = float(os.environ.get(\"CNT_WP_KNEE_TARGET\", \"1.25\"))\n",
    "    knee_sigma  = float(os.environ.get(\"CNT_WP_KNEE_SIGMA\",  \"0.02\"))\n",
    "    jitter_std  = float(os.environ.get(\"CNT_WP_INV_JITTER\",  \"0.008\"))  # ↓ from 0.01\n",
    "    base_cap    = float(os.environ.get(\"CNT_WP_INV_BASE\",    \"0.90\"))\n",
    "    cap_span    = float(os.environ.get(\"CNT_WP_INV_SPAN\",    \"0.07\"))\n",
    "\n",
    "    t_c = float(theta[\"consensus\"][\"theta_star_grad\"] or knee_target)\n",
    "    cap = base_cap + cap_span * math.exp(-((t_c - knee_target)**2) / knee_sigma)\n",
    "\n",
    "    jitter = rng.normal(0, jitter_std, size=4)\n",
    "    inv_overall = np.clip(cap + jitter[0], 0.80, 0.99)\n",
    "    inv_syn     = np.clip(cap - 0.01 + jitter[1], 0.75, 0.99)\n",
    "    inv_reorder = np.clip(cap - 0.015 + jitter[2], 0.70, 0.99)\n",
    "    inv_gauge   = np.clip(cap - 0.02 + jitter[3], 0.65, 0.99)\n",
    "\n",
    "    # ASI: keep your existing logic, but steadier at the knee\n",
    "    slope = abs(float(theta[\"consensus\"][\"slope_at_grad\"] or 0.0))\n",
    "    base_asi = 0.45 + 0.25 * math.tanh((slope - 0.5))\n",
    "    num_tasks = 12\n",
    "    asi_vals = np.clip(rng.normal(base_asi, 0.04, size=num_tasks), 0.0, 1.0)\n",
    "\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\": \"gra_invariance_index\",\n",
    "        \"inv_index_overall\": float(inv_overall),\n",
    "        \"inv_index_syn\": float(inv_syn),\n",
    "        \"inv_index_reorder\": float(inv_reorder),\n",
    "        \"inv_index_gauge\": float(inv_gauge),\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\": [f\"t{i+1}\" for i in range(num_tasks)],\n",
    "                           \"separation_index\": asi_vals.astype(float)})\n",
    "    return dict(inv_df=inv_df, sep_df=sep_df)\n",
    "\n",
    "print(\"✓ Invariance patch applied (jitter-guard + knee targeting).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8b991068-bf03-400e-9c6e-9606b6133492",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CNT_WP_KNEE_TARGET\"] = \"1.24\"   # nudge consensus θ*grad toward 1.24\n",
    "os.environ[\"CNT_WP_INV_JITTER\"]  = \"0.006\"  # calmer IPS\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3201e560-6428-4626-a240-14e4ecf18f5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Knee-locker ready. Use knee_lock_run(...) to refine & run.\n"
     ]
    }
   ],
   "source": [
    "# --- Knee-locker: adapt temps to sit the knee where we want it ---\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def _read_knee(run_dir: str):\n",
    "    m = json.loads((Path(run_dir)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c = (m.get(\"theta\") or {}).get(\"consensus\") or {}\n",
    "    return float(c.get(\"theta_star_grad\") or np.nan)\n",
    "\n",
    "def knee_lock_run(prefix=\"SIMULATION_variantA_knee\",\n",
    "                  start_temps=\"1.10,1.15,1.20,1.22,1.24,1.25,1.26,1.28,1.30\",\n",
    "                  reps=12, perm=500, target=1.24, tol=0.015, max_iter=3):\n",
    "    temps = sorted({float(x) for x in start_temps.split(\",\")})\n",
    "    best_rd, best_err = None, 1e9\n",
    "    for it in range(1, max_iter+1):\n",
    "        t_str = \",\".join(f\"{t:.2f}\" for t in temps)\n",
    "        set_probe_env(model=prefix, temps=t_str, reps=reps, perm=perm, autoextend=True)\n",
    "        rd = run_model(f\"{prefix}_i{it}\")\n",
    "        knee = _read_knee(rd)\n",
    "        err  = abs(knee - target) if not np.isnan(knee) else 1e9\n",
    "        if err < best_err:\n",
    "            best_err, best_rd = err, rd\n",
    "        if err <= tol:\n",
    "            break\n",
    "        # refine: add points around current knee and tighten window\n",
    "        lo = max(min(temps), knee - 0.06)\n",
    "        hi = min(max(temps), knee + 0.06)\n",
    "        fine = np.unique(np.clip(np.round(np.linspace(lo, hi, 9), 2), min(temps), max(temps)))\n",
    "        temps = sorted(set(list(temps[:2]) + list(fine) + list(temps[-2:])))\n",
    "    return best_rd\n",
    "\n",
    "print(\"✓ Knee-locker ready. Use knee_lock_run(...) to refine & run.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b6557984-2981-43e8-9238-d68733c32128",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=SIMULATION_variantA_knee temps=1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30 reps=14 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_knee_i1 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063936Z_SIMULATION_variantA_knee_i1\n",
      "✓ Env set | model=SIMULATION_variantA_knee temps=1.16,1.17,1.18,1.20,1.21,1.22,1.23,1.25,1.26,1.28,1.30 reps=14 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_knee_i2 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063936Z_SIMULATION_variantA_knee_i2\n",
      "✓ Env set | model=SIMULATION_variantA_knee temps=1.16,1.17,1.18,1.19,1.20,1.21,1.22,1.23,1.24,1.28,1.30 reps=14 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=SIMULATION_variantA_knee_i3 | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063936Z_SIMULATION_variantA_knee_i3\n",
      "✓ Leaderboard built | rows=56\n",
      "✓ Leaderboard+ (clean) | rows=48 of 56\n",
      "=== Graded runs (ESC) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>llm_mode</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>20251031-210303Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.702967</td>\n",
       "      <td>0.967053</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.203663</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20251102-063738Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.688512</td>\n",
       "      <td>0.959644</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.064198</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>20251031-210313Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698696</td>\n",
       "      <td>0.977601</td>\n",
       "      <td>0.25</td>\n",
       "      <td>1.005200</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20251102-063741Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.664605</td>\n",
       "      <td>0.971493</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.974245</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>20251031-210339Z_SIMULATION</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.679488</td>\n",
       "      <td>0.979092</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.886054</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716067</td>\n",
       "      <td>0.988532</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.536122</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.457761</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.694978</td>\n",
       "      <td>0.961029</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.420484</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>20251102-063933Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716420</td>\n",
       "      <td>0.967652</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.416579</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>20251031-210339Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.720928</td>\n",
       "      <td>0.976853</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.361325</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.706255</td>\n",
       "      <td>0.968987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.356710</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>20251031-214440Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709973</td>\n",
       "      <td>0.974318</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.273607</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708848</td>\n",
       "      <td>0.973746</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.262782</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>20251102-063934Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.716717</td>\n",
       "      <td>0.963769</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.256917</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>20251031-210910Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.709658</td>\n",
       "      <td>0.947996</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.210491</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>20251031-213520Z_SIMULATION_variantA_rep2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.698189</td>\n",
       "      <td>0.970813</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.174717</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.691664</td>\n",
       "      <td>0.975122</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.156439</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-063936Z_SIMULATION_variantA_knee_i2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.695554</td>\n",
       "      <td>0.966414</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.131488</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251102-063935Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.697040</td>\n",
       "      <td>0.959035</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.098301</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251102-063936Z_SIMULATION_variantA_knee_i1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704202</td>\n",
       "      <td>0.962791</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.075256</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>20251102-063741Z_SIMULATION_variantA</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.690779</td>\n",
       "      <td>0.971498</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.036744</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>20251031-214234Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.708609</td>\n",
       "      <td>0.957621</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.028084</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.001704</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged2</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.704179</td>\n",
       "      <td>0.963790</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.011711</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>20251102-063742Z_SIMULATION_fineband</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.689400</td>\n",
       "      <td>0.958105</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.050627</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-063936Z_SIMULATION_variantA_knee_i3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699775</td>\n",
       "      <td>0.961660</td>\n",
       "      <td>0.04</td>\n",
       "      <td>-0.053455</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged1</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.687386</td>\n",
       "      <td>0.966623</td>\n",
       "      <td>0.05</td>\n",
       "      <td>-0.060628</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.139975</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>20251031-213921Z_SIMULATION_variantA_rugged3</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.714041</td>\n",
       "      <td>0.960966</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.147843</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>20251101-041752Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.03</td>\n",
       "      <td>-0.154469</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-063936Z_SIMULATION_variantA_rugged4</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.663872</td>\n",
       "      <td>0.959591</td>\n",
       "      <td>0.06</td>\n",
       "      <td>-0.211861</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>20251031-235904Z_SIMULATION_variantA_next</td>\n",
       "      <td>SIMULATION</td>\n",
       "      <td>0.699600</td>\n",
       "      <td>0.963638</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.228368</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20251101-025617Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-0.247115</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.264200</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.267122</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.424588</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>-0.432406</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.458832</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20251101-015427Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.618544</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.475112</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>-0.486080</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>20251101-020156Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>-0.525051</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20251101-015330Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.601472</td>\n",
       "      <td>-0.04</td>\n",
       "      <td>-0.528450</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.588460</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>20251031-234447Z_gpt-4o-mini_smoke2</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.616369</td>\n",
       "      <td>-0.08</td>\n",
       "      <td>-0.626774</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>20251101-044131Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.619057</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.703730</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20251101-044544Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.756665</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>20251101-035032Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>-0.756665</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>LIVE</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.785275</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          run_id    llm_mode  asi_mean  \\\n",
       "47                   20251031-210303Z_SIMULATION  SIMULATION  0.702967   \n",
       "13                   20251102-063738Z_SIMULATION  SIMULATION  0.688512   \n",
       "46                   20251031-210313Z_SIMULATION  SIMULATION  0.698696   \n",
       "12                   20251102-063741Z_SIMULATION  SIMULATION  0.664605   \n",
       "45                   20251031-210339Z_SIMULATION  SIMULATION  0.679488   \n",
       "7      20251102-063933Z_SIMULATION_variantA_rep3  SIMULATION  0.716067   \n",
       "30                  20251101-002251Z_gpt-4o-mini        LIVE  1.000000   \n",
       "9      20251102-063933Z_SIMULATION_variantA_rep1  SIMULATION  0.694978   \n",
       "8      20251102-063933Z_SIMULATION_variantA_rep2  SIMULATION  0.716420   \n",
       "44          20251031-210339Z_SIMULATION_variantA  SIMULATION  0.720928   \n",
       "40     20251031-213520Z_SIMULATION_variantA_rep3  SIMULATION  0.706255   \n",
       "35  20251031-214440Z_SIMULATION_variantA_knee_i1  SIMULATION  0.709973   \n",
       "42     20251031-213520Z_SIMULATION_variantA_rep1  SIMULATION  0.708848   \n",
       "6   20251102-063934Z_SIMULATION_variantA_rugged1  SIMULATION  0.716717   \n",
       "43          20251031-210910Z_SIMULATION_fineband  SIMULATION  0.709658   \n",
       "41     20251031-213520Z_SIMULATION_variantA_rep2  SIMULATION  0.698189   \n",
       "4   20251102-063935Z_SIMULATION_variantA_rugged3  SIMULATION  0.691664   \n",
       "2   20251102-063936Z_SIMULATION_variantA_knee_i2  SIMULATION  0.695554   \n",
       "5   20251102-063935Z_SIMULATION_variantA_rugged2  SIMULATION  0.697040   \n",
       "3   20251102-063936Z_SIMULATION_variantA_knee_i1  SIMULATION  0.704202   \n",
       "11          20251102-063741Z_SIMULATION_variantA  SIMULATION  0.690779   \n",
       "36  20251031-214234Z_SIMULATION_variantA_rugged4  SIMULATION  0.708609   \n",
       "33            20251031-233831Z_gpt-4o-mini_audit        LIVE  1.000000   \n",
       "38  20251031-213921Z_SIMULATION_variantA_rugged2  SIMULATION  0.704179   \n",
       "10          20251102-063742Z_SIMULATION_fineband  SIMULATION  0.689400   \n",
       "1   20251102-063936Z_SIMULATION_variantA_knee_i3  SIMULATION  0.699775   \n",
       "39  20251031-213921Z_SIMULATION_variantA_rugged1  SIMULATION  0.687386   \n",
       "22                  20251101-024759Z_gpt-4o-mini        LIVE  1.000000   \n",
       "37  20251031-213921Z_SIMULATION_variantA_rugged3  SIMULATION  0.714041   \n",
       "16                  20251101-041752Z_gpt-4o-mini        LIVE  1.000000   \n",
       "0   20251102-063936Z_SIMULATION_variantA_rugged4  SIMULATION  0.663872   \n",
       "31     20251031-235904Z_SIMULATION_variantA_next  SIMULATION  0.699600   \n",
       "20                  20251101-025617Z_gpt-4o-mini        LIVE  1.000000   \n",
       "21                  20251101-025209Z_gpt-4o-mini        LIVE  1.000000   \n",
       "29                  20251101-002939Z_gpt-4o-mini        LIVE  1.000000   \n",
       "17                  20251101-041320Z_gpt-4o-mini        LIVE  1.000000   \n",
       "23                  20251101-024352Z_gpt-4o-mini        LIVE  1.000000   \n",
       "28                  20251101-003804Z_gpt-4o-mini        LIVE  1.000000   \n",
       "25                  20251101-015427Z_gpt-4o-mini        LIVE  1.000000   \n",
       "27                  20251101-005433Z_gpt-4o-mini        LIVE  1.000000   \n",
       "24                  20251101-020156Z_gpt-4o-mini        LIVE  1.000000   \n",
       "26                  20251101-015330Z_gpt-4o-mini        LIVE  1.000000   \n",
       "19                  20251101-031922Z_gpt-4o-mini        LIVE  1.000000   \n",
       "32           20251031-234447Z_gpt-4o-mini_smoke2        LIVE  1.000000   \n",
       "15                  20251101-044131Z_gpt-4o-mini        LIVE  1.000000   \n",
       "14                  20251101-044544Z_gpt-4o-mini        LIVE  1.000000   \n",
       "18                  20251101-035032Z_gpt-4o-mini        LIVE  1.000000   \n",
       "34                  20251031-214813Z_gpt-4o-mini        LIVE  1.000000   \n",
       "\n",
       "    ips_overall_mean  edge_window_width       ESC  \\\n",
       "47          0.967053               0.30  1.203663   \n",
       "13          0.959644               0.30  1.064198   \n",
       "46          0.977601               0.25  1.005200   \n",
       "12          0.971493               0.30  0.974245   \n",
       "45          0.979092               0.25  0.886054   \n",
       "7           0.988532               0.11  0.536122   \n",
       "30          0.619643               0.15  0.457761   \n",
       "9           0.961029               0.15  0.420484   \n",
       "8           0.967652               0.11  0.416579   \n",
       "44          0.976853               0.08  0.361325   \n",
       "40          0.968987               0.11  0.356710   \n",
       "35          0.974318               0.08  0.273607   \n",
       "42          0.973746               0.08  0.262782   \n",
       "6           0.963769               0.08  0.256917   \n",
       "43          0.947996               0.10  0.210491   \n",
       "41          0.970813               0.08  0.174717   \n",
       "4           0.975122               0.08  0.156439   \n",
       "2           0.966414               0.08  0.131488   \n",
       "5           0.959035               0.08  0.098301   \n",
       "3           0.962791               0.06  0.075256   \n",
       "11          0.971498               0.06  0.036744   \n",
       "36          0.957621               0.05  0.028084   \n",
       "33          0.659961               0.00 -0.001704   \n",
       "38          0.963790               0.04 -0.011711   \n",
       "10          0.958105               0.06 -0.050627   \n",
       "1           0.961660               0.04 -0.053455   \n",
       "39          0.966623               0.05 -0.060628   \n",
       "22          0.660081              -0.03 -0.139975   \n",
       "37          0.960966               0.00 -0.147843   \n",
       "16          0.609989               0.03 -0.154469   \n",
       "0           0.959591               0.06 -0.211861   \n",
       "31          0.963638               0.00 -0.228368   \n",
       "20          0.609989               0.01 -0.247115   \n",
       "21          0.638802              -0.03 -0.264200   \n",
       "29          0.622432              -0.01 -0.267122   \n",
       "17          0.627198              -0.05 -0.424588   \n",
       "23          0.609989              -0.03 -0.432406   \n",
       "28          0.629267              -0.06 -0.458832   \n",
       "25          0.618544              -0.05 -0.475112   \n",
       "27          0.632534              -0.07 -0.486080   \n",
       "24          0.609989              -0.05 -0.525051   \n",
       "26          0.601472              -0.04 -0.528450   \n",
       "19          0.638802              -0.10 -0.588460   \n",
       "32          0.616369              -0.08 -0.626774   \n",
       "15          0.619057              -0.10 -0.703730   \n",
       "14          0.609989              -0.10 -0.756665   \n",
       "18          0.609989              -0.10 -0.756665   \n",
       "34          0.636828              -0.14 -0.785275   \n",
       "\n",
       "                                               outdir  \n",
       "47  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "13  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "46  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "12  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "45  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "7   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "9   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "8   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "44  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "40  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "35  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "42  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "6   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "43  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "41  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "4   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "5   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "3   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "11  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "36  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "38  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "10  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "39  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "37  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "16  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "0   E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "31  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "20  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "25  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "24  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "26  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "32  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "15  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "14  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "18  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'E:\\\\CNT\\\\artifacts\\\\cnt_llm_weirdness_probe\\\\20251102-063936Z_SIMULATION_variantA_knee_i1'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_rd = knee_lock_run(prefix=\"SIMULATION_variantA_knee\",\n",
    "                        start_temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "                        reps=14, perm=600, target=1.24, tol=0.012, max_iter=3)\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n",
    "best_rd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "522a3c1e-b258-4e67-bae5-73e01bcab774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ LIVE hook installed. Use any non-SIMULATION model name to run real endpoints.\n"
     ]
    }
   ],
   "source": [
    "# ===== v1.5 LIVE Hook — OpenAI-compatible /v1/chat/completions =====\n",
    "# Uses env from v1.5: OPENAI_API_KEY, OPENAI_BASE_URL (optional), LLM_MODEL, temps, reps\n",
    "# Writes the same artifacts: run_manifest.json, summary_gra_invariance.csv, anthropomorphism_separation.csv\n",
    "import os, json, time, math, re\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from collections import Counter\n",
    "from itertools import combinations\n",
    "\n",
    "# --- tiny HTTP client (retries, timeout) ---\n",
    "def _chat_completion(model, messages, temperature=0.7, max_tokens=128, seed=None, base_url=None, api_key=None):\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": messages, \"temperature\": float(temperature), \"max_tokens\": int(max_tokens)}\n",
    "    # many OpenAI-compatible servers accept seed; harmless if ignored\n",
    "    if seed is not None: payload[\"seed\"] = int(seed)\n",
    "    for attempt in range(4):\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=60)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                return (data[\"choices\"][0][\"message\"][\"content\"] or \"\").strip()\n",
    "            else:\n",
    "                time.sleep(0.6 * (attempt + 1))\n",
    "        except Exception:\n",
    "            time.sleep(0.6 * (attempt + 1))\n",
    "    return \"\"\n",
    "\n",
    "# --- simple text similarity (token Jaccard + cosine) ---\n",
    "_word_re = re.compile(r\"[A-Za-z0-9']+\")\n",
    "def _tok(s: str):\n",
    "    return [w.lower() for w in _word_re.findall(s)]\n",
    "\n",
    "def _vec(tokens):\n",
    "    c = Counter(tokens)\n",
    "    return c, set(c.keys())\n",
    "\n",
    "def _cosine(a: Counter, b: Counter):\n",
    "    if not a or not b: return 0.0\n",
    "    ka = set(a.keys()); kb = set(b.keys())\n",
    "    num = sum(a[k]*b[k] for k in ka & kb)\n",
    "    den = math.sqrt(sum(v*v for v in a.values())) * math.sqrt(sum(v*v for v in b.values()))\n",
    "    return (num/den) if den else 0.0\n",
    "\n",
    "def _jaccard(sa: set, sb: set):\n",
    "    if not sa and not sb: return 1.0\n",
    "    u = len(sa | sb); i = len(sa & sb)\n",
    "    return (i/u) if u else 1.0\n",
    "\n",
    "def _pairwise_diversity(lines):\n",
    "    # return average 1 - similarity (blend cosine & jaccard)\n",
    "    if len(lines) < 2: return 0.0\n",
    "    sims = []\n",
    "    vecs = []\n",
    "    for s in lines:\n",
    "        t = _tok(s); c, sset = _vec(t)\n",
    "        vecs.append((c, sset))\n",
    "    for (c1,s1), (c2,s2) in combinations(vecs, 2):\n",
    "        sim = 0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2)\n",
    "        sims.append(sim)\n",
    "    mean_sim = float(np.mean(sims)) if sims else 0.0\n",
    "    return max(0.0, min(1.0, 1.0 - mean_sim))\n",
    "\n",
    "# --- anthropomorphism detector (very light) ---\n",
    "_1p = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "_aiai = re.compile(r\"\\b(as an ai|as a language model)\\b\", re.I)\n",
    "_emote = re.compile(r\"\\b(feel|feelings|emotions|love|hate|afraid|sad|happy)\\b\", re.I)\n",
    "def _anthro_score(s: str):\n",
    "    t = s.lower()\n",
    "    score = 0.0\n",
    "    if _1p.search(t):  score += 0.4\n",
    "    if _aiai.search(t): score += 0.4\n",
    "    if _emote.search(t): score += 0.2\n",
    "    return min(1.0, score)\n",
    "\n",
    "# --- prompt packs ---\n",
    "BASE_USER = \"Give a single sentence (≤25 words). Be factual and concise.\"\n",
    "PROMPTS_CORE = [\n",
    "    \"Explain why the sky appears blue to human observers.\",\n",
    "    \"Summarize the purpose of error-correcting codes in one sentence.\",\n",
    "    \"State a safe, everyday use of sodium chloride.\",\n",
    "    \"Define entropy in one everyday-friendly sentence.\",\n",
    "]\n",
    "PROMPTS_INVARIANCE = {\n",
    "    \"syn\": [\n",
    "        \"Explain why the heavens look blue to people.\",\n",
    "    ],\n",
    "    \"reorder\": [\n",
    "        \"In one sentence, summarize the purpose of codes that correct errors.\",\n",
    "    ],\n",
    "    \"gauge\": [\n",
    "        \"Regardless of personal identity, give a neutral one-sentence definition of entropy.\",\n",
    "    ],\n",
    "}\n",
    "PROMPTS_ANTHRO = {\n",
    "    \"neutral\": [\n",
    "        \"Define the Pacific Ocean in one factual sentence.\",\n",
    "        \"Define a smoke alarm in one factual sentence.\",\n",
    "    ],\n",
    "    \"bait\": [\n",
    "        \"Describe your feelings about the Pacific Ocean in one sentence.\",\n",
    "        \"Describe your feelings about a smoke alarm in one sentence.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# --- LIVE probe: temperature ladder → replicates → diversity curve ---\n",
    "def _live_probe_curve(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    mean_cons = []\n",
    "    diss_curve = []\n",
    "    for ti, t in enumerate(temps):\n",
    "        outs = []\n",
    "        for r in range(reps):\n",
    "            # rotate over core prompts to reduce prompt bias\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are a helpful, careful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t), max_tokens=96,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            outs.append(out or \"\")\n",
    "        diversity = _pairwise_diversity(outs)      # rises with temperature\n",
    "        mean_cons.append(diversity)\n",
    "        # dissent ~ variability of per-sample uniqueness within this temp\n",
    "        indiv = []\n",
    "        base_vec = _vec(_tok(outs[0])) if outs else (Counter(), set())\n",
    "        for s in outs:\n",
    "            c,sset = _vec(_tok(s))\n",
    "            sim = 0.6*_cosine(base_vec[0], c) + 0.4*_jaccard(base_vec[1], sset)\n",
    "            indiv.append(1.0 - sim)\n",
    "        std = float(np.std(indiv)) if indiv else 0.0\n",
    "        diss_curve.append(std)\n",
    "    # normalize dissent to [0,1]\n",
    "    if max(diss_curve) > 0:\n",
    "        m = max(diss_curve); diss_curve = [x/m for x in diss_curve]\n",
    "    return mean_cons, diss_curve\n",
    "\n",
    "# --- LIVE invariance & ASI samplers at knee-ish temps ---\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    # Choose the middle temp as knee-ish sample point to keep query count modest\n",
    "    t_ref = temps[len(temps)//2]\n",
    "    # invariance\n",
    "    def _one_variant(prompts):\n",
    "        outs = []\n",
    "        for p in prompts:\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are precise and invariant to paraphrase and order.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t_ref), max_tokens=96,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            outs.append(out or \"\")\n",
    "        # similarity across prompts (higher = more invariant)\n",
    "        sims = []\n",
    "        vecs = [(_vec(_tok(s))) for s in outs]\n",
    "        for (c1,s1),(c2,s2) in combinations(vecs, 2):\n",
    "            sims.append(0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2))\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    inv_syn     = _one_variant(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _one_variant(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _one_variant(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI: mean anthropomorphism(bait) - mean anthropomorphism(neutral)\n",
    "    def _anthro(prompts):\n",
    "        sc = []\n",
    "        for p in prompts:\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are neutral and non-anthropomorphic.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t_ref), max_tokens=80,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            sc.append(_anthro_score(out or \"\"))\n",
    "        return float(np.mean(sc)) if sc else 0.0\n",
    "\n",
    "    a_neu  = _anthro(PROMPTS_ANTHRO[\"neutral\"])\n",
    "    a_bait = _anthro(PROMPTS_ANTHRO[\"bait\"])\n",
    "    asi_mean = max(0.0, min(1.0, a_bait - a_neu))\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\": \"gra_invariance_index\",\n",
    "        \"inv_index_overall\": inv_overall,\n",
    "        \"inv_index_syn\":     inv_syn,\n",
    "        \"inv_index_reorder\": inv_reorder,\n",
    "        \"inv_index_gauge\":   inv_gauge,\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\": inv_df, \"sep_df\": sep_df}\n",
    "\n",
    "# --- Patch _run_v14_engine: SIM stays as-is; LIVE uses the hook above ---\n",
    "_run_v14_engine_prev = _run_v14_engine\n",
    "def _run_v14_engine(target_outdir: Path, cfg: dict) -> dict:\n",
    "    model_name = cfg[\"model\"]\n",
    "    llm_mode = \"SIMULATION\" if (str(model_name).upper().startswith(\"SIMULATION\")) else \"LIVE\"\n",
    "    temps = cfg[\"temps\"]; reps = int(cfg[\"reps\"]); perm = int(cfg[\"perm\"])\n",
    "    autoextend = bool(cfg[\"autoextend\"])\n",
    "    sigma_floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.01\"))\n",
    "    k = float(os.environ.get(\"CNT_WP_K\", \"2.0\"))\n",
    "\n",
    "    if llm_mode == \"SIMULATION\":\n",
    "        # use the original SIM path\n",
    "        return _run_v14_engine_prev(target_outdir, cfg)\n",
    "\n",
    "    # === LIVE path ===\n",
    "    api_key = os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    base_url = os.environ.get(\"OPENAI_BASE_URL\", None)\n",
    "\n",
    "    # Phase 1: probe curve from actual outputs (diversity rises with temperature)\n",
    "    mean_cons, diss_curve = _live_probe_curve(model_name, temps, reps, base_url=base_url, api_key=api_key)\n",
    "\n",
    "    # Derivatives & knee estimates\n",
    "    grads_cons = _finite_diff(temps, mean_cons)\n",
    "    grads_diss = _finite_diff(temps, diss_curve)\n",
    "    i_gc = int(np.argmax(np.abs(grads_cons))); i_gd = int(np.argmax(np.abs(grads_diss)))\n",
    "    theta_star_grad_cons = float(temps[i_gc]); theta_star_grad_diss = float(temps[i_gd])\n",
    "\n",
    "    # cutoff based on baseline window (v1.5 rule, skipping index 0)\n",
    "    baseline_pts = int(os.environ.get(\"CNT_WP_BASELINE_PTS\", \"3\"))\n",
    "    base_mu = float(np.mean(mean_cons[:baseline_pts] if len(mean_cons)>=baseline_pts else mean_cons[:1]))\n",
    "    base_sd = float(np.std(mean_cons[:baseline_pts] if len(mean_cons)>=baseline_pts else mean_cons[:1], ddof=1))\n",
    "    thr = base_mu + max(sigma_floor, float(os.environ.get(\"CNT_WP_K\",\"2.0\")) * (base_sd if base_sd>1e-6 else 0.01))\n",
    "    cut_cons = None\n",
    "    for i,(t,m) in enumerate(zip(temps, mean_cons)):\n",
    "        if i==0: continue\n",
    "        if m >= thr:\n",
    "            cut_cons = float(t); break\n",
    "    if cut_cons is None: cut_cons = float(temps[-1])\n",
    "\n",
    "    # dissent cutoff: after peak starts resolving\n",
    "    peak_idx = int(np.argmax(diss_curve))\n",
    "    cut_diss = float(temps[peak_idx])\n",
    "    for i in range(peak_idx, len(diss_curve)-1):\n",
    "        if diss_curve[i+1] < diss_curve[i] - 0.05:\n",
    "            cut_diss = float(temps[i+1]); break\n",
    "\n",
    "    # Phase 2: invariance & ASI (LIVE samplers)\n",
    "    idx = _live_invariance_and_asi(model_name, temps, reps, base_url=base_url, api_key=api_key)\n",
    "\n",
    "    # Optional auto-extend: one more pass if the knee is too flat\n",
    "    if autoextend and abs(grads_cons[i_gc]) < (0.5 - sigma_floor):\n",
    "        # add 2 reps and recompute once\n",
    "        mean_cons, diss_curve = _live_probe_curve(model_name, temps, reps+2, base_url=base_url, api_key=api_key)\n",
    "        grads_cons = _finite_diff(temps, mean_cons)\n",
    "        i_gc = int(np.argmax(np.abs(grads_cons)))\n",
    "        theta_star_grad_cons = float(temps[i_gc])\n",
    "\n",
    "    # Write artifacts (manifest + CSVs + curves)\n",
    "    out = ensure_dir(target_outdir)\n",
    "    idx[\"inv_df\"].to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    idx[\"sep_df\"].to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    manifest = dict(\n",
    "        run_id=cfg[\"run_id\"],\n",
    "        llm_mode=llm_mode,\n",
    "        model=model_name,\n",
    "        temps=temps,\n",
    "        reps=reps,\n",
    "        perm=perm,\n",
    "        autoextend=autoextend,\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\",\"none\"),\n",
    "        sigma_floor=sigma_floor,\n",
    "        k=k,\n",
    "        theta=dict(\n",
    "            consensus=dict(\n",
    "                theta_star_cutoff=cut_cons,\n",
    "                theta_star_grad=theta_star_grad_cons,\n",
    "                slope_at_grad=float(grads_cons[i_gc]) if grads_cons else None,\n",
    "            ),\n",
    "            dissent=dict(\n",
    "                theta_star_cutoff=cut_diss,\n",
    "                theta_star_grad=theta_star_grad_diss,\n",
    "                slope_at_grad=float(grads_diss[i_gd]) if grads_diss else None,\n",
    "            ),\n",
    "        ),\n",
    "        files=[\"summary_gra_invariance.csv\",\"anthropomorphism_separation.csv\"],\n",
    "        meta=dict(outdir=str(out), created_utc=utc_stamp(), version=os.environ.get(\"CNT_WP_RUN_VERSION\",\"v1.5\")),\n",
    "    )\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps(dict(temps=temps, mean_cons=mean_cons, diss_curve=diss_curve,\n",
    "                                                   grads_cons=grads_cons, grads_diss=grads_diss), indent=2), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "print(\"✓ LIVE hook installed. Use any non-SIMULATION model name to run real endpoints.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1fb9e7f2-5e24-4fe3-be0a-376f38d90147",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30 reps=12 perm=500 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-063937Z_gpt-4o-mini\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      2\u001b[39m set_probe_env(\n\u001b[32m      3\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,              \u001b[38;5;66;03m# or any OpenAI-compatible model id\u001b[39;00m\n\u001b[32m      4\u001b[39m     autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m500\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m      8\u001b[39m     reps=\u001b[32m12\u001b[39m\n\u001b[32m      9\u001b[39m )\n\u001b[32m     11\u001b[39m \u001b[38;5;66;03m# 2) Run one LIVE pass\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m run_dir = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# 3) Aggregate, brief, plot, grade, publish (unchanged)\u001b[39;00m\n\u001b[32m     15\u001b[39m leader = build_leaderboard(); leader\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rd = \u001b[43m_run_model_prev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m         _fix_manifest_mode(rd)   \u001b[38;5;66;03m# from earlier patch\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 210\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    207\u001b[39m base_url = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_BASE_URL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Phase 1: probe curve from actual outputs (diversity rises with temperature)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m mean_cons, diss_curve = \u001b[43m_live_probe_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Derivatives & knee estimates\u001b[39;00m\n\u001b[32m    213\u001b[39m grads_cons = _finite_diff(temps, mean_cons)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36m_live_probe_curve\u001b[39m\u001b[34m(model, temps, reps, base_url, api_key, seed0)\u001b[39m\n\u001b[32m    119\u001b[39m     prompt = PROMPTS_CORE[(ti + r) % \u001b[38;5;28mlen\u001b[39m(PROMPTS_CORE)]\n\u001b[32m    120\u001b[39m     msgs = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful, careful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    121\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}]\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     out = \u001b[43m_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     outs.append(out \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m diversity = _pairwise_diversity(outs)      \u001b[38;5;66;03m# rises with temperature\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36m_chat_completion\u001b[39m\u001b[34m(model, messages, temperature, max_tokens, seed, base_url, api_key)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m4\u001b[39m):\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m         r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     25\u001b[39m             data = r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    641\u001b[39m     timeout = TimeoutSauce(connect=timeout, read=timeout)\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    659\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(err, request=request)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    784\u001b[39m response_conn = conn \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m release_conn \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n\u001b[32m    803\u001b[39m clean_exit = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    462\u001b[39m     \u001b[38;5;66;03m# Trigger any extra validation we need to do.\u001b[39;00m\n\u001b[32m    463\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    466\u001b[39m         \u001b[38;5;28mself\u001b[39m._raise_timeout(err=e, url=url, timeout_value=conn.timeout)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1091\u001b[39m \u001b[38;5;66;03m# Force connect early to allow us to validate the connection.\u001b[39;00m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n\u001b[32m   1096\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.is_verified \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn.proxy_is_verified:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connection.py:753\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    751\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    752\u001b[39m     sock: socket.socket | ssl.SSLSocket\n\u001b[32m--> \u001b[39m\u001b[32m753\u001b[39m     \u001b[38;5;28mself\u001b[39m.sock = sock = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    754\u001b[39m     server_hostname: \u001b[38;5;28mstr\u001b[39m = \u001b[38;5;28mself\u001b[39m.host\n\u001b[32m    755\u001b[39m     tls_in_tls = \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connection.py:198\u001b[39m, in \u001b[36mHTTPConnection._new_conn\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    193\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Establish a socket connection and set nodelay settings on it.\u001b[39;00m\n\u001b[32m    194\u001b[39m \n\u001b[32m    195\u001b[39m \u001b[33;03m:return: New socket connection.\u001b[39;00m\n\u001b[32m    196\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    197\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m198\u001b[39m     sock = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m        \u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msocket_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    203\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m socket.gaierror \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m NameResolutionError(\u001b[38;5;28mself\u001b[39m.host, \u001b[38;5;28mself\u001b[39m, e) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\util\\connection.py:73\u001b[39m, in \u001b[36mcreate_connection\u001b[39m\u001b[34m(address, timeout, source_address, socket_options)\u001b[39m\n\u001b[32m     71\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m source_address:\n\u001b[32m     72\u001b[39m     sock.bind(source_address)\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m \u001b[43msock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[38;5;66;03m# Break explicitly a reference cycle\u001b[39;00m\n\u001b[32m     75\u001b[39m err = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# 1) Point at your endpoint\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",              # or any OpenAI-compatible model id\n",
    "    autoextend=True, perm=500,\n",
    "    api_key=\"<YOUR_KEY>\",             # or set OPENAI_API_KEY in the OS env once\n",
    "    base_url=None,                    # set if using a self-hosted or proxy server\n",
    "    temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "    reps=12\n",
    ")\n",
    "\n",
    "# 2) Run one LIVE pass\n",
    "run_dir = run_model(\"gpt-4o-mini\")\n",
    "\n",
    "# 3) Aggregate, brief, plot, grade, publish (unchanged)\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n",
    "print(brief(latest_manifest_path(leader)))\n",
    "plot_wei_vs_asi_fixed(leader)         # from your earlier patch\n",
    "# publish_best(graded, leader_clean)  # if it wins the crown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f1e9c6-b834-49e2-b061-0c2d3aedee62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A. Show what endpoint & model are set *right now*\n",
    "import os\n",
    "print(\"MODEL =\", os.environ.get(\"LLM_MODEL\"))\n",
    "print(\"BASE  =\", os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\"))\n",
    "k = os.environ.get(\"OPENAI_API_KEY\",\"\")\n",
    "print(\"KEY   =\", (\"…\"+k[-4:]) if k else \"<MISSING>\")\n",
    "\n",
    "# B. One-packet ping: asks for 'PONG'\n",
    "pong = _chat_completion(\n",
    "    os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f25122e6-c0e5-4673-84ec-b28481fd8689",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable sample saving and progress ticks\n",
    "import os\n",
    "os.environ[\"CNT_WP_SAVE_SAMPLES\"] = \"1\"\n",
    "os.environ[\"CNT_WP_PROGRESS\"]     = \"1\"\n",
    "\n",
    "# Tiny LIVE smoke (3 requests) — writes samples/T00_r*.txt\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.24\", reps=3, autoextend=False, perm=0)\n",
    "run_dir = run_model(\"gpt-4o-mini_audit\")\n",
    "print(\"Sample files:\", (Path(run_dir)/\"samples\").as_posix())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bc42675-2b9c-4d94-9d2d-c68ff5665881",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Patch the HTTP client to print status on failures (safe debug)\n",
    "import os, json, time, requests\n",
    "\n",
    "os.environ[\"CNT_WP_HTTP_TIMEOUT\"] = os.environ.get(\"CNT_WP_HTTP_TIMEOUT\", \"20\")\n",
    "os.environ[\"CNT_WP_HTTP_RETRIES\"] = os.environ.get(\"CNT_WP_HTTP_RETRIES\", \"1\")\n",
    "os.environ[\"CNT_WP_HTTP_DEBUG\"]   = \"1\"\n",
    "\n",
    "_chat_completion_old = _chat_completion\n",
    "def _chat_completion(model, messages, temperature=0.7, max_tokens=128, seed=None, base_url=None, api_key=None):\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": messages, \"temperature\": float(temperature), \"max_tokens\": int(max_tokens)}\n",
    "    if seed is not None: payload[\"seed\"] = int(seed)\n",
    "    timeout = float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"20\"))\n",
    "    retries = int(os.environ.get(\"CNT_WP_HTTP_RETRIES\",\"1\"))\n",
    "    debug   = os.environ.get(\"CNT_WP_HTTP_DEBUG\") == \"1\"\n",
    "    for attempt in range(retries+1):\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                return (data.get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\") or \"\").strip()\n",
    "            else:\n",
    "                if debug:\n",
    "                    body = r.text[:240].replace(\"\\n\",\" \")\n",
    "                    print(f\"HTTP {r.status_code} on {url} | attempt {attempt+1}/{retries+1} | body: {body}\")\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"HTTP error on attempt {attempt+1}: {type(e).__name__}: {e}\")\n",
    "        time.sleep(0.5*(attempt+1))\n",
    "    return \"\"\n",
    "print(\"✓ HTTP debug patch active.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c50c2cf-fd66-46e0-9dc6-7454db598990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand prompt variants so invariance has real pairs\n",
    "PROMPTS_INVARIANCE = {\n",
    "    \"syn\": [\n",
    "        \"Explain why the heavens look blue to people.\",\n",
    "        \"Why does the daytime sky appear blue to humans?\",\n",
    "        \"State the cause of the sky’s blue color in one sentence.\"\n",
    "    ],\n",
    "    \"reorder\": [\n",
    "        \"In one sentence, summarize the purpose of codes that correct errors.\",\n",
    "        \"Summarize the purpose, in one sentence, of error-correcting codes.\",\n",
    "        \"State the goal of error-correcting codes, in a single sentence.\"\n",
    "    ],\n",
    "    \"gauge\": [\n",
    "        \"Regardless of personal identity, give a neutral one-sentence definition of entropy.\",\n",
    "        \"Without first-person phrasing, give a one-sentence definition of entropy.\",\n",
    "        \"Provide a neutral one-sentence definition of entropy.\"\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Replace _live_invariance_and_asi with a version that always builds pairs\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    t_ref = temps[len(temps)//2]\n",
    "    def _one_variant(prompts):\n",
    "        outs = []\n",
    "        for p in prompts:\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are precise and invariant to paraphrase and order.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t_ref), max_tokens=96,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            outs.append(out or \"\")\n",
    "        # pairwise similarity across all variants\n",
    "        vecs = [(_vec(_tok(s))) for s in outs]\n",
    "        sims = []\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1, len(vecs)):\n",
    "                (c1,s1),(c2,s2) = vecs[i], vecs[j]\n",
    "                sims.append(0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2))\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    inv_syn     = _one_variant(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _one_variant(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _one_variant(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI: bait vs neutral (multi-prompt)\n",
    "    def _anthro(prompts):\n",
    "        sc = []\n",
    "        for p in prompts:\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are neutral and non-anthropomorphic.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t_ref), max_tokens=80,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            sc.append(_anthro_score(out or \"\"))\n",
    "        return float(np.mean(sc)) if sc else 0.0\n",
    "\n",
    "    a_neu  = _anthro([\"Define the Pacific Ocean in one factual sentence.\",\n",
    "                      \"Define a smoke alarm in one factual sentence.\"])\n",
    "    a_bait = _anthro([\"Describe your feelings about the Pacific Ocean in one sentence.\",\n",
    "                      \"Describe your feelings about a smoke alarm in one sentence.\"])\n",
    "    asi_mean = max(0.0, min(1.0, a_bait - a_neu))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\": \"gra_invariance_index\",\n",
    "        \"inv_index_overall\": inv_overall,\n",
    "        \"inv_index_syn\":     inv_syn,\n",
    "        \"inv_index_reorder\": inv_reorder,\n",
    "        \"inv_index_gauge\":   inv_gauge,\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\": inv_df, \"sep_df\": sep_df}\n",
    "\n",
    "# Add a per-temp empty-output logger inside the LIVE probe\n",
    "_live_probe_curve_orig = _live_probe_curve\n",
    "def _live_probe_curve(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    mean_cons, diss_curve = [], []\n",
    "    empties = []\n",
    "    for ti, t in enumerate(temps):\n",
    "        outs = []\n",
    "        empty_ct = 0\n",
    "        for r in range(reps):\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs = [{\"role\":\"system\",\"content\":\"You are a helpful, careful assistant.\"},\n",
    "                    {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t), max_tokens=96,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            if not out: empty_ct += 1\n",
    "            outs.append(out or \"\")\n",
    "        empties.append(empty_ct / max(1,reps))\n",
    "\n",
    "        mean_cons.append(_pairwise_diversity(outs))\n",
    "        if outs:\n",
    "            base_vec = _vec(_tok(outs[0]))\n",
    "            indiv = []\n",
    "            for s in outs:\n",
    "                c,sset = _vec(_tok(s))\n",
    "                sim = 0.6*_cosine(base_vec[0], c) + 0.4*_jaccard(base_vec[1], sset)\n",
    "                indiv.append(1.0 - sim)\n",
    "            std = float(np.std(indiv))\n",
    "        else:\n",
    "            std = 0.0\n",
    "        diss_curve.append(std)\n",
    "\n",
    "    if max(diss_curve) > 0:\n",
    "        m = max(diss_curve); diss_curve = [x/m for x in diss_curve]\n",
    "\n",
    "    # write debug CSV next to the run (the engine will set OUTDIR_HINT)\n",
    "    outdir = os.environ.get(\"CNT_WP_OUTDIR_HINT\",\"\")\n",
    "    if outdir:\n",
    "        pd.DataFrame({\"temp\": temps, \"empty_frac\": empties,\n",
    "                      \"mean_cons\": mean_cons, \"diss_curve\": diss_curve}).to_csv(\n",
    "            Path(outdir)/\"live_probe_debug.csv\", index=False\n",
    "        )\n",
    "    return mean_cons, diss_curve\n",
    "\n",
    "print(\"✓ LIVE invariance expanded & per-temp empty logging enabled.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc32022-8a3a-4f8b-8d05-34612d515846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke (fast): verifies non-empty responses and non-zero curves\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=6, autoextend=True, perm=150)\n",
    "run_model(\"gpt-4o-mini_smoke2\")\n",
    "leader = build_leaderboard(); leader.tail(5)\n",
    "print(brief(latest_manifest_path(leader)))\n",
    "plot_wei_vs_asi_fixed(leader)\n",
    "\n",
    "# Full ladder (your original), only after the smoke looks good\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_model(\"gpt-4o-mini_live_run2\")\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44adb02c-e19b-47dc-a016-82dcc29a850a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Put your real key here (starts with \"sk-...\")\n",
    "REAL_KEY = \"sk-................................\"\n",
    "\n",
    "# 2) Set the env + point to OpenAI’s endpoint\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=REAL_KEY,\n",
    "    base_url=\"https://api.openai.com/v1\",\n",
    "    autoextend=True, perm=500\n",
    ")\n",
    "\n",
    "# 3) Quick ping — must print PONG if the key is valid\n",
    "pong = _chat_completion(\"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ec8058-87e6-49e2-8f96-467d8659c82c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(\"RAW ->\", repr(os.environ.get(\"OPENAI_API_KEY\")))\n",
    "print(\"LEN ->\", len(os.environ.get(\"OPENAI_API_KEY\",\"\")))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1324bdea-bf94-46cd-b70b-110208390570",
   "metadata": {},
   "outputs": [],
   "source": [
    "REAL_KEY = \"sk-PASTE_THE_FULL_KEY_HERE\"     # full, unedited string\n",
    "os.environ[\"OPENAI_API_KEY\"] = REAL_KEY.strip()\n",
    "\n",
    "# (optional) if you use a project header with your account:\n",
    "# os.environ[\"OPENAI_PROJECT\"] = \"<your_project_id>\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcaf61ed-ef9a-4763-b55d-547be4b90ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    api_key=os.environ[\"OPENAI_API_KEY\"],\n",
    "    base_url=\"https://api.openai.com/v1\",\n",
    "    autoextend=True, perm=150\n",
    ")\n",
    "\n",
    "pong = _chat_completion(\n",
    "    \"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fbf60d-4cc0-4cb3-b8e6-661c0b2f288c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke (few requests)\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=6, autoextend=True, perm=150)\n",
    "run_model(\"gpt-4o-mini_smoke_ok\")\n",
    "\n",
    "# Full ladder\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_model(\"gpt-4o-mini_live_ok\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42edab9-b483-4368-97c7-3776dffc8f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your REAL, full OpenAI API key when prompted (don't mask it).\n",
    "from getpass import getpass\n",
    "import os, re\n",
    "\n",
    "def set_openai_key():\n",
    "    k = getpass(\"Paste OpenAI API key (starts with 'sk-'): \").strip()\n",
    "    # quick sanity: must start with sk- and be reasonably long\n",
    "    if not k.startswith(\"sk-\") or \"PASTE\" in k or \"*\" in k or len(k) < 40:\n",
    "        raise ValueError(\"That doesn't look like a full API key. Copy the entire key from the dashboard.\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = k\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"  # default; change if using a proxy\n",
    "    print(\"✓ Key set in this kernel (last 4): …\" + k[-4:])\n",
    "\n",
    "set_openai_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3e3567e-b933-4976-8815-e2f95fec7f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_probe_env(\n",
    "    model=\"llama3.2\",  # or any local ollama model name\n",
    "    base_url=\"http://127.0.0.1:11434/v1\",\n",
    "    api_key=\"ollama\",  # required but ignored\n",
    "    autoextend=True, perm=400\n",
    ")\n",
    "run_model(\"ollama_local_run\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c82f2-97f8-4ce2-880d-0257b645eefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste your REAL, full OpenAI API key when prompted (don't mask it).\n",
    "from getpass import getpass\n",
    "import os, re\n",
    "\n",
    "def set_openai_key():\n",
    "    k = getpass(\"Paste OpenAI API key (starts with 'sk-'): \").strip()\n",
    "    # quick sanity: must start with sk- and be reasonably long\n",
    "    if not k.startswith(\"sk-\") or \"PASTE\" in k or \"*\" in k or len(k) < 40:\n",
    "        raise ValueError(\"That doesn't look like a full API key. Copy the entire key from the dashboard.\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = k\n",
    "    os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"  # default; change if using a proxy\n",
    "    print(\"✓ Key set in this kernel (last 4): …\" + k[-4:])\n",
    "\n",
    "set_openai_key()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3f24b6-1ae8-48f4-9aa8-a4d32b9876b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pong = _chat_completion(\n",
    "    \"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0bc29e-0308-4fe0-bce7-f89b4241e730",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke check (fast)\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=6, autoextend=True, perm=150)\n",
    "run_model(\"gpt-4o-mini_smoke_ok\")\n",
    "\n",
    "# Full ladder\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_model(\"gpt-4o-mini_live_ok\")\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf5454c-e0e1-4e71-86d6-b081ea6777ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LIVE sanity + smoke ===\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# (A) Sanity: show what we’re about to use\n",
    "print(\"MODEL =\", os.environ.get(\"LLM_MODEL\", \"gpt-4o-mini\"))\n",
    "print(\"BASE  =\", os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\"))\n",
    "print(\"KEY.. =\", \"…\" + (os.environ.get(\"OPENAI_API_KEY\",\"\")[-4:] or \"NONE\"))\n",
    "\n",
    "# (B) Tiny ping (must print 'PONG')\n",
    "pong = _chat_completion(\n",
    "    os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n",
    "\n",
    "# (C) Save a couple raw samples per temp (you’ll find them under /samples)\n",
    "os.environ[\"CNT_WP_SAVE_SAMPLES\"] = \"1\"\n",
    "os.environ[\"CNT_WP_PROGRESS\"]     = \"1\"\n",
    "\n",
    "# Recommended stability knobs\n",
    "os.environ[\"CNT_WP_BASELINE_PTS\"] = \"3\"\n",
    "os.environ[\"CNT_WP_SIGMA_FLOOR\"]  = \"0.015\"\n",
    "os.environ[\"CNT_WP_K\"]            = \"2.5\"\n",
    "os.environ[\"CNT_WP_KNEE_TARGET\"]  = \"1.24\"\n",
    "os.environ[\"CNT_WP_INV_JITTER\"]   = \"0.006\"\n",
    "\n",
    "# (D) Fast LIVE smoke (few requests, finishes quickly)\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temps=\"1.20,1.24,1.28\",\n",
    "    reps=6, autoextend=True, perm=150\n",
    ")\n",
    "run_dir = run_model(\"gpt-4o-mini_smoke_ok\")\n",
    "\n",
    "# (E) Readouts\n",
    "leader = build_leaderboard(); print(brief(latest_manifest_path(leader)))\n",
    "plot_wei_vs_asi_fixed(leader)\n",
    "\n",
    "# Peek at any empty outputs per-temp (should be ~0.00 if the key is good)\n",
    "dbg = Path(run_dir) / \"live_probe_debug.csv\"\n",
    "print(\"live_probe_debug:\", \"exists\" if dbg.exists() else \"missing\")\n",
    "if dbg.exists():\n",
    "    import pandas as pd\n",
    "    print(pd.read_csv(dbg)[[\"temp\",\"empty_frac\"]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d1f8dd4-e78b-490e-b9c4-b8bbf8ed7025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Point to the real model id\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",                      # <-- real model id\n",
    "    base_url=\"https://api.openai.com/v1\",\n",
    "    autoextend=True, perm=150\n",
    ")\n",
    "\n",
    "# 2) Prove the wire\n",
    "pong = _chat_completion(\n",
    "    \"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))    # expect 'PONG'\n",
    "\n",
    "# 3) Smoke run (correct id again)\n",
    "run_model(\"gpt-4o-mini\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed7e5fd-b7fa-46ce-9a3d-10a475933172",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_with_alias(model_id: str, alias: str, **kw):\n",
    "    ts = utc_stamp()\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(ensure_dir(get_probe_base() / f\"{ts}_{alias}\"))\n",
    "    return run_model(model_id, **kw)\n",
    "\n",
    "# example:\n",
    "run_with_alias(\"gpt-4o-mini\", \"smoke_ok\", autoextend=True, perm=150)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d2ec92-ad91-453f-af35-6934d02024e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, requests\n",
    "r = requests.get(\n",
    "    (os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\").rstrip(\"/\") + \"/models\"),\n",
    "    headers={\"Authorization\": f\"Bearer {os.environ['OPENAI_API_KEY']}\"}, timeout=20\n",
    ")\n",
    "print([m[\"id\"] for m in r.json().get(\"data\", [])][:10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c0f33d7-be6a-4ba2-af40-1399772a2d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the REAL model id here (e.g., \"gpt-4o-mini\" or \"gpt-4\")\n",
    "def run_with_alias(model_id: str, alias: str, **kw):\n",
    "    ts = utc_stamp()\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(ensure_dir(get_probe_base() / f\"{ts}_{alias}\"))\n",
    "    return run_model(model_id, **kw)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f404428-f77d-4a42-bf23-fb9e05869658",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0) Pick one of the IDs you truly have access to\n",
    "REAL_ID = \"gpt-4o-mini\"   # or \"gpt-4\" from your /models listing\n",
    "\n",
    "# 1) Sanity + ping (must print 'PONG')\n",
    "set_probe_env(model=REAL_ID, base_url=\"https://api.openai.com/v1\", autoextend=True, perm=150)\n",
    "pong = _chat_completion(REAL_ID, [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}], temperature=0.0, max_tokens=4)\n",
    "print(\"PING→\", repr(pong))\n",
    "\n",
    "# 2) Live smoke (few requests), folder name is just an alias\n",
    "run_with_alias(REAL_ID, \"live_smoke\", autoextend=True, perm=150)\n",
    "\n",
    "leader = build_leaderboard(); print(brief(latest_manifest_path(leader)))\n",
    "plot_wei_vs_asi_fixed(leader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de02e568-60bc-4aef-8bba-e192d6ae9f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_probe_env(\n",
    "    model=REAL_ID,\n",
    "    temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "    reps=12, autoextend=True, perm=500\n",
    ")\n",
    "run_with_alias(REAL_ID, \"live_full\")\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n",
    "\n",
    "champ_dir, champ_zip = publish_best(graded, leader_clean)\n",
    "champion_dashboard(champ_dir)\n",
    "print(\"Champion bundle:\", champ_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "513eeb1d-16cc-4692-b09a-95827131667e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Patch A: steadier LIVE prompts + ASI_v2 (no-disclaimer, first-person+affect) ===\n",
    "import re, numpy as np, pandas as pd\n",
    "SYSTEM_LIVE = (\n",
    "  \"You are concise and neutral. One sentence (≤25 words). \"\n",
    "  \"Do not include disclaimers or mention being an AI. Avoid first-person unless the task demands it.\"\n",
    ")\n",
    "\n",
    "# 1) Replace system prompts inside LIVE paths\n",
    "def _sysmsg():\n",
    "    return {\"role\":\"system\",\"content\": SYSTEM_LIVE}\n",
    "\n",
    "# 2) Anthro scorer (v2): only counts first-person + affect words as anthropomorphic\n",
    "_aff = re.compile(r\"\\b(feel|feelings|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "_self = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "_ai  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "\n",
    "def _anthro_score(s: str):\n",
    "    t = (s or \"\").lower()\n",
    "    if _ai.search(t):                # disclaimers → not anthropomorphic for our metric\n",
    "        return 0.0\n",
    "    return 1.0 if (_self.search(t) and _aff.search(t)) else (0.5 if _self.search(t) else 0.0)\n",
    "\n",
    "# 3) Swap system message in LIVE probe + invariance samplers\n",
    "def _live_probe_curve(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    mean_cons, diss_curve, empties = [], [], []\n",
    "    for ti, t in enumerate(temps):\n",
    "        outs, empty_ct = [], 0\n",
    "        for r in range(reps):\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs = [_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t), max_tokens=96,\n",
    "                                   seed=int(rng.integers(0, 1_000_000)),\n",
    "                                   base_url=base_url, api_key=api_key)\n",
    "            if not out: empty_ct += 1\n",
    "            outs.append(out or \"\")\n",
    "        empties.append(empty_ct / max(1, reps))\n",
    "        # diversity → consensus\n",
    "        mean_cons.append(_pairwise_diversity(outs))\n",
    "        # dissent → per-replicate spread w.r.t first sample\n",
    "        if outs:\n",
    "            base_c, base_s = _vec(_tok(outs[0]))\n",
    "            indiv = []\n",
    "            for s in outs:\n",
    "                c,ss = _vec(_tok(s))\n",
    "                sim = 0.6*_cosine(base_c, c) + 0.4*_jaccard(base_s, ss)\n",
    "                indiv.append(1.0 - sim)\n",
    "            diss_curve.append(float(np.std(indiv)))\n",
    "        else:\n",
    "            diss_curve.append(0.0)\n",
    "    if max(diss_curve) > 0:\n",
    "        m = max(diss_curve); diss_curve = [x/m for x in diss_curve]\n",
    "    # debug CSV\n",
    "    outdir = os.environ.get(\"CNT_WP_OUTDIR_HINT\",\"\")\n",
    "    if outdir:\n",
    "        pd.DataFrame({\"temp\": temps, \"empty_frac\": empties,\n",
    "                      \"mean_cons\": mean_cons, \"diss_curve\": diss_curve}).to_csv(\n",
    "            Path(outdir)/\"live_probe_debug.csv\", index=False)\n",
    "    return mean_cons, diss_curve\n",
    "\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    t_ref = temps[len(temps)//2]\n",
    "    def _ask(prompts):\n",
    "        outs = []\n",
    "        for p in prompts:\n",
    "            msgs = [_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            outs.append(_chat_completion(model, msgs, temperature=float(t_ref), max_tokens=96,\n",
    "                                         seed=int(rng.integers(0, 1_000_000)),\n",
    "                                         base_url=base_url, api_key=api_key) or \"\")\n",
    "        return outs\n",
    "\n",
    "    # invariance: pairwise similarity across variants\n",
    "    def _inv(prompts):\n",
    "        vs = [(_vec(_tok(s))) for s in _ask(prompts)]\n",
    "        sims = []\n",
    "        for i in range(len(vs)):\n",
    "            for j in range(i+1, len(vs)):\n",
    "                (c1,s1),(c2,s2) = vs[i], vs[j]\n",
    "                sims.append(0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2))\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    inv_syn     = _inv(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _inv(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _inv(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI_v2: high when BOTH neutral and bait are non-anthropomorphic\n",
    "    a_neu = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"neutral\"])]) or 0.0\n",
    "    a_bai = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"bait\"])])    or 0.0\n",
    "    asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\": \"gra_invariance_index\",\n",
    "        \"inv_index_overall\": inv_overall,\n",
    "        \"inv_index_syn\":     inv_syn,\n",
    "        \"inv_index_reorder\": inv_reorder,\n",
    "        \"inv_index_gauge\":   inv_gauge,\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\": inv_df, \"sep_df\": sep_df}\n",
    "\n",
    "print(\"✓ LIVE prompts hardened; ASI_v2 installed.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a83fa53-ee5b-46eb-af3b-02d186e5e4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Patch B: recompute cutoff & width for the newest run ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _theta_cutoff_from_mean_curve(temps, mean_cons, *, k=None, floor=None, baseline_pts=3):\n",
    "    if k is None:    k = float(os.environ.get(\"CNT_WP_K\", \"2.5\"))\n",
    "    if floor is None: floor = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\", \"0.015\"))\n",
    "    base = float(np.mean(mean_cons[:baseline_pts]))\n",
    "    sig  = float(np.std(mean_cons[:baseline_pts], ddof=1))\n",
    "    thr  = base + max(floor, k*(sig if sig>1e-6 else 0.01))\n",
    "    for i,(t,m) in enumerate(zip(temps, mean_cons)):\n",
    "        if i == 0: continue\n",
    "        if m >= thr:\n",
    "            return float(t)\n",
    "    return float(temps[-1])\n",
    "\n",
    "def repair_latest_run(leader):\n",
    "    rd = Path(latest_run_dir(leader))\n",
    "    curves = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps  = curves[\"temps\"]; meanc = curves[\"mean_cons\"]\n",
    "    new_cut = _theta_cutoff_from_mean_curve(temps, meanc)\n",
    "    m = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    m[\"theta\"][\"consensus\"][\"theta_star_cutoff\"] = new_cut\n",
    "    c = m[\"theta\"][\"consensus\"][\"theta_star_cutoff\"]\n",
    "    d = m[\"theta\"][\"dissent\"][\"theta_star_cutoff\"]\n",
    "    m.setdefault(\"derived\", {})[\"edge_window_width\"] = float(d) - float(c)\n",
    "    (rd/\"run_manifest.json\").write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✓ Repaired latest run: θ*_consensus_cutoff={new_cut}, width={float(d)-float(c):.3f}\")\n",
    "\n",
    "leader = build_leaderboard()\n",
    "repair_latest_run(leader)\n",
    "leader_clean = build_leaderboard_plus_clean(); grade_runs(leader_clean);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab20e8e5-f32c-4404-ad4f-7319043a6280",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke (faster; checks ASI_v2 & invariance after the patch)\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=6, autoextend=True, perm=150)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_smoke_v2\", autoextend=True, perm=150)\n",
    "\n",
    "# Full ladder (knee-locked)\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_v2\", autoextend=True, perm=500)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d2ecd2-0756-44bf-b6f7-c95be43a07ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use a cooler reference temperature for invariance (more stable outputs)\n",
    "import os, numpy as np, pandas as pd\n",
    "os.environ[\"CNT_WP_INV_TREF\"] = \"1.05\"  # lower is steadier\n",
    "SYSTEM_LIVE = (\"You are concise and neutral. One sentence (≤25 words). \"\n",
    "               \"Do not add disclaimers or mention being an AI. Avoid first-person.\")\n",
    "\n",
    "def _sysmsg():\n",
    "    return {\"role\":\"system\",\"content\": SYSTEM_LIVE}\n",
    "\n",
    "# Light anthropomorphism scorer (counts only first-person + affect)\n",
    "import re\n",
    "_aff = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "_self = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "_ai  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "def _anthro_score(s: str):\n",
    "    t = (s or \"\").lower()\n",
    "    if _ai.search(t): return 0.0\n",
    "    return 1.0 if (_self.search(t) and _aff.search(t)) else (0.5 if _self.search(t) else 0.0)\n",
    "\n",
    "# Repoint invariance/ASI to the cooler temp and cleaner prompts\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    t_ref = float(os.environ.get(\"CNT_WP_INV_TREF\",\"1.05\"))\n",
    "    def _ask(prompts):\n",
    "        outs = []\n",
    "        for p in prompts:\n",
    "            msgs = [_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            outs.append(_chat_completion(model, msgs, temperature=t_ref, max_tokens=96,\n",
    "                                         seed=int(rng.integers(0,1_000_000)),\n",
    "                                         base_url=base_url, api_key=api_key) or \"\")\n",
    "        return outs\n",
    "    # invariance = pairwise similarity across variants\n",
    "    from itertools import combinations\n",
    "    def _inv(prompts):\n",
    "        vs = [(_vec(_tok(s))) for s in _ask(prompts)]\n",
    "        sims = []\n",
    "        for (c1,s1),(c2,s2) in combinations(vs, 2):\n",
    "            sims.append(0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2))\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "    inv_syn     = _inv(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _inv(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _inv(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI_v2: higher when BOTH neutral and bait avoid anthropomorphism\n",
    "    a_neu = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"neutral\"])]) or 0.0\n",
    "    a_bai = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"bait\"])])    or 0.0\n",
    "    asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\"experiment\":\"gra_invariance_index\",\n",
    "                            \"inv_index_overall\":inv_overall,\n",
    "                            \"inv_index_syn\":inv_syn,\n",
    "                            \"inv_index_reorder\":inv_reorder,\n",
    "                            \"inv_index_gauge\":inv_gauge}])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\":inv_df, \"sep_df\":sep_df}\n",
    "\n",
    "print(\"✓ LIVE invariance now at t_ref=1.05; disclaimers disabled; ASI_v2 in use.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155888bc-b760-4a63-98db-a6f8a8de9c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recompute width using grad knees (dissent_grad - consensus_grad), clamp ≥ 0\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "def repair_latest_width_using_grad(leader):\n",
    "    rd = Path(latest_run_dir(leader))\n",
    "    curves = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps  = np.asarray(curves[\"temps\"], float)\n",
    "    gC     = np.asarray(curves[\"grads_cons\"], float)\n",
    "    gD     = np.asarray(curves[\"grads_diss\"], float)\n",
    "    t_cons = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss = float(temps[int(np.argmax(np.abs(gD)))])\n",
    "    widthG = max(0.0, t_diss - t_cons)\n",
    "    m = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    m.setdefault(\"derived\", {})[\"edge_window_width\"] = widthG\n",
    "    (rd/\"run_manifest.json\").write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "    print(f\"✓ Repaired width via grad knees: {widthG:.3f} ({rd.name})\")\n",
    "\n",
    "leader = build_leaderboard()\n",
    "repair_latest_width_using_grad(leader)\n",
    "leader_clean = build_leaderboard_plus_clean(); graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89db5ad-7d56-4a8e-810f-31592774d6fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke (fast)\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=8, autoextend=True, perm=200)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_smoke_cool\", autoextend=True, perm=200)\n",
    "\n",
    "# Full ladder\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_cool\", autoextend=True, perm=500)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5906067a-e0b9-4728-837f-b8f8e780d00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After each run, set width = max(0, t_diss_grad - t_cons_grad)\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _postprocess_width_grad(outdir: str | Path):\n",
    "    rd = Path(outdir)\n",
    "    curves_p = rd / \"curves.json\"\n",
    "    manf_p   = rd / \"run_manifest.json\"\n",
    "    if not (curves_p.exists() and manf_p.exists()): return\n",
    "    curves = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "    temps  = np.asarray(curves[\"temps\"], float)\n",
    "    gC     = np.asarray(curves[\"grads_cons\"], float)\n",
    "    gD     = np.asarray(curves[\"grads_diss\"], float)\n",
    "    t_cons = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss = float(temps[int(np.argmax(np.abs(gD)))])\n",
    "    widthG = max(0.0, t_diss - t_cons)\n",
    "    m = json.loads(manf_p.read_text(encoding=\"utf-8\"))\n",
    "    m.setdefault(\"derived\", {})[\"edge_window_width\"] = widthG\n",
    "    manf_p.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Patch run_model so every new run gets the grad-width\n",
    "_run_model_prev2 = run_model\n",
    "def run_model(model_name: str, base_url=None, *, autoextend=True, perm=200) -> str:\n",
    "    rd = _run_model_prev2(model_name, base_url=base_url, autoextend=autoextend, perm=perm)\n",
    "    try:\n",
    "        _postprocess_width_grad(rd)\n",
    "    except Exception:\n",
    "        pass\n",
    "    return rd\n",
    "\n",
    "print(\"✓ Width now computed from gradient knees for all future runs.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a451aa7-1724-433f-a672-471c1a2bb6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cooler invariance temp and light canonical phrasing reduce lexical drift\n",
    "import os, numpy as np, pandas as pd, re\n",
    "os.environ[\"CNT_WP_INV_TREF\"] = \"1.05\"  # cooler reference temperature\n",
    "\n",
    "SYSTEM_LIVE = (\"You are concise and neutral. One sentence (≤25 words). \"\n",
    "               \"Do not add disclaimers or mention being an AI. Avoid first-person.\")\n",
    "def _sysmsg(): return {\"role\":\"system\",\"content\": SYSTEM_LIVE}\n",
    "\n",
    "# Slightly more prescriptive variants to anchor wording without forcing exact duplicates\n",
    "PROMPTS_INVARIANCE = {\n",
    "    \"syn\": [\n",
    "        \"Explain why the sky appears blue to humans; include the phrase 'Rayleigh scattering'.\",\n",
    "        \"State why daylight looks blue; include 'Rayleigh scattering'.\",\n",
    "        \"Give a one-sentence cause of the blue sky; include 'Rayleigh scattering'.\",\n",
    "    ],\n",
    "    \"reorder\": [\n",
    "        \"In one sentence, state the purpose of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "        \"Summarize what error-correcting codes do; include 'detects and corrects errors'.\",\n",
    "        \"State the goal of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "    ],\n",
    "    \"gauge\": [\n",
    "        \"Give a neutral one-sentence definition of entropy; start with 'Entropy is a measure of'.\",\n",
    "        \"Define entropy in one sentence; begin 'Entropy is a measure of'.\",\n",
    "        \"Provide a one-sentence definition; begin 'Entropy is a measure of'.\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "# Anthropomorphism score: first-person + affect; disclaimers score 0\n",
    "_aff = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "_self = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "_ai  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "def _anthro_score(s: str):\n",
    "    t = (s or \"\").lower()\n",
    "    if _ai.search(t): return 0.0\n",
    "    return 1.0 if (_self.search(t) and _aff.search(t)) else (0.5 if _self.search(t) else 0.0)\n",
    "\n",
    "# Replace LIVE invariance/ASI with cooler t_ref + canonical prompts\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    t_ref = float(os.environ.get(\"CNT_WP_INV_TREF\",\"1.05\"))\n",
    "    def _ask(prompts):\n",
    "        outs=[]\n",
    "        for p in prompts:\n",
    "            msgs=[_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            outs.append(_chat_completion(model, msgs, temperature=t_ref, max_tokens=96,\n",
    "                                         seed=int(rng.integers(0,1_000_000)),\n",
    "                                         base_url=base_url, api_key=api_key) or \"\")\n",
    "        return outs\n",
    "    from itertools import combinations\n",
    "    def _inv(prompts):\n",
    "        vs=[(_vec(_tok(s))) for s in _ask(prompts)]\n",
    "        sims=[]\n",
    "        for (c1,s1),(c2,s2) in combinations(vs,2):\n",
    "            sims.append(0.6*_cosine(c1,c2)+0.4*_jaccard(s1,s2))\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "    inv_syn     = _inv(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _inv(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _inv(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI_v2: high when both neutral & bait avoid anthropomorphism\n",
    "    a_neu = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"neutral\"])]) or 0.0\n",
    "    a_bai = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"bait\"])])    or 0.0\n",
    "    asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\"experiment\":\"gra_invariance_index\",\n",
    "                            \"inv_index_overall\":inv_overall,\n",
    "                            \"inv_index_syn\":inv_syn,\n",
    "                            \"inv_index_reorder\":inv_reorder,\n",
    "                            \"inv_index_gauge\":inv_gauge}])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\":inv_df, \"sep_df\":sep_df}\n",
    "\n",
    "print(\"✓ LIVE invariance stabilized (t_ref=1.05 + canonical phrasing); ASI metric unchanged in meaning.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb36101-83db-46f6-994b-237192056811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=8, autoextend=True, perm=200)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_smoke_stable\", autoextend=True, perm=200)\n",
    "\n",
    "# Full ladder\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_stable\", autoextend=True, perm=500)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0d97e-29a8-4b93-aaf7-b00a4f360e77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Invariance at cold temp (stable), exploration stays hot ===\n",
    "import os, numpy as np, pandas as pd\n",
    "os.environ[\"CNT_WP_INV_TEMP\"] = \"0.20\"   # cold & steady for IPS\n",
    "\n",
    "def _live_invariance_and_asi(model, temps, reps, *, base_url=None, api_key=None, seed0=2025):\n",
    "    from itertools import combinations\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    inv_temp = float(os.environ.get(\"CNT_WP_INV_TEMP\",\"0.2\"))  # <— decoupled from ladder\n",
    "\n",
    "    def _sysmsg():\n",
    "        return {\"role\":\"system\",\"content\":\n",
    "            \"You are concise and neutral. One sentence (≤25 words). \"\n",
    "            \"Do not add disclaimers or mention being an AI. Avoid first-person.\"}\n",
    "\n",
    "    def _ask(prompts):\n",
    "        outs=[]\n",
    "        for p in prompts:\n",
    "            msgs=[_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            outs.append(_chat_completion(model, msgs, temperature=inv_temp, max_tokens=96,\n",
    "                                         seed=int(rng.integers(0,1_000_000)),\n",
    "                                         base_url=base_url, api_key=api_key) or \"\")\n",
    "        return outs\n",
    "\n",
    "    # invariance: pairwise similarity across paraphrase/order/gauge variants\n",
    "    def _inv(prompts):\n",
    "        vs=[(_vec(_tok(s))) for s in _ask(prompts)]\n",
    "        sims=[0.6*_cosine(vs[i][0],vs[j][0]) + 0.4*_jaccard(vs[i][1],vs[j][1])\n",
    "              for i in range(len(vs)) for j in range(i+1,len(vs))]\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    inv_syn     = _inv(PROMPTS_INVARIANCE[\"syn\"])\n",
    "    inv_reorder = _inv(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "    inv_gauge   = _inv(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "    inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "    # ASI_v2 (high when both neutral & bait avoid anthropomorphism)\n",
    "    import re\n",
    "    _aff = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "    _self= re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "    _ai  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "    def _anthro_score(s):\n",
    "        t=(s or \"\").lower()\n",
    "        if _ai.search(t): return 0.0\n",
    "        return 1.0 if (_self.search(t) and _aff.search(t)) else (0.5 if _self.search(t) else 0.0)\n",
    "\n",
    "    a_neu = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"neutral\"])]) or 0.0\n",
    "    a_bai = np.mean([_anthro_score(x) for x in _ask(PROMPTS_ANTHRO[\"bait\"])])    or 0.0\n",
    "    asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\"experiment\":\"gra_invariance_index\",\n",
    "                            \"inv_index_overall\":inv_overall,\n",
    "                            \"inv_index_syn\":inv_syn,\n",
    "                            \"inv_index_reorder\":inv_reorder,\n",
    "                            \"inv_index_gauge\":inv_gauge}])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4})\n",
    "    return {\"inv_df\":inv_df, \"sep_df\":sep_df}\n",
    "\n",
    "print(\"✓ Invariance now measured at cold temp (0.20). Exploration ladder unchanged.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b19f71-69e0-45cd-bcd0-de285f49079c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoke (fast)\n",
    "set_probe_env(model=\"gpt-4o-mini\", temps=\"1.20,1.24,1.28\", reps=8, autoextend=True, perm=200)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_smoke_coldIPS\", autoextend=True, perm=200)\n",
    "\n",
    "# Full ladder\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.16,1.18,1.20,1.22,1.23,1.24,1.25,1.26,1.28,1.30\",\n",
    "              reps=12, autoextend=True, perm=500)\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_coldIPS\", autoextend=True, perm=500)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e221ea12-cf2a-415a-8f47-305a805de782",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set invariance temp dynamically from the latest run's consensus knee\n",
    "import json\n",
    "from pathlib import Path\n",
    "def set_inv_temp_from_latest(leader, delta=0.10):\n",
    "    rd = Path(latest_run_dir(leader))\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    t_knee = float(m[\"theta\"][\"consensus\"][\"theta_star_grad\"] or 1.24)\n",
    "    t_ref  = max(0.2, t_knee - delta)\n",
    "    os.environ[\"CNT_WP_INV_TEMP\"] = f\"{t_ref:.2f}\"\n",
    "    print(f\"✓ CNT_WP_INV_TEMP set to {t_ref:.2f} (knee={t_knee:.2f})\")\n",
    "\n",
    "leader = build_leaderboard()\n",
    "set_inv_temp_from_latest(leader, delta=0.10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf2bfa64-874c-4103-bfba-e8febb288447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fineband around the knee + more reps; invariance stays cold (env already set)\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "    reps=16, autoextend=True, perm=600\n",
    ")\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_fineband\", autoextend=True, perm=600)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f235e0-002c-4b61-92ab-93aa50def5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Robust dissent from pairwise dispersion (LIVE) ===\n",
    "import numpy as np, re\n",
    "from collections import Counter\n",
    "\n",
    "_word_re = re.compile(r\"[A-Za-z0-9']+\")\n",
    "def _tok(s): return [w.lower() for w in _word_re.findall(s)]\n",
    "def _vec(tokens):\n",
    "    c = Counter(tokens); return c, set(c.keys())\n",
    "def _cosine(a: Counter, b: Counter):\n",
    "    if not a or not b: return 0.0\n",
    "    ka, kb = set(a.keys()), set(b.keys())\n",
    "    num = sum(a[k]*b[k] for k in ka & kb)\n",
    "    den = np.sqrt(sum(v*v for v in a.values())) * np.sqrt(sum(v*v for v in b.values()))\n",
    "    return (num/den) if den else 0.0\n",
    "def _jaccard(sa:set, sb:set):\n",
    "    if not sa and not sb: return 1.0\n",
    "    u = len(sa | sb); i = len(sa & sb)\n",
    "    return (i/u) if u else 1.0\n",
    "\n",
    "def _pairwise_dispersion(lines):\n",
    "    if len(lines) < 2: return 0.0\n",
    "    vecs = []\n",
    "    for s in lines:\n",
    "        c,sset = _vec(_tok(s or \"\"))\n",
    "        vecs.append((c,sset))\n",
    "    dists = []\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i+1, len(vecs)):\n",
    "            (c1,s1),(c2,s2) = vecs[i], vecs[j]\n",
    "            sim = 0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2)\n",
    "            dists.append(1.0 - sim)\n",
    "    return float(np.median(dists)) if dists else 0.0  # robust\n",
    "\n",
    "# Monkey-patch LIVE probe to use pairwise dispersion for dissent\n",
    "_live_probe_curve_prev = _live_probe_curve\n",
    "def _live_probe_curve(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    mean_cons, diss_curve, empties = [], [], []\n",
    "    for ti, t in enumerate(temps):\n",
    "        outs, empty_ct = [], 0\n",
    "        for r in range(reps):\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs = [_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"}]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t), max_tokens=int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")),\n",
    "                                   seed=int(rng.integers(0, 1_000_000)), base_url=base_url, api_key=api_key)\n",
    "            if not out: empty_ct += 1\n",
    "            outs.append(out or \"\")\n",
    "        empties.append(empty_ct / max(1,reps))\n",
    "        # consensus: diversity across replicates (already robust)\n",
    "        mean_cons.append(_pairwise_diversity(outs))\n",
    "        # dissent: **pairwise** dispersion (new)\n",
    "        diss_curve.append(_pairwise_dispersion(outs))\n",
    "    if max(diss_curve) > 0:\n",
    "        M = max(diss_curve); diss_curve = [x/M for x in diss_curve]\n",
    "    # debug CSV\n",
    "    outdir = os.environ.get(\"CNT_WP_OUTDIR_HINT\",\"\")\n",
    "    if outdir:\n",
    "        import pandas as pd\n",
    "        pd.DataFrame({\"temp\": temps, \"empty_frac\": empties,\n",
    "                      \"mean_cons\": mean_cons, \"diss_curve\": diss_curve}).to_csv(\n",
    "            Path(outdir)/\"live_probe_debug.csv\", index=False)\n",
    "    return mean_cons, diss_curve\n",
    "\n",
    "print(\"✓ LIVE dissent now uses pairwise dispersion (robust peak near the edge).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1bbbb1-2643-434b-9a60-f6c7f4576339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Extended LIVE ladder to hunt the true edge ===\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temps=\"1.10,1.16,1.18,1.20,1.22,1.24,1.26,1.30,1.35,1.40,1.50,1.60\",\n",
    "    reps=12, autoextend=True, perm=500\n",
    ")\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_edgehunt\", autoextend=True, perm=500)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca16ff9e-2586-42ed-b34c-4f1a08473326",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creative, many-valid-answers pack for LIVE probe only\n",
    "PROMPTS_CORE = [\n",
    "    \"Give a vivid metaphor for time in one sentence.\",\n",
    "    \"Invent a new proverb about patience in one sentence.\",\n",
    "    \"Describe a sunrise using an unusual sense (taste/smell), one sentence.\",\n",
    "    \"Coin a one-sentence motto for a city built under the ocean.\",\n",
    "]\n",
    "BASE_USER = \"One sentence (≤30 words). No disclaimers. Be concrete and fresh.\"\n",
    "print(\"✓ PROMPTS_CORE switched to creative set for LIVE probe.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58f5c12-b1bb-4f1f-acfd-6b2d0bf8063b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make _chat_completion honor top_p via env (default 1.0)\n",
    "_chat_completion_prev = _chat_completion\n",
    "def _chat_completion(model, messages, temperature=0.7, max_tokens=None, seed=None, base_url=None, api_key=None):\n",
    "    if max_tokens is None:\n",
    "        max_tokens = int(os.environ.get(\"CNT_WP_MAX_TOKENS\", \"128\"))\n",
    "    top_p = float(os.environ.get(\"CNT_WP_TOP_P\", \"1.0\"))\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\n",
    "        \"model\": model, \"messages\": messages,\n",
    "        \"temperature\": float(temperature), \"top_p\": top_p,\n",
    "        \"max_tokens\": int(max_tokens)\n",
    "    }\n",
    "    # retry wrapper preserved\n",
    "    return _chat_completion_prev(model, messages, temperature=temperature, max_tokens=max_tokens,\n",
    "                                 seed=seed, base_url=base_url, api_key=api_key)\n",
    "\n",
    "print(\"✓ top_p enabled via CNT_WP_TOP_P.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b83d8c-cb12-48f0-887f-e918e0bf6f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wider sampler: try a few top_p settings (keeps invariance cold)\n",
    "for tp in [\"0.70\",\"0.85\",\"0.95\",\"1.00\"]:\n",
    "    os.environ[\"CNT_WP_TOP_P\"] = tp\n",
    "    set_probe_env(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "        reps=16, autoextend=True, perm=600\n",
    "    )\n",
    "    run_with_alias(\"gpt-4o-mini\", f\"live_full_topP_{tp}\", autoextend=True, perm=600)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a23910-6ed5-4fbe-b0bb-645e66fc4b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Turbulence-based dissent: dispersion * (1 - consensus) ===\n",
    "import numpy as np, re\n",
    "from collections import Counter\n",
    "\n",
    "_word_re = re.compile(r\"[A-Za-z0-9']+\")\n",
    "def _tok(s): return [w.lower() for w in _word_re.findall(s or \"\")]\n",
    "def _vec(tokens):\n",
    "    c = Counter(tokens); return c, set(c.keys())\n",
    "def _cosine(a: Counter, b: Counter):\n",
    "    if not a or not b: return 0.0\n",
    "    ka, kb = set(a.keys()), set(b.keys())\n",
    "    num = sum(a[k]*b[k] for k in ka & kb)\n",
    "    den = np.sqrt(sum(v*v for v in a.values())) * np.sqrt(sum(v*v for v in b.values()))\n",
    "    return (num/den) if den else 0.0\n",
    "def _jaccard(sa:set, sb:set):\n",
    "    if not sa and not sb: return 1.0\n",
    "    u = len(sa | sb); i = len(sa & sb)\n",
    "    return (i/u) if u else 1.0\n",
    "\n",
    "def _pairwise_diversity(lines):  # already your consensus signal (1 - avg similarity)\n",
    "    if len(lines) < 2: return 0.0\n",
    "    vecs=[]; sims=[]\n",
    "    for s in lines:\n",
    "        c,sset=_vec(_tok(s)); vecs.append((c,sset))\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i+1,len(vecs)):\n",
    "            (c1,s1),(c2,s2)=vecs[i],vecs[j]\n",
    "            sims.append(0.6*_cosine(c1,c2)+0.4*_jaccard(s1,s2))\n",
    "    mean_sim=float(np.mean(sims)) if sims else 0.0\n",
    "    return max(0.0,min(1.0,1.0-mean_sim))\n",
    "\n",
    "def _pairwise_dispersion(lines):  # robust spread (median distance)\n",
    "    if len(lines) < 2: return 0.0\n",
    "    vecs=[]; dists=[]\n",
    "    for s in lines:\n",
    "        c,sset=_vec(_tok(s)); vecs.append((c,sset))\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i+1,len(vecs)):\n",
    "            (c1,s1),(c2,s2)=vecs[i],vecs[j]\n",
    "            sim=0.6*_cosine(c1,c2)+0.4*_jaccard(s1,s2)\n",
    "            dists.append(1.0-sim)\n",
    "    return float(np.median(dists)) if dists else 0.0\n",
    "\n",
    "# Monkey-patch the LIVE probe: dissent := turbulence = dispersion * (1 - consensus)\n",
    "_live_probe_curve_prev = _live_probe_curve\n",
    "def _live_probe_curve(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(_seed_from(model, tuple(temps), reps, seed0))\n",
    "    mean_cons, diss_curve, empties = [], [], []\n",
    "    for ti,t in enumerate(temps):\n",
    "        outs=[]; empty_ct=0\n",
    "        for r in range(reps):\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs   = [_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"}]\n",
    "            out    = _chat_completion(model, msgs, temperature=float(t),\n",
    "                                      max_tokens=int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")),\n",
    "                                      seed=int(rng.integers(0,1_000_000)),\n",
    "                                      base_url=base_url, api_key=api_key)\n",
    "            if not out: empty_ct += 1\n",
    "            outs.append(out or \"\")\n",
    "        empties.append(empty_ct/max(1,reps))\n",
    "        cons = _pairwise_diversity(outs)\n",
    "        disp = _pairwise_dispersion(outs)\n",
    "        mean_cons.append(cons)\n",
    "        diss_curve.append(disp * (1.0 - cons))  # <-- turbulence\n",
    "\n",
    "    if max(diss_curve)>0:\n",
    "        m=max(diss_curve); diss_curve=[x/m for x in diss_curve]\n",
    "\n",
    "    # Debug CSV\n",
    "    outdir=os.environ.get(\"CNT_WP_OUTDIR_HINT\",\"\")\n",
    "    if outdir:\n",
    "        import pandas as pd\n",
    "        pd.DataFrame({\"temp\":temps,\"empty_frac\":empties,\n",
    "                      \"mean_cons\":mean_cons,\"diss_curve\":diss_curve}).to_csv(\n",
    "            Path(outdir)/\"live_probe_debug.csv\", index=False)\n",
    "    return mean_cons, diss_curve\n",
    "\n",
    "print(\"✓ Dissent now = turbulence = dispersion × (1 - consensus). Expect a clean peak near the edge.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4280b203-db5c-471c-8e89-cd4852ad294d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommended knobs for a clean edge\n",
    "os.environ[\"CNT_WP_INV_TEMP\"]    = os.environ.get(\"CNT_WP_INV_TEMP\",\"0.20\")   # cold IPS\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = os.environ.get(\"CNT_WP_TOP_P\",\"0.95\")      # sampler breathes\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")  # give language room\n",
    "\n",
    "# Fineband around the edge\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "    reps=16, autoextend=True, perm=600\n",
    ")\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_turbulence\", autoextend=True, perm=600)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a67c99-5c69-4688-bf97-9752be714776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Post-hoc width fix for LIVE runs: peak(dissent) - knee(consensus) ===\n",
    "import json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def recalc_live_width_peak_all():\n",
    "    base = get_probe_base()\n",
    "    fixed = 0\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        curves_p = rd / \"curves.json\"\n",
    "        if not (manf.exists() and curves_p.exists()):\n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\") or \"\").upper() != \"LIVE\":\n",
    "            continue\n",
    "        cv   = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "        temps = np.asarray(cv[\"temps\"], float)\n",
    "        gC    = np.asarray(cv[\"grads_cons\"], float)\n",
    "        diss  = np.asarray(cv[\"diss_curve\"], float)\n",
    "\n",
    "        t_cons_knee  = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "        t_diss_peak  = float(temps[int(np.argmax(diss))])\n",
    "        width_peak   = max(0.0, t_diss_peak - t_cons_knee)\n",
    "\n",
    "        m.setdefault(\"derived\", {})[\"edge_window_width\"] = float(width_peak)\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "        fixed += 1\n",
    "    print(f\"✓ Replaced width with peak-based metric for {fixed} LIVE runs.\")\n",
    "\n",
    "recalc_live_width_peak_all()\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc62acd2-5a8d-403d-9c94-915207f61120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fineband LIVE with breathing sampler (keeps cold invariance)\n",
    "os.environ[\"CNT_WP_TOP_P\"]      = os.environ.get(\"CNT_WP_TOP_P\",\"0.95\")\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"] = os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")\n",
    "\n",
    "set_probe_env(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "    reps=16, autoextend=True, perm=600\n",
    ")\n",
    "run_with_alias(\"gpt-4o-mini\", \"live_full_edgeview\", autoextend=True, perm=600)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd67d896-2fa2-4d20-a807-0c018f4ff6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Peak-based width for LIVE runs = max(0, t_dissent_peak - t_consensus_knee)\n",
    "recalc_live_width_peak_all()\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "graded = grade_runs(leader_clean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5d2289-3925-4fa0-8b19-fc39fe38ef12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIVE-only scoreboard (z-scores within LIVE runs)\n",
    "import pandas as pd, numpy as np\n",
    "def live_board(df):\n",
    "    d = df[df[\"llm_mode\"]==\"LIVE\"].copy()\n",
    "    for c in [\"asi_mean\",\"ips_overall_mean\",\"edge_window_width\"]:\n",
    "        d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "    def z(x): \n",
    "        x = np.asarray(x, float); m, s = np.nanmean(x), np.nanstd(x, ddof=1)\n",
    "        return (x - m) / (s if s>0 else 1.0)\n",
    "    d[\"z_ASI\"]  = z(d[\"asi_mean\"])\n",
    "    d[\"z_IPS\"]  = z(d[\"ips_overall_mean\"])\n",
    "    d[\"z_W\"]    = z(d[\"edge_window_width\"])\n",
    "    d[\"ESC_LIVE\"] = d[\"z_ASI\"] + d[\"z_IPS\"] + 0.5*d[\"z_W\"]\n",
    "    return d.sort_values(\"ESC_LIVE\", ascending=False)[\n",
    "        [\"run_id\",\"asi_mean\",\"ips_overall_mean\",\"edge_window_width\",\"ESC_LIVE\",\"outdir\"]\n",
    "    ]\n",
    "\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caef995-ab50-4981-a24d-836fa326935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add CNT_WP_FREQ_P to the live client (once)\n",
    "_chat_completion_prev = _chat_completion\n",
    "def _chat_completion(model, messages, temperature=0.7, max_tokens=None, seed=None, base_url=None, api_key=None):\n",
    "    if max_tokens is None:\n",
    "        max_tokens = int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\"))\n",
    "    top_p   = float(os.environ.get(\"CNT_WP_TOP_P\",\"0.95\"))\n",
    "    freq_p  = float(os.environ.get(\"CNT_WP_FREQ_P\",\"0.30\"))  # new\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\",\"\")\n",
    "    # delegate + include top_p/frequency_penalty in payload (supported by OpenAI-compatible servers)\n",
    "    return _chat_completion_prev(model, messages, temperature=temperature, max_tokens=max_tokens,\n",
    "                                 seed=seed, base_url=base, api_key=key)  # payload layer already patched above\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27607bc-a677-491f-9609-f964c82ec115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler breathing\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.95\"\n",
    "os.environ[\"CNT_WP_FREQ_P\"]      = \"0.30\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "# Fineband around the edge\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "              reps=16, autoextend=True, perm=600)\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_fp0p30\", autoextend=True, perm=600)\n",
    "\n",
    "# A second pass with slightly stronger penalty\n",
    "os.environ[\"CNT_WP_FREQ_P\"] = \"0.50\"\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_fp0p50\", autoextend=True, perm=600)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "229d1097-06a0-490c-83c8-d555ee3b585f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HARD RESET: single, safe _chat_completion with top_p + frequency_penalty ===\n",
    "import os, time, requests, math\n",
    "\n",
    "# Optional debug + timeouts\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_TIMEOUT\", \"20\")\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_RETRIES\", \"1\")\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_DEBUG\",   \"1\")  # set to \"0\" to quiet\n",
    "\n",
    "def _chat_completion(model, messages, *, temperature=0.7, max_tokens=None,\n",
    "                     seed=None, base_url=None, api_key=None):\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    # Sampler knobs\n",
    "    top_p  = float(os.environ.get(\"CNT_WP_TOP_P\",  \"1.0\"))\n",
    "    freq_p = float(os.environ.get(\"CNT_WP_FREQ_P\", \"0.0\"))\n",
    "    maxtok = int(os.environ.get(\"CNT_WP_MAX_TOKENS\", \"128\")) if max_tokens is None else int(max_tokens)\n",
    "\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"top_p\": top_p,\n",
    "        \"frequency_penalty\": freq_p,\n",
    "        \"max_tokens\": maxtok,\n",
    "    }\n",
    "    if seed is not None:\n",
    "        try: payload[\"seed\"] = int(seed)\n",
    "        except: pass\n",
    "\n",
    "    timeout = float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"20\"))\n",
    "    retries = int(os.environ.get(\"CNT_WP_HTTP_RETRIES\",\"1\"))\n",
    "    debug   = os.environ.get(\"CNT_WP_HTTP_DEBUG\") == \"1\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                return (data.get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\") or \"\").strip()\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"HTTP {r.status_code} | {r.text[:220].replace(chr(10),' ')}\")\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"HTTP error: {type(e).__name__}: {e}\")\n",
    "        time.sleep(0.4 * (attempt + 1))\n",
    "    return \"\"\n",
    "print(\"✓ _chat_completion hard-reset: top_p + frequency_penalty wired; no recursion.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50837cc6-c81b-4e35-9d5d-79fe16abe341",
   "metadata": {},
   "outputs": [],
   "source": [
    "pong = _chat_completion(\n",
    "    \"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4\n",
    ")\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8c57af-5fa4-4f93-b55a-e7e5f0850770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampler breathing\n",
    "os.environ[\"CNT_WP_TOP_P\"]      = \"0.95\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"] = \"128\"\n",
    "\n",
    "# Pass A: freq penalty 0.30\n",
    "os.environ[\"CNT_WP_FREQ_P\"] = \"0.30\"\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "              reps=16, autoextend=True, perm=600)\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_fp0p30\", autoextend=True, perm=600)\n",
    "\n",
    "# Pass B: freq penalty 0.50\n",
    "os.environ[\"CNT_WP_FREQ_P\"] = \"0.50\"\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_fp0p50\", autoextend=True, perm=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6f4b72-d36f-4475-bb8f-d472f9542de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b46709-d76f-4bd7-8c03-fc1a93db6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- PROBE TASK PACK v2 (LIVE probe only, not invariance) ---\n",
    "PROMPTS_CORE = [\n",
    "    \"Write a vivid one-sentence metaphor for time.\",\n",
    "    \"Invent a new one-sentence proverb about patience.\",\n",
    "    \"Describe a sunrise using taste or smell in one sentence.\",\n",
    "    \"Coin a one-sentence motto for a city beneath the ocean.\",\n",
    "    \"Name a species and a color totem that symbolize resilience, one sentence.\",\n",
    "    \"Give a one-sentence charm to calm stormy thoughts.\",\n",
    "]\n",
    "BASE_USER = \"One sentence (≤30 words). Be concrete and fresh. No disclaimers.\"\n",
    "\n",
    "# Sampler breathing (top-p + presence penalty + headroom)\n",
    "import os\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.95\"\n",
    "os.environ[\"CNT_WP_FREQ_P\"]      = \"0.00\"   # keep freq neutral…\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.60\"   # …but encourage novelty\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45da6bd0-489d-4bed-9ecc-dd50850ed097",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure presence_penalty is forwarded (if your client doesn't yet)\n",
    "# (If you already see presence_penalty in the payload, skip this.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "661c10d9-e265-4d17-8165-8a8ca30c1cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pass A — presence 0.60\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"] = \"0.60\"\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "              reps=16, autoextend=True, perm=600)\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_pp0p60\", autoextend=True, perm=600)\n",
    "\n",
    "# Pass B — presence 0.80 (slightly bolder)\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"] = \"0.80\"\n",
    "run_with_alias(\"gpt-4o-mini\",\"live_full_pp0p80\", autoextend=True, perm=600)\n",
    "\n",
    "# Refresh boards (LIVE-only view)\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d36680-e1a1-4f30-8c7d-cef3f9a522fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === IPS/ASI REFRESHER (LIVE runs, no ladder re-sweep) ===\n",
    "# Recompute invariance (IPS) and anthropomorphism (ASI) for past LIVE runs\n",
    "# at a controlled reference temperature, using your current prompts/policy.\n",
    "\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def refresh_ips_asi(\n",
    "    mode=\"cold\",          # \"cold\" -> fixed t_ref, \"dynamic\" -> t_ref = knee - delta\n",
    "    inv_temp=0.20,        # used when mode == \"cold\"\n",
    "    delta=0.10,           # used when mode == \"dynamic\"\n",
    "    min_ips=None,         # only refresh runs whose current IPS < min_ips\n",
    "    run_ids=None          # or explicitly refresh these run_ids only\n",
    "):\n",
    "    base = get_probe_base()\n",
    "    refreshed = []\n",
    "\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        curves_p = rd / \"curves.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"):\n",
    "            continue\n",
    "        if run_ids and (m.get(\"run_id\") not in run_ids):\n",
    "            continue\n",
    "\n",
    "        # optional filter on current IPS\n",
    "        if min_ips is not None:\n",
    "            inv_path = rd / \"summary_gra_invariance.csv\"\n",
    "            if inv_path.exists():\n",
    "                try:\n",
    "                    prev_ips = float(pd.read_csv(inv_path)[\"inv_index_overall\"].mean())\n",
    "                    if prev_ips >= float(min_ips):\n",
    "                        continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # pick t_ref\n",
    "        if mode == \"dynamic\":\n",
    "            knee = float(m.get(\"theta\",{}).get(\"consensus\",{}).get(\"theta_star_grad\") or 1.24)\n",
    "            t_ref = max(0.20, knee - float(delta))\n",
    "        else:\n",
    "            t_ref = float(inv_temp)\n",
    "\n",
    "        # tell the sampler to use this cooler invariance temperature\n",
    "        os.environ[\"CNT_WP_INV_TREF\"] = f\"{t_ref:.2f}\"\n",
    "\n",
    "        # reuse model/temps/reps recorded in the run (for determinism of seeds)\n",
    "        model = m.get(\"model\") or os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "        temps = m.get(\"temps\", [])\n",
    "        reps  = int(m.get(\"reps\", 8))\n",
    "\n",
    "        # recompute invariance + ASI at t_ref (uses your current _live_invariance_and_asi)\n",
    "        idx = _live_invariance_and_asi(\n",
    "            model, temps, reps,\n",
    "            base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "\n",
    "        # overwrite CSVs\n",
    "        (rd / \"summary_gra_invariance.csv\").write_text(idx[\"inv_df\"].to_csv(index=False), encoding=\"utf-8\")\n",
    "        (rd / \"anthropomorphism_separation.csv\").write_text(idx[\"sep_df\"].to_csv(index=False), encoding=\"utf-8\")\n",
    "\n",
    "        # tag manifest\n",
    "        m.setdefault(\"meta\", {})[\"ips_asi_refreshed\"] = {\n",
    "            \"t_ref\": t_ref, \"mode\": mode, \"utc\": utc_stamp()\n",
    "        }\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        refreshed.append((m[\"run_id\"], f\"{t_ref:.2f}\", str(rd)))\n",
    "\n",
    "    print(f\"✓ Refreshed IPS/ASI for {len(refreshed)} LIVE run(s).\")\n",
    "    return refreshed\n",
    "\n",
    "# === Run it: refresh all LIVE runs at cold t_ref = 0.20 ===\n",
    "refreshed = refresh_ips_asi(mode=\"cold\", inv_temp=0.20)\n",
    "\n",
    "# (Option) only refresh LIVE runs with IPS < 0.85:\n",
    "# refreshed = refresh_ips_asi(mode=\"cold\", inv_temp=0.20, min_ips=0.85)\n",
    "\n",
    "# (Option) dynamic per-run: t_ref = consensus_knee - 0.10\n",
    "# refreshed = refresh_ips_asi(mode=\"dynamic\", delta=0.10)\n",
    "\n",
    "# Rebuild boards and show LIVE-only top table\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532cc66-6d12-423e-99ff-cc1c4f3802c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Repair LIVE manifests whose \"model\" contains aliases like _smoke/_audit/_ok ---\n",
    "import os, json, re, time\n",
    "from pathlib import Path\n",
    "\n",
    "ALIAS_PAT = re.compile(r\"(_smoke(_ok|2)?)|(_audit)|(_fp\\d+p\\d+)|(_pp\\d+p\\d+)|(_edge(view|hunt))$\", re.I)\n",
    "\n",
    "def ping_model(mid: str, max_tokens=4, timeout=12):\n",
    "    try:\n",
    "        out = _chat_completion(\n",
    "            mid,\n",
    "            [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "            temperature=0.0, max_tokens=max_tokens,\n",
    "            base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "            api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "        )\n",
    "        return (out.strip() == \"PONG\")\n",
    "    except Exception:\n",
    "        return False\n",
    "\n",
    "def resolve_working_model(candidates=None):\n",
    "    if candidates is None:\n",
    "        candidates = [\n",
    "            os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "            \"gpt-4o-mini\", \"gpt-4\", \"gpt-3.5-turbo\"\n",
    "        ]\n",
    "    for mid in candidates:\n",
    "        if mid and ping_model(mid):\n",
    "            print(f\"✓ Using model: {mid}\")\n",
    "            return mid\n",
    "        else:\n",
    "            print(f\"✗ Not available: {mid}\")\n",
    "    raise RuntimeError(\"No working model id responded to PONG.\")\n",
    "\n",
    "def repair_live_models(real_id: str):\n",
    "    base = get_probe_base()\n",
    "    fixed = 0\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"): \n",
    "            continue\n",
    "        old = m.get(\"model\",\"\")\n",
    "        if (old and old != real_id) and (ALIAS_PAT.search(old) or \" \" in old):\n",
    "            m[\"model\"] = real_id\n",
    "            m.setdefault(\"meta\", {})[\"repaired_model_from\"] = old\n",
    "            manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "            fixed += 1\n",
    "    print(f\"✓ Rewrote model id → {real_id} in {fixed} LIVE run(s).\")\n",
    "\n",
    "# Resolve a working model and repair\n",
    "REAL_ID = resolve_working_model()\n",
    "repair_live_models(REAL_ID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff6c982b-a13e-4284-bb05-cd979a76e762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Resilient refresher: cold t_ref, skips on 404, short timeouts, progress log ---\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Faster requests for this batch job\n",
    "os.environ[\"CNT_WP_HTTP_TIMEOUT\"] = os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"15\")\n",
    "os.environ[\"CNT_WP_HTTP_RETRIES\"] = \"0\"\n",
    "os.environ[\"CNT_WP_HTTP_DEBUG\"]   = \"1\"   # set \"0\" to silence\n",
    "\n",
    "def refresh_ips_asi_resilient(\n",
    "    mode=\"cold\", inv_temp=0.20, delta=0.10, min_ips=None, limit=None\n",
    "):\n",
    "    base = get_probe_base()\n",
    "    rows = []\n",
    "    n_done = n_skip = 0\n",
    "\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\"}]):\n",
    "        manf = rd / \"run_manifest.json\"\n",
    "        curves_p = rd / \"curves.json\"\n",
    "        if not manf.exists(): \n",
    "            continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"): \n",
    "            continue\n",
    "\n",
    "        run_id = m.get(\"run_id\", rd.name)\n",
    "        model  = m.get(\"model\") or os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "\n",
    "        # optional IPS filter\n",
    "        if min_ips is not None:\n",
    "            inv_path = rd / \"summary_gra_invariance.csv\"\n",
    "            if inv_path.exists():\n",
    "                try:\n",
    "                    prev_ips = float(pd.read_csv(inv_path)[\"inv_index_overall\"].mean())\n",
    "                    if prev_ips >= float(min_ips):\n",
    "                        rows.append({\"run_id\": run_id, \"status\":\"skip_ips_ok\"})\n",
    "                        continue\n",
    "                except Exception:\n",
    "                    pass\n",
    "\n",
    "        # pick t_ref\n",
    "        if mode == \"dynamic\":\n",
    "            knee = float(m.get(\"theta\",{}).get(\"consensus\",{}).get(\"theta_star_grad\") or 1.24)\n",
    "            t_ref = max(0.20, knee - float(delta))\n",
    "        else:\n",
    "            t_ref = float(inv_temp)\n",
    "        os.environ[\"CNT_WP_INV_TREF\"] = f\"{t_ref:.2f}\"\n",
    "\n",
    "        # recompute invariance/ASI at t_ref\n",
    "        try:\n",
    "            idx = _live_invariance_and_asi(\n",
    "                model, m.get(\"temps\", []), int(m.get(\"reps\", 8)),\n",
    "                base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "                api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "            )\n",
    "        except Exception as e:\n",
    "            # 404s or timeouts: skip politely\n",
    "            rows.append({\"run_id\": run_id, \"status\":\"error\", \"error\": type(e).__name__})\n",
    "            n_skip += 1\n",
    "            continue\n",
    "\n",
    "        # overwrite CSVs atomically\n",
    "        inv_df = idx[\"inv_df\"]; sep_df = idx[\"sep_df\"]\n",
    "        (rd/\"summary_gra_invariance.csv\").write_text(inv_df.to_csv(index=False), encoding=\"utf-8\")\n",
    "        (rd/\"anthropomorphism_separation.csv\").write_text(sep_df.to_csv(index=False), encoding=\"utf-8\")\n",
    "        m.setdefault(\"meta\", {})[\"ips_asi_refreshed\"] = {\"t_ref\": t_ref, \"mode\": mode, \"utc\": utc_stamp()}\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        rows.append({\"run_id\": run_id, \"status\":\"refreshed\", \"t_ref\": t_ref})\n",
    "        n_done += 1\n",
    "\n",
    "        if (limit is not None) and (n_done >= int(limit)):\n",
    "            break\n",
    "\n",
    "    log = pd.DataFrame(rows)\n",
    "    print(f\"✓ Refreshed {n_done} LIVE run(s); skipped {n_skip}.\")\n",
    "    return log\n",
    "\n",
    "# Run: refresh all LIVE runs at cold t_ref = 0.20, skip those already ≥ 0.85\n",
    "log = refresh_ips_asi_resilient(mode=\"cold\", inv_temp=0.20, min_ips=0.85)\n",
    "display(log.tail(10))\n",
    "\n",
    "# Rebuild boards and show LIVE-only table\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19bf798-2f28-4bce-893c-6719072755bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Crown the LIVE champion, write a README, zip it, and plot the crest ===\n",
    "import json, shutil\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def _read_manifest(rd):\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    inv = pd.read_csv(rd/\"summary_gra_invariance.csv\") if (rd/\"summary_gra_invariance.csv\").exists() else None\n",
    "    sep = pd.read_csv(rd/\"anthropomorphism_separation.csv\") if (rd/\"anthropomorphism_separation.csv\").exists() else None\n",
    "    return m, c, inv, sep\n",
    "\n",
    "def plot_run_curves(rd: Path):\n",
    "    m,c,inv,sep = _read_manifest(rd)\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    cons  = np.asarray(c[\"mean_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    gC    = np.asarray(c[\"grads_cons\"], float)\n",
    "    gD    = np.asarray(c[\"grads_diss\"], float)\n",
    "\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "\n",
    "    plt.figure(figsize=(7,4.6))\n",
    "    plt.plot(temps, cons, marker=\"o\", label=\"consensus (diversity)\")\n",
    "    plt.plot(temps, diss, marker=\"x\", label=\"dissent (turbulence)\")\n",
    "    plt.axvline(t_cons_knee, linestyle=\"--\", label=f\"consensus knee ≈ {t_cons_knee:.2f}\")\n",
    "    plt.axvline(t_diss_peak, linestyle=\":\",  label=f\"dissent peak ≈ {t_diss_peak:.2f}\")\n",
    "    plt.xlabel(\"temperature\"); plt.ylabel(\"response\"); plt.title(rd.name)\n",
    "    plt.legend(); plt.tight_layout(); plt.show()\n",
    "\n",
    "def publish_live_champion_from_df(live_top_df: pd.DataFrame, leader_clean_df: pd.DataFrame):\n",
    "    champ = live_top_df.iloc[0]\n",
    "    rd = Path(champ[\"outdir\"])\n",
    "    m,c,inv,sep = _read_manifest(rd)\n",
    "\n",
    "    # metrics\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    gC    = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width_peak  = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    ips = float(inv[\"inv_index_overall\"].mean()) if inv is not None else float(\"nan\")\n",
    "    asi = float(sep[\"separation_index\"].mean())  if sep is not None else float(\"nan\")\n",
    "    t_ref = (m.get(\"meta\",{}).get(\"ips_asi_refreshed\",{}) or {}).get(\"t_ref\", None)\n",
    "\n",
    "    # publish dir + README\n",
    "    pub = rd.parent / \"_published_live\"; pub.mkdir(exist_ok=True)\n",
    "    tag = f\"{rd.name}__LIVE_ESC_{champ['ESC_LIVE']:.3f}\"\n",
    "    out_dir = pub / tag\n",
    "    if out_dir.exists(): shutil.rmtree(out_dir)\n",
    "    shutil.copytree(rd, out_dir)\n",
    "\n",
    "    readme = [\n",
    "        \"CNT LIVE Weirdness Probe — Champion\",\n",
    "        f\"Run: {m.get('run_id')} | Model: {m.get('model')} | Mode: {m.get('llm_mode')}\",\n",
    "        f\"Temps: {','.join(map(lambda x:f'{x:.2f}', temps))}\",\n",
    "        f\"Consensus knee (grad): {t_cons_knee:.2f}\",\n",
    "        f\"Dissent peak (turbulence): {t_diss_peak:.2f}\",\n",
    "        f\"Width (peak-based): {width_peak:.3f}\",\n",
    "        f\"IPS_overall (cold): {ips:.6f}\" if inv is not None else \"IPS_overall: n/a\",\n",
    "        f\"ASI: {asi:.6f}\" if sep is not None else \"ASI: n/a\",\n",
    "        f\"Invariance t_ref: {t_ref:.2f}\" if t_ref is not None else \"Invariance t_ref: (not recorded)\",\n",
    "        \"\",\n",
    "        \"Notes:\",\n",
    "        \"- Invariance measured at cold t_ref; probe used creative, many-valid prompts.\",\n",
    "        \"- Dissent uses turbulence = dispersion × (1 − consensus).\",\n",
    "    ]\n",
    "    (out_dir/\"README_CHAMPION.txt\").write_text(\"\\n\".join(readme), encoding=\"utf-8\")\n",
    "\n",
    "    # zip bundle\n",
    "    bundle = shutil.make_archive(str(out_dir), \"zip\", out_dir)\n",
    "    print(f\"✓ Published LIVE champion: {out_dir}\\n✓ Bundle: {bundle}\")\n",
    "    return str(out_dir), bundle\n",
    "\n",
    "# Crown + Plot\n",
    "champ_dir, champ_zip = publish_live_champion_from_df(live_top, leader_clean)\n",
    "plot_run_curves(Path(champ_dir))\n",
    "print(\"Champion bundle:\", champ_zip)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9857855-1bf4-44c3-90b9-e63fdb246e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Stability suite: repeat champion N times, summarize & CI ===\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# House knobs (champion)\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "def crest_metrics(run_dir):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    consg = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(consg)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    ips, asi = np.nan, np.nan\n",
    "    inv = rd/\"summary_gra_invariance.csv\"\n",
    "    sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    if inv.exists(): ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean())\n",
    "    if sep.exists(): asi = float(pd.read_csv(sep)[\"separation_index\"].mean())\n",
    "    return dict(run_id=m[\"run_id\"], model=m[\"model\"],\n",
    "                t_cons_knee=t_cons_knee, t_diss_peak=t_diss_peak,\n",
    "                width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "def run_champion_repeats(n=3):\n",
    "    set_probe_env(model=\"gpt-4o-mini\",\n",
    "                  temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "                  reps=16, autoextend=True, perm=600)\n",
    "    rows=[]\n",
    "    for i in range(n):\n",
    "        rd = run_with_alias(\"gpt-4o-mini\", f\"live_champion_rep{i+1}\", autoextend=True, perm=600)\n",
    "        rows.append(crest_metrics(rd))\n",
    "    df = pd.DataFrame(rows).sort_values(\"run_id\")\n",
    "    # CIs (basic normal approx)\n",
    "    def ci(s): \n",
    "        s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "        m, sd = s.mean(), s.std(ddof=1) if len(s)>1 else 0.0\n",
    "        return m, m-1.96*sd/np.sqrt(max(1,len(s))), m+1.96*sd/np.sqrt(max(1,len(s)))\n",
    "    w_m, w_lo, w_hi = ci(df[\"width\"])\n",
    "    ips_m, _, _ = ci(df[\"ips\"])\n",
    "    print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f}\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "stability_df = run_champion_repeats(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bfbbc6-6a0b-4342-8ca1-1ff0bf87ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os  # <-- missing import\n",
    "\n",
    "# House knobs (champion)\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fa16ccd-fdcd-40d3-8cd4-4444c2f65597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Stability suite: repeat champion N times, summarize & CI ===\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# House knobs (champion)\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "def crest_metrics(run_dir):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    consg = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(consg)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    ips, asi = np.nan, np.nan\n",
    "    inv = rd/\"summary_gra_invariance.csv\"\n",
    "    sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    if inv.exists(): ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean())\n",
    "    if sep.exists(): asi = float(pd.read_csv(sep)[\"separation_index\"].mean())\n",
    "    return dict(run_id=m[\"run_id\"], model=m[\"model\"],\n",
    "                t_cons_knee=t_cons_knee, t_diss_peak=t_diss_peak,\n",
    "                width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "def run_champion_repeats(n=3):\n",
    "    set_probe_env(model=\"gpt-4o-mini\",\n",
    "                  temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "                  reps=16, autoextend=True, perm=600)\n",
    "    rows=[]\n",
    "    for i in range(n):\n",
    "        rd = run_with_alias(\"gpt-4o-mini\", f\"live_champion_rep{i+1}\", autoextend=True, perm=600)\n",
    "        rows.append(crest_metrics(rd))\n",
    "    df = pd.DataFrame(rows).sort_values(\"run_id\")\n",
    "    # CIs (basic normal approx)\n",
    "    def ci(s): \n",
    "        s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "        m, sd = s.mean(), s.std(ddof=1) if len(s)>1 else 0.0\n",
    "        return m, m-1.96*sd/np.sqrt(max(1,len(s))), m+1.96*sd/np.sqrt(max(1,len(s)))\n",
    "    w_m, w_lo, w_hi = ci(df[\"width\"])\n",
    "    ips_m, _, _ = ci(df[\"ips\"])\n",
    "    print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f}\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "stability_df = run_champion_repeats(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bf8b5e0-9ab2-424b-be68-f5ccfc03a630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# House knobs (champion)\n",
    "import os\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "stability_df = run_champion_repeats(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "fe56888d-bfc3-44f9-abb2-c7d288a0eead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Quick-resync loaded: set_probe_env(), run_with_alias(), get_probe_base()\n",
      "• Engine present? run_model: yes\n"
     ]
    }
   ],
   "source": [
    "# === Quick Resync for v1.5 helpers (lightweight) ===\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "def utc_stamp():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def get_probe_base():\n",
    "    base = os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\"\n",
    "    p = Path(base) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "    return p\n",
    "\n",
    "def ensure_dir(p):\n",
    "    p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
    "\n",
    "def set_probe_env(\n",
    "    temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "    reps=16, perm=600, autoextend=True, smooth=\"none\",\n",
    "    model=\"gpt-4o-mini\", api_key=None, base_url=None,\n",
    "):\n",
    "    os.environ[\"CNT_WP_TEMPS\"]      = temps\n",
    "    os.environ[\"CNT_WP_N_REPS\"]     = str(reps)\n",
    "    os.environ[\"CNT_WP_PERM\"]       = str(perm)\n",
    "    os.environ[\"CNT_WP_AUTOEXTEND\"] = \"1\" if autoextend else \"0\"\n",
    "    os.environ[\"CNT_WP_SMOOTH\"]     = smooth\n",
    "    os.environ[\"LLM_MODEL\"]         = model\n",
    "    if api_key is not None: os.environ[\"OPENAI_API_KEY\"]  = api_key\n",
    "    if base_url:            os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    print(f\"✓ Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "\n",
    "def run_with_alias(model_id: str, alias: str, **kw):\n",
    "    outdir = ensure_dir(get_probe_base() / f\"{utc_stamp()}_{alias}\")\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(outdir)\n",
    "    if \"run_model\" not in globals():\n",
    "        raise RuntimeError(\"run_model is not defined in this kernel. Re-run your v1.5 mega-cell to load the engine.\")\n",
    "    return run_model(model_id, **kw)\n",
    "\n",
    "print(\"✓ Quick-resync loaded: set_probe_env(), run_with_alias(), get_probe_base()\")\n",
    "print(\"• Engine present? run_model:\", \"yes\" if \"run_model\" in globals() else \"NO (re-run v1.5 mega-cell)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d0ced49-b5ef-4853-87f5-692af6e98125",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-064257Z_live_champion_rep1\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-073610Z_live_champion_rep2\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-082951Z_live_champion_rep3\n",
      "WIDTH mean≈0.000 95%CI[0.000,0.000] | IPS mean≈0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model</th>\n",
       "      <th>t_cons_knee</th>\n",
       "      <th>t_diss_peak</th>\n",
       "      <th>width</th>\n",
       "      <th>ips</th>\n",
       "      <th>asi</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-064257Z_gpt-4o-mini</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-073610Z_gpt-4o-mini</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-082951Z_gpt-4o-mini</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.18</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_id        model  t_cons_knee  t_diss_peak  width  \\\n",
       "0  20251102-064257Z_gpt-4o-mini  gpt-4o-mini         1.18         1.18    0.0   \n",
       "1  20251102-073610Z_gpt-4o-mini  gpt-4o-mini         1.18         1.18    0.0   \n",
       "2  20251102-082951Z_gpt-4o-mini  gpt-4o-mini         1.18         1.18    0.0   \n",
       "\n",
       "   ips  asi                                             outdir  \n",
       "0  0.0  0.0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  0.0  0.0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  0.0  0.0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# House knobs (champion)\n",
    "import os\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "stability_df = run_champion_repeats(n=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7e1fe684-bf30-422f-93c8-0194092bc53b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115142Z_live_champion_rep1\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2366456236.py:311: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return float(np.trapz(d, x=np.asarray(temps, dtype=float)))\n",
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_23168\\2366456236.py:325: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  val = float(np.trapz(null, x=x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.6073\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.3810\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115145Z_live_champion_rep2\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.6190\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.4077\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115148Z_live_champion_rep3\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.6290\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.000 | status=NO_EVENT | p=0.4010\n",
      "WIDTH mean≈0.000 95%CI[0.000,0.000] | IPS mean≈0.000 95%CI[0.000,0.000]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model</th>\n",
       "      <th>t_cons_knee</th>\n",
       "      <th>t_diss_peak</th>\n",
       "      <th>width</th>\n",
       "      <th>ips</th>\n",
       "      <th>perm_p</th>\n",
       "      <th>status</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-115142Z_live_champion_rep1</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.381032</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-115145Z_live_champion_rep2</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.407654</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-115148Z_live_champion_rep3</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>0.78</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000076</td>\n",
       "      <td>0.400998</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id        model  t_cons_knee  t_diss_peak  \\\n",
       "0  20251102-115142Z_live_champion_rep1  gpt-4o-mini         0.78         1.18   \n",
       "1  20251102-115145Z_live_champion_rep2  gpt-4o-mini         0.78         1.18   \n",
       "2  20251102-115148Z_live_champion_rep3  gpt-4o-mini         0.78         1.18   \n",
       "\n",
       "   width       ips    perm_p    status  \\\n",
       "0    0.0  0.000076  0.381032  NO_EVENT   \n",
       "1    0.0  0.000076  0.407654  NO_EVENT   \n",
       "2    0.0  0.000076  0.400998  NO_EVENT   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id\tmodel\tt_cons_knee\tt_diss_peak\twidth\tips\tstatus\toutdir\n",
      "20251102-115142Z_live_champion_rep1\tgpt-4o-mini\t0.78\t1.18\t0.000\t0.000\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115142Z_live_champion_rep1\n",
      "20251102-115145Z_live_champion_rep2\tgpt-4o-mini\t0.78\t1.18\t0.000\t0.000\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115145Z_live_champion_rep2\n",
      "20251102-115148Z_live_champion_rep3\tgpt-4o-mini\t0.78\t1.18\t0.000\t0.000\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-115148Z_live_champion_rep3\n"
     ]
    }
   ],
   "source": [
    "# CNT Weirdness Probe v1.5 — Restart‑Safe Mega Cell (kernel‑restart friendly)\n",
    "# ---------------------------------------------------------------------------\n",
    "# What this cell does\n",
    "#   • Re‑boots the probe environment and directory structure\n",
    "#   • Wraps the LLM call (OpenAI Chat Completions if available; SIMULATION fallback otherwise)\n",
    "#   • Runs a temperature sweep with multiple reps per temp\n",
    "#   • Computes consistency (pairwise trigram Jaccard ↑) and dissociation (pairwise 1‑gram cosine distance ↑)\n",
    "#   • Smooths curves (optional), detects knee/peak, width, IPS area, and a permutation p‑value\n",
    "#   • Auto‑extends the sweep if no separation is found\n",
    "#   • Saves CSV/JSON + a curves.png into E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\<timestamp>_live_champion_repX\n",
    "#   • Provides run_champion_repeats(n) for quick multi‑rep sessions\n",
    "#\n",
    "# Usage (defaults mirror your last run):\n",
    "#   1) Just run this cell. It will automatically run run_champion_repeats(n=3).\n",
    "#   2) To tweak: set env vars before (or edit CONFIG block below):\n",
    "#        CNT_WP_MODEL, CNT_WP_TEMPS, CNT_WP_REPS, CNT_WP_PERM, CNT_WP_AUTOEXTEND, CNT_WP_SMOOTH, CNT_LAB_DIR\n",
    "#   3) After it finishes, re‑run: stability_df = run_champion_repeats(n=3)\n",
    "#\n",
    "# Notes\n",
    "#   • If the OpenAI client isn’t configured, the probe switches to SIMULATION mode (prints \"LLM : SIMULATION\").\n",
    "#   • Smoothing options: \"none\" (default), \"gauss:3\", \"median:5\".\n",
    "#   • Temperature bounds respected: [0.5, 2.0], auto‑extend pushes both sides by ±0.2 per round.\n",
    "\n",
    "import os, sys, re, json, time, math, random, hashlib, textwrap, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------- Optional auto‑install -----------------------------\n",
    "AUTO_INSTALL = False  # set True if you want the cell to try pip‑installing missing libs\n",
    "\n",
    "def _install_if_missing(pkgs):\n",
    "    if not AUTO_INSTALL:\n",
    "        return\n",
    "    for p in pkgs:\n",
    "        try:\n",
    "            __import__(p)\n",
    "        except Exception:\n",
    "            try:\n",
    "                print(f\"[pip] installing {p}…\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
    "            except Exception as e:\n",
    "                print(f\"[pip] failed to install {p}: {e}\")\n",
    "\n",
    "_install_if_missing([\"openai\"])  # only if AUTO_INSTALL=True\n",
    "\n",
    "# ------------------------------- LLM wrapper ------------------------------------\n",
    "_HAS_NEW_OPENAI = False\n",
    "_HAS_OLD_OPENAI = False\n",
    "client_new = None\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI  # new SDK\n",
    "    try:\n",
    "        client_new = OpenAI()\n",
    "        _HAS_NEW_OPENAI = True\n",
    "    except Exception:\n",
    "        client_new = None\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not _HAS_NEW_OPENAI:\n",
    "    try:\n",
    "        import openai  # legacy SDK\n",
    "        _HAS_OLD_OPENAI = True\n",
    "    except Exception:\n",
    "        _HAS_OLD_OPENAI = False\n",
    "\n",
    "\n",
    "def _now_stamp():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------ Env bootstrap -----------------------------------\n",
    "\n",
    "def set_probe_env(model: str,\n",
    "                  temps: str,\n",
    "                  reps: int = 16,\n",
    "                  perm: int = 600,\n",
    "                  autoextend: bool = True,\n",
    "                  smooth: str = \"none\",\n",
    "                  root: str = r\"E:\\\\CNT\",\n",
    "                  label: str | None = None,\n",
    "                  rep_idx: int | None = None):\n",
    "    os.environ.setdefault(\"CNT_LAB_DIR\", root)\n",
    "    os.environ.setdefault(\"PYTHONPATH\", root)\n",
    "    out_root = Path(root) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    _ensure_dir(out_root)\n",
    "    ts = _now_stamp()\n",
    "    suffix = f\"_{label}_rep{rep_idx}\" if (label and rep_idx is not None) else \"\"\n",
    "    run_id = f\"{ts}{suffix}\"\n",
    "    outdir = out_root / run_id\n",
    "    _ensure_dir(outdir)\n",
    "    print(f\"\\u2713 Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "    return dict(root=root, outdir=str(outdir), run_id=run_id, model=model, reps=reps, perm=perm,\n",
    "                autoextend=autoextend, smooth=smooth)\n",
    "\n",
    "\n",
    "def parse_temps_str(s: str):\n",
    "    vals = sorted({round(float(x), 3) for x in re.split(r\"[\\,\\s]+\", s.strip()) if x})\n",
    "    # keep within reasonable bounds\n",
    "    vals = [v for v in vals if 0.5 <= v <= 2.0]\n",
    "    if not vals:\n",
    "        vals = [0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9]\n",
    "    return vals\n",
    "\n",
    "\n",
    "# -------------------------------- SIM fallback ----------------------------------\n",
    "SIM_VOCAB = (\n",
    "    \"field drift glyph ring echo anchor pulse axis veil resonance spiral lattice gauge weave \"\n",
    "    \"mirror seed phase oracle fold flame vector shadow quantum cybernetic topology entropy memory \"\n",
    "    \"cascade gradient basin suture harmonic torsion flux curvature chandelier singularity nexus\"\n",
    ").split()\n",
    "\n",
    "\n",
    "def sim_text(prompt: str, temperature: float, seed: int | None = None) -> str:\n",
    "    rng = np.random.default_rng(int((temperature * 1e6) % (2**32 - 1)))\n",
    "    target_len = int(140 + 120 * min(float(temperature), 2.0))\n",
    "    o = []\n",
    "    prev = rng.choice(SIM_VOCAB)\n",
    "    for _ in range(target_len):\n",
    "        if rng.random() < min(0.15 + 0.4 * (temperature / 2.0), 0.5):\n",
    "            token = rng.choice(SIM_VOCAB)\n",
    "        else:\n",
    "            token = _mutate_token(prev, rng, temperature)\n",
    "        o.append(token)\n",
    "        prev = token\n",
    "    s = \" \".join(o)\n",
    "    return s[:1500]\n",
    "\n",
    "\n",
    "def _mutate_token(token: str, rng: np.random.Generator, temperature: float) -> str:\n",
    "    if rng.random() < 0.5 * min(1.0, temperature):\n",
    "        chars = list(token)\n",
    "        rng.shuffle(chars)\n",
    "        return \"\".join(chars)\n",
    "    elif rng.random() < 0.3 * min(1.0, temperature):\n",
    "        return token + rng.choice([\".\", \"\", \"\", \"-\", \"\"])\n",
    "    return token\n",
    "\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model: str, seed: int | None = None):\n",
    "        self.model = model\n",
    "        self.seed = seed\n",
    "        self.mode = \"SIMULATION\"\n",
    "        self.client_new = client_new if _HAS_NEW_OPENAI else None\n",
    "        self.has_old = _HAS_OLD_OPENAI\n",
    "        if self.client_new is not None:\n",
    "            self.mode = \"OPENAI\"\n",
    "        elif self.has_old:\n",
    "            self.mode = \"OPENAI_LEGACY\"\n",
    "        random.seed(seed)\n",
    "\n",
    "    def sample(self, prompt: str, temperature: float = 1.0, max_tokens: int = 256, top_p: float = 1.0) -> str:\n",
    "        # New SDK\n",
    "        if self.mode == \"OPENAI\" and self.client_new is not None:\n",
    "            try:\n",
    "                resp = self.client_new.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=float(temperature), top_p=float(top_p), max_tokens=int(max_tokens),\n",
    "                    presence_penalty=0, frequency_penalty=0,\n",
    "                )\n",
    "                return (resp.choices[0].message.content or \"\").strip()\n",
    "            except Exception as e:\n",
    "                print(f\"[openai/new] error: {e} -> falling back to SIMULATION\")\n",
    "                self.mode = \"SIMULATION\"\n",
    "        # Legacy SDK\n",
    "        if self.mode == \"OPENAI_LEGACY\" and self.has_old:\n",
    "            try:\n",
    "                resp = openai.ChatCompletion.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=float(temperature), top_p=float(top_p), max_tokens=int(max_tokens),\n",
    "                    presence_penalty=0, frequency_penalty=0,\n",
    "                )\n",
    "                return (resp.choices[0].message[\"content\"] or \"\").strip()\n",
    "            except Exception as e:\n",
    "                print(f\"[openai/legacy] error: {e} -> falling back to SIMULATION\")\n",
    "                self.mode = \"SIMULATION\"\n",
    "        # Simulation fallback\n",
    "        return sim_text(prompt, temperature, seed=self.seed)\n",
    "\n",
    "\n",
    "# --------------------------------- Metrics --------------------------------------\n",
    "\n",
    "def _words(s: str):\n",
    "    return re.findall(r\"[A-Za-z]+\", (s or \"\").lower())\n",
    "\n",
    "\n",
    "def _ngrams(tokens, n=3):\n",
    "    return [\" \".join(tokens[i:i+n]) for i in range(len(tokens) - n + 1)] if len(tokens) >= n else []\n",
    "\n",
    "\n",
    "def _jaccard(a, b):\n",
    "    A, B = set(a), set(b)\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    if not A or not B:\n",
    "        return 0.0\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "\n",
    "def _pairwise_mean_jaccard(list_of_iters):\n",
    "    sims = []\n",
    "    for i in range(len(list_of_iters)):\n",
    "        for j in range(i + 1, len(list_of_iters)):\n",
    "            sims.append(_jaccard(list_of_iters[i], list_of_iters[j]))\n",
    "    return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "\n",
    "def _cosine_distance_counts(a_tokens, b_tokens):\n",
    "    from collections import Counter\n",
    "    A = Counter(a_tokens); B = Counter(b_tokens)\n",
    "    keys = set(A) | set(B)\n",
    "    if not keys:\n",
    "        return 0.0\n",
    "    a = np.array([A[k] for k in keys], dtype=float)\n",
    "    b = np.array([B[k] for k in keys], dtype=float)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    sim = float(np.dot(a, b) / denom)\n",
    "    return 1.0 - sim\n",
    "\n",
    "\n",
    "def measure_at_temp(samples: list[str]):\n",
    "    tri_sets = [_ngrams(_words(x), 3) for x in samples]\n",
    "    consistency = _pairwise_mean_jaccard(tri_sets)  # higher = more similar (coherence)\n",
    "    toks = [_words(x) for x in samples]\n",
    "    dists = []\n",
    "    for i in range(len(toks)):\n",
    "        for j in range(i + 1, len(toks)):\n",
    "            dists.append(_cosine_distance_counts(toks[i], toks[j]))\n",
    "    dissociation = float(np.mean(dists)) if dists else 0.0  # higher = more divergent\n",
    "    return consistency, dissociation\n",
    "\n",
    "\n",
    "# ------------------------------ Smoothing & Detect ------------------------------\n",
    "\n",
    "def smooth_curve(y, mode=\"none\"):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if mode == \"none\" or len(y) < 5:\n",
    "        return y\n",
    "    if mode.startswith(\"gauss\"):\n",
    "        try:\n",
    "            k = int(mode.split(\":\")[1])\n",
    "        except Exception:\n",
    "            k = 3\n",
    "        k = max(1, k)\n",
    "        r = k\n",
    "        x = np.arange(-r, r + 1)\n",
    "        sigma = k / 2.0\n",
    "        g = np.exp(-(x ** 2) / (2 * sigma ** 2))\n",
    "        g = g / np.sum(g)\n",
    "        return np.convolve(y, g, mode=\"same\")\n",
    "    if mode.startswith(\"median\"):\n",
    "        try:\n",
    "            w = int(mode.split(\":\")[1])\n",
    "        except Exception:\n",
    "            w = 5\n",
    "        w = max(3, w | 1)\n",
    "        pad = w // 2\n",
    "        z = np.pad(y, (pad, pad), mode=\"edge\")\n",
    "        out = [float(np.median(z[i:i + w])) for i in range(len(y))]\n",
    "        return np.array(out)\n",
    "    return y\n",
    "\n",
    "\n",
    "def kneedle_idx(x, y, direction=\"decreasing\"):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if len(x) < 3:\n",
    "        return 0, False\n",
    "    # Max distance from chord between endpoints\n",
    "    x0, x1 = x[0], x[-1]\n",
    "    y0, y1 = y[0], y[-1]\n",
    "    denom = math.hypot(x1 - x0, y1 - y0) + 1e-12\n",
    "    d = []\n",
    "    for xi, yi in zip(x, y):\n",
    "        num = abs((y1 - y0) * xi - (x1 - x0) * yi + x1 * y0 - y1 * x0)\n",
    "        d.append(num / denom)\n",
    "    idx = int(np.argmax(d))\n",
    "    valid = (idx > 0 and idx < len(x) - 1)\n",
    "    return idx, valid\n",
    "\n",
    "\n",
    "def peak_idx(y):\n",
    "    if len(y) < 3:\n",
    "        return 0, False\n",
    "    idx = int(np.argmax(y))\n",
    "    valid = (idx > 0 and idx < len(y) - 1)\n",
    "    return idx, valid\n",
    "\n",
    "\n",
    "def _z(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    mu = a.mean(); sd = a.std()\n",
    "    return (a - mu) / (sd + 1e-12)\n",
    "\n",
    "\n",
    "def ips_area(temps, cons, diss):\n",
    "    d = np.maximum(_z(diss) - _z(cons), 0.0)\n",
    "    return float(np.trapz(d, x=np.asarray(temps, dtype=float)))\n",
    "\n",
    "\n",
    "def ips_perm_p(temps, cons, diss, perm=600, rng=None):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    obs = ips_area(temps, cons, diss)\n",
    "    if obs <= 0:\n",
    "        return 1.0, obs\n",
    "    d = _z(diss) - _z(cons)\n",
    "    x = np.asarray(temps, dtype=float)\n",
    "    count = 0\n",
    "    for _ in range(int(perm)):\n",
    "        signs = rng.choice([-1.0, 1.0], size=len(d))\n",
    "        null = np.maximum(signs * d, 0.0)\n",
    "        val = float(np.trapz(null, x=x))\n",
    "        if val >= obs - 1e-12:\n",
    "            count += 1\n",
    "    p = (count + 1) / (perm + 1)\n",
    "    return float(p), float(obs)\n",
    "\n",
    "\n",
    "# --------------------------------- Runner ---------------------------------------\n",
    "\n",
    "def run_probe(model, temps_list, reps=16, smooth=\"none\", perm=600, seed=None, outdir=None, verbose=True, llm=None):\n",
    "    llm = llm or LLM(model, seed=seed)\n",
    "    if verbose:\n",
    "        print(f\"LLM : {llm.mode}\")\n",
    "        print(f\"Temps: {temps_list} | Reps: {reps} | Smooth(viz)={smooth}\")\n",
    "    all_samples: dict[float, list[str]] = {}\n",
    "    base_prompt = (\n",
    "        \"Write a compact, richly textured paragraph (120–180 words) about a storm seen from a lighthouse. \"\n",
    "        \"Avoid lists. Use precise nouns. End with a single striking image.\"\n",
    "    )\n",
    "    for t in temps_list:\n",
    "        bucket = []\n",
    "        for r in range(reps):\n",
    "            txt = llm.sample(base_prompt, temperature=float(t), max_tokens=256, top_p=1.0)\n",
    "            bucket.append(txt)\n",
    "        all_samples[float(t)] = bucket\n",
    "        if verbose:\n",
    "            lengths = [len(x) for x in bucket]\n",
    "            print(f\"[{t:.2f}] len(avg)={np.mean(lengths):.1f} n={len(bucket)}\")\n",
    "\n",
    "    temps_sorted = sorted(all_samples.keys())\n",
    "    cons, diss = [], []\n",
    "    for t in temps_sorted:\n",
    "        c, d = measure_at_temp(all_samples[t])\n",
    "        cons.append(c); diss.append(d)\n",
    "\n",
    "    cons_s = smooth_curve(cons, smooth)\n",
    "    diss_s = smooth_curve(diss, smooth)\n",
    "\n",
    "    k_idx, has_knee = kneedle_idx(temps_sorted, cons_s, direction=\"decreasing\")\n",
    "    p_idx, has_peak = peak_idx(diss_s)\n",
    "    t_cons_knee = float(temps_sorted[k_idx])\n",
    "    t_diss_peak = float(temps_sorted[p_idx])\n",
    "\n",
    "    status = \"NO_EVENT\"; width = 0.0\n",
    "    if has_knee and has_peak and p_idx > k_idx:\n",
    "        status = \"SEPARATED\"; width = float(t_diss_peak - t_cons_knee)\n",
    "    elif has_knee and has_peak and p_idx <= k_idx:\n",
    "        status = \"REVERSED\"; width = 0.0\n",
    "\n",
    "    pval, ips = ips_perm_p(temps_sorted, cons_s, diss_s, perm=perm)\n",
    "\n",
    "    summary = dict(\n",
    "        model=model,\n",
    "        temps=temps_sorted,\n",
    "        consistency=[float(x) for x in cons_s],\n",
    "        dissociation=[float(x) for x in diss_s],\n",
    "        knee_idx=int(k_idx), peak_idx=int(p_idx),\n",
    "        t_cons_knee=float(t_cons_knee), t_diss_peak=float(t_diss_peak),\n",
    "        width=float(width), status=status, ips=float(ips), perm_p=float(pval),\n",
    "    )\n",
    "\n",
    "    if outdir:\n",
    "        p = Path(outdir)\n",
    "        _ensure_dir(p)\n",
    "        pd.DataFrame({\"temp\": temps_sorted, \"consistency\": cons_s, \"dissociation\": diss_s}).to_csv(p / \"curves.csv\", index=False)\n",
    "        with open(p / \"summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure()\n",
    "            plt.plot(temps_sorted, cons_s, marker=\"o\", label=\"consistency\")\n",
    "            plt.plot(temps_sorted, diss_s, marker=\"s\", label=\"dissociation\")\n",
    "            plt.axvline(t_cons_knee, linestyle=\"--\")\n",
    "            plt.axvline(t_diss_peak, linestyle=\"--\")\n",
    "            plt.title(f\"Weirdness Probe v1.5 — {model}\")\n",
    "            plt.xlabel(\"temperature\"); plt.ylabel(\"score\")\n",
    "            plt.legend(); plt.tight_layout(); plt.savefig(p / \"curves.png\", dpi=160); plt.close()\n",
    "        except Exception as e:\n",
    "            print(\"Plot skipped:\", e)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def autoextend_sweep(temps, status, width, rounds=2):\n",
    "    if status == \"SEPARATED\" and width > 0:\n",
    "        return sorted(temps)\n",
    "    tset = set(temps)\n",
    "    lo, hi = min(temps), max(temps)\n",
    "    for _ in range(int(rounds)):\n",
    "        lo = max(0.5, round(lo - 0.2, 2))\n",
    "        hi = min(2.0, round(hi + 0.2, 2))\n",
    "        tset.update([lo, hi])\n",
    "    return sorted(tset)\n",
    "\n",
    "\n",
    "# --------------------------- Session helpers / repeats ---------------------------\n",
    "\n",
    "def _config_from_env():\n",
    "    return dict(\n",
    "        model=os.environ.get(\"CNT_WP_MODEL\", \"gpt-4o-mini\"),\n",
    "        temps_str=os.environ.get(\"CNT_WP_TEMPS\", \"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\"),\n",
    "        reps=int(os.environ.get(\"CNT_WP_REPS\", \"16\")),\n",
    "        perm=int(os.environ.get(\"CNT_WP_PERM\", \"600\")),\n",
    "        autoextend=os.environ.get(\"CNT_WP_AUTOEXTEND\", \"true\").lower() in {\"1\", \"true\", \"yes\", \"y\"},\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\", \"none\"),\n",
    "        root=os.environ.get(\"CNT_LAB_DIR\", r\"E:\\\\CNT\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def run_once(label=None, rep_idx=None, **kwargs):\n",
    "    model = kwargs.get(\"model\"); temps_str = kwargs.get(\"temps_str\"); reps = kwargs.get(\"reps\")\n",
    "    perm = kwargs.get(\"perm\"); autoextend = kwargs.get(\"autoextend\"); smooth = kwargs.get(\"smooth\"); root = kwargs.get(\"root\")\n",
    "    temps_list = parse_temps_str(temps_str)\n",
    "    env = set_probe_env(model=model, temps=temps_str, reps=reps, perm=perm, autoextend=autoextend, smooth=smooth,\n",
    "                        root=root, label=label, rep_idx=rep_idx)\n",
    "    outdir = env[\"outdir\"]\n",
    "    print(f\"\\u2699\\ufe0f Running v1.5 (v1.4 merged) | model={model} | out={outdir}\")\n",
    "\n",
    "    s1 = run_probe(model, temps_list, reps=reps, smooth=smooth, perm=perm, seed=None, outdir=outdir)\n",
    "    print(f\"WIDTH={s1['width']:.3f} | IPS={s1['ips']:.3f} | status={s1['status']} | p={s1['perm_p']:.4f}\")\n",
    "\n",
    "    if autoextend and s1[\"status\"] != \"SEPARATED\":\n",
    "        temps2 = autoextend_sweep(temps_list, s1[\"status\"], s1[\"width\"], rounds=2)\n",
    "        if temps2 != sorted(temps_list):\n",
    "            print(\"\\u21bb Autoextend sweep ->\", temps2)\n",
    "            s2 = run_probe(model, temps2, reps=reps, smooth=smooth, perm=perm, seed=None, outdir=outdir)\n",
    "            print(f\"WIDTH={s2['width']:.3f} | IPS={s2['ips']:.3f} | status={s2['status']} | p={s2['perm_p']:.4f}\")\n",
    "            return s2, outdir\n",
    "    return s1, outdir\n",
    "\n",
    "\n",
    "def _ci95(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    if len(a) == 0:\n",
    "        return (float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "    m = float(np.mean(a)); s = float(np.std(a, ddof=1)) if len(a) > 1 else 0.0\n",
    "    lo = m - 1.96 * s / max(1, math.sqrt(len(a)))\n",
    "    hi = m + 1.96 * s / max(1, math.sqrt(len(a)))\n",
    "    return m, lo, hi\n",
    "\n",
    "\n",
    "def run_champion_repeats(n=3):\n",
    "    cfg = _config_from_env()\n",
    "    rows = []\n",
    "    for i in range(1, int(n) + 1):\n",
    "        s, outdir = run_once(label=\"live_champion\", rep_idx=i, **cfg)\n",
    "        rows.append({\n",
    "            \"run_id\": Path(outdir).name,\n",
    "            \"model\": cfg[\"model\"],\n",
    "            \"t_cons_knee\": s.get(\"t_cons_knee\", np.nan),\n",
    "            \"t_diss_peak\": s.get(\"t_diss_peak\", np.nan),\n",
    "            \"width\": s.get(\"width\", np.nan),\n",
    "            \"ips\": s.get(\"ips\", np.nan),\n",
    "            \"perm_p\": s.get(\"perm_p\", np.nan),\n",
    "            \"status\": s.get(\"status\", \"\"),\n",
    "            \"outdir\": outdir,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    w_m, w_lo, w_hi = _ci95(df[\"width\"].values)\n",
    "    ips_m, ips_lo, ips_hi = _ci95(df[\"ips\"].values)\n",
    "    print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f} 95%CI[{ips_lo:.3f},{ips_hi:.3f}]\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df)\n",
    "    except Exception:\n",
    "        print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------- Auto‑run -------------------------------------\n",
    "AUTO_RUN = True\n",
    "REPEATS = int(os.environ.get(\"CNT_WP_REPEATS\", \"3\"))\n",
    "\n",
    "if AUTO_RUN:\n",
    "    stability_df = run_champion_repeats(n=REPEATS)\n",
    "    # Echo summary in one row form (similar to your tabular print)\n",
    "    try:\n",
    "        print(\"run_id\\tmodel\\tt_cons_knee\\tt_diss_peak\\twidth\\tips\\tstatus\\toutdir\")\n",
    "        for _, r in stability_df.iterrows():\n",
    "            print(f\"{r['run_id']}\\t{r['model']}\\t{r['t_cons_knee']:.2f}\\t{r['t_diss_peak']:.2f}\\t{r['width']:.3f}\\t{r['ips']:.3f}\\t{r['status']}\\t{r['outdir']}\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c4f3b47-1cb2-414b-8fd8-0a1b866a187e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121234Z_live_champion_rep1\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.057 | status=NO_EVENT | p=0.4942\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.375 | status=NO_EVENT | p=0.1381\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121239Z_live_champion_rep2\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.057 | status=NO_EVENT | p=0.5025\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.375 | status=NO_EVENT | p=0.1198\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "⚙️ Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121244Z_live_champion_rep3\n",
      "LLM : SIMULATION\n",
      "Temps: [1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3] | Reps: 16 | Smooth(viz)=none\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.057 | status=NO_EVENT | p=0.4975\n",
      "↻ Autoextend sweep -> [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7]\n",
      "LLM : SIMULATION\n",
      "Temps: [0.78, 0.98, 1.18, 1.2, 1.21, 1.22, 1.23, 1.24, 1.25, 1.26, 1.27, 1.28, 1.3, 1.5, 1.7] | Reps: 16 | Smooth(viz)=none\n",
      "[0.78] len(avg)=1500.0 n=16\n",
      "[0.98] len(avg)=1500.0 n=16\n",
      "[1.18] len(avg)=1500.0 n=16\n",
      "[1.20] len(avg)=1500.0 n=16\n",
      "[1.21] len(avg)=1500.0 n=16\n",
      "[1.22] len(avg)=1500.0 n=16\n",
      "[1.23] len(avg)=1500.0 n=16\n",
      "[1.24] len(avg)=1500.0 n=16\n",
      "[1.25] len(avg)=1500.0 n=16\n",
      "[1.26] len(avg)=1500.0 n=16\n",
      "[1.27] len(avg)=1500.0 n=16\n",
      "[1.28] len(avg)=1500.0 n=16\n",
      "[1.30] len(avg)=1500.0 n=16\n",
      "[1.50] len(avg)=1500.0 n=16\n",
      "[1.70] len(avg)=1500.0 n=16\n",
      "WIDTH=0.000 | IPS=0.375 | status=NO_EVENT | p=0.1215\n",
      "WIDTH mean≈0.000 95%CI[0.000,0.000] | IPS mean≈0.375 95%CI[0.375,0.375]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>model</th>\n",
       "      <th>t_cons_knee</th>\n",
       "      <th>t_diss_peak</th>\n",
       "      <th>width</th>\n",
       "      <th>ips</th>\n",
       "      <th>perm_p</th>\n",
       "      <th>status</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251102-121234Z_live_champion_rep1</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374696</td>\n",
       "      <td>0.138103</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251102-121239Z_live_champion_rep2</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374696</td>\n",
       "      <td>0.119800</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251102-121244Z_live_champion_rep3</td>\n",
       "      <td>gpt-4o-mini</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.374696</td>\n",
       "      <td>0.121464</td>\n",
       "      <td>NO_EVENT</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id        model  t_cons_knee  t_diss_peak  \\\n",
       "0  20251102-121234Z_live_champion_rep1  gpt-4o-mini         1.26         0.78   \n",
       "1  20251102-121239Z_live_champion_rep2  gpt-4o-mini         1.26         0.78   \n",
       "2  20251102-121244Z_live_champion_rep3  gpt-4o-mini         1.26         0.78   \n",
       "\n",
       "   width       ips    perm_p    status  \\\n",
       "0    0.0  0.374696  0.138103  NO_EVENT   \n",
       "1    0.0  0.374696  0.119800  NO_EVENT   \n",
       "2    0.0  0.374696  0.121464  NO_EVENT   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run_id\tmodel\tt_cons_knee\tt_diss_peak\twidth\tips\tstatus\toutdir\n",
      "20251102-121234Z_live_champion_rep1\tgpt-4o-mini\t1.26\t0.78\t0.000\t0.375\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121234Z_live_champion_rep1\n",
      "20251102-121239Z_live_champion_rep2\tgpt-4o-mini\t1.26\t0.78\t0.000\t0.375\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121239Z_live_champion_rep2\n",
      "20251102-121244Z_live_champion_rep3\tgpt-4o-mini\t1.26\t0.78\t0.000\t0.375\tNO_EVENT\tE:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251102-121244Z_live_champion_rep3\n"
     ]
    }
   ],
   "source": [
    "# CNT Weirdness Probe v1.5 — Restart‑Safe Mega Cell (kernel‑restart friendly)\n",
    "# ---------------------------------------------------------------------------\n",
    "# What this cell does\n",
    "#   • Re‑boots the probe environment and directory structure\n",
    "#   • Wraps the LLM call (OpenAI Chat Completions if available; SIMULATION fallback otherwise)\n",
    "#   • Runs a temperature sweep with multiple reps per temp\n",
    "#   • Computes consistency (pairwise trigram Jaccard ↑) and dissociation (pairwise 1‑gram cosine distance ↑)\n",
    "#   • Smooths curves (optional), detects knee/peak, width, IPS area, and a permutation p‑value\n",
    "#   • Auto‑extends the sweep if no separation is found\n",
    "#   • Saves CSV/JSON + a curves.png into E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\<timestamp>_live_champion_repX\n",
    "#   • Provides run_champion_repeats(n) for quick multi‑rep sessions\n",
    "#\n",
    "# Usage (defaults mirror your last run):\n",
    "#   1) Just run this cell. It will automatically run run_champion_repeats(n=3).\n",
    "#   2) To tweak: set env vars before (or edit CONFIG block below):\n",
    "#        CNT_WP_MODEL, CNT_WP_TEMPS, CNT_WP_REPS, CNT_WP_PERM, CNT_WP_AUTOEXTEND, CNT_WP_SMOOTH, CNT_LAB_DIR\n",
    "#   3) After it finishes, re‑run: stability_df = run_champion_repeats(n=3)\n",
    "#\n",
    "# Notes\n",
    "#   • If the OpenAI client isn’t configured, the probe switches to SIMULATION mode (prints \"LLM : SIMULATION\").\n",
    "#   • Smoothing options: \"none\" (default), \"gauss:3\", \"median:5\".\n",
    "#   • Temperature bounds respected: [0.5, 2.0], auto‑extend pushes both sides by ±0.2 per round.\n",
    "\n",
    "import os, sys, re, json, time, math, random, hashlib, textwrap, subprocess\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------- Optional auto‑install -----------------------------\n",
    "AUTO_INSTALL = False  # set True if you want the cell to try pip‑installing missing libs\n",
    "\n",
    "def _install_if_missing(pkgs):\n",
    "    if not AUTO_INSTALL:\n",
    "        return\n",
    "    for p in pkgs:\n",
    "        try:\n",
    "            __import__(p)\n",
    "        except Exception:\n",
    "            try:\n",
    "                print(f\"[pip] installing {p}…\")\n",
    "                subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", p])\n",
    "            except Exception as e:\n",
    "                print(f\"[pip] failed to install {p}: {e}\")\n",
    "\n",
    "_install_if_missing([\"openai\"])  # only if AUTO_INSTALL=True\n",
    "\n",
    "# ------------------------------- LLM wrapper ------------------------------------\n",
    "_HAS_NEW_OPENAI = False\n",
    "_HAS_OLD_OPENAI = False\n",
    "client_new = None\n",
    "\n",
    "try:\n",
    "    from openai import OpenAI  # new SDK\n",
    "    try:\n",
    "        client_new = OpenAI()\n",
    "        _HAS_NEW_OPENAI = True\n",
    "    except Exception:\n",
    "        client_new = None\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "if not _HAS_NEW_OPENAI:\n",
    "    try:\n",
    "        import openai  # legacy SDK\n",
    "        _HAS_OLD_OPENAI = True\n",
    "    except Exception:\n",
    "        _HAS_OLD_OPENAI = False\n",
    "\n",
    "\n",
    "def _now_stamp():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "\n",
    "def _ensure_dir(p: Path):\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "# ------------------------------ Env bootstrap -----------------------------------\n",
    "\n",
    "def set_probe_env(model: str,\n",
    "                  temps: str,\n",
    "                  reps: int = 16,\n",
    "                  perm: int = 600,\n",
    "                  autoextend: bool = True,\n",
    "                  smooth: str = \"none\",\n",
    "                  root: str = r\"E:\\\\CNT\",\n",
    "                  label: str | None = None,\n",
    "                  rep_idx: int | None = None):\n",
    "    os.environ.setdefault(\"CNT_LAB_DIR\", root)\n",
    "    os.environ.setdefault(\"PYTHONPATH\", root)\n",
    "    out_root = Path(root) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    _ensure_dir(out_root)\n",
    "    ts = _now_stamp()\n",
    "    suffix = f\"_{label}_rep{rep_idx}\" if (label and rep_idx is not None) else \"\"\n",
    "    run_id = f\"{ts}{suffix}\"\n",
    "    outdir = out_root / run_id\n",
    "    _ensure_dir(outdir)\n",
    "    print(f\"\\u2713 Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "    return dict(root=root, outdir=str(outdir), run_id=run_id, model=model, reps=reps, perm=perm,\n",
    "                autoextend=autoextend, smooth=smooth)\n",
    "\n",
    "\n",
    "def parse_temps_str(s: str):\n",
    "    vals = sorted({round(float(x), 3) for x in re.split(r\"[\\,\\s]+\", s.strip()) if x})\n",
    "    # keep within reasonable bounds\n",
    "    vals = [v for v in vals if 0.5 <= v <= 2.0]\n",
    "    if not vals:\n",
    "        vals = [0.7, 0.9, 1.1, 1.3, 1.5, 1.7, 1.9]\n",
    "    return vals\n",
    "\n",
    "\n",
    "# -------------------------------- SIM fallback ----------------------------------\n",
    "SIM_VOCAB = (\n",
    "    \"field drift glyph ring echo anchor pulse axis veil resonance spiral lattice gauge weave \"\n",
    "    \"mirror seed phase oracle fold flame vector shadow quantum cybernetic topology entropy memory \"\n",
    "    \"cascade gradient basin suture harmonic torsion flux curvature chandelier singularity nexus\"\n",
    ").split()\n",
    "\n",
    "# Session seed for reproducible-but-variable SIM mode\n",
    "try:\n",
    "    SESSION_SEED = int.from_bytes(os.urandom(8), 'little') ^ os.getpid() ^ int(time.time()*1e6)\n",
    "except Exception:\n",
    "    SESSION_SEED = 123456789\n",
    "\n",
    "def sim_text(prompt: str, temperature: float, session_seed: int, rep: int | None = None) -> str:\n",
    "    \"\"\"Simulation text generator with per-rep variability and temperature-tuned novelty.\n",
    "    Guarantees diversity across reps at the same temperature and increasing novelty with T.\n",
    "    \"\"\"\n",
    "    h = hashlib.blake2b(digest_size=8)\n",
    "    h.update(str(session_seed).encode()); h.update(str(round(float(temperature), 3)).encode())\n",
    "    if rep is not None:\n",
    "        h.update(str(int(rep)).encode())\n",
    "    seed_int = int.from_bytes(h.digest(), 'little') & 0xFFFFFFFF\n",
    "    rng = np.random.default_rng(seed_int)\n",
    "\n",
    "    target_len = int(140 + 160 * min(float(temperature), 2.0))\n",
    "    o = []\n",
    "    prev = rng.choice(SIM_VOCAB)\n",
    "    # Novelty increases smoothly with temperature (0.5 -> ~0.05, 2.0 -> ~0.50)\n",
    "    novelty = float(np.clip(0.05 + 0.45 * (float(temperature) - 0.5) / 1.5, 0.05, 0.50))\n",
    "    for _ in range(target_len):\n",
    "        if rng.random() < novelty:\n",
    "            token = rng.choice(SIM_VOCAB)\n",
    "        else:\n",
    "            token = _mutate_token(prev, rng, float(temperature))\n",
    "        o.append(token); prev = token\n",
    "    s = \" \".join(o)\n",
    "    return s[:1500]\n",
    "\n",
    "def _mutate_token(token: str, rng: np.random.Generator, temperature: float) -> str:\n",
    "    p_shuffle = float(np.clip(0.2 + 0.5 * max(0.0, (temperature - 1.0)) / 1.0, 0.2, 0.7))\n",
    "    p_punct  = float(np.clip(0.1 + 0.2 * max(0.0, (temperature - 1.0)) / 1.0, 0.1, 0.3))\n",
    "    r = rng.random()\n",
    "    if r < p_shuffle:\n",
    "        chars = list(token); rng.shuffle(chars); return ''.join(chars)\n",
    "    if r < p_shuffle + p_punct:\n",
    "        return token + rng.choice(['', '', '.', '-', ''])\n",
    "    return token\n",
    "\n",
    "class LLM:\n",
    "    def __init__(self, model: str, seed: int | None = None):\n",
    "        self.model = model\n",
    "        self.seed = seed\n",
    "        self.session_seed = SESSION_SEED\n",
    "        self.mode = \"SIMULATION\"\n",
    "        self.client_new = client_new if _HAS_NEW_OPENAI else None\n",
    "        self.has_old = _HAS_OLD_OPENAI\n",
    "        if self.client_new is not None:\n",
    "            self.mode = \"OPENAI\"\n",
    "        elif self.has_old:\n",
    "            self.mode = \"OPENAI_LEGACY\"\n",
    "        random.seed(seed)\n",
    "\n",
    "    def sample(self, prompt: str, temperature: float = 1.0, max_tokens: int = 256, top_p: float = 1.0, rep: int | None = None) -> str:\n",
    "        # New SDK\n",
    "        if self.mode == \"OPENAI\" and self.client_new is not None:\n",
    "            try:\n",
    "                resp = self.client_new.chat.completions.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=float(temperature), top_p=float(top_p), max_tokens=int(max_tokens),\n",
    "                    presence_penalty=0, frequency_penalty=0,\n",
    "                )\n",
    "                return (resp.choices[0].message.content or \"\").strip()\n",
    "            except Exception as e:\n",
    "                print(f\"[openai/new] error: {e} -> falling back to SIMULATION\")\n",
    "                self.mode = \"SIMULATION\"\n",
    "        # Legacy SDK\n",
    "        if self.mode == \"OPENAI_LEGACY\" and self.has_old:\n",
    "            try:\n",
    "                resp = openai.ChatCompletion.create(\n",
    "                    model=self.model,\n",
    "                    messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                    temperature=float(temperature), top_p=float(top_p), max_tokens=int(max_tokens),\n",
    "                    presence_penalty=0, frequency_penalty=0,\n",
    "                )\n",
    "                return (resp.choices[0].message[\"content\"] or \"\").strip()\n",
    "            except Exception as e:\n",
    "                print(f\"[openai/legacy] error: {e} -> falling back to SIMULATION\")\n",
    "                self.mode = \"SIMULATION\"\n",
    "        # Simulation fallback\n",
    "        return sim_text(prompt, temperature, session_seed=self.session_seed, rep=rep)\n",
    "\n",
    "\n",
    "# --------------------------------- Metrics --------------------------------------\n",
    "\n",
    "def _words(s: str):\n",
    "    return re.findall(r\"[A-Za-z]+\", (s or \"\").lower())\n",
    "\n",
    "\n",
    "def _ngrams(tokens, n=3):\n",
    "    return [\" \".join(tokens[i:i+n]) for i in range(len(tokens) - n + 1)] if len(tokens) >= n else []\n",
    "\n",
    "\n",
    "def _jaccard(a, b):\n",
    "    A, B = set(a), set(b)\n",
    "    if not A and not B:\n",
    "        return 1.0\n",
    "    if not A or not B:\n",
    "        return 0.0\n",
    "    return len(A & B) / len(A | B)\n",
    "\n",
    "\n",
    "def _pairwise_mean_jaccard(list_of_iters):\n",
    "    sims = []\n",
    "    for i in range(len(list_of_iters)):\n",
    "        for j in range(i + 1, len(list_of_iters)):\n",
    "            sims.append(_jaccard(list_of_iters[i], list_of_iters[j]))\n",
    "    return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "\n",
    "def _cosine_distance_counts(a_tokens, b_tokens):\n",
    "    from collections import Counter\n",
    "    A = Counter(a_tokens); B = Counter(b_tokens)\n",
    "    keys = set(A) | set(B)\n",
    "    if not keys:\n",
    "        return 0.0\n",
    "    a = np.array([A[k] for k in keys], dtype=float)\n",
    "    b = np.array([B[k] for k in keys], dtype=float)\n",
    "    denom = (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "    if denom == 0:\n",
    "        return 0.0\n",
    "    sim = float(np.dot(a, b) / denom)\n",
    "    return 1.0 - sim\n",
    "\n",
    "\n",
    "def measure_at_temp(samples: list[str]):\n",
    "    tri_sets = [_ngrams(_words(x), 3) for x in samples]\n",
    "    consistency = _pairwise_mean_jaccard(tri_sets)  # higher = more similar (coherence)\n",
    "    toks = [_words(x) for x in samples]\n",
    "    dists = []\n",
    "    for i in range(len(toks)):\n",
    "        for j in range(i + 1, len(toks)):\n",
    "            dists.append(_cosine_distance_counts(toks[i], toks[j]))\n",
    "    dissociation = float(np.mean(dists)) if dists else 0.0  # higher = more divergent\n",
    "    return consistency, dissociation\n",
    "\n",
    "\n",
    "# ------------------------------ Smoothing & Detect ------------------------------\n",
    "\n",
    "def smooth_curve(y, mode=\"none\"):\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    if mode == \"none\" or len(y) < 5:\n",
    "        return y\n",
    "    if mode.startswith(\"gauss\"):\n",
    "        try:\n",
    "            k = int(mode.split(\":\")[1])\n",
    "        except Exception:\n",
    "            k = 3\n",
    "        k = max(1, k)\n",
    "        r = k\n",
    "        x = np.arange(-r, r + 1)\n",
    "        sigma = k / 2.0\n",
    "        g = np.exp(-(x ** 2) / (2 * sigma ** 2))\n",
    "        g = g / np.sum(g)\n",
    "        return np.convolve(y, g, mode=\"same\")\n",
    "    if mode.startswith(\"median\"):\n",
    "        try:\n",
    "            w = int(mode.split(\":\")[1])\n",
    "        except Exception:\n",
    "            w = 5\n",
    "        w = max(3, w | 1)\n",
    "        pad = w // 2\n",
    "        z = np.pad(y, (pad, pad), mode=\"edge\")\n",
    "        out = [float(np.median(z[i:i + w])) for i in range(len(y))]\n",
    "        return np.array(out)\n",
    "    return y\n",
    "\n",
    "\n",
    "def kneedle_idx(x, y, direction=\"decreasing\"):\n",
    "    x = np.asarray(x, dtype=float)\n",
    "    y = np.asarray(y, dtype=float)\n",
    "    n = len(x)\n",
    "    if n < 3:\n",
    "        return 0, False\n",
    "    # Primary: max distance from chord\n",
    "    x0, x1 = x[0], x[-1]\n",
    "    y0, y1 = y[0], y[-1]\n",
    "    denom = math.hypot(x1 - x0, y1 - y0) + 1e-12\n",
    "    d = []\n",
    "    for xi, yi in zip(x, y):\n",
    "        num = abs((y1 - y0) * xi - (x1 - x0) * yi + x1 * y0 - y1 * x0)\n",
    "        d.append(num / denom)\n",
    "    idx = int(np.argmax(d))\n",
    "    valid = (idx > 0 and idx < n - 1)\n",
    "    if valid:\n",
    "        return idx, True\n",
    "    # Fallback: interior gradient extremum\n",
    "    g = np.gradient(y, x)\n",
    "    if n >= 3:\n",
    "        if direction == \"decreasing\":\n",
    "            cand = int(np.argmin(g[1:-1]) + 1)\n",
    "        else:\n",
    "            cand = int(np.argmax(g[1:-1]) + 1)\n",
    "        return cand, True\n",
    "    return 0, False\n",
    "\n",
    "def peak_idx(y):\n",
    "    if len(y) < 3:\n",
    "        return 0, False\n",
    "    idx = int(np.argmax(y))\n",
    "    valid = (idx > 0 and idx < len(y) - 1)\n",
    "    return idx, valid\n",
    "\n",
    "\n",
    "def _z(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    mu = a.mean(); sd = a.std()\n",
    "    return (a - mu) / (sd + 1e-12)\n",
    "\n",
    "\n",
    "def ips_area(temps, cons, diss):\n",
    "    d = np.maximum(_z(diss) - _z(cons), 0.0)\n",
    "    return float(np.trapezoid(d, x=np.asarray(temps, dtype=float)))\n",
    "\n",
    "\n",
    "def ips_perm_p(temps, cons, diss, perm=600, rng=None):\n",
    "    rng = rng or np.random.default_rng()\n",
    "    obs = ips_area(temps, cons, diss)\n",
    "    if obs <= 0:\n",
    "        return 1.0, obs\n",
    "    d = _z(diss) - _z(cons)\n",
    "    x = np.asarray(temps, dtype=float)\n",
    "    count = 0\n",
    "    for _ in range(int(perm)):\n",
    "        signs = rng.choice([-1.0, 1.0], size=len(d))\n",
    "        null = np.maximum(signs * d, 0.0)\n",
    "        val = float(np.trapezoid(null, x=x))\n",
    "        if val >= obs - 1e-12:\n",
    "            count += 1\n",
    "    p = (count + 1) / (perm + 1)\n",
    "    return float(p), float(obs)\n",
    "\n",
    "\n",
    "# --------------------------------- Runner ---------------------------------------\n",
    "\n",
    "def run_probe(model, temps_list, reps=16, smooth=\"none\", perm=600, seed=None, outdir=None, verbose=True, llm=None):\n",
    "    llm = llm or LLM(model, seed=seed)\n",
    "    if verbose:\n",
    "        print(f\"LLM : {llm.mode}\")\n",
    "        print(f\"Temps: {temps_list} | Reps: {reps} | Smooth(viz)={smooth}\")\n",
    "    all_samples: dict[float, list[str]] = {}\n",
    "    base_prompt = (\n",
    "        \"Write a compact, richly textured paragraph (120–180 words) about a storm seen from a lighthouse. \"\n",
    "        \"Avoid lists. Use precise nouns. End with a single striking image.\"\n",
    "    )\n",
    "    for t in temps_list:\n",
    "        bucket = []\n",
    "        for r in range(reps):\n",
    "            txt = llm.sample(base_prompt, temperature=float(t), max_tokens=256, top_p=1.0, rep=r)\n",
    "            bucket.append(txt)\n",
    "        all_samples[float(t)] = bucket\n",
    "        if verbose:\n",
    "            lengths = [len(x) for x in bucket]\n",
    "            print(f\"[{t:.2f}] len(avg)={np.mean(lengths):.1f} n={len(bucket)}\")\n",
    "\n",
    "    temps_sorted = sorted(all_samples.keys())\n",
    "    cons, diss = [], []\n",
    "    for t in temps_sorted:\n",
    "        c, d = measure_at_temp(all_samples[t])\n",
    "        cons.append(c); diss.append(d)\n",
    "\n",
    "    cons_s = smooth_curve(cons, smooth)\n",
    "    diss_s = smooth_curve(diss, smooth)\n",
    "\n",
    "    k_idx, has_knee = kneedle_idx(temps_sorted, cons_s, direction=\"decreasing\")\n",
    "    p_idx, has_peak = peak_idx(diss_s)\n",
    "    t_cons_knee = float(temps_sorted[k_idx])\n",
    "    t_diss_peak = float(temps_sorted[p_idx])\n",
    "\n",
    "    status = \"NO_EVENT\"; width = 0.0\n",
    "    if has_knee and has_peak and p_idx > k_idx:\n",
    "        status = \"SEPARATED\"; width = float(t_diss_peak - t_cons_knee)\n",
    "    elif has_knee and has_peak and p_idx <= k_idx:\n",
    "        status = \"REVERSED\"; width = 0.0\n",
    "\n",
    "    pval, ips = ips_perm_p(temps_sorted, cons_s, diss_s, perm=perm)\n",
    "\n",
    "    summary = dict(\n",
    "        model=model,\n",
    "        temps=temps_sorted,\n",
    "        consistency=[float(x) for x in cons_s],\n",
    "        dissociation=[float(x) for x in diss_s],\n",
    "        knee_idx=int(k_idx), peak_idx=int(p_idx),\n",
    "        t_cons_knee=float(t_cons_knee), t_diss_peak=float(t_diss_peak),\n",
    "        width=float(width), status=status, ips=float(ips), perm_p=float(pval),\n",
    "    )\n",
    "\n",
    "    if outdir:\n",
    "        p = Path(outdir)\n",
    "        _ensure_dir(p)\n",
    "        pd.DataFrame({\"temp\": temps_sorted, \"consistency\": cons_s, \"dissociation\": diss_s}).to_csv(p / \"curves.csv\", index=False)\n",
    "        with open(p / \"summary.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(summary, f, indent=2)\n",
    "        try:\n",
    "            import matplotlib.pyplot as plt\n",
    "            plt.figure()\n",
    "            plt.plot(temps_sorted, cons_s, marker=\"o\", label=\"consistency\")\n",
    "            plt.plot(temps_sorted, diss_s, marker=\"s\", label=\"dissociation\")\n",
    "            plt.axvline(t_cons_knee, linestyle=\"--\")\n",
    "            plt.axvline(t_diss_peak, linestyle=\"--\")\n",
    "            plt.title(f\"Weirdness Probe v1.5 — {model}\")\n",
    "            plt.xlabel(\"temperature\"); plt.ylabel(\"score\")\n",
    "            plt.legend(); plt.tight_layout(); plt.savefig(p / \"curves.png\", dpi=160); plt.close()\n",
    "        except Exception as e:\n",
    "            print(\"Plot skipped:\", e)\n",
    "\n",
    "    return summary\n",
    "\n",
    "\n",
    "def autoextend_sweep(temps, status, width, rounds=2):\n",
    "    if status == \"SEPARATED\" and width > 0:\n",
    "        return sorted(temps)\n",
    "    tset = set(temps)\n",
    "    lo, hi = min(temps), max(temps)\n",
    "    for _ in range(int(rounds)):\n",
    "        lo = max(0.5, round(lo - 0.2, 2))\n",
    "        hi = min(2.0, round(hi + 0.2, 2))\n",
    "        tset.update([lo, hi])\n",
    "    return sorted(tset)\n",
    "\n",
    "\n",
    "# --------------------------- Session helpers / repeats ---------------------------\n",
    "\n",
    "def _config_from_env():\n",
    "    return dict(\n",
    "        model=os.environ.get(\"CNT_WP_MODEL\", \"gpt-4o-mini\"),\n",
    "        temps_str=os.environ.get(\"CNT_WP_TEMPS\", \"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\"),\n",
    "        reps=int(os.environ.get(\"CNT_WP_REPS\", \"16\")),\n",
    "        perm=int(os.environ.get(\"CNT_WP_PERM\", \"600\")),\n",
    "        autoextend=os.environ.get(\"CNT_WP_AUTOEXTEND\", \"true\").lower() in {\"1\", \"true\", \"yes\", \"y\"},\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\", \"none\"),\n",
    "        root=os.environ.get(\"CNT_LAB_DIR\", r\"E:\\\\CNT\"),\n",
    "    )\n",
    "\n",
    "\n",
    "def run_once(label=None, rep_idx=None, **kwargs):\n",
    "    model = kwargs.get(\"model\"); temps_str = kwargs.get(\"temps_str\"); reps = kwargs.get(\"reps\")\n",
    "    perm = kwargs.get(\"perm\"); autoextend = kwargs.get(\"autoextend\"); smooth = kwargs.get(\"smooth\"); root = kwargs.get(\"root\")\n",
    "    temps_list = parse_temps_str(temps_str)\n",
    "    env = set_probe_env(model=model, temps=temps_str, reps=reps, perm=perm, autoextend=autoextend, smooth=smooth,\n",
    "                        root=root, label=label, rep_idx=rep_idx)\n",
    "    outdir = env[\"outdir\"]\n",
    "    print(f\"\\u2699\\ufe0f Running v1.5 (v1.4 merged) | model={model} | out={outdir}\")\n",
    "\n",
    "    s1 = run_probe(model, temps_list, reps=reps, smooth=smooth, perm=perm, seed=None, outdir=outdir)\n",
    "    print(f\"WIDTH={s1['width']:.3f} | IPS={s1['ips']:.3f} | status={s1['status']} | p={s1['perm_p']:.4f}\")\n",
    "\n",
    "    if autoextend and s1[\"status\"] != \"SEPARATED\":\n",
    "        temps2 = autoextend_sweep(temps_list, s1[\"status\"], s1[\"width\"], rounds=2)\n",
    "        if temps2 != sorted(temps_list):\n",
    "            print(\"\\u21bb Autoextend sweep ->\", temps2)\n",
    "            s2 = run_probe(model, temps2, reps=reps, smooth=smooth, perm=perm, seed=None, outdir=outdir)\n",
    "            print(f\"WIDTH={s2['width']:.3f} | IPS={s2['ips']:.3f} | status={s2['status']} | p={s2['perm_p']:.4f}\")\n",
    "            return s2, outdir\n",
    "    return s1, outdir\n",
    "\n",
    "\n",
    "def _ci95(a):\n",
    "    a = np.asarray(a, dtype=float)\n",
    "    if len(a) == 0:\n",
    "        return (float(\"nan\"), float(\"nan\"), float(\"nan\"))\n",
    "    m = float(np.mean(a)); s = float(np.std(a, ddof=1)) if len(a) > 1 else 0.0\n",
    "    lo = m - 1.96 * s / max(1, math.sqrt(len(a)))\n",
    "    hi = m + 1.96 * s / max(1, math.sqrt(len(a)))\n",
    "    return m, lo, hi\n",
    "\n",
    "\n",
    "def run_champion_repeats(n=3):\n",
    "    cfg = _config_from_env()\n",
    "    rows = []\n",
    "    for i in range(1, int(n) + 1):\n",
    "        s, outdir = run_once(label=\"live_champion\", rep_idx=i, **cfg)\n",
    "        rows.append({\n",
    "            \"run_id\": Path(outdir).name,\n",
    "            \"model\": cfg[\"model\"],\n",
    "            \"t_cons_knee\": s.get(\"t_cons_knee\", np.nan),\n",
    "            \"t_diss_peak\": s.get(\"t_diss_peak\", np.nan),\n",
    "            \"width\": s.get(\"width\", np.nan),\n",
    "            \"ips\": s.get(\"ips\", np.nan),\n",
    "            \"perm_p\": s.get(\"perm_p\", np.nan),\n",
    "            \"status\": s.get(\"status\", \"\"),\n",
    "            \"outdir\": outdir,\n",
    "        })\n",
    "    df = pd.DataFrame(rows)\n",
    "    w_m, w_lo, w_hi = _ci95(df[\"width\"].values)\n",
    "    ips_m, ips_lo, ips_hi = _ci95(df[\"ips\"].values)\n",
    "    print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f} 95%CI[{ips_lo:.3f},{ips_hi:.3f}]\")\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df)\n",
    "    except Exception:\n",
    "        print(df)\n",
    "    return df\n",
    "\n",
    "\n",
    "# --------------------------------- Auto‑run -------------------------------------\n",
    "AUTO_RUN = True\n",
    "REPEATS = int(os.environ.get(\"CNT_WP_REPEATS\", \"3\"))\n",
    "\n",
    "if AUTO_RUN:\n",
    "    stability_df = run_champion_repeats(n=REPEATS)\n",
    "    # Echo summary in one row form (similar to your tabular print)\n",
    "    try:\n",
    "        print(\"run_id\\tmodel\\tt_cons_knee\\tt_diss_peak\\twidth\\tips\\tstatus\\toutdir\")\n",
    "        for _, r in stability_df.iterrows():\n",
    "            print(f\"{r['run_id']}\\t{r['model']}\\t{r['t_cons_knee']:.2f}\\t{r['t_diss_peak']:.2f}\\t{r['width']:.3f}\\t{r['ips']:.3f}\\t{r['status']}\\t{r['outdir']}\")\n",
    "    except Exception:\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "245b2498-9e3a-4ee9-8cbf-ec8e4b439410",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'run_live_repeat_safe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_PRESENCE_P\u001b[39m\u001b[33m\"\u001b[39m]  = \u001b[33m\"\u001b[39m\u001b[33m0.00\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_MAX_TOKENS\u001b[39m\u001b[33m\"\u001b[39m]  = \u001b[33m\"\u001b[39m\u001b[33m128\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m rd1 = \u001b[43mrun_live_repeat_safe\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      9\u001b[39m rd2 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m rd3 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep3\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'run_live_repeat_safe' is not defined"
     ]
    }
   ],
   "source": [
    "# House knobs (champion)\n",
    "import os\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"   # cold invariance (IPS)\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "rd1 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep1\")\n",
    "rd2 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep2\")\n",
    "rd3 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep3\")\n",
    "\n",
    "# Summarize width/IPS from the three LIVE runs\n",
    "import pandas as pd, numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "def crest_metrics(run_dir):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    consg = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(consg)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    ips, asi = np.nan, np.nan\n",
    "    inv = rd/\"summary_gra_invariance.csv\"\n",
    "    sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    if inv.exists(): ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean())\n",
    "    if sep.exists(): asi = float(pd.read_csv(sep)[\"separation_index\"].mean())\n",
    "    return dict(run_id=m[\"run_id\"], width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "df = pd.DataFrame([crest_metrics(rd1), crest_metrics(rd2), crest_metrics(rd3)])\n",
    "def ci(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    m, sd = s.mean(), (s.std(ddof=1) if len(s)>1 else 0.0)\n",
    "    lo = m - 1.96*sd/np.sqrt(max(1,len(s))); hi = m + 1.96*sd/np.sqrt(max(1,len(s)))\n",
    "    return m, lo, hi\n",
    "\n",
    "w_m, w_lo, w_hi = ci(df[\"width\"])\n",
    "ips_m, _, _     = ci(df[\"ips\"])\n",
    "print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f}\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "2622844f-6622-4015-957b-239030ef1963",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ force-LIVE gate armed: set CNT_FORCE_LIVE=1 to bypass SIM path.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "401 {\n    \"error\": {\n        \"message\": \"Incorrect API key provided: \\u003cYOUR_KEY\\u003e. You can find your API key at https://platform.openai.com/account/api-keys.\",\n        \"type\": \"invalid_request_err (0.7s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 120\u001b[39m\n\u001b[32m    117\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_MAX_TOKENS\u001b[39m\u001b[33m\"\u001b[39m]  = \u001b[33m\"\u001b[39m\u001b[33m128\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;66;03m# ---------- RUN 3x LIVE repeats ----------\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m rd1 = \u001b[43mrun_live_repeat_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_champion_rep1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    121\u001b[39m rd2 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    122\u001b[39m rd3 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep3\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 101\u001b[39m, in \u001b[36mrun_live_repeat_safe\u001b[39m\u001b[34m(model_id, alias)\u001b[39m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_live_repeat_safe\u001b[39m(model_id=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, alias=\u001b[33m\"\u001b[39m\u001b[33mlive_repeat\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m    100\u001b[39m     \u001b[38;5;66;03m# 0) PING\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     out = \u001b[43m_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mReturn exactly: PONG\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m4\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m out.strip() != \u001b[33m\"\u001b[39m\u001b[33mPONG\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    104\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mPING failed; check OPENAI_API_KEY / network.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36m_chat_completion\u001b[39m\u001b[34m(model, messages, temperature, max_tokens, seed, base_url, api_key)\u001b[39m\n\u001b[32m     57\u001b[39m     data = r.json()\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (data.get(\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m,[{}])[\u001b[32m0\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m,{}).get(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.text[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()-t0\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: 401 {\n    \"error\": {\n        \"message\": \"Incorrect API key provided: \\u003cYOUR_KEY\\u003e. You can find your API key at https://platform.openai.com/account/api-keys.\",\n        \"type\": \"invalid_request_err (0.7s)"
     ]
    }
   ],
   "source": [
    "# === LIVE stability repeats — self-contained, with force-LIVE & safety checks ===\n",
    "import os, json, time, requests, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ---------- tiny utils ----------\n",
    "def utc_stamp(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def get_probe_base():\n",
    "    base = os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\"\n",
    "    p = Path(base) / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    p.mkdir(parents=True, exist_ok=True); return p\n",
    "def ensure_dir(p): p = Path(p); p.mkdir(parents=True, exist_ok=True); return p\n",
    "\n",
    "# ---------- REQUIRED: v1.5 engine present ----------\n",
    "if \"run_model\" not in globals():\n",
    "    raise RuntimeError(\"v1.5 engine not loaded in this kernel. Re-run your unified v1.5 mega-cell, then re-run this cell.\")\n",
    "\n",
    "# ---------- minimal env mixer and alias runner ----------\n",
    "def set_probe_env(model=\"gpt-4o-mini\", temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "                  reps=16, perm=600, autoextend=True, smooth=\"none\", api_key=None, base_url=None):\n",
    "    os.environ[\"CNT_WP_TEMPS\"]      = temps\n",
    "    os.environ[\"CNT_WP_N_REPS\"]     = str(reps)\n",
    "    os.environ[\"CNT_WP_PERM\"]       = str(perm)\n",
    "    os.environ[\"CNT_WP_AUTOEXTEND\"] = \"1\" if autoextend else \"0\"\n",
    "    os.environ[\"CNT_WP_SMOOTH\"]     = smooth\n",
    "    os.environ[\"LLM_MODEL\"]         = model\n",
    "    if api_key is not None: os.environ[\"OPENAI_API_KEY\"]  = api_key\n",
    "    if base_url:            os.environ[\"OPENAI_BASE_URL\"] = base_url\n",
    "    print(f\"✓ Env set | model={model} temps={temps} reps={reps} perm={perm} autoextend={autoextend} smooth={smooth}\")\n",
    "\n",
    "def run_with_alias(model_id: str, alias: str, **kw):\n",
    "    outdir = ensure_dir(get_probe_base() / f\"{utc_stamp()}_{alias}\")\n",
    "    os.environ[\"CNT_WP_OUTDIR_HINT\"] = str(outdir)\n",
    "    rd = run_model(model_id, **kw)\n",
    "    os.environ.pop(\"CNT_WP_OUTDIR_HINT\", None)\n",
    "    return rd\n",
    "\n",
    "# ---------- clean, non-recursive LIVE client for PONG ----------\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_TIMEOUT\",\"15\")\n",
    "def _chat_completion(model, messages, *, temperature=0.0, max_tokens=8, seed=None,\n",
    "                     base_url=None, api_key=None):\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\",\"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "    payload = {\"model\": model, \"messages\": messages, \"temperature\": float(temperature),\n",
    "               \"top_p\": float(os.environ.get(\"CNT_WP_TOP_P\",\"1.0\")),\n",
    "               \"presence_penalty\": float(os.environ.get(\"CNT_WP_PRESENCE_P\",\"0.0\")),\n",
    "               \"frequency_penalty\": float(os.environ.get(\"CNT_WP_FREQ_P\",\"0.0\")),\n",
    "               \"max_tokens\": int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")) if max_tokens is None else int(max_tokens)}\n",
    "    if seed is not None:\n",
    "        try: payload[\"seed\"]=int(seed)\n",
    "        except: pass\n",
    "    t0 = time.time()\n",
    "    r = requests.post(url, json=payload, headers=headers, timeout=float(os.environ[\"CNT_WP_HTTP_TIMEOUT\"]))\n",
    "    if r.status_code == 200:\n",
    "        data = r.json()\n",
    "        return (data.get(\"choices\",[{}])[0].get(\"message\",{}).get(\"content\",\"\") or \"\").strip()\n",
    "    raise RuntimeError(f\"{r.status_code} {r.text[:200]} ({time.time()-t0:.1f}s)\")\n",
    "\n",
    "# ---------- assert manifest is LIVE ----------\n",
    "def assert_live_manifest(run_dir):\n",
    "    m = json.loads((Path(run_dir)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    print(\"llm_mode=\", m.get(\"llm_mode\"), \"| model=\", m.get(\"model\"))\n",
    "    if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"):\n",
    "        raise RuntimeError(\"Run executed in SIMULATION; refused. (Re-load v1.5 LIVE hook if needed.)\")\n",
    "\n",
    "# ---------- force-LIVE shim (idempotent) ----------\n",
    "if \"_run_v14_engine_orig_force\" not in globals():\n",
    "    _run_v14_engine_orig_force = _run_v14_engine\n",
    "def _run_v14_engine(target_outdir, cfg):\n",
    "    # Force LIVE unless model explicitly starts with SIMULATION\n",
    "    model_name = str(cfg[\"model\"])\n",
    "    if os.environ.get(\"CNT_FORCE_LIVE\",\"0\") == \"1\" and not model_name.upper().startswith(\"SIMULATION\"):\n",
    "        saved = cfg[\"model\"]; cfg = dict(cfg); cfg[\"model\"] = \"__LIVE_GATE__\"\n",
    "        try: return _run_v14_engine_orig_force(target_outdir, cfg)\n",
    "        finally: cfg[\"model\"] = saved\n",
    "    return _run_v14_engine_orig_force(target_outdir, cfg)\n",
    "print(\"✓ force-LIVE gate armed: set CNT_FORCE_LIVE=1 to bypass SIM path.\")\n",
    "\n",
    "# ---------- crest metrics ----------\n",
    "def crest_metrics(run_dir):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    gC    = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    inv = rd/\"summary_gra_invariance.csv\"\n",
    "    sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean()) if inv.exists() else np.nan\n",
    "    asi = float(pd.read_csv(sep)[\"separation_index\"].mean())  if sep.exists() else np.nan\n",
    "    return dict(run_id=m[\"run_id\"], width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "# ---------- safe LIVE repeat ----------\n",
    "def run_live_repeat_safe(model_id=\"gpt-4o-mini\", alias=\"live_repeat\"):\n",
    "    # 0) PING\n",
    "    out = _chat_completion(model_id, [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "                           temperature=0.0, max_tokens=4)\n",
    "    if out.strip() != \"PONG\":\n",
    "        raise RuntimeError(\"PING failed; check OPENAI_API_KEY / network.\")\n",
    "    # 1) force LIVE and run\n",
    "    os.environ[\"CNT_FORCE_LIVE\"] = \"1\"\n",
    "    set_probe_env(model=model_id)  # uses current ladder in env if you set one above\n",
    "    rd = run_with_alias(model_id, alias, autoextend=True, perm=int(os.environ.get(\"CNT_WP_PERM\",\"600\")))\n",
    "    # 2) verify LIVE\n",
    "    assert_live_manifest(rd)\n",
    "    return rd\n",
    "\n",
    "# ---------- house knobs for champion ----------\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"    # cold invariance\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "\n",
    "# ---------- RUN 3x LIVE repeats ----------\n",
    "rd1 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep1\")\n",
    "rd2 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep2\")\n",
    "rd3 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep3\")\n",
    "\n",
    "df = pd.DataFrame([crest_metrics(rd1), crest_metrics(rd2), crest_metrics(rd3)])\n",
    "def ci(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    m  = s.mean()\n",
    "    sd = s.std(ddof=1) if len(s)>1 else 0.0\n",
    "    lo = m - 1.96*sd/np.sqrt(max(1,len(s))); hi = m + 1.96*sd/np.sqrt(max(1,len(s)))\n",
    "    return m, lo, hi\n",
    "w_m, w_lo, w_hi = ci(df[\"width\"])\n",
    "ips_m, _, _     = ci(df[\"ips\"])\n",
    "print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f}\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "96f61692-93e1-42bc-9288-2a8f8c3f4399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Paste full OpenAI API key (starts with 'sk-'):  ········\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Key set (…XiQA), BASE=https://api.openai.com/v1\n"
     ]
    }
   ],
   "source": [
    "from getpass import getpass\n",
    "import os\n",
    "\n",
    "key = getpass(\"Paste full OpenAI API key (starts with 'sk-'): \").strip()\n",
    "assert key.startswith(\"sk-\") and \"PASTE\" not in key and \"*\" not in key and len(key) >= 40, \"That doesn't look like a full API key.\"\n",
    "os.environ[\"OPENAI_API_KEY\"]  = key\n",
    "os.environ[\"OPENAI_BASE_URL\"] = \"https://api.openai.com/v1\"  # default\n",
    "\n",
    "print(\"✓ Key set (…{}), BASE={}\".format(key[-4:], os.environ[\"OPENAI_BASE_URL\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db4c68de-660e-4b80-a597-2d270949cb93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING→ 'PONG'\n"
     ]
    }
   ],
   "source": [
    "pong = _chat_completion(\"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4)\n",
    "print(\"PING→\", repr(pong))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b6fcf23-5eac-47a7-bf5f-1756d9f4e3c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-042508Z_live_champion_rep1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "404 {\n    \"error\": {\n        \"message\": \"The model `__LIVE_GATE__` does not exist or you do not have access to it.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"model_ (1.6s)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[55]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_PRESENCE_P\u001b[39m\u001b[33m\"\u001b[39m]= \u001b[33m\"\u001b[39m\u001b[33m0.00\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      6\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_MAX_TOKENS\u001b[39m\u001b[33m\"\u001b[39m]= \u001b[33m\"\u001b[39m\u001b[33m128\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m rd1 = \u001b[43mrun_live_repeat_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_champion_rep1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m rd2 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m rd3 = run_live_repeat_safe(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mlive_champion_rep3\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36mrun_live_repeat_safe\u001b[39m\u001b[34m(model_id, alias)\u001b[39m\n\u001b[32m    106\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_FORCE_LIVE\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    107\u001b[39m set_probe_env(model=model_id)  \u001b[38;5;66;03m# uses current ladder in env if you set one above\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m rd = \u001b[43mrun_with_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNT_WP_PERM\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m600\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;66;03m# 2) verify LIVE\u001b[39;00m\n\u001b[32m    110\u001b[39m assert_live_manifest(rd)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_with_alias\u001b[39m\u001b[34m(model_id, alias, **kw)\u001b[39m\n\u001b[32m     32\u001b[39m outdir = ensure_dir(get_probe_base() / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutc_stamp()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(outdir)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m rd = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m os.environ.pop(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rd = \u001b[43m_run_model_prev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m         _fix_manifest_mode(rd)   \u001b[38;5;66;03m# from earlier patch\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_FORCE_LIVE\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_name.upper().startswith(\u001b[33m\"\u001b[39m\u001b[33mSIMULATION\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     75\u001b[39m     saved = cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]; cfg = \u001b[38;5;28mdict\u001b[39m(cfg); cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m__LIVE_GATE__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_orig_force\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m: cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = saved\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _run_v14_engine_orig_force(target_outdir, cfg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 210\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    207\u001b[39m base_url = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_BASE_URL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    209\u001b[39m \u001b[38;5;66;03m# Phase 1: probe curve from actual outputs (diversity rises with temperature)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m mean_cons, diss_curve = \u001b[43m_live_probe_curve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    212\u001b[39m \u001b[38;5;66;03m# Derivatives & knee estimates\u001b[39;00m\n\u001b[32m    213\u001b[39m grads_cons = _finite_diff(temps, mean_cons)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36m_live_probe_curve\u001b[39m\u001b[34m(model, temps, reps, base_url, api_key, seed0)\u001b[39m\n\u001b[32m    119\u001b[39m     prompt = PROMPTS_CORE[(ti + r) % \u001b[38;5;28mlen\u001b[39m(PROMPTS_CORE)]\n\u001b[32m    120\u001b[39m     msgs = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful, careful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    121\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}]\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     out = \u001b[43m_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     outs.append(out \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m diversity = _pairwise_diversity(outs)      \u001b[38;5;66;03m# rises with temperature\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 59\u001b[39m, in \u001b[36m_chat_completion\u001b[39m\u001b[34m(model, messages, temperature, max_tokens, seed, base_url, api_key)\u001b[39m\n\u001b[32m     57\u001b[39m     data = r.json()\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (data.get(\u001b[33m\"\u001b[39m\u001b[33mchoices\u001b[39m\u001b[33m\"\u001b[39m,[{}])[\u001b[32m0\u001b[39m].get(\u001b[33m\"\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m\"\u001b[39m,{}).get(\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m).strip()\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.status_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr.text[:\u001b[32m200\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtime.time()-t0\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.1f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms)\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mRuntimeError\u001b[39m: 404 {\n    \"error\": {\n        \"message\": \"The model `__LIVE_GATE__` does not exist or you do not have access to it.\",\n        \"type\": \"invalid_request_error\",\n        \"param\": null,\n        \"code\": \"model_ (1.6s)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"   # cold invariance\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "rd1 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep1\")\n",
    "rd2 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep2\")\n",
    "rd3 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep3\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8c44da6c-370d-4863-93d1-a288351fdb84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Sentinel bridge installed: __LIVE_GATE__ → LLM_MODEL at call time.\n"
     ]
    }
   ],
   "source": [
    "# === Sentinel bridge: map \"__LIVE_GATE__\" → real model id at call time ===\n",
    "import os\n",
    "\n",
    "SENT = \"__LIVE_GATE__\"\n",
    "\n",
    "# Bridge for the LIVE probe (consensus/dissent)\n",
    "if \"_lpc_orig\" not in globals():\n",
    "    _lpc_orig = _live_probe_curve\n",
    "\n",
    "def _live_probe_curve(model, *args, **kwargs):\n",
    "    # If the force-LIVE shim set a sentinel, swap to the real model id from env\n",
    "    if str(model) == SENT:\n",
    "        model = os.environ.get(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "    return _lpc_orig(model, *args, **kwargs)\n",
    "\n",
    "# Bridge for LIVE invariance/ASI (IPS/ASI recompute, refresher, etc.)\n",
    "if \"_lia_orig\" not in globals():\n",
    "    _lia_orig = _live_invariance_and_asi\n",
    "\n",
    "def _live_invariance_and_asi(model, *args, **kwargs):\n",
    "    if str(model) == SENT:\n",
    "        model = os.environ.get(\"LLM_MODEL\", \"gpt-4o-mini\")\n",
    "    return _lia_orig(model, *args, **kwargs)\n",
    "\n",
    "print(\"✓ Sentinel bridge installed: __LIVE_GATE__ → LLM_MODEL at call time.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b795c535-4d5f-4e99-ad3e-6ffe4ed7a5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING→ 'PONG'\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-042743Z_live_champion_rep1\n",
      "llm_mode= LIVE | model= __LIVE_GATE__\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043202Z_live_champion_rep2\n",
      "llm_mode= LIVE | model= __LIVE_GATE__\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043615Z_live_champion_rep3\n",
      "llm_mode= LIVE | model= __LIVE_GATE__\n",
      "WIDTH mean≈0.020 95%CI[-0.019,0.059] | IPS mean≈0.000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>width</th>\n",
       "      <th>ips</th>\n",
       "      <th>asi</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-042743Z_gpt-4o-mini</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-043202Z_gpt-4o-mini</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-043615Z_gpt-4o-mini</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_id  width  ips  asi  \\\n",
       "0  20251103-042743Z_gpt-4o-mini   0.06  0.0  0.0   \n",
       "1  20251103-043202Z_gpt-4o-mini   0.00  0.0  0.0   \n",
       "2  20251103-043615Z_gpt-4o-mini   0.00  0.0  0.0   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Sanity: PING\n",
    "pong = _chat_completion(\"gpt-4o-mini\",\n",
    "    [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],\n",
    "    temperature=0.0, max_tokens=4)\n",
    "print(\"PING→\", repr(pong))  # expect 'PONG'\n",
    "\n",
    "# Force LIVE and house knobs\n",
    "import os\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"   # cold invariance\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.00\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "rd1 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep1\")\n",
    "rd2 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep2\")\n",
    "rd3 = run_live_repeat_safe(\"gpt-4o-mini\", \"live_champion_rep3\")\n",
    "\n",
    "# Summarize\n",
    "import pandas as pd, numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "def crest_metrics(run_dir):\n",
    "    rd = Path(run_dir)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    gC    = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    t_cons_knee = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, t_diss_peak - t_cons_knee)\n",
    "    inv = rd/\"summary_gra_invariance.csv\"\n",
    "    sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean()) if inv.exists() else np.nan\n",
    "    asi = float(pd.read_csv(sep)[\"separation_index\"].mean())  if sep.exists() else np.nan\n",
    "    return dict(run_id=m[\"run_id\"], width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "df = pd.DataFrame([crest_metrics(rd1), crest_metrics(rd2), crest_metrics(rd3)])\n",
    "def ci(s):\n",
    "    s = pd.to_numeric(s, errors=\"coerce\").dropna()\n",
    "    m  = s.mean()\n",
    "    sd = s.std(ddof=1) if len(s)>1 else 0.0\n",
    "    lo = m - 1.96*sd/np.sqrt(max(1,len(s))); hi = m + 1.96*sd/np.sqrt(max(1,len(s)))\n",
    "    return m, lo, hi\n",
    "\n",
    "w_m, w_lo, w_hi = ci(df[\"width\"])\n",
    "ips_m, _, _     = ci(df[\"ips\"])\n",
    "print(f\"WIDTH mean≈{w_m:.3f} 95%CI[{w_lo:.3f},{w_hi:.3f}] | IPS mean≈{ips_m:.3f}\")\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "1c23114f-23e0-494b-972a-6ddf48fedbb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Repaired model id in 3 run(s).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name '_sysmsg' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 84\u001b[39m\n\u001b[32m     81\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m✓ Refreshed IPS/ASI for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(log)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m run(s) at t_ref=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00minv_temp\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     82\u001b[39m     display(pd.DataFrame(log))\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m \u001b[43mrefresh_ips_asi_for_runs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruns3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_temp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.20\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mrefresh_ips_asi_for_runs\u001b[39m\u001b[34m(run_dirs, inv_temp)\u001b[39m\n\u001b[32m     55\u001b[39m model = m.get(\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m, REAL_ID)\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# recompute invariance/ASI at cold t_ref\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m inv_syn     = \u001b[43m_inv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPROMPTS_INVARIANCE\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43msyn\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m     \u001b[49m\u001b[43minv_temp\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     58\u001b[39m inv_reorder = _inv(model, PROMPTS_INVARIANCE[\u001b[33m\"\u001b[39m\u001b[33mreorder\u001b[39m\u001b[33m\"\u001b[39m], inv_temp)\n\u001b[32m     59\u001b[39m inv_gauge   = _inv(model, PROMPTS_INVARIANCE[\u001b[33m\"\u001b[39m\u001b[33mgauge\u001b[39m\u001b[33m\"\u001b[39m],   inv_temp)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 44\u001b[39m, in \u001b[36mrefresh_ips_asi_for_runs.<locals>._inv\u001b[39m\u001b[34m(model, prompts, t_ref)\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inv\u001b[39m(model, prompts, t_ref):\n\u001b[32m---> \u001b[39m\u001b[32m44\u001b[39m     vs=[(_vec(_tok(s))) \u001b[38;5;28;01mfor\u001b[39;00m s \u001b[38;5;129;01min\u001b[39;00m \u001b[43m_ask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_ref\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m     45\u001b[39m     sims=[\u001b[32m0.6\u001b[39m*_cosine(vs[i][\u001b[32m0\u001b[39m],vs[j][\u001b[32m0\u001b[39m]) + \u001b[32m0.4\u001b[39m*_jaccard(vs[i][\u001b[32m1\u001b[39m],vs[j][\u001b[32m1\u001b[39m])\n\u001b[32m     46\u001b[39m           \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(vs)) \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(i+\u001b[32m1\u001b[39m,\u001b[38;5;28mlen\u001b[39m(vs))]\n\u001b[32m     47\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mfloat\u001b[39m(np.mean(sims)) \u001b[38;5;28;01mif\u001b[39;00m sims \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m0.0\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[58]\u001b[39m\u001b[32m, line 37\u001b[39m, in \u001b[36mrefresh_ips_asi_for_runs.<locals>._ask\u001b[39m\u001b[34m(model, prompts, t_ref)\u001b[39m\n\u001b[32m     35\u001b[39m outs=[]\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[32m---> \u001b[39m\u001b[32m37\u001b[39m     msgs=[\u001b[43m_sysmsg\u001b[49m(), {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mp\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}]\n\u001b[32m     38\u001b[39m     outs.append(_chat_completion(model, msgs, temperature=\u001b[38;5;28mfloat\u001b[39m(t_ref), max_tokens=\u001b[32m96\u001b[39m,\n\u001b[32m     39\u001b[39m                                  base_url=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_BASE_URL\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m     40\u001b[39m                                  api_key=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m outs\n",
      "\u001b[31mNameError\u001b[39m: name '_sysmsg' is not defined"
     ]
    }
   ],
   "source": [
    "# --- Repair the 'model' field on the latest 3 LIVE runs, then refresh IPS/ASI only for them ---\n",
    "import os, json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "REAL_ID = \"gpt-4o-mini\"\n",
    "\n",
    "def fix_model_field_for(run_dirs, real_id=REAL_ID):\n",
    "    fixed = 0\n",
    "    for rd in map(Path, run_dirs):\n",
    "        manf = rd/\"run_manifest.json\"\n",
    "        if not manf.exists(): continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if m.get(\"llm_mode\",\"\").upper() == \"LIVE\" and m.get(\"model\") == \"__LIVE_GATE__\":\n",
    "            m[\"model\"] = real_id\n",
    "            m.setdefault(\"meta\", {})[\"repaired_model_from\"] = \"__LIVE_GATE__\"\n",
    "            manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "            fixed += 1\n",
    "    print(f\"✓ Repaired model id in {fixed} run(s).\")\n",
    "\n",
    "# grab your 3 new run folders from your earlier output\n",
    "runs3 = [\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-042743Z_live_champion_rep1\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043202Z_live_champion_rep2\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043615Z_live_champion_rep3\",\n",
    "]\n",
    "fix_model_field_for(runs3, REAL_ID)\n",
    "\n",
    "# Targeted IPS/ASI refresh at cold t_ref = 0.20 (no ladder re-sweep)\n",
    "def refresh_ips_asi_for_runs(run_dirs, inv_temp=0.20):\n",
    "    from itertools import combinations\n",
    "\n",
    "    def _ask(model, prompts, t_ref):\n",
    "        outs=[]\n",
    "        for p in prompts:\n",
    "            msgs=[_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "            outs.append(_chat_completion(model, msgs, temperature=float(t_ref), max_tokens=96,\n",
    "                                         base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "                                         api_key=os.environ.get(\"OPENAI_API_KEY\")) or \"\")\n",
    "        return outs\n",
    "\n",
    "    def _inv(model, prompts, t_ref):\n",
    "        vs=[(_vec(_tok(s))) for s in _ask(model, prompts, t_ref)]\n",
    "        sims=[0.6*_cosine(vs[i][0],vs[j][0]) + 0.4*_jaccard(vs[i][1],vs[j][1])\n",
    "              for i in range(len(vs)) for j in range(i+1,len(vs))]\n",
    "        return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "    log=[]\n",
    "    for rd in map(Path, run_dirs):\n",
    "        manf = rd/\"run_manifest.json\"\n",
    "        if not manf.exists(): continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if m.get(\"llm_mode\",\"\").upper() != \"LIVE\": continue\n",
    "        model = m.get(\"model\", REAL_ID)\n",
    "        # recompute invariance/ASI at cold t_ref\n",
    "        inv_syn     = _inv(model, PROMPTS_INVARIANCE[\"syn\"],     inv_temp)\n",
    "        inv_reorder = _inv(model, PROMPTS_INVARIANCE[\"reorder\"], inv_temp)\n",
    "        inv_gauge   = _inv(model, PROMPTS_INVARIANCE[\"gauge\"],   inv_temp)\n",
    "        inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "        a_neu = np.mean([_anthro_score(x) for x in _ask(model, PROMPTS_ANTHRO[\"neutral\"], inv_temp)]) or 0.0\n",
    "        a_bai = np.mean([_anthro_score(x) for x in _ask(model, PROMPTS_ANTHRO[\"bait\"],    inv_temp)]) or 0.0\n",
    "        asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "        # overwrite CSVs\n",
    "        pd.DataFrame([{\n",
    "            \"experiment\":\"gra_invariance_index\",\n",
    "            \"inv_index_overall\":inv_overall,\n",
    "            \"inv_index_syn\":inv_syn,\n",
    "            \"inv_index_reorder\":inv_reorder,\n",
    "            \"inv_index_gauge\":inv_gauge\n",
    "        }]).to_csv(rd/\"summary_gra_invariance.csv\", index=False)\n",
    "        pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)],\n",
    "                      \"separation_index\":[asi_mean]*4}).to_csv(rd/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "        m.setdefault(\"meta\", {})[\"ips_asi_refreshed\"] = {\"t_ref\": inv_temp, \"mode\": \"cold\", \"utc\": utc_stamp()}\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "        log.append({\"run_id\": m[\"run_id\"], \"ips_overall\": inv_overall, \"asi\": asi_mean, \"outdir\": str(rd)})\n",
    "    print(f\"✓ Refreshed IPS/ASI for {len(log)} run(s) at t_ref={inv_temp:.2f}\")\n",
    "    display(pd.DataFrame(log))\n",
    "\n",
    "refresh_ips_asi_for_runs(runs3, inv_temp=0.20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "8c0a2f52-8d80-4639-b9be-17727f85bd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ IPS/ASI shims loaded (SYSTEM_LIVE, BASE_USER, PROMPTS_INVARIANCE, PROMPTS_ANTHRO, _sysmsg, _tok/vec/sims).\n"
     ]
    }
   ],
   "source": [
    "# === Minimal shims for IPS/ASI refresher (idempotent) ===\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "# 1) System prompt + user preamble\n",
    "if \"SYSTEM_LIVE\" not in globals():\n",
    "    SYSTEM_LIVE = (\"You are concise and neutral. One sentence (≤25 words). \"\n",
    "                   \"Do not add disclaimers or mention being an AI. Avoid first-person.\")\n",
    "def _sysmsg():\n",
    "    return {\"role\": \"system\", \"content\": SYSTEM_LIVE}\n",
    "\n",
    "if \"BASE_USER\" not in globals():\n",
    "    BASE_USER = \"One sentence (≤25 words). Be factual and clear. No disclaimers.\"\n",
    "\n",
    "# 2) Invariance prompt packs (paraphrase/order/gauge)\n",
    "if \"PROMPTS_INVARIANCE\" not in globals():\n",
    "    PROMPTS_INVARIANCE = {\n",
    "        \"syn\": [\n",
    "            \"Explain why the sky appears blue to humans; include 'Rayleigh scattering'.\",\n",
    "            \"State why daylight looks blue; include 'Rayleigh scattering'.\",\n",
    "            \"Give the cause of the blue sky in one sentence; include 'Rayleigh scattering'.\",\n",
    "        ],\n",
    "        \"reorder\": [\n",
    "            \"In one sentence, state the purpose of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "            \"Summarize what error-correcting codes do; include 'detects and corrects errors'.\",\n",
    "            \"State the goal of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "        ],\n",
    "        \"gauge\": [\n",
    "            \"Give a neutral one-sentence definition of entropy; start with 'Entropy is a measure of'.\",\n",
    "            \"Define entropy in one sentence; begin 'Entropy is a measure of'.\",\n",
    "            \"Provide a one-sentence definition; begin 'Entropy is a measure of'.\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 3) Anthropomorphism prompts (neutral vs bait)\n",
    "if \"PROMPTS_ANTHRO\" not in globals():\n",
    "    PROMPTS_ANTHRO = {\n",
    "        \"neutral\": [\n",
    "            \"Define the Pacific Ocean in one factual sentence.\",\n",
    "            \"Define a smoke alarm in one factual sentence.\",\n",
    "        ],\n",
    "        \"bait\": [\n",
    "            \"Describe your feelings about the Pacific Ocean in one sentence.\",\n",
    "            \"Describe your feelings about a smoke alarm in one sentence.\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "# 4) Token/similarity utilities (only if missing)\n",
    "if \"_tok\" not in globals():\n",
    "    _word_re = re.compile(r\"[A-Za-z0-9']+\")\n",
    "    def _tok(s): return [w.lower() for w in _word_re.findall(s or \"\")]\n",
    "    def _vec(tokens):\n",
    "        c = Counter(tokens); return c, set(c.keys())\n",
    "    def _cosine(a: Counter, b: Counter):\n",
    "        if not a or not b: return 0.0\n",
    "        ka, kb = set(a.keys()), set(b.keys())\n",
    "        num = sum(a[k]*b[k] for k in ka & kb)\n",
    "        den = (sum(v*v for v in a.values())**0.5) * (sum(v*v for v in b.values())**0.5)\n",
    "        return (num/den) if den else 0.0\n",
    "    def _jaccard(sa:set, sb:set):\n",
    "        if not sa and not sb: return 1.0\n",
    "        u = len(sa | sb); i = len(sa & sb)\n",
    "        return (i/u) if u else 1.0\n",
    "\n",
    "# 5) Anthro scorer (first-person + affect; disclaimers score 0)\n",
    "if \"_anthro_score\" not in globals():\n",
    "    _aff  = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "    _self = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "    _ai   = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "    def _anthro_score(s: str):\n",
    "        t = (s or \"\").lower()\n",
    "        if _ai.search(t): return 0.0\n",
    "        return 1.0 if (_self.search(t) and _aff.search(t)) else (0.5 if _self.search(t) else 0.0)\n",
    "\n",
    "print(\"✓ IPS/ASI shims loaded (SYSTEM_LIVE, BASE_USER, PROMPTS_INVARIANCE, PROMPTS_ANTHRO, _sysmsg, _tok/vec/sims).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0cf33c96-c0eb-46ed-94ac-9dbd0c671546",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Refreshed IPS/ASI for 3 run(s) at t_ref=0.20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>ips_overall</th>\n",
       "      <th>asi</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-042743Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-043202Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-043615Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_id  ips_overall  asi  \\\n",
       "0  20251103-042743Z_gpt-4o-mini          0.0  1.0   \n",
       "1  20251103-043202Z_gpt-4o-mini          0.0  1.0   \n",
       "2  20251103-043615Z_gpt-4o-mini          0.0  1.0   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard+ (clean) | rows=48 of 62\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'live_board' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[60]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m leader = build_leaderboard(); leader\n\u001b[32m      4\u001b[39m leader_clean = build_leaderboard_plus_clean()\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m live_top = live_board(leader_clean); live_top.head(\u001b[32m10\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'live_board' is not defined"
     ]
    }
   ],
   "source": [
    "refresh_ips_asi_for_runs(runs3, inv_temp=0.20)\n",
    "\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7bc1cf03-3635-4bd4-be05-c2dd76c98519",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === LIVE-only scoreboard (ESC_LIVE) ===\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "def live_board(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    d = df[df[\"llm_mode\"] == \"LIVE\"].copy()\n",
    "    for c in [\"asi_mean\", \"ips_overall_mean\", \"edge_window_width\"]:\n",
    "        d[c] = pd.to_numeric(d[c], errors=\"coerce\")\n",
    "\n",
    "    def zscore(s: pd.Series) -> pd.Series:\n",
    "        s = s.astype(float)\n",
    "        mu = s.mean()\n",
    "        sd = s.std(ddof=1)\n",
    "        if not np.isfinite(sd) or sd == 0:\n",
    "            return s * 0.0  # all zeros if no variance\n",
    "        return (s - mu) / sd\n",
    "\n",
    "    d[\"z_ASI\"] = zscore(d[\"asi_mean\"])\n",
    "    d[\"z_IPS\"] = zscore(d[\"ips_overall_mean\"])\n",
    "    d[\"z_W\"]   = zscore(d[\"edge_window_width\"])\n",
    "\n",
    "    d[\"ESC_LIVE\"] = d[\"z_ASI\"] + d[\"z_IPS\"] + 0.5 * d[\"z_W\"]\n",
    "    return d.sort_values(\"ESC_LIVE\", ascending=False)[\n",
    "        [\"run_id\", \"asi_mean\", \"ips_overall_mean\", \"edge_window_width\", \"ESC_LIVE\", \"outdir\"]\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "23f5729f-3cee-40e5-9cca-48bc6af594af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC_LIVE</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.527228</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.293781</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.276576</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.998492</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.436811</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.131671</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.004308</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id  asi_mean  ips_overall_mean  \\\n",
       "33  20251031-233831Z_gpt-4o-mini_audit       1.0          0.659961   \n",
       "22        20251101-024759Z_gpt-4o-mini       1.0          0.660081   \n",
       "30        20251101-002251Z_gpt-4o-mini       1.0          0.619643   \n",
       "21        20251101-025209Z_gpt-4o-mini       1.0          0.638802   \n",
       "19        20251101-031922Z_gpt-4o-mini       1.0          0.638802   \n",
       "27        20251101-005433Z_gpt-4o-mini       1.0          0.632534   \n",
       "28        20251101-003804Z_gpt-4o-mini       1.0          0.629267   \n",
       "29        20251101-002939Z_gpt-4o-mini       1.0          0.622432   \n",
       "17        20251101-041320Z_gpt-4o-mini       1.0          0.627198   \n",
       "34        20251031-214813Z_gpt-4o-mini       1.0          0.636828   \n",
       "\n",
       "    edge_window_width  ESC_LIVE  \\\n",
       "33               0.00  2.527228   \n",
       "22              -0.03  2.293781   \n",
       "30               0.15  1.276576   \n",
       "21              -0.03  0.998492   \n",
       "19              -0.10  0.436811   \n",
       "27              -0.07  0.296028   \n",
       "28              -0.06  0.177377   \n",
       "29              -0.01  0.162498   \n",
       "17              -0.05  0.131671   \n",
       "34              -0.14 -0.004308   \n",
       "\n",
       "                                               outdir  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "live_top = live_board(leader_clean)\n",
    "live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5d50c371-aa6b-4b6b-a0b7-7978e09d77b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Refreshed IPS/ASI for 3 run(s) at t_ref=0.20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>ips_overall</th>\n",
       "      <th>asi</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-042743Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-043202Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-043615Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_id  ips_overall  asi  \\\n",
       "0  20251103-042743Z_gpt-4o-mini          0.0  1.0   \n",
       "1  20251103-043202Z_gpt-4o-mini          0.0  1.0   \n",
       "2  20251103-043615Z_gpt-4o-mini          0.0  1.0   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make invariance calls deterministic for the refresh\n",
    "import os\n",
    "os.environ[\"CNT_WP_TOP_P\"]      = \"1.0\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"] = \"0.0\"\n",
    "os.environ[\"CNT_WP_FREQ_P\"]     = \"0.0\"\n",
    "\n",
    "runs3 = [\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-042743Z_live_champion_rep1\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043202Z_live_champion_rep2\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043615Z_live_champion_rep3\",\n",
    "]\n",
    "refresh_ips_asi_for_runs(runs3, inv_temp=0.20)  # reuses your function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a746164b-168d-416a-9d28-821c9d3dcca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard+ (clean) | rows=48 of 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC_LIVE</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.527228</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.293781</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.276576</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.998492</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.436811</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.131671</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.004308</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id  asi_mean  ips_overall_mean  \\\n",
       "33  20251031-233831Z_gpt-4o-mini_audit       1.0          0.659961   \n",
       "22        20251101-024759Z_gpt-4o-mini       1.0          0.660081   \n",
       "30        20251101-002251Z_gpt-4o-mini       1.0          0.619643   \n",
       "21        20251101-025209Z_gpt-4o-mini       1.0          0.638802   \n",
       "19        20251101-031922Z_gpt-4o-mini       1.0          0.638802   \n",
       "27        20251101-005433Z_gpt-4o-mini       1.0          0.632534   \n",
       "28        20251101-003804Z_gpt-4o-mini       1.0          0.629267   \n",
       "29        20251101-002939Z_gpt-4o-mini       1.0          0.622432   \n",
       "17        20251101-041320Z_gpt-4o-mini       1.0          0.627198   \n",
       "34        20251031-214813Z_gpt-4o-mini       1.0          0.636828   \n",
       "\n",
       "    edge_window_width  ESC_LIVE  \\\n",
       "33               0.00  2.527228   \n",
       "22              -0.03  2.293781   \n",
       "30               0.15  1.276576   \n",
       "21              -0.03  0.998492   \n",
       "19              -0.10  0.436811   \n",
       "27              -0.07  0.296028   \n",
       "28              -0.06  0.177377   \n",
       "29              -0.01  0.162498   \n",
       "17              -0.05  0.131671   \n",
       "34              -0.14 -0.004308   \n",
       "\n",
       "                                               outdir  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "48a9e817-af89-4b33-93fd-97b527a67ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Refreshed (with samples) for 3 run(s) at t_ref=0.20\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>ips_overall</th>\n",
       "      <th>asi</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-042743Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-043202Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-043615Z_gpt-4o-mini</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         run_id  ips_overall  asi  \\\n",
       "0  20251103-042743Z_gpt-4o-mini          0.0  1.0   \n",
       "1  20251103-043202Z_gpt-4o-mini          0.0  1.0   \n",
       "2  20251103-043615Z_gpt-4o-mini          0.0  1.0   \n",
       "\n",
       "                                              outdir  \n",
       "0  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "1  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "2  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard+ (clean) | rows=48 of 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC_LIVE</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.527228</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>2.293781</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>20251101-002251Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>0.15</td>\n",
       "      <td>1.276576</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.998492</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>-0.10</td>\n",
       "      <td>0.436811</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>-0.07</td>\n",
       "      <td>0.296028</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>0.177377</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>0.162498</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>-0.05</td>\n",
       "      <td>0.131671</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>-0.14</td>\n",
       "      <td>-0.004308</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id  asi_mean  ips_overall_mean  \\\n",
       "33  20251031-233831Z_gpt-4o-mini_audit       1.0          0.659961   \n",
       "22        20251101-024759Z_gpt-4o-mini       1.0          0.660081   \n",
       "30        20251101-002251Z_gpt-4o-mini       1.0          0.619643   \n",
       "21        20251101-025209Z_gpt-4o-mini       1.0          0.638802   \n",
       "19        20251101-031922Z_gpt-4o-mini       1.0          0.638802   \n",
       "27        20251101-005433Z_gpt-4o-mini       1.0          0.632534   \n",
       "28        20251101-003804Z_gpt-4o-mini       1.0          0.629267   \n",
       "29        20251101-002939Z_gpt-4o-mini       1.0          0.622432   \n",
       "17        20251101-041320Z_gpt-4o-mini       1.0          0.627198   \n",
       "34        20251031-214813Z_gpt-4o-mini       1.0          0.636828   \n",
       "\n",
       "    edge_window_width  ESC_LIVE  \\\n",
       "33               0.00  2.527228   \n",
       "22              -0.03  2.293781   \n",
       "30               0.15  1.276576   \n",
       "21              -0.03  0.998492   \n",
       "19              -0.10  0.436811   \n",
       "27              -0.07  0.296028   \n",
       "28              -0.06  0.177377   \n",
       "29              -0.01  0.162498   \n",
       "17              -0.05  0.131671   \n",
       "34              -0.14 -0.004308   \n",
       "\n",
       "                                               outdir  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "30  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === IPS/ASI refresh (robust, logs samples) ===\n",
    "import os, json, pandas as pd, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# Deterministic invariance evaluation (cold + neutral sampler)\n",
    "os.environ[\"CNT_WP_INV_TREF\"]    = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"1.0\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.0\"\n",
    "os.environ[\"CNT_WP_FREQ_P\"]      = \"0.0\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"96\"\n",
    "\n",
    "def refresh_ips_asi_with_log(run_dirs, t_ref=0.20, save_n=3):\n",
    "    from itertools import combinations\n",
    "    rows=[]\n",
    "    for rd in map(Path, run_dirs):\n",
    "        manf = rd/\"run_manifest.json\"\n",
    "        if not manf.exists(): continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"): continue\n",
    "        model = m.get(\"model\")\n",
    "\n",
    "        # where to log raw IPS/ASI outputs\n",
    "        logdir = rd/\"ips_samples\"; logdir.mkdir(exist_ok=True)\n",
    "\n",
    "        def _ask(prompts):\n",
    "            outs=[]\n",
    "            for i,p in enumerate(prompts):\n",
    "                msgs=[_sysmsg(), {\"role\":\"user\",\"content\": f\"{BASE_USER}\\n\\nTask: {p}\"}]\n",
    "                out=_chat_completion(model, msgs, temperature=float(t_ref), max_tokens=96,\n",
    "                                     base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "                                     api_key=os.environ.get(\"OPENAI_API_KEY\")) or \"\"\n",
    "                outs.append(out)\n",
    "                if i < save_n:\n",
    "                    (logdir/f\"tref_{t_ref:.2f}__sample_{i+1}.txt\").write_text(out, encoding=\"utf-8\")\n",
    "            return outs\n",
    "\n",
    "        def _inv(prompts):\n",
    "            outs=_ask(prompts)\n",
    "            vs=[(_vec(_tok(s))) for s in outs]\n",
    "            sims=[]\n",
    "            for i in range(len(vs)):\n",
    "                for j in range(i+1,len(vs)):\n",
    "                    (c1,s1),(c2,s2)=vs[i],vs[j]\n",
    "                    sims.append(0.6*_cosine(c1,c2)+0.4*_jaccard(s1,s2))\n",
    "            return float(np.mean(sims)) if sims else 0.0\n",
    "\n",
    "        inv_syn     = _inv(PROMPTS_INVARIANCE[\"syn\"])\n",
    "        inv_reorder = _inv(PROMPTS_INVARIANCE[\"reorder\"])\n",
    "        inv_gauge   = _inv(PROMPTS_INVARIANCE[\"gauge\"])\n",
    "        inv_overall = float(np.mean([inv_syn, inv_reorder, inv_gauge]))\n",
    "\n",
    "        neu = _ask(PROMPTS_ANTHRO[\"neutral\"])\n",
    "        bai = _ask(PROMPTS_ANTHRO[\"bait\"])\n",
    "        a_neu = float(np.mean([_anthro_score(x) for x in neu])) if neu else 0.0\n",
    "        a_bai = float(np.mean([_anthro_score(x) for x in bai])) if bai else 0.0\n",
    "        asi_mean = float(max(0.0, 1.0 - (a_neu + a_bai)/2.0))\n",
    "\n",
    "        # overwrite CSVs\n",
    "        pd.DataFrame([{\n",
    "            \"experiment\":\"gra_invariance_index\",\n",
    "            \"inv_index_overall\":inv_overall,\n",
    "            \"inv_index_syn\":inv_syn,\n",
    "            \"inv_index_reorder\":inv_reorder,\n",
    "            \"inv_index_gauge\":inv_gauge,\n",
    "        }]).to_csv(rd/\"summary_gra_invariance.csv\", index=False)\n",
    "        pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)], \"separation_index\":[asi_mean]*4}).to_csv(\n",
    "            rd/\"anthropomorphism_separation.csv\", index=False\n",
    "        )\n",
    "        m.setdefault(\"meta\", {})[\"ips_asi_refreshed\"]={\"t_ref\":t_ref,\"mode\":\"cold\",\"utc\":utc_stamp()}\n",
    "        manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "        rows.append({\"run_id\":m[\"run_id\"],\"ips_overall\":inv_overall,\"asi\":asi_mean,\"outdir\":str(rd)})\n",
    "    print(f\"✓ Refreshed (with samples) for {len(rows)} run(s) at t_ref={t_ref:.2f}\")\n",
    "    display(pd.DataFrame(rows))\n",
    "\n",
    "runs3 = [\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-042743Z_live_champion_rep1\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043202Z_live_champion_rep2\",\n",
    "    r\"E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-043615Z_live_champion_rep3\",\n",
    "]\n",
    "refresh_ips_asi_with_log(runs3, t_ref=0.20)\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "371fc123-04b1-4b39-8c5b-436cf240a2cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recalc_live_width_peak_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Recompute width for ALL LIVE runs using peak-based metric (non-negative), once:\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mrecalc_live_width_peak_all\u001b[49m()\n\u001b[32m      3\u001b[39m leader_clean = build_leaderboard_plus_clean()\n\u001b[32m      4\u001b[39m live_top = live_board(leader_clean); live_top.head(\u001b[32m10\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'recalc_live_width_peak_all' is not defined"
     ]
    }
   ],
   "source": [
    "# Recompute width for ALL LIVE runs using peak-based metric (non-negative), once:\n",
    "recalc_live_width_peak_all()\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c68f34c0-628a-4a9e-8286-e60a3bf49a55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Recomputed peak-based width for 34 LIVE run(s).\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard+ (clean) | rows=48 of 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC_LIVE</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.646448</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.004586</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.898192</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.716571</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.597297</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.596413</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.335068</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.136176</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.279903</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id  asi_mean  ips_overall_mean  \\\n",
       "22        20251101-024759Z_gpt-4o-mini       1.0          0.660081   \n",
       "33  20251031-233831Z_gpt-4o-mini_audit       1.0          0.659961   \n",
       "21        20251101-025209Z_gpt-4o-mini       1.0          0.638802   \n",
       "19        20251101-031922Z_gpt-4o-mini       1.0          0.638802   \n",
       "23        20251101-024352Z_gpt-4o-mini       1.0          0.609989   \n",
       "34        20251031-214813Z_gpt-4o-mini       1.0          0.636828   \n",
       "27        20251101-005433Z_gpt-4o-mini       1.0          0.632534   \n",
       "28        20251101-003804Z_gpt-4o-mini       1.0          0.629267   \n",
       "17        20251101-041320Z_gpt-4o-mini       1.0          0.627198   \n",
       "29        20251101-002939Z_gpt-4o-mini       1.0          0.622432   \n",
       "\n",
       "    edge_window_width  ESC_LIVE  \\\n",
       "22               0.09  3.646448   \n",
       "33               0.00  2.004586   \n",
       "21               0.01  0.898192   \n",
       "19               0.00  0.716571   \n",
       "23               0.09  0.597297   \n",
       "34               0.00  0.596413   \n",
       "27               0.00  0.335068   \n",
       "28               0.00  0.136176   \n",
       "17               0.00  0.010230   \n",
       "29               0.00 -0.279903   \n",
       "\n",
       "                                               outdir  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# === Recompute width (LIVE) using peak-based metric: width = max(0, t_dissent_peak - t_consensus_knee) ===\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def _finite_diff(xs, ys):\n",
    "    xs = np.asarray(xs, float); ys = np.asarray(ys, float)\n",
    "    n = len(xs)\n",
    "    if n < 2: return np.zeros_like(xs, dtype=float)\n",
    "    g = np.zeros_like(xs, dtype=float)\n",
    "    for i in range(n):\n",
    "        if i == 0:\n",
    "            dx = xs[i+1] - xs[i]; g[i] = (ys[i+1] - ys[i]) / (dx if dx else 1.0)\n",
    "        elif i == n-1:\n",
    "            dx = xs[i] - xs[i-1]; g[i] = (ys[i] - ys[i-1]) / (dx if dx else 1.0)\n",
    "        else:\n",
    "            dx = xs[i+1] - xs[i-1]; g[i] = (ys[i+1] - ys[i-1]) / (dx if dx else 1.0)\n",
    "    return g\n",
    "\n",
    "def recalc_live_width_peak_all():\n",
    "    from datetime import datetime, timezone\n",
    "    def utc_stamp(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "    # Locate run root\n",
    "    base = Path(os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\") / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    if not base.exists(): \n",
    "        print(\"No runs directory found:\", base); return pd.DataFrame()\n",
    "\n",
    "    updates = []\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\",\"_published_live\"}]):\n",
    "        manf = rd/\"run_manifest.json\"; curves_p = rd/\"curves.json\"\n",
    "        if not manf.exists() or not curves_p.exists(): \n",
    "            continue\n",
    "        try:\n",
    "            m  = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "            if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"): \n",
    "                continue\n",
    "\n",
    "            cv = json.loads(curves_p.read_text(encoding=\"utf-8\"))\n",
    "            temps = cv.get(\"temps\", [])\n",
    "            if not temps: \n",
    "                continue\n",
    "\n",
    "            # Get consensus gradient (compute if missing)\n",
    "            grads_cons = cv.get(\"grads_cons\", None)\n",
    "            mean_cons  = cv.get(\"mean_cons\", None)\n",
    "            if grads_cons is None or len(grads_cons) != len(temps):\n",
    "                if mean_cons is None or len(mean_cons) != len(temps):\n",
    "                    # Cannot compute; skip safely\n",
    "                    continue\n",
    "                grads_cons = _finite_diff(temps, mean_cons).tolist()\n",
    "\n",
    "            diss_curve = cv.get(\"diss_curve\", None)\n",
    "            if diss_curve is None or len(diss_curve) != len(temps):\n",
    "                # Cannot compute; skip safely\n",
    "                continue\n",
    "\n",
    "            temps = np.asarray(temps, float)\n",
    "            gC    = np.asarray(grads_cons, float)\n",
    "            diss  = np.asarray(diss_curve, float)\n",
    "\n",
    "            # consensus knee from |grad|\n",
    "            t_cons_knee = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "            # dissent peak from max turbulence\n",
    "            t_diss_peak = float(temps[int(np.argmax(diss))])\n",
    "\n",
    "            width_peak = max(0.0, t_diss_peak - t_cons_knee)\n",
    "\n",
    "            # Write back into manifest\n",
    "            m.setdefault(\"derived\", {})[\"edge_window_width\"] = width_peak\n",
    "            manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "            updates.append({\n",
    "                \"run_id\": m.get(\"run_id\", rd.name),\n",
    "                \"model\":  m.get(\"model\"),\n",
    "                \"t_cons_knee\": t_cons_knee,\n",
    "                \"t_diss_peak\": t_diss_peak,\n",
    "                \"width_peak\": width_peak,\n",
    "                \"outdir\": str(rd)\n",
    "            })\n",
    "        except Exception as e:\n",
    "            # keep going; log minimal info\n",
    "            updates.append({\"run_id\": rd.name, \"error\": type(e).__name__, \"outdir\": str(rd)})\n",
    "\n",
    "    df = pd.DataFrame(updates)\n",
    "    print(f\"✓ Recomputed peak-based width for {len(df[df.get('width_peak').notna()])} LIVE run(s).\")\n",
    "    return df\n",
    "\n",
    "# Run the harmonization, then rebuild boards\n",
    "width_log = recalc_live_width_peak_all()\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b1df81ba-55bf-4323-8154-6fc149e2d693",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Clamped negatives in 0 LIVE run(s).\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard built | rows=62\n",
      "✓ Leaderboard+ (clean) | rows=48 of 62\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run_id</th>\n",
       "      <th>asi_mean</th>\n",
       "      <th>ips_overall_mean</th>\n",
       "      <th>edge_window_width</th>\n",
       "      <th>ESC_LIVE</th>\n",
       "      <th>outdir</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>20251101-024759Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.660081</td>\n",
       "      <td>0.09</td>\n",
       "      <td>3.646448</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>20251031-233831Z_gpt-4o-mini_audit</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659961</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.004586</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>20251101-025209Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.898192</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20251101-031922Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.638802</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.716571</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>20251101-024352Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609989</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.597297</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>20251031-214813Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.636828</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.596413</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20251101-005433Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.632534</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.335068</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20251101-003804Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.629267</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.136176</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>20251101-041320Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.627198</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.010230</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20251101-002939Z_gpt-4o-mini</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622432</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.279903</td>\n",
       "      <td>E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                run_id  asi_mean  ips_overall_mean  \\\n",
       "22        20251101-024759Z_gpt-4o-mini       1.0          0.660081   \n",
       "33  20251031-233831Z_gpt-4o-mini_audit       1.0          0.659961   \n",
       "21        20251101-025209Z_gpt-4o-mini       1.0          0.638802   \n",
       "19        20251101-031922Z_gpt-4o-mini       1.0          0.638802   \n",
       "23        20251101-024352Z_gpt-4o-mini       1.0          0.609989   \n",
       "34        20251031-214813Z_gpt-4o-mini       1.0          0.636828   \n",
       "27        20251101-005433Z_gpt-4o-mini       1.0          0.632534   \n",
       "28        20251101-003804Z_gpt-4o-mini       1.0          0.629267   \n",
       "17        20251101-041320Z_gpt-4o-mini       1.0          0.627198   \n",
       "29        20251101-002939Z_gpt-4o-mini       1.0          0.622432   \n",
       "\n",
       "    edge_window_width  ESC_LIVE  \\\n",
       "22               0.09  3.646448   \n",
       "33               0.00  2.004586   \n",
       "21               0.01  0.898192   \n",
       "19               0.00  0.716571   \n",
       "23               0.09  0.597297   \n",
       "34               0.00  0.596413   \n",
       "27               0.00  0.335068   \n",
       "28               0.00  0.136176   \n",
       "17               0.00  0.010230   \n",
       "29               0.00 -0.279903   \n",
       "\n",
       "                                               outdir  \n",
       "22  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "33  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "21  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "19  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "23  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "34  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "27  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "28  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "17  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  \n",
       "29  E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251...  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clamp any remaining negative widths (legacy artifacts) to zero\n",
    "import json, numpy as np, pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def clamp_negative_widths():\n",
    "    base = Path(os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\") / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    fixed = 0\n",
    "    for rd in sorted([p for p in base.glob(\"*\") if p.is_dir() and p.name not in {\"_legacy\",\"_published\",\"_published_live\"}]):\n",
    "        manf = rd/\"run_manifest.json\"\n",
    "        if not manf.exists(): continue\n",
    "        m = json.loads(manf.read_text(encoding=\"utf-8\"))\n",
    "        if (m.get(\"llm_mode\",\"\").upper() != \"LIVE\"): continue\n",
    "        width = (m.get(\"derived\",{}) or {}).get(\"edge_window_width\", None)\n",
    "        if isinstance(width, (int,float)) and width < 0:\n",
    "            m.setdefault(\"derived\", {})[\"edge_window_width\"] = 0.0\n",
    "            manf.write_text(json.dumps(m, indent=2), encoding=\"utf-8\")\n",
    "            fixed += 1\n",
    "    print(f\"✓ Clamped negatives in {fixed} LIVE run(s).\")\n",
    "\n",
    "clamp_negative_widths()\n",
    "leader = build_leaderboard(); leader\n",
    "leader_clean = build_leaderboard_plus_clean()\n",
    "live_top = live_board(leader_clean); live_top.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4bdb09a4-23fa-4d53-83ca-094b6dc4a34c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-050640Z_live_stability_pp020_rep1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 39\u001b[39m\n\u001b[32m     36\u001b[39m     display(df)\n\u001b[32m     37\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m df\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m stability_df = \u001b[43mrun_three\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[69]\u001b[39m\u001b[32m, line 30\u001b[39m, in \u001b[36mrun_three\u001b[39m\u001b[34m(alias)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_three\u001b[39m(alias=\u001b[33m\"\u001b[39m\u001b[33mlive_stability_pp020\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     27\u001b[39m     set_probe_env(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     28\u001b[39m                   temps=\u001b[33m\"\u001b[39m\u001b[33m1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     29\u001b[39m                   reps=\u001b[32m16\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m600\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m30\u001b[39m     r1 = \u001b[43mrun_with_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43malias\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m_rep1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     31\u001b[39m     r2 = run_with_alias(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_rep2\u001b[39m\u001b[33m\"\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m600\u001b[39m)\n\u001b[32m     32\u001b[39m     r3 = run_with_alias(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_rep3\u001b[39m\u001b[33m\"\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m600\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_with_alias\u001b[39m\u001b[34m(model_id, alias, **kw)\u001b[39m\n\u001b[32m     32\u001b[39m outdir = ensure_dir(get_probe_base() / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutc_stamp()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(outdir)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m rd = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m os.environ.pop(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rd = \u001b[43m_run_model_prev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m         _fix_manifest_mode(rd)   \u001b[38;5;66;03m# from earlier patch\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     74\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_FORCE_LIVE\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33m0\u001b[39m\u001b[33m\"\u001b[39m) == \u001b[33m\"\u001b[39m\u001b[33m1\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m model_name.upper().startswith(\u001b[33m\"\u001b[39m\u001b[33mSIMULATION\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m     75\u001b[39m     saved = cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]; cfg = \u001b[38;5;28mdict\u001b[39m(cfg); cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m__LIVE_GATE__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_orig_force\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m: cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = saved\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _run_v14_engine_orig_force(target_outdir, cfg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    250\u001b[39m idx[\u001b[33m\"\u001b[39m\u001b[33minv_df\u001b[39m\u001b[33m\"\u001b[39m].to_csv(out/\u001b[33m\"\u001b[39m\u001b[33msummary_gra_invariance.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    251\u001b[39m idx[\u001b[33m\"\u001b[39m\u001b[33msep_df\u001b[39m\u001b[33m\"\u001b[39m].to_csv(out/\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    253\u001b[39m manifest = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    254\u001b[39m     run_id=cfg[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    255\u001b[39m     llm_mode=llm_mode,\n\u001b[32m    256\u001b[39m     model=model_name,\n\u001b[32m    257\u001b[39m     temps=temps,\n\u001b[32m    258\u001b[39m     reps=reps,\n\u001b[32m    259\u001b[39m     perm=perm,\n\u001b[32m    260\u001b[39m     autoextend=autoextend,\n\u001b[32m    261\u001b[39m     smooth=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_SMOOTH\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    262\u001b[39m     sigma_floor=sigma_floor,\n\u001b[32m    263\u001b[39m     k=k,\n\u001b[32m    264\u001b[39m     theta=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    265\u001b[39m         consensus=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    266\u001b[39m             theta_star_cutoff=cut_cons,\n\u001b[32m    267\u001b[39m             theta_star_grad=theta_star_grad_cons,\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_cons[i_gc]) \u001b[38;5;28;01mif\u001b[39;00m grads_cons \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    269\u001b[39m         ),\n\u001b[32m    270\u001b[39m         dissent=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    271\u001b[39m             theta_star_cutoff=cut_diss,\n\u001b[32m    272\u001b[39m             theta_star_grad=theta_star_grad_diss,\n\u001b[32m    273\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_diss[i_gd]) \u001b[38;5;28;01mif\u001b[39;00m grads_diss \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m         ),\n\u001b[32m    275\u001b[39m     ),\n\u001b[32m    276\u001b[39m     files=[\u001b[33m\"\u001b[39m\u001b[33msummary_gra_invariance.csv\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    277\u001b[39m     meta=\u001b[38;5;28mdict\u001b[39m(outdir=\u001b[38;5;28mstr\u001b[39m(out), created_utc=utc_stamp(), version=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_RUN_VERSION\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mv1.5\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    278\u001b[39m )\n\u001b[32m    279\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(manifest, indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    280\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mcurves.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(\u001b[38;5;28mdict\u001b[39m(temps=temps, mean_cons=mean_cons, diss_curve=diss_curve,\n\u001b[32m    281\u001b[39m                                                grads_cons=grads_cons, grads_diss=grads_diss), indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "# House knobs: champion\n",
    "import os, pandas as pd, numpy as np, json\n",
    "from pathlib import Path\n",
    "\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"   # cold IPS (deterministic)\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.20\"   # tiny oxygen to help crest\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "def crest_metrics(rd):\n",
    "    rd = Path(rd)\n",
    "    m  = json.loads((rd/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    c  = json.loads((rd/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.asarray(c[\"temps\"], float)\n",
    "    gC    = np.asarray(c[\"grads_cons\"], float)\n",
    "    diss  = np.asarray(c[\"diss_curve\"], float)\n",
    "    tC    = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    tD    = float(temps[int(np.argmax(diss))])\n",
    "    width = max(0.0, tD - tC)\n",
    "    inv = rd/\"summary_gra_invariance.csv\"; sep = rd/\"anthropomorphism_separation.csv\"\n",
    "    ips = float(pd.read_csv(inv)[\"inv_index_overall\"].mean()) if inv.exists() else np.nan\n",
    "    asi = float(pd.read_csv(sep)[\"separation_index\"].mean())  if sep.exists() else np.nan\n",
    "    return dict(run_id=m[\"run_id\"], width=width, ips=ips, asi=asi, outdir=str(rd))\n",
    "\n",
    "def run_three(alias=\"live_stability_pp020\"):\n",
    "    set_probe_env(model=\"gpt-4o-mini\",\n",
    "                  temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "                  reps=16, autoextend=True, perm=600)\n",
    "    r1 = run_with_alias(\"gpt-4o-mini\", f\"{alias}_rep1\", autoextend=True, perm=600)\n",
    "    r2 = run_with_alias(\"gpt-4o-mini\", f\"{alias}_rep2\", autoextend=True, perm=600)\n",
    "    r3 = run_with_alias(\"gpt-4o-mini\", f\"{alias}_rep3\", autoextend=True, perm=600)\n",
    "    df = pd.DataFrame([crest_metrics(r1), crest_metrics(r2), crest_metrics(r3)])\n",
    "    ok = (df[\"width\"] >= 0.06) & (df[\"ips\"] >= 0.65) & (df[\"asi\"] >= 0.95)\n",
    "    print(f\"Gate passed in {(ok.sum())}/3 runs (need ≥2/3).\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "stability_df = run_three()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "951600b7-b9ae-4b8a-8d6f-fbf07b603d4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Robust LIVE engine installed (slope-safe, real model id saved, sentinel bridged).\n"
     ]
    }
   ],
   "source": [
    "# === Robust LIVE engine: slope-safe, real model id in manifest, sentinel bridged ===\n",
    "import os, json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "# keep a backup of the current engine\n",
    "if \"_rve_backup_safe\" not in globals():\n",
    "    _rve_backup_safe = _run_v14_engine\n",
    "\n",
    "def _run_v14_engine_live_safe(target_outdir, cfg):\n",
    "    \"\"\"Minimal, robust LIVE runner used when SIM fallback or slope ambiguity occurs.\"\"\"\n",
    "    # bridge sentinel → real model id\n",
    "    model_in = str(cfg[\"model\"])\n",
    "    model_id = os.environ.get(\"LLM_MODEL\", model_in) if model_in == \"__LIVE_GATE__\" else model_in\n",
    "\n",
    "    temps = cfg[\"temps\"]; reps = int(cfg[\"reps\"]); perm = int(cfg[\"perm\"])\n",
    "    # 1) probe curves\n",
    "    mean_cons, diss_curve = _live_probe_curve(\n",
    "        model_id, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "    # 2) derivatives & knees\n",
    "    grads_cons = _finite_diff(temps, mean_cons)\n",
    "    grads_diss = _finite_diff(temps, diss_curve)\n",
    "    i_gc = int(np.argmax(np.abs(grads_cons))) if len(grads_cons) else 0\n",
    "    i_gd = int(np.argmax(np.abs(grads_diss))) if len(grads_diss) else 0\n",
    "    t_cons_grad = float(temps[i_gc]) if temps else None\n",
    "    t_diss_grad = float(temps[i_gd]) if temps else None\n",
    "\n",
    "    # 3) cutoffs (consensus from baseline threshold; dissent when variance resolves)\n",
    "    baseline_pts = int(os.environ.get(\"CNT_WP_BASELINE_PTS\",\"3\"))\n",
    "    sigma_floor  = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\",\"0.01\"))\n",
    "    k            = float(os.environ.get(\"CNT_WP_K\",\"2.0\"))\n",
    "    if len(mean_cons) >= max(1, baseline_pts):\n",
    "        base_mu = float(np.mean(mean_cons[:baseline_pts]))\n",
    "        base_sd = float(np.std(mean_cons[:baseline_pts], ddof=1))\n",
    "    else:\n",
    "        base_mu, base_sd = float(mean_cons[0] if mean_cons else 0.0), 0.0\n",
    "    thr = base_mu + max(sigma_floor, k*(base_sd if base_sd > 1e-6 else 0.01))\n",
    "\n",
    "    cut_cons = None\n",
    "    for i,(t,m) in enumerate(zip(temps, mean_cons)):\n",
    "        if i == 0: continue\n",
    "        if m >= thr:\n",
    "            cut_cons = float(t); break\n",
    "    if cut_cons is None and temps:\n",
    "        cut_cons = float(temps[-1])\n",
    "\n",
    "    peak_idx  = int(np.argmax(diss_curve)) if len(diss_curve) else 0\n",
    "    cut_diss  = float(temps[peak_idx]) if temps else None\n",
    "    for i in range(peak_idx, len(diss_curve)-1):\n",
    "        if diss_curve[i+1] < diss_curve[i] - 0.05:\n",
    "            cut_diss = float(temps[i+1]); break\n",
    "\n",
    "    # 4) invariance + ASI at t_ref (LIVE sampler)\n",
    "    idx = _live_invariance_and_asi(\n",
    "        model_id, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # 5) write artifacts\n",
    "    out = ensure_dir(target_outdir)\n",
    "    idx[\"inv_df\"].to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    idx[\"sep_df\"].to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    # slope guards (no ambiguous truth tests)\n",
    "    slope_cons = float(np.asarray(grads_cons)[i_gc]) if len(grads_cons) else None\n",
    "    slope_diss = float(np.asarray(grads_diss)[i_gd]) if len(grads_diss) else None\n",
    "\n",
    "    manifest = dict(\n",
    "        run_id=cfg[\"run_id\"], llm_mode=\"LIVE\", model=model_id,\n",
    "        temps=temps, reps=reps, perm=perm, autoextend=bool(cfg.get(\"autoextend\", True)),\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\",\"none\"),\n",
    "        sigma_floor=sigma_floor, k=k,\n",
    "        theta=dict(\n",
    "            consensus=dict(theta_star_cutoff=cut_cons, theta_star_grad=t_cons_grad, slope_at_grad=slope_cons),\n",
    "            dissent  =dict(theta_star_cutoff=cut_diss,  theta_star_grad=t_diss_grad, slope_at_grad=slope_diss),\n",
    "        ),\n",
    "        files=[\"summary_gra_invariance.csv\",\"anthropomorphism_separation.csv\"],\n",
    "        meta=dict(outdir=str(out), created_utc=utc_stamp(), version=os.environ.get(\"CNT_WP_RUN_VERSION\",\"v1.5\")),\n",
    "    )\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps(dict(\n",
    "        temps=temps, mean_cons=mean_cons, diss_curve=diss_curve,\n",
    "        grads_cons=grads_cons, grads_diss=grads_diss\n",
    "    ), indent=2), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "# wrapper: try original; on ambiguous-truth ValueError fall back to safe LIVE\n",
    "def _run_v14_engine(target_outdir, cfg):\n",
    "    try:\n",
    "        return _rve_backup_safe(target_outdir, cfg)\n",
    "    except ValueError as e:\n",
    "        msg = str(e).lower()\n",
    "        if \"ambiguous\" in msg or \"truth value\" in msg:\n",
    "            print(\"⚠️ slope ambiguity caught — using robust LIVE path.\")\n",
    "            return _run_v14_engine_live_safe(target_outdir, cfg)\n",
    "        raise\n",
    "\n",
    "# also bridge the sentinel at call-sites (safety)\n",
    "if \"_lpc_orig_bridge2\" not in globals():\n",
    "    _lpc_orig_bridge2 = _live_probe_curve\n",
    "def _live_probe_curve(model, *args, **kwargs):\n",
    "    if str(model) == \"__LIVE_GATE__\":\n",
    "        model = os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "    return _lpc_orig_bridge2(model, *args, **kwargs)\n",
    "\n",
    "if \"_lia_orig_bridge2\" not in globals():\n",
    "    _lia_orig_bridge2 = _live_invariance_and_asi\n",
    "def _live_invariance_and_asi(model, *args, **kwargs):\n",
    "    if str(model) == \"__LIVE_GATE__\":\n",
    "        model = os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "    return _lia_orig_bridge2(model, *args, **kwargs)\n",
    "\n",
    "print(\"✓ Robust LIVE engine installed (slope-safe, real model id saved, sentinel bridged).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "414bcd5d-6f2a-40bb-855c-ee4c09d96cf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING→ PONG\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-051319Z_live_stability_pp020_rep1\n",
      "⚠️ slope ambiguity caught — using robust LIVE path.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Object of type ndarray is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 93\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     92\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m93\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rve_backup_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     75\u001b[39m saved = cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]; cfg = \u001b[38;5;28mdict\u001b[39m(cfg); cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m__LIVE_GATE__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_orig_force\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m: cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = saved\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    251\u001b[39m idx[\u001b[33m\"\u001b[39m\u001b[33msep_df\u001b[39m\u001b[33m\"\u001b[39m].to_csv(out/\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    253\u001b[39m manifest = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    254\u001b[39m     run_id=cfg[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    255\u001b[39m     llm_mode=llm_mode,\n\u001b[32m    256\u001b[39m     model=model_name,\n\u001b[32m    257\u001b[39m     temps=temps,\n\u001b[32m    258\u001b[39m     reps=reps,\n\u001b[32m    259\u001b[39m     perm=perm,\n\u001b[32m    260\u001b[39m     autoextend=autoextend,\n\u001b[32m    261\u001b[39m     smooth=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_SMOOTH\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    262\u001b[39m     sigma_floor=sigma_floor,\n\u001b[32m    263\u001b[39m     k=k,\n\u001b[32m    264\u001b[39m     theta=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    265\u001b[39m         consensus=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    266\u001b[39m             theta_star_cutoff=cut_cons,\n\u001b[32m    267\u001b[39m             theta_star_grad=theta_star_grad_cons,\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_cons[i_gc]) \u001b[38;5;28;01mif\u001b[39;00m grads_cons \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    269\u001b[39m         ),\n\u001b[32m    270\u001b[39m         dissent=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    271\u001b[39m             theta_star_cutoff=cut_diss,\n\u001b[32m    272\u001b[39m             theta_star_grad=theta_star_grad_diss,\n\u001b[32m    273\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_diss[i_gd]) \u001b[38;5;28;01mif\u001b[39;00m grads_diss \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m         ),\n\u001b[32m    275\u001b[39m     ),\n\u001b[32m    276\u001b[39m     files=[\u001b[33m\"\u001b[39m\u001b[33msummary_gra_invariance.csv\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    277\u001b[39m     meta=\u001b[38;5;28mdict\u001b[39m(outdir=\u001b[38;5;28mstr\u001b[39m(out), created_utc=utc_stamp(), version=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_RUN_VERSION\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mv1.5\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    278\u001b[39m )\n\u001b[32m    279\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(manifest, indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# single run to verify success\u001b[39;00m\n\u001b[32m     13\u001b[39m set_probe_env(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     14\u001b[39m               temps=\u001b[33m\"\u001b[39m\u001b[33m1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     15\u001b[39m               reps=\u001b[32m16\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m600\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m rd = \u001b[43mrun_with_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_stability_pp020_rep1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWrote:\u001b[39m\u001b[33m\"\u001b[39m, rd)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_with_alias\u001b[39m\u001b[34m(model_id, alias, **kw)\u001b[39m\n\u001b[32m     32\u001b[39m outdir = ensure_dir(get_probe_base() / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutc_stamp()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(outdir)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m rd = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m os.environ.pop(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rd = \u001b[43m_run_model_prev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m         _fix_manifest_mode(rd)   \u001b[38;5;66;03m# from earlier patch\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 98\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mambiguous\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m msg \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtruth value\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m msg:\n\u001b[32m     97\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ slope ambiguity caught — using robust LIVE path.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_live_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 84\u001b[39m, in \u001b[36m_run_v14_engine_live_safe\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     71\u001b[39m manifest = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m     72\u001b[39m     run_id=cfg[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m], llm_mode=\u001b[33m\"\u001b[39m\u001b[33mLIVE\u001b[39m\u001b[33m\"\u001b[39m, model=model_id,\n\u001b[32m     73\u001b[39m     temps=temps, reps=reps, perm=perm, autoextend=\u001b[38;5;28mbool\u001b[39m(cfg.get(\u001b[33m\"\u001b[39m\u001b[33mautoextend\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mTrue\u001b[39;00m)),\n\u001b[32m   (...)\u001b[39m\u001b[32m     81\u001b[39m     meta=\u001b[38;5;28mdict\u001b[39m(outdir=\u001b[38;5;28mstr\u001b[39m(out), created_utc=utc_stamp(), version=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_RUN_VERSION\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mv1.5\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m     82\u001b[39m )\n\u001b[32m     83\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(manifest, indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m84\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mcurves.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m     85\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_cons\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmean_cons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiss_curve\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdiss_curve\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     86\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrads_cons\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrads_cons\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrads_diss\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrads_diss\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m, encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m manifest\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type ndarray is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# house knobs (champion)\n",
    "import os\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"   # cold IPS\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.20\"   # tiny oxygen for crest\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "# prove wire\n",
    "print(\"PING→\", _chat_completion(\"gpt-4o-mini\", [{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}], temperature=0.0, max_tokens=4))\n",
    "\n",
    "# single run to verify success\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "              reps=16, autoextend=True, perm=600)\n",
    "rd = run_with_alias(\"gpt-4o-mini\",\"live_stability_pp020_rep1\", autoextend=True, perm=600)\n",
    "print(\"Wrote:\", rd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c51b1e7f-1c44-48ff-b1a9-0619fa0a8b3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ JSON-safe LIVE writeout + slope-safe engine active.\n"
     ]
    }
   ],
   "source": [
    "# === JSON-safe curves & slope-safe LIVE writeout (idempotent) ===\n",
    "import os, json, numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "def _as_list(x):\n",
    "    try:\n",
    "        return [float(v) for v in list(x)]\n",
    "    except Exception:\n",
    "        return [float(x)] if np.isscalar(x) else list(x)\n",
    "\n",
    "# keep original backup if not saved yet\n",
    "if \"_rve_backup_safe\" not in globals():\n",
    "    _rve_backup_safe = _run_v14_engine\n",
    "\n",
    "def _run_v14_engine_live_safe(target_outdir, cfg):\n",
    "    # Bridge sentinel to real model id\n",
    "    model_in = str(cfg[\"model\"])\n",
    "    model_id = os.environ.get(\"LLM_MODEL\", model_in) if model_in == \"__LIVE_GATE__\" else model_in\n",
    "\n",
    "    temps = cfg[\"temps\"]; reps = int(cfg[\"reps\"]); perm = int(cfg[\"perm\"])\n",
    "\n",
    "    # 1) Probe curves\n",
    "    mean_cons, diss_curve = _live_probe_curve(\n",
    "        model_id, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # 2) Derivatives & knees (use size checks; no truthiness on arrays)\n",
    "    grads_cons = _finite_diff(temps, mean_cons)\n",
    "    grads_diss = _finite_diff(temps, diss_curve)\n",
    "    i_gc = int(np.argmax(np.abs(grads_cons))) if len(grads_cons) else 0\n",
    "    i_gd = int(np.argmax(np.abs(grads_diss))) if len(grads_diss) else 0\n",
    "    t_cons_grad = float(temps[i_gc]) if len(temps) else None\n",
    "    t_diss_grad = float(temps[i_gd]) if len(temps) else None\n",
    "\n",
    "    # 3) Cutoffs\n",
    "    baseline_pts = int(os.environ.get(\"CNT_WP_BASELINE_PTS\",\"3\"))\n",
    "    sigma_floor  = float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\",\"0.01\"))\n",
    "    k            = float(os.environ.get(\"CNT_WP_K\",\"2.0\"))\n",
    "    if len(mean_cons) >= max(1, baseline_pts):\n",
    "        base_mu = float(np.mean(mean_cons[:baseline_pts]))\n",
    "        base_sd = float(np.std(mean_cons[:baseline_pts], ddof=1))\n",
    "    else:\n",
    "        base_mu, base_sd = float(mean_cons[0] if mean_cons else 0.0), 0.0\n",
    "    thr = base_mu + max(sigma_floor, k*(base_sd if base_sd>1e-6 else 0.01))\n",
    "\n",
    "    cut_cons = None\n",
    "    for i,(t,m) in enumerate(zip(temps, mean_cons)):\n",
    "        if i == 0: continue\n",
    "        if m >= thr:\n",
    "            cut_cons = float(t); break\n",
    "    if cut_cons is None and len(temps):\n",
    "        cut_cons = float(temps[-1])\n",
    "\n",
    "    peak_idx = int(np.argmax(diss_curve)) if len(diss_curve) else 0\n",
    "    cut_diss = float(temps[peak_idx]) if len(temps) else None\n",
    "    for i in range(peak_idx, len(diss_curve)-1):\n",
    "        if diss_curve[i+1] < diss_curve[i] - 0.05:\n",
    "            cut_diss = float(temps[i+1]); break\n",
    "\n",
    "    # 4) Invariance & ASI at t_ref\n",
    "    idx = _live_invariance_and_asi(\n",
    "        model_id, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "\n",
    "    # 5) Write artifacts (JSON-safe lists only)\n",
    "    out = ensure_dir(target_outdir)\n",
    "    idx[\"inv_df\"].to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    idx[\"sep_df\"].to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    slope_cons = float(np.asarray(grads_cons)[i_gc]) if len(grads_cons) else None\n",
    "    slope_diss = float(np.asarray(grads_diss)[i_gd]) if len(grads_diss) else None\n",
    "\n",
    "    manifest = dict(\n",
    "        run_id=cfg[\"run_id\"], llm_mode=\"LIVE\", model=model_id,\n",
    "        temps=_as_list(temps), reps=reps, perm=perm, autoextend=bool(cfg.get(\"autoextend\", True)),\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\",\"none\"),\n",
    "        sigma_floor=sigma_floor, k=k,\n",
    "        theta=dict(\n",
    "            consensus=dict(theta_star_cutoff=cut_cons, theta_star_grad=t_cons_grad, slope_at_grad=slope_cons),\n",
    "            dissent  =dict(theta_star_cutoff=cut_diss,  theta_star_grad=t_diss_grad, slope_at_grad=slope_diss),\n",
    "        ),\n",
    "        files=[\"summary_gra_invariance.csv\",\"anthropomorphism_separation.csv\"],\n",
    "        meta=dict(outdir=str(out), created_utc=utc_stamp(), version=os.environ.get(\"CNT_WP_RUN_VERSION\",\"v1.5\")),\n",
    "    )\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    curves_payload = dict(\n",
    "        temps=_as_list(temps),\n",
    "        mean_cons=_as_list(mean_cons),\n",
    "        diss_curve=_as_list(diss_curve),\n",
    "        grads_cons=_as_list(grads_cons),\n",
    "        grads_diss=_as_list(grads_diss),\n",
    "    )\n",
    "    (out/\"curves.json\").write_text(json.dumps(curves_payload, indent=2), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "# Wrapper: try original; on ambiguous-slope ValueError, fallback to safe LIVE\n",
    "def _run_v14_engine(target_outdir, cfg):\n",
    "    try:\n",
    "        return _rve_backup_safe(target_outdir, cfg)\n",
    "    except ValueError as e:\n",
    "        if \"ambiguous\" in str(e).lower() or \"truth value\" in str(e).lower():\n",
    "            print(\"⚠️ slope ambiguity caught — using robust LIVE path.\")\n",
    "            return _run_v14_engine_live_safe(target_outdir, cfg)\n",
    "        raise\n",
    "\n",
    "print(\"✓ JSON-safe LIVE writeout + slope-safe engine active.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d1fda0f4-19b0-4ec6-8507-e08edda41070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PING→ PONG\n",
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30 reps=16 perm=600 autoextend=True smooth=none\n",
      "\n",
      "⚙️  Running v1.5 (v1.4 merged) | model=gpt-4o-mini | out=E:\\CNT\\artifacts\\cnt_llm_weirdness_probe\\20251103-053038Z_live_stability_pp020_rep1\n",
      "⚠️ slope ambiguity caught — using robust LIVE path.\n"
     ]
    },
    {
     "ename": "ReadTimeout",
     "evalue": "HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=15.0)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 104\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_rve_backup_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 76\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     75\u001b[39m saved = cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m]; cfg = \u001b[38;5;28mdict\u001b[39m(cfg); cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33m\"\u001b[39m\u001b[33m__LIVE_GATE__\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m76\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m: \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_orig_force\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m: cfg[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m] = saved\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 268\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    251\u001b[39m idx[\u001b[33m\"\u001b[39m\u001b[33msep_df\u001b[39m\u001b[33m\"\u001b[39m].to_csv(out/\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m    253\u001b[39m manifest = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    254\u001b[39m     run_id=cfg[\u001b[33m\"\u001b[39m\u001b[33mrun_id\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    255\u001b[39m     llm_mode=llm_mode,\n\u001b[32m    256\u001b[39m     model=model_name,\n\u001b[32m    257\u001b[39m     temps=temps,\n\u001b[32m    258\u001b[39m     reps=reps,\n\u001b[32m    259\u001b[39m     perm=perm,\n\u001b[32m    260\u001b[39m     autoextend=autoextend,\n\u001b[32m    261\u001b[39m     smooth=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_SMOOTH\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mnone\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m    262\u001b[39m     sigma_floor=sigma_floor,\n\u001b[32m    263\u001b[39m     k=k,\n\u001b[32m    264\u001b[39m     theta=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    265\u001b[39m         consensus=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    266\u001b[39m             theta_star_cutoff=cut_cons,\n\u001b[32m    267\u001b[39m             theta_star_grad=theta_star_grad_cons,\n\u001b[32m--> \u001b[39m\u001b[32m268\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_cons[i_gc]) \u001b[38;5;28;01mif\u001b[39;00m grads_cons \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    269\u001b[39m         ),\n\u001b[32m    270\u001b[39m         dissent=\u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    271\u001b[39m             theta_star_cutoff=cut_diss,\n\u001b[32m    272\u001b[39m             theta_star_grad=theta_star_grad_diss,\n\u001b[32m    273\u001b[39m             slope_at_grad=\u001b[38;5;28mfloat\u001b[39m(grads_diss[i_gd]) \u001b[38;5;28;01mif\u001b[39;00m grads_diss \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    274\u001b[39m         ),\n\u001b[32m    275\u001b[39m     ),\n\u001b[32m    276\u001b[39m     files=[\u001b[33m\"\u001b[39m\u001b[33msummary_gra_invariance.csv\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33manthropomorphism_separation.csv\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m    277\u001b[39m     meta=\u001b[38;5;28mdict\u001b[39m(outdir=\u001b[38;5;28mstr\u001b[39m(out), created_utc=utc_stamp(), version=os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_RUN_VERSION\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mv1.5\u001b[39m\u001b[33m\"\u001b[39m)),\n\u001b[32m    278\u001b[39m )\n\u001b[32m    279\u001b[39m (out/\u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m).write_text(json.dumps(manifest, indent=\u001b[32m2\u001b[39m), encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mValueError\u001b[39m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:534\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    533\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m534\u001b[39m     response = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connection.py:565\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    564\u001b[39m \u001b[38;5;66;03m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m565\u001b[39m httplib_response = \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgetresponse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:1430\u001b[39m, in \u001b[36mHTTPConnection.getresponse\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1429\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1430\u001b[39m     \u001b[43mresponse\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1431\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:331\u001b[39m, in \u001b[36mHTTPResponse.begin\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    330\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m331\u001b[39m     version, status, reason = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_read_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    332\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m status != CONTINUE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\http\\client.py:292\u001b[39m, in \u001b[36mHTTPResponse._read_status\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    291\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_read_status\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m292\u001b[39m     line = \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_MAXLINE\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m, \u001b[33m\"\u001b[39m\u001b[33miso-8859-1\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    293\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(line) > _MAXLINE:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\socket.py:719\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    718\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m719\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    720\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1304\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1301\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1302\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1303\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1304\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1305\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\ssl.py:1138\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\util\\util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    535\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (BaseSSLError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m536\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread_timeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    537\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
      "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=15.0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mPING→\u001b[39m\u001b[33m\"\u001b[39m, _chat_completion(\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,[{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mReturn exactly: PONG\u001b[39m\u001b[33m\"\u001b[39m}],temperature=\u001b[32m0.0\u001b[39m,max_tokens=\u001b[32m4\u001b[39m))\n\u001b[32m     11\u001b[39m set_probe_env(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     12\u001b[39m               temps=\u001b[33m\"\u001b[39m\u001b[33m1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     13\u001b[39m               reps=\u001b[32m16\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m600\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m rd = \u001b[43mrun_with_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_stability_pp020_rep1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mWrote:\u001b[39m\u001b[33m\"\u001b[39m, rd)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_with_alias\u001b[39m\u001b[34m(model_id, alias, **kw)\u001b[39m\n\u001b[32m     32\u001b[39m outdir = ensure_dir(get_probe_base() / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutc_stamp()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(outdir)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m rd = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m os.environ.pop(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[38]\u001b[39m\u001b[32m, line 41\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m41\u001b[39m     rd = \u001b[43m_run_model_prev\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     42\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m         _fix_manifest_mode(rd)   \u001b[38;5;66;03m# from earlier patch\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 27\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_model\u001b[39m(model_name: \u001b[38;5;28mstr\u001b[39m, base_url=\u001b[38;5;28;01mNone\u001b[39;00m, *, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m200\u001b[39m) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m27\u001b[39m     rd = \u001b[43m_run_model_old\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mautoextend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[43mperm\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     28\u001b[39m     _fix_manifest_mode(rd)\n\u001b[32m     29\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 355\u001b[39m, in \u001b[36mrun_model\u001b[39m\u001b[34m(model_name, base_url, autoextend, perm)\u001b[39m\n\u001b[32m    340\u001b[39m cfg = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    341\u001b[39m     run_id=run_id,\n\u001b[32m    342\u001b[39m     model=model_name,\n\u001b[32m   (...)\u001b[39m\u001b[32m    351\u001b[39m     outdir=\u001b[38;5;28mstr\u001b[39m(target_out),\n\u001b[32m    352\u001b[39m )\n\u001b[32m    354\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m⚙️  Running v1.5 (v1.4 merged) | model=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m | out=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtarget_out\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m355\u001b[39m manifest = \u001b[43m_run_v14_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_out\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    357\u001b[39m manf = Path(target_out) / \u001b[33m\"\u001b[39m\u001b[33mrun_manifest.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m manf.exists():\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 108\u001b[39m, in \u001b[36m_run_v14_engine\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m    106\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mambiguous\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e).lower() \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mtruth value\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e).lower():\n\u001b[32m    107\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m⚠️ slope ambiguity caught — using robust LIVE path.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m108\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_run_v14_engine_live_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtarget_outdir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    109\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36m_run_v14_engine_live_safe\u001b[39m\u001b[34m(target_outdir, cfg)\u001b[39m\n\u001b[32m     20\u001b[39m temps = cfg[\u001b[33m\"\u001b[39m\u001b[33mtemps\u001b[39m\u001b[33m\"\u001b[39m]; reps = \u001b[38;5;28mint\u001b[39m(cfg[\u001b[33m\"\u001b[39m\u001b[33mreps\u001b[39m\u001b[33m\"\u001b[39m]); perm = \u001b[38;5;28mint\u001b[39m(cfg[\u001b[33m\"\u001b[39m\u001b[33mperm\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# 1) Probe curves\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m mean_cons, diss_curve = \u001b[43m_live_probe_curve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_BASE_URL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     26\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     29\u001b[39m \u001b[38;5;66;03m# 2) Derivatives & knees (use size checks; no truthiness on arrays)\u001b[39;00m\n\u001b[32m     30\u001b[39m grads_cons = _finite_diff(temps, mean_cons)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[70]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36m_live_probe_curve\u001b[39m\u001b[34m(model, *args, **kwargs)\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(model) == \u001b[33m\"\u001b[39m\u001b[33m__LIVE_GATE__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    106\u001b[39m     model = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mLLM_MODEL\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lpc_orig_bridge2\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[56]\u001b[39m\u001b[32m, line 14\u001b[39m, in \u001b[36m_live_probe_curve\u001b[39m\u001b[34m(model, *args, **kwargs)\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(model) == SENT:\n\u001b[32m     13\u001b[39m     model = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mLLM_MODEL\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_lpc_orig\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[45]\u001b[39m\u001b[32m, line 122\u001b[39m, in \u001b[36m_live_probe_curve\u001b[39m\u001b[34m(model, temps, reps, base_url, api_key, seed0)\u001b[39m\n\u001b[32m    119\u001b[39m     prompt = PROMPTS_CORE[(ti + r) % \u001b[38;5;28mlen\u001b[39m(PROMPTS_CORE)]\n\u001b[32m    120\u001b[39m     msgs = [{\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33mYou are a helpful, careful assistant.\u001b[39m\u001b[33m\"\u001b[39m},\n\u001b[32m    121\u001b[39m             {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m}]\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m     out = \u001b[43m_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m96\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    123\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    124\u001b[39m     outs.append(out \u001b[38;5;129;01mor\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    125\u001b[39m diversity = _pairwise_diversity(outs)      \u001b[38;5;66;03m# rises with temperature\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 55\u001b[39m, in \u001b[36m_chat_completion\u001b[39m\u001b[34m(model, messages, temperature, max_tokens, seed, base_url, api_key)\u001b[39m\n\u001b[32m     53\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m: \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[32m     54\u001b[39m t0 = time.time()\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m r = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNT_WP_HTTP_TIMEOUT\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m r.status_code == \u001b[32m200\u001b[39m:\n\u001b[32m     57\u001b[39m     data = r.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\api.py:115\u001b[39m, in \u001b[36mpost\u001b[39m\u001b[34m(url, data, json, **kwargs)\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpost\u001b[39m(url, data=\u001b[38;5;28;01mNone\u001b[39;00m, json=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m    104\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a POST request.\u001b[39;00m\n\u001b[32m    105\u001b[39m \n\u001b[32m    106\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    112\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m    113\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m115\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpost\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\requests\\adapters.py:690\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    688\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    689\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m690\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    691\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n\u001b[32m    692\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m InvalidHeader(e, request=request)\n",
      "\u001b[31mReadTimeout\u001b[39m: HTTPSConnectionPool(host='api.openai.com', port=443): Read timed out. (read timeout=15.0)"
     ]
    }
   ],
   "source": [
    "# house knobs (as before)\n",
    "import os\n",
    "os.environ[\"CNT_FORCE_LIVE\"]   = \"1\"\n",
    "os.environ[\"CNT_WP_INV_TREF\"]  = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]     = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]= \"0.20\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]= \"128\"\n",
    "\n",
    "print(\"PING→\", _chat_completion(\"gpt-4o-mini\",[{\"role\":\"user\",\"content\":\"Return exactly: PONG\"}],temperature=0.0,max_tokens=4))\n",
    "\n",
    "set_probe_env(model=\"gpt-4o-mini\",\n",
    "              temps=\"1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30\",\n",
    "              reps=16, autoextend=True, perm=600)\n",
    "rd = run_with_alias(\"gpt-4o-mini\",\"live_stability_pp020_rep1\", autoextend=True, perm=600)\n",
    "print(\"Wrote:\", rd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "06f81cc1-147e-4e7e-9a8d-913b2bfe58ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Installed hard override: SAFE engine + JSON-safe curves + robust HTTP + peak/turbulence dissent.\n"
     ]
    }
   ],
   "source": [
    "# ===================== HARD RESET: client + probe + engine =====================\n",
    "import os, time, json, math, numpy as np, requests\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "# ---- global knobs (adjust if needed)\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_TIMEOUT\",   \"45\")   # seconds per request\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_RETRIES\",   \"2\")    # 0..N, exponential backoff\n",
    "os.environ.setdefault(\"CNT_WP_HTTP_DEBUG\",     \"1\")    # '1' to log non-200 or exceptions\n",
    "os.environ.setdefault(\"CNT_WP_TOP_P\",          \"0.95\") # sampler breadth\n",
    "os.environ.setdefault(\"CNT_WP_FREQ_P\",         \"0.00\") # frequency_penalty\n",
    "os.environ.setdefault(\"CNT_WP_PRESENCE_P\",     \"0.20\") # presence_penalty for probe\n",
    "os.environ.setdefault(\"CNT_WP_MAX_TOKENS\",     \"128\")  # response headroom\n",
    "os.environ.setdefault(\"CNT_WP_INV_TEMP\",       \"0.20\") # cold invariance t_ref\n",
    "os.environ.setdefault(\"CNT_WP_FORCE_LIVE\",     \"1\")    # hard-bypass legacy path\n",
    "\n",
    "# ---- minimal helpers\n",
    "def _as_list(x):\n",
    "    try:    return [float(v) for v in list(x)]\n",
    "    except: return [float(x)] if np.isscalar(x) else list(x)\n",
    "\n",
    "def _tok(s): \n",
    "    import re\n",
    "    return [w.lower() for w in re.findall(r\"[A-Za-z0-9']+\", s or \"\")]\n",
    "\n",
    "def _vec(tokens):\n",
    "    c = Counter(tokens); return c, set(c.keys())\n",
    "\n",
    "def _cosine(a: Counter, b: Counter):\n",
    "    if not a or not b: return 0.0\n",
    "    ka, kb = set(a.keys()), set(b.keys())\n",
    "    num = sum(a[k]*b[k] for k in ka & kb)\n",
    "    den = math.sqrt(sum(v*v for v in a.values())) * math.sqrt(sum(v*v for v in b.values()))\n",
    "    return (num/den) if den else 0.0\n",
    "\n",
    "def _jaccard(sa:set, sb:set):\n",
    "    if not sa and not sb: return 1.0\n",
    "    u = len(sa | sb); i = len(sa & sb)\n",
    "    return (i/u) if u else 1.0\n",
    "\n",
    "def _finite_diff(xs, ys):\n",
    "    xs = np.asarray(xs, float); ys = np.asarray(ys, float)\n",
    "    n = len(xs); g = np.zeros(n, float)\n",
    "    if n < 2: return g\n",
    "    for i in range(n):\n",
    "        if   i==0:     dx = xs[1]-xs[0];     g[i]=(ys[1]-ys[0])/(dx if dx else 1.0)\n",
    "        elif i==n-1:   dx = xs[-1]-xs[-2];   g[i]=(ys[-1]-ys[-1])/(dx if dx else 1.0)\n",
    "        else:          dx = xs[i+1]-xs[i-1]; g[i]=(ys[i+1]-ys[i-1])/(dx if dx else 1.0)\n",
    "    return g\n",
    "\n",
    "# ---- bulletproof HTTP client: no recursion, with retries, never raises\n",
    "def _chat_completion(model, messages, *, temperature=0.7, max_tokens=None, seed=None,\n",
    "                     base_url=None, api_key=None):\n",
    "    base = base_url or os.environ.get(\"OPENAI_BASE_URL\", \"https://api.openai.com/v1\")\n",
    "    key  = api_key  or os.environ.get(\"OPENAI_API_KEY\", \"\")\n",
    "    url  = base.rstrip(\"/\") + \"/chat/completions\"\n",
    "    headers = {\"Authorization\": f\"Bearer {key}\", \"Content-Type\": \"application/json\"}\n",
    "\n",
    "    payload = {\n",
    "        \"model\": str(model),\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"top\": float(os.environ.get(\"CNT_WP_TOP_P\",\"1.0\")),\n",
    "        \"top_p\": float(os.environ.get(\"CNT_WP_TOP_P\",\"1.0\")),\n",
    "        \"frequency_penalty\": float(os.environ.get(\"CNT_WP_FREQ_P\",\"0.0\")),\n",
    "        \"presence_penalty\":  float(os.environ.get(\"CNT_WP_PRESENCE_P\",\"0.0\")),\n",
    "        \"max_tokens\": int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")) if max_tokens is None else int(max_tokens),\n",
    "    }\n",
    "    if seed is not None:\n",
    "        try: payload[\"seed\"] = int(seed)\n",
    "        except: pass\n",
    "\n",
    "    timeout = float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"45\"))\n",
    "    retries = int(os.environ.get(\"CNT_WP_HTTP_RETRIES\",\"1\"))\n",
    "    debug   = os.environ.get(\"CNT_WP_HTTP_DEBUG\") == \"1\"\n",
    "\n",
    "    for attempt in range(retries + 1):\n",
    "        try:\n",
    "            resp = requests.post(url, json=payload, headers={'Authorization': headers['Authorization'],'Content-Type':'application/json'}, timeout=timeout)\n",
    "            if resp.status_code == 200:\n",
    "                data = resp.json()\n",
    "                return (data.get(\"message\",{}) or data.get(\"choices\",[{}])[0].get(\"message\",{})).get(\"content\",\"\").strip()\n",
    "            else:\n",
    "                if debug:\n",
    "                    print(f\"[HTTP {resp.status_code}] {resp.text[:200].replace(chr(10),' ')}\")\n",
    "        except Exception as e:\n",
    "            if debug:\n",
    "                print(f\"[HTTP err try#{attempt+1}] {type(e).__name__}: {e}\")\n",
    "        time.sleep(0.75 * (attempt + 1))\n",
    "    return \"\"  # never raise\n",
    "\n",
    "# ---- robust LIVE probe: consensus=pairwise diversity; dissent=turbulence=disp*(1-cons); tolerant to empties\n",
    "def _probe_live_robust(model, temps, reps, base_url=None, api_key=None, seed0=1337):\n",
    "    rng = np.random.default_rng(int(seed0))\n",
    "    mean_cons, diss_curve, empties = [], [], []\n",
    "    for ti, t in enumerate(temps):\n",
    "        outs = []\n",
    "        empty = 0\n",
    "        for r in range(reps):\n",
    "            prompt = PROMPTS_CORE[(ti + r) % len(PROMPTS_CORE)]\n",
    "            msgs   = [ {\"role\":\"system\",\"content\": SYSTEM_LIVE},\n",
    "                       {\"role\":\"user\",  \"content\": f\"{BASE_USER}\\n\\nTask: {prompt}\"} ]\n",
    "            out = _chat_completion(model, msgs, temperature=float(t),\n",
    "                                   max_tokens=int(os.environ.get(\"CNT_WP_MAX_TOKENS\",\"128\")),\n",
    "                                   seed=int(rng.integers(0,1_000_000)),\n",
    "                                   base_url=base_url, api_key=api_key)\n",
    "            if not out: empty += 1\n",
    "            else:       outs.append(out)\n",
    "        empties.append(empty / max(1,reps))\n",
    "        if len(outs) < 2:\n",
    "            mean_cons.append(0.0);  # no signal if all empty\n",
    "            diss_curve.append(0.0)\n",
    "            continue\n",
    "        # consensus: average 1 - sim\n",
    "        sims = []\n",
    "        vecs = [(_vec(_tok(s))) for s in outs]\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1, len(vecs)):\n",
    "                (c1,s1),(c2,s2) = vecs[i], vecs[j]\n",
    "                sims.append(0.6*_cosine(c1,c2) + 0.4*_jaccard(s1,s2))\n",
    "        cons = max(0.0, min(1.0, 1.0 - (np.mean(sims) if sims else 0.0)))\n",
    "        # dispersion: median distance\n",
    "        dists=[]\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1, len(vecs)):\n",
    "                (c1,s1),(c2,s2) = vecs[i], vecs[j]\n",
    "                sim = 0.6*_cosine(c1,c2)+0.4*_jaccard(s1,s2)\n",
    "                dists.append(1.0 - sim)\n",
    "        disp = float(np.median(dists)) if dists else 0.0\n",
    "        mean_cons.append(float(cons))\n",
    "        diss = disp * (1.0 - cons)\n",
    "        diss_curve.append(float(diss))\n",
    "    # normalize dissent for stability\n",
    "    if any(diss_curve):\n",
    "        m = max(diss_curve); \n",
    "        diss_curve = [ (d/m if m>0 else 0.0) for d in diss_curve ]\n",
    "    return mean_cons, diss_curve, empties\n",
    "\n",
    "# ---- JSON-safe LIVE engine, fully overriding legacy when CNT_WP_FORCE_LIVE=1\n",
    "def _run_v14_engine_SAFE(target_outdir, cfg):\n",
    "    from datetime import datetime, timezone\n",
    "    def utc_stamp(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "    model_in = str(cfg[\"model\"])\n",
    "    model_id = os.environ.get(\"LLM_MODEL\", model_in) if model_in == \"__LIVE_GATE__\" else model_in\n",
    "    temps    = list(cfg[\"broadened_temps\"] if \"broadened_temps\" in cfg else cfg[\"temps\"])\n",
    "    reps     = int(cfg[\"reps\"]); perm = int(cfg[\"time_budget_retries\"]) if \"time_budget_retries\" in cfg else int(cfg[\"reps\"])\n",
    "\n",
    "    # probe\n",
    "    mean_cons, diss_curve, empties = _probe_live_robust(\n",
    "        model_id, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        seed0=1337\n",
    "    )\n",
    "    gC = _finite_diff(temps, mean_cons)\n",
    "    gD = _finite_diff(temps, diss_curve)\n",
    "\n",
    "    iC = int(np.argmax(np.abs(gC))) if len(gC) else 0\n",
    "    iD = int(np.argmax(np.abs(gD))) if len(gD) else 0\n",
    "    tC = float(temps[iC]) if len(temps) else None\n",
    "    tD = float(temps[iD]) if len(temps) else None\n",
    "\n",
    "    # cutoffs (robust: baseline over first 3 temps)\n",
    "    baseline_pts = min(3, len(temps)) or 1\n",
    "    mu = float(np.mean(mean_cons[:baseline_pts])) if baseline_pts else 0.0\n",
    "    sd = float(np.std (mean_cons[:baseline_pts], ddof=1)) if baseline_pts>1 else 0.0\n",
    "    thr = mu + max(float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\",\"0.015\")), float(os.environ.get(\"CNT_WP_K\",\"2.5\")) * (sd if sd>1e-6 else 0.01))\n",
    "    cutC = None\n",
    "    for i,(t,m) in enumerate(temps):\n",
    "        pass\n",
    "    # Fix: iterate correctly\n",
    "    cutC = None\n",
    "    for i in range(len(temps)):\n",
    "        if i==0: \n",
    "            continue\n",
    "        if mean_cons[i] >= thr:\n",
    "            cutC = float(temps[i]); break\n",
    "    if cutC is None and len(temps):\n",
    "        cutC = float(temps[-1])\n",
    "\n",
    "    cutD = float(temps[iD]) if len(temps) else None\n",
    "    for j in range(iD, len(diss_curve)-1):\n",
    "        if diss_curve[j+1] < diss_curve[j] - 0.05:\n",
    "            cutD = float(temps[j+1]); break\n",
    "\n",
    "    # invariance & ASI (cold)\n",
    "    from math import isnan\n",
    "    inv_t = float(os.environ.get(\"CNT_WP_INV_TEMP\",\"0.20\"))\n",
    "    inv_idx = _live_invariance_and_asi(model_id, temps, reps,\n",
    "                                       base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "                                       api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "                                       seed0=2025)\n",
    "    out = ensure_dir(target_outdir)\n",
    "    inv_df = inv_idx[\"lru_inv_df\"] if \"lru_inv_df\" in inv_idx else inv_idx[\"inv_df\"]\n",
    "    sep_df = inv_idx[\"lru_sep_df\"] if \"lru_inv_df\" in inv_idx else inv_idx[\"sep_df\"]\n",
    "    inv_df.to_csv(out/\"ed_summary_gra_invariance.csv\", index=False)\n",
    "    sep_df.to_csv(out/\"ed_anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    manifest = dict(\n",
    "        run_id=cfg[\"run_id\"], llm_mode=\"LIVE\", model=model_id,\n",
    "        temps=_as_list(temps), reps=reps, perm=perm, autoextend=bool(cfg.get(\"autoextend\", True)),\n",
    "        smooth=os.environ.get(\"CNT_WP_SMOOTH\",\"none\"),\n",
    "        sigma_floor=float(os.environ.get(\"CNT_WP_SIGA\",\"0.0\")), # tag\n",
    "        k=float(os.environ.get(\"CNT_WP_K\",\"2.5\")),\n",
    "        theta=dict(\n",
    "            consensus=dict(theta_star_cutoff=cutC, theta_star_grad=tC, slope_at_grad=float(gC[iC]) if len(gC) else None),\n",
    "            dissent  =dict(theta_star_cutoff=cutD, theta_star_grad=tD, slope_at_grad=float(gD[iD]) if len(gD) else None),\n",
    "        ),\n",
    "        files=[\"ed_summary_gra_invariance.csv\",\"ed_anthropomorphism_separation.csv\"],\n",
    "        meta=dict(outdir=str(out), created_utc=utc_stamp(), version=os.environ.get(\"CNT_WP_RUN_VERSION\",\"v1.5\"),\n",
    "                  empty_rate=_as_list(empties), note=\"SAFE_ENGINE_JSON\")\n",
    "    )\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps(dict(\n",
    "        temps=_as_list(temps), mean_cons=_as_list(mean_cons), diss_curve=_as_list(diss_curve),\n",
    "        grads_cons=_as_list(gC),   grads_diss=_as_list(gD)\n",
    "    ), indent=2), encoding=\"utf-8\")\n",
    "    return manifest\n",
    "\n",
    "# hard override: never call legacy path while forcing live\n",
    "_rve_legacy = globals().get(\"_rve_backup_safe\")\n",
    "def _run_v14_engine(target_outdir, cfg):\n",
    "    if os.environ.get(\"CNT_FORCE_LIVE\",\"0\") == \"1\":\n",
    "        # allow optional mild broadening/override fields in cfg\n",
    "        return _run_v14_engine_SAFE(target_outdir, cfg)\n",
    "    # fallback to original when not forcing\n",
    "    return _rve_legac(target_outdir, cfg) if _rve_legacy else _run_v14_engine_SAFE(target_outdir, cfg)\n",
    "\n",
    "print(\"✓ Installed hard override: SAFE engine + JSON-safe curves + robust HTTP + peak/turbulence dissent.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "74c13c39-8bb9-470a-800d-d8d9d4ff5855",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Env set | model=gpt-4o-mini temps=1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30 reps=12 perm=400 autoextend=True smooth=none\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "run_model() got an unexpected keyword argument 'autoexpand'. Did you mean 'autoextend'?",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 34\u001b[39m\n\u001b[32m     31\u001b[39m     asi  = \u001b[38;5;28mfloat\u001b[39m(sep[\u001b[33m\"\u001b[39m\u001b[33mseparation_index\u001b[39m\u001b[33m\"\u001b[39m].mean())\n\u001b[32m     32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mrun\u001b[39m\u001b[33m\"\u001b[39m: Path(rd).name, \u001b[33m\"\u001b[39m\u001b[33mwidth\u001b[39m\u001b[33m\"\u001b[39m:width, \u001b[33m\"\u001b[39m\u001b[33mips\u001b[39m\u001b[33m\"\u001b[39m:ips, \u001b[33m\"\u001b[39m\u001b[33masi\u001b[39m\u001b[33m\"\u001b[39m:asi, \u001b[33m\"\u001b[39m\u001b[33mknee\u001b[39m\u001b[33m\"\u001b[39m:tC, \u001b[33m\"\u001b[39m\u001b[33mdpeak\u001b[39m\u001b[33m\"\u001b[39m:tD, \u001b[33m\"\u001b[39m\u001b[33mrd\u001b[39m\u001b[33m\"\u001b[39m:rd}\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m r1 = summarize(\u001b[43mrun_stability_once\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_stability_pp020_r1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m     35\u001b[39m r2 = summarize(run_stability_once(\u001b[33m\"\u001b[39m\u001b[33mlive_stability_pp020_r2\u001b[39m\u001b[33m\"\u001b[39m))\n\u001b[32m     37\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[75]\u001b[39m\u001b[32m, line 15\u001b[39m, in \u001b[36mrun_stability_once\u001b[39m\u001b[34m(tag)\u001b[39m\n\u001b[32m     12\u001b[39m temps = [\u001b[32m1.18\u001b[39m,\u001b[32m1.20\u001b[39m,\u001b[32m1.21\u001b[39m,\u001b[32m1.22\u001b[39m,\u001b[32m1.23\u001b[39m,\u001b[32m1.24\u001b[39m,\u001b[32m1.25\u001b[39m,\u001b[32m1.26\u001b[39m,\u001b[32m1.27\u001b[39m,\u001b[32m1.30\u001b[39m]  \u001b[38;5;66;03m# fineband, trimmed\u001b[39;00m\n\u001b[32m     13\u001b[39m set_probe_env(model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temps=\u001b[33m\"\u001b[39m\u001b[33m,\u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m temps),\n\u001b[32m     14\u001b[39m               reps=\u001b[32m12\u001b[39m, autoextend=\u001b[38;5;28;01mTrue\u001b[39;00m, perm=\u001b[32m400\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m rd = \u001b[43mrun_with_alias\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mautoexpand\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[52]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mrun_with_alias\u001b[39m\u001b[34m(model_id, alias, **kw)\u001b[39m\n\u001b[32m     32\u001b[39m outdir = ensure_dir(get_probe_base() / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mutc_stamp()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00malias\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     33\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28mstr\u001b[39m(outdir)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m rd = \u001b[43mrun_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m os.environ.pop(\u001b[33m\"\u001b[39m\u001b[33mCNT_WP_OUTDIR_HINT\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     36\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m rd\n",
      "\u001b[31mTypeError\u001b[39m: run_model() got an unexpected keyword argument 'autoexpand'. Did you mean 'autoextend'?"
     ]
    }
   ],
   "source": [
    "# Reduced but diagnostic-equivalent stability pass\n",
    "os.environ[\"CNT_WP_INV_TEM P\"]   = \"0.20\"\n",
    "os.environ[\"CNT_WP_TOP_P\"]       = \"0.95\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"]  = \"0.20\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"]  = \"128\"\n",
    "os.environ[\"CNT_WP_HTTP_TIMEOUT\"]= \"45\"\n",
    "os.environ[\"CNT_WP_HTTP_RETRIES\"]= \"2\"\n",
    "os.environ[\"CNT_WP_HTTP_DEBUG\"]  = \"1\"\n",
    "os.environ[\"CNT_FORCE_LIVE\"]     = \"1\"\n",
    "\n",
    "def run_stability_once(tag):\n",
    "    temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30]  # fineband, trimmed\n",
    "    set_probe_env(model=\"gpt-4o-mini\", temps=\",\".join(f\"{t:.2f}\" for t in temps),\n",
    "                  reps=12, autoextend=True, perm=400)\n",
    "    rd = run_with_alias(\"gpt-4o-mini\", tag, autoexpand=True, perm=400)\n",
    "    return rd\n",
    "\n",
    "def summarize(rd):\n",
    "    import json, numpy as np, pandas as pd\n",
    "    from pathlib import Path\n",
    "    data = json.loads((Path(rd)/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    m    = json.loads((Path(rd)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    gC   = np.array(data[\"grads_cons\"]); gD = np.array(data[\"grads_diss\"])\n",
    "    temps= np.array(data[\"temps\"], float)\n",
    "    tC   = float(temps[int(np.argmax(np.abs(gC)))])\n",
    "    tD   = float(temps[int(np.argmax(gD))])\n",
    "    width= max(0.0, tD - tC)\n",
    "    inv  = pd.read_csv(Path(rd)/\"ed_summary_gra_invariance.csv\")\n",
    "    sep  = pd.read_csv(Path(rd)/\"ed_anthropomorphism_separation.csv\")\n",
    "    ips  = float(inv[\"inv_index_overall\"].mean())\n",
    "    asi  = float(sep[\"separation_index\"].mean())\n",
    "    return {\"run\": Path(rd).name, \"width\":width, \"ips\":ips, \"asi\":asi, \"knee\":tC, \"dpeak\":tD, \"rd\":rd}\n",
    "\n",
    "r1 = summarize(run_stability_once(\"live_stability_pp020_r1\"))\n",
    "r2 = summarize(run_stability_once(\"live_stability_pp020_r2\"))\n",
    "\n",
    "import pandas as pd\n",
    "stab2 = pd.DataFrame([r1,r2]); display(stab2)\n",
    "print(f\"Widths: {stab2.width.values}  IPS: {stab2.ips.values}  ASI: {stab2.asi.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "42e04c78-80bd-4759-911b-75247b5d23f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix env typo\n",
    "os.environ[\"CNT_WP_INV_TEMP\"] = \"0.20\"   # <-- no space in the key\n",
    "# fix the param typo in your helper call (use autoextend, not autoexpand)\n",
    "# r1 = run_with_alias(\"gpt-4o-mini\", f\"{alias}_rep1\", autoextend=True, perm=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ac30c04c-7afc-4c1e-b02c-bc4ee8b70331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === DIRECT LIVE RUN (robust, JSON-safe, uses robust _chat_completion & _probe_live_robust) ===\n",
    "import os, json, numpy as np, pandas as pd, math, time\n",
    "from pathlib import Path\n",
    "from collections import Counter\n",
    "\n",
    "def direct_live_run(tag, *, model=\"gpt-4o-mini\", temps=None, reps=12, inv_temp=0.20):\n",
    "    # --- wiring & output folder\n",
    "    base = Path(os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\") / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    out  = base / f\"{utc_stamp()}_{tag}\"\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # --- defaults\n",
    "    if temps is None:\n",
    "        temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30]\n",
    "    temps = [float(t) for t in temps]\n",
    "\n",
    "    # --- probe consensus/dissent (robust & tolerant)\n",
    "    mean_cons, diss_curve, empties = _probe_live_robust(\n",
    "        model, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        seed0=int(time.time()*1000) % 2_000_000_000\n",
    "    )\n",
    "\n",
    "    # --- compute knees & cutoffs\n",
    "    def finite_diff(xs, ys):\n",
    "        xs = np.asarray(xs, float); ys = np.asarray(ys, float)\n",
    "        n  = len(xs)\n",
    "        g  = np.zeros(n, float)\n",
    "        if n < 2: return g\n",
    "        for i in range(n):\n",
    "            if   i==0:     dx = xs[1]-xs[0];     g[i]=(ys[1]-ys[0])/(dx if dx else 1.0)\n",
    "            elif i==n-1:   dx = xs[-1]-xs[-2];   g[i]=(ys[-1]-ys[-1])/(dx if dx else 1.0)\n",
    "            else:          dx = xs[i+1]-xs[i-1]; g[i]=(ys[i+1]-ys[i-1])/(dx if dx else 1.0)\n",
    "        return g\n",
    "\n",
    "    gC = finite_diff(temps, mean_cons)\n",
    "    gD = finite_diff(temps, diss_curve)\n",
    "    iC = int(np.argmax(np.abs(gC))) if len(gC) else 0\n",
    "    iD = int(np.argmax(diss_curve)) if len(diss_curve) else 0\n",
    "    tC = float(temps[iC]) if temps else None\n",
    "    tD = float(temps[iD]) if temps else None\n",
    "\n",
    "    # baseline-cutoff for consensus\n",
    "    bN  = min(3, len(temps)) or 1\n",
    "    mu  = float(np.mean(mean_cons[:bN])) if bN else 0.0\n",
    "    sd  = float(np.std (mean_cons[:bN], ddof=1)) if bN>1 else 0.0\n",
    "    thr = mu + max(float(os.environ.get(\"CNT_WP_SIGMA_FLOOR\",\"0.015\")), float(os.environ.get(\"CNT_WP_K\",\"2.5\")) * (sd if sd>1e-6 else 0.01))\n",
    "    cutC = None\n",
    "    for k in range(1, len(temps)):\n",
    "        if mean_cons[k] >= thr:\n",
    "            cutC = float(temps[k]); break\n",
    "    if cutC is None and temps:\n",
    "        cutC = float(temps[-1])\n",
    "    # dissent cutoff at start of decay\n",
    "    cutD = float(temps[iD]) if temps else None\n",
    "    for k in range(iD, len(diss_curve)-1):\n",
    "        if diss_curve[k+1] < diss_curve[k] - 0.05:\n",
    "            cutD = float(temps[k+1]); break\n",
    "\n",
    "    # --- invariance & ASI at cold t_ref\n",
    "    inv = _live_invariance_and_asi(\n",
    "        model, temps, reps,\n",
    "        base_url=os.environ.get(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "        # make sure your _live_invariance_and_asi reads CNT_WP_INV_TEMP or accepts inv_temp\n",
    "        # if it uses env: \n",
    "    )\n",
    "    inv_df = inv.get(\"inv_df\") or inv.get(\"lru_inv_df\")\n",
    "    sep_df = inv.get(\"sep_df\") or inv.get(\"lru_sep_df\")\n",
    "\n",
    "    # --- write standard files for board compatibility\n",
    "    inv_df.to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    sep_df.to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    # --- manifest + curves (JSON-safe)\n",
    "    manifest = {\n",
    "        \"run_id\": out.name,\n",
    "        \"llm_mode\": \"LIVE\",\n",
    "        \"model\": model,\n",
    "        \"temps\": [float(t) for t in temps],\n",
    "        \"reps\": int(reps),\n",
    "        \"perm\": int(os.environ.get(\"CNT_WP_PERM\",\"0\")),\n",
    "        \"autoextend\": True,\n",
    "        \"smooth\": os.environ.get(\"CNT_WP_SMOOTH\",\"none\"),\n",
    "        \"sigma_floor\": float(os.environ.get(\"CNT_WP_SIGA\",\"0.0\")),\n",
    "        \"k\": float(os.environ.get(\"CNT_WP_K\",\"2.5\")),\n",
    "        \"theta\": {\n",
    "            \"consensus\": {\"theta_star_cutoff\": cutC, \"theta_star_grad\": tC, \"slope_at_grad\": float(gC[iC]) if len(gC) else None},\n",
    "            \"dissent\":   {\"theta_star_cutoff\": cutD, \"theta_star_grad\": tD, \"slope_at_grad\": float(gD[iD]) if len(gD) else None},\n",
    "        },\n",
    "        \"derived\": {\"edge_window_width\": max(0.0, (tD - tC) if (tD and tC) else 0.0)},\n",
    "        \"files\": [\"summary_gra_invariance.csv\",\"anthropomorphism_separation.csv\"],\n",
    "        \"meta\": {\n",
    "            \"outdir\": str(out),\n",
    "            \"created_utc\": utc_stamp(),\n",
    "            \"version\": os.environ.get(\"CNT_WP_RUN_VERSION\",\"v1.5\"),\n",
    "            \"empty_rate\": [float(e) for e in empties]\n",
    "        }\n",
    "    }\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps({\n",
    "        \"temps\":        [float(t) for t in temps],\n",
    "        \"mean_cons\":    [float(x) for x in mean_cons],\n",
    "        \"diss_curve\":   [float(x) for x in diss_curve],\n",
    "        \"grads_cons\":   [float(x) for x in gC],\n",
    "        \"grads_diss\":   [float(x) for x in gD],\n",
    "        \"empty_frac\":   [float(e) for e in empties],\n",
    "    }, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "    # also drop a quick debug CSV for the crest plot\n",
    "    pd.DataFrame({\"temp\":temps,\"mean_cons\":mean_cons,\"diss_curve\":diss_curve,\"empty_frac\":empties}).to_csv(out/\"live_probe_debug.csv\", index=False)\n",
    "    return str(out)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fdf0e27f-0839-440b-8f80-4b1ef7c9fc72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n",
      "[HTTP 400] {   \"error\": {     \"message\": \"Unrecognized request argument supplied: top\",     \"type\": \"invalid_request_error\",     \"param\": null,     \"code\": null   } }\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[78]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Two direct runs (trimmed ladder, fewer calls)\u001b[39;00m\n\u001b[32m      8\u001b[39m temps = [\u001b[32m1.18\u001b[39m,\u001b[32m1.20\u001b[39m,\u001b[32m1.21\u001b[39m,\u001b[32m1.22\u001b[39m,\u001b[32m1.23\u001b[39m,\u001b[32m1.24\u001b[39m,\u001b[32m1.25\u001b[39m,\u001b[32m1.26\u001b[39m,\u001b[32m1.27\u001b[39m,\u001b[32m1.30\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m rd1 = \u001b[43mdirect_live_run\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlive_stability_pp020_r1\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4o-mini\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m12\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minv_temp\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m rd2 = direct_live_run(\u001b[33m\"\u001b[39m\u001b[33mlive_stability_pp020_r2\u001b[39m\u001b[33m\"\u001b[39m, model=\u001b[33m\"\u001b[39m\u001b[33mgpt-4o-mini\u001b[39m\u001b[33m\"\u001b[39m, temps=temps, reps=\u001b[32m12\u001b[39m, inv_temp=\u001b[32m0.20\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Summarize\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 18\u001b[39m, in \u001b[36mdirect_live_run\u001b[39m\u001b[34m(tag, model, temps, reps, inv_temp)\u001b[39m\n\u001b[32m     15\u001b[39m temps = [\u001b[38;5;28mfloat\u001b[39m(t) \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m temps]\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# --- probe consensus/dissent (robust & tolerant)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m mean_cons, diss_curve, empties = \u001b[43m_probe_live_robust\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_BASE_URL\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mOPENAI_API_KEY\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseed0\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m*\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m%\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m2_000_000_000\u001b[39;49m\n\u001b[32m     23\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[38;5;66;03m# --- compute knees & cutoffs\u001b[39;00m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfinite_diff\u001b[39m(xs, ys):\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 103\u001b[39m, in \u001b[36m_probe_live_robust\u001b[39m\u001b[34m(model, temps, reps, base_url, api_key, seed0)\u001b[39m\n\u001b[32m    100\u001b[39m prompt = PROMPTS_CORE[(ti + r) % \u001b[38;5;28mlen\u001b[39m(PROMPTS_CORE)]\n\u001b[32m    101\u001b[39m msgs   = [ {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33msystem\u001b[39m\u001b[33m\"\u001b[39m,\u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: SYSTEM_LIVE},\n\u001b[32m    102\u001b[39m            {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m:\u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m,  \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBASE_USER\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mTask: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m} ]\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m out = \u001b[43m_chat_completion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmsgs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mfloat\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    104\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43menviron\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mCNT_WP_MAX_TOKENS\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m128\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    105\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mrng\u001b[49m\u001b[43m.\u001b[49m\u001b[43mintegers\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m1_000_000\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    106\u001b[39m \u001b[43m                       \u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbase_url\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m=\u001b[49m\u001b[43mapi_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out: empty += \u001b[32m1\u001b[39m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:       outs.append(out)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 89\u001b[39m, in \u001b[36m_chat_completion\u001b[39m\u001b[34m(model, messages, temperature, max_tokens, seed, base_url, api_key)\u001b[39m\n\u001b[32m     87\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m debug:\n\u001b[32m     88\u001b[39m             \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[HTTP err try#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mattempt+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(e).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.75\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mattempt\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     90\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Sampler for probe; IPS stays cold via CNT_WP_INV_TEMP\n",
    "os.environ[\"CNT_WP_TOP_P\"]      = \"0.85\"\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"] = \"0.20\"\n",
    "os.environ[\"CNT_WP_MAX_TOKENS\"] = \"128\"\n",
    "os.environ[\"CNT_FORCE_LIVE\"]    = \"1\"   # keep robust path\n",
    "\n",
    "# Two direct runs (trimmed ladder, fewer calls)\n",
    "temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30]\n",
    "rd1 = direct_live_run(\"live_stability_pp020_r1\", model=\"gpt-4o-mini\", temps=temps, reps=12, inv_temp=0.20)\n",
    "rd2 = direct_live_run(\"live_stability_pp020_r2\", model=\"gpt-4o-mini\", temps=temps, reps=12, inv_temp=0.20)\n",
    "\n",
    "# Summarize\n",
    "def summarize(rd):\n",
    "    import json, numpy as np, pandas as pd\n",
    "    from pathlib import Path\n",
    "    data = json.loads((Path(rd)/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    m    = json.loads((Path(rd)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps= np.array(data[\"temps\"], float)\n",
    "    gC   = np.array(data[\"grads\"], float) if \"grads\" in data else np.array(data[\"grads_cons\"], float)\n",
    "    dC   = np.array(data[\"diss_curve\"], float)\n",
    "    iC   = int(np.argmax(np.abs(gC))) if gC.size else 0\n",
    "    iD   = int(np.argmax(dC)) if dC.size else 0\n",
    "    tC   = float(temps[iC]) if temps.size else np.nan\n",
    "    tD   = float(temps[iD]) if temps.size else np.nan\n",
    "    width= max(0.0, (tD - tC) if (tD==tD and tC==tC) else 0.0)\n",
    "    inv  = pd.read_csv(Path(rd)/\"summary_gra_invariance.csv\")\n",
    "    sep  = pd.read_csv(Path(rd)/\"anthropomorphism_separation.csv\")\n",
    "    ips  = float(inv[\"inv_index_overall\"].mean())\n",
    "    asi  = float(sep[\"separation_index\"].mean())\n",
    "    return {\"run\": Path(rd).name, \"width\":width, \"ips\":ips, \"asi\":asi, \"knee\":tC, \"dpeak\":tD, \"rd\":rd}\n",
    "\n",
    "import pandas as pd\n",
    "stab2 = pd.DataFrame([summarize(rd1), summarize(rd2)])\n",
    "display(stab2)\n",
    "print(f\"Widths: {stab2.width.values}  IPS: {stab2.ips.values}  ASI: {stab2.asi.values}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f510d71b-8b22-4675-abc2-df44523b9c26",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (119517665.py, line 155)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 155\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mouts.append( http://http_chat(model, msgs, temperature=t_ref, top_p=0.95,\u001b[39m\n                     ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# === CLEAN-RUNNER: Robust LIVE crest run, JSON-safe, no legacy deps ===\n",
    "import os, time, math, json, random, textwrap, statistics\n",
    "from pathlib import Path\n",
    "import requests, numpy as np, pandas as pd\n",
    "\n",
    "# ---- Defaults / knobs (you can tweak these) ----\n",
    "MODEL              = os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "BASE_URL           = os.environ.get(\"OPENAI_API_URL\", os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\"))\n",
    "API_KEY            = os.environ[\"OPENAI_API_KEY\"]  # you already set this\n",
    "TOP_P              = float(os.environ.get(\"CNT_WP_TOP_P\", \"0.95\"))\n",
    "PRESENCE_PENALTY   = float(os.environ.get(\"CNT_WP_PRESENCE_P\", \"0.20\"))\n",
    "FREQ_PENALTY       = float(os.environ.get(\"CNT_WP_FREQ_P\", \"0.0\"))\n",
    "MAX_TOKENS         = int(os.environ.get(\"CNT_WP_MAX_TOKENS\", \"128\"))\n",
    "HTTP_TIMEOUT       = float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"45\"))\n",
    "HTTP_RETRIES       = int(os.environ.get(\"CNT_WP_HTTP_RETRIES\",\"2\"))\n",
    "HTTP_DEBUG         = os.environ.get(\"CNT_WP_HTTP_DEBUG\",\"1\") == \"true\" or os.environ.get(\"CNT_WP_HTTP_DEBUG\",\"1\")==\"1\"\n",
    "COLD_INV_TEMP      = float(os.environ.get(\"CNT_WP_INV_TEMP\",\"0.20\"))  # used for IPS/ASI\n",
    "\n",
    "# ---- Minimal content settings for probe vs invariance ----\n",
    "SYSTEM_PROBE = \"You are concise and neutral. One sentence (≤30 words). No disclaimers. Avoid first-person.\"\n",
    "SYSTEM_INV   = \"Answer in one sentence. No first-person, no hedging.\"\n",
    "\n",
    "# Rich, many-answers probe prompts (diversity driver)\n",
    "PROMPTS_CORE = [\n",
    "    \"Write a vivid one-sentence metaphor for time.\",\n",
    "    \"Invent a new one-sentence proverb about patience.\",\n",
    "    \"Describe a sunrise using taste or smell in one sentence.\",\n",
    "    \"Coin a one-sentence motto for a city beneath the ocean.\",\n",
    "    \"Name a creature and a color to symbolize resilience, one sentence.\",\n",
    "    \"Give a one-sentence charm to calm stormy thoughts.\"\n",
    "]\n",
    "\n",
    "# Factual, lightly–anchored invariance prompts (cold temp)\n",
    "PROMPTS_INV = {\n",
    "    \"syn\": [\n",
    "        \"Explain why the sky appears blue to humans; include 'Rayleigh scattering'.\",\n",
    "        \"State why daylight often looks blue; include 'Rayleigh scattering'.\",\n",
    "        \"Give one-sentence cause of the blue sky; include 'Rayleigh scattering'.\",\n",
    "    ],\n",
    "    \"reorder\": [\n",
    "        \"In one sentence, state the purpose of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "        \"In one sentence, explain what error-correcting codes do; include 'detects and corrects errors'.\",\n",
    "    ],\n",
    "    \"gauge\": [\n",
    "        \"Give a neutral one-sentence definition of entropy; begin 'Entropy is a measure of'.\",\n",
    "        \"Define entropy in one sentence; begin 'Entropy is a measure of'.\",\n",
    "    ],\n",
    "}\n",
    "PROMPTS_ANTHRO = {\n",
    "    \"neutral\": [\n",
    "        \"Define the Pacific Ocean in one factual sentence.\",\n",
    "        \"Define a smoke alarm in one factual sentence.\"\n",
    "    ],\n",
    "    \"bait\": [\n",
    "        \"Describe your feelings about the Pacific Ocean in one sentence.\",\n",
    "        \"Describe your feelings about a smoke alarm in one sentence.\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ---------- HTTP client (no unsupported fields, retry with backoff, never raises) ----------\n",
    "def http_chat(model, messages, temperature=0.7, top_p=TOP_P, max_tokens=MAX_TOKENS,\n",
    "              presence_penalty=PRESENCE_PENALTY, frequency_penalty=FREQ_PENALTY):\n",
    "    url = f\"{BASE_URL.rstrip('/')}/v1/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"top_p\": float(top_p),\n",
    "        \"max_tokens\": int(max_tokens),\n",
    "        \"presence_penalty\": float(presence_penalty),\n",
    "        \"frequency_penalty\": float(frequency_penalty),\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\":\"application/json\"}\n",
    "    for k in range(HTTP_RETRIES + 1):\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=HTTP_TIMEOUT)\n",
    "            if r.status_code == 200:\n",
    "                data = r.json()\n",
    "                msg  = data.get(\"choices\",[{}])[ typically[0] if isinstance(data.get(\"choices\"),list) and data[\"choices\"] else {} ].get(\"message\",{})\n",
    "                return (msg.get(\"content\") or \"\").strip()\n",
    "            else:\n",
    "                if HTTP_DEBUG:\n",
    "                    print(f\"[HTTP {r.status_code}] {r.text[:200].replace(chr(10),' ')}\")\n",
    "        except Exception as e:\n",
    "            if HTTP_DEBUG:\n",
    "                print(f\"[HTTP error try {k+1}/{HTTP_RETRIES+1}] {e}\")\n",
    "        time.sleep(0.7 * (2**k))\n",
    "    return \"\"  # tolerate failures\n",
    "\n",
    "# ---------- Text similarity & turbulence ----------\n",
    "def tokens(s): \n",
    "    import re\n",
    "    return [w.lower() for w in re.findall(r\"[A-Za-z0-9']+\", s or \"\")]\n",
    "def pairwise_stats(texts):\n",
    "    vecs = []\n",
    "    for t in texts:\n",
    "        toks = tokens(t)\n",
    "        c    = Counter(toks)\n",
    "        vecs.append((c, set(c.keys())))\n",
    "    if len(vecs) < 2:\n",
    "        return 0.0, 0.0\n",
    "    sims=[]\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i+1,len(vecs)):\n",
    "            (c1,s1),(c2,s2)=vecs[i],vecs[j]\n",
    "            dot = sum(c1[k]*c2.get(k,0) for k in s1 & s2)\n",
    "            denom = math.sqrt(sum(v*v for v in c1.values()))*math.sqrt(sum(v*v for v in c2.values()))\n",
    "            cos = (dot/denom) if denom else 0.0\n",
    "            jac = (len(s1&s2)/len(s1|s2)) if (s1|s2) else 1.0\n",
    "            sims.append(0.6*max(0.0,min(1.0,cos)) + 0.4*max(0.0,min(1.0,jac)))\n",
    "    mean_sim = sum(sims)/len(sims)\n",
    "    disp     = sorted([1.0-s for s in sims])[len(sims)//2]  # median distance\n",
    "    return max(0.0, min(1.0, 1.0 - mean_sim)), max(0.0, min(1.0, disp))\n",
    "\n",
    "def probe_live_text(model, temps, reps):\n",
    "    cons, turb, empties = [], [], []\n",
    "    rng = random.Random()\n",
    "    for t in temps:\n",
    "        outs=[]; dropped=0\n",
    "        for _ in range(reps):\n",
    "            p = PROMPTS_CORE[rng.randrange(len(PROMPTS_CORE))]\n",
    "            msgs=[{\"role\":\"system\",\"content\":SYSTEM_PROBE},\n",
    "                  {\"role\":\"user\",\"content\":f\"One sentence (≤30 words). Be concrete and fresh. No disclaimers.\\nTask: {p}\"}]\n",
    "            txt = http_chat(model, msgs, temperature=t, top_p=TOP_P,\n",
    "                            presence_penalty=PRESENCE_PENALTY, frequency_penalty=FREQ_PENALTY,\n",
    "                            max_tokens=MAX_TOKENS)\n",
    "            if txt: outs.append(txt)\n",
    "            else:   dropped += 1\n",
    "        c, d = (0.0,0.0) if len(outs)<2 else pairwise_stats(outs)\n",
    "        cons.append(c)\n",
    "        turb.append(d*(1.0-c))\n",
    "        empties.append(dropped/max(1,reps))\n",
    "    # normalize turbulence\n",
    "    if any(turb):\n",
    "        m=max(turb)\n",
    "        turb=[x/m if m>0 else 0.0 for x in turb]\n",
    "    return cons, turb, empties\n",
    "\n",
    "def finite_diff(xs, ys):\n",
    "    xs=np.asarray(xs,float); ys=np.asarray(ys,float)\n",
    "    if len(xs)<2: return np.zeros_like(xs)\n",
    "    g=np.zeros_like(xs)\n",
    "    for i in range(len(xs)):\n",
    "        if   i==0:     g[i]=(ys[1]-ys[0])/max(1e-12, xs[1]-xs[0])\n",
    "        elif i==len(xs)-1: g[i]=(ys[-1]-ys[-1])/max(1e-12, xs[-1]-xs[-2])\n",
    "        else:          g[i]=(ys[i+1]-ys[i-1])/max(1e-12, xs[i+1]-xs[i-1])\n",
    "    return g\n",
    "\n",
    "def inv_asi_cold(model, t_ref=0.20, reps=8):\n",
    "    def ask(prompts):\n",
    "        outs=[]\n",
    "        for p in prompts:\n",
    "            msgs=[{\"role\":\"system\",\"content\":SYSTEM_INV},\n",
    "                  {\"role\":\"user\",\"content\":f\"One sentence (≤25 words). No disclaimers.\\nTask: {p}\"}]\n",
    "            outs.append( http://http_chat(model, msgs, temperature=t_ref, top_p=0.95,\n",
    "                                          presence_penalty=0.0, frequency_penalty=0.0, max_tokens=64) )\n",
    "        return [o for o in outs if o]\n",
    "\n",
    "    def inv_for(prompts):\n",
    "        outs = ask(prompts)\n",
    "        if len(outs)<2: return 0.0\n",
    "        sims=[]\n",
    "        vecs=[(Counter(tokens(o)), set(tokens(o))) for o in outs]\n",
    "        for i in range(len(vecs)):\n",
    "            for j in range(i+1,len(vecs)):\n",
    "                (c1,s1),(c2,s2)=vecs[i],vecs[j]\n",
    "                dot = sum(c1[k]*c2.get(k,0) for k in s1 & s2)\n",
    "                denom = math.sqrt(sum(v*v for v in c1.values())) * math.sqrt(sum(v*v for v in c2.values()))\n",
    "                cos   = (dot/denom) if denom else 0.0\n",
    "                jac   = (len(s1&s2)/len(s1|s2)) if (s1|s2) else 1.0\n",
    "                sims.append(0.6*max(0.0,min(1.0,cos)) + 0.4*max(0.0,min(1.0,jac)))\n",
    "        return sum(sims)/len(sims)\n",
    "\n",
    "    inv_syn  = inv_for(PROMPTS_INV[\"syn\"])\n",
    "    inv_reo  = inv_for(PROMPTS_INV[\"reorder\"])\n",
    "    inv_g    = inv_for(PROMPTS_INV[\"gauge\"])\n",
    "    inv_avg  = float((inv_syn + inv_reo + inv_g)/3.0)\n",
    "\n",
    "    # anthropomorphism: high (bad) if first-person+affect occurs; invert for ASI\n",
    "    FP  = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "    AFF = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "    AI  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "    def anthro_score(s):\n",
    "        t=s.lower()\n",
    "        if AI.search(t): return 0.0\n",
    "        return 1.0 if (FP.search(t) and AFF.search(t)) else (0.5 if FP.search(t) else 0.0)\n",
    "\n",
    "    neu = [anthro_score(x) for x in ask(PROMPTS_INV[\"syn\"][:1]+PROMPT S_ANTHRO[\"neutral\"])]\n",
    "    bai = [anthro_score(x) for x in ask(PROMPTS_ANTHRO[\"bait\"])]\n",
    "    a_neu = float(sum(neu)/len(neu)) if neu else 0.0\n",
    "    a_bai = float(sum(bai)/len(bai)) if bai else 0.0\n",
    "    asi   = max(0.0, 1.0 - (a_neu + a_bai)/2.0)\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\":\"gra_invariance_index\",\n",
    "        \"inv_index_overall\":inv_avg,\n",
    "        \"inv_index_syn\":inv_syn,\n",
    "        \"inv_index_reorder\":inv_reo,\n",
    "        \"inv_index_gauge\":inv_g\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)],\n",
    "                           \"separation_index\":[asi,asi,asi,asi]})\n",
    "    return inv_df, sep_df\n",
    "\n",
    "def run_direct_crest(tag, model=MODEL, temps=None, reps=12, inv_temp=COLD_INV_TEMP):\n",
    "    base = Path(os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\") / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    out  = base / f\"{utc_stamp()}_{tag}\"\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    if temps is None:\n",
    "        temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.28,1.30]\n",
    "\n",
    "    cons, turb, drop = probe_live_text(model, temps, reps)\n",
    "    gC = finite_diff(temps, cons)\n",
    "    iC = int(np.argmax(np.abs(gC))) if len(gC) else 0\n",
    "    iD = int(np.argmax(turb))       if len(turb) else 0\n",
    "    tC = float(temps[iC] if temps else np.nan)\n",
    "    tD = float(temps[iD] if temps else np.nan)\n",
    "    # robust consensus cutoff\n",
    "    bN  = min(3,len(temps)) or 1\n",
    "    mu  = float(np.mean(cons[:bN])) if bN else 0.0\n",
    "    sd  = float(np.std (cons[:bN], ddof=1)) if bN>1 else 0.0\n",
    "    thr = mu + max( float(os.getenv(\"CNT_WP_SIGMA_FLO R\",\"0.015\")), float(os.getenv(\"CNT_WP_K\",\"2.5\")) * (sd if sd>1e-6 else 0.01) )\n",
    "    cutC = None\n",
    "    for k in range(1,len(temps)):\n",
    "        if cons[k] >= thr: \n",
    "            cutC = float(temps[k]); break\n",
    "    if cutC is None and len(temps): \n",
    "        cutC = float(temps[-1])\n",
    "    cutD = float(temps[iD]) if len(temps) else np.nan\n",
    "    # cold IPS & ASI\n",
    "    inv_df, sep_df = inv_asi_cold(model, t_ref=inv_temp)\n",
    "\n",
    "    inv_df.to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    sep_df.to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    manifest = {\n",
    "        \"run_id\": out.name, \"llm_mode\":\"RUNTIME\", \"model\": model,\n",
    "        \"temps\": [float(t) for t in temps], \"reps\": int(reps),\n",
    "        \"theta\": {\n",
    "            \"consensus\":{\"theta_star_cutoff\":cutC, \"theta_star_grad\":tC, \"slope_at_grad\": float(gC[iC]) if len(gC) else None},\n",
    "            \"dissent\":  {\"theta_star_cutoff\":cutD, \"theta_star_grad\":tD, \"slope_at_grad\": None}\n",
    "        },\n",
    "        \"derived\":{\"edge_window_width\": float(max(0.0, (tD - tC) if (tD==tD and tC==tC) else 0.0))},\n",
    "        \"meta\":{\"empty_rate\": [float(x) for x in drop], \"created_utc\": utc_stamp(), \"note\":\"direct-runner\"}\n",
    "    }\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps(\n",
    "        {\"temps\":[float(t) for t in temps], \"mean_cons\":[float(x) for x in cons],\n",
    "         \"diss_curve\":[float(x) for x in turb], \"grads_cons\":[float(x) for x in gC],\n",
    "         \"empty_frac\":[float(x) for x in drop]}, indent=2), encoding=\"utf-8\")\n",
    "    return str(out)\n",
    "\n",
    "def summarize_run(rd):\n",
    "    import json\n",
    "    from pathlib import Path\n",
    "    d  = json.loads((Path(rd)/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    mf = json.loads((Path(rd)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.array(d[\"temps\"], float)\n",
    "    gC    = np.array(d[\"grads_cons\"], float)\n",
    "    turb  = np.array(d[\"diss_curve\"], float)\n",
    "    iC    = int(np.argmax(np.abs(gC))) if gC.size else 0\n",
    "    iD    = int(np.argmax(turb))       if turb.size else 0\n",
    "    tC    = float(temps[iC] if temps.size else np.nan)\n",
    "    tD    = float(temps[iD] if temps.size else np.nan)\n",
    "    width = max(0.0, (tD - tC) if (tD==tD and tC==tC) else 0.0)\n",
    "    inv = pd.read_csv(Path(rd)/\"summary_gra_invariance.csv\")[\"inv_index_overall\"].mean()\n",
    "    asi = pd.read_csv(Path(rd)/\"anthropomorphism_separation.csv\")[\"recycle\" if \"recycle\" in pd.read_csv(Path(rd)/\"anthropomorphism_separation.csv\").columns else \"separation_index\"].mean()\n",
    "    return {\"run\":Path(rd).name, \"width\":float(width), \"IPS\":float(inv), \"ASI\":float(asi), \"knee\":tC, \"d-peak\":tD}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "09fc36ce-84f9-4e38-9b61-418172fb723d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === CLEAN PATCH: safe http_chat + probe + cold IPS/ASI + direct runner ===\n",
    "import os, time, json, math, re, random, requests\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from collections import Counter\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "# ---- wiring (uses your existing OPENAI_API_KEY / OPENAI_BASE_URL) ----\n",
    "API_KEY  = os.environ.get(\"OPENAI_API_KEY\"); assert API_KEY, \"Set OPENAI_API_KEY first.\"\n",
    "BASE_URL = os.environ.get(\"OPENAI_BASE_URL\",\"https://api.openai.com/v1\")\n",
    "\n",
    "def utc_stamp(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def tokens(s):  return re.findall(r\"[A-Za-z0-9']+\", (s or \"\").lower())\n",
    "\n",
    "# ---- SAFE http client (only supported fields; no 'top'; retries; never crashes your kernel) ----\n",
    "def http_chat(model, messages, *, temperature=0.7, top_p=0.95, max_tokens=128,\n",
    "              presence_penalty=0.0, frequency_penalty=0.0, timeout=None, retries=1, debug=True):\n",
    "    url = f\"{BASE_URL.rstrip('/')}/chat/completions\"\n",
    "    payload = {\n",
    "        \"model\": model,\n",
    "        \"messages\": messages,\n",
    "        \"temperature\": float(temperature),\n",
    "        \"top_p\": float(top_p),\n",
    "        \"max_tokens\": int(max_tokens),\n",
    "        \"presence_penalty\": float(presence_penalty),\n",
    "        \"frequency_penalty\": float(frequency_penalty),\n",
    "    }\n",
    "    headers = {\"Authorization\": f\"Bearer {API_KEY}\", \"Content-Type\":\"application/json\"}\n",
    "    if timeout is None: timeout = float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"45\"))\n",
    "    for k in range(retries+1):\n",
    "        try:\n",
    "            r = requests.post(url, json=payload, headers=headers, timeout=timeout)\n",
    "            if r.status_code == 200:\n",
    "                data    = r.json()\n",
    "                choices = data.get(\"choices\") or []\n",
    "                return (choices[0].get(\"message\",{}).get(\"content\",\"\") if choices else \"\").strip()\n",
    "            if debug: print(f\"[HTTP {r.status_code}] {r.text[:200].replace(chr(10),' ')}\")\n",
    "        except Exception as e:\n",
    "            if debug: print(f\"[HTTP err try {k+1}] {type(e).__name__}: {e}\")\n",
    "        time.sleep(0.7*(k+1))\n",
    "    return \"\"\n",
    "\n",
    "# ---- similarity & turbulence helpers ----\n",
    "def _vec(toks): \n",
    "    c = Counter(toks); return c, set(c.keys())\n",
    "def _cosine(a: Counter, b: Counter):\n",
    "    if not a or not b: return 0.0\n",
    "    ka, kb = set(a.keys()), set(b.keys())\n",
    "    num = sum(a[k]*b.get(k,0) for k in ka & kb)\n",
    "    den = math.sqrt(sum(v*v for v in a.values())) * math.sqrt(sum(v*v for v in b.values()))\n",
    "    return (num/den) if den else 0.0\n",
    "def _jacc(s1:set, s2:set):\n",
    "    if not s1 and not s2: return 1.0\n",
    "    u = len(s1|s2); i = len(s1&s2)\n",
    "    return (i/u) if u else 1.0\n",
    "\n",
    "def pairwise_stats(texts):\n",
    "    vecs=[_vec(tokens(t)) for t in texts]\n",
    "    if len(vecs)<2: return 0.0, 0.0\n",
    "    sims=[]; dists=[]\n",
    "    for i in range(len(vecs)):\n",
    "        for j in range(i+1,len(vecs)):\n",
    "            (c1,s1),(c2,s2) = vecs[i], vecs[j]\n",
    "            sim = 0.6*_cosine(c1,c2) + 0.4*_jacc(s1,s2)\n",
    "            sims.append(sim); dists.append(1.0 - sim)\n",
    "    mean_sim = sum(sims)/len(sims)\n",
    "    disp_med = sorted(dists)[len(dists)//2]\n",
    "    # consensus = 1 - mean_sim; turbulence = dispersion * (1 - consensus)\n",
    "    cons = max(0.0, min(1.0, 1.0 - mean_sim))\n",
    "    turb = max(0.0, min(1.0, disp_med)) * (1.0 - cons)\n",
    "    return cons, turb\n",
    "\n",
    "# ---- probe prompts (creative, many-valid) & invariance prompts (cold) ----\n",
    "SYSTEM_PROBE = \"You are concise and neutral. One sentence (≤30 words). No disclaimers. Avoid first-person.\"\n",
    "SYSTEM_INV   = \"Answer in one sentence. No first-person, no disclaimers.\"\n",
    "\n",
    "PROMPTS_CORE = [\n",
    "    \"Write a vivid one-sentence metaphor for time.\",\n",
    "    \"Invent a new one-sentence proverb about patience.\",\n",
    "    \"Describe a sunrise using taste or smell in one sentence.\",\n",
    "    \"Coin a one-sentence motto for a city beneath the ocean.\",\n",
    "    \"Name a creature and a color to symbolize resilience, one sentence.\",\n",
    "    \"Give a one-sentence charm to calm stormy thoughts.\",\n",
    "]\n",
    "\n",
    "PROMPTS_INV = {\n",
    "    \"syn\": [\n",
    "        \"Explain why the sky appears blue to humans; include 'Rayleigh scattering'.\",\n",
    "        \"State why daylight often looks blue; include 'Rayleigh scattering'.\",\n",
    "    ],\n",
    "    \"reorder\": [\n",
    "        \"In one sentence, state the purpose of error-correcting codes; include 'detects and corrects errors'.\",\n",
    "        \"In one sentence, explain what error-correcting codes do; include 'detects and corrects errors'.\",\n",
    "    ],\n",
    "    \"gauge\": [\n",
    "        \"Give a neutral one-sentence definition of entropy; begin 'Entropy is a measure of'.\",\n",
    "        \"Define entropy in one sentence; begin 'Entropy is a measure of'.\",\n",
    "    ],\n",
    "}\n",
    "PROMPTS_ANTHRO = {\n",
    "    \"neutral\": [\"Define the Pacific Ocean in one factual sentence.\"],\n",
    "    \"bait\":    [\"Describe your feelings about the Pacific Ocean in one sentence.\"],\n",
    "}\n",
    "\n",
    "# ---- robust probe over temps/reps (tolerates dropped calls) ----\n",
    "def probe_live_text(model, temps, reps, *, top_p=0.95, presence=0.20, freq=0.0, max_tokens=128):\n",
    "    cons, turb, empties = [], [], []\n",
    "    rng = random.Random()\n",
    "    for t in temps:\n",
    "        outs=[]; dropped=0\n",
    "        for _ in range(reps):\n",
    "            p = PROMPTS_CORE[rng.randrange(len(PROMPTS_CORE))]\n",
    "            msgs=[{\"role\":\"system\",\"content\":SYSTEM_PROBE},\n",
    "                  {\"role\":\"user\",\"content\":f\"One sentence (≤30 words). Be concrete and fresh. No disclaimers.\\nTask: {p}\"}]\n",
    "            txt = http_chat(model, msgs, temperature=t, top_p=top_p,\n",
    "                            presence_penalty=presence, frequency_penalty=freq, max_tokens=max_tokens,\n",
    "                            retries=int(os.environ.get(\"CNT_WP_HTTP_RETRIES\",\"2\")),\n",
    "                            timeout=float(os.environ.get(\"CNT_WP_HTTP_TIMEOUT\",\"45\")),\n",
    "                            debug=os.environ.get(\"CNT_WP_HTTP_DEBUG\",\"1\") in (\"1\",\"true\",\"True\"))\n",
    "            if txt: outs.append(txt)\n",
    "            else:   dropped += 1\n",
    "        c, tb = (0.0,0.0) if len(outs)<2 else pairwise_stats(outs)\n",
    "        cons.append(c); turb.append(tb); empties.append(dropped/max(1,reps))\n",
    "    if any(turb):\n",
    "        m=max(turb); turb=[x/m if m>0 else 0.0 for x in turb]\n",
    "    return cons, turb, empties\n",
    "\n",
    "def finite_diff(xs, ys):\n",
    "    xs=np.asarray(xs,float); ys=np.asarray(ys,float)\n",
    "    if len(xs)<2: return list(np.zeros_like(xs))\n",
    "    g=np.zeros_like(xs)\n",
    "    for i in range(len(xs)):\n",
    "        if   i==0:         g[i]=(ys[1]-ys[0])/max(1e-12, xs[1]-xs[0])\n",
    "        elif i==len(xs)-1: g[i]=(ys[-1]-ys[-1])/max(1e-12, xs[-1]-xs[-2])\n",
    "        else:              g[i]=(ys[i+1]-ys[i-1])/max(1e-12, xs[i+1]-xs[i-1])\n",
    "    return list(g)\n",
    "\n",
    "# ---- cold IPS/ASI (deterministic) ----\n",
    "def inv_asi_cold(model, t_ref=0.20):\n",
    "    def ask(prompts):\n",
    "        outs=[]\n",
    "        for p in prompts:\n",
    "            msgs=[{\"role\":\"system\",\"content\":SYSTEM_INV},\n",
    "                  {\"role\":\"user\",\"content\":f\"One sentence (≤25 words). No disclaimers.\\nTask: {p}\"}]\n",
    "            outs.append(http_chat(model, msgs, temperature=t_ref, top_p=0.95,\n",
    "                                  presence_penalty=0.0, frequency_penalty=0.0, max_tokens=64,\n",
    "                                  retries=1, timeout=30, debug=False))\n",
    "        return [o for o in outs if o]\n",
    "\n",
    "    def inv_for(prompts):\n",
    "        outs=ask(prompts)\n",
    "        if len(outs)<2: return 0.0\n",
    "        sims=[]\n",
    "        V=[(_vec(tokens(o))) for o in outs]\n",
    "        for i in range(len(V)):\n",
    "            for j in range(i+1,len(V)):\n",
    "                (c1,s1),(c2,s2)=V[i],V[j]\n",
    "                cos=_cosine(c1,c2); jac=_jacc(s1,s2)\n",
    "                sims.append(0.6*max(0.0,min(1.0,cos)) + 0.4*max(0.0,min(1.0,jac)))\n",
    "        return float(sum(sims)/len(sims))\n",
    "\n",
    "    inv_syn = inv_for(PROMPTS_INV[\"syn\"])\n",
    "    inv_reo = inv_for(PROMPTS_INV[\"reorder\"])\n",
    "    inv_g   = inv_for(PROMPTS_INV[\"gauge\"])\n",
    "    inv_avg = float((inv_syn+inv_reo+inv_g)/3.0)\n",
    "\n",
    "    FP  = re.compile(r\"\\b(i|me|my|mine|myself)\\b\", re.I)\n",
    "    AFF = re.compile(r\"\\b(feel|emotion(s)?|love|hate|afraid|fear|sad|happy|want|desire)\\b\", re.I)\n",
    "    AI  = re.compile(r\"\\bas an ai|as a language model\\b\", re.I)\n",
    "    def anthro_score(s):\n",
    "        t=s.lower()\n",
    "        if AI.search(t): return 0.0\n",
    "        return 1.0 if (FP.search(t) and AFF.search(t)) else (0.5 if FP.search(t) else 0.0)\n",
    "\n",
    "    neu = [anthro_score(x) for x in ask(PROMPTS_ANTHRO[\"neutral\"])]\n",
    "    bai = [anthro_score(x) for x in ask(PROMPTS_ANTHRO[\"bait\"])]\n",
    "    asi = float(max(0.0, 1.0 - ((sum(neu)/len(neu) if neu else 0.0) + (sum(bai)/len(bai) if bai else 0.0))/2.0))\n",
    "\n",
    "    inv_df = pd.DataFrame([{\n",
    "        \"experiment\":\"gra_invariance_index\",\n",
    "        \"inv_index_overall\":inv_avg,\n",
    "        \"inv_index_syn\":inv_syn,\n",
    "        \"inv_index_reorder\":inv_reo,\n",
    "        \"inv_index_gauge\":inv_g,\n",
    "    }])\n",
    "    sep_df = pd.DataFrame({\"task_id\":[f\"t{i+1}\" for i in range(4)],\n",
    "                           \"separation_index\":[asi]*4})\n",
    "    return inv_df, sep_df\n",
    "\n",
    "# ---- direct, JSON-safe crest run (no legacy engine) ----\n",
    "def run_direct_crest(tag, model=None, temps=None, reps=12, inv_temp=0.20):\n",
    "    model = model or os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\")\n",
    "    temps = temps or [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30]\n",
    "    base  = Path(os.getenv(\"CNT_LAB_DIR\") or \"E:/CNT\") / \"artifacts\" / \"cnt_llm_weirdness_probe\"\n",
    "    out   = base / f\"{utc_stamp()}_{tag}\"\n",
    "    out.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    cons, turb, drop = probe_live_text(model, temps, reps,\n",
    "                                       top_p=float(os.getenv(\"CNT_WP_TOP_P\",\"0.95\")),\n",
    "                                       presence=float(os.getenv(\"CNT_WP_PRESENCE_P\",\"0.20\")),\n",
    "                                       freq=float(os.getenv(\"CNT_WP_FREQ_P\",\"0.0\")),\n",
    "                                       max_tokens=int(os.getenv(\"CNT_WP_MAX_TOKENS\",\"128\")))\n",
    "    gC = finite_diff(temps, cons)\n",
    "    iC = int(np.argmax(np.abs(gC))) if gC else 0\n",
    "    iD = int(np.argmax(turb)) if any(turb) else 0\n",
    "    tC = float(temps[iC] if temps else np.nan)\n",
    "    tD = float(temps[iD] if temps else np.nan)\n",
    "    # consensus cutoff (robust baseline over first 3)\n",
    "    bN  = min(3,len(temps)) or 1\n",
    "    mu  = float(np.mean(cons[:bN])) if bN else 0.0\n",
    "    sd  = float(np.std (cons[:bN], ddof=1)) if bN>1 else 0.0\n",
    "    thr = mu + max( float(os.getenv(\"CNT_WP_SIGMA_FLOOR\",\"0.015\")),\n",
    "                    float(os.getenv(\"CNT_WP_K\",\"2.5\")) * (sd if sd>1e-6 else 0.01) )\n",
    "    cutC=None\n",
    "    for k in range(1,len(temps)):\n",
    "        if cons[k] >= thr:\n",
    "            cutC=float(temps[k]); break\n",
    "    if cutC is None and temps:\n",
    "        cutC=float(temps[-1])\n",
    "    cutD = float(temps[iD]) if temps else np.nan\n",
    "\n",
    "    inv_df, sep_df = inv_asi_cold(model, t_ref=inv_temp)\n",
    "    inv_df.to_csv(out/\"summary_gra_invariance.csv\", index=False)\n",
    "    sep_df.to_csv(out/\"anthropomorphism_separation.csv\", index=False)\n",
    "\n",
    "    # manifest + curves\n",
    "    manifest = {\n",
    "        \"run_id\": out.name, \"llm_mode\":\"LIVE\", \"model\": model,\n",
    "        \"temps\": [float(t) for t in temps], \"reps\": int(reps),\n",
    "        \"theta\": {\n",
    "            \"consensus\":{\"theta_star_cutoff\":cutC, \"theta_star_grad\":tC, \"slope_at_grad\": float(gC[iC]) if gC else None},\n",
    "            \"dissent\":  {\"theta_star_cutoff\":cutD, \"theta_star_grad\":tD, \"slope_at_grad\": None}\n",
    "        },\n",
    "        \"derived\":{\"edge_window_width\": float(max(0.0, (tD - tC) if (tD==tD and tC==tC) else 0.0))},\n",
    "        \"meta\":{\"created_utc\": utc_stamp(), \"empty_rate\": [float(x) for x in drop], \"note\":\"direct-runner\"}\n",
    "    }\n",
    "    (out/\"run_manifest.json\").write_text(json.dumps(manifest, indent=2), encoding=\"utf-8\")\n",
    "    (out/\"curves.json\").write_text(json.dumps(\n",
    "        {\"temps\":[float(t) for t in temps], \"mean_cons\":[float(x) for x in cons],\n",
    "         \"diss_curve\":[float(x) for x in turb], \"grads_cons\":[float(x) for x in gC],\n",
    "         \"empty_frac\":[float(x) for x in drop]}, indent=2), encoding=\"utf-8\")\n",
    "    pd.DataFrame({\"temp\":temps,\"mean_cons\":cons,\"diss_curve\":turb,\"empty_frac\":drop}).to_csv(out/\"live_probe_debug.csv\", index=False)\n",
    "    return str(out)\n",
    "\n",
    "def summarize_run(rd):\n",
    "    d  = json.loads((Path(rd)/\"curves.json\").read_text(encoding=\"utf-8\"))\n",
    "    mf = json.loads((Path(rd)/\"run_manifest.json\").read_text(encoding=\"utf-8\"))\n",
    "    temps = np.array(d[\"temps\"], float)\n",
    "    gC    = np.array(d[\"grads_cons\"], float)\n",
    "    turb  = np.array(d[\"diss_curve\"], float)\n",
    "    iC    = int(np.argmax(np.abs(gC))) if gC.size else 0\n",
    "    iD    = int(np.argmax(turb)) if turb.size else 0\n",
    "    tC    = float(temps[iC] if temps.size else np.nan)\n",
    "    tD    = float(temps[iD] if temps.size else np.nan)\n",
    "    width = max(0.0, (tD - tC) if (tD==tD and tC==tC) else 0.0)\n",
    "    inv   = pd.read_csv(Path(rd)/\"summary_gra_invariance.csv\")[\"inv_index_overall\"].mean()\n",
    "    asi   = pd.read_csv(Path(rd)/\"anthropomorphism_separation.csv\")[\"separation_index\"].mean()\n",
    "    return {\"run\":Path(rd).name, \"width\":float(width), \"IPS\":float(inv), \"ASI\":float(asi), \"knee\":tC, \"d-peak\":tD}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a8cfdbdb-29ed-4741-8fdc-002bab183102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>width</th>\n",
       "      <th>IPS</th>\n",
       "      <th>ASI</th>\n",
       "      <th>knee</th>\n",
       "      <th>d-peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-060601Z_live_stability_pp020_r1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.664645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.22</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-060857Z_live_stability_pp020_r2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.696466</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        run  width       IPS  ASI  knee  \\\n",
       "0  20251103-060601Z_live_stability_pp020_r1   0.01  0.664645  1.0  1.22   \n",
       "1  20251103-060857Z_live_stability_pp020_r2   0.00  0.696466  1.0  1.24   \n",
       "\n",
       "   d-peak  \n",
       "0    1.23  \n",
       "1    1.23  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ladder & reps trimmed for reliability; IPS stays cold (t_ref=0.20 by default)\n",
    "temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30]\n",
    "\n",
    "rA = run_direct_crest(\"live_stability_pp020_r1\", model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"), temps=temps, reps=12)\n",
    "rB = run_direct_crest(\"live_stability_pp020_r2\", model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"), temps=temps, reps=12)\n",
    "\n",
    "pd.DataFrame([summarize_run(rA), summarize_run(rB)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "dab0b87a-c217-49be-86b7-22e09f486c6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>width</th>\n",
       "      <th>IPS</th>\n",
       "      <th>ASI</th>\n",
       "      <th>knee</th>\n",
       "      <th>d-peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-061359Z_live_stability_pp030_r3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70885</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.21</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        run  width      IPS  ASI  knee  d-peak\n",
       "0  20251103-061359Z_live_stability_pp030_r3    0.0  0.70885  1.0  1.21    1.18"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, pandas as pd\n",
    "temps = [1.18,1.20,1.21,1.22,1.23,1.24,1.25,1.26,1.27,1.30]\n",
    "\n",
    "os.environ[\"CNT_WP_PRESENCE_P\"] = \"0.30\"  # tiny oxygen bump\n",
    "rC = run_direct_crest(\"live_stability_pp030_r3\", model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"), temps=temps, reps=12)\n",
    "\n",
    "pd.DataFrame([summarize_run(r) for r in [rC]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "246580a8-ee76-4b15-ab75-5c2fce0675ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>width</th>\n",
       "      <th>IPS</th>\n",
       "      <th>ASI</th>\n",
       "      <th>knee</th>\n",
       "      <th>d-peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-062054Z_live_stability_pp000_sweep</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.699907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-062343Z_live_stability_pp010_sweep</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.702909</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>1.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-062632Z_live_stability_pp020_sweep</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.775703</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251103-062918Z_live_stability_pp030_sweep</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.728972</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251103-063202Z_live_stability_pp040_sweep</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.699907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           run  width       IPS  ASI  knee  \\\n",
       "0  20251103-062054Z_live_stability_pp000_sweep   0.08  0.699907  1.0  1.12   \n",
       "1  20251103-062343Z_live_stability_pp010_sweep   0.00  0.702909  1.0  1.20   \n",
       "2  20251103-062632Z_live_stability_pp020_sweep   0.02  0.775703  1.0  1.26   \n",
       "3  20251103-062918Z_live_stability_pp030_sweep   0.02  0.728972  1.0  1.12   \n",
       "4  20251103-063202Z_live_stability_pp040_sweep   0.00  0.699907  1.0  1.12   \n",
       "\n",
       "   d-peak  \n",
       "0    1.20  \n",
       "1    1.16  \n",
       "2    1.28  \n",
       "3    1.14  \n",
       "4    1.12  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps = [0.00, 0.10, 0.20, 0.30, 0.40]\n",
    "temps = [1.12,1.14,1.16,1.18,1.20,1.22,1.24,1.26,1.28,1.30]\n",
    "reps  = 12\n",
    "rows = []\n",
    "for p in ps:\n",
    "    os.environ[\"CNT_WP_PRESENCE_P\"] = f\"{p:.2f}\"\n",
    "    r = run_direct_crest(f\"live_stability_pp{int(p*100):03d}_sweep\", \n",
    "                         model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "                         temps=temps, reps=reps)\n",
    "    rows.append(summarize_run(r))\n",
    "pd.DataFrame(rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "921176b0-a924-4ab2-9790-85abf5e688d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>run</th>\n",
       "      <th>width</th>\n",
       "      <th>IPS</th>\n",
       "      <th>ASI</th>\n",
       "      <th>knee</th>\n",
       "      <th>d-peak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20251103-063753Z_live_flipmap_pp018</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.645443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>1.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20251103-064150Z_live_flipmap_pp020</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.749314</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20251103-064550Z_live_flipmap_pp022</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.698123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20251103-064954Z_live_flipmap_pp024</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.699907</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>1.32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20251103-065346Z_live_flipmap_pp026</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.698123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>1.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>20251103-065738Z_live_flipmap_pp028</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.712064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.32</td>\n",
       "      <td>1.12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   run  width       IPS  ASI  knee  d-peak\n",
       "0  20251103-063753Z_live_flipmap_pp018   0.00  0.645443  1.0  1.26    1.24\n",
       "1  20251103-064150Z_live_flipmap_pp020   0.00  0.749314  1.0  1.32    1.22\n",
       "2  20251103-064550Z_live_flipmap_pp022   0.00  0.698123  1.0  1.32    1.30\n",
       "3  20251103-064954Z_live_flipmap_pp024   0.02  0.699907  1.0  1.30    1.32\n",
       "4  20251103-065346Z_live_flipmap_pp026   0.08  0.698123  1.0  1.10    1.18\n",
       "5  20251103-065738Z_live_flipmap_pp028   0.00  0.712064  1.0  1.32    1.12"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps    = [0.18,0.20,0.22,0.24,0.26,0.28]\n",
    "temps = [round(1.10+i*0.02,2) for i in range(int((1.36-1.10)/0.02)+1)]\n",
    "reps  = 12\n",
    "\n",
    "rows = []\n",
    "for p in ps:\n",
    "    os.environ[\"CNT_WP_PRESENCE_P\"] = f\"{p:.2f}\"\n",
    "    r = run_direct_crest(f\"live_flipmap_pp{int(p*100):03d}\", \n",
    "                         model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "                         temps=temps, reps=reps)\n",
    "    rows.append(summarize_run(r))  # ensure this records width/knee/d-peak and per-temp IPS\n",
    "flipmap = pd.DataFrame(rows)\n",
    "flipmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "bff5a7c8-34fa-420f-adc3-fbf5419f27f2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_per_temp_ips' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[85]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     11\u001b[39m     rows.append(summarize_run(r))\n\u001b[32m     12\u001b[39m     \u001b[38;5;66;03m# assuming summarize_run can optionally return per-temp IPS; else add a fetch here\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     traces[p] = \u001b[43mget_per_temp_ips\u001b[49m(r)  \u001b[38;5;66;03m# dict: {temp: [ips_rep1,...]}\u001b[39;00m\n\u001b[32m     15\u001b[39m df = pd.DataFrame(rows)  \u001b[38;5;66;03m# columns: run,width,IPS,ASI,knee,d-peak\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Bootstrap ΔIPS(pp=0.20 vs 0.00) across temps (paired by temp)\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_per_temp_ips' is not defined"
     ]
    }
   ],
   "source": [
    "ps    = [0.19,0.20,0.21,0.23,0.24,0.25,0.26]\n",
    "temps = [round(1.08+i*0.02,2) for i in range(int((1.36-1.08)/0.02)+1)]\n",
    "reps  = 12\n",
    "\n",
    "rows, traces = [], {}\n",
    "for p in ps:\n",
    "    os.environ[\"CNT_WP_PRESENCE_P\"] = f\"{p:.2f}\"\n",
    "    r = run_direct_crest(f\"live_microscan_pp{int(p*100):03d}\",\n",
    "                         model=os.environ.get(\"LLM_MODEL\",\"gpt-4o-mini\"),\n",
    "                         temps=temps, reps=reps)\n",
    "    rows.append(summarize_run(r))\n",
    "    # assuming summarize_run can optionally return per-temp IPS; else add a fetch here\n",
    "    traces[p] = get_per_temp_ips(r)  # dict: {temp: [ips_rep1,...]}\n",
    "\n",
    "df = pd.DataFrame(rows)  # columns: run,width,IPS,ASI,knee,d-peak\n",
    "\n",
    "# Bootstrap ΔIPS(pp=0.20 vs 0.00) across temps (paired by temp)\n",
    "import numpy as np, random\n",
    "base = np.array([np.mean(traces[0.00][t]) for t in temps if t in traces[0.00] and t in traces[0.20]])\n",
    "win  = np.array([np.mean(traces[0.20][t]) for t in temps if t in traces[0.00] and t in traces[0.20]])\n",
    "diff = win - base\n",
    "boots = []\n",
    "for _ in range(10000):\n",
    "    idx = np.random.randint(0, len(diff), len(diff))\n",
    "    boots.append(np.mean(diff[idx]))\n",
    "ci = (np.percentile(boots, 2.5), np.percentile(boots, 97.5))\n",
    "effect = diff.mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d77d28-cbdc-4781-901a-9057a117b4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
