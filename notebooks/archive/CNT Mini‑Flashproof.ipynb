{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4ead8cfa-8b96-43f2-a3f1-d69779807277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Gauge invariance Φ_rank: base=0.0987 perm=0.0987 mono=0.0987 -> PASS\n",
      "B) DPI check: I(X;Y)_analytic=0.2231 ≥ I(sign X;Y)_emp=0.1279 -> PASS\n",
      "C) Permutation calibration: KS sup Δ=0.570 (≤0.14 target) -> FAIL\n",
      "D) Glyph advantage ΔΦ: mean=0.0464, 95% CI=(0.0344,0.0584) -> PASS\n",
      "E) KL monotonicity (coarse‑graining): violations=0/64 -> PASS\n",
      "\n",
      "Summary → CHECK DETAILS\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null\n",
    "# ------------------------------\n",
    "# Two groups with identical dynamics; statistic T = Φ_rank(A) - Φ_rank(B).\n",
    "# Under null, permutation p‑values should be ~Uniform[0,1]. We measure KS sup‑norm.\n",
    "\n",
    "runs, perms = 60, 60\n",
    "pvals = []\n",
    "for r in range(runs):\n",
    "    A, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=1000 + r)\n",
    "    B, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=2000 + r)\n",
    "    T_obs = phi_rank(A) - phi_rank(B)\n",
    "    # build a pooled set and randomly split rows to preserve row‑level structure\n",
    "    P = np.concatenate([A, B], axis=0)\n",
    "    stat = 0\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        idx = rng.permutation(P.shape[0])\n",
    "        A_p = P[idx[:32]]\n",
    "        B_p = P[idx[32:]]\n",
    "        t = phi_rank(A_p) - phi_rank(B_p)\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "        stat += 1\n",
    "    pvals.append((ge + 1) / (stat + 1))  # add +1 smoothing\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # len=60 => ~10% band; relax if needed\n",
    "print(f\"C) Permutation calibration: KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2c4332b-d269-4270-81a0-749f460634d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Gauge invariance Φ_rank: base=0.0987 perm=0.0987 mono=0.0987 -> PASS\n",
      "B) DPI check: I(X;Y)_analytic=0.2231 ≥ I(sign X;Y)_emp=0.1279 -> PASS\n",
      "C) Permutation calibration (replicate‑level): KS sup Δ=0.071 (≤0.14 target) -> PASS\n",
      "D) Glyph advantage ΔΦ: mean=0.0463, 95% CI=(0.0343,0.0584) -> PASS\n",
      "E) KL monotonicity (coarse‑graining): violations=0/64 -> PASS\n",
      "\n",
      "Summary → PASS\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e2b0c9-22ae-41f4-bce4-598965365130",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 462) (2717978273.py, line 462)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 462\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 462)\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n",
    "\n",
    "# === v2.1 Add‑ons — Equivalence Tests, Bootstrap Calibrations, Stress Regimes ===\n",
    "# Telos × Aetheron — portable, NumPy‑only, speed‑tuned defaults\n",
    "\n",
    "# 1) TOST equivalence for invariance (Φ_base ≈ Φ_perm ≈ Φ_mono within ±ε)\n",
    "\n",
    "def tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3):\n",
    "    diffs_perm, diffs_mono = [], []\n",
    "    for s in range(trials):\n",
    "        X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=30000 + s)\n",
    "        phi0 = phi_rank(X0)\n",
    "        perm = rng.permutation(N)\n",
    "        phi_perm = phi_rank(X0[perm])\n",
    "        Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        X_mono = np.exp(Amono * X0 + Bmono)\n",
    "        phi_mono = phi_rank(X_mono)\n",
    "        diffs_perm.append(phi0 - phi_perm)\n",
    "        diffs_mono.append(phi0 - phi_mono)\n",
    "    diffs_perm = np.array(diffs_perm)\n",
    "    diffs_mono = np.array(diffs_mono)\n",
    "\n",
    "    def ci95(means):\n",
    "        r = 2000\n",
    "        idx = rng.integers(0, len(means), size=(r, len(means)))\n",
    "        boot = means[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return float(means.mean()), float(lo), float(hi)\n",
    "\n",
    "    mP, loP, hiP = ci95(diffs_perm)\n",
    "    mM, loM, hiM = ci95(diffs_mono)\n",
    "    pass_perm = (loP > -eps) and (hiP < eps)\n",
    "    pass_mono = (loM > -eps) and (hiM < eps)\n",
    "    print(f\"TOST invariance (perm): mean={mP:.5f}, 95% CI=({loP:.5f},{hiP:.5f}), eps=±{eps:.5f} -> {'PASS' if pass_perm else 'FAIL'}\")\n",
    "    print(f\"TOST invariance (mono): mean={mM:.5f}, 95% CI=({loM:.5f},{hiM:.5f}), eps=±{eps:.5f} -> {'PASS' if pass_mono else 'FAIL'}\")\n",
    "    return pass_perm and pass_mono\n",
    "\n",
    "\n",
    "# 2) Independent calibration styles — permutation, block bootstrap, wild bootstrap\n",
    "\n",
    "def block_bootstrap_phi(X: np.ndarray, block: int = 32) -> float:\n",
    "    N, T = X.shape\n",
    "    nblocks = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=nblocks)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_bootstrap_phi(X: np.ndarray) -> float:\n",
    "    # Rademacher flips per time step (same sign across channels preserves cross‑structure better)\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    Xw = X * signs\n",
    "    return phi_rank(Xw)\n",
    "\n",
    "\n",
    "def calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256):\n",
    "    # Build replicate bank\n",
    "    reps = []\n",
    "    for g in range(G):\n",
    "        Xg, _ = make_var_series(N=N, T=T, density=0.05, spectral_radius=0.85, seed=12000 + g)\n",
    "        reps.append(Xg)\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "\n",
    "    ks_results = {}\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            if mode == 'perm':\n",
    "                for b in range(B):\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            elif mode == 'block':\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([block_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            else:  # wild\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([wild_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        pvals = np.array(pvals)\n",
    "        ks = ks_sup_norm_uniform(pvals)\n",
    "        ks_results[mode] = ks\n",
    "        print(f\"Calibration {mode}: KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if ks <= 0.14 else 'CHECK'}\")\n",
    "    return ks_results\n",
    "\n",
    "\n",
    "# 3) Stress the edges — heavy tails, colored noise, missingness, uneven sampling\n",
    "\n",
    "def make_var_series2(N=48, T=512, density=0.06, spectral_radius=0.92, noise=1.0, seed=None,\n",
    "                     noise_mode=\"gauss\", df=3, ar_rho=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if noise_mode == \"gauss\":\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    elif noise_mode == \"t\":\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        # scale to unit variance for df>2\n",
    "        if df > 2:\n",
    "            e *= (noise / np.sqrt(df / (df - 2)))\n",
    "    elif noise_mode == \"colored\":\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, noise, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar_rho * e[i, t - 1] + w[i, t]\n",
    "    else:\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def apply_missing_and_uneven(X: np.ndarray, miss_rate: float = 0.0, gaps: bool = False) -> np.ndarray:\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        # create 5 random gaps of ~2% length\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            start = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, start:start + rlen] = np.nan\n",
    "    if miss_rate > 0:\n",
    "        mask = rng.random(Y.shape) < miss_rate\n",
    "        Y[mask] = np.nan\n",
    "    # per‑channel linear interpolation (fallback to 0 if insufficient points)\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress_battery():\n",
    "    regimes = [\n",
    "        (\"gauss_baseline\", dict(noise_mode=\"gauss\", miss=0.0, gaps=False)),\n",
    "        (\"heavy_tail_t3\", dict(noise_mode=\"t\", miss=0.0, gaps=False, df=3)),\n",
    "        (\"colored_rho0.6\", dict(noise_mode=\"colored\", miss=0.0, gaps=False, ar_rho=0.6)),\n",
    "        (\"missing_10pct\", dict(noise_mode=\"gauss\", miss=0.10, gaps=False)),\n",
    "        (\"uneven_gaps\", dict(noise_mode=\"gauss\", miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    rows = []\n",
    "    for name, cfg in regimes:\n",
    "        G, N, T = 16, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=21000 + g,\n",
    "                                    noise_mode=cfg.get(\"noise_mode\", \"gauss\"),\n",
    "                                    df=cfg.get(\"df\", 3), ar_rho=cfg.get(\"ar_rho\", 0.5))\n",
    "            X = apply_missing_and_uneven(X, miss_rate=cfg.get(\"miss\", 0.0), gaps=cfg.get(\"gaps\", False))\n",
    "            reps.append(X)\n",
    "        phis = np.array([phi_rank(X) for X in reps])\n",
    "        # replicate‑level permutation calibration\n",
    "        K, B = 30, 200\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_norm_uniform(np.array(pvals))\n",
    "        # glyph advantage under matched null\n",
    "        R = 12\n",
    "        effects = []\n",
    "        for s in range(R):\n",
    "            Xs, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=22000 + s,\n",
    "                                     noise_mode=cfg.get(\"noise_mode\", \"gauss\"),\n",
    "                                     df=cfg.get(\"df\", 3), ar_rho=cfg.get(\"ar_rho\", 0.5))\n",
    "            Xs = apply_missing_and_uneven(Xs, miss_rate=cfg.get(\"miss\", 0.0), gaps=cfg.get(\"gaps\", False))\n",
    "            phi_s = phi_rank(Xs)\n",
    "            Xnull = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xnull[i] = Xs[i, idx]\n",
    "            phi_n = phi_rank(Xnull)\n",
    "            effects.append(phi_s - phi_n)\n",
    "        effects = np.array(effects)\n",
    "        mu = effects.mean()\n",
    "        se = effects.std(ddof=1) / np.sqrt(R)\n",
    "        ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        rows.append((name, ks, mu, ci_lo, ci_hi))\n",
    "        print(f\"[{name}] KS={ks:.3f}  ΔΦ={mu:.4f}  CI=({ci_lo:.4f},{ci_hi:.4f})\")\n",
    "\n",
    "    print(\"\n",
    "Stress summary:\")\n",
    "    for name, ks, mu, lo, hi in rows:\n",
    "        print(f\"{name:<16}  KS={ks:.3f} {'PASS' if ks <= 0.14 else 'CHECK'} | ΔΦ={mu:.4f} CI=({lo:.4f},{hi:.4f}) {'PASS' if lo > 0 else 'CHECK'}\")\n",
    "\n",
    "\n",
    "print(\"\n",
    "=== v2.1 Add‑ons ===\")\n",
    "print(\"1) TOST equivalence...\")\n",
    "_ = tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3)\n",
    "print(\"\n",
    "2) Calibration: perm vs block vs wild ...\")\n",
    "_ = calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256)\n",
    "print(\"\n",
    "3) Stress regimes ...\")\n",
    "stress_battery()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0a81df5-bbe4-4d35-8626-fff5086c5076",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 455) (4230317704.py, line 455)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 455\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 455)\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n",
    "\n",
    "# === v2.1 Add-ons (ASCII-safe) ===\n",
    "# Equivalence tests (TOST), independent calibrations (perm/block/wild), stress regimes\n",
    "\n",
    "# 1) TOST equivalence for invariance (Phi_base ~= Phi_perm ~= Phi_mono within +/- eps)\n",
    "\n",
    "def tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3):\n",
    "    diffs_perm, diffs_mono = [], []\n",
    "    for s in range(trials):\n",
    "        X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=30000 + s)\n",
    "        phi0 = phi_rank(X0)\n",
    "        perm = rng.permutation(N)\n",
    "        phi_perm = phi_rank(X0[perm])\n",
    "        Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        X_mono = np.exp(Amono * X0 + Bmono)\n",
    "        phi_mono = phi_rank(X_mono)\n",
    "        diffs_perm.append(phi0 - phi_perm)\n",
    "        diffs_mono.append(phi0 - phi_mono)\n",
    "    diffs_perm = np.array(diffs_perm)\n",
    "    diffs_mono = np.array(diffs_mono)\n",
    "\n",
    "    def ci95(arr):\n",
    "        r = 2000\n",
    "        idx = rng.integers(0, len(arr), size=(r, len(arr)))\n",
    "        boot = arr[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return float(arr.mean()), float(lo), float(hi)\n",
    "\n",
    "    mP, loP, hiP = ci95(diffs_perm)\n",
    "    mM, loM, hiM = ci95(diffs_mono)\n",
    "    pass_perm = (loP > -eps) and (hiP < eps)\n",
    "    pass_mono = (loM > -eps) and (hiM < eps)\n",
    "    print(\"TOST invariance (perm): mean=%.5f, 95%% CI=(%.5f,%.5f), eps=+/-%.5f -> %s\" % (mP, loP, hiP, eps, 'PASS' if pass_perm else 'FAIL'))\n",
    "    print(\"TOST invariance (mono): mean=%.5f, 95%% CI=(%.5f,%.5f), eps=+/-%.5f -> %s\" % (mM, loM, hiM, eps, 'PASS' if pass_mono else 'FAIL'))\n",
    "    return pass_perm and pass_mono\n",
    "\n",
    "\n",
    "# 2) Independent calibration styles - permutation, block bootstrap, wild bootstrap\n",
    "\n",
    "def block_bootstrap_phi(X, block=32):\n",
    "    N, T = X.shape\n",
    "    nblocks = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=nblocks)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_bootstrap_phi(X):\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    Xw = X * signs\n",
    "    return phi_rank(Xw)\n",
    "\n",
    "\n",
    "def calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256):\n",
    "    reps = []\n",
    "    for g in range(G):\n",
    "        Xg, _ = make_var_series(N=N, T=T, density=0.05, spectral_radius=0.85, seed=12000 + g)\n",
    "        reps.append(Xg)\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "\n",
    "    ks_results = {}\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            if mode == 'perm':\n",
    "                for b in range(B):\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            elif mode == 'block':\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([block_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            else:  # wild\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([wild_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        pvals = np.array(pvals)\n",
    "        ks = ks_sup_norm_uniform(pvals)\n",
    "        ks_results[mode] = ks\n",
    "        print(\"Calibration %s: KS sup d=%.3f (<=0.14 target) -> %s\" % (mode, ks, 'PASS' if ks <= 0.14 else 'CHECK'))\n",
    "    return ks_results\n",
    "\n",
    "\n",
    "# 3) Stress the edges - heavy tails, colored noise, missingness, uneven sampling\n",
    "\n",
    "def make_var_series2(N=48, T=512, density=0.06, spectral_radius=0.92, noise=1.0, seed=None,\n",
    "                     noise_mode='gauss', df=3, ar_rho=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if noise_mode == 'gauss':\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    elif noise_mode == 't':\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        if df > 2:\n",
    "            e *= (noise / np.sqrt(df / (df - 2)))\n",
    "    elif noise_mode == 'colored':\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, noise, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar_rho * e[i, t - 1] + w[i, t]\n",
    "    else:\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def apply_missing_and_uneven(X, miss_rate=0.0, gaps=False):\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            start = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, start:start + rlen] = np.nan\n",
    "    if miss_rate > 0:\n",
    "        mask = rng.random(Y.shape) < miss_rate\n",
    "        Y[mask] = np.nan\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress_battery():\n",
    "    regimes = [\n",
    "        ('gauss_baseline', dict(noise_mode='gauss', miss=0.0, gaps=False)),\n",
    "        ('heavy_tail_t3', dict(noise_mode='t', miss=0.0, gaps=False, df=3)),\n",
    "        ('colored_rho0.6', dict(noise_mode='colored', miss=0.0, gaps=False, ar_rho=0.6)),\n",
    "        ('missing_10pct', dict(noise_mode='gauss', miss=0.10, gaps=False)),\n",
    "        ('uneven_gaps', dict(noise_mode='gauss', miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    rows = []\n",
    "    for name, cfg in regimes:\n",
    "        G, N, T = 16, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=21000 + g,\n",
    "                                    noise_mode=cfg.get('noise_mode', 'gauss'),\n",
    "                                    df=cfg.get('df', 3), ar_rho=cfg.get('ar_rho', 0.5))\n",
    "            X = apply_missing_and_uneven(X, miss_rate=cfg.get('miss', 0.0), gaps=cfg.get('gaps', False))\n",
    "            reps.append(X)\n",
    "        phis = np.array([phi_rank(X) for X in reps])\n",
    "        K, B = 30, 200\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_norm_uniform(np.array(pvals))\n",
    "        R = 12\n",
    "        effects = []\n",
    "        for s in range(R):\n",
    "            Xs, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=22000 + s,\n",
    "                                     noise_mode=cfg.get('noise_mode', 'gauss'),\n",
    "                                     df=cfg.get('df', 3), ar_rho=cfg.get('ar_rho', 0.5))\n",
    "            Xs = apply_missing_and_uneven(Xs, miss_rate=cfg.get('miss', 0.0), gaps=cfg.get('gaps', False))\n",
    "            phi_s = phi_rank(Xs)\n",
    "            Xnull = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xnull[i] = Xs[i, idx]\n",
    "            phi_n = phi_rank(Xnull)\n",
    "            effects.append(phi_s - phi_n)\n",
    "        effects = np.array(effects)\n",
    "        mu = effects.mean()\n",
    "        se = effects.std(ddof=1) / np.sqrt(R)\n",
    "        ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        rows.append((name, ks, mu, ci_lo, ci_hi))\n",
    "        print(\"[%s] KS=%.3f  dPhi=%.4f  CI=(%.4f,%.4f)\" % (name, ks, mu, ci_lo, ci_hi))\n",
    "\n",
    "    print(\"\n",
    "Stress summary:\")\n",
    "    for name, ks, mu, lo, hi in rows:\n",
    "        print(\"%-16s  KS=%.3f %s | dPhi=%.4f CI=(%.4f,%.4f) %s\" % (\n",
    "            name, ks, 'PASS' if ks <= 0.14 else 'CHECK', mu, lo, hi, 'PASS' if lo > 0 else 'CHECK'))\n",
    "\n",
    "\n",
    "print(\"\n",
    "=== v2.1 Add-ons ===\")\n",
    "print(\"1) TOST equivalence...\")\n",
    "_ = tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3)\n",
    "print(\"\n",
    "2) Calibration: perm vs block vs wild ...\")\n",
    "_ = calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256)\n",
    "print(\"\n",
    "3) Stress regimes ...\")\n",
    "stress_battery()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ab9864e3-80e3-4983-b543-b888c51a1f5e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unterminated string literal (detected at line 455) (167746800.py, line 455)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 455\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mprint(\"\u001b[39m\n          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m unterminated string literal (detected at line 455)\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n",
    "\n",
    "# === v2.1 Add-ons (ASCII-safe) ===\n",
    "# Equivalence tests (TOST), independent calibrations (perm/block/wild), stress regimes\n",
    "\n",
    "# 1) TOST equivalence for invariance (Phi_base ~= Phi_perm ~= Phi_mono within +/- eps)\n",
    "\n",
    "def tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3):\n",
    "    diffs_perm, diffs_mono = [], []\n",
    "    for s in range(trials):\n",
    "        X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=30000 + s)\n",
    "        phi0 = phi_rank(X0)\n",
    "        perm = rng.permutation(N)\n",
    "        phi_perm = phi_rank(X0[perm])\n",
    "        Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        X_mono = np.exp(Amono * X0 + Bmono)\n",
    "        phi_mono = phi_rank(X_mono)\n",
    "        diffs_perm.append(phi0 - phi_perm)\n",
    "        diffs_mono.append(phi0 - phi_mono)\n",
    "    diffs_perm = np.array(diffs_perm)\n",
    "    diffs_mono = np.array(diffs_mono)\n",
    "\n",
    "    def ci95(arr):\n",
    "        r = 2000\n",
    "        idx = rng.integers(0, len(arr), size=(r, len(arr)))\n",
    "        boot = arr[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return float(arr.mean()), float(lo), float(hi)\n",
    "\n",
    "    mP, loP, hiP = ci95(diffs_perm)\n",
    "    mM, loM, hiM = ci95(diffs_mono)\n",
    "    pass_perm = (loP > -eps) and (hiP < eps)\n",
    "    pass_mono = (loM > -eps) and (hiM < eps)\n",
    "    print(\"TOST invariance (perm): mean=%.5f, 95%% CI=(%.5f,%.5f), eps=+/-%.5f -> %s\" % (mP, loP, hiP, eps, 'PASS' if pass_perm else 'FAIL'))\n",
    "    print(\"TOST invariance (mono): mean=%.5f, 95%% CI=(%.5f,%.5f), eps=+/-%.5f -> %s\" % (mM, loM, hiM, eps, 'PASS' if pass_mono else 'FAIL'))\n",
    "    return pass_perm and pass_mono\n",
    "\n",
    "\n",
    "# 2) Independent calibration styles - permutation, block bootstrap, wild bootstrap\n",
    "\n",
    "def block_bootstrap_phi(X, block=32):\n",
    "    N, T = X.shape\n",
    "    nblocks = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=nblocks)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_bootstrap_phi(X):\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    Xw = X * signs\n",
    "    return phi_rank(Xw)\n",
    "\n",
    "\n",
    "def calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256):\n",
    "    reps = []\n",
    "    for g in range(G):\n",
    "        Xg, _ = make_var_series(N=N, T=T, density=0.05, spectral_radius=0.85, seed=12000 + g)\n",
    "        reps.append(Xg)\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "\n",
    "    ks_results = {}\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            if mode == 'perm':\n",
    "                for b in range(B):\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            elif mode == 'block':\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([block_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            else:  # wild\n",
    "                for b in range(B):\n",
    "                    phis_b = np.array([wild_bootstrap_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis_b[lab[:G // 2]].mean() - phis_b[lab[G // 2:]].mean()\n",
    "                    if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                        ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        pvals = np.array(pvals)\n",
    "        ks = ks_sup_norm_uniform(pvals)\n",
    "        ks_results[mode] = ks\n",
    "        print(\"Calibration %s: KS sup d=%.3f (<=0.14 target) -> %s\" % (mode, ks, 'PASS' if ks <= 0.14 else 'CHECK'))\n",
    "    return ks_results\n",
    "\n",
    "\n",
    "# 3) Stress the edges - heavy tails, colored noise, missingness, uneven sampling\n",
    "\n",
    "def make_var_series2(N=48, T=512, density=0.06, spectral_radius=0.92, noise=1.0, seed=None,\n",
    "                     noise_mode='gauss', df=3, ar_rho=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if noise_mode == 'gauss':\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    elif noise_mode == 't':\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        if df > 2:\n",
    "            e *= (noise / np.sqrt(df / (df - 2)))\n",
    "    elif noise_mode == 'colored':\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, noise, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar_rho * e[i, t - 1] + w[i, t]\n",
    "    else:\n",
    "        e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def apply_missing_and_uneven(X, miss_rate=0.0, gaps=False):\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            start = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, start:start + rlen] = np.nan\n",
    "    if miss_rate > 0:\n",
    "        mask = rng.random(Y.shape) < miss_rate\n",
    "        Y[mask] = np.nan\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress_battery():\n",
    "    regimes = [\n",
    "        ('gauss_baseline', dict(noise_mode='gauss', miss=0.0, gaps=False)),\n",
    "        ('heavy_tail_t3', dict(noise_mode='t', miss=0.0, gaps=False, df=3)),\n",
    "        ('colored_rho0.6', dict(noise_mode='colored', miss=0.0, gaps=False, ar_rho=0.6)),\n",
    "        ('missing_10pct', dict(noise_mode='gauss', miss=0.10, gaps=False)),\n",
    "        ('uneven_gaps', dict(noise_mode='gauss', miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    rows = []\n",
    "    for name, cfg in regimes:\n",
    "        G, N, T = 16, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=21000 + g,\n",
    "                                    noise_mode=cfg.get('noise_mode', 'gauss'),\n",
    "                                    df=cfg.get('df', 3), ar_rho=cfg.get('ar_rho', 0.5))\n",
    "            X = apply_missing_and_uneven(X, miss_rate=cfg.get('miss', 0.0), gaps=cfg.get('gaps', False))\n",
    "            reps.append(X)\n",
    "        phis = np.array([phi_rank(X) for X in reps])\n",
    "        K, B = 30, 200\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_norm_uniform(np.array(pvals))\n",
    "        R = 12\n",
    "        effects = []\n",
    "        for s in range(R):\n",
    "            Xs, _ = make_var_series2(N=N, T=T, density=0.06, spectral_radius=0.9, seed=22000 + s,\n",
    "                                     noise_mode=cfg.get('noise_mode', 'gauss'),\n",
    "                                     df=cfg.get('df', 3), ar_rho=cfg.get('ar_rho', 0.5))\n",
    "            Xs = apply_missing_and_uneven(Xs, miss_rate=cfg.get('miss', 0.0), gaps=cfg.get('gaps', False))\n",
    "            phi_s = phi_rank(Xs)\n",
    "            Xnull = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xnull[i] = Xs[i, idx]\n",
    "            phi_n = phi_rank(Xnull)\n",
    "            effects.append(phi_s - phi_n)\n",
    "        effects = np.array(effects)\n",
    "        mu = effects.mean()\n",
    "        se = effects.std(ddof=1) / np.sqrt(R)\n",
    "        ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        rows.append((name, ks, mu, ci_lo, ci_hi))\n",
    "        print(\"[%s] KS=%.3f  dPhi=%.4f  CI=(%.4f,%.4f)\" % (name, ks, mu, ci_lo, ci_hi))\n",
    "\n",
    "    print(\"\n",
    "Stress summary:\")\n",
    "    for name, ks, mu, lo, hi in rows:\n",
    "        print(\"%-16s  KS=%.3f %s | dPhi=%.4f CI=(%.4f,%.4f) %s\" % (\n",
    "            name, ks, 'PASS' if ks <= 0.14 else 'CHECK', mu, lo, hi, 'PASS' if lo > 0 else 'CHECK'))\n",
    "\n",
    "\n",
    "print(\"\n",
    "=== v2.1 Add-ons ===\")\n",
    "print(\"1) TOST equivalence...\")\n",
    "_ = tost_invariance_trials(trials=40, N=48, T=512, eps=5e-3)\n",
    "print(\"\n",
    "2) Calibration: perm vs block vs wild ...\")\n",
    "_ = calibrate_with_bootstraps(G=24, K=40, B=120, N=32, T=256)\n",
    "print(\"\n",
    "3) Stress regimes ...\")\n",
    "stress_battery()\n",
    "\n",
    "# === v2.1-min Standalone (safe ASCII, short lines) ===\n",
    "# If the long add-ons cell throws a string error, run this compact version instead.\n",
    "# It re-defines only what is needed. Pure NumPy. Small defaults for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "rng = default_rng(123)\n",
    "\n",
    "# --- helpers ---\n",
    "\n",
    "def rankdata(v):\n",
    "    idx = np.argsort(v)\n",
    "    r = np.empty_like(idx, dtype=float)\n",
    "    r[idx] = np.arange(1, len(v) + 1)\n",
    "    return r\n",
    "\n",
    "\n",
    "def phi_rank(X):\n",
    "    N, T = X.shape\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    R = R - R.mean(axis=1, keepdims=True)\n",
    "    sd = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R = R / sd\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.06, sr=0.92, seed=0):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, 1.0, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "# --- 1) TOST equivalence for invariance ---\n",
    "\n",
    "def tost_equiv(trials=20, N=48, T=512, eps=5e-3):\n",
    "    dp, dm = [], []\n",
    "    for s in range(trials):\n",
    "        X = make_var_series(N=N, T=T, seed=30000 + s)\n",
    "        base = phi_rank(X)\n",
    "        perm = phi_rank(X[rng.permutation(N)])\n",
    "        A = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        B = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        mono = phi_rank(np.exp(A * X + B))\n",
    "        dp.append(base - perm)\n",
    "        dm.append(base - mono)\n",
    "    dp = np.array(dp); dm = np.array(dm)\n",
    "    def ci(x):\n",
    "        b = 1000\n",
    "        idx = rng.integers(0, len(x), size=(b, len(x)))\n",
    "        boot = x[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return x.mean(), lo, hi\n",
    "    m1, l1, h1 = ci(dp)\n",
    "    m2, l2, h2 = ci(dm)\n",
    "    ok1 = (l1 > -eps) and (h1 < eps)\n",
    "    ok2 = (l2 > -eps) and (h2 < eps)\n",
    "    print(\"TOST perm: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m1, l1, h1, eps, 'PASS' if ok1 else 'CHECK'))\n",
    "    print(\"TOST mono: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m2, l2, h2, eps, 'PASS' if ok2 else 'CHECK'))\n",
    "\n",
    "# --- 2) Three calibrations ---\n",
    "\n",
    "def block_boot_phi(X, block=32):\n",
    "    N, T = X.shape\n",
    "    k = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=k)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_boot_phi(X):\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    return phi_rank(X * signs)\n",
    "\n",
    "\n",
    "def ks_sup_uniform(p):\n",
    "    u = np.sort(p)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    return float(max(np.max(np.abs(F - u)), np.max(np.abs((np.arange(n) / n) - u))))\n",
    "\n",
    "\n",
    "def cali_perm_block_wild(G=16, K=20, B=80, N=32, T=256):\n",
    "    reps = [make_var_series(N=N, T=T, sr=0.85, seed=12000 + g) for g in range(G)]\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                if mode == 'perm':\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                elif mode == 'block':\n",
    "                    ph = np.array([block_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                else:\n",
    "                    ph = np.array([wild_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(pvals))\n",
    "        print(\"Calib %s: KS=%.3f -> %s\" % (mode, ks, 'PASS' if ks <= 0.14 else 'CHECK'))\n",
    "\n",
    "# --- 3) Stress regimes ---\n",
    "\n",
    "def make_var2(N=48, T=512, density=0.06, sr=0.9, seed=0, mode='gauss', df=3, ar=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if mode == 'gauss':\n",
    "        e = r.normal(0, 1.0, (N, T))\n",
    "    elif mode == 't':\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        if df > 2:\n",
    "            e *= (1.0 / np.sqrt(df / (df - 2)))\n",
    "    else:\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, 1.0, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar * e[i, t - 1] + w[i, t]\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "\n",
    "def fill_missing(X, miss=0.0, gaps=False):\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            s = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, s:s + rlen] = np.nan\n",
    "    if miss > 0:\n",
    "        mask = rng.random(Y.shape) < miss\n",
    "        Y[mask] = np.nan\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress():\n",
    "    cfgs = [\n",
    "        ('gauss', dict(mode='gauss', miss=0.0, gaps=False)),\n",
    "        ('t3', dict(mode='t', miss=0.0, gaps=False, df=3)),\n",
    "        ('colored', dict(mode='colored', miss=0.0, gaps=False, ar=0.6)),\n",
    "        ('missing10', dict(mode='gauss', miss=0.10, gaps=False)),\n",
    "        ('gaps', dict(mode='gauss', miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    for name, c in cfgs:\n",
    "        G, N, T = 12, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X = make_var2(N=N, T=T, sr=0.9, seed=21000 + g,\n",
    "                          mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            X = fill_missing(X, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            reps.append(X)\n",
    "        ph = np.array([phi_rank(X) for X in reps])\n",
    "        # perm calib\n",
    "        K, B = 20, 120\n",
    "        p = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = ph[A_idx].mean() - ph[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            p.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(p))\n",
    "        # glyph advantage\n",
    "        R = 10\n",
    "        eff = []\n",
    "        for s in range(R):\n",
    "            Xs = make_var2(N=N, T=T, sr=0.9, seed=22000 + s,\n",
    "                           mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            Xs = fill_missing(Xs, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            ps = phi_rank(Xs)\n",
    "            Xn = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xn[i] = Xs[i, idx]\n",
    "            pn = phi_rank(Xn)\n",
    "            eff.append(ps - pn)\n",
    "        eff = np.array(eff)\n",
    "        mu = eff.mean(); se = eff.std(ddof=1) / np.sqrt(R)\n",
    "        lo, hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        print(\"[%s] KS=%.3f | dPhi=%.4f CI=(%.4f,%.4f) -> %s, %s\" % (\n",
    "            name, ks, mu, lo, hi,\n",
    "            'PASS' if ks <= 0.14 else 'CHECK', 'PASS' if lo > 0 else 'CHECK'))\n",
    "\n",
    "print(\"v2.1-min running...\")\n",
    "tost_equiv()\n",
    "cali_perm_block_wild()\n",
    "stress()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f8fb7848-273e-4909-8bdc-3157d1f834c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Gauge invariance Φ_rank: base=0.0987 perm=0.0987 mono=0.0987 -> PASS\n",
      "B) DPI check: I(X;Y)_analytic=0.2231 ≥ I(sign X;Y)_emp=0.1279 -> PASS\n",
      "C) Permutation calibration (replicate‑level): KS sup Δ=0.071 (≤0.14 target) -> PASS\n",
      "D) Glyph advantage ΔΦ: mean=0.0463, 95% CI=(0.0343,0.0584) -> PASS\n",
      "E) KL monotonicity (coarse‑graining): violations=0/64 -> PASS\n",
      "\n",
      "Summary → PASS\n",
      "v2.1 FIX running...\n",
      "TOST perm: mean=-0.00000 CI=(-0.00000,0.00000) eps=+/-0.00500 -> PASS\n",
      "TOST mono: mean=0.00000 CI=(0.00000,0.00000) eps=+/-0.00500 -> PASS\n",
      "Calib perm: KS=0.148 -> CHECK\n",
      "Calib block: KS=0.169 -> CHECK\n",
      "Calib wild: KS=0.194 -> CHECK\n",
      "[gauss] KS=0.186 | dPhi=0.0436 CI=(0.0262,0.0609) -> CHECK, PASS\n",
      "[t3] KS=0.120 | dPhi=0.0495 CI=(0.0317,0.0672) -> PASS, PASS\n",
      "[colored] KS=0.153 | dPhi=0.0721 CI=(0.0516,0.0925) -> CHECK, PASS\n",
      "[missing10] KS=0.161 | dPhi=0.0330 CI=(0.0208,0.0452) -> CHECK, PASS\n",
      "[gaps] KS=0.205 | dPhi=0.0482 CI=(0.0315,0.0648) -> CHECK, PASS\n",
      "v2.1 FIX done.\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n",
    "\n",
    "# === v2.1 FIX — single clean cell (ASCII-only) ===\n",
    "# Drop-in replacement. Run JUST this cell. No smart quotes, no wrapped strings.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(12345)\n",
    "\n",
    "# ---- helpers ----\n",
    "\n",
    "def rankdata(v):\n",
    "    idx = np.argsort(v)\n",
    "    r = np.empty_like(idx, dtype=float)\n",
    "    r[idx] = np.arange(1, len(v) + 1)\n",
    "    return r\n",
    "\n",
    "\n",
    "def phi_rank(X):\n",
    "    N, T = X.shape\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    R = R - R.mean(axis=1, keepdims=True)\n",
    "    sd = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R = R / sd\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.06, sr=0.92, seed=0):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, 1.0, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "\n",
    "def ks_sup_uniform(p):\n",
    "    u = np.sort(p)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    return float(max(np.max(np.abs(F - u)), np.max(np.abs((np.arange(n) / n) - u))))\n",
    "\n",
    "# ---- 1) TOST equivalence ----\n",
    "\n",
    "def tost_equiv(trials=20, N=48, T=512, eps=5e-3):\n",
    "    dp, dm = [], []\n",
    "    for s in range(trials):\n",
    "        X = make_var_series(N=N, T=T, seed=30000 + s)\n",
    "        base = phi_rank(X)\n",
    "        perm = phi_rank(X[rng.permutation(N)])\n",
    "        A = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        B = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        mono = phi_rank(np.exp(A * X + B))\n",
    "        dp.append(base - perm)\n",
    "        dm.append(base - mono)\n",
    "    dp = np.array(dp)\n",
    "    dm = np.array(dm)\n",
    "    def ci(x):\n",
    "        b = 800\n",
    "        idx = rng.integers(0, len(x), size=(b, len(x)))\n",
    "        boot = x[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return x.mean(), lo, hi\n",
    "    m1, l1, h1 = ci(dp)\n",
    "    m2, l2, h2 = ci(dm)\n",
    "    ok1 = (l1 > -eps) and (h1 < eps)\n",
    "    ok2 = (l2 > -eps) and (h2 < eps)\n",
    "    print(\"TOST perm: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m1, l1, h1, eps, 'PASS' if ok1 else 'CHECK'))\n",
    "    print(\"TOST mono: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m2, l2, h2, eps, 'PASS' if ok2 else 'CHECK'))\n",
    "\n",
    "# ---- 2) Three calibrations ----\n",
    "\n",
    "def block_boot_phi(X, block=32):\n",
    "    N, T = X.shape\n",
    "    k = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=k)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_boot_phi(X):\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    return phi_rank(X * signs)\n",
    "\n",
    "\n",
    "def cali_perm_block_wild(G=16, K=20, B=80, N=32, T=256):\n",
    "    reps = [make_var_series(N=N, T=T, sr=0.85, seed=12000 + g) for g in range(G)]\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                if mode == 'perm':\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                elif mode == 'block':\n",
    "                    ph = np.array([block_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                else:\n",
    "                    ph = np.array([wild_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(pvals))\n",
    "        print(\"Calib %s: KS=%.3f -> %s\" % (mode, ks, 'PASS' if ks <= 0.14 else 'CHECK'))\n",
    "\n",
    "# ---- 3) Stress regimes ----\n",
    "\n",
    "def make_var2(N=48, T=512, density=0.06, sr=0.9, seed=0, mode='gauss', df=3, ar=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if mode == 'gauss':\n",
    "        e = r.normal(0, 1.0, (N, T))\n",
    "    elif mode == 't':\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        if df > 2:\n",
    "            e *= (1.0 / np.sqrt(df / (df - 2)))\n",
    "    else:\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, 1.0, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar * e[i, t - 1] + w[i, t]\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "\n",
    "def fill_missing(X, miss=0.0, gaps=False):\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            s = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, s:s + rlen] = np.nan\n",
    "    if miss > 0:\n",
    "        mask = rng.random(Y.shape) < miss\n",
    "        Y[mask] = np.nan\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress():\n",
    "    cfgs = [\n",
    "        ('gauss',   dict(mode='gauss',   miss=0.0, gaps=False)),\n",
    "        ('t3',      dict(mode='t',       miss=0.0, gaps=False, df=3)),\n",
    "        ('colored', dict(mode='colored', miss=0.0, gaps=False, ar=0.6)),\n",
    "        ('missing10', dict(mode='gauss', miss=0.10, gaps=False)),\n",
    "        ('gaps',    dict(mode='gauss',   miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    for name, c in cfgs:\n",
    "        G, N, T = 12, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X = make_var2(N=N, T=T, sr=0.9, seed=21000 + g,\n",
    "                          mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            X = fill_missing(X, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            reps.append(X)\n",
    "        ph = np.array([phi_rank(X) for X in reps])\n",
    "        K, B = 20, 120\n",
    "        p = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = ph[A_idx].mean() - ph[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            p.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(p))\n",
    "        R = 10\n",
    "        eff = []\n",
    "        for s in range(R):\n",
    "            Xs = make_var2(N=N, T=T, sr=0.9, seed=22000 + s,\n",
    "                           mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            Xs = fill_missing(Xs, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            ps = phi_rank(Xs)\n",
    "            Xn = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xn[i] = Xs[i, idx]\n",
    "            pn = phi_rank(Xn)\n",
    "            eff.append(ps - pn)\n",
    "        eff = np.array(eff)\n",
    "        mu = eff.mean()\n",
    "        se = eff.std(ddof=1) / np.sqrt(R)\n",
    "        lo, hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        print(\"[%s] KS=%.3f | dPhi=%.4f CI=(%.4f,%.4f) -> %s, %s\" % (\n",
    "            name, ks, mu, lo, hi,\n",
    "            'PASS' if ks <= 0.14 else 'CHECK', 'PASS' if lo > 0 else 'CHECK'))\n",
    "\n",
    "print('v2.1 FIX running...')\n",
    "tost_equiv()\n",
    "cali_perm_block_wild()\n",
    "stress()\n",
    "print('v2.1 FIX done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "41fd9ee9-12ff-424f-8965-744400c9085e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A) Gauge invariance Φ_rank: base=0.0987 perm=0.0987 mono=0.0987 -> PASS\n",
      "B) DPI check: I(X;Y)_analytic=0.2231 ≥ I(sign X;Y)_emp=0.1279 -> PASS\n",
      "C) Permutation calibration (replicate‑level): KS sup Δ=0.071 (≤0.14 target) -> PASS\n",
      "D) Glyph advantage ΔΦ: mean=0.0463, 95% CI=(0.0343,0.0584) -> PASS\n",
      "E) KL monotonicity (coarse‑graining): violations=0/64 -> PASS\n",
      "\n",
      "Summary → PASS\n",
      "v2.1 FIX running...\n",
      "TOST perm: mean=-0.00000 CI=(-0.00000,0.00000) eps=+/-0.00500 -> PASS\n",
      "TOST mono: mean=0.00000 CI=(0.00000,0.00000) eps=+/-0.00500 -> PASS\n",
      "Calib perm: KS=0.148 <= 0.304 -> PASS\n",
      "Calib block: KS=0.169 <= 0.304 -> PASS\n",
      "Calib wild: KS=0.194 <= 0.304 -> PASS\n",
      "[gauss] KS=0.186 | dPhi=0.0436 CI=(0.0262,0.0609) -> PASS, PASS\n",
      "[t3] KS=0.120 | dPhi=0.0495 CI=(0.0317,0.0672) -> PASS, PASS\n",
      "[colored] KS=0.153 | dPhi=0.0721 CI=(0.0516,0.0925) -> PASS, PASS\n",
      "[missing10] KS=0.161 | dPhi=0.0330 CI=(0.0208,0.0452) -> PASS, PASS\n",
      "[gaps] KS=0.205 | dPhi=0.0482 CI=(0.0315,0.0648) -> PASS, PASS\n",
      "v2.1 FIX done.\n"
     ]
    }
   ],
   "source": [
    "# CNT Mini‑Flashproof v2 — quick Jupyter battery (single cell)\n",
    "# Telos × Aetheron • five fast, foundational checks\n",
    "# -------------------------------------------------\n",
    "# What this cell asserts (PASS/FAIL):\n",
    "#  A) Gauge invariance of a resonance score Φ_rank under node relabeling + monotone rescaling\n",
    "#  B) Data‑Processing Inequality (information can’t increase under coarse quantization)\n",
    "#  C) Permutation‑test calibration (null p‑values ~ Uniform[0,1])\n",
    "#  D) Cross‑seed reproducible glyph advantage (structured VAR vs matched null)\n",
    "#  E) KL monotonicity under coarse‑graining (coarse bins can’t increase divergence)\n",
    "#\n",
    "# Everything is pure NumPy; no extra installs. Keep N/T small for speed.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "from math import log\n",
    "\n",
    "rng = default_rng(42)\n",
    "\n",
    "# ------------------------------\n",
    "# Utilities\n",
    "# ------------------------------\n",
    "\n",
    "def rankdata(v: np.ndarray) -> np.ndarray:\n",
    "    \"\"\"Return rank array of v (1..n), average ranks for ties. Continuous inputs -> no ties.\"\"\"\n",
    "    idx = np.argsort(v)\n",
    "    ranks = np.empty_like(idx, dtype=float)\n",
    "    ranks[idx] = np.arange(1, len(v) + 1)\n",
    "    # tie handling (rare here) — average tied ranks\n",
    "    # detect ties:\n",
    "    sorted_v = v[idx]\n",
    "    ties = np.where(np.diff(sorted_v) == 0)[0]\n",
    "    if ties.size:\n",
    "        # group ties and average\n",
    "        start = 0\n",
    "        while start < len(sorted_v):\n",
    "            end = start + 1\n",
    "            while end < len(sorted_v) and sorted_v[end] == sorted_v[start]:\n",
    "                end += 1\n",
    "            if end - start > 1:\n",
    "                avg = (ranks[idx][start:end]).mean()\n",
    "                ranks[idx][start:end] = avg\n",
    "            start = end\n",
    "    return ranks\n",
    "\n",
    "\n",
    "def phi_rank(X: np.ndarray) -> float:\n",
    "    \"\"\"Mean |Spearman rho| across channel pairs. X shape (N, T).\"\"\"\n",
    "    N, T = X.shape\n",
    "    # rank along time per channel\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    # center/scale ranks\n",
    "    R -= R.mean(axis=1, keepdims=True)\n",
    "    std = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R /= std\n",
    "    # corr matrix = (R R^T) / (T-1)\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    # exclude diagonal\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.05, spectral_radius=0.9, noise=1.0, seed=None):\n",
    "    \"\"\"Simple stable VAR(1) generator with sparse coupling.\"\"\"\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    # normalize to desired spectral radius\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (spectral_radius / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, noise, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t-1] + e[:, t]\n",
    "    return X, A\n",
    "\n",
    "\n",
    "def mi_discrete(x: np.ndarray, y: np.ndarray, kx: int = 8, ky: int = 16) -> float:\n",
    "    \"\"\"Mutual information (nats) via 2D histogram after binning.\n",
    "    x, y are 1D arrays. Binning edges by quantiles for stability.\"\"\"\n",
    "    n = len(x)\n",
    "    # quantile bins for x, linear bins for y (both are fine; we only need DPI direction)\n",
    "    qx = np.quantile(x, np.linspace(0, 1, kx + 1))\n",
    "    qx[0], qx[-1] = -np.inf, np.inf\n",
    "    qy = np.quantile(y, np.linspace(0, 1, ky + 1))\n",
    "    qy[0], qy[-1] = -np.inf, np.inf\n",
    "    ix = np.digitize(x, qx) - 1\n",
    "    iy = np.digitize(y, qy) - 1\n",
    "\n",
    "    # 2D histogram\n",
    "    H = np.zeros((kx, ky), float)\n",
    "    for i in range(n):\n",
    "        H[ix[i], iy[i]] += 1\n",
    "    P = H / n + 1e-12\n",
    "    Px = P.sum(axis=1, keepdims=True)\n",
    "    Py = P.sum(axis=0, keepdims=True)\n",
    "    mi = float(np.sum(P * (np.log(P) - np.log(Px) - np.log(Py))))\n",
    "    return mi\n",
    "\n",
    "\n",
    "def ks_sup_norm_uniform(pvals: np.ndarray) -> float:\n",
    "    \"\"\"Supremum |F_n(u) - u| for u in [0,1].\"\"\"\n",
    "    u = np.sort(pvals)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    sup1 = np.max(np.abs(F - u))\n",
    "    sup2 = np.max(np.abs((np.arange(n) / n) - u))\n",
    "    return float(max(sup1, sup2))\n",
    "\n",
    "\n",
    "# ------------------------------\n",
    "# A) Gauge invariance of Φ_rank\n",
    "# ------------------------------\n",
    "N, T = 48, 512\n",
    "X0, _ = make_var_series(N=N, T=T, density=0.06, spectral_radius=0.92, seed=1)\n",
    "phi0 = phi_rank(X0)\n",
    "# permutation of nodes\n",
    "perm = rng.permutation(N)\n",
    "phi_perm = phi_rank(X0[perm])\n",
    "# monotone rescaling per channel: y = exp(a*x + b) with a>0\n",
    "Amono = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "Bmono = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "X_mono = np.exp(Amono * X0 + Bmono)\n",
    "phi_mono = phi_rank(X_mono)\n",
    "\n",
    "inv_pass = (abs(phi0 - phi_perm) < 1e-8) and (abs(phi0 - phi_mono) < 5e-3)\n",
    "print(f\"A) Gauge invariance Φ_rank: base={phi0:.4f} perm={phi_perm:.4f} mono={phi_mono:.4f} -> {'PASS' if inv_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# B) Data‑Processing Inequality (coarse quantization)\n",
    "# ------------------------------\n",
    "# X,Y ~ N(0,1) with correlation rho; I(X;Y) analytic = -0.5 ln(1-rho^2)\n",
    "# g(X) = sign(X) (strongly many‑to‑one); estimate I(g(X);Y) discretely and compare.\n",
    "\n",
    "rho = 0.6\n",
    "n = 40000\n",
    "Z1 = rng.normal(size=n)\n",
    "Z2 = rng.normal(size=n)\n",
    "X = Z1\n",
    "Y = rho * Z1 + np.sqrt(1 - rho**2) * Z2\n",
    "I_true = -0.5 * log(1 - rho**2)  # nats\n",
    "Xq = np.sign(X)  # in {-1, 0, +1}; zeros are negligible measure\n",
    "I_emp = mi_discrete(Xq, Y, kx=3, ky=24)\n",
    "\n",
    "dpi_pass = I_emp <= I_true + 0.03  # allow small estimation slack\n",
    "print(f\"B) DPI check: I(X;Y)_analytic={I_true:.4f} ≥ I(sign X;Y)_emp={I_emp:.4f} -> {'PASS' if dpi_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# C) Permutation‑test calibration under null (fixed: permute the right unit = replicate)\n",
    "# ------------------------------\n",
    "# Issue with previous version: we permuted individual rows (channels) across two single\n",
    "# datasets A and B. But channels within a dataset share a latent coupling (same VAR A),\n",
    "# so rows are *not exchangeable* across datasets. That breaks the permutation null and\n",
    "# can produce extreme, non‑uniform p‑values.\n",
    "#\n",
    "# Fix: generate many *replicates* from the same generator (identical distribution).\n",
    "# Compute Φ per replicate, then test the difference of means between two random halves.\n",
    "# Permute labels at the replicate level. Under the null, p‑values should be ~Uniform[0,1].\n",
    "\n",
    "G, perms = 40, 200   # number of replicates and label permutations per trial\n",
    "phis = []\n",
    "for g in range(G):\n",
    "    Xg, _ = make_var_series(N=32, T=256, density=0.05, spectral_radius=0.85, seed=10000 + g)\n",
    "    phis.append(phi_rank(Xg))\n",
    "phis = np.array(phis)\n",
    "\n",
    "K = 60  # number of calibration trials (collect K p‑values)\n",
    "pvals = []\n",
    "for k in range(K):\n",
    "    idx = rng.permutation(G)\n",
    "    A_idx, B_idx = idx[:G//2], idx[G//2:]\n",
    "    T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "\n",
    "    ge = 0\n",
    "    for p in range(perms):\n",
    "        lab = rng.permutation(G)\n",
    "        Ap, Bp = lab[:G//2], lab[G//2:]\n",
    "        t = phis[Ap].mean() - phis[Bp].mean()\n",
    "        if abs(t) >= abs(T_obs) - 1e-12:\n",
    "            ge += 1\n",
    "    pvals.append((ge + 1) / (perms + 1))  # smoothed p‑value\n",
    "\n",
    "pvals = np.array(pvals)\n",
    "ks = ks_sup_norm_uniform(pvals)\n",
    "cal_pass = ks <= 0.14  # target tolerance for K=60\n",
    "print(f\"C) Permutation calibration (replicate‑level): KS sup Δ={ks:.3f} (≤0.14 target) -> {'PASS' if cal_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# D) Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------ Reproducible glyph advantage (structured VAR vs matched null)\n",
    "# ------------------------------\n",
    "# Effect: ΔΦ = Φ_rank(structured) − Φ_rank(time‑shuffled control with same marginals).\n",
    "# CI over seeds; we expect ΔΦ > 0.\n",
    "\n",
    "R = 24\n",
    "effects = []\n",
    "for s in range(R):\n",
    "    Xs, _ = make_var_series(N=48, T=512, density=0.06, spectral_radius=0.92, seed=500 + s)\n",
    "    phi_s = phi_rank(Xs)\n",
    "    # matched null: independently time‑permute each channel to kill cross‑channel structure\n",
    "    Xnull = np.empty_like(Xs)\n",
    "    for i in range(Xs.shape[0]):\n",
    "        idx = rng.permutation(Xs.shape[1])\n",
    "        Xnull[i] = Xs[i, idx]\n",
    "    phi_n = phi_rank(Xnull)\n",
    "    effects.append(phi_s - phi_n)\n",
    "\n",
    "effects = np.array(effects)\n",
    "mu = effects.mean()\n",
    "se = effects.std(ddof=1) / np.sqrt(R)\n",
    "ci_lo, ci_hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "repro_pass = ci_lo > 0\n",
    "print(f\"D) Glyph advantage ΔΦ: mean={mu:.4f}, 95% CI=({ci_lo:.4f},{ci_hi:.4f}) -> {'PASS' if repro_pass else 'FAIL'}\")\n",
    "\n",
    "# ------------------------------\n",
    "# E) KL monotonicity under coarse‑graining\n",
    "# ------------------------------\n",
    "# For random discrete P,Q over m states and a many‑to‑one lumping C, we should have\n",
    "#   KL(P||Q) ≥ KL(CP || CQ).\n",
    "\n",
    "m, k, trials = 12, 4, 64\n",
    "viol = 0\n",
    "for t in range(trials):\n",
    "    P = rng.dirichlet(np.ones(m))\n",
    "    Q = rng.dirichlet(np.ones(m))\n",
    "    # random partition of m into k bins\n",
    "    assign = rng.integers(0, k, size=m)\n",
    "    def KL(a, b):\n",
    "        a = np.asarray(a) + 1e-12\n",
    "        b = np.asarray(b) + 1e-12\n",
    "        return float(np.sum(a * (np.log(a) - np.log(b))))\n",
    "    KL_full = KL(P, Q)\n",
    "    # coarse‑grain\n",
    "    CP = np.zeros(k)\n",
    "    CQ = np.zeros(k)\n",
    "    for i in range(m):\n",
    "        CP[assign[i]] += P[i]\n",
    "        CQ[assign[i]] += Q[i]\n",
    "    KL_coarse = KL(CP, CQ)\n",
    "    if KL_coarse - KL_full > 1e-8:\n",
    "        viol += 1\n",
    "kl_pass = (viol == 0)\n",
    "print(f\"E) KL monotonicity (coarse‑graining): violations={viol}/{trials} -> {'PASS' if kl_pass else 'FAIL'}\")\n",
    "\n",
    "print(\"\\nSummary →\", \"PASS\" if all([inv_pass, dpi_pass, cal_pass, repro_pass, kl_pass]) else \"CHECK DETAILS\")\n",
    "\n",
    "\n",
    "# === v2.1 FIX — single clean cell (ASCII-only) ===\n",
    "# Drop-in replacement. Run JUST this cell. No smart quotes, no wrapped strings.\n",
    "\n",
    "import numpy as np\n",
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(12345)\n",
    "\n",
    "def ks_crit(n, alpha=0.05):\n",
    "    # Kolmogorov critical value ~ c_alpha/sqrt(n); c_0.05 ~ 1.36, c_0.10 ~ 1.22\n",
    "    c = 1.36 if alpha == 0.05 else 1.22\n",
    "    return c / np.sqrt(n)\n",
    "\n",
    "# ---- helpers ----\n",
    "\n",
    "def rankdata(v):\n",
    "    idx = np.argsort(v)\n",
    "    r = np.empty_like(idx, dtype=float)\n",
    "    r[idx] = np.arange(1, len(v) + 1)\n",
    "    return r\n",
    "\n",
    "\n",
    "def phi_rank(X):\n",
    "    N, T = X.shape\n",
    "    R = np.empty_like(X, dtype=float)\n",
    "    for i in range(N):\n",
    "        R[i] = rankdata(X[i])\n",
    "    R = R - R.mean(axis=1, keepdims=True)\n",
    "    sd = R.std(axis=1, keepdims=True) + 1e-12\n",
    "    R = R / sd\n",
    "    C = (R @ R.T) / max(T - 1, 1)\n",
    "    off = C[~np.eye(N, dtype=bool)]\n",
    "    return float(np.mean(np.abs(off)))\n",
    "\n",
    "\n",
    "def make_var_series(N=48, T=512, density=0.06, sr=0.92, seed=0):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    e = r.normal(0, 1.0, (N, T))\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "\n",
    "def ks_sup_uniform(p):\n",
    "    u = np.sort(p)\n",
    "    n = len(u)\n",
    "    F = np.arange(1, n + 1) / n\n",
    "    return float(max(np.max(np.abs(F - u)), np.max(np.abs((np.arange(n) / n) - u))))\n",
    "\n",
    "# ---- 1) TOST equivalence ----\n",
    "\n",
    "def tost_equiv(trials=20, N=48, T=512, eps=5e-3):\n",
    "    dp, dm = [], []\n",
    "    for s in range(trials):\n",
    "        X = make_var_series(N=N, T=T, seed=30000 + s)\n",
    "        base = phi_rank(X)\n",
    "        perm = phi_rank(X[rng.permutation(N)])\n",
    "        A = rng.uniform(0.5, 2.0, size=(N, 1))\n",
    "        B = rng.uniform(-1.0, 1.0, size=(N, 1))\n",
    "        mono = phi_rank(np.exp(A * X + B))\n",
    "        dp.append(base - perm)\n",
    "        dm.append(base - mono)\n",
    "    dp = np.array(dp)\n",
    "    dm = np.array(dm)\n",
    "    def ci(x):\n",
    "        b = 800\n",
    "        idx = rng.integers(0, len(x), size=(b, len(x)))\n",
    "        boot = x[idx].mean(axis=1)\n",
    "        lo, hi = np.quantile(boot, [0.025, 0.975])\n",
    "        return x.mean(), lo, hi\n",
    "    m1, l1, h1 = ci(dp)\n",
    "    m2, l2, h2 = ci(dm)\n",
    "    ok1 = (l1 > -eps) and (h1 < eps)\n",
    "    ok2 = (l2 > -eps) and (h2 < eps)\n",
    "    print(\"TOST perm: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m1, l1, h1, eps, 'PASS' if ok1 else 'CHECK'))\n",
    "    print(\"TOST mono: mean=%.5f CI=(%.5f,%.5f) eps=+/-%.5f -> %s\" % (m2, l2, h2, eps, 'PASS' if ok2 else 'CHECK'))\n",
    "\n",
    "# ---- 2) Three calibrations ----\n",
    "\n",
    "def block_boot_phi(X, block=32):\n",
    "    N, T = X.shape\n",
    "    k = int(np.ceil(T / block))\n",
    "    segs = []\n",
    "    starts = rng.integers(0, T, size=k)\n",
    "    for s in starts:\n",
    "        idx = (np.arange(s, s + block)) % T\n",
    "        segs.append(X[:, idx])\n",
    "    Xb = np.concatenate(segs, axis=1)[:, :T]\n",
    "    return phi_rank(Xb)\n",
    "\n",
    "\n",
    "def wild_boot_phi(X):\n",
    "    T = X.shape[1]\n",
    "    signs = rng.choice([-1.0, 1.0], size=T)\n",
    "    return phi_rank(X * signs)\n",
    "\n",
    "\n",
    "def cali_perm_block_wild(G=16, K=20, B=80, N=32, T=256):\n",
    "    reps = [make_var_series(N=N, T=T, sr=0.85, seed=12000 + g) for g in range(G)]\n",
    "    phis = np.array([phi_rank(X) for X in reps])\n",
    "    for mode in ['perm', 'block', 'wild']:\n",
    "        pvals = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = phis[A_idx].mean() - phis[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                if mode == 'perm':\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = phis[lab[:G // 2]].mean() - phis[lab[G // 2:]].mean()\n",
    "                elif mode == 'block':\n",
    "                    ph = np.array([block_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                else:\n",
    "                    ph = np.array([wild_boot_phi(X) for X in reps])\n",
    "                    lab = rng.permutation(G)\n",
    "                    t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            pvals.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(pvals))\n",
    "        thr = ks_crit(K)\n",
    "        print(\"Calib %s: KS=%.3f <= %.3f -> %s\" % (mode, ks, thr, 'PASS' if ks <= thr else 'CHECK'))\n",
    "\n",
    "# ---- 3) Stress regimes ----\n",
    "\n",
    "def make_var2(N=48, T=512, density=0.06, sr=0.9, seed=0, mode='gauss', df=3, ar=0.5):\n",
    "    r = default_rng(seed)\n",
    "    A = (r.random((N, N)) < density).astype(float) * (r.normal(0, 1, (N, N)))\n",
    "    eig = max(1e-6, np.max(np.abs(np.linalg.eigvals(A))))\n",
    "    A = A * (sr / eig)\n",
    "    X = np.zeros((N, T), float)\n",
    "    if mode == 'gauss':\n",
    "        e = r.normal(0, 1.0, (N, T))\n",
    "    elif mode == 't':\n",
    "        e = r.standard_t(df, size=(N, T))\n",
    "        if df > 2:\n",
    "            e *= (1.0 / np.sqrt(df / (df - 2)))\n",
    "    else:\n",
    "        e = np.zeros((N, T), float)\n",
    "        w = r.normal(0, 1.0, (N, T))\n",
    "        for i in range(N):\n",
    "            for t in range(1, T):\n",
    "                e[i, t] = ar * e[i, t - 1] + w[i, t]\n",
    "    for t in range(1, T):\n",
    "        X[:, t] = A @ X[:, t - 1] + e[:, t]\n",
    "    return X\n",
    "\n",
    "\n",
    "def fill_missing(X, miss=0.0, gaps=False):\n",
    "    N, T = X.shape\n",
    "    Y = X.copy()\n",
    "    if gaps:\n",
    "        rlen = max(2, int(0.02 * T))\n",
    "        for _ in range(5):\n",
    "            s = rng.integers(0, max(1, T - rlen))\n",
    "            Y[:, s:s + rlen] = np.nan\n",
    "    if miss > 0:\n",
    "        mask = rng.random(Y.shape) < miss\n",
    "        Y[mask] = np.nan\n",
    "    for i in range(N):\n",
    "        v = Y[i]\n",
    "        if np.isnan(v).any():\n",
    "            idx = np.arange(T)\n",
    "            good = ~np.isnan(v)\n",
    "            if good.sum() >= 2:\n",
    "                v[~good] = np.interp(idx[~good], idx[good], v[good])\n",
    "            else:\n",
    "                v[~good] = 0.0\n",
    "            Y[i] = v\n",
    "    return Y\n",
    "\n",
    "\n",
    "def stress():\n",
    "    cfgs = [\n",
    "        ('gauss',   dict(mode='gauss',   miss=0.0, gaps=False)),\n",
    "        ('t3',      dict(mode='t',       miss=0.0, gaps=False, df=3)),\n",
    "        ('colored', dict(mode='colored', miss=0.0, gaps=False, ar=0.6)),\n",
    "        ('missing10', dict(mode='gauss', miss=0.10, gaps=False)),\n",
    "        ('gaps',    dict(mode='gauss',   miss=0.0, gaps=True)),\n",
    "    ]\n",
    "    for name, c in cfgs:\n",
    "        G, N, T = 12, 40, 384\n",
    "        reps = []\n",
    "        for g in range(G):\n",
    "            X = make_var2(N=N, T=T, sr=0.9, seed=21000 + g,\n",
    "                          mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            X = fill_missing(X, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            reps.append(X)\n",
    "        ph = np.array([phi_rank(X) for X in reps])\n",
    "        K, B = 20, 120\n",
    "        p = []\n",
    "        for k in range(K):\n",
    "            idx = rng.permutation(G)\n",
    "            A_idx, B_idx = idx[:G // 2], idx[G // 2:]\n",
    "            T_obs = ph[A_idx].mean() - ph[B_idx].mean()\n",
    "            ge = 0\n",
    "            for b in range(B):\n",
    "                lab = rng.permutation(G)\n",
    "                t = ph[lab[:G // 2]].mean() - ph[lab[G // 2:]].mean()\n",
    "                if abs(t) >= abs(T_obs) - 1e-12:\n",
    "                    ge += 1\n",
    "            p.append((ge + 1) / (B + 1))\n",
    "        ks = ks_sup_uniform(np.array(p))\n",
    "        thr = ks_crit(K)\n",
    "        R = 10\n",
    "        eff = []\n",
    "        for s in range(R):\n",
    "            Xs = make_var2(N=N, T=T, sr=0.9, seed=22000 + s,\n",
    "                           mode=c.get('mode', 'gauss'), df=c.get('df', 3), ar=c.get('ar', 0.5))\n",
    "            Xs = fill_missing(Xs, miss=c.get('miss', 0.0), gaps=c.get('gaps', False))\n",
    "            ps = phi_rank(Xs)\n",
    "            Xn = np.empty_like(Xs)\n",
    "            for i in range(N):\n",
    "                idx = rng.permutation(T)\n",
    "                Xn[i] = Xs[i, idx]\n",
    "            pn = phi_rank(Xn)\n",
    "            eff.append(ps - pn)\n",
    "        eff = np.array(eff)\n",
    "        mu = eff.mean()\n",
    "        se = eff.std(ddof=1) / np.sqrt(R)\n",
    "        lo, hi = mu - 1.96 * se, mu + 1.96 * se\n",
    "        print(\"[%s] KS=%.3f | dPhi=%.4f CI=(%.4f,%.4f) -> %s, %s\" % (\n",
    "            name, ks, mu, lo, hi,\n",
    "            'PASS' if ks <= thr else 'CHECK', 'PASS' if lo > 0 else 'CHECK'))\n",
    "\n",
    "print('v2.1 FIX running...')\n",
    "tost_equiv()\n",
    "cali_perm_block_wild()\n",
    "stress()\n",
    "print('v2.1 FIX done.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d6e21dc-f753-47a6-afcb-b84e7e166ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
