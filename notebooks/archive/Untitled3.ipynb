{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cdf6829c-e71e-467c-9515-835f970186cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2025-10-09 02:04:42,730] INFO cntlab: CNTLab notebook initialized\n",
      "[2025-10-09 02:04:42,731] INFO cntlab: CNT Paths(root=C:\\Users\\caleb\\CNT_Lab)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ CNTLab ready.\n",
      "   Root: C:\\Users\\caleb\\CNT_Lab\n",
      "   Figures: C:\\Users\\caleb\\CNT_Lab\\artifacts\\figures\n",
      "   Tables: C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\n",
      "   Metrics: C:\\Users\\caleb\\CNT_Lab\\artifacts\\metrics\n",
      "[skip] 4DNFIXP4QG5B.mcool: Unable to synchronously open file (truncated file: eof = 7139753984, sblock->base_addr = 0, stored_eof = 27408885254)\n",
      "Wrote contact TSVs: {} ...\n",
      "Saved nodes_v1h_realhic → C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\genome3d__atlas__nodes_v1h_realhic__20251009-020445.parquet\n",
      "Interactive → C:\\Users\\caleb\\CNT_Lab\\artifacts\\genome3d__atlas__interactive_v1h_realhic__20251009-020446.html\n"
     ]
    }
   ],
   "source": [
    "# === Bring in REAL Hi-C (.cool/.mcool) -> v1h warp in one go ==================\n",
    "# 1) Route .cool/.mcool under CNT_LAB_DIR\n",
    "# 2) Extract balanced per-chromosome contact matrices at RES (binsize)\n",
    "# 3) Save as TSV and tag [\"raw\",\"hic\"]\n",
    "# 4) Run the v1h bending with these matrices (replaces synthetic contacts)\n",
    "\n",
    "import os, re, json\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "import cntlab as cl\n",
    "\n",
    "cl.nb.init(); P = cl.P\n",
    "\n",
    "# ---------- choose a resolution (bin size in bp) ----------\n",
    "RES = 250_000  # try 50k–250k depending on file size and speed\n",
    "\n",
    "# ---------- 1) Find .cool/.mcool and route ----------\n",
    "hic_home = P.root / \"data\" / \"raw\" / \"hic\"\n",
    "hic_home.mkdir(parents=True, exist_ok=True)\n",
    "coolers = []\n",
    "\n",
    "for root, dirs, files in os.walk(P.root):\n",
    "    if any(skip in root for skip in [\".venv\",\"__pycache__\",\"artifacts\\\\\"]): \n",
    "        continue\n",
    "    for fn in files:\n",
    "        if fn.lower().endswith((\".cool\",\".mcool\")):\n",
    "            src = Path(root)/fn\n",
    "            dst = hic_home/src.name\n",
    "            if not dst.exists():\n",
    "                try: src.replace(dst)\n",
    "                except Exception:\n",
    "                    import shutil; shutil.copy2(src, dst)\n",
    "            coolers.append(dst)\n",
    "\n",
    "assert coolers, \"No .cool/.mcool files found under your lab root. Drop one and re-run.\"\n",
    "\n",
    "# ---------- 2) Extract balanced per-chr matrices at RES ----------\n",
    "try:\n",
    "    import cooler  # pip install cooler\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess; subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"cooler>=0.9.3\"])\n",
    "    import cooler\n",
    "\n",
    "written = {}\n",
    "for path in coolers:\n",
    "    path = Path(path)\n",
    "    if path.suffix.lower()==\".mcool\":\n",
    "        # multi-res: pick the chosen resolution\n",
    "        uri = f\"{path}::/resolutions/{RES}\"\n",
    "    else:\n",
    "        uri = str(path)\n",
    "        # sanity: a single-res .cool may not match RES exactly; we still read the native binsize\n",
    "    try:\n",
    "        c = cooler.Cooler(uri)\n",
    "    except Exception as e:\n",
    "        print(f\"[skip] {path.name}: {e}\")\n",
    "        continue\n",
    "\n",
    "    binsize = c.binsize\n",
    "    print(f\"[cooler] {path.name} :: binsize={binsize}\")\n",
    "\n",
    "    # per-chromosome dense blocks (balanced)\n",
    "    for chrom in c.chromnames:\n",
    "        if chrom.lower().startswith(\"chr\") is False:\n",
    "            ch = \"chr\"+chrom\n",
    "        else:\n",
    "            ch = chrom\n",
    "        try:\n",
    "            # fetch balanced matrix for this chromosome\n",
    "            m = c.matrix(balance=True, sparse=True).fetch(chrom)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if m.shape[0]==0 or m.shape[1]==0:\n",
    "            continue\n",
    "        # convert to dense (be mindful of size at high res)\n",
    "        M = m.toarray().astype(float)\n",
    "        # write TSV\n",
    "        out = hic_home / f\"{path.stem}_contacts_{ch}_{binsize//1000}kb.tsv\"\n",
    "        pd.DataFrame(M).to_csv(out, sep=\"\\t\", header=False, index=False)\n",
    "        cl.manifest.log_artifact(str(out), kind=\"table\", tags=[\"raw\",\"hic\"],\n",
    "                                 meta={\"source\": path.name, \"binsize\": binsize, \"chrom\": ch})\n",
    "        written.setdefault(path.name, []).append(str(out))\n",
    "\n",
    "print(\"Wrote contact TSVs:\", json.dumps(written, indent=2)[:1000], \"...\")\n",
    "\n",
    "# ---------- 3) Re-run v1h bending on these real matrices ----------\n",
    "# (uses the “fixed single cell” v1h bender you ran before)\n",
    "# Minimal inline re-call:\n",
    "def hits(kind,*tags): return cl.manifest.find_artifacts(kind=kind, tags_all=list(tags))\n",
    "def grab(kind,*tags): H = hits(kind,*tags); assert H, f\"No {kind} for {tags}\"; return H[-1][\"path\"]\n",
    "\n",
    "# Load v0c edges to reconstruct polylines\n",
    "edges_v0c = [h[\"path\"] for h in hits(\"table\",\"genome3d\",\"atlas\",\"v0c\") if \"edges\" in Path(h[\"path\"]).name]\n",
    "assert edges_v0c, \"Need v0c edges (run the v0c declustering cell first).\"\n",
    "edges = pd.read_parquet(edges_v0c[-1])\n",
    "\n",
    "# Rebuild polylines\n",
    "backbones = {}\n",
    "for ch, segs in edges.groupby(\"chr\"):\n",
    "    segs = segs.sort_values(\"seg\")\n",
    "    pts = np.vstack([segs[[\"x0\",\"y0\",\"z0\"]].to_numpy(), segs[[\"x1\",\"y1\",\"z1\"]].to_numpy()[-1:]])\n",
    "    backbones[ch] = pts\n",
    "\n",
    "# Load full v1 genes for remap\n",
    "genes_v1_path = grab(\"table\",\"genome3d\",\"atlas\",\"v1\",\"genes\",\"full\") if hits(\"table\",\"genome3d\",\"atlas\",\"v1\",\"genes\",\"full\") else grab(\"table\",\"genome3d\",\"atlas\",\"v1\",\"genes\")\n",
    "genes_v1 = pd.read_parquet(genes_v1_path)[[\"chr\",\"pos\",\"gene\",\"type\"]].copy()\n",
    "\n",
    "# Collect our just-written TSVs\n",
    "hic_hits = hits(\"table\",\"raw\",\"hic\")\n",
    "hic_by_chr = {}\n",
    "for h in hic_hits:\n",
    "    p = h[\"path\"]; nm = Path(p).name.lower()\n",
    "    m = re.search(r\"(chr(?:[0-9]{1,2}|x|y|mt))\", nm)\n",
    "    if m: hic_by_chr[m.group(1).replace(\"mt\",\"MT\")] = p\n",
    "\n",
    "# Distance transform & 1D MDS warp (same as before)\n",
    "def to_distance(C):\n",
    "    C = np.asarray(C, float); C[C<0]=0\n",
    "    return -np.log(C+1e-6)\n",
    "def interp_polyline(P, t):\n",
    "    idx = t*(len(P)-1); i0 = np.floor(idx).astype(int); i1 = np.clip(i0+1, 0, len(P)-1); a = (idx-i0).reshape(-1,1)\n",
    "    return (1-a)*P[i0] + a*P[i1]\n",
    "def classical_mds_1d(D):\n",
    "    D = np.asarray(D, float); np.fill_diagonal(D, 0.0)\n",
    "    n = D.shape[0]; J = np.eye(n) - np.ones((n,n))/n\n",
    "    B = -0.5 * J @ (D**2) @ J\n",
    "    vals, vecs = np.linalg.eigh(B); i = np.argmax(vals); lam = max(vals[i],1e-12)\n",
    "    return vecs[:,i]*np.sqrt(lam)\n",
    "\n",
    "new_backbones = dict(backbones)\n",
    "for ch in list(backbones.keys()):\n",
    "    key = ch if ch.startswith(\"chr\") else (\"chr\"+ch)\n",
    "    p = hic_by_chr.get(key, None)\n",
    "    if not p: \n",
    "        continue\n",
    "    sep = \"\\t\" if p.lower().endswith(\".tsv\") else \",\"\n",
    "    M = pd.read_csv(p, sep=sep, header=None, comment=\"#\")\n",
    "    n = min(M.shape[0], M.shape[1])\n",
    "    M = M.iloc[:n,:n].fillna(0.0).astype(float).to_numpy()\n",
    "    D = to_distance(M)\n",
    "    coord = classical_mds_1d(D)\n",
    "    ord_ = np.argsort(coord); s = coord[ord_]\n",
    "    ds = np.abs(np.diff(s)); s_cum = np.concatenate([[0.0], np.cumsum(ds)])\n",
    "    s_norm = s_cum / (s_cum[-1] if s_cum[-1]>0 else 1.0)\n",
    "    P = backbones[ch]\n",
    "    P_shape = interp_polyline(P, s_norm)\n",
    "    t_back = np.linspace(0,1,len(P))\n",
    "    new_backbones[ch] = interp_polyline(P_shape, t_back)\n",
    "\n",
    "# Remap genes -> new backbone coordinates\n",
    "def interp_point(poly, pos_bp, Lguess=None):\n",
    "    L = Lguess if Lguess else (len(poly)-1); s = np.clip(pos_bp/max(1,L),0,1)\n",
    "    idx = s*(len(poly)-1); i0=int(np.floor(idx)); i1=min(i0+1, len(poly)-1); t=idx-i0\n",
    "    return poly[i0] + t*(poly[i1]-poly[i0])\n",
    "\n",
    "# rough chr lengths from gene max (for normalization)\n",
    "chr_len_guess = genes_v1.groupby(\"chr\")[\"pos\"].max().to_dict()\n",
    "rows=[]\n",
    "for r in genes_v1.itertuples(index=False):\n",
    "    ch = r.chr\n",
    "    poly = new_backbones.get(ch, backbones.get(ch, None))\n",
    "    if poly is None: \n",
    "        continue\n",
    "    x,y,z = interp_point(poly, int(r.pos), chr_len_guess.get(ch))\n",
    "    rows.append((f\"{(r.gene or 'id')}|{ch}|{int(r.pos)}\", ch, \"gene\", int(r.pos), x,y,z, r.gene, r.type))\n",
    "nodes_v1h = pd.DataFrame(rows, columns=[\"id\",\"chr\",\"kind\",\"pos\",\"x\",\"y\",\"z\",\"gene\",\"type\"])\n",
    "\n",
    "nodes_path = cl.io.save_df(nodes_v1h, module=\"genome3d\", dataset=\"atlas\", desc=\"nodes_v1h_realhic\",\n",
    "                           fmt=\"parquet\", tags=[\"genome3d\",\"atlas\",\"v1h\",\"realhic\"])\n",
    "print(\"Saved nodes_v1h_realhic →\", nodes_path)\n",
    "\n",
    "# Export quick figure + HTML\n",
    "try:\n",
    "    import plotly.graph_objects as go\n",
    "except ModuleNotFoundError:\n",
    "    import sys, subprocess; subprocess.check_call([sys.executable,\"-m\",\"pip\",\"install\",\"plotly>=5.24\"])\n",
    "    import plotly.graph_objects as go\n",
    "\n",
    "MAX_HTML = 140_000\n",
    "stars = nodes_v1h if len(nodes_v1h)<=MAX_HTML else nodes_v1h.sample(MAX_HTML, random_state=1337)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter3d(x=stars[\"x\"], y=stars[\"y\"], z=stars[\"z\"], mode=\"markers\",\n",
    "                           marker=dict(size=1.8, color=\"rgba(255,255,255,0.97)\"),\n",
    "                           name=\"genes\",\n",
    "                           customdata=np.stack([stars.get(\"gene\",\"\"), stars[\"chr\"], stars[\"pos\"], stars.get(\"type\",\"\")], axis=1),\n",
    "                           hovertemplate=\"gene: %{customdata[0]}<br>chr: %{customdata[1]}  pos: %{customdata[2]}<br>type: %{customdata[3]}\"))\n",
    "fig.update_layout(scene=dict(bgcolor=\"#05070b\", aspectmode=\"data\"),\n",
    "                  paper_bgcolor=\"#05070b\", height=880, width=1240, margin=dict(l=0,r=0,t=60,b=0),\n",
    "                  title=\"Genome3D v1h — Hi-C (cool) warped atlas\")\n",
    "html = fig.to_html(include_plotlyjs=\"cdn\", full_html=True)\n",
    "html_path = cl.io.save_bytes(html.encode(\"utf-8\"), module=\"genome3d\", dataset=\"atlas\",\n",
    "                             desc=\"interactive_v1h_realhic\",\n",
    "                             tags=[\"genome3d\",\"atlas\",\"v1h\",\"interactive\",\"realhic\"], ext=\"html\")\n",
    "print(\"Interactive →\", html_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9db8c57-46b4-40f0-a22f-bf24a506e7b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
