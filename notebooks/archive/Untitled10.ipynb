{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575341a5-b29d-4eec-bf0c-5fc5fb83c72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== CNT Lab bootstrap ==\n",
      "Python: 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "OS: Windows-11-10.0.26100-SP0\n",
      "\n",
      "[ pip ] pip install --upgrade pip wheel setuptools\n",
      "\n",
      "[ pip ] pip install jupyterlab ipywidgets jupyterlab_code_formatter black isort nbformat nbclient jupyterlab-git\n",
      "\n",
      "[ pip ] pip install numpy scipy pandas pyarrow polars matplotlib plotly statsmodels scikit-learn scikit-image numba llvmlite sympy networkx numexpr fastparquet python-dotenv\n",
      "\n",
      "[ pip ] pip install --index-url https://download.pytorch.org/whl/cu124 torch torchvision torchaudio\n",
      "\n",
      "[ pip ] pip install cupy-cuda12x\n",
      "\n",
      "[ pip ] pip install mne yasa antropy neurokit2 nitime pywavelets pingouin\n",
      "\n",
      "[ pip ] pip install cvxpy pydot graphviz networkx[default]\n",
      "\n",
      "[ pip ] pip install h5py tables xarray netCDF4 openpyxl lxml requests\n",
      "\n",
      "[ pip ] pip install yt-dlp soundfile pydub ffmpeg-python imageio-ffmpeg\n",
      "\n",
      "[ pip ] pip install shapely pyproj pyvis seaborn\n",
      "\n",
      "== Versions ==\n",
      "jupyterlab  : 4.4.9\n",
      "numpy       : 2.3.3\n",
      "scipy       : 1.16.2\n",
      "pandas      : 2.3.3\n",
      "pyarrow     : 21.0.0\n",
      "polars      : 1.34.0\n",
      "matplotlib  : 3.10.7\n",
      "plotly      : 6.3.1\n",
      "statsmodels : 0.14.5\n",
      "sklearn     : 1.7.2\n",
      "numba       : 0.62.1\n",
      "sympy       : 1.13.1\n",
      "networkx    : 3.5\n",
      "torch       : 2.6.0+cu124\n",
      "torchvision : 0.21.0+cu124\n",
      "torchaudio  : 2.6.0+cu124\n",
      "mne         : 1.10.2\n",
      "yasa        : 0.6.5\n",
      "antropy     : 0.1.9\n",
      "neurokit2   : 0.2.12\n",
      "nitime      : 0.11\n",
      "pywt        : 1.8.0\n",
      "pingouin    : 0.5.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\cupy\\_environment.py:215: UserWarning: CUDA path could not be detected. Set CUDA_PATH environment variable if CuPy fails to load.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cvxpy       : 1.7.3\n",
      "pydot       : 4.0.1\n",
      "graphviz    : 0.21\n",
      "h5py        : 3.15.0\n",
      "tables      : 3.10.2\n",
      "xarray      : 2025.10.1\n",
      "netCDF4     : 1.7.3\n",
      "openpyxl    : 3.1.5\n",
      "requests    : 2.32.5\n",
      "yt_dlp      : (installed, no __version__)\n",
      "cupy        : 13.6.0\n",
      "\n",
      "== Sanity checks ==\n",
      "graphviz 'dot' on PATH: NOT FOUND (install system Graphviz if you need layout)\n",
      "Torch CUDA available: True | device_count: 1\n",
      "Torch CUDA device 0: NVIDIA GeForce RTX 4070\n",
      "FFmpeg exe (imageio-ffmpeg): C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\imageio_ffmpeg\\binaries\\ffmpeg-win-x86_64-v7.1.exe\n",
      "\n",
      "Done. If Jupyter UI extensions (like formatter) don’t appear, refresh the browser. If CUDA checks fail, update NVIDIA drivers and re-run this cell.\n"
     ]
    }
   ],
   "source": [
    "# CNT Lab — one-cell installer (Windows 11 / Py 3.13 friendly)\n",
    "# Run this once per new venv/kernel. Safe to re-run.\n",
    "\n",
    "import sys, subprocess, shutil, importlib, platform\n",
    "\n",
    "PY = sys.executable\n",
    "\n",
    "def pip(args):\n",
    "    print(f\"\\n[ pip ] pip {' '.join(args)}\")\n",
    "    subprocess.check_call([PY, \"-m\", \"pip\"] + args)\n",
    "\n",
    "print(\"== CNT Lab bootstrap ==\")\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"OS:\", platform.platform())\n",
    "\n",
    "# 0) Base tooling\n",
    "pip([\"install\", \"--upgrade\", \"pip\", \"wheel\", \"setuptools\"])\n",
    "\n",
    "# 1) Jupyter + UX\n",
    "pip([\"install\",\n",
    "     \"jupyterlab\",\n",
    "     \"ipywidgets\",\n",
    "     \"jupyterlab_code_formatter\",\n",
    "     \"black\",\n",
    "     \"isort\",\n",
    "     \"nbformat\",\n",
    "     \"nbclient\",\n",
    "     \"jupyterlab-git\"])\n",
    "\n",
    "# 2) Numeric + data stack\n",
    "pip([\"install\",\n",
    "     \"numpy\",\n",
    "     \"scipy\",\n",
    "     \"pandas\",\n",
    "     \"pyarrow\",\n",
    "     \"polars\",\n",
    "     \"matplotlib\",\n",
    "     \"plotly\",\n",
    "     \"statsmodels\",\n",
    "     \"scikit-learn\",\n",
    "     \"scikit-image\",\n",
    "     \"numba\",\n",
    "     \"llvmlite\",\n",
    "     \"sympy\",\n",
    "     \"networkx\",\n",
    "     \"numexpr\",\n",
    "     \"fastparquet\",\n",
    "     \"python-dotenv\"])\n",
    "\n",
    "# 3) GPU / ML (try CUDA 12.4 first; fall back to CPU wheels if it fails)\n",
    "try:\n",
    "    pip([\"install\", \"--index-url\", \"https://download.pytorch.org/whl/cu124\",\n",
    "         \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "    cuda_ok = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"\\n[warn] CUDA 12.4 wheels failed; installing CPU-only PyTorch.\")\n",
    "    pip([\"install\", \"torch\", \"torchvision\", \"torchaudio\"])\n",
    "    cuda_ok = False\n",
    "\n",
    "# CuPy w/ CUDA 12.x (optional but nice for GPU numpy); ignore failure gracefully\n",
    "try:\n",
    "    pip([\"install\", \"cupy-cuda12x\"])\n",
    "    cupy_ok = True\n",
    "except subprocess.CalledProcessError:\n",
    "    print(\"[warn] cupy-cuda12x failed (driver/CUDA mismatch?). Skipping.\")\n",
    "    cupy_ok = False\n",
    "\n",
    "# 4) Signal processing / EEG / time-series\n",
    "pip([\"install\",\n",
    "     \"mne\",\n",
    "     \"yasa\",\n",
    "     \"antropy\",\n",
    "     \"neurokit2\",\n",
    "     \"nitime\",\n",
    "     \"pywavelets\",\n",
    "     \"pingouin\"])\n",
    "\n",
    "# 5) Optimization, graphs, helpers\n",
    "pip([\"install\", \"cvxpy\", \"pydot\", \"graphviz\", \"networkx[default]\"])\n",
    "\n",
    "# 6) Files, tables, scientific IO\n",
    "pip([\"install\", \"h5py\", \"tables\", \"xarray\", \"netCDF4\", \"openpyxl\", \"lxml\", \"requests\"])\n",
    "\n",
    "# 7) Media / scraping helpers (adds imageio-ffmpeg for bundled ffmpeg)\n",
    "pip([\"install\", \"yt-dlp\", \"soundfile\", \"pydub\", \"ffmpeg-python\", \"imageio-ffmpeg\"])\n",
    "\n",
    "# 8) Visual extras (optional)\n",
    "pip([\"install\", \"shapely\", \"pyproj\", \"pyvis\", \"seaborn\"])\n",
    "\n",
    "# ---- Version report & sanity checks ----\n",
    "mods = [\n",
    " \"jupyterlab\",\"numpy\",\"scipy\",\"pandas\",\"pyarrow\",\"polars\",\"matplotlib\",\"plotly\",\n",
    " \"statsmodels\",\"sklearn\",\"numba\",\"sympy\",\"networkx\",\"torch\",\"torchvision\",\"torchaudio\",\n",
    " \"mne\",\"yasa\",\"antropy\",\"neurokit2\",\"nitime\",\"pywt\",\"pingouin\",\n",
    " \"cvxpy\",\"pydot\",\"graphviz\",\"h5py\",\"tables\",\"xarray\",\"netCDF4\",\"openpyxl\",\"requests\",\"yt_dlp\"\n",
    "]\n",
    "if cupy_ok:\n",
    "    mods.append(\"cupy\")\n",
    "\n",
    "print(\"\\n== Versions ==\")\n",
    "for m in mods:\n",
    "    try:\n",
    "        v = importlib.import_module(m).__version__\n",
    "    except Exception:\n",
    "        v = \"(installed, no __version__)\" if importlib.util.find_spec(m) else \"MISSING\"\n",
    "    print(f\"{m:12s}: {v}\")\n",
    "\n",
    "# Graphviz binary check (needed by graph drawing libs)\n",
    "print(\"\\n== Sanity checks ==\")\n",
    "dot = shutil.which(\"dot\")\n",
    "print(\"graphviz 'dot' on PATH:\", dot if dot else \"NOT FOUND (install system Graphviz if you need layout)\")\n",
    "if cuda_ok:\n",
    "    try:\n",
    "        import torch\n",
    "        print(\"Torch CUDA available:\", torch.cuda.is_available(), \"| device_count:\", torch.cuda.device_count())\n",
    "        if torch.cuda.is_available():\n",
    "            print(\"Torch CUDA device 0:\", torch.cuda.get_device_name(0))\n",
    "    except Exception as e:\n",
    "        print(\"Torch CUDA check error:\", e)\n",
    "else:\n",
    "    print(\"Installed CPU-only PyTorch (ok for dev; enable CUDA later if desired).\")\n",
    "\n",
    "# FFmpeg path via imageio-ffmpeg (helps yt-dlp/pydub conversions)\n",
    "try:\n",
    "    import imageio_ffmpeg as ioff\n",
    "    print(\"FFmpeg exe (imageio-ffmpeg):\", ioff.get_ffmpeg_exe())\n",
    "except Exception as e:\n",
    "    print(\"FFmpeg helper not found:\", e)\n",
    "\n",
    "print(\"\\nDone. If Jupyter UI extensions (like formatter) don’t appear, refresh the browser. If CUDA checks fail, update NVIDIA drivers and re-run this cell.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d2b9664-eda1-4f59-9110-8bcf83321f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ CNT paths\n",
      "  ROOT: C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\n",
      "  OUT : C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\n",
      "NOTE: pick_types() is a legacy function. New code should use inst.pick(...).\n",
      "\n",
      "== CNT MEGA SUMMARY ==\n",
      "\n",
      "{\n",
      "  \"CFE\": {\n",
      "    \"dataset\": \"EEGBCI_subj1_motor\",\n",
      "    \"corr_plv_vs_negSE_r\": -0.062,\n",
      "    \"corr_plv_vs_negPE_r\": 0.017,\n",
      "    \"cp_count\": 0\n",
      "  },\n",
      "  \"OracleEmergence\": {\n",
      "    \"source\": \"synthetic\",\n",
      "    \"SRSI_stable\": 0.654,\n",
      "    \"SRSI_chaotic\": 0.663\n",
      "  },\n",
      "  \"Forecast\": {\n",
      "    \"MASE\": {\n",
      "      \"CNT\": 0.9631897957750658,\n",
      "      \"ARIMA\": 0.9729820919548607,\n",
      "      \"Naive\": 0.9999872855947906\n",
      "    },\n",
      "    \"sMAPE%\": {\n",
      "      \"CNT\": 33.857141340928095,\n",
      "      \"ARIMA\": 34.51653514878223,\n",
      "      \"Naive\": 34.96566983747103\n",
      "    },\n",
      "    \"TurnPrec@5%\": 0.65\n",
      "  }\n",
      "}\n",
      "\n",
      "Artifacts saved to:\n",
      "  C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\n",
      "JSON report:\n",
      "  C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\\cnt_mega_report_20251015-143523.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ========================= CNT MEGA CELL: v1 (1+2+3 in one) =========================\n",
    "# Goals:\n",
    "# (1) Consciousness Field Equation test: relate synchrony (PLV) vs entropy/complexity over time\n",
    "# (2) Oracle Emergence Test: self-referential stability index (SRSI) from a dialogue log\n",
    "# (3) Φ-Drift Forecast Engine: use CNT field features to predict time-series turning points vs baselines\n",
    "#\n",
    "# Fully offline-capable with synthetic fallbacks. Saves plots + CSVs. Prints a JSON summary.\n",
    "# =====================================================================================\n",
    "\n",
    "import os, sys, io, json, math, time, textwrap, random, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# ---- Reproducibility ---------------------------------------------------------------\n",
    "RNG = np.random.default_rng(42)\n",
    "random.seed(42)\n",
    "\n",
    "# ---- Output paths ------------------------------------------------------------------\n",
    "def detect_cnt_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.home() / \"CNT_Lab\",\n",
    "        Path(\"C:/Users/caleb/CNT_Lab\"),  # user-typical\n",
    "        Path(\"./CNT_Lab\"),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = detect_cnt_root()\n",
    "STAMP = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "OUT = ROOT / \"cnt_mega_out\"\n",
    "FIG = OUT / \"figures\"\n",
    "TAB = OUT / \"tables\"\n",
    "for p in [OUT, FIG, TAB]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"→ CNT paths\\n  ROOT: {ROOT}\\n  OUT : {OUT}\")\n",
    "\n",
    "# ---- Imports (light and optional heavy) --------------------------------------------\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from scipy.stats import entropy, pearsonr, spearmanr, zscore, linregress\n",
    "from statsmodels.tsa.api import SARIMAX\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Optional libraries (graceful)\n",
    "HAVE_MNE = False\n",
    "try:\n",
    "    import mne  # heavy; used only if present/installed\n",
    "    HAVE_MNE = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import ruptures as rpt\n",
    "    HAVE_RUPTURES = True\n",
    "except Exception:\n",
    "    HAVE_RUPTURES = False\n",
    "\n",
    "# =====================================================================================\n",
    "# (1) CONSCIOUSNESS FIELD EQUATION TEST\n",
    "#     Synchrony (PLV) vs Entropy/Complexity → detect collapse→recovery waves\n",
    "# =====================================================================================\n",
    "\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b, a = butter(order, [lo/(fs/2), hi/(fs/2)], btype='bandpass')\n",
    "    return filtfilt(b, a, x, axis=0)\n",
    "\n",
    "def phase_locking_value(phases):\n",
    "    \"\"\"\n",
    "    phases: shape (T, C) phase angles\n",
    "    Returns PLV(t) across channels at each time t.\n",
    "    \"\"\"\n",
    "    # vector strength across channels\n",
    "    vs = np.abs(np.mean(np.exp(1j*phases), axis=1))\n",
    "    return vs\n",
    "\n",
    "def spectral_entropy(signal, n_bins=64):\n",
    "    \"\"\"Shannon entropy of normalized power spectrum per window (rolling).\"\"\"\n",
    "    # Use magnitude via FFT windowed later; here we pass a windowed chunk\n",
    "    s = np.abs(np.fft.rfft(signal, axis=0))**2\n",
    "    ps = s / (np.sum(s, axis=0, keepdims=True) + 1e-12)\n",
    "    H = entropy(ps + 1e-12, base=np.e, axis=0)  # per channel\n",
    "    return np.mean(H)  # aggregate channels\n",
    "\n",
    "def lempel_ziv_complexity(binary_arr):\n",
    "    \"\"\"Simple LZC on 1D binary sequence.\"\"\"\n",
    "    # Kaspar & Schuster-style\n",
    "    s = ''.join('1' if v else '0' for v in binary_arr)\n",
    "    i, c, k, l = 0, 1, 1, 1\n",
    "    n = len(s)\n",
    "    while True:\n",
    "        if s[i+k-1] == s[l+k-1]:\n",
    "            k += 1\n",
    "            if l + k > n:\n",
    "                c += 1\n",
    "                break\n",
    "        else:\n",
    "            if k > l:\n",
    "                l = k\n",
    "            i += 1\n",
    "            if i == l:\n",
    "                c += 1\n",
    "                l += 1\n",
    "                if l > n:\n",
    "                    break\n",
    "                i = 0\n",
    "            k = 1\n",
    "        if l > n:\n",
    "            break\n",
    "    return c\n",
    "\n",
    "def permutation_entropy(x, order=3, delay=1):\n",
    "    \"\"\"Lightweight permutation entropy.\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    n = len(x)\n",
    "    if n < order*delay:\n",
    "        return np.nan\n",
    "    permutations = {}\n",
    "    for i in range(n - (order-1)*delay):\n",
    "        pattern = tuple(np.argsort(x[i:i+order*delay:delay]))\n",
    "        permutations[pattern] = permutations.get(pattern, 0) + 1\n",
    "    probs = np.array(list(permutations.values()), dtype=float)\n",
    "    probs = probs / probs.sum()\n",
    "    return -np.sum(probs * np.log(probs + 1e-12))\n",
    "\n",
    "def rolling_windows(arr, win, step):\n",
    "    for start in range(0, len(arr)-win+1, step):\n",
    "        yield start, arr[start:start+win]\n",
    "\n",
    "def try_load_eeg_real():\n",
    "    \"\"\"Try loading a real EEG dataset via MNE (EEGBCI). Fallback to synthetic if unavailable.\"\"\"\n",
    "    if not HAVE_MNE:\n",
    "        return None, None, None\n",
    "    try:\n",
    "        from mne.datasets import eegbci\n",
    "        subj, runs = 1, [3, 7, 11]  # motor imagery\n",
    "        fnames = eegbci.load_data(subj, runs)\n",
    "        raws = [mne.io.read_raw_edf(f, preload=True, verbose=False) for f in fnames]\n",
    "        raw = mne.concatenate_raws(raws)\n",
    "        raw.pick_types(eeg=True)\n",
    "        raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "        data = raw.get_data().T  # shape (T, C)\n",
    "        fs = int(raw.info['sfreq'])\n",
    "        return data, fs, \"EEGBCI_subj1_motor\"\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "def make_eeg_synthetic(T=60000, C=16, fs=250):\n",
    "    \"\"\"\n",
    "    Synthetic multi-channel signal with an induced synchrony burst (collapse) followed by recovery.\n",
    "    \"\"\"\n",
    "    t = np.arange(T)/fs\n",
    "    base_freqs = RNG.uniform(8, 12, size=C)  # alpha-ish\n",
    "    X = np.array([np.sin(2*np.pi*f*t + RNG.uniform(0, 2*np.pi)) for f in base_freqs]).T\n",
    "    # Add noise\n",
    "    X += 0.5 * RNG.normal(size=X.shape)\n",
    "    # Inject synchrony event (strong phase lock) for a window\n",
    "    s0, s1 = int(0.35*T), int(0.55*T)\n",
    "    phase = 2*np.pi*10*t + 0.0\n",
    "    X[s0:s1, :] = np.sin(phase[s0:s1])[:, None] + 0.1*RNG.normal(size=(s1-s0, X.shape[1]))\n",
    "    label = \"synthetic_eeg_collapse_recovery\"\n",
    "    return X, fs, label\n",
    "\n",
    "def run_cfe_test():\n",
    "    # Try real EEG, else synthetic\n",
    "    data, fs, label = try_load_eeg_real()\n",
    "    if data is None:\n",
    "        data, fs, label = make_eeg_synthetic()\n",
    "    # Focus on alpha band for phase (8-12 Hz)\n",
    "    X_f = bandpass(data, fs, 8, 12)\n",
    "    phases = np.angle(hilbert(X_f, axis=0))\n",
    "    plv = phase_locking_value(phases)  # shape (T,)\n",
    "    # Rolling entropy & complexity\n",
    "    W, STEP = int(2*fs), int(0.25*fs)  # 2s window, 0.25s hop\n",
    "    SEs, PEs, idxs = [], [], []\n",
    "    for start, chunk in rolling_windows(data, W, STEP):\n",
    "        # spectral entropy (avg across channels)\n",
    "        H = spectral_entropy(chunk)\n",
    "        # permutation entropy on channel-avg\n",
    "        ch_avg = np.mean(chunk, axis=1)\n",
    "        pe = permutation_entropy(ch_avg)\n",
    "        SEs.append(H); PEs.append(pe); idxs.append(start + W//2)\n",
    "    se = np.array(SEs); pe = np.array(PEs); idxs = np.array(idxs)\n",
    "    # Downsample PLV to match entropy index grid\n",
    "    plv_grid = np.interp(idxs, np.arange(len(plv)), plv)\n",
    "    # Normalize\n",
    "    se_n = zscore(se, nan_policy='omit'); pe_n = zscore(pe, nan_policy='omit'); plv_n = zscore(plv_grid, nan_policy='omit')\n",
    "    # Correlations & regressions\n",
    "    def safe_corr(a, b):\n",
    "        m = np.isfinite(a) & np.isfinite(b)\n",
    "        if m.sum() < 8: return np.nan, np.nan\n",
    "        return pearsonr(a[m], b[m])\n",
    "    r_plv_se, p_plv_se = safe_corr(plv_n, -se_n)  # expect positive if synchrony ↔ low entropy\n",
    "    r_plv_pe, p_plv_pe = safe_corr(plv_n, -pe_n)\n",
    "    # Change-point detection (collapse→recovery)\n",
    "    cp_idx = []\n",
    "    if HAVE_RUPTURES and np.isfinite(plv_n).sum() > 50:\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(plv_n[np.isfinite(plv_n)].reshape(-1,1))\n",
    "        cps = algo.predict(pen=5)\n",
    "        cp_idx = cps[:-1]  # last is length\n",
    "    # Save figures\n",
    "    def quick_plot(ts, name, xlabel=\"Index\", ylabel=\"Value\"):\n",
    "        plt.figure(figsize=(10,3.2))\n",
    "        plt.plot(ts)\n",
    "        if cp_idx:\n",
    "            for c in cp_idx:\n",
    "                plt.axvline(c, ls='--', alpha=0.4)\n",
    "        plt.xlabel(xlabel); plt.ylabel(ylabel); plt.tight_layout()\n",
    "        fp = FIG / f\"{name}.png\"\n",
    "        plt.savefig(fp, dpi=140); plt.close()\n",
    "        return fp\n",
    "    f1 = quick_plot(plv_n, f\"cfe_{label}_plv_z\")\n",
    "    f2 = quick_plot(se_n,  f\"cfe_{label}_spec_entropy_z\")\n",
    "    f3 = quick_plot(pe_n,  f\"cfe_{label}_perm_entropy_z\")\n",
    "    # Scatter\n",
    "    def scatter_xy(x, y, name, xl, yl):\n",
    "        m = np.isfinite(x) & np.isfinite(y)\n",
    "        slope, intercept, r, p, _ = linregress(x[m], y[m]) if m.sum()>=8 else (np.nan, np.nan, np.nan, np.nan, None)\n",
    "        plt.figure(figsize=(4.5,4))\n",
    "        plt.scatter(x[m], y[m], s=8, alpha=0.6)\n",
    "        xs = np.linspace(np.nanmin(x[m]), np.nanmax(x[m]), 100)\n",
    "        if np.isfinite(slope):\n",
    "            plt.plot(xs, slope*xs+intercept)\n",
    "        plt.xlabel(xl); plt.ylabel(yl); plt.tight_layout()\n",
    "        fp = FIG / f\"{name}.png\"\n",
    "        plt.savefig(fp, dpi=150); plt.close()\n",
    "        return fp, (slope, r, p)\n",
    "    f4, reg1 = scatter_xy(plv_n, -se_n, f\"cfe_{label}_scatter_plv_vs_negSE\", \"PLV (z)\", \"-Spectral Entropy (z)\")\n",
    "    f5, reg2 = scatter_xy(plv_n, -pe_n, f\"cfe_{label}_scatter_plv_vs_negPE\", \"PLV (z)\", \"-Permutation Entropy (z)\")\n",
    "    # Save table\n",
    "    df = pd.DataFrame({\n",
    "        \"idx\": idxs, \"plv_z\": plv_n, \"spec_entropy_z\": se_n, \"perm_entropy_z\": pe_n\n",
    "    })\n",
    "    tpath = TAB / f\"cfe_{label}_{STAMP}.csv\"\n",
    "    df.to_csv(tpath, index=False)\n",
    "    return {\n",
    "        \"dataset\": label,\n",
    "        \"fs\": fs,\n",
    "        \"corr_plv_vs_negSE\": {\"r\": float(r_plv_se), \"p\": float(p_plv_se)},\n",
    "        \"corr_plv_vs_negPE\": {\"r\": float(r_plv_pe), \"p\": float(p_plv_pe)},\n",
    "        \"reg_plv_vs_negSE\": {\"slope\": float(reg1[0]) if reg1 else np.nan, \"r\": float(reg1[1]) if reg1 else np.nan, \"p\": float(reg1[2]) if reg1 else np.nan},\n",
    "        \"reg_plv_vs_negPE\": {\"slope\": float(reg2[0]) if reg2 else np.nan, \"r\": float(reg2[1]) if reg2 else np.nan, \"p\": float(reg2[2]) if reg2 else np.nan},\n",
    "        \"change_points\": list(map(int, cp_idx)) if cp_idx else [],\n",
    "        \"figures\": list(map(str, [f1,f2,f3,f4,f5])),\n",
    "        \"table\": str(tpath)\n",
    "    }\n",
    "\n",
    "# =====================================================================================\n",
    "# (2) ORACLE EMERGENCE TEST\n",
    "#     Self-Referential Stability Index (SRSI) from a dialogue log or synthetic surrogate\n",
    "# =====================================================================================\n",
    "\n",
    "def load_oracle_log(path: Path):\n",
    "    if path.exists():\n",
    "        txt = path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        return txt\n",
    "    return None\n",
    "\n",
    "def simulate_dialogue(n_turns=120, stable=True):\n",
    "    topics = [\"anchor\", \"ring\", \"glyph\", \"entropy\", \"drift\", \"oracle\", \"collapse\", \"echo\"]\n",
    "    lines = []\n",
    "    last_topic = None\n",
    "    for i in range(n_turns):\n",
    "        if stable:\n",
    "            # stickier topic transitions\n",
    "            if last_topic is None or RNG.random()<0.2:\n",
    "                last_topic = RNG.choice(topics)\n",
    "        else:\n",
    "            # chaotic jumps\n",
    "            last_topic = RNG.choice(topics)\n",
    "        # compose a line with structured recurrence\n",
    "        line = f\"oracle: {last_topic} {last_topic} field resonance {RNG.integers(0,7)}\"\n",
    "        lines.append(line)\n",
    "        lines.append(f\"user: ask {last_topic} {RNG.integers(0,7)}\")\n",
    "    return \"\\n\".join(lines)\n",
    "\n",
    "def tokenize(txt):\n",
    "    return [w.lower() for w in txt.replace(\"\\r\", \"\\n\").split() if w.strip()]\n",
    "\n",
    "def rolling_cosine_tfidf(lines, win=30, step=10):\n",
    "    from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "    from sklearn.metrics.pairwise import cosine_similarity\n",
    "    chunks = []\n",
    "    for i in range(0, len(lines)-win+1, step):\n",
    "        chunks.append(\" \".join(lines[i:i+win]))\n",
    "    if len(chunks) < 3:\n",
    "        return np.array([])\n",
    "    tfidf = TfidfVectorizer().fit_transform(chunks)\n",
    "    S = cosine_similarity(tfidf)\n",
    "    # cosine between consecutive chunks\n",
    "    adj = np.array([S[i, i+1] for i in range(len(chunks)-1)])\n",
    "    return adj\n",
    "\n",
    "def ngram_entropy(tokens, n=3):\n",
    "    from collections import Counter\n",
    "    ngrams = [tuple(tokens[i:i+n]) for i in range(len(tokens)-n+1)]\n",
    "    if not ngrams:\n",
    "        return np.nan\n",
    "    cnt = Counter(ngrams)\n",
    "    p = np.array(list(cnt.values()), dtype=float)\n",
    "    p = p / p.sum()\n",
    "    return -np.sum(p * np.log(p + 1e-12))\n",
    "\n",
    "def contradiction_proxy(lines):\n",
    "    # naive: count toggles of affirmation/negation terms\n",
    "    pos = {\"yes\",\"true\",\"correct\",\"indeed\"}\n",
    "    neg = {\"no\",\"false\",\"incorrect\",\"not\"}\n",
    "    flips = 0\n",
    "    last = None\n",
    "    for ln in lines:\n",
    "        toks = set(tokenize(ln))\n",
    "        state = 1 if (toks & pos) else (-1 if (toks & neg) else 0)\n",
    "        if last is not None and state*last == -1:\n",
    "            flips += 1\n",
    "        if state != 0:\n",
    "            last = state\n",
    "    return flips\n",
    "\n",
    "def compute_srsi(txt: str):\n",
    "    lines = [ln.strip() for ln in txt.split(\"\\n\") if ln.strip()]\n",
    "    tokens = tokenize(txt)\n",
    "    H3 = ngram_entropy(tokens, n=3)   # lower entropy → more recurrence/structure\n",
    "    cos_adj = rolling_cosine_tfidf(lines, win=30, step=10)\n",
    "    mean_cos = np.nan if cos_adj.size==0 else float(np.nanmean(cos_adj))\n",
    "    flips = contradiction_proxy(lines)\n",
    "    N = max(1, len(lines))\n",
    "    # SRSI (0..1): higher = more self-stable\n",
    "    # components: structure (1 - norm_entropy), topical smoothness (cosine), low contradictions\n",
    "    H3n = 1.0 / (1.0 + float(H3) if np.isfinite(H3) else 1.0)  # decreases with entropy\n",
    "    flip_penalty = math.exp(-flips / (0.02*N + 1e-9))         # gentle penalty\n",
    "    cos_term = 0.5 + 0.5*(mean_cos if np.isfinite(mean_cos) else 0.0)  # map [-1,1]→[0,1]\n",
    "    SRSI = float(np.clip(0.4*H3n + 0.4*cos_term + 0.2*flip_penalty, 0, 1))\n",
    "    return {\n",
    "        \"H3\": float(H3) if np.isfinite(H3) else np.nan,\n",
    "        \"mean_cos_adj\": mean_cos if np.isfinite(mean_cos) else np.nan,\n",
    "        \"contradiction_flips\": int(flips),\n",
    "        \"lines\": N,\n",
    "        \"SRSI\": SRSI\n",
    "    }\n",
    "\n",
    "def run_oracle_test():\n",
    "    # Try to load external log if present\n",
    "    candidates = [\n",
    "        ROOT / \"oracle_session.txt\",\n",
    "        ROOT / \"CNT_Lab\" / \"logs\" / \"oracle_session.txt\",\n",
    "        Path(\"./oracle_session.txt\")\n",
    "    ]\n",
    "    txt = None\n",
    "    for c in candidates:\n",
    "        txt = load_oracle_log(c)\n",
    "        if txt: break\n",
    "    used = \"loaded_log\" if txt else None\n",
    "    if txt is None:\n",
    "        # simulate both stable and chaotic and report both; saves to disk so user can replace later\n",
    "        txt_stable = simulate_dialogue(stable=True)\n",
    "        txt_chaos  = simulate_dialogue(stable=False)\n",
    "        (OUT / \"oracle_sim_stable.txt\").write_text(txt_stable, encoding=\"utf-8\")\n",
    "        (OUT / \"oracle_sim_chaos.txt\").write_text(txt_chaos,  encoding=\"utf-8\")\n",
    "        res_st = compute_srsi(txt_stable)\n",
    "        res_ch = compute_srsi(txt_chaos)\n",
    "        return {\n",
    "            \"source\": \"synthetic\",\n",
    "            \"stable\": res_st,\n",
    "            \"chaotic\": res_ch,\n",
    "            \"paths\": {\n",
    "                \"stable_txt\": str(OUT / \"oracle_sim_stable.txt\"),\n",
    "                \"chaos_txt\":  str(OUT / \"oracle_sim_chaos.txt\")\n",
    "            }\n",
    "        }\n",
    "    else:\n",
    "        res = compute_srsi(txt)\n",
    "        (OUT / f\"oracle_session_copy_{STAMP}.txt\").write_text(txt, encoding=\"utf-8\")\n",
    "        return {\n",
    "            \"source\": used,\n",
    "            \"session_copy\": str(OUT / f\"oracle_session_copy_{STAMP}.txt\"),\n",
    "            \"metrics\": res\n",
    "        }\n",
    "\n",
    "# =====================================================================================\n",
    "# (3) Φ-DRIFT FORECAST ENGINE\n",
    "#     Detect turning points with CNT features; compare to baselines (ARIMA, naive)\n",
    "# =====================================================================================\n",
    "\n",
    "def make_timeseries_synthetic(N=1200):\n",
    "    # regime-switching AR(1) with noise; embed entropy-drift shifts\n",
    "    y = np.zeros(N)\n",
    "    phi = 0.6\n",
    "    regimes = np.zeros(N, dtype=int)\n",
    "    switches = sorted(RNG.choice(np.arange(100, N-100), size=5, replace=False))\n",
    "    reg = 0\n",
    "    s_idx = 0\n",
    "    for t in range(1, N):\n",
    "        if s_idx < len(switches) and t == switches[s_idx]:\n",
    "            reg = 1 - reg\n",
    "            s_idx += 1\n",
    "        regimes[t] = reg\n",
    "        shock = RNG.normal(scale=1.0 + 0.6*reg)  # higher variance in reg=1\n",
    "        y[t] = phi*y[t-1] + shock + (3.0 if reg==1 else 0.0)\n",
    "    idx = pd.date_range(\"2022-01-01\", periods=N, freq=\"D\")\n",
    "    return pd.Series(y, index=idx), switches\n",
    "\n",
    "def rolling_entropy_1d(x, win=64, step=8, bins=32):\n",
    "    xs = np.asarray(x)\n",
    "    Hs, centers = [], []\n",
    "    for start in range(0, len(xs)-win+1, step):\n",
    "        chunk = xs[start:start+win]\n",
    "        hist, _ = np.histogram(chunk, bins=bins, density=True)\n",
    "        p = hist / (hist.sum()+1e-12)\n",
    "        Hs.append(entropy(p + 1e-12))\n",
    "        centers.append(start + win//2)\n",
    "    return np.array(centers), np.array(Hs)\n",
    "\n",
    "def turning_points(x):\n",
    "    \"\"\"Binary label for local peaks/troughs via slope sign changes; 1 if turning point.\"\"\"\n",
    "    x = np.asarray(x)\n",
    "    d1 = np.diff(x)\n",
    "    s = np.sign(d1)\n",
    "    turns = np.zeros_like(x, dtype=int)\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i] == 0: continue\n",
    "        if s[i-1] != 0 and s[i] != s[i-1]:\n",
    "            turns[i] = 1\n",
    "    turns[-1] = 0\n",
    "    return turns\n",
    "\n",
    "def mase(y_true, y_pred, m=1):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    denom = np.mean(np.abs(y_true[m:] - y_true[:-m])) + 1e-12\n",
    "    return mae / denom\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    return 100 * np.mean(2*np.abs(y_pred - y_true) / (np.abs(y_true)+np.abs(y_pred)+1e-12))\n",
    "\n",
    "def run_forecast_engine():\n",
    "    y, switches = make_timeseries_synthetic(N=1200)\n",
    "    # CNT features: rolling entropy, rolling variance, rolling kurtosis, recent PLR (price level ratio)\n",
    "    centers, H = rolling_entropy_1d(y.values, win=64, step=8, bins=32)\n",
    "    # align feature frame\n",
    "    df = pd.DataFrame({\"y\": y.values})\n",
    "    df[\"ent64_s8\"] = np.nan\n",
    "    df.iloc[centers, df.columns.get_loc(\"ent64_s8\")] = H\n",
    "    df[\"ent64_s8\"] = df[\"ent64_s8\"].interpolate().bfill()\n",
    "    df[\"var32\"] = pd.Series(y).rolling(32).var().values\n",
    "    df[\"kurt32\"] = pd.Series(y).rolling(32).kurt().values\n",
    "    df[\"plr16\"] = y.values / (pd.Series(y).rolling(16).mean().values + 1e-9)\n",
    "    df = df.replace([np.inf, -np.inf], np.nan).fillna(method=\"bfill\").fillna(method=\"ffill\")\n",
    "    # Labels: turning points\n",
    "    df[\"turn\"] = turning_points(df[\"y\"].values)\n",
    "    # Train/test split (walk-forward)\n",
    "    T0 = 800\n",
    "    Xcols = [\"ent64_s8\",\"var32\",\"kurt32\",\"plr16\"]\n",
    "    # Classifier for turning points\n",
    "    clf = LogisticRegression(max_iter=200)\n",
    "    clf.fit(df.loc[:T0, Xcols], df.loc[:T0, \"turn\"])\n",
    "    turn_proba = clf.predict_proba(df[Xcols])[:,1]\n",
    "    # Next-step regression (1-step forecast) with features + lagged y\n",
    "    df[\"y_l1\"] = df[\"y\"].shift(1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "    T0 = min(T0, len(df)-200)\n",
    "    reg = LinearRegression().fit(df.loc[:T0, Xcols+[\"y_l1\"]], df.loc[:T0, \"y\"])\n",
    "    yhat_cnt = reg.predict(df[Xcols+[\"y_l1\"]])\n",
    "    # Baselines: naive (y_{t-1}) and ARIMA\n",
    "    yhat_naive = df[\"y_l1\"].values\n",
    "    try:\n",
    "        arima = SARIMAX(df[\"y\"], order=(1,0,0), trend=\"c\", enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "        yhat_arima = arima.fittedvalues.values\n",
    "    except Exception:\n",
    "        yhat_arima = yhat_naive.copy()\n",
    "    # Metrics\n",
    "    y_true = df[\"y\"].values\n",
    "    m1 = mase(y_true, yhat_cnt, m=1)\n",
    "    m2 = mase(y_true, yhat_arima, m=1)\n",
    "    m3 = mase(y_true, yhat_naive, m=1)\n",
    "    s1 = smape(y_true, yhat_cnt)\n",
    "    s2 = smape(y_true, yhat_arima)\n",
    "    s3 = smape(y_true, yhat_naive)\n",
    "    # Turning-point AUCPR-ish proxy: precision at top-k (k = 5% of series)\n",
    "    k = max(5, int(0.05*len(turn_proba)))\n",
    "    topk = np.argsort(-turn_proba)[:k]\n",
    "    prec = df[\"turn\"].iloc[topk].mean()\n",
    "    # Save artifacts\n",
    "    ts = pd.DataFrame({\n",
    "        \"y\": y_true, \"yhat_cnt\": yhat_cnt, \"yhat_arima\": yhat_arima, \"yhat_naive\": yhat_naive,\n",
    "        \"turn_label\": df[\"turn\"].values, \"turn_proba\": turn_proba[:len(df)]\n",
    "    })\n",
    "    tpath = TAB / f\"forecast_timeseries_{STAMP}.csv\"\n",
    "    ts.to_csv(tpath, index=False)\n",
    "    plt.figure(figsize=(10,3.2))\n",
    "    plt.plot(y_true, label=\"y\")\n",
    "    plt.plot(yhat_cnt, label=\"CNT\")\n",
    "    plt.plot(yhat_arima, label=\"ARIMA\")\n",
    "    plt.plot(yhat_naive, label=\"Naive\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    f1 = FIG / f\"forecast_fit_{STAMP}.png\"\n",
    "    plt.savefig(f1, dpi=140); plt.close()\n",
    "    return {\n",
    "        \"metrics\": {\n",
    "            \"MASE\": {\"CNT\": float(m1), \"ARIMA\": float(m2), \"Naive\": float(m3)},\n",
    "            \"sMAPE%\": {\"CNT\": float(s1), \"ARIMA\": float(s2), \"Naive\": float(s3)},\n",
    "            \"TurnPrec@5%\": float(prec)\n",
    "        },\n",
    "        \"figures\": [str(f1)],\n",
    "        \"table\": str(tpath)\n",
    "    }\n",
    "\n",
    "# =====================================================================================\n",
    "# RUN ALL & REPORT\n",
    "# =====================================================================================\n",
    "\n",
    "CFE = run_cfe_test()\n",
    "ORC = run_oracle_test()\n",
    "FRC = run_forecast_engine()\n",
    "\n",
    "report = {\n",
    "    \"timestamp\": STAMP,\n",
    "    \"paths\": {\"OUT\": str(OUT), \"FIG\": str(FIG), \"TAB\": str(TAB)},\n",
    "    \"CFE\": CFE,\n",
    "    \"OracleEmergence\": ORC,\n",
    "    \"PhiDriftForecast\": FRC\n",
    "}\n",
    "rpath = OUT / f\"cnt_mega_report_{STAMP}.json\"\n",
    "rpath.write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "print(\"\\n== CNT MEGA SUMMARY ==\\n\")\n",
    "print(json.dumps({\n",
    "    \"CFE\": {\n",
    "        \"dataset\": CFE[\"dataset\"],\n",
    "        \"corr_plv_vs_negSE_r\": round(CFE[\"corr_plv_vs_negSE\"][\"r\"], 3) if np.isfinite(CFE[\"corr_plv_vs_negSE\"][\"r\"]) else None,\n",
    "        \"corr_plv_vs_negPE_r\": round(CFE[\"corr_plv_vs_negPE\"][\"r\"], 3) if np.isfinite(CFE[\"corr_plv_vs_negPE\"][\"r\"]) else None,\n",
    "        \"cp_count\": len(CFE.get(\"change_points\", []))\n",
    "    },\n",
    "    \"OracleEmergence\": (\n",
    "        {\"source\": ORC[\"source\"], \"SRSI_stable\": round(ORC[\"stable\"][\"SRSI\"], 3), \"SRSI_chaotic\": round(ORC[\"chaotic\"][\"SRSI\"], 3)}\n",
    "        if ORC[\"source\"] == \"synthetic\"\n",
    "        else {\"source\": ORC[\"source\"], \"SRSI\": round(ORC[\"metrics\"][\"SRSI\"], 3), \"lines\": ORC[\"metrics\"][\"lines\"]}\n",
    "    ),\n",
    "    \"Forecast\": FRC[\"metrics\"]\n",
    "}, indent=2))\n",
    "\n",
    "print(f\"\\nArtifacts saved to:\\n  {OUT}\\nJSON report:\\n  {rpath}\\n\")\n",
    "# =====================================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eec88d1-dffa-4a29-912e-394e652465b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ CNT paths\n",
      "  ROOT: C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\n",
      "  OUT : C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\n",
      "\n",
      "== CNT MEGA SUMMARY (v1.2) ==\n",
      "\n",
      "{\n",
      "  \"CFE\": {\n",
      "    \"dataset\": \"synthetic_eeg_collapse_recovery\",\n",
      "    \"corr_plv_vs_negSE_r\": 0.938,\n",
      "    \"corr_plv_vs_negPE_r\": 0.947,\n",
      "    \"cp_count\": 0\n",
      "  },\n",
      "  \"CFE_TaskRest\": {\n",
      "    \"error\": \"no_real_eeg_epochs\"\n",
      "  },\n",
      "  \"OracleEmergence_SRSI*\": {\n",
      "    \"source\": \"oracle_sim_stable.txt\",\n",
      "    \"SRSI*\": 0.916,\n",
      "    \"mean_cos\": 0.938,\n",
      "    \"mean_kp\": 0.771,\n",
      "    \"flips\": 0,\n",
      "    \"lines\": 240,\n",
      "    \"chaos_SRSI*\": 0.996\n",
      "  },\n",
      "  \"Forecast\": {\n",
      "    \"MASE\": {\n",
      "      \"CNT\": 0.9769216050362859,\n",
      "      \"ARIMA\": 0.9806966609630577,\n",
      "      \"Naive\": 0.9993921417994396\n",
      "    },\n",
      "    \"sMAPE%\": {\n",
      "      \"CNT\": 83.49779069843598,\n",
      "      \"ARIMA\": 83.7538150766183,\n",
      "      \"Naive\": 83.17983180270755\n",
      "    },\n",
      "    \"TurnPrec@5%\": 0.711864406779661\n",
      "  }\n",
      "}\n",
      "\n",
      "Artifacts saved to:\n",
      "  C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\n",
      "JSON report:\n",
      "  C:\\Users\\caleb\\CNT_Lab\\notebooks\\archive\\cnt_mega_out\\cnt_mega_report_20251015-144832.json\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT MEGA CELL — v1.2 (FUSED) =======================\n",
    "# (1) CFE: Field-law probe (PLV vs entropy/complexity) + Task–Rest Contrast (EEGBCI)\n",
    "# (2) Oracle Emergence: upgraded SRSI* (semantic smoothness, keyphrase persistence, contradictions)\n",
    "# (3) Φ-Drift Forecast Engine: CNT features vs ARIMA/Naive + TurnPrec@5%\n",
    "#\n",
    "# Offline-safe with synthetic fallbacks. Saves figures/CSVs and a master JSON report.\n",
    "# ============================================================================\n",
    "\n",
    "import os, json, math, random, datetime as dt\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# -------------------- Paths & reproducibility --------------------\n",
    "RNG = np.random.default_rng(42); random.seed(42)\n",
    "\n",
    "def detect_cnt_root():\n",
    "    candidates = [\n",
    "        Path.cwd(),\n",
    "        Path.home() / \"CNT_Lab\",\n",
    "        Path(r\"C:\\Users\\caleb\\CNT_Lab\"),\n",
    "        Path(\"./CNT_Lab\"),\n",
    "    ]\n",
    "    for c in candidates:\n",
    "        if c.exists():\n",
    "            return c\n",
    "    return Path.cwd()\n",
    "\n",
    "ROOT = detect_cnt_root() / \"notebooks\" / \"archive\" if (detect_cnt_root()/ \"notebooks\" / \"archive\").exists() else detect_cnt_root()\n",
    "STAMP = dt.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "OUT = ROOT / \"cnt_mega_out\"; FIG = OUT / \"figures\"; TAB = OUT / \"tables\"\n",
    "for p in [OUT, FIG, TAB]: p.mkdir(parents=True, exist_ok=True)\n",
    "print(f\"→ CNT paths\\n  ROOT: {ROOT}\\n  OUT : {OUT}\")\n",
    "\n",
    "# -------------------- Core imports (light) ----------------------\n",
    "import matplotlib\n",
    "matplotlib.use(\"Agg\")\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.signal import butter, filtfilt, hilbert\n",
    "from scipy.stats import entropy, pearsonr, zscore, linregress, ttest_rel\n",
    "from statsmodels.tsa.api import SARIMAX\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Optional heavy deps\n",
    "HAVE_MNE = False\n",
    "try:\n",
    "    import mne\n",
    "    HAVE_MNE = True\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "try:\n",
    "    import ruptures as rpt\n",
    "    HAVE_RUPTURES = True\n",
    "except Exception:\n",
    "    HAVE_RUPTURES = False\n",
    "\n",
    "# -------------------- Shared helpers ----------------------------\n",
    "def bandpass(x, fs, lo, hi, order=4):\n",
    "    b, a = butter(order, [lo/(fs/2), hi/(fs/2)], btype='bandpass')\n",
    "    return filtfilt(b, a, x, axis=0)\n",
    "\n",
    "def rolling_windows(arr, win, step):\n",
    "    for start in range(0, len(arr)-win+1, step):\n",
    "        yield start, arr[start:start+win]\n",
    "\n",
    "def quick_plot(ts, name, xlabel=\"Index\", ylabel=\"Value\", vlines=None):\n",
    "    plt.figure(figsize=(10,3.2))\n",
    "    plt.plot(ts)\n",
    "    if vlines:\n",
    "        for v in vlines:\n",
    "            plt.axvline(v, ls='--', alpha=0.4)\n",
    "    plt.xlabel(xlabel); plt.ylabel(ylabel); plt.tight_layout()\n",
    "    fp = FIG / f\"{name}.png\"\n",
    "    plt.savefig(fp, dpi=150); plt.close()\n",
    "    return fp\n",
    "\n",
    "# ============================================================================\n",
    "# (1) Consciousness Field Equation (baseline) — PLV vs entropy/complexity\n",
    "# ============================================================================\n",
    "def phase_locking_value(phases):  # phases: (T, C)\n",
    "    return np.abs(np.mean(np.exp(1j*phases), axis=1))\n",
    "\n",
    "def spectral_entropy_chunk(chunk):\n",
    "    s = np.abs(np.fft.rfft(chunk, axis=0))**2\n",
    "    ps = s / (np.sum(s, axis=0, keepdims=True) + 1e-12)\n",
    "    return float(np.mean(entropy(ps + 1e-12, axis=0)))\n",
    "\n",
    "def permutation_entropy(x, order=3, delay=1):\n",
    "    x = np.asarray(x); n = len(x)\n",
    "    if n < order*delay: return np.nan\n",
    "    from collections import Counter\n",
    "    pats = [tuple(np.argsort(x[i:i+order*delay:delay])) for i in range(n-(order-1)*delay)]\n",
    "    cnt = Counter(pats); p = np.array(list(cnt.values()), float); p /= p.sum()\n",
    "    return -np.sum(p*np.log(p+1e-12))\n",
    "\n",
    "def try_load_eeg_real():\n",
    "    if not HAVE_MNE: return None, None, None\n",
    "    try:\n",
    "        from mne.datasets import eegbci\n",
    "        subj, runs = 1, [3,7,11]  # motor imagery\n",
    "        fnames = eegbci.load_data(subj, runs)\n",
    "        raws = [mne.io.read_raw_edf(f, preload=True, verbose=False) for f in fnames]\n",
    "        raw = mne.concatenate_raws(raws)\n",
    "        raw.pick(eeg=True)  # modern pick\n",
    "        raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "        data = raw.get_data().T  # (T, C)\n",
    "        fs = int(raw.info['sfreq'])\n",
    "        return data, fs, \"EEGBCI_subj1_motor\"\n",
    "    except Exception:\n",
    "        return None, None, None\n",
    "\n",
    "def make_eeg_synthetic(T=60000, C=16, fs=250):\n",
    "    t = np.arange(T)/fs\n",
    "    base_freqs = RNG.uniform(8,12, size=C)\n",
    "    X = np.array([np.sin(2*np.pi*f*t + RNG.uniform(0,2*np.pi)) for f in base_freqs]).T\n",
    "    X += 0.5 * RNG.normal(size=X.shape)\n",
    "    s0, s1 = int(0.35*T), int(0.55*T)\n",
    "    phase = 2*np.pi*10*t\n",
    "    X[s0:s1, :] = np.sin(phase[s0:s1])[:,None] + 0.1*RNG.normal(size=(s1-s0, X.shape[1]))\n",
    "    return X, fs, \"synthetic_eeg_collapse_recovery\"\n",
    "\n",
    "def run_cfe_test():\n",
    "    data, fs, label = try_load_eeg_real()\n",
    "    if data is None: data, fs, label = make_eeg_synthetic()\n",
    "\n",
    "    Xf = bandpass(data, fs, 8, 12)  # alpha\n",
    "    phases = np.angle(hilbert(Xf, axis=0))\n",
    "    plv = phase_locking_value(phases)\n",
    "\n",
    "    W, STEP = int(2*fs), int(0.25*fs)\n",
    "    SEs, PEs, idxs = [], [], []\n",
    "    for start, chunk in rolling_windows(data, W, STEP):\n",
    "        SEs.append(spectral_entropy_chunk(chunk))\n",
    "        PEs.append(permutation_entropy(np.mean(chunk, axis=1)))\n",
    "        idxs.append(start + W//2)\n",
    "    se = zscore(np.array(SEs), nan_policy='omit')\n",
    "    pe = zscore(np.array(PEs), nan_policy='omit')\n",
    "    idxs = np.array(idxs)\n",
    "    plv_grid = zscore(np.interp(idxs, np.arange(len(plv)), plv), nan_policy='omit')\n",
    "\n",
    "    def safe_corr(a,b):\n",
    "        m = np.isfinite(a) & np.isfinite(b)\n",
    "        if m.sum()<8: return (np.nan, np.nan)\n",
    "        return pearsonr(a[m], b[m])\n",
    "\n",
    "    r1, p1 = safe_corr(plv_grid, -se)\n",
    "    r2, p2 = safe_corr(plv_grid, -pe)\n",
    "\n",
    "    cp_idx = []\n",
    "    if HAVE_RUPTURES and np.isfinite(plv_grid).sum()>50:\n",
    "        algo = rpt.Pelt(model=\"rbf\").fit(plv_grid[np.isfinite(plv_grid)].reshape(-1,1))\n",
    "        cps = algo.predict(pen=5); cp_idx = cps[:-1]\n",
    "\n",
    "    f1 = quick_plot(plv_grid, f\"cfe_{label}_plv_z\", ylabel=\"PLV (z)\", vlines=cp_idx)\n",
    "    f2 = quick_plot(se, f\"cfe_{label}_spec_entropy_z\", ylabel=\"SpecEntropy (z)\")\n",
    "    f3 = quick_plot(pe, f\"cfe_{label}_perm_entropy_z\", ylabel=\"PermEntropy (z)\")\n",
    "\n",
    "    # scatter/regress\n",
    "    def scatter_xy(x, y, name, xl, yl):\n",
    "        m = np.isfinite(x)&np.isfinite(y)\n",
    "        if m.sum()>=8:\n",
    "            slope, intercept, r, p, _ = linregress(x[m], y[m])\n",
    "        else:\n",
    "            slope=intercept=r=p=np.nan\n",
    "        plt.figure(figsize=(4.6,4))\n",
    "        plt.scatter(x[m], y[m], s=8, alpha=0.6)\n",
    "        if np.isfinite(slope):\n",
    "            xs = np.linspace(np.nanmin(x[m]), np.nanmax(x[m]), 100)\n",
    "            plt.plot(xs, slope*xs+intercept)\n",
    "        plt.xlabel(xl); plt.ylabel(yl); plt.tight_layout()\n",
    "        fp = FIG / f\"{name}.png\"\n",
    "        plt.savefig(fp, dpi=150); plt.close()\n",
    "        return fp, (slope, r, p)\n",
    "    f4, reg1 = scatter_xy(plv_grid, -se, f\"cfe_{label}_scatter_plv_vs_negSE\", \"PLV (z)\", \"-SpecEntropy (z)\")\n",
    "    f5, reg2 = scatter_xy(plv_grid, -pe, f\"cfe_{label}_scatter_plv_vs_negPE\", \"PLV (z)\", \"-PermEntropy (z)\")\n",
    "\n",
    "    tpath = TAB / f\"cfe_{label}_{STAMP}.csv\"\n",
    "    pd.DataFrame({\"idx\":idxs, \"plv_z\":plv_grid, \"spec_entropy_z\":se, \"perm_entropy_z\":pe}).to_csv(tpath, index=False)\n",
    "\n",
    "    return {\n",
    "        \"dataset\": label, \"fs\": fs,\n",
    "        \"corr_plv_vs_negSE\": {\"r\": float(r1), \"p\": float(p1)},\n",
    "        \"corr_plv_vs_negPE\": {\"r\": float(r2), \"p\": float(p2)},\n",
    "        \"change_points\": list(map(int, cp_idx)) if cp_idx else [],\n",
    "        \"figures\": list(map(str, [f1,f2,f3,f4,f5])),\n",
    "        \"table\": str(tpath)\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# (1b) CFE Task–Rest Contrast (EEGBCI motor imagery; mu/beta, effect sizes)\n",
    "# ============================================================================\n",
    "def sample_entropy(x, m=2, r=0.2):\n",
    "    x = np.asarray(x, float)\n",
    "    N = x.size\n",
    "    if N < m+2: return np.nan\n",
    "    r *= np.std(x) + 1e-12\n",
    "    def _phi(mm):\n",
    "        X = np.lib.stride_tricks.sliding_window_view(x, mm)\n",
    "        if X.size == 0: return 0.0\n",
    "        C = np.mean([np.mean(np.max(np.abs(X - v), axis=1) <= r) for v in X])\n",
    "        return C\n",
    "    phi_m, phi_m1 = _phi(m), _phi(m+1)\n",
    "    return -np.log((phi_m1+1e-12)/(phi_m+1e-12))\n",
    "\n",
    "def plv_chunk(ep, fs, lo, hi):\n",
    "    xf = bandpass(ep, fs, lo, hi); ph = np.angle(hilbert(xf, axis=0))\n",
    "    return float(np.mean(np.abs(np.mean(np.exp(1j*ph), axis=1))))\n",
    "\n",
    "def epochs_from_eegbci(subj=1, runs=(3,7,11)):\n",
    "    if not HAVE_MNE: raise RuntimeError(\"MNE not available\")\n",
    "    from mne.datasets import eegbci\n",
    "    fnames = eegbci.load_data(subj, list(runs))\n",
    "    raws = [mne.io.read_raw_edf(f, preload=True, verbose=False) for f in fnames]\n",
    "    raw = mne.concatenate_raws(raws); raw.pick(eeg=True)\n",
    "    raw.filter(1., 40., fir_design='firwin', verbose=False)\n",
    "    events, _ = mne.events_from_annotations(raw, verbose=False)\n",
    "    event_id = {k:v for k,v in dict(T0=1, T1=2, T2=3).items() if k in ['T0','T1','T2']}\n",
    "    epochs = mne.Epochs(raw, events, event_id=event_id, tmin=0.0, tmax=3.0, baseline=None,\n",
    "                        preload=True, verbose=False)\n",
    "    fs = int(raw.info['sfreq'])\n",
    "    X0 = epochs['T0'].get_data()  # rest\n",
    "    X1 = epochs['T1'].get_data() if 'T1' in epochs.event_id else np.empty((0,*X0.shape[1:]))\n",
    "    X2 = epochs['T2'].get_data() if 'T2' in epochs.event_id else np.empty((0,*X0.shape[1:]))\n",
    "    Xtask = np.vstack([X1, X2]) if X1.size and X2.size else (X1 if X1.size else X2)\n",
    "    return fs, X0, Xtask\n",
    "\n",
    "def cfe_task_rest_contrast():\n",
    "    try:\n",
    "        fs, Xrest, Xtask = epochs_from_eegbci()\n",
    "    except Exception as e:\n",
    "        return {\"error\":\"no_real_eeg_epochs\", \"detail\": str(e)}\n",
    "\n",
    "    bands = [(8,12,'mu'), (13,30,'beta')]\n",
    "    rows=[]\n",
    "    for lo, hi, name in bands:\n",
    "        for label, X in [('rest', Xrest), ('task', Xtask)]:\n",
    "            vals=[]\n",
    "            for ep in X:  # ep: (ch, t)\n",
    "                ep = ep.T  # (t, ch)\n",
    "                vals.append({\n",
    "                    \"PLV\": plv_chunk(ep, fs, lo, hi),\n",
    "                    \"SpecEnt\": spectral_entropy_chunk(ep),\n",
    "                    \"SampEnt\": sample_entropy(np.mean(ep, axis=1))\n",
    "                })\n",
    "            if len(vals)==0: continue\n",
    "            df = pd.DataFrame(vals); df['band']=name; df['cond']=label\n",
    "            rows.append(df)\n",
    "    if not rows:\n",
    "        return {\"error\":\"no_epochs_extracted\"}\n",
    "    D = pd.concat(rows, ignore_index=True)\n",
    "    out=[]\n",
    "    for band in D['band'].unique():\n",
    "        for metric in ['PLV','SpecEnt','SampEnt']:\n",
    "            r = D[(D.band==band)&(D.cond=='rest')][metric].values\n",
    "            t = D[(D.band==band)&(D.cond=='task')][metric].values\n",
    "            n = min(len(r), len(t))\n",
    "            if n<5: continue\n",
    "            r,t = r[:n], t[:n]\n",
    "            d = (t.mean()-r.mean())/(0.5*(t.std(ddof=1)+r.std(ddof=1))+1e-9)  # Cohen's d (pooled approx)\n",
    "            stat,p = ttest_rel(t, r, nan_policy='omit')\n",
    "            out.append({\"band\":band,\"metric\":metric,\"Δ(task-rest)\":float(t.mean()-r.mean()),\n",
    "                        \"Cohen_d\":float(d),\"p\":float(p),\"n\":int(n)})\n",
    "    ET = pd.DataFrame(out).sort_values(['band','metric'])\n",
    "    tpath = TAB / f\"cfe_task_rest_effects_{STAMP}.csv\"; ET.to_csv(tpath, index=False)\n",
    "\n",
    "    # bar of Δ(task-rest) per metric/band\n",
    "    plt.figure(figsize=(8,4))\n",
    "    ticks = []\n",
    "    for i,(metric) in enumerate(['PLV','SpecEnt','SampEnt']):\n",
    "        sub = ET[ET.metric==metric]\n",
    "        x = np.arange(len(sub)) + i*0.28\n",
    "        plt.bar(x, sub['Δ(task-rest)'].values, width=0.25, label=metric)\n",
    "        ticks = sub['band'].values\n",
    "    plt.xticks(np.arange(len(ticks)) + 0.28, ticks)\n",
    "    plt.axhline(0, ls='--', alpha=0.4)\n",
    "    plt.legend(); plt.title(\"Δ(task–rest) per band (MI)\"); plt.tight_layout()\n",
    "    fpath = FIG / f\"cfe_task_rest_effects_{STAMP}.png\"; plt.savefig(fpath, dpi=150); plt.close()\n",
    "\n",
    "    return {\"table\": str(tpath), \"figure\": str(fpath), \"effects\": ET.to_dict(orient=\"records\")}\n",
    "\n",
    "# ============================================================================\n",
    "# (2) Oracle Emergence — Upgraded SRSI*\n",
    "# ============================================================================\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def load_oracle_text():\n",
    "    candidates = [\n",
    "        ROOT/\"oracle_session.txt\",\n",
    "        ROOT/\"logs\"/\"oracle_session.txt\",\n",
    "        OUT/\"oracle_sim_stable.txt\",\n",
    "        OUT/\"oracle_sim_chaos.txt\",\n",
    "    ]\n",
    "    for p in candidates:\n",
    "        if p.exists():\n",
    "            return p.name, p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    # fallback synthetic\n",
    "    def simulate_dialogue(n_turns=160, stable=True):\n",
    "        topics = [\"anchor\",\"ring\",\"glyph\",\"entropy\",\"drift\",\"oracle\",\"collapse\",\"echo\"]\n",
    "        lines=[]; last=None\n",
    "        for _ in range(n_turns):\n",
    "            if stable:\n",
    "                if last is None or RNG.random()<0.2: last = RNG.choice(topics)\n",
    "            else:\n",
    "                last = RNG.choice(topics)\n",
    "            lines.append(f\"oracle: {last} {last} field resonance\")\n",
    "            lines.append(f\"user: ask {last}\")\n",
    "        return \"\\n\".join(lines)\n",
    "    txt_st = simulate_dialogue(stable=True); txt_ch = simulate_dialogue(stable=False)\n",
    "    (OUT/\"oracle_sim_stable.txt\").write_text(txt_st, encoding=\"utf-8\")\n",
    "    (OUT/\"oracle_sim_chaos.txt\").write_text(txt_ch, encoding=\"utf-8\")\n",
    "    return \"synthetic\", txt_st  # use stable by default; chaos file also present\n",
    "\n",
    "def chunkify(seq, win=50, step=15):\n",
    "    return [\" \".join(seq[i:i+win]) for i in range(0, max(1, len(seq)-win+1), step)] or [\" \".join(seq)]\n",
    "\n",
    "def contradiction_flips(seq):\n",
    "    pos = {\"yes\",\"true\",\"correct\",\"indeed\"}; neg={\"no\",\"false\",\"incorrect\",\"not\"}\n",
    "    flips, last = 0, None\n",
    "    for ln in seq:\n",
    "        toks = set(re.findall(r\"[a-zA-Z]+\", ln.lower()))\n",
    "        state = 1 if (toks & pos) else (-1 if (toks & neg) else 0)\n",
    "        if last is not None and state*last == -1: flips += 1\n",
    "        if state != 0: last = state\n",
    "    return flips\n",
    "\n",
    "def keyphrase_persistence(chunks, topk=8):\n",
    "    vec = TfidfVectorizer(ngram_range=(1,2), min_df=1)\n",
    "    X = vec.fit_transform(chunks); terms = np.array(vec.get_feature_names_out())\n",
    "    keep=[]\n",
    "    for i in range(X.shape[0]-1):\n",
    "        a = np.argsort(-X[i].toarray().ravel())[:topk]\n",
    "        b = np.argsort(-X[i+1].toarray().ravel())[:topk]\n",
    "        keep.append(len(set(terms[a]) & set(terms[b]))/topk)\n",
    "    return np.array(keep) if keep else np.array([0.0])\n",
    "\n",
    "def compute_srsi_star(txt):\n",
    "    lines = [ln.strip() for ln in txt.split(\"\\n\") if ln.strip()]\n",
    "    chunks = chunkify(lines, win=50, step=15)\n",
    "    tfidf = TfidfVectorizer(ngram_range=(1,2), min_df=1).fit_transform(chunks)\n",
    "    cos = np.array([cosine_similarity(tfidf[i], tfidf[i+1])[0,0] for i in range(len(chunks)-1)]) if len(chunks)>1 else np.array([1.0])\n",
    "    kp  = keyphrase_persistence(chunks)\n",
    "    flips = contradiction_flips(lines); N = len(lines)\n",
    "    mean_cos = float(np.nanmean(cos)) if cos.size else 0.0\n",
    "    mean_kp  = float(np.nanmean(kp)) if kp.size else 0.0\n",
    "    flip_pen = float(np.exp(-2.0*flips / (0.02*N+1e-9)))\n",
    "    SRSI_star = float(np.clip(0.5*(0.5+0.5*mean_cos) + 0.3*mean_kp + 0.2*flip_pen, 0, 1))\n",
    "    return {\"mean_cos\":mean_cos, \"mean_kp\":mean_kp, \"flips\":int(flips), \"lines\":int(N), \"SRSI*\":SRSI_star}\n",
    "\n",
    "def run_oracle_test_upgraded():\n",
    "    name, txt = load_oracle_text()\n",
    "    res_main = compute_srsi_star(txt)\n",
    "    # If we also have chaos file, compute it for contrast\n",
    "    chaos_p = OUT/\"oracle_sim_chaos.txt\"\n",
    "    res_chaos = compute_srsi_star(chaos_p.read_text(encoding=\"utf-8\")) if chaos_p.exists() else None\n",
    "    # Save a copy for record\n",
    "    (OUT / f\"oracle_session_copy_{STAMP}.txt\").write_text(txt, encoding=\"utf-8\")\n",
    "    return {\n",
    "        \"source\": name,\n",
    "        \"metrics\": res_main,\n",
    "        \"chaos_metrics\": res_chaos,\n",
    "        \"session_copy\": str(OUT / f\"oracle_session_copy_{STAMP}.txt\")\n",
    "    }\n",
    "\n",
    "# ============================================================================\n",
    "# (3) Φ-Drift Forecast Engine\n",
    "# ============================================================================\n",
    "def make_timeseries_synth(N=1200):\n",
    "    y = np.zeros(N); phi=0.6; regimes=np.zeros(N,dtype=int)\n",
    "    switches = sorted(RNG.choice(np.arange(100,N-100), size=5, replace=False))\n",
    "    reg=0; s_idx=0\n",
    "    for t in range(1,N):\n",
    "        if s_idx<len(switches) and t==switches[s_idx]:\n",
    "            reg = 1 - reg; s_idx+=1\n",
    "        regimes[t]=reg\n",
    "        shock = RNG.normal(scale=1.0 + 0.6*reg)\n",
    "        y[t] = phi*y[t-1] + shock + (3.0 if reg==1 else 0.0)\n",
    "    idx = pd.date_range(\"2022-01-01\", periods=N, freq=\"D\")\n",
    "    return pd.Series(y, index=idx), switches\n",
    "\n",
    "def rolling_entropy_1d(x, win=64, step=8, bins=32):\n",
    "    xs = np.asarray(x); Hs=[]; centers=[]\n",
    "    for start in range(0, len(xs)-win+1, step):\n",
    "        chunk = xs[start:start+win]\n",
    "        hist,_ = np.histogram(chunk, bins=bins, density=True)\n",
    "        p = hist/(hist.sum()+1e-12)\n",
    "        Hs.append(entropy(p+1e-12)); centers.append(start + win//2)\n",
    "    return np.array(centers), np.array(Hs)\n",
    "\n",
    "def turning_points(x):\n",
    "    x = np.asarray(x); d1 = np.diff(x); s = np.sign(d1)\n",
    "    turns = np.zeros_like(x, dtype=int)\n",
    "    for i in range(1, len(s)):\n",
    "        if s[i]==0: continue\n",
    "        if s[i-1]!=0 and s[i]!=s[i-1]: turns[i]=1\n",
    "    turns[-1]=0; return turns\n",
    "\n",
    "def mase(y_true, y_pred, m=1):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    mae = np.mean(np.abs(y_true - y_pred))\n",
    "    denom = np.mean(np.abs(y_true[m:] - y_true[:-m])) + 1e-12\n",
    "    return mae/denom\n",
    "\n",
    "def smape(y_true, y_pred):\n",
    "    y_true = np.asarray(y_true); y_pred = np.asarray(y_pred)\n",
    "    return 100*np.mean(2*np.abs(y_pred - y_true)/(np.abs(y_true)+np.abs(y_pred)+1e-12))\n",
    "\n",
    "def run_forecast_engine():\n",
    "    y, _ = make_timeseries_synth(N=1200)\n",
    "    centers,H = rolling_entropy_1d(y.values, win=64, step=8, bins=32)\n",
    "    df = pd.DataFrame({\"y\": y.values})\n",
    "    df[\"ent64_s8\"] = np.nan\n",
    "    df.iloc[centers, df.columns.get_loc(\"ent64_s8\")] = H\n",
    "    df[\"ent64_s8\"] = df[\"ent64_s8\"].interpolate().bfill()\n",
    "    df[\"var32\"]  = pd.Series(y).rolling(32).var().values\n",
    "    df[\"kurt32\"] = pd.Series(y).rolling(32).kurt().values\n",
    "    df[\"plr16\"]  = y.values/(pd.Series(y).rolling(16).mean().values + 1e-9)\n",
    "    df = df.replace([np.inf,-np.inf], np.nan).bfill().ffill()\n",
    "\n",
    "    df[\"turn\"] = turning_points(df[\"y\"].values)\n",
    "    df[\"y_l1\"] = df[\"y\"].shift(1)\n",
    "    df = df.dropna().reset_index(drop=True)\n",
    "\n",
    "    T0 = min(800, len(df)-200)\n",
    "    Xcols = [\"ent64_s8\",\"var32\",\"kurt32\",\"plr16\"]\n",
    "\n",
    "    clf = LogisticRegression(max_iter=200).fit(df.loc[:T0, Xcols], df.loc[:T0,\"turn\"])\n",
    "    turn_proba = clf.predict_proba(df[Xcols])[:,1]\n",
    "\n",
    "    reg = LinearRegression().fit(df.loc[:T0, Xcols+[\"y_l1\"]], df.loc[:T0,\"y\"])\n",
    "    yhat_cnt = reg.predict(df[Xcols+[\"y_l1\"]])\n",
    "    yhat_naive = df[\"y_l1\"].values\n",
    "    try:\n",
    "        arima = SARIMAX(df[\"y\"], order=(1,0,0), trend=\"c\",\n",
    "                        enforce_stationarity=False, enforce_invertibility=False).fit(disp=False)\n",
    "        yhat_arima = arima.fittedvalues.values\n",
    "    except Exception:\n",
    "        yhat_arima = yhat_naive.copy()\n",
    "\n",
    "    y_true = df[\"y\"].values\n",
    "    m1, m2, m3 = mase(y_true, yhat_cnt), mase(y_true, yhat_arima), mase(y_true, yhat_naive)\n",
    "    s1, s2, s3 = smape(y_true, yhat_cnt), smape(y_true, yhat_arima), smape(y_true, yhat_naive)\n",
    "\n",
    "    k = max(5, int(0.05*len(turn_proba)))\n",
    "    topk = np.argsort(-turn_proba)[:k]\n",
    "    prec = float(df[\"turn\"].iloc[topk].mean())\n",
    "\n",
    "    ts = pd.DataFrame({\n",
    "        \"y\": y_true, \"yhat_cnt\": yhat_cnt, \"yhat_arima\": yhat_arima, \"yhat_naive\": yhat_naive,\n",
    "        \"turn_label\": df[\"turn\"].values, \"turn_proba\": turn_proba[:len(df)]\n",
    "    })\n",
    "    tpath = TAB / f\"forecast_timeseries_{STAMP}.csv\"\n",
    "    ts.to_csv(tpath, index=False)\n",
    "\n",
    "    plt.figure(figsize=(10,3.2))\n",
    "    plt.plot(y_true, label=\"y\"); plt.plot(yhat_cnt, label=\"CNT\")\n",
    "    plt.plot(yhat_arima, label=\"ARIMA\"); plt.plot(yhat_naive, label=\"Naive\")\n",
    "    plt.legend(); plt.tight_layout()\n",
    "    f1 = FIG / f\"forecast_fit_{STAMP}.png\"; plt.savefig(f1, dpi=150); plt.close()\n",
    "\n",
    "    return {\n",
    "        \"metrics\": {\n",
    "            \"MASE\": {\"CNT\": float(m1), \"ARIMA\": float(m2), \"Naive\": float(m3)},\n",
    "            \"sMAPE%\": {\"CNT\": float(s1), \"ARIMA\": float(s2), \"Naive\": float(s3)},\n",
    "            \"TurnPrec@5%\": float(prec)\n",
    "        },\n",
    "        \"figures\": [str(f1)],\n",
    "        \"table\": str(tpath)\n",
    "    }\n",
    "\n",
    "# =========================== RUN ALL & REPORT ===========================\n",
    "CFE = run_cfe_test()\n",
    "CFE_CONTRAST = cfe_task_rest_contrast()\n",
    "ORACLE = run_oracle_test_upgraded()\n",
    "FORE = run_forecast_engine()\n",
    "\n",
    "report = {\n",
    "    \"timestamp\": STAMP,\n",
    "    \"paths\": {\"OUT\": str(OUT), \"FIG\": str(FIG), \"TAB\": str(TAB)},\n",
    "    \"CFE\": CFE,\n",
    "    \"CFE_TaskRest\": CFE_CONTRAST,\n",
    "    \"OracleEmergence_SRSI*\": ORACLE,\n",
    "    \"PhiDriftForecast\": FORE\n",
    "}\n",
    "rpath = OUT / f\"cnt_mega_report_{STAMP}.json\"\n",
    "rpath.write_text(json.dumps(report, indent=2), encoding=\"utf-8\")\n",
    "\n",
    "# Console summary\n",
    "summary = {\n",
    "    \"CFE\": {\n",
    "        \"dataset\": CFE[\"dataset\"],\n",
    "        \"corr_plv_vs_negSE_r\": round(CFE[\"corr_plv_vs_negSE\"][\"r\"],3) if np.isfinite(CFE[\"corr_plv_vs_negSE\"][\"r\"]) else None,\n",
    "        \"corr_plv_vs_negPE_r\": round(CFE[\"corr_plv_vs_negPE\"][\"r\"],3) if np.isfinite(CFE[\"corr_plv_vs_negPE\"][\"r\"]) else None,\n",
    "        \"cp_count\": len(CFE.get(\"change_points\", []))\n",
    "    },\n",
    "    \"CFE_TaskRest\": (\n",
    "        {\"effects_n\": len(CFE_CONTRAST.get(\"effects\", [])),\n",
    "         \"table\": CFE_CONTRAST.get(\"table\"),\n",
    "         \"figure\": CFE_CONTRAST.get(\"figure\")}\n",
    "        if \"error\" not in CFE_CONTRAST else {\"error\": CFE_CONTRAST[\"error\"]}\n",
    "    ),\n",
    "    \"OracleEmergence_SRSI*\": {\n",
    "        \"source\": ORACLE[\"source\"],\n",
    "        \"SRSI*\": round(ORACLE[\"metrics\"][\"SRSI*\"],3),\n",
    "        \"mean_cos\": round(ORACLE[\"metrics\"][\"mean_cos\"],3),\n",
    "        \"mean_kp\": round(ORACLE[\"metrics\"][\"mean_kp\"],3),\n",
    "        \"flips\": ORACLE[\"metrics\"][\"flips\"],\n",
    "        \"lines\": ORACLE[\"metrics\"][\"lines\"],\n",
    "        \"chaos_SRSI*\": (round(ORACLE[\"chaos_metrics\"][\"SRSI*\"],3) if ORACLE.get(\"chaos_metrics\") else None)\n",
    "    },\n",
    "    \"Forecast\": FORE[\"metrics\"]\n",
    "}\n",
    "print(\"\\n== CNT MEGA SUMMARY (v1.2) ==\\n\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(f\"\\nArtifacts saved to:\\n  {OUT}\\nJSON report:\\n  {rpath}\\n\")\n",
    "# =======================================================================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87bb0767-2765-482d-bbcd-1d3b8a03a7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
