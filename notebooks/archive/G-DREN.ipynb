{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5934c01b-4d65-4368-92c8-ca3fa958f62f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_15696\\2388790087.py:103: FutureWarning: Series.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  delayed = df['signal'].shift(3).fillna(method='bfill').values\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-210414Z\\\\gdren_m0_features.csv\",\n",
      "  \"run_meta_json\": \"204\"\n",
      "}\n",
      "         NEXUS alert\n",
      "3990  0.341865    OK\n",
      "3991  0.341865    OK\n",
      "3992  0.341865    OK\n",
      "3993  0.341865    OK\n",
      "3994  0.341865    OK\n",
      "3995  0.341865    OK\n",
      "3996  0.341865    OK\n",
      "3997  0.341865    OK\n",
      "3998  0.341865    OK\n",
      "3999  0.341865    OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_15696\\2388790087.py:65: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  F = F.fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.1: Milestone-0 bootstrap ===\n",
    "import os, sys, json, math, time, hashlib\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.signal import welch, coherence\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# --- Paths ---\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "for p in [ROOT, RUN]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "# --- Utilities ---\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x)\n",
    "    out = np.full_like(x, np.nan, dtype=float)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]\n",
    "        out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def phase_echo(x, max_lag=60):\n",
    "    x = pd.Series(x).astype(float)\n",
    "    x = (x - x.mean())/(x.std()+1e-9)\n",
    "    vals = []\n",
    "    for tau in range(1, max_lag+1):\n",
    "        a = x[tau:].values\n",
    "        b = x.shift(tau).dropna().values\n",
    "        if len(a)!=len(b) or len(a)<16: vals.append(np.nan); continue\n",
    "        r = np.corrcoef(a, b)[0,1]\n",
    "        vals.append(r)\n",
    "    vals = np.array(vals, float)\n",
    "    # echo power = max positive lag-corr over window\n",
    "    return np.nanmax(vals)\n",
    "\n",
    "def theta_breaches(sig, q=0.98, win=256):\n",
    "    sig = pd.Series(sig).astype(float)\n",
    "    thr = sig.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (sig > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    if not np.any(band): return np.nan\n",
    "    return float(np.nanmean(Cxy[band]))\n",
    "\n",
    "def zscore(x):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    return ((x - x.rolling(512, min_periods=64).mean())\n",
    "            /(x.rolling(512, min_periods=64).std()+1e-9)).values\n",
    "\n",
    "def fuse_to_nexus(features: pd.DataFrame):\n",
    "    # Simple monotone fusion for v0\n",
    "    F = features.copy()\n",
    "    F = F.fillna(method=\"ffill\").fillna(method=\"bfill\").fillna(0.0)\n",
    "    # Normalize each feature\n",
    "    for c in F.columns:\n",
    "        F[c] = (F[c]-F[c].quantile(0.1))/(F[c].quantile(0.9)-F[c].quantile(0.1)+1e-9)\n",
    "        F[c] = np.clip(F[c], 0, 1)\n",
    "    # Weighted sum + isotonic calibration against a synthetic target (peaks)\n",
    "    raw = 0.35*F['S_d'] + 0.25*F['Echo'] + 0.2*F['Theta'] + 0.2*F['Gamma']\n",
    "    # pseudo-target: rolling future volatility as proxy (for bootstrap only)\n",
    "    y = F['S_d'].shift(-12).fillna(F['S_d'].median()).values\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    xfit = raw.values\n",
    "    nexus = ir.fit_transform(xfit, y)\n",
    "    nex = pd.Series(nexus, index=F.index).astype(float)\n",
    "    return (nex - nex.rolling(256, min_periods=64).min()) / (\n",
    "            nex.rolling(256, min_periods=64).max() - nex.rolling(256, min_periods=64).min() + 1e-9)\n",
    "\n",
    "# --- Synthetic criticality test (Kuramoto-lite order parameter proxy) ---\n",
    "def synthetic_criticality(T=4000, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    # Piecewise parameter drifting toward critical region\n",
    "    base = np.cumsum(rng.normal(0, 0.02, T))\n",
    "    trend = np.linspace(0, 1.6, T)   # rising “K” proxy\n",
    "    shock = (np.arange(T) > int(0.85*T)).astype(float) * rng.normal(0, 2.0, T)\n",
    "    x = base + 0.6*np.tanh(1.5*(trend-1.0)) + 0.1*rng.normal(0,1,T) + shock\n",
    "    return pd.Series(x)\n",
    "\n",
    "def run_m0():\n",
    "    x = synthetic_criticality()\n",
    "    df = pd.DataFrame(index=pd.RangeIndex(len(x)))\n",
    "    df['signal'] = x.values\n",
    "    df['S_d']   = rolling_entropy(df['signal'], win=256, bins=48)\n",
    "    df['Echo']  = pd.Series([np.nan]*len(df))\n",
    "    for i in range(len(df)):\n",
    "        if i<300: continue\n",
    "        df.loc[i,'Echo'] = phase_echo(df['signal'].iloc[:i].values, max_lag=48)\n",
    "    df['Theta'] = theta_breaches(zscore(df['signal']), q=0.985, win=256)\n",
    "    # For Gamma, compare signal to a delayed copy as a stand-in second channel\n",
    "    df['Gamma'] = pd.Series([np.nan]*len(df))\n",
    "    delayed = df['signal'].shift(3).fillna(method='bfill').values\n",
    "    for i in range(300, len(df)):\n",
    "        a = df['signal'].iloc[max(0,i-512):i].values\n",
    "        b = delayed[max(0,i-512):i]\n",
    "        df.loc[i,'Gamma'] = glyph_coupling(a, b, fs=1.0)\n",
    "    feats = df[['S_d','Echo','Theta','Gamma']]\n",
    "    df['NEXUS'] = fuse_to_nexus(feats)\n",
    "    paths = {\n",
    "        \"features_csv\": save_df(df, \"gdren_m0_features\"),\n",
    "        \"run_meta_json\": str((RUN / \"meta.json\").write_text(json.dumps({\n",
    "            \"run_id\": RUN.name,\n",
    "            \"root\": str(ROOT), \"cnt_lab_dir\": str(CNT),\n",
    "            \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "            \"notes\": \"Milestone-0 synthetic criticality + NEXUS v0.1\"\n",
    "        }, indent=2)))\n",
    "    }\n",
    "    print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "    # Simple alerting demo\n",
    "    thr_watch, thr_warn = 0.65, 0.80\n",
    "    df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                    np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "    save_df(df[['NEXUS','alert']], \"gdren_m0_nexus_alerts\")\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = run_m0()\n",
    "    print(out[['NEXUS','alert']].tail(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99fb8c57-0968-46cc-8f35-ba0d22683ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-210655Z\\\\gdren_m0_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-210655Z\\\\gdren_m0_nexus_alerts.csv\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-210655Z\\\\meta.json\"\n",
      "}\n",
      "Thresholds → WATCH>=0.000 | WARNING>=1.000\n",
      "      NEXUS  alert\n",
      "3988    0.0  WATCH\n",
      "3989    0.0  WATCH\n",
      "3990    0.0  WATCH\n",
      "3991    0.0  WATCH\n",
      "3992    0.0  WATCH\n",
      "3993    0.0  WATCH\n",
      "3994    0.0  WATCH\n",
      "3995    0.0  WATCH\n",
      "3996    0.0  WATCH\n",
      "3997    0.0  WATCH\n",
      "3998    0.0  WATCH\n",
      "3999    0.0  WATCH\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.1.1: Milestone-0 bootstrap (stabilized & non-flat) ===\n",
    "import os, json, math, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.signal import welch, coherence\n",
    "from sklearn.isotonic import IsotonicRegression\n",
    "\n",
    "# --- Paths ---\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "for p in [ROOT, RUN]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "# --- Utilities ---\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float)\n",
    "    out = np.full_like(x, np.nan, dtype=float)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]\n",
    "        out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def phase_echo(x, max_lag=60):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    x = (x - x.mean())/(x.std()+1e-9)\n",
    "    vals = []\n",
    "    for tau in range(1, max_lag+1):\n",
    "        a = x[tau:].values\n",
    "        b = x.shift(tau).dropna().values\n",
    "        if len(a)!=len(b) or len(a)<16: vals.append(np.nan); continue\n",
    "        r = np.corrcoef(a, b)[0,1]\n",
    "        vals.append(r)\n",
    "    vals = np.array(vals, float)\n",
    "    return np.nanmax(vals)\n",
    "\n",
    "def theta_breaches(sig, q=0.98, win=256):\n",
    "    sig = pd.Series(sig, dtype=float)\n",
    "    thr = sig.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (sig > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    if not np.any(band): return np.nan\n",
    "    return float(np.nanmean(Cxy[band]))\n",
    "\n",
    "def zscore_series(x, win=512):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    return ((x - x.rolling(win, min_periods=64).mean())\n",
    "            /(x.rolling(win, min_periods=64).std()+1e-9)).values\n",
    "\n",
    "def normalize01(s):\n",
    "    q10, q90 = np.nanquantile(s, 0.10), np.nanquantile(s, 0.90)\n",
    "    return np.clip((s - q10) / (q90 - q10 + 1e-9), 0, 1)\n",
    "\n",
    "def fuse_to_nexus(features: pd.DataFrame, target: pd.Series):\n",
    "    F = features.copy()\n",
    "    F = F.ffill().bfill().fillna(0.0)   # ← no deprecation\n",
    "    for c in F.columns:\n",
    "        F[c] = normalize01(F[c].values)\n",
    "    raw = 0.35*F['S_d'] + 0.25*F['Echo'] + 0.2*F['Theta'] + 0.2*F['Gamma']\n",
    "    # Stronger target: future realized volatility (proxy for instability)\n",
    "    y = pd.Series(target, index=F.index).astype(float).values\n",
    "    ir = IsotonicRegression(out_of_bounds='clip')\n",
    "    nx = ir.fit_transform(raw.values, y)\n",
    "    nx = pd.Series(nx, index=F.index, dtype=float)\n",
    "    # rolling min-max to smooth scale\n",
    "    nxn = (nx - nx.rolling(256, min_periods=64).min()) / (\n",
    "           nx.rolling(256, min_periods=64).max() - nx.rolling(256, min_periods=64).min() + 1e-9)\n",
    "    return nxn.clip(0,1)\n",
    "\n",
    "# --- Synthetic criticality (with rising variance near criticality) ---\n",
    "def synthetic_criticality(T=4000, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    t = np.linspace(0, 1, T)\n",
    "    base = np.cumsum(rng.normal(0, 0.02, T))\n",
    "    drift = 0.6*np.tanh(3*(t-0.65))                  # slow regime drift\n",
    "    sigma = 0.12 + 0.35/(1+np.exp(-12*(t-0.72)))     # variance ramps up\n",
    "    shock = (t > 0.86)*rng.normal(0, 2.0, T)         # terminal rupture\n",
    "    x = base + drift + sigma*rng.normal(0,1,T) + shock\n",
    "    return pd.Series(x)\n",
    "\n",
    "def future_volatility(sig: pd.Series, horizon=24):\n",
    "    r = sig.diff()\n",
    "    vol = r.rolling(horizon).std().shift(-horizon//2)\n",
    "    return vol.ffill().bfill()\n",
    "\n",
    "def run_m0():\n",
    "    sig = synthetic_criticality()\n",
    "    df = pd.DataFrame(index=pd.RangeIndex(len(sig)))\n",
    "    df['signal'] = sig.values\n",
    "    df['S_d']   = rolling_entropy(df['signal'], win=256, bins=48)\n",
    "    df['Echo']  = pd.Series(np.nan, index=df.index, dtype=float)\n",
    "    for i in range(len(df)):\n",
    "        if i<300: continue\n",
    "        df.loc[i,'Echo'] = phase_echo(df['signal'].iloc[:i].values, max_lag=48)\n",
    "    df['Theta'] = theta_breaches(zscore_series(df['signal']), q=0.985, win=256)\n",
    "    df['Gamma'] = pd.Series(np.nan, index=df.index, dtype=float)\n",
    "    delayed = df['signal'].shift(3).bfill().values   # ← no deprecation\n",
    "    for i in range(300, len(df)):\n",
    "        a = df['signal'].iloc[max(0,i-512):i].values\n",
    "        b = delayed[max(0,i-512):i]\n",
    "        df.loc[i,'Gamma'] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "    # target for isotonic: future realized volatility\n",
    "    df['y_future_vol'] = future_volatility(pd.Series(df['signal']), horizon=24)\n",
    "\n",
    "    feats = df[['S_d','Echo','Theta','Gamma']]\n",
    "    df['NEXUS'] = fuse_to_nexus(feats, df['y_future_vol'])\n",
    "\n",
    "    # Data-driven thresholds\n",
    "    nx_train = df['NEXUS'].iloc[300:-300].dropna()\n",
    "    thr_watch = float(nx_train.quantile(0.75))\n",
    "    thr_warn  = float(nx_train.quantile(0.90))\n",
    "    df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                    np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "    paths = {\n",
    "        \"features_csv\": save_df(df, \"gdren_m0_features\"),\n",
    "        \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_m0_nexus_alerts\"),\n",
    "        \"meta_json\": str(RUN / \"meta.json\")\n",
    "    }\n",
    "    (RUN / \"meta.json\").write_text(json.dumps({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"root\": str(ROOT), \"cnt_lab_dir\": str(CNT),\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"Milestone-0 synthetic + sturdy calibration (future volatility).\"\n",
    "    }, indent=2))\n",
    "    print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "    print(\"Thresholds → WATCH>=%.3f | WARNING>=%.3f\" % (thr_watch, thr_warn))\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = run_m0()\n",
    "    print(out[['NEXUS','alert']].tail(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd068c2-7c04-4d95-9964-7170ff535622",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-211340Z\\\\gdren_m0_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-211340Z\\\\gdren_m0_nexus_alerts.csv\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-211340Z\\\\meta.json\"\n",
      "}\n",
      "Thresholds → WATCH>=0.686 | WARNING>=0.905\n",
      "min     0.032656\n",
      "mean    0.488264\n",
      "50%     0.471149\n",
      "max     0.961931\n",
      "Name: NEXUS, dtype: float64\n",
      "         NEXUS  alert\n",
      "3988  0.862075  WATCH\n",
      "3989  0.859618  WATCH\n",
      "3990  0.856996  WATCH\n",
      "3991  0.853494  WATCH\n",
      "3992  0.849678  WATCH\n",
      "3993  0.845620  WATCH\n",
      "3994  0.841385  WATCH\n",
      "3995  0.839024  WATCH\n",
      "3996  0.837697  WATCH\n",
      "3997  0.836471  WATCH\n",
      "3998  0.835043  WATCH\n",
      "3999  0.834079  WATCH\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.1.2: robust fusion (no isotonic), early-warning features on ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from scipy.signal import coherence, welch\n",
    "from scipy.stats import percentileofscore\n",
    "\n",
    "# --- Paths ---\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "for p in [ROOT, RUN]: p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "# --- Utilities ---\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float)\n",
    "    out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]\n",
    "        out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def phase_echo(x, max_lag=60):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    x = (x - x.mean())/(x.std()+1e-9)\n",
    "    vals = []\n",
    "    for tau in range(1, max_lag+1):\n",
    "        a = x[tau:].values\n",
    "        b = x.shift(tau).dropna().values\n",
    "        if len(a)!=len(b) or len(a)<16:\n",
    "            vals.append(np.nan); continue\n",
    "        vals.append(np.corrcoef(a, b)[0,1])\n",
    "    return np.nanmax(vals)\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    return float(np.nanmean(Cxy[band])) if np.any(band) else np.nan\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    x = pd.Series(x, dtype=float)\n",
    "    out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x.iloc[i-win+1:i+1].values\n",
    "        sw = w.std()\n",
    "        out[i] = 0.0 if sw<1e-9 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def rolling_var(x, win=256):\n",
    "    return pd.Series(x, dtype=float).rolling(win, min_periods=win//2).var(ddof=1).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def zscore_series(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    mu = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-mu).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - mu)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def rolling_percent_rank(s, win=512):\n",
    "    s = pd.Series(s, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        return percentileofscore(w, v, kind='mean')/100.0\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(features: pd.DataFrame):\n",
    "    F = features.copy().ffill().bfill().fillna(0.0)\n",
    "    # robust z per feature (median/MAD over a rolling window)\n",
    "    for c in F.columns:\n",
    "        mu  = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-mu).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-mu)/(1.4826*mad + 1e-9)\n",
    "\n",
    "    # Weighted early-warning score (critical slowing down + dispersion + echoes)\n",
    "    score = (0.26*F['S_d'] + 0.18*F['Echo'] + 0.16*F['Theta'] +\n",
    "             0.28*F['AR1'] + 0.12*F['Gamma'])\n",
    "\n",
    "    # Turn score into a stable 0..1 index via rolling percentile rank, then smooth\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512))\n",
    "    nx = nx.ewm(span=64, min_periods=16).mean()\n",
    "    return nx.clip(0,1)\n",
    "\n",
    "# --- Synthetic criticality with variance ramp + late rupture ---\n",
    "def synthetic_criticality(T=4000, seed=7):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    t = np.linspace(0, 1, T)\n",
    "    base = np.cumsum(rng.normal(0, 0.02, T))\n",
    "    drift = 0.6*np.tanh(3*(t-0.65))\n",
    "    sigma = 0.12 + 0.35/(1+np.exp(-12*(t-0.72)))\n",
    "    shock = (t > 0.86)*rng.normal(0, 2.0, T)\n",
    "    x = base + drift + sigma*rng.normal(0,1,T) + shock\n",
    "    return pd.Series(x)\n",
    "\n",
    "def run_m0():\n",
    "    sig = synthetic_criticality()\n",
    "    df = pd.DataFrame(index=pd.RangeIndex(len(sig)))\n",
    "    df['signal'] = sig.values\n",
    "\n",
    "    # CNT features\n",
    "    df['S_d']   = rolling_entropy(df['signal'], win=256, bins=48)\n",
    "    df['Echo']  = np.nan\n",
    "    for i in range(len(df)):\n",
    "        if i<300: continue\n",
    "        df.loc[i,'Echo'] = phase_echo(df['signal'].iloc[:i].values, max_lag=48)\n",
    "    df['AR1']   = rolling_ar1(df['signal'], win=256)\n",
    "    df['VAR']   = rolling_var(df['signal'], win=256)\n",
    "    df['Theta'] = theta_breaches(zscore_series(df['signal']), q=0.985, win=256)\n",
    "\n",
    "    # Gamma via delayed coherence as a placeholder hetero-channel coupling\n",
    "    df['Gamma'] = np.nan\n",
    "    delayed = df['signal'].shift(3).bfill().values\n",
    "    for i in range(300, len(df)):\n",
    "        a = df['signal'].iloc[max(0,i-512):i].values\n",
    "        b = delayed[max(0,i-512):i]\n",
    "        df.loc[i,'Gamma'] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "    # Fuse → NEXUS\n",
    "    feats = df[['S_d','Echo','Theta','AR1','Gamma']]\n",
    "    df['NEXUS'] = fuse_to_nexus(feats)\n",
    "\n",
    "    # Thresholds from central training slice (no edges)\n",
    "    nx_train = df['NEXUS'].iloc[300:-300].dropna()\n",
    "    thr_watch = float(nx_train.quantile(0.75))\n",
    "    thr_warn  = float(nx_train.quantile(0.90))\n",
    "    df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                    np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "    paths = {\n",
    "        \"features_csv\": save_df(df, \"gdren_m0_features\"),\n",
    "        \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_m0_nexus_alerts\"),\n",
    "        \"meta_json\": str(RUN / \"meta.json\")\n",
    "    }\n",
    "    (RUN / \"meta.json\").write_text(json.dumps({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"root\": str(ROOT), \"cnt_lab_dir\": str(CNT),\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"v0.1.2 — robust percentile fusion; AR1+VAR+S_d+Echo+Theta\"\n",
    "    }, indent=2))\n",
    "    print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "    print(\"Thresholds → WATCH>=%.3f | WARNING>=%.3f\" % (thr_watch, thr_warn))\n",
    "    print(df['NEXUS'].describe()[['min','mean','50%','max']])\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    out = run_m0()\n",
    "    print(out[['NEXUS','alert']].tail(12))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4ad9570-aeab-431d-b5d3-31b35d83fb9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing yfinance …\n",
      "[setup] installing meteostat …\n",
      "[setup] installing scikit-learn …\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'WindowsPath' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m CNT = Path(os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mCNT_LAB_DIR\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mE:/CNT\u001b[39m\u001b[33m\"\u001b[39m)).resolve()\n\u001b[32m     35\u001b[39m ROOT = CNT / \u001b[33m\"\u001b[39m\u001b[33martifacts\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33mg_dren\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m RUN = \u001b[43mROOT\u001b[49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstrftime\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mY\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mm\u001b[39;49m\u001b[38;5;132;43;01m%d\u001b[39;49;00m\u001b[33;43m-\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mH\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mM\u001b[39;49m\u001b[33;43m%\u001b[39;49m\u001b[33;43mSZ\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgmtime\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m_v02\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     37\u001b[39m RUN.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     39\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msave_df\u001b[39m(df, name):\n",
      "\u001b[31mTypeError\u001b[39m: unsupported operand type(s) for +: 'WindowsPath' and 'str'"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2: Real feeds + skill metrics (SPY + local temperature) ===\n",
    "import os, json, time, math, sys, subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "def need(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        return False\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve\n",
    "\n",
    "# --- Config ---\n",
    "LAT, LON = 40.7128, -74.0060     # <— change this to your location if you like\n",
    "START, END = \"2005-01-01\", None  # None → today\n",
    "FREQ = \"D\"\n",
    "LOOKAHEAD_D = 10                  # window within which an \"event\" must occur after an alert\n",
    "EVENT_KSIGMA = 2.0               # event = |Δprice| > K * rolling σ (21d)\n",
    "\n",
    "# --- Paths ---\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) + \"_v02\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"\n",
    "    fp.write_text(json.dumps(obj, indent=2))\n",
    "    return str(fp)\n",
    "\n",
    "# --- Util blocks (same spirit as v0.1.2) ---\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = w.std()\n",
    "        out[i] = 0.0 if sw<1e-9 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def rolling_var(x, win=256):\n",
    "    return pd.Series(x, dtype=float).rolling(win, min_periods=win//2).var(ddof=1).values\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    mu  = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-mu).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - mu)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    return float(np.nanmean(Cxy[band])) if np.any(band) else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        return (np.searchsorted(np.sort(w), v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    # robust per-feature normalize (median/MAD)\n",
    "    for c in F.columns:\n",
    "        mu  = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-mu).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-mu)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F['S_d_mkt'] + 0.20*F['AR1_mkt'] + 0.10*F['Theta_mkt'] +\n",
    "             0.18*F['S_d_tmp'] + 0.14*F['AR1_tmp'] + 0.06*F['Theta_tmp'] +\n",
    "             0.08*F['Gamma'])\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# --- Data: SPY & local temperature anomaly ---\n",
    "def get_market():\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", start=START, end=END, interval=FREQ, progress=False)\n",
    "        px = s['Adj Close'].rename(\"px\").dropna()\n",
    "        return px\n",
    "    except Exception as e:\n",
    "        print(\"[warn] market download failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        loc = Point(lat, lon)\n",
    "        df = Daily(loc, START, END).fetch().rename(columns={\"tavg\":\"t\"})\n",
    "        # anomaly vs 31d rolling median\n",
    "        t = df['t'].astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return anom\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# align to common daily index\n",
    "idx = px.index if len(px)>0 else ta.index\n",
    "if len(px)>0 and len(ta)>0:\n",
    "    idx = px.index.union(ta.index)\n",
    "df = pd.DataFrame(index=pd.DatetimeIndex(idx)).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# basic returns for events\n",
    "if 'px' in df:\n",
    "    df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# --- Features per stream ---\n",
    "# market\n",
    "if 'px' in df:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    for c in ['S_d_mkt','AR1_mkt','Theta_mkt']:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# temperature\n",
    "if 'temp_anom' in df:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    for c in ['S_d_tmp','AR1_tmp','Theta_tmp']:\n",
    "        df[c] = np.nan\n",
    "\n",
    "# hetero-coupling (coherence of mkt returns vs temp anomaly)\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df and 'temp_anom' in df:\n",
    "    for i in range(400, len(df)):\n",
    "        a = df['ret'].iloc[i-400:i].values\n",
    "        b = df['temp_anom'].iloc[i-400:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# --- Fuse → NEXUS + thresholds ---\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "# --- Event labeling (market) & skill metrics ---\n",
    "metrics = {}\n",
    "if 'ret' in df:\n",
    "    # Event definition: big absolute move relative to recent volatility\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    events = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int)\n",
    "    events = events.shift(-1).fillna(0).astype(int)  # event realized next day\n",
    "    y = events.reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # Binary scores from NEXUS (direct), PR-AUC\n",
    "    nx = df['NEXUS'].fillna(0.0)\n",
    "    if y.sum() > 0:\n",
    "        auc_pr = float(average_precision_score(y.values, nx.values))\n",
    "    else:\n",
    "        auc_pr = float('nan')\n",
    "\n",
    "    # Lead-time & false alarms from thresholded WARNING\n",
    "    warn = (df['alert']==\"WARNING\").astype(int)\n",
    "    # identify warning starts\n",
    "    starts = (warn.diff().fillna(0) == 1)\n",
    "    event_ix = np.where(y.values==1)[0]\n",
    "    start_ix = np.where(starts.values)[0]\n",
    "\n",
    "    lead_days = []\n",
    "    hits = 0\n",
    "    for s in start_ix:\n",
    "        # did an event occur within LOOKAHEAD_D?\n",
    "        window = range(s, min(s+LOOKAHEAD_D+1, len(df)))\n",
    "        if any(y.values[w]==1 for w in window):\n",
    "            hits += 1\n",
    "            # lead time = distance from start to next event\n",
    "            next_event = next((w for w in window if y.values[w]==1), None)\n",
    "            if next_event is not None:\n",
    "                lead_days.append(int(next_event - s))\n",
    "\n",
    "    # false alarms = warnings with no event within horizon; per year\n",
    "    false_alarms = int(len(start_ix) - hits)\n",
    "    years = max(1, (df.index[-1]-df.index[0]).days/365.25)\n",
    "    fa_per_year = float(false_alarms / years)\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": years,\n",
    "        \"events_total\": int(y.sum()),\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"warnings\": int(warn.sum()),\n",
    "        \"warning_starts\": int(len(start_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": fa_per_year,\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],  # truncate for meta\n",
    "    }\n",
    "\n",
    "# --- Persist artifacts ---\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_v02_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\n",
    "            \"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "            \"lookahead_days\": LOOKAHEAD_D, \"event_ksigma\": EVENT_KSIGMA\n",
    "        },\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"Real-data v0.2 (SPY + local temperature anomaly).\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2 SKILL (market events) ===\")\n",
    "    for k,v in metrics.items(): print(f\"{k:>24}: {v}\")\n",
    "else:\n",
    "    print(\"\\n[info] No market series available; metrics skipped.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0179cb52-257e-470c-a2e6-b5efb8e8d23e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "[warn] market download failed: 'str' object is not callable\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Cannot load daily/2005/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2006/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2007/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2008/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2009/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2010/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2011/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2012/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2013/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2014/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2015/KJRB0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2011/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2012/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2013/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2014/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2015/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2016/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2017/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2018/KNYC0.csv.gz from https://data.meteostat.net/\n",
      "Warning: Cannot load daily/2019/KNYC0.csv.gz from https://data.meteostat.net/\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-213542Z_v02\\\\gdren_v02_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-213542Z_v02\\\\gdren_v02_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-213542Z_v02\\\\gdren_v02_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-213542Z_v02\\\\meta.json\"\n",
      "}\n",
      "\n",
      "[info] Metrics skipped (no market series).\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2 (single cell): SPY + local temperature, thresholds + skill metrics ===\n",
    "import os, json, time, sys, subprocess, math\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----- lightweight bootstrap for needed libs -----\n",
    "def need(pkg):\n",
    "    try:\n",
    "        __import__(pkg)\n",
    "        return False\n",
    "    except Exception:\n",
    "        return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ----- config -----\n",
    "LAT, LON = 40.7128, -74.0060            # set your city if you wish\n",
    "START, END = \"2005-01-01\", None          # None → today\n",
    "LOOKAHEAD_D = 10                         # days after WARNING to count a hit\n",
    "EVENT_KSIGMA = 2.0                       # event = |Δ| > K * rolling σ\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"\n",
    "    fp.write_text(json.dumps(obj, indent=2))\n",
    "    return str(fp)\n",
    "\n",
    "# ----- CNT feature utils -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = w.std()\n",
    "        out[i] = 0.0 if sw<1e-9 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def rolling_var(x, win=256):\n",
    "    return pd.Series(x, dtype=float).rolling(win, min_periods=win//2).var(ddof=1).values\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    return float(np.nanmean(Cxy[band])) if np.any(band) else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        return (np.searchsorted(np.sort(w), v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F.get('S_d_mkt',0) + 0.20*F.get('AR1_mkt',0) + 0.10*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_tmp',0) + 0.14*F.get('AR1_tmp',0) + 0.06*F.get('Theta_tmp',0) +\n",
    "             0.08*F.get('Gamma',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders -----\n",
    "def get_market():\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", start=START, end=None, interval=\"1d\", progress=False, auto_adjust=True)\n",
    "        px = s['Close'].rename(\"px\").dropna()\n",
    "        return px\n",
    "    except Exception as e:\n",
    "        print(\"[warn] market download failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon)\n",
    "        d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        if 'tavg' in d.columns and d['tavg'].notna().any():\n",
    "            t = d['tavg'].astype(float)\n",
    "        else:\n",
    "            t = ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return anom\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & build frame -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "if len(px)>0: idx = px.index\n",
    "if len(ta)>0: idx = ta.index if idx.empty else idx.union(ta.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "if 'px' in df.columns:\n",
    "    df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# ----- features (market) -----\n",
    "if 'px' in df.columns:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt'] = df['AR1_mkt'] = df['Theta_mkt'] = np.nan\n",
    "\n",
    "# ----- features (temperature) -----\n",
    "if 'temp_anom' in df.columns:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp'] = df['AR1_tmp'] = df['Theta_tmp'] = np.nan\n",
    "\n",
    "# ----- hetero-coupling -----\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df.columns and 'temp_anom' in df.columns:\n",
    "    for i in range(400, len(df)):\n",
    "        a = df['ret'].iloc[i-400:i].values\n",
    "        b = df['temp_anom'].iloc[i-400:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "# ----- label events & compute skill (market only) -----\n",
    "metrics = {}\n",
    "if 'ret' in df.columns:\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    events = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int).shift(-1).fillna(0).astype(int)\n",
    "    y = events.reindex(df.index).fillna(0).astype(int)\n",
    "    nx = df['NEXUS'].fillna(0.0)\n",
    "    auc_pr = float(average_precision_score(y.values, nx.values)) if y.sum() > 0 else float('nan')\n",
    "    warn_mask = (df['alert']==\"WARNING\").astype(int)\n",
    "    starts = (warn_mask.diff().fillna(0) == 1)\n",
    "    event_ix = np.where(y.values==1)[0]\n",
    "    start_ix = np.where(starts.values)[0]\n",
    "    hits, lead_days = 0, []\n",
    "    for s in start_ix:\n",
    "        window = range(s, min(s+LOOKAHEAD_D+1, len(df)))\n",
    "        if any(y.values[w]==1 for w in window):\n",
    "            hits += 1\n",
    "            ne = next((w for w in window if y.values[w]==1), None)\n",
    "            if ne is not None: lead_days.append(int(ne - s))\n",
    "    false_alarms = int(len(start_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_total\": int(y.sum()),\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"warning_days\": int(warn_mask.sum()),\n",
    "        \"warning_starts\": int(len(start_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms / years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_v02_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D, \"event_ksigma\": EVENT_KSIGMA},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"Real-data v0.2 (SPY + local temperature anomaly).\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2 SKILL (market events) ===\")\n",
    "    for k,v in metrics.items(): print(f\"{k:>24}: {v}\")\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a592ea1e-8453-4c64-a13c-abe6f6c650c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot compare tz-naive and tz-aware timestamps",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 156\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(px)>\u001b[32m0\u001b[39m: idx = px.index\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ta)>\u001b[32m0\u001b[39m: idx = ta.index \u001b[38;5;28;01mif\u001b[39;00m idx.empty \u001b[38;5;28;01melse\u001b[39;00m idx.union(ta.index)\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m=\u001b[49m\u001b[43midx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(px)>\u001b[32m0\u001b[39m: df[\u001b[33m'\u001b[39m\u001b[33mpx\u001b[39m\u001b[33m'\u001b[39m] = px.reindex(df.index).ffill()\n\u001b[32m    158\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(ta)>\u001b[32m0\u001b[39m: df[\u001b[33m'\u001b[39m\u001b[33mtemp_anom\u001b[39m\u001b[33m'\u001b[39m] = ta.reindex(df.index).interpolate(limit=\u001b[32m7\u001b[39m).ffill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:7401\u001b[39m, in \u001b[36mDataFrame.sort_index\u001b[39m\u001b[34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[39m\n\u001b[32m   7304\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msort_index\u001b[39m(\n\u001b[32m   7305\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   7306\u001b[39m     *,\n\u001b[32m   (...)\u001b[39m\u001b[32m   7315\u001b[39m     key: IndexKeyFunc | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   7316\u001b[39m ) -> DataFrame | \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   7317\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   7318\u001b[39m \u001b[33;03m    Sort object by labels (along an axis).\u001b[39;00m\n\u001b[32m   7319\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m   7399\u001b[39m \u001b[33;03m    d  4\u001b[39;00m\n\u001b[32m   7400\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m7401\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msort_index\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7402\u001b[39m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7403\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7404\u001b[39m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7405\u001b[39m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7406\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7407\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7408\u001b[39m \u001b[43m        \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7409\u001b[39m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m=\u001b[49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7410\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   7411\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5331\u001b[39m, in \u001b[36mNDFrame.sort_index\u001b[39m\u001b[34m(self, axis, level, ascending, inplace, kind, na_position, sort_remaining, ignore_index, key)\u001b[39m\n\u001b[32m   5327\u001b[39m ascending = validate_ascending(ascending)\n\u001b[32m   5329\u001b[39m target = \u001b[38;5;28mself\u001b[39m._get_axis(axis)\n\u001b[32m-> \u001b[39m\u001b[32m5331\u001b[39m indexer = \u001b[43mget_indexer_indexer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   5332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_remaining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\n\u001b[32m   5333\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   5335\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m indexer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   5336\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m inplace:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\sorting.py:113\u001b[39m, in \u001b[36mget_indexer_indexer\u001b[39m\u001b[34m(target, level, ascending, kind, na_position, sort_remaining, key)\u001b[39m\n\u001b[32m    108\u001b[39m     indexer = lexsort_indexer(\n\u001b[32m    109\u001b[39m         codes, orders=ascending, na_position=na_position, codes_given=\u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    110\u001b[39m     )\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    112\u001b[39m     \u001b[38;5;66;03m# ascending can only be a Sequence for MultiIndex\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m113\u001b[39m     indexer = \u001b[43mnargsort\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    114\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    115\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    116\u001b[39m \u001b[43m        \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mascending\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    117\u001b[39m \u001b[43m        \u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m=\u001b[49m\u001b[43mna_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    118\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m indexer\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\sorting.py:439\u001b[39m, in \u001b[36mnargsort\u001b[39m\u001b[34m(items, kind, ascending, na_position, key, mask)\u001b[39m\n\u001b[32m    437\u001b[39m     non_nans = non_nans[::-\u001b[32m1\u001b[39m]\n\u001b[32m    438\u001b[39m     non_nan_idx = non_nan_idx[::-\u001b[32m1\u001b[39m]\n\u001b[32m--> \u001b[39m\u001b[32m439\u001b[39m indexer = non_nan_idx[\u001b[43mnon_nans\u001b[49m\u001b[43m.\u001b[49m\u001b[43margsort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkind\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[32m    440\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ascending:\n\u001b[32m    441\u001b[39m     indexer = indexer[::-\u001b[32m1\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/tslibs/timestamps.pyx:387\u001b[39m, in \u001b[36mpandas._libs.tslibs.timestamps._Timestamp.__richcmp__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: Cannot compare tz-naive and tz-aware timestamps"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2a (single cell) — robust SPY fetch + temp fallback + thresholds + skill ===\n",
    "import os, json, time, sys, subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----- lightweight bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ----- config -----\n",
    "LAT, LON = 40.7128, -74.0060          # set your lat/lon if you want\n",
    "START, END = \"2005-01-01\", None       # None → today\n",
    "LOOKAHEAD_D = 10                      # days after WARNING counted as a hit\n",
    "EVENT_KSIGMA = 2.0                    # event = |Δ| > K * rolling σ\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02a\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"\n",
    "    fp.write_text(json.dumps(obj, indent=2))\n",
    "    return str(fp)\n",
    "\n",
    "# ----- CNT feature utils -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = w.std()\n",
    "        out[i] = 0.0 if sw<1e-9 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    return float(np.nanmean(Cxy[band])) if np.any(band) else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        return (np.searchsorted(np.sort(w), v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F.get('S_d_mkt',0) + 0.20*F.get('AR1_mkt',0) + 0.10*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_tmp',0) + 0.14*F.get('AR1_tmp',0) + 0.06*F.get('Theta_tmp',0) +\n",
    "             0.08*F.get('Gamma',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders (robust) -----\n",
    "def get_market():\n",
    "    # Try 1: Ticker.history (most resilient)\n",
    "    try:\n",
    "        h = yf.Ticker(\"SPY\").history(period=\"max\", auto_adjust=True)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h.columns and len(h)>0:\n",
    "            px = h['Close'].rename(\"px\").dropna()\n",
    "            if len(px): return px\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance Ticker.history failed:\", e)\n",
    "    # Try 2: download(period=\"max\")\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", period=\"max\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s.columns and len(s)>0:\n",
    "            px = s['Close'].rename(\"px\").dropna()\n",
    "            if len(px): return px\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance download failed:\", e)\n",
    "    # Try 3: Stooq fallback (no API key, plain CSV)\n",
    "    try:\n",
    "        url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "        stq = pd.read_csv(url)\n",
    "        stq.columns = [c.lower() for c in stq.columns]\n",
    "        stq['date'] = pd.to_datetime(stq['date'])\n",
    "        stq = stq.set_index('date').sort_index()\n",
    "        px = stq['close'].rename('px').astype(float)\n",
    "        print(\"[info] Using Stooq fallback for SPY.\")\n",
    "        return px\n",
    "    except Exception as e:\n",
    "        print(\"[error] stooq fallback failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon)\n",
    "        d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        if 'tavg' in d.columns and d['tavg'].notna().any():\n",
    "            t = d['tavg'].astype(float)\n",
    "        else:\n",
    "            t = ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return anom\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & frame -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "if len(px)>0: idx = px.index\n",
    "if len(ta)>0: idx = ta.index if idx.empty else idx.union(ta.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "if 'px' in df.columns: df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# ----- features -----\n",
    "if 'px' in df.columns:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt'] = df['AR1_mkt'] = df['Theta_mkt'] = np.nan\n",
    "\n",
    "if 'temp_anom' in df.columns:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp'] = df['AR1_tmp'] = df['Theta_tmp'] = np.nan\n",
    "\n",
    "# hetero-coupling\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df.columns and 'temp_anom' in df.columns:\n",
    "    for i in range(400, len(df)):\n",
    "        a = df['ret'].iloc[i-400:i].values\n",
    "        b = df['temp_anom'].iloc[i-400:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "# ----- events & skill (market only) -----\n",
    "metrics = {}\n",
    "if 'ret' in df.columns and df['ret'].notna().any():\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    events = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int).shift(-1).fillna(0).astype(int)\n",
    "    y = events.reindex(df.index).fillna(0).astype(int)\n",
    "    nx = df['NEXUS'].fillna(0.0)\n",
    "    auc_pr = float(average_precision_score(y.values, nx.values)) if y.sum() > 0 else float('nan')\n",
    "    warn_mask = (df['alert']==\"WARNING\").astype(int)\n",
    "    starts = (warn_mask.diff().fillna(0) == 1)\n",
    "    start_ix = np.where(starts.values)[0]\n",
    "    hits, lead_days = 0, []\n",
    "    for s in start_ix:\n",
    "        window = range(s, min(s+LOOKAHEAD_D+1, len(df)))\n",
    "        if any(y.values[w]==1 for w in window):\n",
    "            hits += 1\n",
    "            ne = next((w for w in window if y.values[w]==1), None)\n",
    "            if ne is not None: lead_days.append(int(ne - s))\n",
    "    false_alarms = int(len(start_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_total\": int(y.sum()),\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"warning_days\": int(warn_mask.sum()),\n",
    "        \"warning_starts\": int(len(start_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms / years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02a_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_v02a_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02a_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D, \"event_ksigma\": EVENT_KSIGMA},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"Real-data v0.2a (robust SPY fetch + Meteostat fallback).\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2a SKILL (market events) ===\")\n",
    "    for k,v in metrics.items(): print(f\"{k:>24}: {v}\")\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d364b3d9-70cb-416e-bab6-74185a2f5002",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "RuntimeWarning: invalid value encountered in divide\n",
      "RuntimeWarning: invalid value encountered in divide\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n",
      "RuntimeWarning: Mean of empty slice\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-214614Z_v02b\\\\gdren_v02b_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-214614Z_v02b\\\\gdren_v02b_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-214614Z_v02b\\\\gdren_v02b_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-214614Z_v02b\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2b SKILL (market events) ===\n",
      "                 samples: 10615\n",
      "                   years: 32.766598220396986\n",
      "            events_total: 712\n",
      "                  auc_pr: 0.0663486089959487\n",
      "         watch_threshold: 0.7535573991041762\n",
      "       warning_threshold: 0.8935674198565323\n",
      "            warning_days: 986\n",
      "          warning_starts: 14\n",
      "        hits_within_days: 10\n",
      "                    hits: 11\n",
      "            false_alarms: 3\n",
      "   false_alarms_per_year: 0.09155665106951873\n",
      "   lead_time_days_median: 7.0\n",
      "     lead_time_days_mean: 5.909090909090909\n",
      "      lead_time_days_all: [3, 5, 6, 9, 1, 8, 10, 8, 0, 7, 8]\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2b (single cell) — tz-safe index + robust SPY fetch + temp fallback + skill ===\n",
    "import os, json, time, sys, subprocess\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----- lightweight bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ----- config -----\n",
    "LAT, LON = 40.7128, -74.0060          # change if you like\n",
    "START, END = \"2005-01-01\", None       # None → today\n",
    "LOOKAHEAD_D = 10                      # days after WARNING counted as a hit\n",
    "EVENT_KSIGMA = 2.0                    # event = |Δ| > K * rolling σ\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02b\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"\n",
    "    fp.write_text(json.dumps(obj, indent=2))\n",
    "    return str(fp)\n",
    "\n",
    "# ----- helpers -----\n",
    "def normalize_daily_index(idx):\n",
    "    \"\"\"Return tz-naive, normalized-to-midnight daily DatetimeIndex.\"\"\"\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None:\n",
    "        idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "\n",
    "def normalize_series_daily(s):\n",
    "    \"\"\"Apply normalize_daily_index to a Series index; return Series.\"\"\"\n",
    "    if s is None or len(s) == 0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy())\n",
    "    s.index = normalize_daily_index(s.index)\n",
    "    # drop duplicates after normalization by keeping last\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ----- CNT feature utils -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p))\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = w.std()\n",
    "        out[i] = 0.0 if sw<1e-9 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 256: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    return float(np.nanmean(Cxy[band])) if np.any(band) else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        return (np.searchsorted(np.sort(w), v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F.get('S_d_mkt',0) + 0.20*F.get('AR1_mkt',0) + 0.10*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_tmp',0) + 0.14*F.get('AR1_tmp',0) + 0.06*F.get('Theta_tmp',0) +\n",
    "             0.08*F.get('Gamma',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders (robust) -----\n",
    "def get_market():\n",
    "    # Try 1: Ticker.history\n",
    "    try:\n",
    "        h = yf.Ticker(\"SPY\").history(period=\"max\", auto_adjust=True)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h.columns and len(h)>0:\n",
    "            px = h['Close'].rename(\"px\").dropna()\n",
    "            return normalize_series_daily(px)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance Ticker.history failed:\", e)\n",
    "    # Try 2: download(period=\"max\")\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", period=\"max\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s.columns and len(s)>0:\n",
    "            px = s['Close'].rename(\"px\").dropna()\n",
    "            return normalize_series_daily(px)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance download failed:\", e)\n",
    "    # Try 3: Stooq fallback\n",
    "    try:\n",
    "        url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "        stq = pd.read_csv(url)\n",
    "        stq.columns = [c.lower() for c in stq.columns]\n",
    "        stq['date'] = pd.to_datetime(stq['date'])\n",
    "        stq = stq.set_index('date').sort_index()\n",
    "        px = stq['close'].rename('px').astype(float)\n",
    "        print(\"[info] Using Stooq fallback for SPY.\")\n",
    "        return normalize_series_daily(px)\n",
    "    except Exception as e:\n",
    "        print(\"[error] stooq fallback failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon)\n",
    "        d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        if 'tavg' in d.columns and d['tavg'].notna().any():\n",
    "            t = d['tavg'].astype(float)\n",
    "        else:\n",
    "            t = ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & frame (all indices now tz-naive daily) -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "if len(px)>0: idx = px.index\n",
    "if len(ta)>0: idx = ta.index if idx.empty else idx.union(ta.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "if 'px' in df.columns:\n",
    "    df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# ----- features -----\n",
    "if 'px' in df.columns:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt'] = df['AR1_mkt'] = df['Theta_mkt'] = np.nan\n",
    "\n",
    "if 'temp_anom' in df.columns:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp'] = df['AR1_tmp'] = df['Theta_tmp'] = np.nan\n",
    "\n",
    "# hetero-coupling\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df.columns and 'temp_anom' in df.columns:\n",
    "    for i in range(400, len(df)):\n",
    "        a = df['ret'].iloc[i-400:i].values\n",
    "        b = df['temp_anom'].iloc[i-400:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "df['alert'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "# ----- events & skill (market only) -----\n",
    "metrics = {}\n",
    "if 'ret' in df.columns and df['ret'].notna().any():\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    events = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int).shift(-1).fillna(0).astype(int)\n",
    "    y = events.reindex(df.index).fillna(0).astype(int)\n",
    "    nx = df['NEXUS'].fillna(0.0)\n",
    "    auc_pr = float(average_precision_score(y.values, nx.values)) if y.sum() > 0 else float('nan')\n",
    "    warn_mask = (df['alert']==\"WARNING\").astype(int)\n",
    "    starts = (warn_mask.diff().fillna(0) == 1)\n",
    "    start_ix = np.where(starts.values)[0]\n",
    "    hits, lead_days = 0, []\n",
    "    for s in start_ix:\n",
    "        window = range(s, min(s+LOOKAHEAD_D+1, len(df)))\n",
    "        if any(y.values[w]==1 for w in window):\n",
    "            hits += 1\n",
    "            ne = next((w for w in window if y.values[w]==1), None)\n",
    "            if ne is not None: lead_days.append(int(ne - s))\n",
    "    false_alarms = int(len(start_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_total\": int(y.sum()),\n",
    "        \"auc_pr\": auc_pr,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"warning_days\": int(warn_mask.sum()),\n",
    "        \"warning_starts\": int(len(start_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms / years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02b_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert']], \"gdren_v02b_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02b_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D, \"event_ksigma\": EVENT_KSIGMA},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"v0.2b — timezone-normalized daily index; robust SPY + Meteostat.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2b SKILL (market events) ===\")\n",
    "    for k,v in metrics.items(): print(f\"{k:>24}: {v}\")\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "99ae0756-11c9-4b53-9b27-0704a8dcc89e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-215632Z_v02c\\\\gdren_v02c_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-215632Z_v02c\\\\gdren_v02c_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-215632Z_v02c\\\\gdren_v02c_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-215632Z_v02c\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2c SKILL ===\n",
      "                     samples: 10615\n",
      "                       years: 32.766598220396986\n",
      "        events_nextday_total: 712\n",
      "         events_window_total: 5252\n",
      "              auc_pr_nextday: 0.0662339310716148\n",
      "             auc_pr_windowed: 0.4961180029348552\n",
      "             watch_threshold: 0.7447845042357616\n",
      "           warning_threshold: 0.8928629829113786\n",
      "                warning_days: 986\n",
      "              warning_starts: 14\n",
      "            hits_within_days: 10\n",
      "                        hits: 12\n",
      "                false_alarms: 2\n",
      "       false_alarms_per_year: 0.06103776737967915\n",
      "       lead_time_days_median: 0.0\n",
      "         lead_time_days_mean: 0.5833333333333334\n",
      "          lead_time_days_all: [0, 0, 0, 0, 0, 0, 2, 0, 5, 0, 0, 0]\n",
      "           coverage_windowed: 0.020182787509520184\n",
      "            warning_segments: 14\n",
      "  warning_segment_len_median: 67.5\n",
      "cooldown_applied_min_days_between_starts: 15\n",
      "        cooldown_starts_kept: 13\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2c (single cell) — robust features, windowed events, clearer skill ===\n",
    "import os, json, time, sys, subprocess, contextlib, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# --- quiet noisy numeric warnings from lower libs (we guard ourselves) ---\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ----- lightweight bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score, precision_recall_curve, auc\n",
    "\n",
    "# ----- config -----\n",
    "LAT, LON = 40.7128, -74.0060           # set to your location if you like\n",
    "START, END = \"2005-01-01\", None        # None → today\n",
    "LOOKAHEAD_D = 10                       # event horizon for early warning\n",
    "EVENT_KSIGMA = 2.0                     # base threshold scale (you can try 2.5–3.0)\n",
    "COUPLING_WIN = 400                     # samples for hetero-coupling window\n",
    "COOLDOWN_D = 15                        # minimal days between WARNING starts (reporting only)\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02c\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"\n",
    "    df.to_csv(fp, index=True)\n",
    "    return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"\n",
    "    fp.write_text(json.dumps(obj, indent=2))\n",
    "    return str(fp)\n",
    "\n",
    "# ----- time index helpers -----\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None:\n",
    "        idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s) == 0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy())\n",
    "    s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ----- CNT feature utils -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]\n",
    "        out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w)\n",
    "        out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    # robust coherence: guard constants/NaNs/empty bands\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 128: return np.nan\n",
    "    mask = np.isfinite(a) & np.isfinite(b)\n",
    "    a, b = a[mask], b[mask]\n",
    "    if len(a) < 128: return np.nan\n",
    "    a = a - np.mean(a); b = b - np.mean(b)\n",
    "    if np.std(a) < 1e-12 or np.std(b) < 1e-12: return np.nan\n",
    "    with np.errstate(all='ignore'):\n",
    "        f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25)\n",
    "    if not np.any(band): return np.nan\n",
    "    v = Cxy[band]\n",
    "    v = v[np.isfinite(v)]\n",
    "    return float(v.mean()) if v.size else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]\n",
    "        arr = np.sort(w)\n",
    "        return (np.searchsorted(arr, v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F.get('S_d_mkt',0) + 0.20*F.get('AR1_mkt',0) + 0.10*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_tmp',0) + 0.14*F.get('AR1_tmp',0) + 0.06*F.get('Theta_tmp',0) +\n",
    "             0.08*F.get('Gamma',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders (robust) -----\n",
    "def get_market():\n",
    "    try:\n",
    "        h = yf.Ticker(\"SPY\").history(period=\"max\", auto_adjust=True)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h.columns and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(\"px\").dropna())\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance Ticker.history failed:\", e)\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", period=\"max\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s.columns and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(\"px\").dropna())\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance download failed:\", e)\n",
    "    try:\n",
    "        url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "        stq = pd.read_csv(url)\n",
    "        stq.columns = [c.lower() for c in stq.columns]\n",
    "        stq['date'] = pd.to_datetime(stq['date'])\n",
    "        stq = stq.set_index('date').sort_index()\n",
    "        print(\"[info] Using Stooq fallback for SPY.\")\n",
    "        return normalize_series_daily(stq['close'].rename('px').astype(float))\n",
    "    except Exception as e:\n",
    "        print(\"[error] stooq fallback failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon)\n",
    "        d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        if 'tavg' in d.columns and d['tavg'].notna().any():\n",
    "            t = d['tavg'].astype(float)\n",
    "        else:\n",
    "            t = ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & frame -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "if len(px)>0: idx = px.index\n",
    "if len(ta)>0: idx = ta.index if idx.empty else idx.union(ta.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "if 'px' in df.columns: df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# ----- features -----\n",
    "if 'px' in df.columns:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt'] = df['AR1_mkt'] = df['Theta_mkt'] = np.nan\n",
    "\n",
    "if 'temp_anom' in df.columns:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp'] = df['AR1_tmp'] = df['Theta_tmp'] = np.nan\n",
    "\n",
    "# hetero-coupling (robust)\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df.columns and 'temp_anom' in df.columns:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['temp_anom'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "\n",
    "# base alert\n",
    "df['alert_raw'] = np.where(df['NEXUS']>=thr_warn, 'WARNING',\n",
    "                    np.where(df['NEXUS']>=thr_watch, 'WATCH','OK'))\n",
    "\n",
    "# optional: cooldown-summarized starts (reporting; does not rewrite NEXUS)\n",
    "starts_raw = (df['alert_raw'].eq(\"WARNING\") & ~df['alert_raw'].shift(1).eq(\"WARNING\"))\n",
    "start_ix = list(np.where(starts_raw.fillna(False).values)[0])\n",
    "kept = []\n",
    "last = -10**9\n",
    "for s in start_ix:\n",
    "    if s - last >= COOLDOWN_D:\n",
    "        kept.append(s)\n",
    "        last = s\n",
    "kept = np.array(kept, dtype=int)\n",
    "df['alert'] = df['alert_raw']  # for now keep raw state; we report cooldowned starts separately\n",
    "\n",
    "# ----- events & skill (two views) -----\n",
    "metrics = {}\n",
    "if 'ret' in df.columns and df['ret'].notna().any():\n",
    "    # (A) classic next-day spikes (for reference)\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    events_nextday = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int).shift(-1).fillna(0).astype(int)\n",
    "    yA = events_nextday.reindex(df.index).fillna(0).astype(int)\n",
    "    nx = df['NEXUS'].fillna(0.0)\n",
    "    auc_pr_A = float(average_precision_score(yA.values, nx.values)) if yA.sum() > 0 else float('nan')\n",
    "\n",
    "    # (B) windowed events: is there a K-sigma spike in the NEXT LOOKAHEAD_D days?\n",
    "    future_max = (df['ret'].abs()\n",
    "                  .rolling(LOOKAHEAD_D, min_periods=1).max()\n",
    "                  .shift(-(LOOKAHEAD_D-1)))\n",
    "    yB = (future_max > EVENT_KSIGMA*vol).astype(int).reindex(df.index).fillna(0).astype(int)\n",
    "    auc_pr_B = float(average_precision_score(yB.values, nx.values)) if yB.sum() > 0 else float('nan')\n",
    "\n",
    "    # WARNING starts & hits within horizon on yB\n",
    "    warn_mask = (df['alert']==\"WARNING\").astype(int)\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\"))\n",
    "    start_ix_all = np.where(starts.fillna(False).values)[0]\n",
    "    hits, lead_days = 0, []\n",
    "    for s in start_ix_all:\n",
    "        window = range(s, min(s+LOOKAHEAD_D+1, len(df)))\n",
    "        if any(yB.values[w]==1 for w in window):\n",
    "            hits += 1\n",
    "            ne = next((w for w in window if yB.values[w]==1), None)\n",
    "            if ne is not None: lead_days.append(int(ne - s))\n",
    "    false_alarms = int(len(start_ix_all) - hits)\n",
    "\n",
    "    # Coverage: what fraction of all windowed events had a WARNING start in the prior horizon?\n",
    "    ev_ix = np.where(yB.values==1)[0]\n",
    "    covered = 0\n",
    "    start_set = set(start_ix_all)\n",
    "    for e in ev_ix:\n",
    "        left = max(0, e-LOOKAHEAD_D)\n",
    "        if any((i in start_set) for i in range(left, e+1)): covered += 1\n",
    "    coverage = float(covered/len(ev_ix)) if len(ev_ix) else float('nan')\n",
    "\n",
    "    # segment stats\n",
    "    segs, in_warn, st = [], False, None\n",
    "    for i, a in enumerate(df['alert'].values):\n",
    "        if a==\"WARNING\" and not in_warn:\n",
    "            st, in_warn = i, True\n",
    "        elif a!=\"WARNING\" and in_warn:\n",
    "            segs.append((st, i-1)); in_warn=False\n",
    "    if in_warn: segs.append((st, len(df)-1))\n",
    "    seg_lens = [e-s+1 for s,e in segs]\n",
    "\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_nextday_total\": int(yA.sum()),\n",
    "        \"events_window_total\": int(yB.sum()),\n",
    "        \"auc_pr_nextday\": auc_pr_A,\n",
    "        \"auc_pr_windowed\": auc_pr_B,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"warning_days\": int(warn_mask.sum()),\n",
    "        \"warning_starts\": int(len(start_ix_all)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms / years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"coverage_windowed\": coverage,\n",
    "        \"warning_segments\": int(len(segs)),\n",
    "        \"warning_segment_len_median\": (float(np.median(seg_lens)) if seg_lens else None),\n",
    "        \"cooldown_applied_min_days_between_starts\": COOLDOWN_D,\n",
    "        \"cooldown_starts_kept\": int(len(kept))\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02c_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert','alert_raw']], \"gdren_v02c_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02c_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D, \"event_ksigma\": EVENT_KSIGMA,\n",
    "                \"coupling_win\": COUPLING_WIN},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn},\n",
    "        \"notes\": \"v0.2c — robust coupling; windowed-event metrics; clearer coverage.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2c SKILL ===\")\n",
    "    for k,v in metrics.items(): print(f\"{k:>28}: {v}\")\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ecfb9e9-04bb-4980-ae9d-e094a1b587f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220142Z_v02d\\\\gdren_v02d_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220142Z_v02d\\\\gdren_v02d_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220142Z_v02d\\\\gdren_v02d_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220142Z_v02d\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2d SKILL (horizon-aware) ===\n",
      "                   samples: 10615\n",
      "                     years: 32.766598220396986\n",
      "              events_total: 265\n",
      "           watch_threshold: 0.7447568136044356\n",
      "         warning_threshold: 0.8928152410147528\n",
      "            exit_threshold: 0.6947568136044355\n",
      "              warning_days: 1743\n",
      "            warning_starts: 11\n",
      "          hits_within_days: 7\n",
      "                      hits: 4\n",
      "              false_alarms: 7\n",
      "     false_alarms_per_year: 0.21363218582887702\n",
      "     lead_time_days_median: 3.5\n",
      "       lead_time_days_mean: 3.5\n",
      " auc_pr_lead_curve (k→AUC): {1: 0.02326670043046703, 2: 0.02327318286306805, 3: 0.023247071628575196, 4: 0.023240759619402286, 5: 0.023250577519007998, 6: 0.023269450493103985, 7: 0.023283926606406553}\n",
      " coverage_by_event (K→cov): {1: 0.0037735849056603774, 2: 0.0037735849056603774, 3: 0.007547169811320755, 4: 0.011320754716981131, 5: 0.011320754716981131, 6: 0.01509433962264151, 7: 0.01509433962264151}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2d (single cell) — horizon-aware skill, true lead time, hysteresis exits ===\n",
    "import os, json, time, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ----- lightweight bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ----- config (tune freely) -----\n",
    "LAT, LON = 40.7128, -74.0060    # your location\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # early-warning horizon\n",
    "EVENT_KSIGMA = 2.5              # event = |Δ| > K * rolling σ (try 2.5–3.0)\n",
    "COUPLING_WIN = 400              # samples for hetero-coupling\n",
    "HYST_EXIT_MARGIN = 0.05         # WARNING exits when NEXUS < (watch - margin) for N days\n",
    "HYST_EXIT_DAYS = 5\n",
    "COOLDOWN_BETWEEN_STARTS = 10    # min days between WARNING starts (reporting)\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02d\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# ----- time helpers -----\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None:\n",
    "        idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s) == 0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy())\n",
    "    s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ----- CNT features -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h, _ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w)\n",
    "        out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a) != len(b) or len(a) < 128: return np.nan\n",
    "    mask = np.isfinite(a) & np.isfinite(b); a, b = a[mask], b[mask]\n",
    "    if len(a) < 128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    f, Cxy = coherence(a, b, fs=fs, nperseg=min(256, len(a)))\n",
    "    band = (f>0.02) & (f<0.25); v = Cxy[band]\n",
    "    v = v[np.isfinite(v)]; return float(v.mean()) if v.size else np.nan\n",
    "\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w):\n",
    "        v = w.iat[-1]; arr = np.sort(w)\n",
    "        return (np.searchsorted(arr, v, side=\"right\")/len(w))\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.24*F.get('S_d_mkt',0) + 0.20*F.get('AR1_mkt',0) + 0.10*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_tmp',0) + 0.14*F.get('AR1_tmp',0) + 0.06*F.get('Theta_tmp',0) +\n",
    "             0.08*F.get('Gamma',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders (robust) -----\n",
    "def get_market():\n",
    "    try:\n",
    "        h = yf.Ticker(\"SPY\").history(period=\"max\", auto_adjust=True)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h.columns and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(\"px\").dropna())\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance Ticker.history failed:\", e)\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", period=\"max\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s.columns and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(\"px\").dropna())\n",
    "    except Exception as e:\n",
    "        print(\"[warn] yfinance download failed:\", e)\n",
    "    try:\n",
    "        url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "        stq = pd.read_csv(url)\n",
    "        stq.columns = [c.lower() for c in stq.columns]\n",
    "        stq['date'] = pd.to_datetime(stq['date'])\n",
    "        stq = stq.set_index('date').sort_index()\n",
    "        print(\"[info] Using Stooq fallback for SPY.\")\n",
    "        return normalize_series_daily(stq['close'].rename('px').astype(float))\n",
    "    except Exception as e:\n",
    "        print(\"[error] stooq fallback failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon)\n",
    "        d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        if 'tavg' in d.columns and d['tavg'].notna().any():\n",
    "            t = d['tavg'].astype(float)\n",
    "        else:\n",
    "            t = ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temperature fetch failed:\", e)\n",
    "        return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "ta = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & frame -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "if len(px)>0: idx = px.index\n",
    "if len(ta)>0: idx = ta.index if idx.empty else idx.union(ta.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0: df['px'] = px.reindex(df.index).ffill()\n",
    "if len(ta)>0: df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "if 'px' in df.columns: df['ret'] = df['px'].pct_change()\n",
    "\n",
    "# ----- features -----\n",
    "if 'px' in df.columns:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m   = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt'] = df['AR1_mkt'] = df['Theta_mkt'] = np.nan\n",
    "\n",
    "if 'temp_anom' in df.columns:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp'] = df['AR1_tmp'] = df['Theta_tmp'] = np.nan\n",
    "\n",
    "# hetero-coupling\n",
    "df['Gamma'] = np.nan\n",
    "if 'ret' in df.columns and 'temp_anom' in df.columns:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['temp_anom'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_tmp','AR1_tmp','Theta_tmp','Gamma']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "thr_exit  = thr_watch - HYST_EXIT_MARGIN\n",
    "\n",
    "# ----- state with hysteresis exits -----\n",
    "state = []\n",
    "in_warn = False; below_cnt = 0\n",
    "nx = df['NEXUS'].values\n",
    "for i in range(len(df)):\n",
    "    val = nx[i]\n",
    "    slope3 = (val - nx[i-3]) if i>=3 and np.isfinite(nx[i-3]) else 0.0\n",
    "    if in_warn:\n",
    "        if val < thr_exit: below_cnt += 1\n",
    "        else: below_cnt = 0\n",
    "        if below_cnt >= HYST_EXIT_DAYS:\n",
    "            in_warn = False\n",
    "            state.append('WATCH' if val >= thr_watch else 'OK')\n",
    "        else:\n",
    "            state.append('WARNING')\n",
    "    else:\n",
    "        if (val >= thr_warn) and (slope3 > 0):\n",
    "            in_warn = True; below_cnt = 0\n",
    "            state.append('WARNING')\n",
    "        elif val >= thr_watch:\n",
    "            state.append('WATCH')\n",
    "        else:\n",
    "            state.append('OK')\n",
    "df['alert'] = state\n",
    "\n",
    "# ----- event series (actual spike days) -----\n",
    "metrics = {}\n",
    "if 'ret' in df.columns and df['ret'].notna().any():\n",
    "    vol = df['ret'].rolling(21).std()\n",
    "    E = (df['ret'].abs() > EVENT_KSIGMA*vol).astype(int)     # event days\n",
    "    df['EVENT'] = E\n",
    "\n",
    "    # Lead-curve PR-AUC: use NEXUS from k days earlier to rank today's events\n",
    "    auc_lead = {}\n",
    "    nx_series = df['NEXUS'].fillna(0.0)\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        y = E.iloc[k:].values\n",
    "        x = nx_series.shift(k).iloc[k:].values\n",
    "        if y.sum() > 0:\n",
    "            auc_lead[k] = float(average_precision_score(y, x))\n",
    "        else:\n",
    "            auc_lead[k] = float('nan')\n",
    "\n",
    "    # WARNING starts (after hysteresis)\n",
    "    starts_mask = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    start_ix = np.where(starts_mask.values)[0].tolist()\n",
    "    # apply reporting cooldown\n",
    "    kept = []\n",
    "    last = -10**9\n",
    "    for s in start_ix:\n",
    "        if s - last >= COOLDOWN_BETWEEN_STARTS:\n",
    "            kept.append(s); last = s\n",
    "    start_ix = kept\n",
    "\n",
    "    # Hits/lead using TRUE next event day within horizon\n",
    "    hits, lead_days = 0, []\n",
    "    e_ix = np.where(E.values==1)[0]\n",
    "    e_set = set(e_ix)\n",
    "    for s in start_ix:\n",
    "        hit = None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set:\n",
    "                hit = s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit - s))\n",
    "    false_alarms = int(len(start_ix) - hits)\n",
    "\n",
    "    # Coverage_by_event: proportion of events with a WARNING start in previous K days\n",
    "    coverage_by_k = {}\n",
    "    start_set = set(start_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered = 0\n",
    "        for e in e_ix:\n",
    "            left = max(0, e-K)\n",
    "            if any((t in start_set) for t in range(left, e)):\n",
    "                covered += 1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    # segment stats\n",
    "    segs, inw, st = [], False, None\n",
    "    for i, a in enumerate(df['alert'].values):\n",
    "        if a==\"WARNING\" and not inw: st, inw = i, True\n",
    "        elif a!=\"WARNING\" and inw: segs.append((st, i-1)); inw=False\n",
    "    if inw: segs.append((st, len(df)-1))\n",
    "    seg_lens = [e-s+1 for s,e in segs]\n",
    "\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    warn_days = int((df['alert']==\"WARNING\").sum())\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_total\": int(E.sum()),\n",
    "        \"auc_pr_lead_curve\": auc_lead,                    # PR-AUC at lead k days\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"exit_threshold\": thr_exit,\n",
    "        \"warning_days\": warn_days,\n",
    "        \"warning_starts\": int(len(start_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms/years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"coverage_by_event\": coverage_by_k,\n",
    "        \"warning_segments\": int(len(segs)),\n",
    "        \"warning_segment_len_median\": (float(np.median(seg_lens)) if seg_lens else None),\n",
    "        \"cooldown_between_starts_days\": COOLDOWN_BETWEEN_STARTS,\n",
    "        \"hysteresis_exit_days\": HYST_EXIT_DAYS,\n",
    "        \"hysteresis_exit_margin\": HYST_EXIT_MARGIN,\n",
    "        \"event_ksigma\": EVENT_KSIGMA,\n",
    "        \"lookahead_days\": LOOKAHEAD_D,\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02d_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert','EVENT']], \"gdren_v02d_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02d_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn, \"exit\": thr_exit},\n",
    "        \"notes\": \"v0.2d — event=|ret|>Kσ; lead-curve PR-AUC; true lead-to-event; hysteresis exits.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2d SKILL (horizon-aware) ===\")\n",
    "    key = ['samples','years','events_total','watch_threshold','warning_threshold','exit_threshold',\n",
    "           'warning_days','warning_starts','hits_within_days','hits','false_alarms','false_alarms_per_year',\n",
    "           'lead_time_days_median','lead_time_days_mean']\n",
    "    for k in key:\n",
    "        print(f\"{k:>26}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics['auc_pr_lead_curve'])\n",
    "    print(\" coverage_by_event (K→cov):\", metrics['coverage_by_event'])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8bf2157-da0c-429a-85b1-5debf4b5bc93",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220622Z_v02e\\\\gdren_v02e_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220622Z_v02e\\\\gdren_v02e_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220622Z_v02e\\\\gdren_v02e_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-220622Z_v02e\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2e SKILL (regime-aware) ===\n",
      "                   samples: 11394\n",
      "                     years: 35.841204654346335\n",
      "              events_total: 1537\n",
      "           watch_threshold: 0.7173172519040436\n",
      "         warning_threshold: 0.8774624411014813\n",
      "            exit_threshold: 0.6373172519040436\n",
      "              warning_days: 760\n",
      "            warning_starts: 40\n",
      "          hits_within_days: 7\n",
      "                      hits: 10\n",
      "              false_alarms: 30\n",
      "     false_alarms_per_year: 0.837025437323352\n",
      "     lead_time_days_median: 2.0\n",
      "       lead_time_days_mean: 2.4\n",
      " auc_pr_lead_curve (k→AUC): {1: 0.13588386034591796, 2: 0.1353583940825056, 3: 0.13483436367389043, 4: 0.13432494172297105, 5: 0.1338334556274971, 6: 0.13334887127750727, 7: 0.13287375772128263}\n",
      " coverage_by_event (K→cov): {1: 0.002602472348731295, 2: 0.006506180871828237, 3: 0.009108653220559532, 4: 0.01236174365647365, 5: 0.01626545217957059, 6: 0.01756668835393624, 7: 0.020169160702667534}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2e — regime events (spike ∪ vol-breakout ∪ drawdown), VIX channel, tidy warnings ===\n",
    "import os, json, time, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ---- bootstrap ----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ---- config (tune as needed) ----\n",
    "LAT, LON = 40.7128, -74.0060      # set to your city if desired\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                   # early-warning horizon (days)\n",
    "EVENT_KSIGMA = 2.5                # spike: |ret| > K * 21d σ\n",
    "VOL_BREAK_Q = 0.98                # vol-breakout: 10d σ above rolling q\n",
    "VOL_BREAK_WIN = 252*3             # quantile lookback (≈3y)\n",
    "DD_WIN = 60                       # drawdown window (days)\n",
    "DD_FRAC = 0.08                    # drawdown threshold (>=8%)\n",
    "COUPLING_WIN = 400                # window for hetero-coupling\n",
    "HYST_EXIT_MARGIN = 0.08           # WARNING exits when NEXUS < (watch - margin) for N days\n",
    "HYST_EXIT_DAYS = 3\n",
    "MAX_WARN_DAYS = 20                # hard cap for WARNING segment length\n",
    "COOLDOWN_BETWEEN_STARTS = 12      # min days between WARNING starts (reporting)\n",
    "\n",
    "# ---- paths ----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02e\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name):\n",
    "    fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name):\n",
    "    fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# ---- time helpers ----\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ---- CNT utilities ----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]; h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    mask = np.isfinite(a)&np.isfinite(b); a,b = a[mask], b[mask]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    f,Cxy = coherence(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "    band = (f>0.02)&(f<0.25); v = Cxy[band]; v = v[np.isfinite(v)]\n",
    "    return float(v.mean()) if v.size else np.nan\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w): v = w.iat[-1]; arr = np.sort(w); return np.searchsorted(arr, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (0.20*F.get('S_d_mkt',0) + 0.15*F.get('AR1_mkt',0) + 0.08*F.get('Theta_mkt',0) +\n",
    "             0.18*F.get('S_d_vix',0) + 0.10*F.get('AR1_vix',0) + 0.06*F.get('Theta_vix',0) +\n",
    "             0.12*F.get('S_d_tmp',0) + 0.08*F.get('AR1_tmp',0) + 0.03*F.get('Theta_tmp',0) +\n",
    "             0.10*F.get('Gamma_mkt_vix',0))\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ---- data loaders ----\n",
    "def get_market():\n",
    "    try:\n",
    "        h = yf.Ticker(\"SPY\").history(period=\"max\", auto_adjust=True)\n",
    "        if isinstance(h,pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename('px').dropna())\n",
    "    except Exception as e: print(\"[warn] history SPY:\", e)\n",
    "    try:\n",
    "        s = yf.download(\"SPY\", period=\"max\", interval=\"1d\", auto_adjust=True, progress=False)\n",
    "        if isinstance(s,pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename('px').dropna())\n",
    "    except Exception as e: print(\"[warn] download SPY:\", e)\n",
    "    try:\n",
    "        url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "        stq = pd.read_csv(url); stq.columns=[c.lower() for c in stq.columns]\n",
    "        stq['date']=pd.to_datetime(stq['date']); stq=stq.set_index('date').sort_index()\n",
    "        return normalize_series_daily(stq['close'].rename('px').astype(float))\n",
    "    except Exception as e: print(\"[error] stooq SPY:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "def get_vix():\n",
    "    try:\n",
    "        h = yf.Ticker(\"^VIX\").history(period=\"max\", auto_adjust=False)\n",
    "        if isinstance(h,pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename('vix').dropna())\n",
    "    except Exception as e: print(\"[warn] history VIX:\", e)\n",
    "    try:\n",
    "        s = yf.download(\"^VIX\", period=\"max\", interval=\"1d\", auto_adjust=False, progress=False)\n",
    "        if isinstance(s,pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename('vix').dropna())\n",
    "    except Exception as e: print(\"[warn] download VIX:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin')+d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "px = get_market()\n",
    "vix = get_vix()\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ---- align & frame ----\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0:  df['px'] = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0: df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(ta)>0:  df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# ---- features: SPY / VIX / temp ----\n",
    "if 'ret' in df:\n",
    "    sig_m = df['ret'].fillna(0.0).values\n",
    "    z_m = zscore_mad(sig_m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(sig_m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(sig_m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(z_m, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "\n",
    "if 'dvix' in df:\n",
    "    sig_v = df['dvix'].fillna(0.0).values\n",
    "    z_v = zscore_mad(sig_v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(sig_v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(sig_v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(z_v, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "\n",
    "if 'temp_anom' in df:\n",
    "    sig_t = df['temp_anom'].fillna(0.0).values\n",
    "    z_t   = zscore_mad(sig_t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(sig_t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(sig_t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(z_t, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# hetero-coupling (SPY vs VIX delta)\n",
    "df['Gamma_mkt_vix'] = np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a, b, fs=1.0)\n",
    "\n",
    "# ---- fuse → NEXUS + thresholds ----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_vix','AR1_vix','Theta_vix','S_d_tmp','AR1_tmp','Theta_tmp','Gamma_mkt_vix']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.90)) if len(core) else 0.90\n",
    "thr_exit  = thr_watch - HYST_EXIT_MARGIN\n",
    "\n",
    "# ---- WARNING state with hysteresis + max-length + slope gate ----\n",
    "state=[]; in_warn=False; below_cnt=0; warn_len=0\n",
    "nx = df['NEXUS'].values\n",
    "for i in range(len(df)):\n",
    "    val = nx[i]\n",
    "    s3  = (val - nx[i-3]) if i>=3 and np.isfinite(nx[i-3]) else 0.0\n",
    "    s7  = (val - nx[i-7]) if i>=7 and np.isfinite(nx[i-7]) else 0.0\n",
    "    if in_warn:\n",
    "        warn_len += 1\n",
    "        if val < thr_exit: below_cnt += 1\n",
    "        else: below_cnt = 0\n",
    "        if below_cnt >= HYST_EXIT_DAYS or warn_len >= MAX_WARN_DAYS:\n",
    "            in_warn=False; warn_len=0\n",
    "            state.append('WATCH' if val>=thr_watch else 'OK')\n",
    "        else:\n",
    "            state.append('WARNING')\n",
    "    else:\n",
    "        if (val>=thr_warn) and (s3>0) and (s7>0):\n",
    "            in_warn=True; below_cnt=0; warn_len=1\n",
    "            state.append('WARNING')\n",
    "        elif val>=thr_watch:\n",
    "            state.append('WATCH')\n",
    "        else:\n",
    "            state.append('OK')\n",
    "df['alert']=state\n",
    "\n",
    "# ---- regime EVENTS (union): spike ∪ vol-breakout ∪ drawdown ----\n",
    "metrics={}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10 = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int)\n",
    "    df['EVENT'] = E\n",
    "\n",
    "    # ---- lead AUC over 1..LOOKAHEAD_D (NEXUS leading EVENTS) ----\n",
    "    nx_s = df['NEXUS'].fillna(0.0)\n",
    "    auc_lead={}\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        y = E.iloc[k:].values\n",
    "        x = nx_s.shift(k).iloc[k:].values\n",
    "        auc_lead[k] = float(average_precision_score(y, x)) if y.sum()>0 else float('nan')\n",
    "\n",
    "    # ---- starts / hits / lead / false alarms ----\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = np.where(starts.values)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    e_ix = np.where(E.values==1)[0]; e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit-s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "\n",
    "    # ---- event coverage: event had WARNING start in prior K days ----\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t in s_set) for t in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    # ---- warning segment stats ----\n",
    "    segs=[]; inw=False; st=None\n",
    "    for i,a in enumerate(df['alert'].values):\n",
    "        if a==\"WARNING\" and not inw: st,i0 = i, i; inw=True\n",
    "        elif a!=\"WARNING\" and inw: segs.append((st, i-1)); inw=False\n",
    "    if inw: segs.append((st, len(df)-1))\n",
    "    seg_lens=[e-s+1 for s,e in segs]\n",
    "\n",
    "    years = max(1e-9,(df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    warn_days = int((df['alert']==\"WARNING\").sum())\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"events_total\": int(E.sum()),\n",
    "        \"auc_pr_lead_curve\": auc_lead,\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"exit_threshold\": thr_exit,\n",
    "        \"warning_days\": warn_days,\n",
    "        \"warning_starts\": int(len(s_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms/years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"coverage_by_event\": coverage_by_k,\n",
    "        \"warning_segments\": int(len(segs)),\n",
    "        \"warning_segment_len_median\": (float(np.median(seg_lens)) if seg_lens else None),\n",
    "        \"event_components\": {\n",
    "            \"spike_k\": EVENT_KSIGMA, \"vol_q\": VOL_BREAK_Q, \"vol_win\": VOL_BREAK_WIN,\n",
    "            \"dd_win\": DD_WIN, \"dd_frac\": DD_FRAC\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ---- persist ----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02e_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert','EVENT']], \"gdren_v02e_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02e_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn, \"exit\": thr_exit},\n",
    "        \"notes\": \"v0.2e — VIX channel + regime events (spike ∪ vol-breakout ∪ drawdown) + hysteresis cap.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2e SKILL (regime-aware) ===\")\n",
    "    for k in [\"samples\",\"years\",\"events_total\",\"watch_threshold\",\"warning_threshold\",\"exit_threshold\",\n",
    "              \"warning_days\",\"warning_starts\",\"hits_within_days\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "              \"lead_time_days_median\",\"lead_time_days_mean\"]:\n",
    "        print(f\"{k:>26}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_by_event (K→cov):\", metrics[\"coverage_by_event\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a2d05892-2b3a-4e84-a048-17337f0f577b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221211Z_v02f\\\\gdren_v02f_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221211Z_v02f\\\\gdren_v02f_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221211Z_v02f\\\\gdren_v02f_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221211Z_v02f\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2f SKILL (onset-aware) ===\n",
      "                   samples: 11394\n",
      "                     years: 35.841204654346335\n",
      "        event_onsets_total: 159\n",
      "           watch_threshold: 0.711124776785366\n",
      "         warning_threshold: 0.8827811619210296\n",
      "            exit_threshold: 0.631124776785366\n",
      "              warning_days: 637\n",
      "            warning_starts: 49\n",
      "          hits_within_days: 7\n",
      "                      hits: 4\n",
      "              false_alarms: 45\n",
      "     false_alarms_per_year: 1.255538155985028\n",
      "     lead_time_days_median: 3.5\n",
      "       lead_time_days_mean: 3.25\n",
      " auc_pr_lead_curve (k→AUC): {1: 0.015039936715597802, 2: 0.015026154574159484, 3: 0.015012223731281422, 4: 0.014994303239131349, 5: 0.014995813385449742, 6: 0.014993195512636785, 7: 0.014984056251027725}\n",
      " coverage_onsets   (K→cov): {1: 0.0, 2: 0.006289308176100629, 3: 0.012578616352201259, 4: 0.025157232704402517, 5: 0.025157232704402517, 6: 0.025157232704402517, 7: 0.025157232704402517}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2f — onset-only regime events, VIX + credit channel, gated warnings, horizon metrics ===\n",
    "import os, json, time, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ----- bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ----- config (tune freely) -----\n",
    "LAT, LON = 40.7128, -74.0060    # your location\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # early-warning horizon (days)\n",
    "EVENT_KSIGMA = 3.0              # spike: |ret| > K * 21d σ  (try 2.5–3.0)\n",
    "VOL_BREAK_Q = 0.995             # vol-breakout: 10d σ above rolling q\n",
    "VOL_BREAK_WIN = 252*3           # quantile lookback (≈3y)\n",
    "DD_WIN = 40                     # drawdown window (days)\n",
    "DD_FRAC = 0.10                  # drawdown threshold (>=10%)\n",
    "COUPLING_WIN = 400              # window for hetero-coupling\n",
    "HYST_EXIT_MARGIN = 0.08         # WARNING exits when NEXUS < (watch - margin) for N days\n",
    "HYST_EXIT_DAYS = 3\n",
    "MAX_WARN_DAYS = 14              # cap individual WARNING segments\n",
    "COOLDOWN_BETWEEN_STARTS = 12    # min days between WARNING starts (reporting)\n",
    "GATE_THETA_MIN = 0.20           # gate requires any channel’s Theta >= this\n",
    "GAMMA_VIX_MIN = 0.05            # or Γ(mkt↔VIX) above this\n",
    "\n",
    "# ----- paths -----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02f\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name): fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name): fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# ----- time helpers -----\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ----- CNT utilities -----\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]; h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    mask = np.isfinite(a)&np.isfinite(b); a,b = a[mask], b[mask]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    f,Cxy = coherence(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "    band = (f>0.02)&(f<0.25); v = Cxy[band]; v = v[np.isfinite(v)]\n",
    "    return float(v.mean()) if v.size else np.nan\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w): v=w.iat[-1]; arr=np.sort(w); return np.searchsorted(arr, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        F[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    score = (\n",
    "        0.18*F.get('S_d_mkt',0) + 0.14*F.get('AR1_mkt',0) + 0.08*F.get('Theta_mkt',0) +\n",
    "        0.18*F.get('S_d_vix',0) + 0.14*F.get('AR1_vix',0) + 0.08*F.get('Theta_vix',0) +\n",
    "        0.12*F.get('S_d_cred',0)+ 0.08*F.get('AR1_cred',0)+ 0.04*F.get('Theta_cred',0) +\n",
    "        0.06*F.get('S_d_tmp',0) + 0.02*F.get('AR1_tmp',0) + 0.02*F.get('Theta_tmp',0) +\n",
    "        0.10*F.get('Gamma_mkt_vix',0) + 0.08*F.get('Gamma_mkt_cred',0)\n",
    "    )\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index)\n",
    "    return nx.ewm(span=64, min_periods=16).mean().clip(0,1)\n",
    "\n",
    "# ----- data loaders -----\n",
    "def get_px(tkr, auto_adjust=True):\n",
    "    try:\n",
    "        h = yf.Ticker(tkr).history(period=\"max\", auto_adjust=auto_adjust)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] history {tkr}:\", e)\n",
    "    try:\n",
    "        s = yf.download(tkr, period=\"max\", interval=\"1d\", auto_adjust=auto_adjust, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] download {tkr}:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e:\n",
    "        print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "px  = get_px(\"SPY\", auto_adjust=True)\n",
    "vix = get_px(\"^VIX\", auto_adjust=False)\n",
    "hyg = get_px(\"HYG\", auto_adjust=True)\n",
    "ief = get_px(\"IEF\", auto_adjust=True)\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ----- align & frame -----\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, hyg, ief, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "\n",
    "if len(px)>0:   df['px'] = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0:  df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(hyg)>0 and len(ief)>0:\n",
    "    ratio = (hyg / ief).reindex(df.index).ffill()\n",
    "    df['cred_ret'] = ratio.pct_change()\n",
    "if len(ta)>0:   df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# ----- features: market / VIX / credit / temp -----\n",
    "# market\n",
    "if 'ret' in df:\n",
    "    m = df['ret'].fillna(0.0).values; mz = zscore_mad(m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(mz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "\n",
    "# vix\n",
    "if 'dvix' in df:\n",
    "    v = df['dvix'].fillna(0.0).values; vz = zscore_mad(v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(vz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "\n",
    "# credit (HYG/IEF ratio)\n",
    "if 'cred_ret' in df:\n",
    "    c = df['cred_ret'].fillna(0.0).values; cz = zscore_mad(c, win=512)\n",
    "    df['S_d_cred']   = rolling_entropy(c, win=256, bins=48)\n",
    "    df['AR1_cred']   = rolling_ar1(c, win=256)\n",
    "    df['Theta_cred'] = theta_breaches(cz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_cred']=df['AR1_cred']=df['Theta_cred']=np.nan\n",
    "\n",
    "# temp\n",
    "if 'temp_anom' in df:\n",
    "    t = df['temp_anom'].fillna(0.0).values; tz = zscore_mad(t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(tz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# hetero-couplings\n",
    "df['Gamma_mkt_vix']  = np.nan\n",
    "df['Gamma_mkt_cred'] = np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a,b,fs=1.0)\n",
    "if 'ret' in df and 'cred_ret' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['cred_ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_cred')] = glyph_coupling(a,b,fs=1.0)\n",
    "\n",
    "# ----- fuse → NEXUS + thresholds -----\n",
    "feats = ['S_d_mkt','AR1_mkt','Theta_mkt',\n",
    "         'S_d_vix','AR1_vix','Theta_vix',\n",
    "         'S_d_cred','AR1_cred','Theta_cred',\n",
    "         'S_d_tmp','AR1_tmp','Theta_tmp',\n",
    "         'Gamma_mkt_vix','Gamma_mkt_cred']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feats])\n",
    "\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.92)) if len(core) else 0.92   # slightly stricter\n",
    "thr_exit  = thr_watch - HYST_EXIT_MARGIN\n",
    "\n",
    "# ----- gated WARNING state (hysteresis + max len + multi-channel gate) -----\n",
    "state=[]; in_warn=False; below_cnt=0; warn_len=0\n",
    "nx = df['NEXUS'].values\n",
    "for i in range(len(df)):\n",
    "    val = nx[i]\n",
    "    s3  = (val - nx[i-3]) if i>=3 and np.isfinite(nx[i-3]) else 0.0\n",
    "    s7  = (val - nx[i-7]) if i>=7 and np.isfinite(nx[i-7]) else 0.0\n",
    "    # gate: any strong Theta or strong Γ(mkt↔VIX)\n",
    "    th_v = float(df['Theta_vix'].iloc[i])  if 'Theta_vix'  in df else np.nan\n",
    "    th_m = float(df['Theta_mkt'].iloc[i])  if 'Theta_mkt'  in df else np.nan\n",
    "    th_c = float(df['Theta_cred'].iloc[i]) if 'Theta_cred' in df else np.nan\n",
    "    gm_v = float(df['Gamma_mkt_vix'].iloc[i])  if 'Gamma_mkt_vix'  in df else np.nan\n",
    "    gate_ok = ((np.nan_to_num(th_v)>=GATE_THETA_MIN) or\n",
    "               (np.nan_to_num(th_m)>=GATE_THETA_MIN) or\n",
    "               (np.nan_to_num(th_c)>=GATE_THETA_MIN) or\n",
    "               (np.nan_to_num(gm_v)>=GAMMA_VIX_MIN))\n",
    "    if in_warn:\n",
    "        warn_len += 1\n",
    "        if val < thr_exit: below_cnt += 1\n",
    "        else: below_cnt = 0\n",
    "        if below_cnt >= HYST_EXIT_DAYS or warn_len >= MAX_WARN_DAYS:\n",
    "            in_warn=False; warn_len=0\n",
    "            state.append('WATCH' if val>=thr_watch else 'OK')\n",
    "        else:\n",
    "            state.append('WARNING')\n",
    "    else:\n",
    "        if (val>=thr_warn) and (s3>0) and (s7>0) and gate_ok:\n",
    "            in_warn=True; below_cnt=0; warn_len=1\n",
    "            state.append('WARNING')\n",
    "        elif val>=thr_watch:\n",
    "            state.append('WATCH')\n",
    "        else:\n",
    "            state.append('OK')\n",
    "df['alert']=state\n",
    "\n",
    "# ----- regime EVENTS (union) then ONSETS-only -----\n",
    "metrics={}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10 = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol  = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int)\n",
    "\n",
    "    # Onset days only\n",
    "    E_onset = ((E==1) & (E.shift(1).fillna(0)==0)).astype(int)\n",
    "    df['EVENT_ONSET'] = E_onset\n",
    "\n",
    "    # Lead PR-AUC: does NEXUS k days earlier rank upcoming ONSETS?\n",
    "    nx_s = df['NEXUS'].fillna(0.0)\n",
    "    auc_lead={}\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        y = E_onset.iloc[k:].values\n",
    "        x = nx_s.shift(k).iloc[k:].values\n",
    "        auc_lead[k] = float(average_precision_score(y, x)) if y.sum()>0 else float('nan')\n",
    "\n",
    "    # Starts & hits (relative to ONSETS)\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = np.where(starts.values)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    e_ix = np.where(E_onset.values==1)[0]; e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit-s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "\n",
    "    # Coverage_by_event_onset: onset had a WARNING start in prior K days\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t in s_set) for t in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    # WARNING segment stats\n",
    "    segs=[]; inw=False; st=None\n",
    "    for i,a in enumerate(df['alert'].values):\n",
    "        if a==\"WARNING\" and not inw: st=i; inw=True\n",
    "        elif a!=\"WARNING\" and inw: segs.append((st, i-1)); inw=False\n",
    "    if inw: segs.append((st, len(df)-1))\n",
    "    seg_lens=[e-s+1 for s,e in segs]\n",
    "\n",
    "    years = max(1e-9,(df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    warn_days = int((df['alert']==\"WARNING\").sum())\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"event_onsets_total\": int(E_onset.sum()),\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"exit_threshold\": thr_exit,\n",
    "        \"warning_days\": warn_days,\n",
    "        \"warning_starts\": int(len(s_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms/years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"auc_pr_lead_curve\": auc_lead,\n",
    "        \"coverage_onsets\": coverage_by_k,\n",
    "        \"warning_segments\": int(len(segs)),\n",
    "        \"warning_segment_len_median\": (float(np.median(seg_lens)) if seg_lens else None),\n",
    "        \"event_components\": {\n",
    "            \"spike_k\": EVENT_KSIGMA, \"vol_q\": VOL_BREAK_Q, \"vol_win\": VOL_BREAK_WIN,\n",
    "            \"dd_win\": DD_WIN, \"dd_frac\": DD_FRAC\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ----- persist -----\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02f_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert','EVENT_ONSET']], \"gdren_v02f_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02f_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END,\n",
    "                \"lookahead_days\": LOOKAHEAD_D},\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn, \"exit\": thr_exit},\n",
    "        \"notes\": \"v0.2f — regime ONSETS only; VIX + credit; gated WARNING; horizon-aware metrics.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2f SKILL (onset-aware) ===\")\n",
    "    keys = [\"samples\",\"years\",\"event_onsets_total\",\"watch_threshold\",\"warning_threshold\",\"exit_threshold\",\n",
    "            \"warning_days\",\"warning_starts\",\"hits_within_days\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "            \"lead_time_days_median\",\"lead_time_days_mean\"]\n",
    "    for k in keys: print(f\"{k:>26}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_onsets   (K→cov):\", metrics[\"coverage_onsets\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a360ecc-12f4-4656-8b3d-0cefd24b2c1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n",
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221858Z_v02g\\\\gdren_v02g_features.csv\",\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221858Z_v02g\\\\gdren_v02g_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221858Z_v02g\\\\gdren_v02g_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-221858Z_v02g\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.2g SKILL (onset clusters) ===\n",
      "                   samples: 11394\n",
      "                     years: 35.841204654346335\n",
      "        event_onsets_total: 45\n",
      "           watch_threshold: 0.7267524477222704\n",
      "         warning_threshold: 0.889088492590035\n",
      "            exit_threshold: 0.6467524477222705\n",
      "              warning_days: 481\n",
      "            warning_starts: 37\n",
      "          hits_within_days: 7\n",
      "                      hits: 1\n",
      "              false_alarms: 36\n",
      "     false_alarms_per_year: 1.0044305247880223\n",
      "     lead_time_days_median: 4.0\n",
      "       lead_time_days_mean: 4.0\n",
      " auc_pr_lead_curve (k→AUC): {1: 0.006777600843701023, 2: 0.0067560807716162356, 3: 0.006945569604921594, 4: 0.006966079429073362, 5: 0.006885568115573876, 6: 0.007065428803589268, 7: 0.007195911915253577}\n",
      " coverage_onsets   (K→cov): {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.022222222222222223, 5: 0.022222222222222223, 6: 0.022222222222222223, 7: 0.022222222222222223}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.2g — onset clusters, ramp-aware NEXUS, multi-signal gates, disciplined warnings ===\n",
    "import os, json, time, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ----- bootstrap -----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ====== CONFIG (tune as you like) ======\n",
    "LAT, LON = 40.7128, -74.0060   # your city\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # warning horizon\n",
    "EVENT_KSIGMA = 3.0              # spike = |ret| > K * 21d σ\n",
    "VOL_BREAK_Q = 0.995             # vol-breakout quantile (10d σ over ~3y)\n",
    "VOL_BREAK_WIN = 252*3\n",
    "DD_WIN = 40                     # drawdown window\n",
    "DD_FRAC = 0.10                  # ≥10% drawdown\n",
    "MIN_CLUSTER_LEN = 3             # sustained regime length (days) to count onset\n",
    "COUPLING_WIN = 400\n",
    "HYST_EXIT_MARGIN = 0.08         # exit when NEXUS < (watch - margin) for N days\n",
    "HYST_EXIT_DAYS = 3\n",
    "MAX_WARN_DAYS = 14              # cap WARNING segment length\n",
    "COOLDOWN_BETWEEN_STARTS = 12    # min days between WARNING starts (reporting)\n",
    "GATE_THETA_MIN = 0.25           # gate requires strength on Θ or Γ\n",
    "GAMMA_VIX_MIN  = 0.08\n",
    "GATE_MIN_VOTES = 2              # require >= this many gate signals\n",
    "\n",
    "# ====== paths ======\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v02g\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name): fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name): fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# ====== time helpers ======\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "# ====== CNT utilities ======\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]\n",
    "        h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    mask = np.isfinite(a)&np.isfinite(b); a,b = a[mask], b[mask]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    f,Cxy = coherence(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "    band = (f>0.02)&(f<0.25); v = Cxy[band]; v = v[np.isfinite(v)]\n",
    "    return float(v.mean()) if v.size else np.nan\n",
    "def rolling_percent_rank(series, win=512):\n",
    "    s = pd.Series(series, dtype=float)\n",
    "    def pr(w): v=w.iat[-1]; arr=np.sort(w); return np.searchsorted(arr, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=False).values\n",
    "\n",
    "# ====== data loaders ======\n",
    "def get_px(tkr, auto_adjust=True):\n",
    "    try:\n",
    "        h = yf.Ticker(tkr).history(period=\"max\", auto_adjust=auto_adjust)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] history {tkr}:\", e)\n",
    "    try:\n",
    "        s = yf.download(tkr, period=\"max\", interval=\"1d\", auto_adjust=auto_adjust, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] download {tkr}:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e: print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "px  = get_px(\"SPY\",  auto_adjust=True)\n",
    "vix = get_px(\"^VIX\", auto_adjust=False)\n",
    "hyg = get_px(\"HYG\",  auto_adjust=True)\n",
    "ief = get_px(\"IEF\",  auto_adjust=True)\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "# ====== align & frame ======\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, hyg, ief, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "\n",
    "if len(px)>0:  df['px']  = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0: df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(hyg)>0 and len(ief)>0:\n",
    "    ratio = (hyg / ief).reindex(df.index).ffill()\n",
    "    df['cred_ret'] = ratio.pct_change()\n",
    "if len(ta)>0:  df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# ====== base features ======\n",
    "if 'ret' in df:\n",
    "    m  = df['ret'].fillna(0.0).values; mz = zscore_mad(m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(mz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "\n",
    "if 'dvix' in df:\n",
    "    v  = df['dvix'].fillna(0.0).values; vz = zscore_mad(v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(vz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "\n",
    "if 'cred_ret' in df:\n",
    "    c  = df['cred_ret'].fillna(0.0).values; cz = zscore_mad(c, win=512)\n",
    "    df['S_d_cred']   = rolling_entropy(c, win=256, bins=48)\n",
    "    df['AR1_cred']   = rolling_ar1(c, win=256)\n",
    "    df['Theta_cred'] = theta_breaches(cz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_cred']=df['AR1_cred']=df['Theta_cred']=np.nan\n",
    "\n",
    "if 'temp_anom' in df:\n",
    "    t  = df['temp_anom'].fillna(0.0).values; tz = zscore_mad(t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(tz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# hetero-couplings\n",
    "df['Gamma_mkt_vix']  = np.nan\n",
    "df['Gamma_mkt_cred'] = np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a,b,fs=1.0)\n",
    "if 'ret' in df and 'cred_ret' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['cred_ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_cred')] = glyph_coupling(a,b,fs=1.0)\n",
    "\n",
    "# ====== ramp-aware NEXUS fuse (adds 7d slopes of z-features) ======\n",
    "def fuse_to_nexus(F: pd.DataFrame):\n",
    "    F = F.copy().ffill().bfill().fillna(0.0)\n",
    "    Z = pd.DataFrame(index=F.index)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        Z[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    # 7-day ramps on normalized features\n",
    "    DZ = Z.diff(7)\n",
    "\n",
    "    # base + ramp weights (favor approach dynamics)\n",
    "    score = (\n",
    "        0.16*Z.get('S_d_mkt',0)+ 0.14*Z.get('AR1_mkt',0)+ 0.08*Z.get('Theta_mkt',0) +\n",
    "        0.16*Z.get('S_d_vix',0)+ 0.14*Z.get('AR1_vix',0)+ 0.08*Z.get('Theta_vix',0) +\n",
    "        0.10*Z.get('S_d_cred',0)+ 0.08*Z.get('AR1_cred',0)+ 0.04*Z.get('Theta_cred',0) +\n",
    "        0.05*Z.get('Gamma_mkt_vix',0)+ 0.04*Z.get('Gamma_mkt_cred',0) +\n",
    "        # ramps\n",
    "        0.06*DZ.get('AR1_mkt',0)+ 0.06*DZ.get('S_d_mkt',0)+ 0.04*DZ.get('Theta_mkt',0) +\n",
    "        0.05*DZ.get('AR1_vix',0)+ 0.05*DZ.get('S_d_vix',0)+ 0.03*DZ.get('Theta_vix',0) +\n",
    "        0.04*DZ.get('Gamma_mkt_vix',0)+ 0.03*DZ.get('Gamma_mkt_cred',0)\n",
    "    )\n",
    "    nx = pd.Series(rolling_percent_rank(score, win=512), index=F.index).ewm(span=64, min_periods=16).mean()\n",
    "    return nx.clip(0,1)\n",
    "\n",
    "feat_cols = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_vix','AR1_vix','Theta_vix',\n",
    "             'S_d_cred','AR1_cred','Theta_cred','S_d_tmp','AR1_tmp','Theta_tmp',\n",
    "             'Gamma_mkt_vix','Gamma_mkt_cred']\n",
    "df['NEXUS'] = fuse_to_nexus(df[feat_cols])\n",
    "\n",
    "# thresholds from core slice\n",
    "core = df['NEXUS'].iloc[365:-365].dropna()\n",
    "thr_watch = float(core.quantile(0.75)) if len(core) else 0.75\n",
    "thr_warn  = float(core.quantile(0.94)) if len(core) else 0.94   # a bit stricter\n",
    "thr_exit  = thr_watch - HYST_EXIT_MARGIN\n",
    "\n",
    "# ====== gated WARNING state ======\n",
    "state=[]; in_warn=False; below_cnt=0; warn_len=0\n",
    "nx = df['NEXUS'].values\n",
    "nx_slope7 = (df['NEXUS'] - df['NEXUS'].shift(7)).fillna(0.0).values\n",
    "for i in range(len(df)):\n",
    "    val = nx[i]\n",
    "    s3  = (val - nx[i-3]) if i>=3 and np.isfinite(nx[i-3]) else 0.0\n",
    "    s7  = (val - nx[i-7]) if i>=7 and np.isfinite(nx[i-7]) else 0.0\n",
    "    # votes: Θ_vix / Θ_cred / Θ_mkt / Γ(mkt↔VIX) / rising NEXUS slope\n",
    "    th_v = float(df['Theta_vix'].iloc[i])   if 'Theta_vix'   in df else np.nan\n",
    "    th_c = float(df['Theta_cred'].iloc[i])  if 'Theta_cred'  in df else np.nan\n",
    "    th_m = float(df['Theta_mkt'].iloc[i])   if 'Theta_mkt'   in df else np.nan\n",
    "    gm_v = float(df['Gamma_mkt_vix'].iloc[i]) if 'Gamma_mkt_vix' in df else np.nan\n",
    "    votes = 0\n",
    "    votes += int(np.nan_to_num(th_v) >= GATE_THETA_MIN)\n",
    "    votes += int(np.nan_to_num(th_c) >= GATE_THETA_MIN)\n",
    "    votes += int(np.nan_to_num(th_m) >= GATE_THETA_MIN)\n",
    "    votes += int(np.nan_to_num(gm_v) >= GAMMA_VIX_MIN)\n",
    "    votes += int(nx_slope7[i] > 0)\n",
    "    gate_ok = (votes >= GATE_MIN_VOTES)\n",
    "\n",
    "    if in_warn:\n",
    "        warn_len += 1\n",
    "        if val < thr_exit: below_cnt += 1\n",
    "        else: below_cnt = 0\n",
    "        if below_cnt >= HYST_EXIT_DAYS or warn_len >= MAX_WARN_DAYS:\n",
    "            in_warn=False; warn_len=0\n",
    "            state.append('WATCH' if val>=thr_watch else 'OK')\n",
    "        else:\n",
    "            state.append('WARNING')\n",
    "    else:\n",
    "        if (val>=thr_warn) and (s3>0) and (s7>0) and gate_ok:\n",
    "            in_warn=True; below_cnt=0; warn_len=1\n",
    "            state.append('WARNING')\n",
    "        elif val>=thr_watch:\n",
    "            state.append('WATCH')\n",
    "        else:\n",
    "            state.append('OK')\n",
    "df['alert']=state\n",
    "\n",
    "# ====== regime events -> cluster onsets only ======\n",
    "metrics={}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10  = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol  = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int)\n",
    "\n",
    "    # cluster sustained regimes (length >= MIN_CLUSTER_LEN) and mark onsets\n",
    "    onset = np.zeros(len(df), dtype=int)\n",
    "    i=0\n",
    "    arr = E.values\n",
    "    while i < len(arr):\n",
    "        if arr[i]==1:\n",
    "            j=i\n",
    "            while j+1<len(arr) and arr[j+1]==1: j+=1\n",
    "            seg_len = j - i + 1\n",
    "            if seg_len >= MIN_CLUSTER_LEN: onset[i] = 1\n",
    "            i = j + 1\n",
    "        else:\n",
    "            i += 1\n",
    "    df['EVENT_ONSET'] = onset\n",
    "\n",
    "    # ====== metrics: lead AUC (1..K), starts/hits/FA, coverage ======\n",
    "    nx_s = df['NEXUS'].fillna(0.0)\n",
    "    auc_lead={}\n",
    "    y_on = df['EVENT_ONSET'].values\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        y = y_on[k:]\n",
    "        x = nx_s.shift(k).iloc[k:].values\n",
    "        auc_lead[k] = float(average_precision_score(y, x)) if y.sum()>0 else float('nan')\n",
    "\n",
    "    # starts with cooldown\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = np.where(starts.values)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    # hits to next onset within horizon\n",
    "    e_ix = np.where(y_on==1)[0]; e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit - s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "\n",
    "    # coverage of onsets: had a WARNING start in prior K days\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t in s_set) for t in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    # segment stats\n",
    "    segs=[]; inw=False; st=None\n",
    "    for i,a in enumerate(df['alert'].values):\n",
    "        if a==\"WARNING\" and not inw: st=i; inw=True\n",
    "        elif a!=\"WARNING\" and inw: segs.append((st, i-1)); inw=False\n",
    "    if inw: segs.append((st, len(df)-1))\n",
    "    seg_lens=[e-s+1 for s,e in segs]\n",
    "\n",
    "    years = max(1e-9,(df.index[-1]-df.index[0]).days/365.25) if len(df) else 1.0\n",
    "    warn_days = int((df['alert']==\"WARNING\").sum())\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"event_onsets_total\": int(y_on.sum()),\n",
    "        \"watch_threshold\": thr_watch,\n",
    "        \"warning_threshold\": thr_warn,\n",
    "        \"exit_threshold\": thr_exit,\n",
    "        \"warning_days\": warn_days,\n",
    "        \"warning_starts\": int(len(s_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(false_alarms/years),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"auc_pr_lead_curve\": auc_lead,\n",
    "        \"coverage_onsets\": coverage_by_k,\n",
    "        \"warning_segments\": int(len(segs)),\n",
    "        \"warning_segment_len_median\": (float(np.median(seg_lens)) if seg_lens else None),\n",
    "        \"params\": {\n",
    "            \"lookahead\": LOOKAHEAD_D, \"ksigma\": EVENT_KSIGMA, \"vol_q\": VOL_BREAK_Q,\n",
    "            \"vol_win\": VOL_BREAK_WIN, \"dd_win\": DD_WIN, \"dd_frac\": DD_FRAC,\n",
    "            \"min_cluster_len\": MIN_CLUSTER_LEN, \"gate_theta\": GATE_THETA_MIN,\n",
    "            \"gate_gamma_vix\": GAMMA_VIX_MIN, \"gate_min_votes\": GATE_MIN_VOTES\n",
    "        }\n",
    "    }\n",
    "\n",
    "# ====== persist ======\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df, \"gdren_v02g_features\"),\n",
    "    \"alerts_csv\": save_df(df[['NEXUS','alert','EVENT_ONSET']], \"gdren_v02g_alerts\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v02g_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"thresholds\": {\"watch\": thr_watch, \"warning\": thr_warn, \"exit\": thr_exit},\n",
    "        \"notes\": \"v0.2g — onset clusters ≥3d; ramp-aware fusion; multi-signal gate; disciplined WARNINGs.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.2g SKILL (onset clusters) ===\")\n",
    "    keys = [\"samples\",\"years\",\"event_onsets_total\",\"watch_threshold\",\"warning_threshold\",\"exit_threshold\",\n",
    "            \"warning_days\",\"warning_starts\",\"hits_within_days\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "            \"lead_time_days_median\",\"lead_time_days_mean\"]\n",
    "    for k in keys: print(f\"{k:>26}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_onsets   (K→cov):\", metrics[\"coverage_onsets\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "62925007-14c7-40cb-8a46-ea8852766875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[setup] installing scikit-learn …\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 341\u001b[39m\n\u001b[32m    336\u001b[39m thetas_train = (df[\u001b[33m'\u001b[39m\u001b[33mTheta_mkt\u001b[39m\u001b[33m'\u001b[39m].loc[idx_train].fillna(\u001b[32m0.0\u001b[39m),\n\u001b[32m    337\u001b[39m                 df[\u001b[33m'\u001b[39m\u001b[33mTheta_vix\u001b[39m\u001b[33m'\u001b[39m].loc[idx_train].fillna(\u001b[32m0.0\u001b[39m),\n\u001b[32m    338\u001b[39m                 df[\u001b[33m'\u001b[39m\u001b[33mTheta_cred\u001b[39m\u001b[33m'\u001b[39m].loc[idx_train].fillna(\u001b[32m0.0\u001b[39m))\n\u001b[32m    339\u001b[39m gammas_train = (df[\u001b[33m'\u001b[39m\u001b[33mGamma_mkt_vix\u001b[39m\u001b[33m'\u001b[39m].loc[idx_train].fillna(\u001b[32m0.0\u001b[39m),)\n\u001b[32m--> \u001b[39m\u001b[32m341\u001b[39m calib = \u001b[43mmake_alert_from_risk\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrisk_all\u001b[49m\u001b[43m.\u001b[49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx_train\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mthetas_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgammas_train\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mfa_target\u001b[49m\u001b[43m=\u001b[49m\u001b[43mFA_PER_YEAR_TARGET\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    345\u001b[39m thr_prob = calib[\u001b[33m\"\u001b[39m\u001b[33mthr\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    346\u001b[39m thr_q    = calib[\u001b[33m\"\u001b[39m\u001b[33mq\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 295\u001b[39m, in \u001b[36mmake_alert_from_risk\u001b[39m\u001b[34m(risk, thetas, gammas, fa_target, thr)\u001b[39m\n\u001b[32m    292\u001b[39m         state.append(\u001b[33m'\u001b[39m\u001b[33mWARNING\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m    293\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    294\u001b[39m     \u001b[38;5;66;03m# persistence: at least 2 of last 3 days above t\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m295\u001b[39m     persist = (\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m.iloc[i] >= \u001b[32m2\u001b[39m)\n\u001b[32m    296\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (r>=t) \u001b[38;5;129;01mand\u001b[39;00m persist \u001b[38;5;129;01mand\u001b[39;00m (v >= GATE_MIN_VOTES):\n\u001b[32m    297\u001b[39m         in_warn=\u001b[38;5;28;01mTrue\u001b[39;00m; below=\u001b[32m0\u001b[39m; warn_len=\u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:7372\u001b[39m, in \u001b[36mNDFrame.fillna\u001b[39m\u001b[34m(self, value, method, axis, inplace, limit, downcast)\u001b[39m\n\u001b[32m   7365\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   7366\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[32m   7367\u001b[39m             \u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mvalue\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m parameter must be a scalar, dict \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7368\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mor Series, but you passed a \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   7369\u001b[39m             \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(value).\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   7370\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m7372\u001b[39m     new_data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_mgr\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfillna\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   7373\u001b[39m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\n\u001b[32m   7374\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   7376\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, (\u001b[38;5;28mdict\u001b[39m, ABCSeries)):\n\u001b[32m   7377\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m axis == \u001b[32m1\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\base.py:186\u001b[39m, in \u001b[36mDataManager.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast)\u001b[39m\n\u001b[32m    182\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m limit \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    183\u001b[39m     \u001b[38;5;66;03m# Do this validation even if we go through one of the no-op paths\u001b[39;00m\n\u001b[32m    184\u001b[39m     limit = libalgos.validate_limit(\u001b[38;5;28;01mNone\u001b[39;00m, limit=limit)\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_with_block\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    187\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfillna\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    188\u001b[39m \u001b[43m    \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m=\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    189\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    190\u001b[39m \u001b[43m    \u001b[49m\u001b[43minplace\u001b[49m\u001b[43m=\u001b[49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    191\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdowncast\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[43m=\u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43malready_warned\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_AlreadyWarned\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:363\u001b[39m, in \u001b[36mBaseBlockManager.apply\u001b[39m\u001b[34m(self, f, align_keys, **kwargs)\u001b[39m\n\u001b[32m    361\u001b[39m         applied = b.apply(f, **kwargs)\n\u001b[32m    362\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m363\u001b[39m         applied = \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    364\u001b[39m     result_blocks = extend_blocks(applied, result_blocks)\n\u001b[32m    366\u001b[39m out = \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m).from_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m.axes)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\internals\\blocks.py:1729\u001b[39m, in \u001b[36mBlock.fillna\u001b[39m\u001b[34m(self, value, limit, inplace, downcast, using_cow, already_warned)\u001b[39m\n\u001b[32m   1727\u001b[39m     noop = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m   1728\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1729\u001b[39m     mask = \u001b[43misna\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1730\u001b[39m     mask, noop = validate_putmask(\u001b[38;5;28mself\u001b[39m.values, mask)\n\u001b[32m   1732\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m noop:\n\u001b[32m   1733\u001b[39m     \u001b[38;5;66;03m# we can't process the value, but nothing to do\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:178\u001b[39m, in \u001b[36misna\u001b[39m\u001b[34m(obj)\u001b[39m\n\u001b[32m    101\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34misna\u001b[39m(obj: \u001b[38;5;28mobject\u001b[39m) -> \u001b[38;5;28mbool\u001b[39m | npt.NDArray[np.bool_] | NDFrame:\n\u001b[32m    102\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    103\u001b[39m \u001b[33;03m    Detect missing values for an array-like object.\u001b[39;00m\n\u001b[32m    104\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    Name: 1, dtype: bool\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:207\u001b[39m, in \u001b[36m_isna\u001b[39m\u001b[34m(obj, inf_as_na)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, (np.ndarray, ABCExtensionArray)):\n\u001b[32m--> \u001b[39m\u001b[32m207\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_isna_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m=\u001b[49m\u001b[43minf_as_na\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, ABCIndex):\n\u001b[32m    209\u001b[39m     \u001b[38;5;66;03m# Try to use cached isna, which also short-circuits for integer dtypes\u001b[39;00m\n\u001b[32m    210\u001b[39m     \u001b[38;5;66;03m#  and avoids materializing RangeIndex._values\u001b[39;00m\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m obj._can_hold_na:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\dtypes\\missing.py:300\u001b[39m, in \u001b[36m_isna_array\u001b[39m\u001b[34m(values, inf_as_na)\u001b[39m\n\u001b[32m    298\u001b[39m         result = ~np.isfinite(values)\n\u001b[32m    299\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m300\u001b[39m         result = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a — supervised calibration (onset-in-next-K), hard-gated warnings, FA/yr control ===\n",
    "import os, json, time, sys, subprocess, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# ---- bootstrap ----\n",
    "def need(pkg):\n",
    "    try: __import__(pkg); return False\n",
    "    except Exception: return True\n",
    "def pip_install(pkgs):\n",
    "    for p in pkgs:\n",
    "        if need(p):\n",
    "            print(f\"[setup] installing {p} …\")\n",
    "            subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", p], check=False)\n",
    "\n",
    "pip_install([\"yfinance\",\"meteostat\",\"scikit-learn\",\"scipy\"])\n",
    "\n",
    "import yfinance as yf\n",
    "from meteostat import Point, Daily\n",
    "from scipy.signal import coherence\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "# ===== CONFIG =====\n",
    "LAT, LON = 40.7128, -74.0060\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # label = onset in next K days\n",
    "EVENT_KSIGMA = 3.0              # spike\n",
    "VOL_BREAK_Q = 0.995             # vol breakout quantile\n",
    "VOL_BREAK_WIN = 252*3\n",
    "DD_WIN = 40\n",
    "DD_FRAC = 0.10\n",
    "MIN_CLUSTER_LEN = 3\n",
    "COUPLING_WIN = 400\n",
    "\n",
    "# Warning state controls\n",
    "GATE_THETA_MIN = 0.25           # channel intensity gate\n",
    "GAMMA_VIX_MIN  = 0.08\n",
    "GATE_MIN_VOTES = 3              # require this many votes to start\n",
    "COOLDOWN_BETWEEN_STARTS = 18\n",
    "MAX_WARN_DAYS = 12\n",
    "HYST_EXIT_DAYS = 3\n",
    "FA_PER_YEAR_TARGET = 0.50       # calibrate threshold on TRAIN to not exceed this\n",
    "\n",
    "# Train/Test split (calibrate on train, evaluate on all)\n",
    "TRAIN_END = \"2015-12-31\"\n",
    "\n",
    "# ===== PATHS =====\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v03a\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name): fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name): fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# ===== helpers =====\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]; h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "def glyph_coupling(a, b, fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    mask = np.isfinite(a)&np.isfinite(b); a,b = a[mask], b[mask]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    f,Cxy = coherence(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "    band = (f>0.02)&(f<0.25); v = Cxy[band]; v = v[np.isfinite(v)]\n",
    "    return float(v.mean()) if v.size else np.nan\n",
    "\n",
    "# ===== data =====\n",
    "def get_px(tkr, auto_adjust=True):\n",
    "    try:\n",
    "        h = yf.Ticker(tkr).history(period=\"max\", auto_adjust=auto_adjust)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] history {tkr}:\", e)\n",
    "    try:\n",
    "        s = yf.download(tkr, period=\"max\", interval=\"1d\", auto_adjust=auto_adjust, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] download {tkr}:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e: print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "px  = get_px(\"SPY\",  auto_adjust=True)\n",
    "vix = get_px(\"^VIX\", auto_adjust=False)\n",
    "hyg = get_px(\"HYG\",  auto_adjust=True)\n",
    "ief = get_px(\"IEF\",  auto_adjust=True)\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, hyg, ief, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "\n",
    "if len(px)>0:  df['px']  = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0: df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(hyg)>0 and len(ief)>0:\n",
    "    ratio = (hyg / ief).reindex(df.index).ffill()\n",
    "    df['cred_ret'] = ratio.pct_change()\n",
    "if len(ta)>0:  df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# ===== features =====\n",
    "# market\n",
    "if 'ret' in df:\n",
    "    m = df['ret'].fillna(0.0).values; mz = zscore_mad(m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(mz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "# vix\n",
    "if 'dvix' in df:\n",
    "    v = df['dvix'].fillna(0.0).values; vz = zscore_mad(v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(vz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "# credit\n",
    "if 'cred_ret' in df:\n",
    "    c = df['cred_ret'].fillna(0.0).values; cz = zscore_mad(c, win=512)\n",
    "    df['S_d_cred']   = rolling_entropy(c, win=256, bins=48)\n",
    "    df['AR1_cred']   = rolling_ar1(c, win=256)\n",
    "    df['Theta_cred'] = theta_breaches(cz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_cred']=df['AR1_cred']=df['Theta_cred']=np.nan\n",
    "# temp (weak weight, but keep as context)\n",
    "if 'temp_anom' in df:\n",
    "    t = df['temp_anom'].fillna(0.0).values; tz = zscore_mad(t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(tz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# hetero-couplings\n",
    "df['Gamma_mkt_vix']=np.nan; df['Gamma_mkt_cred']=np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a,b,fs=1.0)\n",
    "if 'ret' in df and 'cred_ret' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['cred_ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_cred')] = glyph_coupling(a,b,fs=1.0)\n",
    "\n",
    "# ===== regime events -> sustained clusters -> ONSETS =====\n",
    "metrics={}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10  = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol  = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int).reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # cluster sustained regimes, mark onsets\n",
    "    onset = np.zeros(len(df), dtype=int)\n",
    "    arr = E.values; i=0\n",
    "    while i < len(arr):\n",
    "        if arr[i]==1:\n",
    "            j=i\n",
    "            while j+1<len(arr) and arr[j+1]==1: j+=1\n",
    "            if (j-i+1) >= MIN_CLUSTER_LEN: onset[i]=1\n",
    "            i = j+1\n",
    "        else:\n",
    "            i+=1\n",
    "    df['EVENT_ONSET'] = onset\n",
    "\n",
    "    # ===== supervised calibration: label = onset within next K days =====\n",
    "    y_future = pd.Series(df['EVENT_ONSET']).rolling(LOOKAHEAD_D, min_periods=1).max().shift(-(LOOKAHEAD_D-1))\n",
    "    y_future = y_future.reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # Feature matrix (robust z + 7d ramps)\n",
    "    feat_cols = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_vix','AR1_vix','Theta_vix',\n",
    "                 'S_d_cred','AR1_cred','Theta_cred','S_d_tmp','AR1_tmp','Theta_tmp',\n",
    "                 'Gamma_mkt_vix','Gamma_mkt_cred']\n",
    "    F = df[feat_cols].copy().ffill().bfill().fillna(0.0)\n",
    "    # robust z\n",
    "    Z = pd.DataFrame(index=F.index)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        Z[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    DZ7 = Z.diff(7).add_prefix(\"d7_\")\n",
    "    X = pd.concat([Z, DZ7[['d7_AR1_mkt','d7_S_d_mkt','d7_AR1_vix','d7_S_d_vix','d7_Gamma_mkt_vix','d7_Gamma_mkt_cred']].fillna(0.0)], axis=1).fillna(0.0)\n",
    "\n",
    "    # Train / All indices\n",
    "    idx_train = X.index[X.index <= pd.Timestamp(TRAIN_END)]\n",
    "    X_train, y_train = X.loc[idx_train], y_future.loc[idx_train]\n",
    "    if y_train.sum() == 0:\n",
    "        # fallback: relax to any event (not just onset) if train lacks positives\n",
    "        y_train = pd.Series(E, index=df.index).loc[idx_train]\n",
    "\n",
    "    # Fit logistic (balanced)\n",
    "    clf = make_pipeline(StandardScaler(with_mean=False),  # sparse-friendly\n",
    "                        LogisticRegression(max_iter=2000, class_weight=\"balanced\", solver=\"lbfgs\"))\n",
    "    clf.fit(X_train.values, y_train.values)\n",
    "\n",
    "    # Risk probability\n",
    "    risk_all = pd.Series(clf.predict_proba(X.values)[:,1], index=X.index, name=\"RISK\")\n",
    "    df['RISK'] = risk_all\n",
    "\n",
    "    # ===== threshold calibration on TRAIN to meet FA/yr target =====\n",
    "    def make_alert_from_risk(risk, thetas, gammas, fa_target=None, thr=None):\n",
    "        # Build gated WARNING state from risk\n",
    "        Theta_m, Theta_v, Theta_c = thetas\n",
    "        Gamma_v = gammas[0]\n",
    "        risk = pd.Series(risk).fillna(0.0)\n",
    "        votes_series = (\n",
    "            (Theta_v >= GATE_THETA_MIN).astype(int) +\n",
    "            (Theta_c >= GATE_THETA_MIN).astype(int) +\n",
    "            (Theta_m >= GATE_THETA_MIN).astype(int) +\n",
    "            (Gamma_v >= GAMMA_VIX_MIN).astype(int) +\n",
    "            ((risk - risk.shift(7)) > 0).astype(int)\n",
    "        ).fillna(0).astype(int)\n",
    "\n",
    "        if thr is None:\n",
    "            qgrid = np.linspace(0.990, 0.9995, 20)  # strict thresholds\n",
    "        else:\n",
    "            qgrid = [thr]\n",
    "\n",
    "        best = None\n",
    "        for q in qgrid:\n",
    "            t = risk.quantile(q)\n",
    "            in_warn=False; below=0; warn_len=0\n",
    "            state=[]\n",
    "            for i,(r,v) in enumerate(zip(risk.values, votes_series.values)):\n",
    "                if in_warn:\n",
    "                    warn_len += 1\n",
    "                    if r < 0.9*t: below += 1\n",
    "                    else: below = 0\n",
    "                    if below >= HYST_EXIT_DAYS or warn_len >= MAX_WARN_DAYS:\n",
    "                        in_warn=False; warn_len=0\n",
    "                        state.append('OK')\n",
    "                    else:\n",
    "                        state.append('WARNING')\n",
    "                else:\n",
    "                    # persistence: at least 2 of last 3 days above t\n",
    "                    persist = (pd.Series(risk.values).rolling(3).apply(lambda w: (w>=t).sum(), raw=True).fillna(0).iloc[i] >= 2)\n",
    "                    if (r>=t) and persist and (v >= GATE_MIN_VOTES):\n",
    "                        in_warn=True; below=0; warn_len=1\n",
    "                        state.append('WARNING')\n",
    "                    else:\n",
    "                        state.append('OK')\n",
    "            alert = pd.Series(state, index=risk.index)\n",
    "\n",
    "            # starts / hits / FA against ONSET label y_future (on TRAIN or eval slice where provided)\n",
    "            starts = (alert.eq(\"WARNING\") & ~alert.shift(1).eq(\"WARNING\")).fillna(False)\n",
    "            s_ix = list(np.where(starts.values)[0])\n",
    "            # cooldown\n",
    "            kept=[]; last=-10**9\n",
    "            for s in s_ix:\n",
    "                if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "            s_ix = kept\n",
    "\n",
    "            e_ix = list(np.where(df.loc[risk.index, 'EVENT_ONSET'].values==1)[0]); e_set=set(e_ix)\n",
    "            hits=0\n",
    "            for s in s_ix:\n",
    "                for j in range(1, LOOKAHEAD_D+1):\n",
    "                    if (s+j) in e_set: hits += 1; break\n",
    "            false_alarms = int(len(s_ix) - hits)\n",
    "            years = max(1e-9, (risk.index[-1]-risk.index[0]).days/365.25)\n",
    "            fa_per_year = false_alarms / years\n",
    "\n",
    "            cand = {\"thr\": float(t), \"q\": float(q), \"starts\": len(s_ix), \"hits\": hits,\n",
    "                    \"fa_per_year\": fa_per_year, \"alert\": alert}\n",
    "            if fa_target is None:\n",
    "                best = cand; break\n",
    "            else:\n",
    "                # pick highest hits under FA target; tie-break by lowest fa_per_year\n",
    "                if (best is None) or \\\n",
    "                   ((cand[\"fa_per_year\"] <= fa_target) and\n",
    "                    (cand[\"hits\"] > best.get(\"hits_ok\", -1))) or \\\n",
    "                   ((cand[\"fa_per_year\"] <= fa_target) and\n",
    "                    (cand[\"hits\"] == best.get(\"hits_ok\", -1)) and (cand[\"fa_per_year\"] < best[\"fa_per_year\"])):\n",
    "                    best = cand.copy()\n",
    "                    best[\"hits_ok\"] = hits\n",
    "        return best\n",
    "\n",
    "    thetas_train = (df['Theta_mkt'].loc[idx_train].fillna(0.0),\n",
    "                    df['Theta_vix'].loc[idx_train].fillna(0.0),\n",
    "                    df['Theta_cred'].loc[idx_train].fillna(0.0))\n",
    "    gammas_train = (df['Gamma_mkt_vix'].loc[idx_train].fillna(0.0),)\n",
    "\n",
    "    calib = make_alert_from_risk(risk_all.loc[idx_train],\n",
    "                                 thetas_train, gammas_train,\n",
    "                                 fa_target=FA_PER_YEAR_TARGET)\n",
    "\n",
    "    thr_prob = calib[\"thr\"]\n",
    "    thr_q    = calib[\"q\"]\n",
    "\n",
    "    # ===== apply calibrated threshold to FULL series =====\n",
    "    thetas_all = (df['Theta_mkt'].fillna(0.0), df['Theta_vix'].fillna(0.0), df['Theta_cred'].fillna(0.0))\n",
    "    gammas_all = (df['Gamma_mkt_vix'].fillna(0.0),)\n",
    "    final = make_alert_from_risk(risk_all, thetas_all, gammas_all, thr=thr_q)\n",
    "    df['alert'] = final[\"alert\"]\n",
    "\n",
    "    # Metrics (full)\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = list(np.where(starts.values)[0])\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    y_on = df['EVENT_ONSET'].values\n",
    "    e_ix = list(np.where(y_on==1)[0]); e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit - s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25)\n",
    "    fa_per_year = false_alarms/years\n",
    "\n",
    "    # Lead PR-AUC (ranking by risk K days ahead)\n",
    "    auc_lead={}\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        yk = y_on[k:]\n",
    "        xk = risk_all.shift(k).iloc[k:].values\n",
    "        auc_lead[k] = float(average_precision_score(yk, xk)) if yk.sum()>0 else float('nan')\n",
    "\n",
    "    # Coverage of onsets by starts within prior K\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t in s_set) for t in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    warn_days = int((df['alert']==\"WARNING\").sum())\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)),\n",
    "        \"years\": float(years),\n",
    "        \"event_onsets_total\": int(df['EVENT_ONSET'].sum()),\n",
    "        \"calibrated_thr_quantile_train\": float(thr_q),\n",
    "        \"calibrated_thr_prob\": float(thr_prob),\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"warning_starts\": int(len(s_ix)),\n",
    "        \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits),\n",
    "        \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(fa_per_year),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"auc_pr_lead_curve\": auc_lead,\n",
    "        \"coverage_onsets\": coverage_by_k,\n",
    "        \"warning_days\": warn_days,\n",
    "        \"gate\": {\"theta_min\": GATE_THETA_MIN, \"gamma_vix_min\": GAMMA_VIX_MIN, \"min_votes\": GATE_MIN_VOTES},\n",
    "        \"cooldown_days\": COOLDOWN_BETWEEN_STARTS,\n",
    "        \"max_warn_days\": MAX_WARN_DAYS\n",
    "    }\n",
    "\n",
    "# ===== persist =====\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df[['RISK','alert','EVENT_ONSET'] + [c for c in df.columns if c.startswith('S_d_') or c.startswith('AR1_') or c.startswith('Theta_') or c.startswith('Gamma_')]], \"gdren_v03a_features\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v03a_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END, \"lookahead\": LOOKAHEAD_D},\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"notes\": \"v0.3a — logistic risk for onset-in-next-K, threshold calibrated on TRAIN to cap FA/yr; gated WARNING.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.3a SKILL (calibrated) ===\")\n",
    "    for k in [\"samples\",\"years\",\"event_onsets_total\",\"calibrated_thr_quantile_train\",\n",
    "              \"warning_starts\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "              \"lead_time_days_median\",\"lead_time_days_mean\"]:\n",
    "        print(f\"{k:>28}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_onsets   (K→cov):\", metrics[\"coverage_onsets\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "37069365-2b63-4de7-b92a-9fe8b586c615",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'count'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 374\u001b[39m\n\u001b[32m    368\u001b[39m t = np.quantile(risk[np.isfinite(risk)], thr_q)\n\u001b[32m    369\u001b[39m votes = ((Theta_v>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    370\u001b[39m          (Theta_c>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    371\u001b[39m          (Theta_m>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    372\u001b[39m          (Gamma_v>=GAMMA_VIX_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    373\u001b[39m          ((pd.Series(risk).diff(\u001b[32m7\u001b[39m).fillna(\u001b[32m0.0\u001b[39m).values)>\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m persist = (\u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSeries\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrisk\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrolling\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m3\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m.fillna(\u001b[32m0\u001b[39m).values >= \u001b[32m2\u001b[39m)\n\u001b[32m    376\u001b[39m state=[]; in_warn=\u001b[38;5;28;01mFalse\u001b[39;00m; below=\u001b[32m0\u001b[39m; wlen=\u001b[32m0\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,(r,v,pers) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(risk, votes, persist)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:2049\u001b[39m, in \u001b[36mRolling.apply\u001b[39m\u001b[34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[39m\n\u001b[32m   2016\u001b[39m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[32m   2017\u001b[39m     template_header,\n\u001b[32m   2018\u001b[39m     create_section_header(\u001b[33m\"\u001b[39m\u001b[33mParameters\u001b[39m\u001b[33m\"\u001b[39m),\n\u001b[32m   (...)\u001b[39m\u001b[32m   2047\u001b[39m     kwargs: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any] | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   2048\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m2049\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2050\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2051\u001b[39m \u001b[43m        \u001b[49m\u001b[43mraw\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2052\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2054\u001b[39m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m=\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2055\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2056\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1508\u001b[39m, in \u001b[36mRollingAndExpandingMixin.apply\u001b[39m\u001b[34m(self, func, raw, engine, engine_kwargs, args, kwargs)\u001b[39m\n\u001b[32m   1505\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1506\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mengine must be either \u001b[39m\u001b[33m'\u001b[39m\u001b[33mnumba\u001b[39m\u001b[33m'\u001b[39m\u001b[33m or \u001b[39m\u001b[33m'\u001b[39m\u001b[33mcython\u001b[39m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1508\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1509\u001b[39m \u001b[43m    \u001b[49m\u001b[43mapply_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1510\u001b[39m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mapply\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1511\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1512\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:619\u001b[39m, in \u001b[36mBaseWindow._apply\u001b[39m\u001b[34m(self, func, name, numeric_only, numba_args, **kwargs)\u001b[39m\n\u001b[32m    616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.method == \u001b[33m\"\u001b[39m\u001b[33msingle\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_columnwise\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumeric_only\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._apply_tablewise(homogeneous_func, name, numeric_only)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:472\u001b[39m, in \u001b[36mBaseWindow._apply_columnwise\u001b[39m\u001b[34m(self, homogeneous_func, name, numeric_only)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_numeric_only(name, numeric_only)\n\u001b[32m    471\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._selected_obj.ndim == \u001b[32m1\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_apply_series\u001b[49m\u001b[43m(\u001b[49m\u001b[43mhomogeneous_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    474\u001b[39m obj = \u001b[38;5;28mself\u001b[39m._create_data(\u001b[38;5;28mself\u001b[39m._selected_obj, numeric_only)\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m name == \u001b[33m\"\u001b[39m\u001b[33mcount\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    476\u001b[39m     \u001b[38;5;66;03m# GH 12541: Special case for count where we support date-like types\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:456\u001b[39m, in \u001b[36mBaseWindow._apply_series\u001b[39m\u001b[34m(self, homogeneous_func, name)\u001b[39m\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, \u001b[38;5;167;01mNotImplementedError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[32m    454\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m DataError(\u001b[33m\"\u001b[39m\u001b[33mNo numeric types to aggregate\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m result = \u001b[43mhomogeneous_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m index = \u001b[38;5;28mself\u001b[39m._slice_axis_for_step(obj.index, result)\n\u001b[32m    458\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m obj._constructor(result, index=index, name=obj.name)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:614\u001b[39m, in \u001b[36mBaseWindow._apply.<locals>.homogeneous_func\u001b[39m\u001b[34m(values)\u001b[39m\n\u001b[32m    611\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m func(x, start, end, min_periods, *numba_args)\n\u001b[32m    613\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m np.errstate(\u001b[38;5;28mall\u001b[39m=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m614\u001b[39m     result = \u001b[43mcalc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:611\u001b[39m, in \u001b[36mBaseWindow._apply.<locals>.homogeneous_func.<locals>.calc\u001b[39m\u001b[34m(x)\u001b[39m\n\u001b[32m    602\u001b[39m start, end = window_indexer.get_window_bounds(\n\u001b[32m    603\u001b[39m     num_values=\u001b[38;5;28mlen\u001b[39m(x),\n\u001b[32m    604\u001b[39m     min_periods=min_periods,\n\u001b[32m   (...)\u001b[39m\u001b[32m    607\u001b[39m     step=\u001b[38;5;28mself\u001b[39m.step,\n\u001b[32m    608\u001b[39m )\n\u001b[32m    609\u001b[39m \u001b[38;5;28mself\u001b[39m._check_window_bounds(start, end, \u001b[38;5;28mlen\u001b[39m(x))\n\u001b[32m--> \u001b[39m\u001b[32m611\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mnumba_args\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\window\\rolling.py:1535\u001b[39m, in \u001b[36mRollingAndExpandingMixin._generate_cython_apply_func.<locals>.apply_func\u001b[39m\u001b[34m(values, begin, end, min_periods, raw)\u001b[39m\n\u001b[32m   1532\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw:\n\u001b[32m   1533\u001b[39m     \u001b[38;5;66;03m# GH 45912\u001b[39;00m\n\u001b[32m   1534\u001b[39m     values = Series(values, index=\u001b[38;5;28mself\u001b[39m._on, copy=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1535\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwindow_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbegin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_periods\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mpandas/_libs/window/aggregations.pyx:1420\u001b[39m, in \u001b[36mpandas._libs.window.aggregations.roll_apply\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 374\u001b[39m, in \u001b[36m<lambda>\u001b[39m\u001b[34m(w)\u001b[39m\n\u001b[32m    368\u001b[39m t = np.quantile(risk[np.isfinite(risk)], thr_q)\n\u001b[32m    369\u001b[39m votes = ((Theta_v>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    370\u001b[39m          (Theta_c>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    371\u001b[39m          (Theta_m>=GATE_THETA_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    372\u001b[39m          (Gamma_v>=GAMMA_VIX_MIN).astype(\u001b[38;5;28mint\u001b[39m) +\n\u001b[32m    373\u001b[39m          ((pd.Series(risk).diff(\u001b[32m7\u001b[39m).fillna(\u001b[32m0.0\u001b[39m).values)>\u001b[32m0\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m))\n\u001b[32m--> \u001b[39m\u001b[32m374\u001b[39m persist = (pd.Series(risk).rolling(\u001b[32m3\u001b[39m).apply(\u001b[38;5;28;01mlambda\u001b[39;00m w: \u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m>\u001b[49m\u001b[43m=\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcount\u001b[49m(), raw=\u001b[38;5;28;01mTrue\u001b[39;00m).fillna(\u001b[32m0\u001b[39m).values >= \u001b[32m2\u001b[39m)\n\u001b[32m    376\u001b[39m state=[]; in_warn=\u001b[38;5;28;01mFalse\u001b[39;00m; below=\u001b[32m0\u001b[39m; wlen=\u001b[32m0\u001b[39m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i,(r,v,pers) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mzip\u001b[39m(risk, votes, persist)):\n",
      "\u001b[31mAttributeError\u001b[39m: 'numpy.ndarray' object has no attribute 'count'"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a-lite — no sklearn; NumPy IRLS logistic + pure-NumPy AP; gated WARNINGs ===\n",
    "import os, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -------- config --------\n",
    "LAT, LON = 40.7128, -74.0060\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # label = onset in next K days\n",
    "EVENT_KSIGMA = 3.0              # spike threshold (try 2.5–3.0)\n",
    "VOL_BREAK_Q = 0.995             # vol breakout quantile\n",
    "VOL_BREAK_WIN = 252*3\n",
    "DD_WIN = 40\n",
    "DD_FRAC = 0.10\n",
    "MIN_CLUSTER_LEN = 3\n",
    "COUPLING_WIN = 400\n",
    "\n",
    "# Warning/gating & calibration\n",
    "GATE_THETA_MIN = 0.25\n",
    "GAMMA_VIX_MIN  = 0.08\n",
    "GATE_MIN_VOTES = 3\n",
    "COOLDOWN_BETWEEN_STARTS = 18\n",
    "MAX_WARN_DAYS = 12\n",
    "HYST_EXIT_DAYS = 3\n",
    "FA_PER_YEAR_TARGET = 0.50\n",
    "TRAIN_END = \"2015-12-31\"\n",
    "\n",
    "# -------- paths --------\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v03a_lite\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name): fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name): fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# -------- small utils (tz, robust z, coherence fallback, AP, IRLS) --------\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]; h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "# coherence fallback if SciPy absent\n",
    "try:\n",
    "    from scipy.signal import coherence as _coh\n",
    "    def coherence_band(a,b,fs=1.0):\n",
    "        f,Cxy = _coh(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "        band = (f>0.02)&(f<0.25)\n",
    "        v = Cxy[band]\n",
    "        v = v[np.isfinite(v)]\n",
    "        return float(v.mean()) if v.size else np.nan\n",
    "except Exception:\n",
    "    def coherence_band(a,b,fs=1.0):\n",
    "        return np.nan\n",
    "\n",
    "def glyph_coupling(a,b,fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    m = np.isfinite(a)&np.isfinite(b); a,b = a[m], b[m]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    return coherence_band(a,b,fs)\n",
    "\n",
    "def average_precision_np(y_true, y_score):\n",
    "    y = np.asarray(y_true).astype(int)\n",
    "    s = np.asarray(y_score, float)\n",
    "    m = np.isfinite(s)\n",
    "    y, s = y[m], s[m]\n",
    "    P = y.sum()\n",
    "    if P == 0: return float('nan')\n",
    "    order = np.argsort(-s)\n",
    "    y_sorted = y[order]\n",
    "    tp = np.cumsum(y_sorted)\n",
    "    prec = tp / (np.arange(len(y_sorted))+1)\n",
    "    ap = prec[y_sorted==1].sum() / P\n",
    "    return float(ap)\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -30, 30)\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def logistic_ridge_fit(X, y, l2=1e-2, max_iter=200, tol=1e-6):\n",
    "    # X: (n,p) already scaled; add intercept inside\n",
    "    n,p = X.shape\n",
    "    X_ = np.hstack([np.ones((n,1)), X])\n",
    "    beta = np.zeros(p+1)\n",
    "    eps = 1e-9\n",
    "    for _ in range(max_iter):\n",
    "        z = X_ @ beta\n",
    "        mu = sigmoid(z)\n",
    "        w = mu*(1-mu) + eps\n",
    "        # IRLS normal equations: (X' W X + λI) β = X' W (z + (y-μ)/w)\n",
    "        z_tilde = z + (y - mu)/w\n",
    "        # compute A = X' W X and b = X' W z_tilde\n",
    "        WX = X_ * w[:,None]\n",
    "        A = X_.T @ WX\n",
    "        # ridge (do not penalize intercept)\n",
    "        A[1:,1:] += l2*np.eye(p)\n",
    "        b = X_.T @ (w * z_tilde)\n",
    "        beta_new = np.linalg.solve(A, b)\n",
    "        if np.max(np.abs(beta_new - beta)) < tol:\n",
    "            beta = beta_new; break\n",
    "        beta = beta_new\n",
    "    return beta\n",
    "\n",
    "def logistic_predict_proba(X, beta):\n",
    "    X_ = np.hstack([np.ones((X.shape[0],1)), X])\n",
    "    return sigmoid(X_ @ beta)\n",
    "\n",
    "# -------- data loaders (no installs) --------\n",
    "def get_px(tkr, auto_adjust=True):\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        h = yf.Ticker(tkr).history(period=\"max\", auto_adjust=auto_adjust)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] history {tkr}:\", e)\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        s = yf.download(tkr, period=\"max\", interval=\"1d\", auto_adjust=auto_adjust, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] download {tkr}:\", e)\n",
    "    # last resort: SPY from Stooq\n",
    "    if tkr.upper()==\"SPY\":\n",
    "        try:\n",
    "            url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "            stq = pd.read_csv(url); stq.columns=[c.lower() for c in stq.columns]\n",
    "            stq['date']=pd.to_datetime(stq['date'])\n",
    "            stq = stq.set_index('date').sort_index()\n",
    "            return normalize_series_daily(stq['close'].rename('SPY').astype(float))\n",
    "        except Exception as e: print(\"[error] stooq SPY:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        from meteostat import Point, Daily\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e: print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "# -------- ingest --------\n",
    "px  = get_px(\"SPY\",  auto_adjust=True)\n",
    "vix = get_px(\"^VIX\", auto_adjust=False)\n",
    "hyg = get_px(\"HYG\",  auto_adjust=True)\n",
    "ief = get_px(\"IEF\",  auto_adjust=True)\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, hyg, ief, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0:  df['px']  = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0: df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(hyg)>0 and len(ief)>0:\n",
    "    ratio = (hyg / ief).reindex(df.index).ffill()\n",
    "    df['cred_ret'] = ratio.pct_change()\n",
    "if len(ta)>0:  df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# -------- features --------\n",
    "# market\n",
    "if 'ret' in df:\n",
    "    m = df['ret'].fillna(0.0).values; mz = zscore_mad(m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(mz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "# vix\n",
    "if 'dvix' in df:\n",
    "    v = df['dvix'].fillna(0.0).values; vz = zscore_mad(v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(vz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "# credit\n",
    "if 'cred_ret' in df:\n",
    "    c = df['cred_ret'].fillna(0.0).values; cz = zscore_mad(c, win=512)\n",
    "    df['S_d_cred']   = rolling_entropy(c, win=256, bins=48)\n",
    "    df['AR1_cred']   = rolling_ar1(c, win=256)\n",
    "    df['Theta_cred'] = theta_breaches(cz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_cred']=df['AR1_cred']=df['Theta_cred']=np.nan\n",
    "# temp\n",
    "if 'temp_anom' in df:\n",
    "    t = df['temp_anom'].fillna(0.0).values; tz = zscore_mad(t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(tz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# couplings\n",
    "df['Gamma_mkt_vix']=np.nan; df['Gamma_mkt_cred']=np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a,b,fs=1.0)\n",
    "if 'ret' in df and 'cred_ret' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['cred_ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_cred')] = glyph_coupling(a,b,fs=1.0)\n",
    "\n",
    "# -------- regime events → sustained clusters → ONSETS --------\n",
    "metrics = {}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10  = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol  = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int).reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # sustained cluster onsets\n",
    "    onset = np.zeros(len(df), dtype=int)\n",
    "    i=0; arr=E.values\n",
    "    while i<len(arr):\n",
    "        if arr[i]==1:\n",
    "            j=i\n",
    "            while j+1<len(arr) and arr[j+1]==1: j+=1\n",
    "            if (j-i+1) >= MIN_CLUSTER_LEN: onset[i]=1\n",
    "            i = j+1\n",
    "        else:\n",
    "            i+=1\n",
    "    df['EVENT_ONSET'] = onset\n",
    "\n",
    "    # ----- supervised label = onset in next K days -----\n",
    "    y_future = pd.Series(df['EVENT_ONSET']).rolling(LOOKAHEAD_D, min_periods=1).max().shift(-(LOOKAHEAD_D-1))\n",
    "    y_future = y_future.reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # feature matrix (robust Z + selected ramps)\n",
    "    feat_cols = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_vix','AR1_vix','Theta_vix',\n",
    "                 'S_d_cred','AR1_cred','Theta_cred','S_d_tmp','AR1_tmp','Theta_tmp',\n",
    "                 'Gamma_mkt_vix','Gamma_mkt_cred']\n",
    "    F = df[feat_cols].copy().ffill().bfill().fillna(0.0)\n",
    "    Z = pd.DataFrame(index=F.index)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        Z[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    DZ7 = Z.diff(7).add_prefix(\"d7_\")\n",
    "    X = pd.concat([Z, DZ7[['d7_AR1_mkt','d7_S_d_mkt','d7_AR1_vix','d7_S_d_vix','d7_Gamma_mkt_vix','d7_Gamma_mkt_cred']].fillna(0.0)], axis=1).fillna(0.0)\n",
    "\n",
    "    # train split\n",
    "    idx_train = X.index[X.index <= pd.Timestamp(TRAIN_END)]\n",
    "    X_train, y_train = X.loc[idx_train].values, y_future.loc[idx_train].values.astype(int)\n",
    "    if y_train.sum()==0:\n",
    "        y_train = E.loc[idx_train].values.astype(int)\n",
    "\n",
    "    # IRLS logistic on robust Z (already roughly standardized)\n",
    "    beta = logistic_ridge_fit(X_train, y_train, l2=1e-2, max_iter=300, tol=1e-6)\n",
    "    risk_all = pd.Series(logistic_predict_proba(X.values, beta), index=X.index, name=\"RISK\")\n",
    "    df['RISK'] = risk_all\n",
    "\n",
    "    # ----- threshold calibration on TRAIN to meet FA budget -----\n",
    "    Theta_m_train = df['Theta_mkt'].loc[idx_train].fillna(0.0).values\n",
    "    Theta_v_train = df['Theta_vix'].loc[idx_train].fillna(0.0).values\n",
    "    Theta_c_train = df['Theta_cred'].loc[idx_train].fillna(0.0).values\n",
    "    Gamma_v_train = df['Gamma_mkt_vix'].loc[idx_train].fillna(0.0).values\n",
    "    onset_train   = df['EVENT_ONSET'].loc[idx_train].values.astype(int)\n",
    "    rtrain        = risk_all.loc[idx_train].values\n",
    "\n",
    "    qgrid = np.linspace(0.990, 0.9995, 20)\n",
    "    best = None\n",
    "    for q in qgrid:\n",
    "        t = np.quantile(rtrain[np.isfinite(rtrain)], q)\n",
    "        # votes & persistence\n",
    "        votes = ((Theta_v_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Theta_c_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Theta_m_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Gamma_v_train>=GAMMA_VIX_MIN).astype(int) +\n",
    "                 ((pd.Series(rtrain).diff(7).fillna(0.0).values)>0).astype(int))\n",
    "        persist = (pd.Series(rtrain).rolling(3).apply(lambda w: (w>=t).sum(), raw=True).fillna(0).values >= 2)\n",
    "\n",
    "        # build state\n",
    "        state=[]; in_warn=False; below=0; wlen=0\n",
    "        for i,(r,v,pers) in enumerate(zip(rtrain, votes, persist)):\n",
    "            if in_warn:\n",
    "                wlen += 1\n",
    "                below = below+1 if r < 0.9*t else 0\n",
    "                if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS: in_warn=False; wlen=0; state.append('OK')\n",
    "                else: state.append('WARNING')\n",
    "            else:\n",
    "                if (r>=t) and pers and (v>=GATE_MIN_VOTES): in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "                else: state.append('OK')\n",
    "        state = np.array(state, dtype=object)\n",
    "\n",
    "        # starts → hits/FA vs ONSET on TRAIN\n",
    "        starts = (state=='WARNING') & np.roll(state!='WARNING', 1)\n",
    "        starts[0] = (state[0]=='WARNING')\n",
    "        s_ix = np.where(starts)[0].tolist()\n",
    "        kept=[]; last=-10**9\n",
    "        for s in s_ix:\n",
    "            if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "        s_ix = kept\n",
    "\n",
    "        e_ix = np.where(onset_train==1)[0]; e_set=set(e_ix)\n",
    "        hits=0\n",
    "        for s in s_ix:\n",
    "            if any(((s+j) in e_set) for j in range(1, LOOKAHEAD_D+1)): hits+=1\n",
    "        fa = int(len(s_ix)-hits)\n",
    "        years = max(1e-9, (idx_train[-1]-idx_train[0]).days/365.25)\n",
    "        fa_per_year = fa/years\n",
    "\n",
    "        cand = {\"q\": float(q), \"thr\": float(t), \"hits\": hits, \"fa_py\": fa_per_year}\n",
    "        if (best is None) or ((fa_per_year <= FA_PER_YEAR_TARGET) and (hits > best[\"hits\"])) or \\\n",
    "           ((fa_per_year <= FA_PER_YEAR_TARGET) and (hits == best[\"hits\"]) and (fa_per_year < best[\"fa_py\"])):\n",
    "            best = cand\n",
    "\n",
    "    thr_q, thr_prob = best[\"q\"], best[\"thr\"]\n",
    "\n",
    "    # ----- apply to FULL series -----\n",
    "    Theta_m = df['Theta_mkt'].fillna(0.0).values\n",
    "    Theta_v = df['Theta_vix'].fillna(0.0).values\n",
    "    Theta_c = df['Theta_cred'].fillna(0.0).values\n",
    "    Gamma_v = df['Gamma_mkt_vix'].fillna(0.0).values\n",
    "    risk    = df['RISK'].fillna(0.0).values\n",
    "    t = np.quantile(risk[np.isfinite(risk)], thr_q)\n",
    "    votes = ((Theta_v>=GATE_THETA_MIN).astype(int) +\n",
    "             (Theta_c>=GATE_THETA_MIN).astype(int) +\n",
    "             (Theta_m>=GATE_THETA_MIN).astype(int) +\n",
    "             (Gamma_v>=GAMMA_VIX_MIN).astype(int) +\n",
    "             ((pd.Series(risk).diff(7).fillna(0.0).values)>0).astype(int))\n",
    "    persist = (pd.Series(risk).rolling(3).apply(lambda w: (w>=t).count(), raw=True).fillna(0).values >= 2)\n",
    "\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    for i,(r,v,pers) in enumerate(zip(risk, votes, persist)):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS: in_warn=False; wlen=0; state.append('OK')\n",
    "            else: state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and pers and (v>=GATE_MIN_VOTES): in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else: state.append('OK')\n",
    "    df['alert'] = state\n",
    "\n",
    "    # ----- full metrics -----\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = np.where(starts.values)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    y_on = df['EVENT_ONSET'].values\n",
    "    e_ix = np.where(y_on==1)[0]; e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit-s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25)\n",
    "    fa_per_year = false_alarms/years\n",
    "\n",
    "    # lead PR-AUC with our AP\n",
    "    auc_lead={}\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        yk = y_on[k:]\n",
    "        xk = pd.Series(risk).shift(k).iloc[k:].values\n",
    "        auc_lead[k] = average_precision_np(yk, xk) if yk.sum()>0 else float('nan')\n",
    "\n",
    "    # onset coverage by starts in prior K days\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t0 in s_set) for t0 in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)), \"years\": float(years),\n",
    "        \"event_onsets_total\": int(df['EVENT_ONSET'].sum()),\n",
    "        \"calibrated_thr_quantile_train\": float(thr_q),\n",
    "        \"calibrated_thr_prob\": float(thr_prob),\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"warning_starts\": int(len(s_ix)), \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits), \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(fa_per_year),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"auc_pr_lead_curve\": auc_lead, \"coverage_onsets\": coverage_by_k,\n",
    "        \"warning_days\": int((df['alert']==\"WARNING\").sum()),\n",
    "        \"gate\": {\"theta_min\": GATE_THETA_MIN, \"gamma_vix_min\": GAMMA_VIX_MIN, \"min_votes\": GATE_MIN_VOTES},\n",
    "        \"cooldown_days\": COOLDOWN_BETWEEN_STARTS, \"max_warn_days\": MAX_WARN_DAYS\n",
    "    }\n",
    "\n",
    "# -------- persist --------\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df[['RISK','alert','EVENT_ONSET'] + [c for c in df.columns\n",
    "                     if c.startswith(('S_d_','AR1_','Theta_','Gamma_'))]], \"gdren_v03a_lite_features\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v03a_lite_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END, \"lookahead\": LOOKAHEAD_D},\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"notes\": \"v0.3a-lite — removed sklearn; IRLS logistic + NumPy AP; gated WARNING; calibrated threshold.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.3a-lite SKILL (calibrated) ===\")\n",
    "    for k in [\"samples\",\"years\",\"event_onsets_total\",\"calibrated_thr_quantile_train\",\n",
    "              \"warning_starts\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "              \"lead_time_days_median\",\"lead_time_days_mean\"]:\n",
    "        print(f\"{k:>28}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_onsets   (K→cov):\", metrics[\"coverage_onsets\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f27a064c-b1bc-4fd1-9b8f-006aea9175ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"features_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-230753Z_v03a_lite_fix\\\\gdren_v03a_lite_fix_features.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-230753Z_v03a_lite_fix\\\\gdren_v03a_lite_fix_metrics.json\",\n",
      "  \"meta_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-230753Z_v03a_lite_fix\\\\meta.json\"\n",
      "}\n",
      "\n",
      "=== v0.3a-lite SKILL (calibrated) ===\n",
      "                     samples: 11394\n",
      "                       years: 35.841204654346335\n",
      "          event_onsets_total: 45\n",
      "calibrated_thr_quantile_train: 0.99\n",
      "              warning_starts: 0\n",
      "                        hits: 0\n",
      "                false_alarms: 0\n",
      "       false_alarms_per_year: 0.0\n",
      "       lead_time_days_median: None\n",
      "         lead_time_days_mean: None\n",
      " auc_pr_lead_curve (k→AUC): {1: 0.0038998667934615114, 2: 0.0039006333315377045, 3: 0.0039004217787224067, 4: 0.0039008745657014665, 5: 0.0039000362672410877, 6: 0.0038998139332011117, 7: 0.003901709916340501}\n",
      " coverage_onsets   (K→cov): {1: 0.0, 2: 0.0, 3: 0.0, 4: 0.0, 5: 0.0, 6: 0.0, 7: 0.0}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a-lite (FIXED) — no sklearn; IRLS logistic + NumPy AP; gated WARNING; vectorized persistence ===\n",
    "import os, json, time, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# -------- config --------\n",
    "LAT, LON = 40.7128, -74.0060\n",
    "START, END = \"2005-01-01\", None\n",
    "LOOKAHEAD_D = 7                 # label = onset in next K days\n",
    "EVENT_KSIGMA = 3.0              # spike threshold (try 2.5–3.0)\n",
    "VOL_BREAK_Q = 0.995             # vol breakout quantile\n",
    "VOL_BREAK_WIN = 252*3\n",
    "DD_WIN = 40\n",
    "DD_FRAC = 0.10\n",
    "MIN_CLUSTER_LEN = 3\n",
    "COUPLING_WIN = 400\n",
    "\n",
    "# Warning/gating & calibration\n",
    "GATE_THETA_MIN = 0.25\n",
    "GAMMA_VIX_MIN  = 0.08\n",
    "GATE_MIN_VOTES = 3\n",
    "COOLDOWN_BETWEEN_STARTS = 18\n",
    "MAX_WARN_DAYS = 12\n",
    "HYST_EXIT_DAYS = 3\n",
    "FA_PER_YEAR_TARGET = 0.50\n",
    "TRAIN_END = \"2015-12-31\"\n",
    "\n",
    "# -------- paths --------\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ts = time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "RUN = ROOT / f\"{ts}_v03a_lite_fix\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "def save_df(df, name): fp = RUN / f\"{name}.csv\"; df.to_csv(fp, index=True); return str(fp)\n",
    "def save_json(obj, name): fp = RUN / f\"{name}.json\"; fp.write_text(json.dumps(obj, indent=2)); return str(fp)\n",
    "\n",
    "# -------- small utils (tz, robust z, coherence fallback, AP, IRLS) --------\n",
    "def normalize_daily_index(idx):\n",
    "    idx = pd.DatetimeIndex(idx)\n",
    "    if idx.tz is not None: idx = idx.tz_convert(\"UTC\").tz_localize(None)\n",
    "    return idx.normalize()\n",
    "\n",
    "def normalize_series_daily(s):\n",
    "    if s is None or len(s)==0: return pd.Series(dtype=float)\n",
    "    s = pd.Series(s.copy()); s.index = normalize_daily_index(s.index)\n",
    "    s = s[~s.index.duplicated(keep=\"last\")]\n",
    "    return s.sort_index()\n",
    "\n",
    "def rolling_entropy(x, win=128, bins=32):\n",
    "    x = np.asarray(x, float); out = np.full(len(x), np.nan)\n",
    "    for i in range(win-1, len(x)):\n",
    "        w = x[i-win+1:i+1]; h,_ = np.histogram(w, bins=bins, density=True)\n",
    "        p = h[h>0]; out[i] = -np.sum(p*np.log(p)) if len(p) else np.nan\n",
    "    return out\n",
    "\n",
    "def rolling_ar1(x, win=256):\n",
    "    s = pd.Series(x, dtype=float); out = np.full(len(s), np.nan)\n",
    "    for i in range(win-1, len(s)):\n",
    "        w = s.iloc[i-win+1:i+1].values\n",
    "        sw = np.nanstd(w); out[i] = 0.0 if sw<1e-12 else np.corrcoef(w[1:], w[:-1])[0,1]\n",
    "    return out\n",
    "\n",
    "def zscore_mad(x, win=512):\n",
    "    s = pd.Series(x, dtype=float)\n",
    "    med = s.rolling(win, min_periods=64).median()\n",
    "    mad = (s-med).abs().rolling(win, min_periods=64).median()\n",
    "    return ((s - med)/(1.4826*mad + 1e-9)).values\n",
    "\n",
    "def theta_breaches(zsig, q=0.985, win=256):\n",
    "    s = pd.Series(zsig, dtype=float)\n",
    "    thr = s.rolling(win, min_periods=win//2).quantile(q)\n",
    "    return (s > thr).astype(int).rolling(win, min_periods=win//2).mean().values\n",
    "\n",
    "# coherence fallback if SciPy absent\n",
    "try:\n",
    "    from scipy.signal import coherence as _coh\n",
    "    def coherence_band(a,b,fs=1.0):\n",
    "        f,Cxy = _coh(a,b,fs=fs, nperseg=min(256,len(a)))\n",
    "        band = (f>0.02)&(f<0.25)\n",
    "        v = Cxy[band]; v = v[np.isfinite(v)]\n",
    "        return float(v.mean()) if v.size else np.nan\n",
    "except Exception:\n",
    "    def coherence_band(a,b,fs=1.0):\n",
    "        return np.nan\n",
    "\n",
    "def glyph_coupling(a,b,fs=1.0):\n",
    "    a = np.asarray(a, float); b = np.asarray(b, float)\n",
    "    if len(a)!=len(b) or len(a)<128: return np.nan\n",
    "    m = np.isfinite(a)&np.isfinite(b); a,b = a[m], b[m]\n",
    "    if len(a)<128: return np.nan\n",
    "    a -= a.mean(); b -= b.mean()\n",
    "    if a.std()<1e-12 or b.std()<1e-12: return np.nan\n",
    "    return coherence_band(a,b,fs)\n",
    "\n",
    "def average_precision_np(y_true, y_score):\n",
    "    y = np.asarray(y_true).astype(int)\n",
    "    s = np.asarray(y_score, float)\n",
    "    m = np.isfinite(s)\n",
    "    y, s = y[m], s[m]\n",
    "    P = y.sum()\n",
    "    if P == 0: return float('nan')\n",
    "    order = np.argsort(-s)\n",
    "    y_sorted = y[order]\n",
    "    tp = np.cumsum(y_sorted)\n",
    "    prec = tp / (np.arange(len(y_sorted))+1)\n",
    "    ap = prec[y_sorted==1].sum() / P\n",
    "    return float(ap)\n",
    "\n",
    "def sigmoid(z):\n",
    "    z = np.clip(z, -30, 30)\n",
    "    return 1.0/(1.0+np.exp(-z))\n",
    "\n",
    "def logistic_ridge_fit(X, y, l2=1e-2, max_iter=200, tol=1e-6):\n",
    "    n,p = X.shape\n",
    "    X_ = np.hstack([np.ones((n,1)), X])\n",
    "    beta = np.zeros(p+1)\n",
    "    eps = 1e-9\n",
    "    for _ in range(max_iter):\n",
    "        z = X_ @ beta\n",
    "        mu = sigmoid(z)\n",
    "        w = mu*(1-mu) + eps\n",
    "        z_tilde = z + (y - mu)/w\n",
    "        WX = X_ * w[:,None]\n",
    "        A = X_.T @ WX\n",
    "        A[1:,1:] += l2*np.eye(p)   # ridge (not penalizing intercept)\n",
    "        b = X_.T @ (w * z_tilde)\n",
    "        beta_new = np.linalg.solve(A, b)\n",
    "        if np.max(np.abs(beta_new - beta)) < tol:\n",
    "            beta = beta_new; break\n",
    "        beta = beta_new\n",
    "    return beta\n",
    "\n",
    "def logistic_predict_proba(X, beta):\n",
    "    X_ = np.hstack([np.ones((X.shape[0],1)), X])\n",
    "    return sigmoid(X_ @ beta)\n",
    "\n",
    "# -------- data loaders (no heavy installs) --------\n",
    "def get_px(tkr, auto_adjust=True):\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        h = yf.Ticker(tkr).history(period=\"max\", auto_adjust=auto_adjust)\n",
    "        if isinstance(h, pd.DataFrame) and 'Close' in h and len(h)>0:\n",
    "            return normalize_series_daily(h['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] history {tkr}:\", e)\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        s = yf.download(tkr, period=\"max\", interval=\"1d\", auto_adjust=auto_adjust, progress=False)\n",
    "        if isinstance(s, pd.DataFrame) and 'Close' in s and len(s)>0:\n",
    "            return normalize_series_daily(s['Close'].rename(tkr).dropna())\n",
    "    except Exception as e: print(f\"[warn] download {tkr}:\", e)\n",
    "    if tkr.upper()==\"SPY\":\n",
    "        try:\n",
    "            url = \"https://stooq.com/q/d/l/?s=spy&i=d\"\n",
    "            stq = pd.read_csv(url); stq.columns=[c.lower() for c in stq.columns]\n",
    "            stq['date']=pd.to_datetime(stq['date'])\n",
    "            stq = stq.set_index('date').sort_index()\n",
    "            return normalize_series_daily(stq['close'].rename('SPY').astype(float))\n",
    "        except Exception as e: print(\"[error] stooq SPY:\", e)\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "def get_temp_anomaly(lat, lon):\n",
    "    try:\n",
    "        from meteostat import Point, Daily\n",
    "        start_dt = pd.Timestamp(START)\n",
    "        end_dt = pd.Timestamp.today().normalize() if END is None else pd.Timestamp(END)\n",
    "        loc = Point(lat, lon); d = Daily(loc, start_dt, end_dt).fetch()\n",
    "        t = d['tavg'].astype(float) if 'tavg' in d and d['tavg'].notna().any() else ((d.get('tmin') + d.get('tmax'))/2).astype(float)\n",
    "        anom = (t - t.rolling(31, min_periods=10).median()).rename(\"temp_anom\").dropna()\n",
    "        return normalize_series_daily(anom)\n",
    "    except Exception as e: print(\"[warn] temp fetch:\", e); return pd.Series(dtype=float)\n",
    "\n",
    "# -------- ingest --------\n",
    "px  = get_px(\"SPY\",  auto_adjust=True)\n",
    "vix = get_px(\"^VIX\", auto_adjust=False)\n",
    "hyg = get_px(\"HYG\",  auto_adjust=True)\n",
    "ief = get_px(\"IEF\",  auto_adjust=True)\n",
    "ta  = get_temp_anomaly(LAT, LON)\n",
    "\n",
    "idx = pd.DatetimeIndex([])\n",
    "for ser in [px, vix, hyg, ief, ta]:\n",
    "    if len(ser)>0: idx = ser.index if idx.empty else idx.union(ser.index)\n",
    "df = pd.DataFrame(index=idx).sort_index()\n",
    "if len(px)>0:  df['px']  = px.reindex(df.index).ffill(); df['ret'] = df['px'].pct_change()\n",
    "if len(vix)>0: df['vix'] = vix.reindex(df.index).ffill(); df['dvix'] = df['vix'].pct_change()\n",
    "if len(hyg)>0 and len(ief)>0:\n",
    "    ratio = (hyg / ief).reindex(df.index).ffill()\n",
    "    df['cred_ret'] = ratio.pct_change()\n",
    "if len(ta)>0:  df['temp_anom'] = ta.reindex(df.index).interpolate(limit=7).ffill()\n",
    "\n",
    "# -------- features --------\n",
    "# market\n",
    "if 'ret' in df:\n",
    "    m = df['ret'].fillna(0.0).values; mz = zscore_mad(m, win=512)\n",
    "    df['S_d_mkt']   = rolling_entropy(m, win=256, bins=48)\n",
    "    df['AR1_mkt']   = rolling_ar1(m, win=256)\n",
    "    df['Theta_mkt'] = theta_breaches(mz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_mkt']=df['AR1_mkt']=df['Theta_mkt']=np.nan\n",
    "# vix\n",
    "if 'dvix' in df:\n",
    "    v = df['dvix'].fillna(0.0).values; vz = zscore_mad(v, win=512)\n",
    "    df['S_d_vix']   = rolling_entropy(v, win=256, bins=48)\n",
    "    df['AR1_vix']   = rolling_ar1(v, win=256)\n",
    "    df['Theta_vix'] = theta_breaches(vz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_vix']=df['AR1_vix']=df['Theta_vix']=np.nan\n",
    "# credit\n",
    "if 'cred_ret' in df:\n",
    "    c = df['cred_ret'].fillna(0.0).values; cz = zscore_mad(c, win=512)\n",
    "    df['S_d_cred']   = rolling_entropy(c, win=256, bins=48)\n",
    "    df['AR1_cred']   = rolling_ar1(c, win=256)\n",
    "    df['Theta_cred'] = theta_breaches(cz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_cred']=df['AR1_cred']=df['Theta_cred']=np.nan\n",
    "# temp\n",
    "if 'temp_anom' in df:\n",
    "    t = df['temp_anom'].fillna(0.0).values; tz = zscore_mad(t, win=512)\n",
    "    df['S_d_tmp']   = rolling_entropy(t, win=256, bins=48)\n",
    "    df['AR1_tmp']   = rolling_ar1(t, win=256)\n",
    "    df['Theta_tmp'] = theta_breaches(tz, q=0.985, win=256)\n",
    "else:\n",
    "    df['S_d_tmp']=df['AR1_tmp']=df['Theta_tmp']=np.nan\n",
    "\n",
    "# couplings\n",
    "df['Gamma_mkt_vix']=np.nan; df['Gamma_mkt_cred']=np.nan\n",
    "if 'ret' in df and 'dvix' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['dvix'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_vix')] = glyph_coupling(a,b,fs=1.0)\n",
    "if 'ret' in df and 'cred_ret' in df:\n",
    "    for i in range(max(128, COUPLING_WIN), len(df)):\n",
    "        a = df['ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        b = df['cred_ret'].iloc[i-COUPLING_WIN:i].values\n",
    "        df.iloc[i, df.columns.get_loc('Gamma_mkt_cred')] = glyph_coupling(a,b,fs=1.0)\n",
    "\n",
    "# -------- regime events → sustained clusters → ONSETS --------\n",
    "metrics = {}\n",
    "if 'ret' in df:\n",
    "    vol21 = df['ret'].rolling(21).std()\n",
    "    E_spike = (df['ret'].abs() > EVENT_KSIGMA*vol21).astype(int)\n",
    "\n",
    "    vol10  = df['ret'].rolling(10).std()\n",
    "    q_roll = vol10.rolling(VOL_BREAK_WIN, min_periods=252).quantile(VOL_BREAK_Q)\n",
    "    E_vol  = (vol10 > q_roll).astype(int).fillna(0).astype(int)\n",
    "\n",
    "    if 'px' in df:\n",
    "        roll_max = df['px'].rolling(DD_WIN, min_periods=DD_WIN//2).max()\n",
    "        dd = df['px']/roll_max - 1.0\n",
    "        E_dd = (dd <= -DD_FRAC).astype(int).fillna(0).astype(int)\n",
    "    else:\n",
    "        E_dd = pd.Series(0, index=df.index)\n",
    "\n",
    "    E = ((E_spike==1) | (E_vol==1) | (E_dd==1)).astype(int).reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # sustained cluster onsets\n",
    "    onset = np.zeros(len(df), dtype=int)\n",
    "    i=0; arr=E.values\n",
    "    while i<len(arr):\n",
    "        if arr[i]==1:\n",
    "            j=i\n",
    "            while j+1<len(arr) and arr[j+1]==1: j+=1\n",
    "            if (j-i+1) >= MIN_CLUSTER_LEN: onset[i]=1\n",
    "            i = j+1\n",
    "        else:\n",
    "            i+=1\n",
    "    df['EVENT_ONSET'] = onset\n",
    "\n",
    "    # ----- supervised label = onset in next K days -----\n",
    "    y_future = pd.Series(df['EVENT_ONSET']).rolling(LOOKAHEAD_D, min_periods=1).max().shift(-(LOOKAHEAD_D-1))\n",
    "    y_future = y_future.reindex(df.index).fillna(0).astype(int)\n",
    "\n",
    "    # feature matrix (robust Z + selected ramps)\n",
    "    feat_cols = ['S_d_mkt','AR1_mkt','Theta_mkt','S_d_vix','AR1_vix','Theta_vix',\n",
    "                 'S_d_cred','AR1_cred','Theta_cred','S_d_tmp','AR1_tmp','Theta_tmp',\n",
    "                 'Gamma_mkt_vix','Gamma_mkt_cred']\n",
    "    F = df[feat_cols].copy().ffill().bfill().fillna(0.0)\n",
    "    Z = pd.DataFrame(index=F.index)\n",
    "    for c in F.columns:\n",
    "        med = F[c].rolling(512, min_periods=64).median()\n",
    "        mad = (F[c]-med).abs().rolling(512, min_periods=64).median()\n",
    "        Z[c] = (F[c]-med)/(1.4826*mad + 1e-9)\n",
    "    DZ7 = Z.diff(7).add_prefix(\"d7_\")\n",
    "    X = pd.concat([Z, DZ7[['d7_AR1_mkt','d7_S_d_mkt','d7_AR1_vix','d7_S_d_vix','d7_Gamma_mkt_vix','d7_Gamma_mkt_cred']].fillna(0.0)], axis=1).fillna(0.0)\n",
    "\n",
    "    # train split\n",
    "    idx_train = X.index[X.index <= pd.Timestamp(TRAIN_END)]\n",
    "    X_train, y_train = X.loc[idx_train].values, y_future.loc[idx_train].values.astype(int)\n",
    "    if y_train.sum()==0:\n",
    "        y_train = E.loc[idx_train].values.astype(int)\n",
    "\n",
    "    # IRLS logistic on robust Z (already roughly standardized)\n",
    "    beta = logistic_ridge_fit(X_train, y_train, l2=1e-2, max_iter=300, tol=1e-6)\n",
    "    risk_all = pd.Series(logistic_predict_proba(X.values, beta), index=X.index, name=\"RISK\")\n",
    "    df['RISK'] = risk_all\n",
    "\n",
    "    # ----- threshold calibration on TRAIN to meet FA budget -----\n",
    "    Theta_m_train = df['Theta_mkt'].loc[idx_train].fillna(0.0).values\n",
    "    Theta_v_train = df['Theta_vix'].loc[idx_train].fillna(0.0).values\n",
    "    Theta_c_train = df['Theta_cred'].loc[idx_train].fillna(0.0).values\n",
    "    Gamma_v_train = df['Gamma_mkt_vix'].loc[idx_train].fillna(0.0).values\n",
    "    onset_train   = df['EVENT_ONSET'].loc[idx_train].values.astype(int)\n",
    "    rtrain        = risk_all.loc[idx_train].values\n",
    "\n",
    "    qgrid = np.linspace(0.990, 0.9995, 20)\n",
    "    best = None\n",
    "    for q in qgrid:\n",
    "        t = np.quantile(rtrain[np.isfinite(rtrain)], q)\n",
    "        votes = ((Theta_v_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Theta_c_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Theta_m_train>=GATE_THETA_MIN).astype(int) +\n",
    "                 (Gamma_v_train>=GAMMA_VIX_MIN).astype(int) +\n",
    "                 ((pd.Series(rtrain).diff(7).fillna(0.0).values)>0).astype(int))\n",
    "        # === FIX: vectorized persistence over last 3 days ===\n",
    "        persist = ((pd.Series(rtrain) >= t).astype(int).rolling(3).sum().fillna(0).values >= 2)\n",
    "\n",
    "        # build state\n",
    "        state=[]; in_warn=False; below=0; wlen=0\n",
    "        for i,(r,v,pers) in enumerate(zip(rtrain, votes, persist)):\n",
    "            if in_warn:\n",
    "                wlen += 1\n",
    "                below = below+1 if r < 0.9*t else 0\n",
    "                if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS: in_warn=False; wlen=0; state.append('OK')\n",
    "                else: state.append('WARNING')\n",
    "            else:\n",
    "                if (r>=t) and pers and (v>=GATE_MIN_VOTES): in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "                else: state.append('OK')\n",
    "        state = np.array(state, dtype=object)\n",
    "\n",
    "        # starts → hits/FA vs ONSET on TRAIN\n",
    "        starts = (state=='WARNING') & np.roll(state!='WARNING', 1)\n",
    "        starts[0] = (state[0]=='WARNING')\n",
    "        s_ix = np.where(starts)[0].tolist()\n",
    "        kept=[]; last=-10**9\n",
    "        for s in s_ix:\n",
    "            if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "        s_ix = kept\n",
    "\n",
    "        e_ix = np.where(onset_train==1)[0]; e_set=set(e_ix)\n",
    "        hits=0\n",
    "        for s in s_ix:\n",
    "            if any(((s+j) in e_set) for j in range(1, LOOKAHEAD_D+1)): hits+=1\n",
    "        fa = int(len(s_ix)-hits)\n",
    "        years = max(1e-9, (idx_train[-1]-idx_train[0]).days/365.25)\n",
    "        fa_per_year = fa/years\n",
    "\n",
    "        cand = {\"q\": float(q), \"thr\": float(t), \"hits\": hits, \"fa_py\": fa_per_year}\n",
    "        if (best is None) or ((fa_per_year <= FA_PER_YEAR_TARGET) and (hits > best[\"hits\"])) or \\\n",
    "           ((fa_per_year <= FA_PER_YEAR_TARGET) and (hits == best[\"hits\"]) and (fa_per_year < best[\"fa_py\"])):\n",
    "            best = cand\n",
    "\n",
    "    thr_q, thr_prob = best[\"q\"], best[\"thr\"]\n",
    "\n",
    "    # ----- apply to FULL series -----\n",
    "    Theta_m = df['Theta_mkt'].fillna(0.0).values\n",
    "    Theta_v = df['Theta_vix'].fillna(0.0).values\n",
    "    Theta_c = df['Theta_cred'].fillna(0.0).values\n",
    "    Gamma_v = df['Gamma_mkt_vix'].fillna(0.0).values\n",
    "    risk    = df['RISK'].fillna(0.0).values\n",
    "    t = np.quantile(risk[np.isfinite(risk)], thr_q)\n",
    "    votes = ((Theta_v>=GATE_THETA_MIN).astype(int) +\n",
    "             (Theta_c>=GATE_THETA_MIN).astype(int) +\n",
    "             (Theta_m>=GATE_THETA_MIN).astype(int) +\n",
    "             (Gamma_v>=GAMMA_VIX_MIN).astype(int) +\n",
    "             ((pd.Series(risk).diff(7).fillna(0.0).values)>0).astype(int))\n",
    "    # === FIX: vectorized persistence (full series) ===\n",
    "    persist = ((pd.Series(risk) >= t).astype(int).rolling(3).sum().fillna(0).values >= 2)\n",
    "\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    for i,(r,v,pers) in enumerate(zip(risk, votes, persist)):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS: in_warn=False; wlen=0; state.append('OK')\n",
    "            else: state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and pers and (v>=GATE_MIN_VOTES): in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else: state.append('OK')\n",
    "    df['alert'] = state\n",
    "\n",
    "    # ----- full metrics -----\n",
    "    starts = (df['alert'].eq(\"WARNING\") & ~df['alert'].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "    s_ix = np.where(starts.values)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_BETWEEN_STARTS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "\n",
    "    y_on = df['EVENT_ONSET'].values\n",
    "    e_ix = np.where(y_on==1)[0]; e_set=set(e_ix)\n",
    "    hits=0; lead_days=[]\n",
    "    for s in s_ix:\n",
    "        hit=None\n",
    "        for j in range(1, LOOKAHEAD_D+1):\n",
    "            if (s+j) in e_set: hit=s+j; break\n",
    "        if hit is not None:\n",
    "            hits += 1; lead_days.append(int(hit-s))\n",
    "    false_alarms = int(len(s_ix) - hits)\n",
    "    years = max(1e-9, (df.index[-1]-df.index[0]).days/365.25)\n",
    "    fa_per_year = false_alarms/years\n",
    "\n",
    "    # lead PR-AUC with our AP\n",
    "    auc_lead={}\n",
    "    for k in range(1, LOOKAHEAD_D+1):\n",
    "        yk = y_on[k:]\n",
    "        xk = pd.Series(risk).shift(k).iloc[k:].values\n",
    "        auc_lead[k] = average_precision_np(yk, xk) if yk.sum()>0 else float('nan')\n",
    "\n",
    "    # onset coverage by starts in prior K days\n",
    "    coverage_by_k={}\n",
    "    s_set=set(s_ix)\n",
    "    for K in range(1, LOOKAHEAD_D+1):\n",
    "        covered=0\n",
    "        for e in e_ix:\n",
    "            left=max(0, e-K)\n",
    "            if any((t0 in s_set) for t0 in range(left, e)): covered+=1\n",
    "        coverage_by_k[K] = float(covered/len(e_ix)) if len(e_ix) else float('nan')\n",
    "\n",
    "    metrics = {\n",
    "        \"samples\": int(len(df)), \"years\": float(years),\n",
    "        \"event_onsets_total\": int(df['EVENT_ONSET'].sum()),\n",
    "        \"calibrated_thr_quantile_train\": float(thr_q),\n",
    "        \"calibrated_thr_prob\": float(thr_prob),\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"warning_starts\": int(len(s_ix)), \"hits_within_days\": LOOKAHEAD_D,\n",
    "        \"hits\": int(hits), \"false_alarms\": int(false_alarms),\n",
    "        \"false_alarms_per_year\": float(fa_per_year),\n",
    "        \"lead_time_days_median\": (float(np.median(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_mean\": (float(np.mean(lead_days)) if lead_days else None),\n",
    "        \"lead_time_days_all\": lead_days[:64],\n",
    "        \"auc_pr_lead_curve\": auc_lead, \"coverage_onsets\": coverage_by_k,\n",
    "        \"warning_days\": int((df['alert']==\"WARNING\").sum()),\n",
    "        \"gate\": {\"theta_min\": GATE_THETA_MIN, \"gamma_vix_min\": GAMMA_VIX_MIN, \"min_votes\": GATE_MIN_VOTES},\n",
    "        \"cooldown_days\": COOLDOWN_BETWEEN_STARTS, \"max_warn_days\": MAX_WARN_DAYS\n",
    "    }\n",
    "\n",
    "# -------- persist --------\n",
    "paths = {\n",
    "    \"features_csv\": save_df(df[['RISK','alert','EVENT_ONSET'] + [c for c in df.columns\n",
    "                     if c.startswith(('S_d_','AR1_','Theta_','Gamma_'))]], \"gdren_v03a_lite_fix_features\"),\n",
    "    \"metrics_json\": save_json(metrics, \"gdren_v03a_lite_fix_metrics\"),\n",
    "    \"meta_json\": save_json({\n",
    "        \"run_id\": RUN.name,\n",
    "        \"created_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime()),\n",
    "        \"cfg\": {\"lat\": LAT, \"lon\": LON, \"start\": START, \"end\": END, \"lookahead\": LOOKAHEAD_D},\n",
    "        \"fa_per_year_target_train\": FA_PER_YEAR_TARGET,\n",
    "        \"notes\": \"v0.3a-lite (fix) — vectorized persistence; IRLS logistic + NumPy AP; gated WARNING; calibrated threshold.\"\n",
    "    }, \"meta\")\n",
    "}\n",
    "print(\"Artifacts:\", json.dumps(paths, indent=2))\n",
    "if metrics:\n",
    "    print(\"\\n=== v0.3a-lite SKILL (calibrated) ===\")\n",
    "    for k in [\"samples\",\"years\",\"event_onsets_total\",\"calibrated_thr_quantile_train\",\n",
    "              \"warning_starts\",\"hits\",\"false_alarms\",\"false_alarms_per_year\",\n",
    "              \"lead_time_days_median\",\"lead_time_days_mean\"]:\n",
    "        print(f\"{k:>28}: {metrics.get(k)}\")\n",
    "    print(\" auc_pr_lead_curve (k→AUC):\", metrics[\"auc_pr_lead_curve\"])\n",
    "    print(\" coverage_onsets   (K→cov):\", metrics[\"coverage_onsets\"])\n",
    "else:\n",
    "    print(\"\\n[info] Metrics skipped (no market series).\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18791654-0a32-4087-89f3-0f5ddedc3cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231133Z\\\\v03a_retune\\\\gdren_v03a_retune_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231133Z\\\\v03a_retune\\\\gdren_v03a_retune_metrics.json\"\n",
      "}\n",
      "\n",
      "=== RETUNE SUMMARY ===\n",
      "           features_used: E:\\CNT\\artifacts\\g_dren\\20251105-230753Z_v03a_lite_fix\\gdren_v03a_lite_fix_features.csv\n",
      "      calibrated_q_train: 0.985\n",
      "     calibrated_thr_prob: 9.357622968839301e-14\n",
      "            train_starts: 2\n",
      "              train_hits: 0\n",
      "       train_fa_per_year: 0.07694333263113545\n",
      "             full_starts: 2\n",
      "               full_hits: 0\n",
      "full_false_alarms_per_year: 0.0558016958215568\n",
      "           cooldown_days: 14\n",
      "           max_warn_days: 12\n",
      "          gate_min_votes: 2\n",
      "             persist_win: 5\n",
      "             persist_req: 2\n",
      "      fa_per_year_target: 0.6\n",
      "          lookahead_days: 7\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a RETUNE — threshold & gating tuner (no recompute) ===\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# --- knobs you can tweak quickly ---\n",
    "FA_PER_YEAR_TARGET = 0.60   # raise to allow more starts, lower to be stricter\n",
    "GATE_MIN_VOTES     = 2      # 2 is looser, 3+ stricter\n",
    "COOLDOWN_DAYS      = 14\n",
    "MAX_WARN_DAYS      = 12\n",
    "HYST_EXIT_DAYS     = 3\n",
    "LOOKAHEAD_D        = 7\n",
    "PERSIST_WIN        = 5      # persistence window\n",
    "PERSIST_REQ        = 2      # require >= this many days above threshold in the window\n",
    "QGRID              = np.linspace(0.985, 0.999, 60)  # widen search (we were at ~0.99+)\n",
    "\n",
    "# --- load latest v03a_lite_fix features ---\n",
    "CNT = Path((Path(\"E:/CNT\") if Path(\"E:/CNT\").exists() else Path.cwd()))\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "cands = sorted(ROOT.glob(\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"),\n",
    "               key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert cands, \"No gdren_v03a_lite_fix_features.csv files found\"\n",
    "FEAT = cands[0]\n",
    "df = pd.read_csv(FEAT, index_col=0, parse_dates=True)\n",
    "\n",
    "# sanity columns\n",
    "need_cols = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\"]\n",
    "missing = [c for c in need_cols if c not in df.columns]\n",
    "assert not missing, f\"Missing columns in features CSV: {missing}\"\n",
    "\n",
    "risk = pd.Series(df[\"RISK\"].astype(float), index=df.index).fillna(0.0)\n",
    "Theta_m = df[\"Theta_mkt\"].astype(float).fillna(0.0).values\n",
    "Theta_v = df[\"Theta_vix\"].astype(float).fillna(0.0).values\n",
    "Theta_c = df[\"Theta_cred\"].astype(float).fillna(0.0).values\n",
    "Gamma_v = df[\"Gamma_mkt_vix\"].astype(float).fillna(0.0).values\n",
    "onset   = df[\"EVENT_ONSET\"].astype(int).values\n",
    "idx     = df.index\n",
    "\n",
    "# --- helper: build alert state from risk given a quantile threshold ---\n",
    "def make_alert(risk_s: pd.Series, q: float):\n",
    "    t = float(np.quantile(risk_s.values[np.isfinite(risk_s.values)], q))\n",
    "    # votes = Θ_vix + Θ_cred + Θ_mkt + Γ(mkt↔VIX) + rising risk slope(7d)\n",
    "    votes = ((Theta_v>=0.25).astype(int) +\n",
    "             (Theta_c>=0.25).astype(int) +\n",
    "             (Theta_m>=0.25).astype(int) +\n",
    "             (Gamma_v>=0.08).astype(int) +\n",
    "             ((risk_s.diff(7).fillna(0.0).values)>0).astype(int))\n",
    "    # persistence: >= PERSIST_REQ of last PERSIST_WIN days above t\n",
    "    persist = ( (risk_s >= t).astype(int)\n",
    "               .rolling(PERSIST_WIN).sum()\n",
    "               .fillna(0).values >= PERSIST_REQ )\n",
    "    # state machine\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    rv = risk_s.values\n",
    "    for i,(r,v,ps) in enumerate(zip(rv, votes, persist)):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else:\n",
    "                state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and ps and (v>=GATE_MIN_VOTES):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else:\n",
    "                state.append('OK')\n",
    "    return pd.Series(state, index=risk_s.index, name=\"alert\"), t\n",
    "\n",
    "# --- score starts/hits/FA vs onset (on a slice) ---\n",
    "def score(alert_s: pd.Series, onset_arr: np.ndarray, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = list(np.where(starts)[0])\n",
    "    # cooldown\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    # hits within horizon\n",
    "    e_ix = list(np.where(onset_arr[a.index.get_indexer(ix)]==1)[0])\n",
    "    e_set = set(e_ix)\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if any(((s+j) in e_set) for j in range(1, LOOKAHEAD_D+1)): hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years, \"s_ix\": s_ix}\n",
    "\n",
    "# --- choose TRAIN slice for calibration (<= 2015-12-31) ---\n",
    "TRAIN_END = pd.Timestamp(\"2015-12-31\")\n",
    "ix_train = idx[idx <= TRAIN_END]\n",
    "assert len(ix_train)>2000, \"Too little train history; adjust TRAIN_END.\"\n",
    "\n",
    "# --- search thresholds to meet FA budget while maximizing hits ---\n",
    "best = None\n",
    "for q in QGRID:\n",
    "    alert_q, thr = make_alert(risk.loc[idx], q)\n",
    "    res = score(alert_q, onset, ix_train)\n",
    "    cand = {\"q\": q, \"thr\": float(thr), **res}\n",
    "    if (best is None) or \\\n",
    "       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\", -1))) or \\\n",
    "       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\", -1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "       ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "        best = cand.copy()\n",
    "        best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# Fallback: if still zero starts on train, force a looser threshold\n",
    "if best[\"starts\"] == 0:\n",
    "    q_fallback = 0.985\n",
    "    alert_q, thr = make_alert(risk.loc[idx], q_fallback)\n",
    "    res = score(alert_q, onset, ix_train)\n",
    "    best = {\"q\": q_fallback, \"thr\": float(thr), **res, \"hits_ok\": res[\"hits\"]}\n",
    "\n",
    "# --- apply best threshold to FULL series ---\n",
    "alert_final, thr_final = make_alert(risk.loc[idx], best[\"q\"])\n",
    "full = score(alert_final, onset, idx)\n",
    "\n",
    "# --- write artifacts ---\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_retune\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "(df.assign(alert=alert_final)\n",
    "   [[\"RISK\",\"alert\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\"]]\n",
    "   .to_csv(RUN / \"gdren_v03a_retune_alerts.csv\"))\n",
    "\n",
    "metrics = {\n",
    "    \"features_used\": str(FEAT),\n",
    "    \"calibrated_q_train\": float(best[\"q\"]),\n",
    "    \"calibrated_thr_prob\": float(best[\"thr\"]),\n",
    "    \"train_starts\": int(best[\"starts\"]), \"train_hits\": int(best[\"hits\"]),\n",
    "    \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "    \"full_starts\": int(full[\"starts\"]), \"full_hits\": int(full[\"hits\"]),\n",
    "    \"full_false_alarms_per_year\": float(full[\"fa_py\"]),\n",
    "    \"cooldown_days\": COOLDOWN_DAYS, \"max_warn_days\": MAX_WARN_DAYS,\n",
    "    \"gate_min_votes\": GATE_MIN_VOTES, \"persist_win\": PERSIST_WIN, \"persist_req\": PERSIST_REQ,\n",
    "    \"fa_per_year_target\": FA_PER_YEAR_TARGET, \"lookahead_days\": LOOKAHEAD_D\n",
    "}\n",
    "(RUN / \"gdren_v03a_retune_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "print(\"Artifacts:\", json.dumps({\n",
    "    \"alerts_csv\": str(RUN / \"gdren_v03a_retune_alerts.csv\"),\n",
    "    \"metrics_json\": str(RUN / \"gdren_v03a_retune_metrics.json\")\n",
    "}, indent=2))\n",
    "print(\"\\n=== RETUNE SUMMARY ===\")\n",
    "for k,v in metrics.items():\n",
    "    print(f\"{k:>24}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7f2140cd-78d3-4fd1-aa39-31760cf4f211",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231403Z\\\\v03a_retune_pp\\\\gdren_v03a_retune_pp_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231403Z\\\\v03a_retune_pp\\\\gdren_v03a_retune_pp_metrics.json\"\n",
      "}\n",
      "\n",
      "=== RETUNE++ SUMMARY ===\n",
      "           features_used: E:\\CNT\\artifacts\\g_dren\\20251105-230753Z_v03a_lite_fix\\gdren_v03a_lite_fix_features.csv\n",
      "      calibrated_q_train: 0.97\n",
      "   calibrated_thr_driver: 1.0\n",
      "            train_starts: 3\n",
      "              train_hits: 0\n",
      "       train_fa_per_year: 0.11541499894670318\n",
      "             full_starts: 3\n",
      "               full_hits: 0\n",
      "full_false_alarms_per_year: 0.0837025437323352\n",
      "           cooldown_days: 14\n",
      "           max_warn_days: 12\n",
      "          gate_min_votes: 2\n",
      "             persist_win: 3\n",
      "             persist_req: 1\n",
      "      fa_per_year_target: 0.6\n",
      "          lookahead_days: 7\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a RETUNE++ — hybrid driver (risk_pct ∨ consensus), wider q-grid, low-FA calibration ===\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---- quick knobs ----\n",
    "FA_PER_YEAR_TARGET = 0.60   # raise to allow more recall, lower to be stricter\n",
    "GATE_MIN_VOTES     = 2      # 2=looser gate; try 3 later if FA rises\n",
    "COOLDOWN_DAYS      = 14\n",
    "MAX_WARN_DAYS      = 12\n",
    "HYST_EXIT_DAYS     = 3\n",
    "LOOKAHEAD_D        = 7\n",
    "PERSIST_WIN        = 3      # require persistence in recent window\n",
    "PERSIST_REQ        = 1\n",
    "QGRID              = np.linspace(0.970, 0.995, 51)\n",
    "WIN_RANK           = 512    # rolling window for percentile ranks\n",
    "\n",
    "# ---- load latest features ----\n",
    "ROOT = Path(\"E:/CNT/artifacts/g_dren\")\n",
    "cands = sorted(ROOT.glob(\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"),\n",
    "               key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert cands, \"No gdren_v03a_lite_fix_features.csv found.\"\n",
    "FEAT = cands[0]\n",
    "df = pd.read_csv(FEAT, index_col=0, parse_dates=True)\n",
    "\n",
    "need = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "risk = pd.Series(df[\"RISK\"].astype(float), index=df.index).fillna(0.0)\n",
    "Theta_m = df[\"Theta_mkt\"].astype(float).fillna(0.0).values\n",
    "Theta_v = df[\"Theta_vix\"].astype(float).fillna(0.0).values\n",
    "Theta_c = df[\"Theta_cred\"].astype(float).fillna(0.0).values\n",
    "Gamma_v = df[\"Gamma_mkt_vix\"].astype(float).fillna(0.0).values\n",
    "AR1_m   = df[\"AR1_mkt\"].astype(float).fillna(0.0).values\n",
    "onset   = df[\"EVENT_ONSET\"].astype(int).values\n",
    "idx     = df.index\n",
    "\n",
    "# ---- helpers ----\n",
    "def roll_pct_rank(s: pd.Series, win=512):\n",
    "    s = s.astype(float)\n",
    "    def pr(w):\n",
    "        v = w[-1]\n",
    "        arr = np.sort(w)\n",
    "        return np.searchsorted(arr, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=True)\n",
    "\n",
    "def make_alert(driver: pd.Series, q: float):\n",
    "    t = float(np.quantile(driver.values[np.isfinite(driver.values)], q))\n",
    "    votes = ((Theta_v>=0.25).astype(int) +\n",
    "             (Theta_c>=0.25).astype(int) +\n",
    "             (Theta_m>=0.25).astype(int) +\n",
    "             (Gamma_v>=0.08).astype(int) +\n",
    "             ((driver.diff(7).fillna(0.0).values)>0).astype(int))\n",
    "    persist = ((driver>=t).astype(int).rolling(PERSIST_WIN).sum().fillna(0).values >= PERSIST_REQ)\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    for r,v,ps in zip(driver.values, votes, persist):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else:\n",
    "                state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and ps and (v>=GATE_MIN_VOTES):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else:\n",
    "                state.append('OK')\n",
    "    return pd.Series(state, index=driver.index), t\n",
    "\n",
    "def score(alert_s: pd.Series, onset_arr: np.ndarray, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = np.where(starts)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    # hits within horizon\n",
    "    e_slice = onset_arr[a.index.get_indexer(ix)]\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if e_slice[s+1:min(s+1+LOOKAHEAD_D, len(e_slice))].any():\n",
    "            hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years, \"s_ix\": s_ix}\n",
    "\n",
    "# ---- build HYBRID driver: max(rolling risk-percentile, consensus stress) ----\n",
    "risk_pct = roll_pct_rank(risk, win=WIN_RANK).fillna(0.0)\n",
    "\n",
    "# consensus = weighted mix of stress channels, then ranked\n",
    "cons_raw = (0.45*pd.Series(Theta_v, index=idx) +\n",
    "            0.35*pd.Series(Theta_c, index=idx) +\n",
    "            0.15*pd.Series(np.maximum(0, AR1_m), index=idx) +\n",
    "            0.05*pd.Series(np.nan_to_num(Gamma_v), index=idx))\n",
    "cons_pct = roll_pct_rank(cons_raw, win=WIN_RANK).fillna(0.0)\n",
    "\n",
    "driver = pd.Series(np.maximum(risk_pct.values, cons_pct.values), index=idx, name=\"DRIVER\")\n",
    "\n",
    "# ---- calibrate on TRAIN (<=2015-12-31) ----\n",
    "TRAIN_END = pd.Timestamp(\"2015-12-31\")\n",
    "ix_train = idx[idx <= TRAIN_END]\n",
    "assert len(ix_train)>2000, \"Too little train history; adjust TRAIN_END.\"\n",
    "\n",
    "best = None\n",
    "for q in QGRID:\n",
    "    alert_q, thr = make_alert(driver, q)\n",
    "    res = score(alert_q, onset, ix_train)\n",
    "    cand = {\"q\": float(q), \"thr\": float(thr), **res}\n",
    "    if (best is None) or \\\n",
    "       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\", -1))) or \\\n",
    "       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\", -1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "       ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "        best = cand.copy(); best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# fallback if zero starts\n",
    "if best[\"starts\"] == 0:\n",
    "    q_fallback = float(QGRID[0])\n",
    "    alert_q, thr = make_alert(driver, q_fallback)\n",
    "    res = score(alert_q, onset, ix_train)\n",
    "    best = {\"q\": q_fallback, \"thr\": float(thr), **res, \"hits_ok\": res[\"hits\"]}\n",
    "\n",
    "# ---- apply to FULL series ----\n",
    "alert_final, thr_final = make_alert(driver, best[\"q\"])\n",
    "full = score(alert_final, onset, idx)\n",
    "\n",
    "# ---- write artifacts ----\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_retune_pp\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "out_df = df.assign(DRIVER=driver, risk_pct=risk_pct, cons_pct=cons_pct, alert=alert_final)\n",
    "(out_df[[\"RISK\",\"risk_pct\",\"cons_pct\",\"DRIVER\",\"alert\",\"EVENT_ONSET\",\n",
    "         \"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\"]]\n",
    " .to_csv(RUN / \"gdren_v03a_retune_pp_alerts.csv\"))\n",
    "\n",
    "metrics = {\n",
    "    \"features_used\": str(FEAT),\n",
    "    \"calibrated_q_train\": float(best[\"q\"]),\n",
    "    \"calibrated_thr_driver\": float(best[\"thr\"]),\n",
    "    \"train_starts\": int(best[\"starts\"]), \"train_hits\": int(best[\"hits\"]),\n",
    "    \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "    \"full_starts\": int(full[\"starts\"]), \"full_hits\": int(full[\"hits\"]),\n",
    "    \"full_false_alarms_per_year\": float(full[\"fa_py\"]),\n",
    "    \"cooldown_days\": COOLDOWN_DAYS, \"max_warn_days\": MAX_WARN_DAYS,\n",
    "    \"gate_min_votes\": GATE_MIN_VOTES, \"persist_win\": PERSIST_WIN, \"persist_req\": PERSIST_REQ,\n",
    "    \"fa_per_year_target\": FA_PER_YEAR_TARGET, \"lookahead_days\": LOOKAHEAD_D\n",
    "}\n",
    "(RUN / \"gdren_v03a_retune_pp_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "print(\"Artifacts:\", json.dumps({\n",
    "    \"alerts_csv\": str(RUN / \"gdren_v03a_retune_pp_alerts.csv\"),\n",
    "    \"metrics_json\": str(RUN / \"gdren_v03a_retune_pp_metrics.json\")\n",
    "}, indent=2))\n",
    "print(\"\\n=== RETUNE++ SUMMARY ===\")\n",
    "for k,v in metrics.items(): print(f\"{k:>24}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "259c3d67-4f38-43ae-9e74-b0652cfa179a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231708Z\\\\v03a_retune_sweep\\\\gdren_v03a_retune_sweep_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-231708Z\\\\v03a_retune_sweep\\\\gdren_v03a_retune_sweep_metrics.json\"\n",
      "}\n",
      "\n",
      "=== RETUNE+++ SUMMARY ===\n",
      "             features_used: E:\\CNT\\artifacts\\g_dren\\20251105-230753Z_v03a_lite_fix\\gdren_v03a_lite_fix_features.csv\n",
      "        calibrated_q_train: 0.965\n",
      "     calibrated_thr_driver: 1.0\n",
      "        train_horizon_days: 14\n",
      "              train_starts: 3\n",
      "                train_hits: 1\n",
      "         train_fa_per_year: 0.07694333263113545\n",
      "            gate_min_votes: 2\n",
      "               persist_win: 3\n",
      "               persist_req: 1\n",
      "               full_starts: 3\n",
      "                 full_hits: 1\n",
      "full_false_alarms_per_year: 0.0558016958215568\n",
      "        fa_per_year_target: 0.6\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN v0.3a RETUNE+++ — hybrid driver + grid sweep (no feature recompute) ===\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---- knobs ----\n",
    "FA_PER_YEAR_TARGET = 0.60\n",
    "COOLDOWN_DAYS      = 14\n",
    "MAX_WARN_DAYS      = 12\n",
    "HYST_EXIT_DAYS     = 3\n",
    "QGRID              = np.linspace(0.965, 0.990, 51)   # wider than before\n",
    "WIN_RANK           = 512                             # rolling rank window\n",
    "VOTE_THRESH_THETA  = 0.25\n",
    "VOTE_THRESH_GAMMA  = 0.08\n",
    "\n",
    "# ---- load latest features ----\n",
    "ROOT = Path(\"E:/CNT/artifacts/g_dren\")\n",
    "cands = sorted(ROOT.glob(\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"),\n",
    "               key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert cands, \"No gdren_v03a_lite_fix_features.csv found.\"\n",
    "FEAT = cands[0]\n",
    "df = pd.read_csv(FEAT, index_col=0, parse_dates=True)\n",
    "\n",
    "need = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "missing = [c for c in need if c not in df.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "risk   = pd.Series(df[\"RISK\"].astype(float), index=df.index).fillna(0.0)\n",
    "Theta_m= df[\"Theta_mkt\"].astype(float).fillna(0.0).values\n",
    "Theta_v= df[\"Theta_vix\"].astype(float).fillna(0.0).values\n",
    "Theta_c= df[\"Theta_cred\"].astype(float).fillna(0.0).values\n",
    "Gamma_v= df[\"Gamma_mkt_vix\"].astype(float).fillna(0.0).values\n",
    "AR1_m  = df[\"AR1_mkt\"].astype(float).fillna(0.0).values\n",
    "onset  = df[\"EVENT_ONSET\"].astype(int).values\n",
    "idx    = df.index\n",
    "\n",
    "# ---- rolling percentile helper ----\n",
    "def roll_pct_rank(s: pd.Series, win=512):\n",
    "    def pr(w):\n",
    "        v = w[-1]; a = np.sort(w)\n",
    "        return np.searchsorted(a, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=True)\n",
    "\n",
    "# ---- hybrid driver: max(risk_pct, consensus_pct) ----\n",
    "risk_pct = roll_pct_rank(risk, win=WIN_RANK).fillna(0.0)\n",
    "cons_raw = (0.45*pd.Series(Theta_v, index=idx) +\n",
    "            0.35*pd.Series(Theta_c, index=idx) +\n",
    "            0.15*pd.Series(np.maximum(0, AR1_m), index=idx) +\n",
    "            0.05*pd.Series(np.nan_to_num(Gamma_v), index=idx))\n",
    "cons_pct = roll_pct_rank(cons_raw, win=WIN_RANK).fillna(0.0)\n",
    "driver   = pd.Series(np.maximum(risk_pct.values, cons_pct.values), index=idx, name=\"DRIVER\")\n",
    "\n",
    "# ---- optional VIX term-structure gate (non-fatal if fetch fails) ----\n",
    "term_vote = np.zeros(len(idx), dtype=int)\n",
    "try:\n",
    "    import yfinance as yf\n",
    "    def get_close(t):\n",
    "        d = yf.Ticker(t).history(period=\"max\", auto_adjust=False)\n",
    "        return pd.Series(d[\"Close\"]).rename(t)\n",
    "    vix   = get_close(\"^VIX\")\n",
    "    vix9d = get_close(\"^VIX9D\")\n",
    "    vix3m = get_close(\"^VIX3M\")\n",
    "    # align\n",
    "    D = pd.concat([vix, vix9d, vix3m], axis=1).reindex(idx).ffill()\n",
    "    ts1 = (D[\"^VIX9D\"] - D[\"^VIX\"]  > 0).astype(int)   # front stress\n",
    "    ts2 = (D[\"^VIX\"]   - D[\"^VIX3M\"]> 0).astype(int)   # contango inversion\n",
    "    term_vote = np.where((ts1.add(ts2, fill_value=0) > 0), 1, 0)\n",
    "except Exception as e:\n",
    "    # fine; no extra vote\n",
    "    term_vote = np.zeros(len(idx), dtype=int)\n",
    "\n",
    "# ---- core gating pieces (vectors) ----\n",
    "votes_base = ((Theta_v>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_c>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_m>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Gamma_v>=VOTE_THRESH_GAMMA).astype(int) +\n",
    "              ((driver.diff(7).fillna(0.0).values)>0).astype(int) +\n",
    "              term_vote)\n",
    "\n",
    "def make_alert(driver_s: pd.Series, q: float, gate_min_votes: int, persist_win: int, persist_req: int):\n",
    "    t = float(np.quantile(driver_s.values[np.isfinite(driver_s.values)], q))\n",
    "    persist = ((driver_s>=t).astype(int).rolling(persist_win).sum().fillna(0).values >= persist_req)\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    dv = driver_s.values\n",
    "    for i,(r,v,p) in enumerate(zip(dv, votes_base, persist)):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else:\n",
    "                state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and p and (v>=gate_min_votes):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else:\n",
    "                state.append('OK')\n",
    "    return pd.Series(state, index=driver_s.index), t\n",
    "\n",
    "def score(alert_s: pd.Series, onset_arr: np.ndarray, horizon: int, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = np.where(starts)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    e_slice = onset_arr[a.index.get_indexer(ix)]\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if e_slice[s+1:min(s+1+horizon, len(e_slice))].any():\n",
    "            hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years, \"s_ix\": s_ix}\n",
    "\n",
    "# ---- train slice (<=2015-12-31) ----\n",
    "TRAIN_END = pd.Timestamp(\"2015-12-31\")\n",
    "ix_train = idx[idx <= TRAIN_END]\n",
    "assert len(ix_train)>2000\n",
    "\n",
    "# ---- sweep grid ----\n",
    "best=None\n",
    "for horizon in [7, 14]:\n",
    "    for gate_min in [1, 2, 3]:\n",
    "        for pwin in [3, 5]:\n",
    "            for preq in [1, 2]:\n",
    "                for q in QGRID:\n",
    "                    alert_q, thr = make_alert(driver, q, gate_min, pwin, preq)\n",
    "                    res = score(alert_q, onset, horizon, ix_train)\n",
    "                    cand = {\"q\": float(q), \"thr\": float(thr), \"horizon\": horizon,\n",
    "                            \"gate_min_votes\": gate_min, \"persist_win\": pwin, \"persist_req\": preq, **res}\n",
    "                    # pick best: maximize hits under FA budget; tie-break lowest FA, then fewer starts\n",
    "                    if (best is None) or \\\n",
    "                       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\", -1))) or \\\n",
    "                       ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\", -1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "                       ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "                        best = cand.copy(); best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# fallback if zero starts on train\n",
    "if best[\"starts\"] == 0:\n",
    "    q_fallback = float(QGRID[0])\n",
    "    alert_q, thr = make_alert(driver, q_fallback, 1, 3, 1)\n",
    "    res = score(alert_q, onset, 14, ix_train)\n",
    "    best = {\"q\": q_fallback, \"thr\": float(thr), \"horizon\": 14,\n",
    "            \"gate_min_votes\": 1, \"persist_win\": 3, \"persist_req\": 1, **res, \"hits_ok\": res[\"hits\"]}\n",
    "\n",
    "# ---- apply best to FULL series ----\n",
    "alert_final, thr_final = make_alert(driver, best[\"q\"], best[\"gate_min_votes\"], best[\"persist_win\"], best[\"persist_req\"])\n",
    "full = score(alert_final, onset, best[\"horizon\"], idx)\n",
    "\n",
    "# ---- save ----\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_retune_sweep\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "out = df.assign(risk_pct=risk_pct, cons_pct=cons_pct, DRIVER=driver, alert=alert_final)\n",
    "out_cols = [\"RISK\",\"risk_pct\",\"cons_pct\",\"DRIVER\",\"alert\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "out[out_cols].to_csv(RUN / \"gdren_v03a_retune_sweep_alerts.csv\")\n",
    "\n",
    "metrics = {\n",
    "    \"features_used\": str(FEAT),\n",
    "    \"calibrated_q_train\": best[\"q\"],\n",
    "    \"calibrated_thr_driver\": best[\"thr\"],\n",
    "    \"train_horizon_days\": best[\"horizon\"],\n",
    "    \"train_starts\": int(best[\"starts\"]),\n",
    "    \"train_hits\": int(best[\"hits\"]),\n",
    "    \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "    \"gate_min_votes\": int(best[\"gate_min_votes\"]),\n",
    "    \"persist_win\": int(best[\"persist_win\"]),\n",
    "    \"persist_req\": int(best[\"persist_req\"]),\n",
    "    \"full_starts\": int(full[\"starts\"]),\n",
    "    \"full_hits\": int(full[\"hits\"]),\n",
    "    \"full_false_alarms_per_year\": float(full[\"fa_py\"]),\n",
    "    \"fa_per_year_target\": FA_PER_YEAR_TARGET\n",
    "}\n",
    "(Path(RUN / \"gdren_v03a_retune_sweep_metrics.json\")).write_text(json.dumps(metrics, indent=2))\n",
    "print(\"Artifacts:\", json.dumps({\n",
    "    \"alerts_csv\": str(RUN / \"gdren_v03a_retune_sweep_alerts.csv\"),\n",
    "    \"metrics_json\": str(RUN / \"gdren_v03a_retune_sweep_metrics.json\")\n",
    "}, indent=2))\n",
    "print(\"\\n=== RETUNE+++ SUMMARY ===\")\n",
    "for k,v in metrics.items(): print(f\"{k:>26}: {v}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d3832984-5990-4fcf-8b6b-78e2ae569de5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIKE      — OK       as of 2025-11-05 | NEXUS=0.286\n",
      "REGIME     — OK       as of 2025-11-05 | RISK=0.000 DRIVER=1.000\n",
      "\n",
      "[dashboard] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_dashboard_status.json\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Ops Shim v0.1 — “What’s the bell say today?” ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# ---- roots ----\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "assert ROOT.exists(), f\"Missing: {ROOT}\"\n",
    "\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(path_globs):\n",
    "    \"\"\"Return newest file by mtime from a list of glob patterns (recursive).\"\"\"\n",
    "    cands = []\n",
    "    for pat in path_globs:\n",
    "        cands += list(ROOT.glob(pat))\n",
    "    if not cands:\n",
    "        return None\n",
    "    return sorted(cands, key=lambda p: p.stat().st_mtime, reverse=True)[0]\n",
    "\n",
    "def _read_alerts(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "    # normalize to tz-naive daily\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    df = df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "    return df\n",
    "\n",
    "def _status_line(name, df, key_cols=()):\n",
    "    # pick the most recent available day ≤ today\n",
    "    ix = df.index[df.index <= TODAY]\n",
    "    if len(ix) == 0:\n",
    "        ix = df.index\n",
    "    last = ix[-1]\n",
    "    row = df.loc[last]\n",
    "    alert = str(row.get(\"alert\", \"OK\"))\n",
    "    bits = []\n",
    "    for k in key_cols:\n",
    "        if k in row and pd.notna(row[k]):\n",
    "            val = float(row[k])\n",
    "            bits.append(f\"{k}={val:.3f}\")\n",
    "    # since-warning info (if currently WARNING)\n",
    "    since = \"\"\n",
    "    try:\n",
    "        starts = (df[\"alert\"].eq(\"WARNING\") & ~df[\"alert\"].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "        last_start = df.index[(starts) & (df.index <= last)]\n",
    "        if alert == \"WARNING\" and len(last_start) > 0:\n",
    "            days = int((last - last_start[-1]).days)\n",
    "            since = f\" (day {days+1} of WARNING)\"\n",
    "    except Exception:\n",
    "        pass\n",
    "    cols = (\" | \" + \" \".join(bits)) if bits else \"\"\n",
    "    return f\"{name:10s} — {alert:8s} as of {last.date()}{since}{cols}\", last, alert\n",
    "\n",
    "def g_dren_status():\n",
    "    # ---- locate latest artifacts ----\n",
    "    # Spike Bell (v0.2b)\n",
    "    spike_fp = _latest([\n",
    "        \"*_v02b/gdren_v02b_alerts.csv\",      # canonical\n",
    "        \"*_v02b/*alerts*.csv\",               # fallback\n",
    "    ])\n",
    "    # Regime Bell (v0.3 sweeps/retunes)\n",
    "    regime_fp = _latest([\n",
    "        \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",  # preferred\n",
    "        \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\",\n",
    "        \"*/v03a_retune/gdren_v03a_retune_alerts.csv\",\n",
    "        \"*_v02e/*alerts*.csv\", \"*_v02f/*alerts*.csv\", \"*_v02g/*alerts*.csv\"  # earlier betas as fallback\n",
    "    ])\n",
    "\n",
    "    lines = []\n",
    "    payload = {\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "\n",
    "    # ---- Spike Bell ----\n",
    "    if spike_fp and spike_fp.exists():\n",
    "        df_spike = _read_alerts(spike_fp)\n",
    "        line, when, alert = _status_line(\"SPIKE\", df_spike, key_cols=(\"NEXUS\",))\n",
    "        lines.append(line)\n",
    "        payload[\"spike\"] = {\n",
    "            \"file\": str(spike_fp),\n",
    "            \"asof\": str(when.date()),\n",
    "            \"alert\": alert,\n",
    "            \"nexus\": (float(df_spike.loc[when, \"NEXUS\"]) if \"NEXUS\" in df_spike.columns and pd.notna(df_spike.loc[when, \"NEXUS\"]) else None)\n",
    "        }\n",
    "    else:\n",
    "        lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "        payload[\"spike\"] = {\"file\": None, \"alert\": None}\n",
    "\n",
    "    # ---- Regime Bell ----\n",
    "    if regime_fp and regime_fp.exists():\n",
    "        df_reg = _read_alerts(regime_fp)\n",
    "        key_cols = tuple(k for k in (\"RISK\",\"DRIVER\") if k in df_reg.columns)\n",
    "        line, when, alert = _status_line(\"REGIME\", df_reg, key_cols=key_cols)\n",
    "        lines.append(line)\n",
    "        payload[\"regime\"] = {\n",
    "            \"file\": str(regime_fp),\n",
    "            \"asof\": str(when.date()),\n",
    "            \"alert\": alert,\n",
    "            \"risk\": (float(df_reg.loc[when, \"RISK\"]) if \"RISK\" in df_reg.columns and pd.notna(df_reg.loc[when, \"RISK\"]) else None),\n",
    "            \"driver\": (float(df_reg.loc[when, \"DRIVER\"]) if \"DRIVER\" in df_reg.columns and pd.notna(df_reg.loc[when, \"DRIVER\"]) else None)\n",
    "        }\n",
    "    else:\n",
    "        lines.append(\"REGIME     — (no recent v0.3 alerts found)\")\n",
    "        payload[\"regime\"] = {\"file\": None, \"alert\": None}\n",
    "\n",
    "    # ---- write dashboard JSON ----\n",
    "    dash_dir = ROOT / \"dashboard\"\n",
    "    dash_dir.mkdir(parents=True, exist_ok=True)\n",
    "    dash_path = dash_dir / \"g_dren_dashboard_status.json\"\n",
    "    dash_path.write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "    print(\"\\n\".join(lines))\n",
    "    print(f\"\\n[dashboard] {dash_path}\")\n",
    "\n",
    "# ---- run once to print today’s status ----\n",
    "g_dren_status()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "927d32e5-3b10-4b39-b997-f7c36b1750a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== REGIME diagnostics @ 2025-11-05 ==\n",
      "alert         : OK\n",
      "DRIVER / thr  : 1.000 / 1.000 (q=0.965)\n",
      "votes (need≥2): 1  [Θ_vix=0.016 Θ_cred=0.023 Θ_mkt=0.016 Γ_mv=0.776 slope7=0.000]\n",
      "persistence   : OK  (≥1 of last 3 days ≥ thr; had 3)\n",
      "decision path : insufficient votes\n",
      "\n",
      "-- what-if: gate=1, q=0.975, persist_req=1/3 --\n",
      "{'q': 0.975, 'thr': 1.0, 'gate': 1, 'persist_req': 1, 'persist_win': 3, 'qualifies': 1, 'driver_ge_thr': True, 'votes': 1, 'persist_hits': 3, 'persist_len': 3}\n",
      "\n",
      "-- what-if: gate=2, q=0.970, persist_req=1/3 --\n",
      "{'q': 0.97, 'thr': 1.0, 'gate': 2, 'persist_req': 1, 'persist_win': 3, 'qualifies': False, 'driver_ge_thr': True, 'votes': 1, 'persist_hits': 3, 'persist_len': 3}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Ops Diagnostics v0.2 — explain today's REGIME decision + what-ifs ===\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CNT = Path(\"E:/CNT\")\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "# Load latest REGIME alerts + metrics (retune_sweep preferred)\n",
    "alerts_fp = latest([\"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",\n",
    "                    \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\",\n",
    "                    \"*/v03a_retune/gdren_v03a_retune_alerts.csv\"])\n",
    "metrics_fp = latest([\"*/v03a_retune_sweep/gdren_v03a_retune_sweep_metrics.json\",\n",
    "                     \"*/v03a_retune_pp/gdren_v03a_retune_pp_metrics.json\",\n",
    "                     \"*/v03a_retune/gdren_v03a_retune_metrics.json\"])\n",
    "\n",
    "assert alerts_fp and metrics_fp, \"No regime artifacts found\"\n",
    "\n",
    "DF = pd.read_csv(alerts_fp, index_col=0, parse_dates=True).sort_index()\n",
    "DF.index = DF.index.tz_localize(None).normalize()\n",
    "ix = DF.index[DF.index<=TODAY]\n",
    "last = ix[-1] if len(ix) else DF.index[-1]\n",
    "row = DF.loc[last]\n",
    "\n",
    "M = json.loads(metrics_fp.read_text())\n",
    "q    = float(M.get(\"calibrated_q_train\", 0.97))\n",
    "thr  = float(M.get(\"calibrated_thr_driver\", 1.0))\n",
    "gate = int(M.get(\"gate_min_votes\", 2))\n",
    "pwin = int(M.get(\"persist_win\", 3))\n",
    "preq = int(M.get(\"persist_req\", 1))\n",
    "\n",
    "# Compute votes & persistence for today\n",
    "Theta_m = float(row.get(\"Theta_mkt\", 0))\n",
    "Theta_v = float(row.get(\"Theta_vix\", 0))\n",
    "Theta_c = float(row.get(\"Theta_cred\",0))\n",
    "Gamma_v = float(row.get(\"Gamma_mkt_vix\",0))\n",
    "driver  = float(row.get(\"DRIVER\", np.nan)) if \"DRIVER\" in DF.columns else np.nan\n",
    "\n",
    "def votes_at(ts):\n",
    "    i = DF.index.get_loc(ts)\n",
    "    slope7 = 0.0\n",
    "    if i>=7 and \"DRIVER\" in DF.columns:\n",
    "        slope7 = float(DF[\"DRIVER\"].iloc[i] - DF[\"DRIVER\"].iloc[i-7])\n",
    "    v = int(Theta_v>=0.25) + int(Theta_c>=0.25) + int(Theta_m>=0.25) + int(Gamma_v>=0.08) + int(slope7>0)\n",
    "    return v, slope7\n",
    "\n",
    "def persisted(ts, threshold, win, req):\n",
    "    i = DF.index.get_loc(ts)\n",
    "    L = DF[\"DRIVER\"].iloc[max(0,i-win+1):i+1]\n",
    "    return int((L>=threshold).sum() >= req), int((L>=threshold).sum()), len(L)\n",
    "\n",
    "votes, slope7 = votes_at(last)\n",
    "persist_ok, persist_hits, persist_len = persisted(last, thr, pwin, preq)\n",
    "\n",
    "print(f\"== REGIME diagnostics @ {last.date()} ==\")\n",
    "print(f\"alert         : {row.get('alert')}\")\n",
    "print(f\"DRIVER / thr  : {driver:.3f} / {thr:.3f} (q={q})\")\n",
    "print(f\"votes (need≥{gate}): {votes}  [Θ_vix={Theta_v:.3f} Θ_cred={Theta_c:.3f} Θ_mkt={Theta_m:.3f} Γ_mv={Gamma_v:.3f} slope7={slope7:.3f}]\")\n",
    "print(f\"persistence   : {'OK' if persist_ok else 'NO'}  (≥{preq} of last {pwin} days ≥ thr; had {persist_hits})\")\n",
    "\n",
    "reason = []\n",
    "if driver < thr: reason.append(\"driver<threshold\")\n",
    "if votes < gate: reason.append(\"insufficient votes\")\n",
    "if not persist_ok: reason.append(\"failed persistence\")\n",
    "print(\"decision path : \" + (\", \".join(reason) if reason else \"would qualify\"))\n",
    "\n",
    "# --- What-if scenarios ---\n",
    "def simulate(q_alt=None, gate_alt=None, preq_alt=None, pwin_alt=None):\n",
    "    q_a   = q if q_alt is None else q_alt\n",
    "    thr_a = float(DF[\"DRIVER\"].quantile(q_a))\n",
    "    gate_a= gate if gate_alt is None else gate_alt\n",
    "    preq_a= preq if preq_alt is None else preq_alt\n",
    "    pwin_a= pwin if pwin_alt is None else pwin_alt\n",
    "    v,_   = votes_at(last)\n",
    "    p_ok, p_hits, p_len = persisted(last, thr_a, pwin_a, preq_a)\n",
    "    qualifies = (driver>=thr_a) and (v>=gate_a) and p_ok\n",
    "    return {\n",
    "        \"q\": q_a, \"thr\": thr_a, \"gate\": gate_a, \"persist_req\": preq_a, \"persist_win\": pwin_a,\n",
    "        \"qualifies\": qualifies, \"driver_ge_thr\": (driver>=thr_a),\n",
    "        \"votes\": v, \"persist_hits\": p_hits, \"persist_len\": p_len\n",
    "    }\n",
    "\n",
    "print(\"\\n-- what-if: gate=1, q=0.975, persist_req=1/3 --\")\n",
    "print(simulate(q_alt=0.975, gate_alt=1, preq_alt=1, pwin_alt=3))\n",
    "print(\"\\n-- what-if: gate=2, q=0.970, persist_req=1/3 --\")\n",
    "print(simulate(q_alt=0.970, gate_alt=2, preq_alt=1, pwin_alt=3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "62ce74d0-9b9d-4e38-a15f-4a23fd7d17f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIKE      — OK       as of 2025-11-05 | NEXUS=0.286\n",
      "REGIME     — PREWARN  as of 2025-11-05 | RISK=0.000 DRIVER=1.000 policy=PREWARN(Γ strong)\n",
      "\n",
      "[dashboard] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_dashboard_status.json\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Ops Shim v0.1.1 — reason-coded status + PREWARN policy overlay ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _read_alerts(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "\n",
    "def _status_line(name, date, base_alert, extras):\n",
    "    parts = [f\"{name:10s} — {base_alert:8s} as of {date}\"]\n",
    "    if extras:\n",
    "        parts.append(\" | \" + \" \".join(extras))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# ---- locate latest SPIKE + REGIME artifacts ----\n",
    "spike_fp  = _latest([\"*_v02b/gdren_v02b_alerts.csv\", \"*_v02b/*alerts*.csv\"])\n",
    "regime_fp = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_alerts.csv\"\n",
    "])\n",
    "regime_metrics = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_metrics.json\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_metrics.json\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_metrics.json\"\n",
    "])\n",
    "\n",
    "payload = {\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "lines = []\n",
    "\n",
    "# ---- SPIKE status (unchanged) ----\n",
    "if spike_fp and spike_fp.exists():\n",
    "    S = _read_alerts(spike_fp)\n",
    "    ix = S.index[S.index<=TODAY]\n",
    "    last = (ix[-1] if len(ix) else S.index[-1]).date()\n",
    "    s_alert = str(S.loc[pd.Timestamp(last), \"alert\"])\n",
    "    s_nexus = float(S.loc[pd.Timestamp(last), \"NEXUS\"]) if \"NEXUS\" in S.columns else None\n",
    "    lines.append(_status_line(\"SPIKE\", last, s_alert, [f\"NEXUS={s_nexus:.3f}\"] if s_nexus is not None else []))\n",
    "    payload[\"spike\"] = {\"file\": str(spike_fp), \"asof\": str(last), \"alert\": s_alert, \"nexus\": s_nexus}\n",
    "else:\n",
    "    lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "    payload[\"spike\"] = {\"file\": None, \"alert\": None}\n",
    "\n",
    "# ---- REGIME status with reason + PREWARN policy ----\n",
    "if regime_fp and regime_fp.exists() and regime_metrics and regime_metrics.exists():\n",
    "    R = _read_alerts(regime_fp)\n",
    "    with open(regime_metrics, \"r\") as f:\n",
    "        M = json.load(f)\n",
    "\n",
    "    ix = R.index[R.index<=TODAY]\n",
    "    last_ts = ix[-1] if len(ix) else R.index[-1]\n",
    "    last = last_ts.date()\n",
    "    base_alert = str(R.loc[last_ts, \"alert\"])\n",
    "\n",
    "    # pull calibrated threshold if present; else fallback to q-quantile on DRIVER\n",
    "    q = float(M.get(\"calibrated_q_train\", 0.97))\n",
    "    if \"calibrated_thr_driver\" in M:\n",
    "        thr = float(M[\"calibrated_thr_driver\"])\n",
    "    else:\n",
    "        if \"DRIVER\" in R.columns:\n",
    "            thr = float(pd.Series(R[\"DRIVER\"]).quantile(q))\n",
    "        else:\n",
    "            thr = 1.0  # neutral fallback\n",
    "\n",
    "    driver  = float(R.loc[last_ts, \"DRIVER\"]) if \"DRIVER\" in R.columns else np.nan\n",
    "    risk    = float(R.loc[last_ts, \"RISK\"])   if \"RISK\"   in R.columns else np.nan\n",
    "    Theta_m = float(R.loc[last_ts, \"Theta_mkt\"])     if \"Theta_mkt\"     in R.columns else 0.0\n",
    "    Theta_v = float(R.loc[last_ts, \"Theta_vix\"])     if \"Theta_vix\"     in R.columns else 0.0\n",
    "    Theta_c = float(R.loc[last_ts, \"Theta_cred\"])    if \"Theta_cred\"    in R.columns else 0.0\n",
    "    Gamma_v = float(R.loc[last_ts, \"Gamma_mkt_vix\"]) if \"Gamma_mkt_vix\" in R.columns else 0.0\n",
    "\n",
    "    # 7-day slope on DRIVER\n",
    "    i = R.index.get_loc(last_ts)\n",
    "    slope7 = 0.0\n",
    "    if \"DRIVER\" in R.columns and i>=7:\n",
    "        slope7 = float(R[\"DRIVER\"].iloc[i] - R[\"DRIVER\"].iloc[i-7])\n",
    "\n",
    "    # persistence over last 3 days ≥ thr (matches our tuner defaults)\n",
    "    persist_hits = int((R[\"DRIVER\"].iloc[max(0, i-2):i+1] >= thr).sum()) if \"DRIVER\" in R.columns else 0\n",
    "    persist_ok = (persist_hits >= 1)\n",
    "\n",
    "    # votes (same definition as tuner)\n",
    "    votes = int(Theta_v>=0.25) + int(Theta_c>=0.25) + int(Theta_m>=0.25) + int(Gamma_v>=0.08) + int(slope7>0)\n",
    "    gate_needed = int(M.get(\"gate_min_votes\", 2))\n",
    "\n",
    "    # reason for OK\n",
    "    reasons = []\n",
    "    if not np.isfinite(driver) or driver < thr: reasons.append(\"threshold\")\n",
    "    if votes < gate_needed:                      reasons.append(\"votes\")\n",
    "    if not persist_ok:                           reasons.append(\"persistence\")\n",
    "\n",
    "    # PREWARN policy: if driver≥thr & persistence OK & Γ strong (≥0.75), tag PREWARN (no change to WARNING).\n",
    "    policy_alert = base_alert\n",
    "    if base_alert != \"WARNING\":\n",
    "        if np.isfinite(driver) and driver >= thr and persist_ok and (Gamma_v >= 0.75):\n",
    "            policy_alert = \"PREWARN\"\n",
    "\n",
    "    # print line\n",
    "    extras = []\n",
    "    if np.isfinite(risk):   extras.append(f\"RISK={risk:.3f}\")\n",
    "    if np.isfinite(driver): extras.append(f\"DRIVER={driver:.3f}\")\n",
    "    if policy_alert == base_alert and base_alert == \"OK\" and reasons:\n",
    "        extras.append(f\"held_by={'+'.join(reasons)}\")\n",
    "    elif policy_alert == \"PREWARN\":\n",
    "        extras.append(\"policy=PREWARN(Γ strong)\")\n",
    "\n",
    "    lines.append(_status_line(\"REGIME\", last, policy_alert, extras))\n",
    "\n",
    "    payload[\"regime\"] = {\n",
    "        \"file\": str(regime_fp), \"metrics\": str(regime_metrics),\n",
    "        \"asof\": str(last), \"alert\": base_alert, \"policy_alert\": policy_alert,\n",
    "        \"driver\": driver, \"risk\": risk, \"threshold\": thr, \"q\": q,\n",
    "        \"votes\": votes, \"gate_needed\": gate_needed,\n",
    "        \"Theta\": {\"mkt\": Theta_m, \"vix\": Theta_v, \"cred\": Theta_c},\n",
    "        \"Gamma_mkt_vix\": Gamma_v, \"slope7\": slope7,\n",
    "        \"persistence\": {\"ok\": bool(persist_ok), \"hits\": persist_hits, \"win\": 3},\n",
    "        \"held_by\": reasons\n",
    "    }\n",
    "else:\n",
    "    lines.append(\"REGIME     — (no recent v0.3 alerts found)\")\n",
    "    payload[\"regime\"] = {\"file\": None, \"alert\": None}\n",
    "\n",
    "# ---- write dashboard JSON ----\n",
    "dash_dir = ROOT / \"dashboard\"\n",
    "dash_dir.mkdir(parents=True, exist_ok=True)\n",
    "dash_path = dash_dir / \"g_dren_dashboard_status.json\"\n",
    "dash_path.write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "print(\"\\n\".join(lines))\n",
    "print(f\"\\n[dashboard] {dash_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0e568659-0630-42bf-a91e-8d7f07d29843",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Object of type date is not JSON serializable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 178\u001b[39m\n\u001b[32m    176\u001b[39m dash_dir.mkdir(parents=\u001b[38;5;28;01mTrue\u001b[39;00m, exist_ok=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    177\u001b[39m dash_path = dash_dir / \u001b[33m\"\u001b[39m\u001b[33mg_dren_dashboard_status.json\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m dash_path.write_text(\u001b[43mjson\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdumps\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpayload\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m)\n\u001b[32m    180\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m.join(lines))\n\u001b[32m    181\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m[dashboard] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdash_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\__init__.py:238\u001b[39m, in \u001b[36mdumps\u001b[39m\u001b[34m(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)\u001b[39m\n\u001b[32m    232\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    233\u001b[39m     \u001b[38;5;28mcls\u001b[39m = JSONEncoder\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    235\u001b[39m \u001b[43m    \u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m=\u001b[49m\u001b[43mskipkeys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m=\u001b[49m\u001b[43mensure_ascii\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    236\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheck_circular\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m=\u001b[49m\u001b[43mallow_nan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m=\u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m    \u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseparators\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43msort_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m--> \u001b[39m\u001b[32m238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:200\u001b[39m, in \u001b[36mJSONEncoder.encode\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    196\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m encode_basestring(o)\n\u001b[32m    197\u001b[39m \u001b[38;5;66;03m# This doesn't pass the iterator directly to ''.join() because the\u001b[39;00m\n\u001b[32m    198\u001b[39m \u001b[38;5;66;03m# exceptions aren't as detailed.  The list call should be roughly\u001b[39;00m\n\u001b[32m    199\u001b[39m \u001b[38;5;66;03m# equivalent to the PySequence_Fast that ''.join() would do.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m200\u001b[39m chunks = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_one_shot\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    201\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(chunks, (\u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)):\n\u001b[32m    202\u001b[39m     chunks = \u001b[38;5;28mlist\u001b[39m(chunks)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:261\u001b[39m, in \u001b[36mJSONEncoder.iterencode\u001b[39m\u001b[34m(self, o, _one_shot)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    257\u001b[39m     _iterencode = _make_iterencode(\n\u001b[32m    258\u001b[39m         markers, \u001b[38;5;28mself\u001b[39m.default, _encoder, indent, floatstr,\n\u001b[32m    259\u001b[39m         \u001b[38;5;28mself\u001b[39m.key_separator, \u001b[38;5;28mself\u001b[39m.item_separator, \u001b[38;5;28mself\u001b[39m.sort_keys,\n\u001b[32m    260\u001b[39m         \u001b[38;5;28mself\u001b[39m.skipkeys, _one_shot)\n\u001b[32m--> \u001b[39m\u001b[32m261\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_iterencode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\json\\encoder.py:180\u001b[39m, in \u001b[36mJSONEncoder.default\u001b[39m\u001b[34m(self, o)\u001b[39m\n\u001b[32m    161\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdefault\u001b[39m(\u001b[38;5;28mself\u001b[39m, o):\n\u001b[32m    162\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Implement this method in a subclass such that it returns\u001b[39;00m\n\u001b[32m    163\u001b[39m \u001b[33;03m    a serializable object for ``o``, or calls the base implementation\u001b[39;00m\n\u001b[32m    164\u001b[39m \u001b[33;03m    (to raise a ``TypeError``).\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    178\u001b[39m \n\u001b[32m    179\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mObject of type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mo.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    181\u001b[39m                     \u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mis not JSON serializable\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mTypeError\u001b[39m: Object of type date is not JSON serializable"
     ]
    }
   ],
   "source": [
    "# === G-DREN Ops Shim v0.1.2 — history (last 5 transitions) + reason + policy overlay ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "\n",
    "def _last_transitions(df, col=\"alert\", n=5):\n",
    "    a = df[col].astype(str)\n",
    "    trans = (a != a.shift(1)).fillna(True)\n",
    "    pts = df.index[trans]\n",
    "    out=[]\n",
    "    for i in range(len(pts)-1, -1, -1):\n",
    "        t = pts[i]\n",
    "        state = a.loc[t]\n",
    "        if i+1 < len(pts):\n",
    "            next_t = pts[i+1]\n",
    "            days = int((next_t - t).days)\n",
    "        else:\n",
    "            days = int((df.index[-1] - t).days) + 1\n",
    "        out.append((t.date(), state, days))\n",
    "        if len(out) >= n: break\n",
    "    return out\n",
    "\n",
    "def _status_line(name, date, base_alert, extras):\n",
    "    parts = [f\"{name:10s} — {base_alert:8s} as of {date}\"]\n",
    "    if extras: parts.append(\" | \" + \" \".join(extras))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# ---- locate artifacts ----\n",
    "spike_fp  = _latest([\"*_v02b/gdren_v02b_alerts.csv\", \"*_v02b/*alerts*.csv\"])\n",
    "regime_fp = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_alerts.csv\"\n",
    "])\n",
    "regime_metrics = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_metrics.json\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_metrics.json\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_metrics.json\"\n",
    "])\n",
    "\n",
    "payload = {\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "lines   = []\n",
    "overlay = {\"recommendation\": None, \"why\": None}\n",
    "\n",
    "# ---- SPIKE block ----\n",
    "if spike_fp and spike_fp.exists():\n",
    "    S = _load_csv(spike_fp)\n",
    "    ix = S.index[S.index<=TODAY]\n",
    "    last_ts = ix[-1] if len(ix) else S.index[-1]\n",
    "    s_alert = str(S.loc[last_ts, \"alert\"])\n",
    "    s_nexus = float(S.loc[last_ts, \"NEXUS\"]) if \"NEXUS\" in S.columns and pd.notna(S.loc[last_ts, \"NEXUS\"]) else None\n",
    "    lines.append(_status_line(\"SPIKE\", last_ts.date(), s_alert, [f\"NEXUS={s_nexus:.3f}\"] if s_nexus is not None else []))\n",
    "    hist = _last_transitions(S, \"alert\", n=5)\n",
    "    lines.append(\"  recent: \" + \" · \".join([f\"{d}:{st}({days}d)\" for d,st,days in hist]))\n",
    "    payload[\"spike\"] = {\"file\": str(spike_fp), \"asof\": str(last_ts.date()), \"alert\": s_alert, \"nexus\": s_nexus, \"recent\": hist}\n",
    "else:\n",
    "    lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "    payload[\"spike\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# ---- REGIME block (reason + policy PREWARN echo) ----\n",
    "if regime_fp and regime_fp.exists():\n",
    "    R = _load_csv(regime_fp)\n",
    "    ix = R.index[R.index<=TODAY]\n",
    "    last_ts = ix[-1] if len(ix) else R.index[-1]\n",
    "    base_alert = str(R.loc[last_ts, \"alert\"]) if \"alert\" in R.columns else \"OK\"\n",
    "\n",
    "    # metrics (for q / threshold)\n",
    "    q = 0.97\n",
    "    thr = 1.0\n",
    "    if regime_metrics and regime_metrics.exists():\n",
    "        M = json.loads(regime_metrics.read_text())\n",
    "        q   = float(M.get(\"calibrated_q_train\", q))\n",
    "        thr = float(M.get(\"calibrated_thr_driver\", thr)) if \"calibrated_thr_driver\" in M else thr\n",
    "        gate_needed = int(M.get(\"gate_min_votes\", 2))\n",
    "    else:\n",
    "        gate_needed = 2\n",
    "\n",
    "    vals = lambda k, default=0.0: float(R.loc[last_ts, k]) if k in R.columns and pd.notna(R.loc[last_ts, k]) else default\n",
    "    driver  = vals(\"DRIVER\", np.nan) if \"DRIVER\" in R.columns else np.nan\n",
    "    risk    = vals(\"RISK\",   np.nan) if \"RISK\"   in R.columns else np.nan\n",
    "    Theta_m = vals(\"Theta_mkt\")\n",
    "    Theta_v = vals(\"Theta_vix\")\n",
    "    Theta_c = vals(\"Theta_cred\")\n",
    "    Gamma_v = vals(\"Gamma_mkt_vix\")\n",
    "    # slope7\n",
    "    slope7 = 0.0\n",
    "    if \"DRIVER\" in R.columns:\n",
    "        i = R.index.get_loc(last_ts)\n",
    "        if i>=7: slope7 = float(R[\"DRIVER\"].iloc[i] - R[\"DRIVER\"].iloc[i-7])\n",
    "\n",
    "    # persistence 1/3 over threshold\n",
    "    persist_hits = int((R[\"DRIVER\"].iloc[max(0, R.index.get_loc(last_ts)-2):R.index.get_loc(last_ts)+1] >= thr).sum()) if \"DRIVER\" in R.columns else 0\n",
    "    persist_ok   = (persist_hits >= 1)\n",
    "\n",
    "    # votes\n",
    "    votes = int(Theta_v>=0.25) + int(Theta_c>=0.25) + int(Theta_m>=0.25) + int(Gamma_v>=0.08) + int(slope7>0)\n",
    "\n",
    "    # PREWARN overlay (policy): driver≥thr & persist OK & Γ strong\n",
    "    policy_alert = base_alert\n",
    "    if base_alert != \"WARNING\" and np.isfinite(driver) and driver>=thr and persist_ok and (Gamma_v >= 0.75):\n",
    "        policy_alert = \"PREWARN\"\n",
    "\n",
    "    # reason\n",
    "    reasons=[]\n",
    "    if not np.isfinite(driver) or driver < thr: reasons.append(\"threshold\")\n",
    "    if votes < gate_needed:                      reasons.append(\"votes\")\n",
    "    if not persist_ok:                           reasons.append(\"persistence\")\n",
    "\n",
    "    extras = []\n",
    "    if np.isfinite(risk):   extras.append(f\"RISK={risk:.3f}\")\n",
    "    if np.isfinite(driver): extras.append(f\"DRIVER={driver:.3f}\")\n",
    "    if policy_alert == \"PREWARN\" and base_alert != \"WARNING\":\n",
    "        extras.append(\"policy=PREWARN(Γ strong)\")\n",
    "    elif base_alert == \"OK\" and reasons:\n",
    "        extras.append(f\"held_by={'+'.join(reasons)}\")\n",
    "\n",
    "    lines.append(_status_line(\"REGIME\", last_ts.date(), policy_alert, extras))\n",
    "    hist = _last_transitions(R, \"alert\", n=5)\n",
    "    lines.append(\"  recent: \" + \" · \".join([f\"{d}:{st}({days}d)\" for d,st,days in hist]))\n",
    "\n",
    "    payload[\"regime\"] = {\n",
    "        \"file\": str(regime_fp),\n",
    "        \"metrics\": (str(regime_metrics) if regime_metrics else None),\n",
    "        \"asof\": str(last_ts.date()),\n",
    "        \"alert\": base_alert,\n",
    "        \"policy_alert\": policy_alert,\n",
    "        \"q\": q, \"threshold\": thr,\n",
    "        \"driver\": driver, \"risk\": risk,\n",
    "        \"Theta\": {\"mkt\": Theta_m, \"vix\": Theta_v, \"cred\": Theta_c},\n",
    "        \"Gamma_mkt_vix\": Gamma_v, \"slope7\": slope7,\n",
    "        \"votes\": votes, \"gate_needed\": gate_needed,\n",
    "        \"persistence\": {\"ok\": bool(persist_ok), \"hits\": persist_hits, \"win\": 3},\n",
    "        \"recent\": hist,\n",
    "        \"held_by\": reasons\n",
    "    }\n",
    "\n",
    "    # policy overlay recommendation if PREWARN pattern (driver≥thr & Γ strong) is present but votes < gate\n",
    "    overlay_path = ROOT / \"dashboard\" / \"g_dren_policy_overlay.json\"\n",
    "    overlay_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    if np.isfinite(driver) and driver>=thr and persist_ok and (Gamma_v >= 0.75) and (votes < gate_needed):\n",
    "        overlay = {\n",
    "            \"recommendation\": \"consider temporary gate=1 with q≈0.975 (persist 1/3) to catch potential onset; keep FA budget ≤0.8/yr\",\n",
    "            \"why\": {\n",
    "                \"driver_ge_threshold\": True,\n",
    "                \"gamma_strong\": True,\n",
    "                \"persistence_ok\": True,\n",
    "                \"votes_vs_gate\": f\"{votes} < {gate_needed}\"\n",
    "            },\n",
    "            \"asof\": str(last_ts.date())\n",
    "        }\n",
    "    else:\n",
    "        overlay = {\"recommendation\": None, \"why\": None, \"asof\": str(last_ts.date())}\n",
    "    overlay_path.write_text(json.dumps(overlay, indent=2))\n",
    "\n",
    "else:\n",
    "    lines.append(\"REGIME     — (no recent v0.3 alerts found)\")\n",
    "    payload[\"regime\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# ---- write dashboard JSON ----\n",
    "dash_dir = ROOT / \"dashboard\"\n",
    "dash_dir.mkdir(parents=True, exist_ok=True)\n",
    "dash_path = dash_dir / \"g_dren_dashboard_status.json\"\n",
    "dash_path.write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "print(\"\\n\".join(lines))\n",
    "print(f\"\\n[dashboard] {dash_path}\")\n",
    "if overlay[\"recommendation\"]:\n",
    "    print(f\"[overlay ] {ROOT/'dashboard'/'g_dren_policy_overlay.json'}  ← suggestion saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9dd773d2-4257-4e8e-b87a-6e0ccc9af8fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIKE      — OK       as of 2025-11-05 | NEXUS=0.286\n",
      "  recent: 2024-04-18:OK(567d) · 2024-03-11:WATCH(38d) · 2023-12-30:WARNING(72d) · 2023-11-27:WATCH(33d) · 2022-12-27:OK(335d)\n",
      "REGIME     — PREWARN  as of 2025-11-05 | RISK=0.000 DRIVER=1.000 policy=PREWARN(Γ strong)\n",
      "  recent: 2008-12-31:OK(6154d) · 2008-12-20:WARNING(11d) · 2007-09-30:OK(447d) · 2007-09-19:WARNING(11d) · 2007-08-07:OK(43d)\n",
      "\n",
      "[dashboard] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_dashboard_status.json\n",
      "[overlay ] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_policy_overlay.json  ← suggestion saved\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Ops Shim v0.1.2-fix — JSON-safe dates + history + policy overlay ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CNT = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "\n",
    "def _last_transitions(df, col=\"alert\", n=5):\n",
    "    a = df[col].astype(str)\n",
    "    trans = (a != a.shift(1)).fillna(True)\n",
    "    pts = df.index[trans]\n",
    "    out=[]\n",
    "    for i in range(len(pts)-1, -1, -1):\n",
    "        t = pts[i]\n",
    "        state = a.loc[t]\n",
    "        if i+1 < len(pts):\n",
    "            next_t = pts[i+1]\n",
    "            days = int((next_t - t).days)\n",
    "        else:\n",
    "            days = int((df.index[-1] - t).days) + 1\n",
    "        out.append((t.date(), state, days))\n",
    "        if len(out) >= n: break\n",
    "    return out\n",
    "\n",
    "def _stringify_recent(hist):\n",
    "    # convert [(date, state, days), ...] -> [{\"date\":\"YYYY-MM-DD\",\"state\":..., \"days\":...}, ...]\n",
    "    return [{\"date\": str(d), \"state\": st, \"days\": int(days)} for (d, st, days) in hist]\n",
    "\n",
    "def _status_line(name, date, base_alert, extras):\n",
    "    parts = [f\"{name:10s} — {base_alert:8s} as of {date}\"]\n",
    "    if extras: parts.append(\" | \" + \" \".join(extras))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# ---- locate artifacts ----\n",
    "spike_fp  = _latest([\"*_v02b/gdren_v02b_alerts.csv\", \"*_v02b/*alerts*.csv\"])\n",
    "regime_fp = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_alerts.csv\"\n",
    "])\n",
    "regime_metrics = _latest([\n",
    "    \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_metrics.json\",\n",
    "    \"*/v03a_retune_pp/gdren_v03a_retune_pp_metrics.json\",\n",
    "    \"*/v03a_retune/gdren_v03a_retune_metrics.json\"\n",
    "])\n",
    "\n",
    "payload = {\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "lines   = []\n",
    "overlay = {\"recommendation\": None, \"why\": None, \"asof\": str(TODAY.date())}\n",
    "\n",
    "# ---- SPIKE block ----\n",
    "if spike_fp and spike_fp.exists():\n",
    "    S = _load_csv(spike_fp)\n",
    "    ix = S.index[S.index<=TODAY]\n",
    "    last_ts = ix[-1] if len(ix) else S.index[-1]\n",
    "    s_alert = str(S.loc[last_ts, \"alert\"])\n",
    "    s_nexus = float(S.loc[last_ts, \"NEXUS\"]) if \"NEXUS\" in S.columns and pd.notna(S.loc[last_ts, \"NEXUS\"]) else None\n",
    "    lines.append(_status_line(\"SPIKE\", str(last_ts.date()), s_alert, [f\"NEXUS={s_nexus:.3f}\"] if s_nexus is not None else []))\n",
    "    hist = _last_transitions(S, \"alert\", n=5)\n",
    "    lines.append(\"  recent: \" + \" · \".join([f\"{d}:{st}({days}d)\" for d,st,days in hist]))\n",
    "    payload[\"spike\"] = {\n",
    "        \"file\": str(spike_fp),\n",
    "        \"asof\": str(last_ts.date()),\n",
    "        \"alert\": s_alert,\n",
    "        \"nexus\": (float(s_nexus) if s_nexus is not None else None),\n",
    "        \"recent\": _stringify_recent(hist)\n",
    "    }\n",
    "else:\n",
    "    lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "    payload[\"spike\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# ---- REGIME block ----\n",
    "if regime_fp and regime_fp.exists():\n",
    "    R = _load_csv(regime_fp)\n",
    "    ix = R.index[R.index<=TODAY]\n",
    "    last_ts = ix[-1] if len(ix) else R.index[-1]\n",
    "    base_alert = str(R.loc[last_ts, \"alert\"]) if \"alert\" in R.columns else \"OK\"\n",
    "\n",
    "    # metrics (for q / threshold)\n",
    "    q = 0.97; thr = 1.0; gate_needed = 2\n",
    "    if regime_metrics and regime_metrics.exists():\n",
    "        M = json.loads(regime_metrics.read_text())\n",
    "        q   = float(M.get(\"calibrated_q_train\", q))\n",
    "        thr = float(M.get(\"calibrated_thr_driver\", thr)) if \"calibrated_thr_driver\" in M else thr\n",
    "        gate_needed = int(M.get(\"gate_min_votes\", gate_needed))\n",
    "\n",
    "    # pull values (coerce to plain floats)\n",
    "    def val(col, default=np.nan):\n",
    "        return float(R.loc[last_ts, col]) if col in R.columns and pd.notna(R.loc[last_ts, col]) else float(default)\n",
    "\n",
    "    driver  = val(\"DRIVER\", np.nan) if \"DRIVER\" in R.columns else np.nan\n",
    "    risk    = val(\"RISK\",   np.nan) if \"RISK\"   in R.columns else np.nan\n",
    "    Theta_m = val(\"Theta_mkt\", 0.0); Theta_v = val(\"Theta_vix\", 0.0); Theta_c = val(\"Theta_cred\", 0.0)\n",
    "    Gamma_v = val(\"Gamma_mkt_vix\", 0.0)\n",
    "\n",
    "    i = R.index.get_loc(last_ts)\n",
    "    slope7 = 0.0\n",
    "    if \"DRIVER\" in R.columns and i>=7:\n",
    "        slope7 = float(R[\"DRIVER\"].iloc[i] - R[\"DRIVER\"].iloc[i-7])\n",
    "\n",
    "    persist_hits = int((R[\"DRIVER\"].iloc[max(0, i-2):i+1] >= thr).sum()) if \"DRIVER\" in R.columns else 0\n",
    "    persist_ok   = bool(persist_hits >= 1)\n",
    "\n",
    "    votes = int(Theta_v>=0.25) + int(Theta_c>=0.25) + int(Theta_m>=0.25) + int(Gamma_v>=0.08) + int(slope7>0)\n",
    "\n",
    "    # PREWARN overlay (policy): driver≥thr & persist OK & Γ strong (no change to WARNING logic)\n",
    "    policy_alert = base_alert\n",
    "    if base_alert != \"WARNING\" and np.isfinite(driver) and driver>=thr and persist_ok and (Gamma_v >= 0.75):\n",
    "        policy_alert = \"PREWARN\"\n",
    "        overlay = {\n",
    "            \"recommendation\": \"consider temporary gate=1 with q≈0.975 (persist 1/3) to catch potential onset; keep FA budget ≤0.8/yr\",\n",
    "            \"why\": {\n",
    "                \"driver_ge_threshold\": True,\n",
    "                \"gamma_strong\": True,\n",
    "                \"persistence_ok\": True,\n",
    "                \"votes_vs_gate\": f\"{votes} < {gate_needed}\"\n",
    "            },\n",
    "            \"asof\": str(last_ts.date())\n",
    "        }\n",
    "\n",
    "    # reasons for holding\n",
    "    reasons = []\n",
    "    if not np.isfinite(driver) or driver < thr: reasons.append(\"threshold\")\n",
    "    if votes < gate_needed:                      reasons.append(\"votes\")\n",
    "    if not persist_ok:                           reasons.append(\"persistence\")\n",
    "\n",
    "    extras = []\n",
    "    if np.isfinite(risk):   extras.append(f\"RISK={risk:.3f}\")\n",
    "    if np.isfinite(driver): extras.append(f\"DRIVER={driver:.3f}\")\n",
    "    if policy_alert == \"PREWARN\" and base_alert != \"WARNING\":\n",
    "        extras.append(\"policy=PREWARN(Γ strong)\")\n",
    "    elif base_alert == \"OK\" and reasons:\n",
    "        extras.append(f\"held_by={'+'.join(reasons)}\")\n",
    "\n",
    "    lines.append(_status_line(\"REGIME\", str(last_ts.date()), policy_alert, extras))\n",
    "    hist = _last_transitions(R, \"alert\", n=5)\n",
    "    lines.append(\"  recent: \" + \" · \".join([f\"{d}:{st}({days}d)\" for d,st,days in hist]))\n",
    "\n",
    "    payload[\"regime\"] = {\n",
    "        \"file\": str(regime_fp),\n",
    "        \"metrics\": (str(regime_metrics) if regime_metrics else None),\n",
    "        \"asof\": str(last_ts.date()),\n",
    "        \"alert\": base_alert,\n",
    "        \"policy_alert\": policy_alert,\n",
    "        \"q\": float(q), \"threshold\": float(thr),\n",
    "        \"driver\": (float(driver) if np.isfinite(driver) else None),\n",
    "        \"risk\":   (float(risk)   if np.isfinite(risk)   else None),\n",
    "        \"Theta\": {\"mkt\": float(Theta_m), \"vix\": float(Theta_v), \"cred\": float(Theta_c)},\n",
    "        \"Gamma_mkt_vix\": float(Gamma_v),\n",
    "        \"slope7\": float(slope7),\n",
    "        \"votes\": int(votes), \"gate_needed\": int(gate_needed),\n",
    "        \"persistence\": {\"ok\": bool(persist_ok), \"hits\": int(persist_hits), \"win\": 3},\n",
    "        \"recent\": _stringify_recent(hist),\n",
    "        \"held_by\": reasons\n",
    "    }\n",
    "else:\n",
    "    lines.append(\"REGIME     — (no recent v0.3 alerts found)\")\n",
    "    payload[\"regime\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# ---- write dashboard JSONs (JSON-safe) ----\n",
    "dash_dir = ROOT / \"dashboard\"\n",
    "dash_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "dash_path = dash_dir / \"g_dren_dashboard_status.json\"\n",
    "dash_path.write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "overlay_path = dash_dir / \"g_dren_policy_overlay.json\"\n",
    "overlay_path.write_text(json.dumps(overlay, indent=2))\n",
    "\n",
    "print(\"\\n\".join(lines))\n",
    "print(f\"\\n[dashboard] {dash_path}\")\n",
    "if overlay.get(\"recommendation\"):\n",
    "    print(f\"[overlay ] {overlay_path}  ← suggestion saved\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "71d6d3df-4d62-4039-b143-4a32b5a692f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPIKE      — OK       as of 2025-11-05 | NEXUS=0.286\n",
      "REGIME     — PREWARN  as of 2025-11-05 | RISK=0.000 DRIVER=1.000 policy=PREWARN(Γ strong)\n",
      "\n",
      "[dashboard] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_dashboard_status.json\n",
      "[history  ] E:\\CNT\\artifacts\\g_dren\\dashboard\\spike_transitions.csv (if SPIKE present)\n",
      "[history  ] E:\\CNT\\artifacts\\g_dren\\dashboard\\regime_transitions.csv\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Daily Runner v0.1 — retune sweep → dashboard → history CSVs ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ---- knobs (tweak as you like) ----\n",
    "FA_PER_YEAR_TARGET = 0.60       # false-alarm budget for regime tuner\n",
    "COOLDOWN_DAYS      = 14\n",
    "MAX_WARN_DAYS      = 12\n",
    "HYST_EXIT_DAYS     = 3\n",
    "QGRID              = np.linspace(0.965, 0.990, 51)\n",
    "WIN_RANK           = 512\n",
    "VOTE_THRESH_THETA  = 0.25\n",
    "VOTE_THRESH_GAMMA  = 0.08\n",
    "LOOKAHEAD_DAYS     = 14         # regime horizon used in sweep scoring\n",
    "\n",
    "# If features look stale (> 3 days old), we *warn* but do not recompute here.\n",
    "STALE_FEATURE_DAYS = 3\n",
    "\n",
    "# ---- paths ----\n",
    "CNT  = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "DASH = ROOT / \"dashboard\"\n",
    "ROOT.mkdir(parents=True, exist_ok=True); DASH.mkdir(parents=True, exist_ok=True)\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True)\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")].sort_index()\n",
    "\n",
    "def _pct_rank(s: pd.Series, win=512):\n",
    "    def pr(w):\n",
    "        v = w[-1]; a = np.sort(w)\n",
    "        return np.searchsorted(a, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=True)\n",
    "\n",
    "def _transitions(df, col=\"alert\", n=5):\n",
    "    a = df[col].astype(str)\n",
    "    trans = (a != a.shift(1)).fillna(True)\n",
    "    pts = df.index[trans]\n",
    "    out=[]\n",
    "    for i in range(len(pts)-1, -1, -1):\n",
    "        t = pts[i]; state = a.loc[t]\n",
    "        days = (pts[i+1]-t).days if i+1 < len(pts) else (df.index[-1]-t).days + 1\n",
    "        out.append((str(t.date()), state, int(days)))\n",
    "        if len(out)>=n: break\n",
    "    return out\n",
    "\n",
    "# ---------- 1) Locate latest Spike + Regime feature/alert files ----------\n",
    "spike_alerts = _latest([\"*_v02b/gdren_v02b_alerts.csv\", \"*_v02b/*alerts*.csv\"])\n",
    "reg_features = _latest([\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"])\n",
    "if reg_features is None:\n",
    "    raise FileNotFoundError(\"No v03a_lite_fix_features.csv found — run the v0.3a-lite (fix) cell once to seed features.\")\n",
    "\n",
    "age_days = (pd.Timestamp.fromtimestamp(reg_features.stat().st_mtime).normalize() - TODAY).days\n",
    "if age_days < -STALE_FEATURE_DAYS:\n",
    "    print(f\"[warn] Regime features are {abs(age_days)} days old → consider re-running v0.3a-lite fix to refresh.\")\n",
    "\n",
    "DF = _load_csv(reg_features)\n",
    "\n",
    "# ---------- 2) Build Regime hybrid DRIVER & run retune sweep ----------\n",
    "required = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "miss = [c for c in required if c not in DF.columns]\n",
    "if miss: raise ValueError(f\"Missing columns in features CSV: {miss}\")\n",
    "\n",
    "risk   = pd.Series(DF[\"RISK\"].astype(float), index=DF.index).fillna(0.0)\n",
    "Theta_v= DF[\"Theta_vix\"].astype(float).values\n",
    "Theta_c= DF[\"Theta_cred\"].astype(float).values\n",
    "Theta_m= DF[\"Theta_mkt\"].astype(float).values\n",
    "Gamma_v= DF[\"Gamma_mkt_vix\"].astype(float).values\n",
    "AR1_m  = DF[\"AR1_mkt\"].astype(float).values\n",
    "onset  = DF[\"EVENT_ONSET\"].astype(int).values\n",
    "idx    = DF.index\n",
    "\n",
    "risk_pct = _pct_rank(risk, win=WIN_RANK).fillna(0.0)\n",
    "cons_raw = (0.45*pd.Series(Theta_v, index=idx) +\n",
    "            0.35*pd.Series(Theta_c, index=idx) +\n",
    "            0.15*pd.Series(np.maximum(0, AR1_m), index=idx) +\n",
    "            0.05*pd.Series(np.nan_to_num(Gamma_v), index=idx))\n",
    "cons_pct = _pct_rank(cons_raw, win=WIN_RANK).fillna(0.0)\n",
    "driver   = pd.Series(np.maximum(risk_pct.values, cons_pct.values), index=idx, name=\"DRIVER\")\n",
    "\n",
    "votes_base = ((Theta_v>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_c>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_m>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Gamma_v>=VOTE_THRESH_GAMMA).astype(int) +\n",
    "              ((driver.diff(7).fillna(0.0).values)>0).astype(int))\n",
    "\n",
    "def make_alert(driver_s, q, gate_min=2, persist_win=3, persist_req=1):\n",
    "    t = float(np.quantile(driver_s.values[np.isfinite(driver_s.values)], q))\n",
    "    persist = ((driver_s>=t).astype(int).rolling(persist_win).sum().fillna(0).values >= persist_req)\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    dv = driver_s.values\n",
    "    for r,v,p in zip(dv, votes_base, persist):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else: state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and p and (v>=gate_min):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else: state.append('OK')\n",
    "    return pd.Series(state, index=driver_s.index), t\n",
    "\n",
    "def score(alert_s, horizon, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = np.where(starts)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    e_slice = onset[a.index.get_indexer(ix)]\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if e_slice[s+1:min(s+1+horizon, len(e_slice))].any(): hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years}, pd.Index(a.index[s_ix])\n",
    "\n",
    "# Train slice for calibration (≤2015-12-31)\n",
    "ix_train = idx[idx <= pd.Timestamp(\"2015-12-31\")]\n",
    "if len(ix_train) < 2000:\n",
    "    ix_train = idx[: int(len(idx)*0.6)]  # fallback split\n",
    "\n",
    "best=None\n",
    "for gate_min in [1,2,3]:\n",
    "    for pwin in [3,5]:\n",
    "        for preq in [1,2]:\n",
    "            for q in QGRID:\n",
    "                alert_q, thr = make_alert(driver, q, gate_min, pwin, preq)\n",
    "                res,_ = score(alert_q, LOOKAHEAD_DAYS, ix_train)\n",
    "                cand = {\"q\": float(q), \"thr\": float(thr), \"gate\": gate_min, \"pwin\": pwin, \"preq\": preq, **res}\n",
    "                if (best is None) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\",-1))) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\",-1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "                   ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "                    best = cand.copy(); best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# apply to full series\n",
    "alert_final, thr_final = make_alert(driver, best[\"q\"], best[\"gate\"], best[\"pwin\"], best[\"preq\"])\n",
    "full_res, starts_idx   = score(alert_final, LOOKAHEAD_DAYS, idx)\n",
    "\n",
    "# Save regime sweep outputs\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_daily\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "out_df = DF.assign(risk_pct=risk_pct, cons_pct=cons_pct, DRIVER=driver, alert=alert_final)\n",
    "cols = [\"RISK\",\"risk_pct\",\"cons_pct\",\"DRIVER\",\"alert\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "out_df[cols].to_csv(RUN / \"gdren_v03a_daily_alerts.csv\")\n",
    "(Path(RUN / \"gdren_v03a_daily_metrics.json\")).write_text(json.dumps({\n",
    "    \"q\": best[\"q\"], \"thr\": best[\"thr\"], \"gate_min_votes\": best[\"gate\"],\n",
    "    \"persist_win\": best[\"pwin\"], \"persist_req\": best[\"preq\"],\n",
    "    \"train_hits\": int(best[\"hits\"]), \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "    \"full_starts\": int(full_res[\"starts\"]), \"full_hits\": int(full_res[\"hits\"]),\n",
    "    \"full_fa_per_year\": float(full_res[\"fa_py\"]), \"horizon_days\": LOOKAHEAD_DAYS\n",
    "}, indent=2))\n",
    "\n",
    "# ---------- 3) Update dashboard + overlay ----------\n",
    "def _status_line(name, date, base_alert, extras):\n",
    "    parts = [f\"{name:10s} — {base_alert:8s} as of {date}\"]\n",
    "    if extras: parts.append(\" | \" + \" \".join(extras))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "lines=[]; payload={\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "\n",
    "# SPIKE status\n",
    "if spike_alerts and spike_alerts.exists():\n",
    "    S = _load_csv(spike_alerts)\n",
    "    s_last = (S.index[S.index<=TODAY][-1] if any(S.index<=TODAY) else S.index[-1])\n",
    "    s_alert = str(S.loc[s_last, \"alert\"])\n",
    "    s_nexus = float(S.loc[s_last, \"NEXUS\"]) if \"NEXUS\" in S.columns and pd.notna(S.loc[s_last, \"NEXUS\"]) else None\n",
    "    lines.append(_status_line(\"SPIKE\", str(s_last.date()), s_alert, [f\"NEXUS={s_nexus:.3f}\"] if s_nexus is not None else []))\n",
    "    s_hist = _transitions(S, \"alert\", n=5)\n",
    "    payload[\"spike\"] = {\"file\": str(spike_alerts), \"asof\": str(s_last.date()), \"alert\": s_alert, \"nexus\": s_nexus, \"recent\": s_hist}\n",
    "else:\n",
    "    lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "    payload[\"spike\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# REGIME status (from today’s RUN)\n",
    "R = _load_csv(RUN / \"gdren_v03a_daily_alerts.csv\")\n",
    "r_last = (R.index[R.index<=TODAY][-1] if any(R.index<=TODAY) else R.index[-1])\n",
    "base_alert = str(R.loc[r_last, \"alert\"])\n",
    "driver_last= float(R.loc[r_last, \"DRIVER\"]) if \"DRIVER\" in R.columns else None\n",
    "risk_last  = float(R.loc[r_last, \"RISK\"])   if \"RISK\"   in R.columns else None\n",
    "\n",
    "# policy PREWARN echo: driver≥thr & Γ strong\n",
    "Gamma_v_last = float(R.loc[r_last, \"Gamma_mkt_vix\"]) if \"Gamma_mkt_vix\" in R.columns else 0.0\n",
    "persist_hits = int((R[\"DRIVER\"].iloc[max(0, R.index.get_loc(r_last)-2):R.index.get_loc(r_last)+1] >= best[\"thr\"]).sum()) if \"DRIVER\" in R.columns else 0\n",
    "persist_ok   = (persist_hits >= 1)\n",
    "policy_alert = base_alert\n",
    "if base_alert != \"WARNING\" and np.isfinite(driver_last) and driver_last>=best[\"thr\"] and persist_ok and (Gamma_v_last >= 0.75):\n",
    "    policy_alert = \"PREWARN\"\n",
    "\n",
    "extras = []\n",
    "if risk_last is not None:   extras.append(f\"RISK={risk_last:.3f}\")\n",
    "if driver_last is not None: extras.append(f\"DRIVER={driver_last:.3f}\")\n",
    "if policy_alert == \"PREWARN\" and base_alert != \"WARNING\": extras.append(\"policy=PREWARN(Γ strong)\")\n",
    "\n",
    "lines.append(_status_line(\"REGIME\", str(r_last.date()), policy_alert, extras))\n",
    "r_hist = _transitions(R, \"alert\", n=5)\n",
    "\n",
    "payload[\"regime\"] = {\n",
    "    \"file\": str(RUN / \"gdren_v03a_daily_alerts.csv\"),\n",
    "    \"asof\": str(r_last.date()),\n",
    "    \"alert\": base_alert, \"policy_alert\": policy_alert,\n",
    "    \"driver\": driver_last, \"risk\": risk_last,\n",
    "    \"threshold\": float(best[\"thr\"]), \"q\": float(best[\"q\"]),\n",
    "    \"gate_min_votes\": int(best[\"gate\"]), \"persist_win\": int(best[\"pwin\"]), \"persist_req\": int(best[\"preq\"]),\n",
    "    \"recent\": r_hist\n",
    "}\n",
    "\n",
    "# write JSON\n",
    "(DASH / \"g_dren_dashboard_status.json\").write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "# ---------- 4) Export transitions CSVs ----------\n",
    "def export_transitions_csv(fp_in, fp_out):\n",
    "    D = _load_csv(fp_in)\n",
    "    hist = _transitions(D, \"alert\", n=9999)  # full history\n",
    "    pd.DataFrame(hist, columns=[\"date\",\"state\",\"days\"]).to_csv(fp_out, index=False)\n",
    "\n",
    "if spike_alerts and spike_alerts.exists():\n",
    "    export_transitions_csv(spike_alerts, DASH / \"spike_transitions.csv\")\n",
    "export_transitions_csv(RUN / \"gdren_v03a_daily_alerts.csv\", DASH / \"regime_transitions.csv\")\n",
    "\n",
    "# ---------- 5) Print status ----------\n",
    "print(\"\\n\".join(lines))\n",
    "print(f\"\\n[dashboard] {DASH/'g_dren_dashboard_status.json'}\")\n",
    "print(f\"[history  ] {DASH/'spike_transitions.csv'} (if SPIKE present)\")\n",
    "print(f\"[history  ] {DASH/'regime_transitions.csv'}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3a3281c0-bc5c-4465-986b-c2f42b7a7e22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Artifacts: {\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-235917Z\\\\v03a_gate_patch\\\\gdren_v03a_gate_patch_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251105-235917Z\\\\v03a_gate_patch\\\\gdren_v03a_gate_patch_metrics.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === Regime Gate Patch v0.3 — add VIX term-structure + LQD/IEF slope votes into retune sweep ===\n",
    "import json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----- knobs -----\n",
    "FA_PER_YEAR_TARGET = 0.60\n",
    "COOLDOWN_DAYS      = 14\n",
    "MAX_WARN_DAYS      = 12\n",
    "HYST_EXIT_DAYS     = 3\n",
    "LOOKAHEAD_DAYS     = 14\n",
    "QGRID              = np.linspace(0.965, 0.990, 51)\n",
    "WIN_RANK           = 512\n",
    "VOTE_THRESH_THETA  = 0.25\n",
    "VOTE_THRESH_GAMMA  = 0.08\n",
    "\n",
    "CNT  = Path(\"E:/CNT\")\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "ROOT.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True).sort_index()\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "def _pct_rank(s: pd.Series, win=512):\n",
    "    def pr(w):\n",
    "        v = w[-1]; a = np.sort(w)\n",
    "        return np.searchsorted(a, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=True)\n",
    "\n",
    "# 1) Load latest v03a_lite_fix features\n",
    "feat_fp = _latest([\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"])\n",
    "assert feat_fp, \"Run v0.3a-lite (fix) once to seed features.\"\n",
    "DF = _load_csv(feat_fp)\n",
    "\n",
    "need = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "missing = [c for c in need if c not in DF.columns]\n",
    "assert not missing, f\"Missing columns: {missing}\"\n",
    "\n",
    "risk   = DF[\"RISK\"].astype(float).fillna(0.0)\n",
    "Theta_v= DF[\"Theta_vix\"].astype(float).fillna(0.0).values\n",
    "Theta_c= DF[\"Theta_cred\"].astype(float).fillna(0.0).values\n",
    "Theta_m= DF[\"Theta_mkt\"].astype(float).fillna(0.0).values\n",
    "Gamma_v= DF[\"Gamma_mkt_vix\"].astype(float).fillna(0.0).values\n",
    "AR1_m  = DF[\"AR1_mkt\"].astype(float).fillna(0.0).values\n",
    "onset  = DF[\"EVENT_ONSET\"].astype(int).values\n",
    "idx    = DF.index\n",
    "\n",
    "# 2) Build DRIVER (risk percentile ∨ consensus percentile)\n",
    "risk_pct = _pct_rank(risk, win=WIN_RANK).fillna(0.0)\n",
    "cons_raw = (0.45*pd.Series(Theta_v, index=idx) +\n",
    "            0.35*pd.Series(Theta_c, index=idx) +\n",
    "            0.15*pd.Series(np.maximum(0, AR1_m), index=idx) +\n",
    "            0.05*pd.Series(np.nan_to_num(Gamma_v), index=idx))\n",
    "cons_pct = _pct_rank(cons_raw, win=WIN_RANK).fillna(0.0)\n",
    "driver   = pd.Series(np.maximum(risk_pct.values, cons_pct.values), index=idx, name=\"DRIVER\")\n",
    "\n",
    "# 3) Extra votes (new): VIX term-structure + IG credit slope\n",
    "def fetch_series(ticker):\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        d = yf.Ticker(ticker).history(period=\"max\", auto_adjust=False)\n",
    "        if isinstance(d, pd.DataFrame) and \"Close\" in d and len(d)>0:\n",
    "            s = pd.Series(d[\"Close\"]).rename(ticker)\n",
    "            s.index = pd.DatetimeIndex(s.index).tz_localize(None).normalize()\n",
    "            return s\n",
    "    except Exception:\n",
    "        pass\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "vix   = fetch_series(\"^VIX\")\n",
    "vix9d = fetch_series(\"^VIX9D\")\n",
    "vix3m = fetch_series(\"^VIX3M\")\n",
    "D_vix = pd.concat([vix9d, vix, vix3m], axis=1).reindex(idx).ffill()\n",
    "\n",
    "term_vote = ((D_vix.get(\"^VIX9D\",0) - D_vix.get(\"^VIX\",0) > 0).astype(int) +\n",
    "             (D_vix.get(\"^VIX\",0)   - D_vix.get(\"^VIX3M\",0) > 0).astype(int))\n",
    "term_vote = term_vote.fillna(0).clip(0,1).astype(int).values  # 1 if any inversion\n",
    "\n",
    "lqd = fetch_series(\"LQD\")\n",
    "ief = fetch_series(\"IEF\")\n",
    "D_ig = pd.concat([lqd, ief], axis=1).reindex(idx).ffill()\n",
    "ig_ratio = (D_ig[\"LQD\"] / D_ig[\"IEF\"]) if (\"LQD\" in D_ig and \"IEF\" in D_ig) else pd.Series(0.0, index=idx)\n",
    "ig_slope = ig_ratio.pct_change().rolling(10).mean()   # 10d slope proxy\n",
    "ig_vote  = (ig_slope < 0).astype(int).values          # deterioration vote\n",
    "\n",
    "# 4) Base votes + new votes\n",
    "votes_base = ((Theta_v>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_c>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_m>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Gamma_v>=VOTE_THRESH_GAMMA).astype(int) +\n",
    "              ((driver.diff(7).fillna(0.0).values)>0).astype(int))\n",
    "votes_ext  = votes_base + term_vote + ig_vote  # << extended votes\n",
    "\n",
    "def make_alert(driver_s, q, gate_min=2, persist_win=3, persist_req=1):\n",
    "    t = float(np.quantile(driver_s.values[np.isfinite(driver_s.values)], q))\n",
    "    persist = ((driver_s>=t).astype(int).rolling(persist_win).sum().fillna(0).values >= persist_req)\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    dv = driver_s.values\n",
    "    for r,v,p in zip(dv, votes_ext, persist):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else: state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and p and (v>=gate_min):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else: state.append('OK')\n",
    "    return pd.Series(state, index=driver_s.index), t\n",
    "\n",
    "def score(alert_s, horizon, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = np.where(starts)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    e_slice = onset[a.index.get_indexer(ix)]\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if e_slice[s+1:min(s+1+horizon, len(e_slice))].any(): hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years}\n",
    "\n",
    "# 5) Calibrate on train (≤2015-12-31), sweep grid with extended votes\n",
    "ix_train = idx[idx <= pd.Timestamp(\"2015-12-31\")]\n",
    "if len(ix_train) < 2000:\n",
    "    ix_train = idx[: int(len(idx)*0.6)]\n",
    "\n",
    "best=None\n",
    "for gate_min in [1,2,3]:\n",
    "    for pwin in [3,5]:\n",
    "        for preq in [1,2]:\n",
    "            for q in QGRID:\n",
    "                alert_q, thr = make_alert(driver, q, gate_min, pwin, preq)\n",
    "                res = score(alert_q, LOOKAHEAD_DAYS, ix_train)\n",
    "                cand = {\"q\": float(q), \"thr\": float(thr), \"gate\": gate_min, \"pwin\": pwin, \"preq\": preq, **res}\n",
    "                if (best is None) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\",-1))) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\",-1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "                   ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "                    best = cand.copy(); best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# 6) Apply to full series and save\n",
    "alert_final, thr_final = make_alert(driver, best[\"q\"], best[\"gate\"], best[\"pwin\"], best[\"preq\"])\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_gate_patch\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "out_df = DF.assign(risk_pct=risk_pct, cons_pct=cons_pct, DRIVER=driver, alert=alert_final)\n",
    "cols = [\"RISK\",\"risk_pct\",\"cons_pct\",\"DRIVER\",\"alert\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "out_df[cols].to_csv(RUN / \"gdren_v03a_gate_patch_alerts.csv\")\n",
    "(Path(RUN / \"gdren_v03a_gate_patch_metrics.json\")).write_text(json.dumps({\n",
    "    \"q\": best[\"q\"], \"thr\": best[\"thr\"], \"gate_min_votes\": best[\"gate\"],\n",
    "    \"persist_win\": best[\"pwin\"], \"persist_req\": best[\"preq\"],\n",
    "    \"train_hits\": int(best[\"hits\"]), \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "}, indent=2))\n",
    "\n",
    "print(\"Artifacts:\", json.dumps({\n",
    "    \"alerts_csv\": str(RUN / \"gdren_v03a_gate_patch_alerts.csv\"),\n",
    "    \"metrics_json\": str(RUN / \"gdren_v03a_gate_patch_metrics.json\")\n",
    "}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2592b962-9b54-486a-a281-416e451531c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[G-DREN] PREWARN streak 15d — enabling temporary gate=1 for 48h (driver≥thr & Γ strong). Override ends 2025-11-07T23:59:32.594493+00:00.\n"
     ]
    }
   ],
   "source": [
    "# === Runner Hook v0.1 — webhooks + 48h gate override on PREWARN streak≥2 ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from urllib.request import Request, urlopen\n",
    "from urllib.error import URLError, HTTPError\n",
    "\n",
    "CNT  = Path(\"E:/CNT\")\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "DASH = ROOT / \"dashboard\"\n",
    "DASH.mkdir(parents=True, exist_ok=True)\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True).sort_index()\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "def _post_webhook(text):\n",
    "    urls = os.environ.get(\"G_DREN_WEBHOOKS\",\"\").strip()\n",
    "    if not urls: return\n",
    "    for u in [s.strip() for s in urls.split(\",\") if s.strip()]:\n",
    "        try:\n",
    "            body = json.dumps({\"text\": text, \"content\": text}).encode(\"utf-8\")\n",
    "            req = Request(u, data=body, headers={\"Content-Type\":\"application/json\"})\n",
    "            urlopen(req, timeout=10).read()\n",
    "        except Exception as e:\n",
    "            print(f\"[webhook warn] {u} -> {e}\")\n",
    "\n",
    "# read today’s daily alerts (from your Daily Runner v0.1/v0.2)\n",
    "daily = _latest([\"*/v03a_daily/gdren_v03a_daily_alerts.csv\",\n",
    "                 \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_alerts.csv\",\n",
    "                 \"*/v03a_retune_pp/gdren_v03a_retune_pp_alerts.csv\"])\n",
    "assert daily, \"No daily/retune alerts found. Run your daily runner first.\"\n",
    "R = _load_csv(daily)\n",
    "\n",
    "# derive policy PREWARN (driver≥thr & Γ strong) using latest metrics (thr)\n",
    "metrics = _latest([\"*/v03a_daily/gdren_v03a_daily_metrics.json\",\n",
    "                   \"*/v03a_retune_sweep/gdren_v03a_retune_sweep_metrics.json\",\n",
    "                   \"*/v03a_retune_pp/gdren_v03a_retune_pp_metrics.json\"])\n",
    "thr = 1.0\n",
    "if metrics and metrics.exists():\n",
    "    try:\n",
    "        M = json.loads(metrics.read_text())\n",
    "        thr = float(M.get(\"thr\", M.get(\"calibrated_thr_driver\", 1.0)))\n",
    "    except Exception: pass\n",
    "\n",
    "driver = R[\"DRIVER\"]\n",
    "gamma  = R[\"Gamma_mkt_vix\"] if \"Gamma_mkt_vix\" in R.columns else pd.Series(0.0, index=R.index)\n",
    "policy_prewarn = (driver >= thr) & (gamma >= 0.75)\n",
    "\n",
    "# compute streak ending today\n",
    "streak = 0\n",
    "for ts in reversed(R.index[R.index <= TODAY]):\n",
    "    if policy_prewarn.loc[ts]: streak += 1\n",
    "    else: break\n",
    "\n",
    "# 48h gate override file\n",
    "override_fp = DASH / \"g_dren_gate_override.json\"\n",
    "now_utc = pd.Timestamp.utcnow()\n",
    "override = {}\n",
    "if override_fp.exists():\n",
    "    try: override = json.loads(override_fp.read_text())\n",
    "    except Exception: override = {}\n",
    "# prune expired\n",
    "if override.get(\"expires_utc\"):\n",
    "    if pd.Timestamp(override[\"expires_utc\"]) <= now_utc:\n",
    "        override = {}\n",
    "        try: override_fp.unlink()\n",
    "        except Exception: pass\n",
    "\n",
    "# if streak >= 2 and no override, create a 48h gate=1 override + webhook\n",
    "if streak >= 2 and not override:\n",
    "    override = {\n",
    "        \"gate_min_votes_override\": 1,\n",
    "        \"created_utc\": now_utc.isoformat(),\n",
    "        \"expires_utc\": (now_utc + pd.Timedelta(hours=48)).isoformat(),\n",
    "        \"reason\": \"PREWARN_streak>=2\"\n",
    "    }\n",
    "    override_fp.write_text(json.dumps(override, indent=2))\n",
    "    msg = (f\"[G-DREN] PREWARN streak {streak}d — enabling temporary gate=1 for 48h \"\n",
    "           f\"(driver≥thr & Γ strong). Override ends {override['expires_utc']}.\")\n",
    "    print(msg); _post_webhook(msg)\n",
    "elif override:\n",
    "    print(f\"[G-DREN] gate override active → gate=1 until {override['expires_utc']} (reason={override.get('reason')}).\")\n",
    "else:\n",
    "    print(\"[G-DREN] No override: PREWARN streak <\", streak, \"or conditions not met.\")\n",
    "\n",
    "# also notify on new WARNING starts today\n",
    "if \"alert\" in R.columns:\n",
    "    last_idx = R.index[R.index<=TODAY]\n",
    "    if len(last_idx):\n",
    "        today_alert = str(R.loc[last_idx[-1],\"alert\"])\n",
    "        if len(last_idx) >= 2:\n",
    "            prev_alert  = str(R.loc[last_idx[-2],\"alert\"])\n",
    "        else:\n",
    "            prev_alert = \"OK\"\n",
    "        if today_alert==\"WARNING\" and prev_alert!=\"WARNING\":\n",
    "            msg = f\"[G-DREN] WARNING start {str(last_idx[-1].date())} — driver={driver.loc[last_idx[-1]]:.3f}, thr={thr:.3f}\"\n",
    "            print(msg); _post_webhook(msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bda9bda0-9bc8-4cf6-9e28-c4d1966fdf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[override warn] Cannot localize tz-aware Timestamp, use tz_convert for conversions\n",
      "SPIKE      — OK       as of 2025-11-05 | NEXUS=0.286\n",
      "REGIME     — WARNING  as of 2025-11-05 | RISK=0.000 DRIVER=1.000\n",
      "\n",
      "[dashboard] E:\\CNT\\artifacts\\g_dren\\dashboard\\g_dren_dashboard_status.json\n",
      "[history  ] E:\\CNT\\artifacts\\g_dren\\dashboard\\spike_transitions.csv (if SPIKE present)\n",
      "[history  ] E:\\CNT\\artifacts\\g_dren\\dashboard\\regime_transitions.csv\n",
      "Artifacts: {\n",
      "  \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251106-033119Z\\\\v03a_daily_v02\\\\gdren_v03a_daily_v02_alerts.csv\",\n",
      "  \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251106-033119Z\\\\v03a_daily_v02\\\\gdren_v03a_daily_v02_metrics.json\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Daily Runner v0.2 — extended votes + override + dashboard + webhooks ===\n",
    "import os, json, time\n",
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from urllib.request import Request, urlopen\n",
    "\n",
    "# ------------------------ knobs (tune as you like) ------------------------\n",
    "FA_PER_YEAR_TARGET = 0.60           # false-alarm budget for calibration\n",
    "COOLDOWN_DAYS      = 14             # min days between WARNING starts\n",
    "MAX_WARN_DAYS      = 12             # hard cap on WARNING segment length\n",
    "HYST_EXIT_DAYS     = 3              # exit WARNING if under threshold long enough\n",
    "LOOKAHEAD_DAYS     = 14             # regime horizon for scoring (7 or 14 work well)\n",
    "QGRID              = np.linspace(0.965, 0.990, 51)  # threshold quantile sweep\n",
    "WIN_RANK           = 512            # rolling window for percentile ranks\n",
    "VOTE_THRESH_THETA  = 0.25           # Θ vote threshold\n",
    "VOTE_THRESH_GAMMA  = 0.08           # Γ(mkt↔VIX) vote threshold\n",
    "PREWARN_GAMMA_MIN  = 0.75           # PREWARN requires strong Γ\n",
    "STALE_FEATURE_DAYS = 3              # warn if features older than N days\n",
    "CNT  = Path(os.environ.get(\"CNT_LAB_DIR\", \"E:/CNT\")).resolve()\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "DASH = ROOT / \"dashboard\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "ROOT.mkdir(parents=True, exist_ok=True); DASH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ------------------------ helpers ------------------------\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "def _load_csv(fp):\n",
    "    df = pd.read_csv(fp, index_col=0, parse_dates=True).sort_index()\n",
    "    df.index = pd.DatetimeIndex(df.index).tz_localize(None).normalize()\n",
    "    return df[~df.index.duplicated(keep=\"last\")]\n",
    "\n",
    "def _pct_rank(s: pd.Series, win=512):\n",
    "    def pr(w):\n",
    "        v = w[-1]; a = np.sort(w)\n",
    "        return np.searchsorted(a, v, side=\"right\")/len(w)\n",
    "    return s.rolling(win, min_periods=win//2).apply(pr, raw=True)\n",
    "\n",
    "def _transitions(df, col=\"alert\", n=5):\n",
    "    a = df[col].astype(str)\n",
    "    trans = (a != a.shift(1)).fillna(True)\n",
    "    pts = df.index[trans]\n",
    "    out=[]\n",
    "    for i in range(len(pts)-1, -1, -1):\n",
    "        t = pts[i]; state = a.loc[t]\n",
    "        days = (pts[i+1]-t).days if i+1 < len(pts) else (df.index[-1]-t).days + 1\n",
    "        out.append((str(t.date()), state, int(days)))\n",
    "        if len(out)>=n: break\n",
    "    return out\n",
    "\n",
    "def _post_webhook(text):\n",
    "    urls = os.environ.get(\"G_DREN_WEBHOOKS\",\"\").strip()\n",
    "    if not urls: return\n",
    "    for u in [s.strip() for s in urls.split(\",\") if s.strip()]:\n",
    "        try:\n",
    "            body = json.dumps({\"text\": text, \"content\": text}).encode(\"utf-8\")\n",
    "            req  = Request(u, data=body, headers={\"Content-Type\":\"application/json\"})\n",
    "            urlopen(req, timeout=10).read()\n",
    "        except Exception as e:\n",
    "            print(f\"[webhook warn] {u} -> {e}\")\n",
    "\n",
    "def _fetch_series(ticker):\n",
    "    \"\"\"Lightweight yfinance fetch; returns tz-naive daily Close series or empty.\"\"\"\n",
    "    try:\n",
    "        import yfinance as yf\n",
    "        d = yf.Ticker(ticker).history(period=\"max\", auto_adjust=False)\n",
    "        if isinstance(d, pd.DataFrame) and \"Close\" in d and len(d)>0:\n",
    "            s = pd.Series(d[\"Close\"], name=ticker)\n",
    "            s.index = pd.DatetimeIndex(s.index).tz_localize(None).normalize()\n",
    "            return s\n",
    "    except Exception as e:\n",
    "        print(f\"[yf warn] {ticker}: {e}\")\n",
    "    return pd.Series(dtype=float)\n",
    "\n",
    "# ------------------------ 1) Load latest features (v03a_lite_fix) ------------------------\n",
    "feat_fp = _latest([\"*_v03a_lite_fix/gdren_v03a_lite_fix_features.csv\"])\n",
    "if not feat_fp:\n",
    "    raise FileNotFoundError(\"No v03a_lite_fix features found. Run the v0.3a-lite (fix) cell once to seed features.\")\n",
    "mtime_days = (TODAY - pd.Timestamp.fromtimestamp(feat_fp.stat().st_mtime).normalize()).days\n",
    "if mtime_days > STALE_FEATURE_DAYS:\n",
    "    print(f\"[warn] Features are {mtime_days} days old → consider refreshing v0.3a-lite fix.\")\n",
    "\n",
    "DF = _load_csv(feat_fp)\n",
    "required = [\"RISK\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "miss = [c for c in required if c not in DF.columns]\n",
    "if miss: raise ValueError(f\"Missing columns in features CSV: {miss}\")\n",
    "\n",
    "risk   = DF[\"RISK\"].astype(float).fillna(0.0)\n",
    "Theta_v= DF[\"Theta_vix\"].astype(float).fillna(0.0).values\n",
    "Theta_c= DF[\"Theta_cred\"].astype(float).fillna(0.0).values\n",
    "Theta_m= DF[\"Theta_mkt\"].astype(float).fillna(0.0).values\n",
    "Gamma_v= DF[\"Gamma_mkt_vix\"].astype(float).fillna(0.0).values\n",
    "AR1_m  = DF[\"AR1_mkt\"].astype(float).fillna(0.0).values\n",
    "onset  = DF[\"EVENT_ONSET\"].astype(int).values\n",
    "idx    = DF.index\n",
    "\n",
    "# ------------------------ 2) Build DRIVER (risk_pct ∨ consensus_pct) ------------------------\n",
    "risk_pct = _pct_rank(risk, win=WIN_RANK).fillna(0.0)\n",
    "cons_raw = (0.45*pd.Series(Theta_v, index=idx) +\n",
    "            0.35*pd.Series(Theta_c, index=idx) +\n",
    "            0.15*pd.Series(np.maximum(0, AR1_m), index=idx) +\n",
    "            0.05*pd.Series(np.nan_to_num(Gamma_v), index=idx))\n",
    "cons_pct = _pct_rank(cons_raw, win=WIN_RANK).fillna(0.0)\n",
    "driver   = pd.Series(np.maximum(risk_pct.values, cons_pct.values), index=idx, name=\"DRIVER\")\n",
    "\n",
    "# ------------------------ 3) Extended votes: VIX TS + IG credit slope ------------------------\n",
    "# VIX term-structure: ^VIX9D vs ^VIX vs ^VIX3M (any inversion → vote=1)\n",
    "vix9d = _fetch_series(\"^VIX9D\")\n",
    "vix   = _fetch_series(\"^VIX\")\n",
    "vix3m = _fetch_series(\"^VIX3M\")\n",
    "D_vix = pd.concat([vix9d.rename(\"V9D\"), vix.rename(\"VIX\"), vix3m.rename(\"V3M\")], axis=1).reindex(idx).ffill()\n",
    "term_vote = (((D_vix[\"V9D\"] - D_vix[\"VIX\"]) > 0).astype(int) + ((D_vix[\"VIX\"] - D_vix[\"V3M\"]) > 0).astype(int))\n",
    "term_vote = term_vote.fillna(0).clip(0,1).astype(int).values\n",
    "\n",
    "# IG credit slope: LQD/IEF 10d mean return < 0 → deterioration vote\n",
    "lqd = _fetch_series(\"LQD\")\n",
    "ief = _fetch_series(\"IEF\")\n",
    "D_ig = pd.concat([lqd.rename(\"LQD\"), ief.rename(\"IEF\")], axis=1).reindex(idx).ffill()\n",
    "ig_ratio = (D_ig[\"LQD\"] / D_ig[\"IEF\"]) if all(c in D_ig for c in [\"LQD\",\"IEF\"]) else pd.Series(0.0, index=idx)\n",
    "ig_slope = ig_ratio.pct_change().rolling(10).mean()\n",
    "ig_vote  = (ig_slope < 0).astype(int).reindex(idx).fillna(0).astype(int).values\n",
    "\n",
    "# Base votes + extended votes\n",
    "votes_base = ((Theta_v>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_c>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Theta_m>=VOTE_THRESH_THETA).astype(int) +\n",
    "              (Gamma_v>=VOTE_THRESH_GAMMA).astype(int) +\n",
    "              ((driver.diff(7).fillna(0.0).values)>0).astype(int))\n",
    "votes_ext  = votes_base + term_vote + ig_vote\n",
    "\n",
    "# ------------------------ 4) Honor 48h gate override (from policy file) ------------------------\n",
    "override_fp = DASH / \"g_dren_gate_override.json\"\n",
    "override_gate = None\n",
    "if override_fp.exists():\n",
    "    try:\n",
    "        _ov = json.loads(override_fp.read_text())\n",
    "        exp = pd.Timestamp(_ov.get(\"expires_utc\", \"1970-01-01T00:00:00Z\"))\n",
    "        if pd.Timestamp.utcnow() < exp:\n",
    "            override_gate = int(_ov.get(\"gate_min_votes_override\", 1))\n",
    "            print(f\"[override] gate_min_votes={override_gate} active until {exp.tz_localize('UTC')}\")\n",
    "    except Exception as e:\n",
    "        print(f\"[override warn] {e}\")\n",
    "\n",
    "# ------------------------ 5) Calibration (sweep q, persistence) ------------------------\n",
    "def make_alert(driver_s, q, gate_min=2, persist_win=3, persist_req=1):\n",
    "    t = float(np.quantile(driver_s.values[np.isfinite(driver_s.values)], q))\n",
    "    persist = ((driver_s>=t).astype(int).rolling(persist_win).sum().fillna(0).values >= persist_req)\n",
    "    state=[]; in_warn=False; below=0; wlen=0\n",
    "    dv = driver_s.values\n",
    "    for r,v,p in zip(dv, votes_ext, persist):\n",
    "        if in_warn:\n",
    "            wlen += 1\n",
    "            below = below+1 if r < 0.9*t else 0\n",
    "            if below>=HYST_EXIT_DAYS or wlen>=MAX_WARN_DAYS:\n",
    "                in_warn=False; wlen=0; state.append('OK')\n",
    "            else: state.append('WARNING')\n",
    "        else:\n",
    "            if (r>=t) and p and (v>=gate_min):\n",
    "                in_warn=True; below=0; wlen=1; state.append('WARNING')\n",
    "            else: state.append('OK')\n",
    "    return pd.Series(state, index=driver_s.index), t\n",
    "\n",
    "def score(alert_s, horizon, ix):\n",
    "    a = alert_s.loc[ix]\n",
    "    starts = (a.eq(\"WARNING\") & ~a.shift(1).eq(\"WARNING\")).fillna(False).values\n",
    "    s_ix = np.where(starts)[0].tolist()\n",
    "    kept=[]; last=-10**9\n",
    "    for s in s_ix:\n",
    "        if s-last >= COOLDOWN_DAYS: kept.append(s); last=s\n",
    "    s_ix = kept\n",
    "    e_slice = DF.loc[ix, \"EVENT_ONSET\"].astype(int).values\n",
    "    hits=0\n",
    "    for s in s_ix:\n",
    "        if e_slice[s+1:min(s+1+horizon, len(e_slice))].any(): hits += 1\n",
    "    fa = int(len(s_ix)-hits)\n",
    "    years = max(1e-9, (ix[-1]-ix[0]).days/365.25)\n",
    "    return {\"starts\": len(s_ix), \"hits\": hits, \"fa_py\": fa/years}\n",
    "\n",
    "# Train slice for calibration\n",
    "ix_train = idx[idx <= pd.Timestamp(\"2015-12-31\")]\n",
    "if len(ix_train) < 2000:\n",
    "    ix_train = idx[: int(len(idx)*0.6)]\n",
    "\n",
    "best=None\n",
    "gate_grid = [override_gate] if override_gate is not None else [1,2,3]\n",
    "for gate_min in gate_grid:\n",
    "    for pwin in [3,5]:\n",
    "        for preq in [1,2]:\n",
    "            for q in QGRID:\n",
    "                alert_q, thr = make_alert(driver, q, gate_min, pwin, preq)\n",
    "                res = score(alert_q, LOOKAHEAD_DAYS, ix_train)\n",
    "                cand = {\"q\": float(q), \"thr\": float(thr), \"gate\": gate_min, \"pwin\": pwin, \"preq\": preq, **res}\n",
    "                if (best is None) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] > best.get(\"hits_ok\",-1))) or \\\n",
    "                   ((res[\"fa_py\"] <= FA_PER_YEAR_TARGET) and (res[\"hits\"] == best.get(\"hits_ok\",-1)) and (res[\"fa_py\"] < best[\"fa_py\"])) or \\\n",
    "                   ((best[\"fa_py\"] > FA_PER_YEAR_TARGET) and (res[\"fa_py\"] < best[\"fa_py\"])):\n",
    "                    best = cand.copy(); best[\"hits_ok\"] = res[\"hits\"]\n",
    "\n",
    "# Apply to full series\n",
    "alert_final, thr_final = make_alert(driver, best[\"q\"], best[\"gate\"], best[\"pwin\"], best[\"preq\"])\n",
    "full_starts = (alert_final.eq(\"WARNING\") & ~alert_final.shift(1).eq(\"WARNING\")).fillna(False)\n",
    "# ------------------------ 6) PREWARN policy + (optional) auto-create override ------------------------\n",
    "# Policy PREWARN pattern (no state change): driver≥thr & Γ strong & persistence OK (1/3)\n",
    "persist_hits_today = int((driver.iloc[max(0, len(driver)-3):] >= thr_final).sum())\n",
    "policy_prewarn_today = (driver.iloc[-1] >= thr_final) and (Gamma_v[-1] >= PREWARN_GAMMA_MIN) and (persist_hits_today >= 1)\n",
    "\n",
    "# Compute PREWARN streak ending today (from this run's series)\n",
    "persist_series = (driver >= thr_final).rolling(3).sum().fillna(0) >= 1\n",
    "policy_series  = persist_series & (pd.Series(Gamma_v, index=idx) >= PREWARN_GAMMA_MIN)\n",
    "streak = 0\n",
    "for ts, val in reversed(list(zip(idx, policy_series.values))):\n",
    "    if ts > TODAY: continue\n",
    "    if val: streak += 1\n",
    "    else: break\n",
    "\n",
    "# If streak>=2 and no active override file, create one (gate=1 for 48h) + webhook\n",
    "now_utc = pd.Timestamp.utcnow()\n",
    "if streak >= 2 and override_gate is None:\n",
    "    override = {\n",
    "        \"gate_min_votes_override\": 1,\n",
    "        \"created_utc\": now_utc.isoformat(),\n",
    "        \"expires_utc\": (now_utc + pd.Timedelta(hours=48)).isoformat(),\n",
    "        \"reason\": \"PREWARN_streak>=2\"\n",
    "    }\n",
    "    (DASH / \"g_dren_gate_override.json\").write_text(json.dumps(override, indent=2))\n",
    "    _post_webhook(f\"[G-DREN] PREWARN streak {streak}d — enabling temporary gate=1 for 48h \"\n",
    "                  f\"(driver≥thr & Γ strong). Override ends {override['expires_utc']}.\")\n",
    "\n",
    "# Notify on new WARNING start today\n",
    "if any(idx <= TODAY):\n",
    "    last2 = idx[idx <= TODAY][-2:] if len(idx[idx <= TODAY])>=2 else idx[-1:]\n",
    "    if len(last2)==2:\n",
    "        if alert_final.loc[last2[-1]]==\"WARNING\" and alert_final.loc[last2[-2]]!=\"WARNING\":\n",
    "            _post_webhook(f\"[G-DREN] WARNING start {str(last2[-1].date())} — driver={driver.loc[last2[-1]]:.3f}, thr={thr_final:.3f}\")\n",
    "\n",
    "# ------------------------ 7) Save artifacts ------------------------\n",
    "RUN = ROOT / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime()) / \"v03a_daily_v02\"\n",
    "RUN.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "out_df = DF.assign(risk_pct=risk_pct, cons_pct=cons_pct, DRIVER=driver, alert=alert_final)\n",
    "cols = [\"RISK\",\"risk_pct\",\"cons_pct\",\"DRIVER\",\"alert\",\"EVENT_ONSET\",\"Theta_mkt\",\"Theta_vix\",\"Theta_cred\",\"Gamma_mkt_vix\",\"AR1_mkt\"]\n",
    "out_df[cols].to_csv(RUN / \"gdren_v03a_daily_v02_alerts.csv\")\n",
    "\n",
    "metrics = {\n",
    "    \"q\": float(best[\"q\"]), \"thr\": float(best[\"thr\"]),\n",
    "    \"gate_min_votes\": int(best[\"gate\"]), \"persist_win\": int(best[\"pwin\"]), \"persist_req\": int(best[\"preq\"]),\n",
    "    \"fa_per_year_target\": float(FA_PER_YEAR_TARGET),\n",
    "    \"override_active\": bool(override_gate is not None),\n",
    "    \"override_gate_min_votes\": (int(override_gate) if override_gate is not None else None),\n",
    "    \"train_hits\": int(best[\"hits\"]), \"train_fa_per_year\": float(best[\"fa_py\"]),\n",
    "    \"full_starts\": int(full_starts.sum()),\n",
    "    \"horizon_days\": int(LOOKAHEAD_DAYS),\n",
    "    \"prewarn_today\": bool(policy_prewarn_today),\n",
    "    \"prewarn_streak_days\": int(streak)\n",
    "}\n",
    "(RUN / \"gdren_v03a_daily_v02_metrics.json\").write_text(json.dumps(metrics, indent=2))\n",
    "\n",
    "# ------------------------ 8) Update dashboard + transitions ------------------------\n",
    "def _status_line(name, date, base_alert, extras=None):\n",
    "    parts = [f\"{name:10s} — {base_alert:8s} as of {date}\"]\n",
    "    if extras: parts.append(\" | \" + \" \".join(extras))\n",
    "    return \"\".join(parts)\n",
    "\n",
    "# SPIKE (v0.2b) status (if present)\n",
    "spike_fp = _latest([\"*_v02b/gdren_v02b_alerts.csv\", \"*_v02b/*alerts*.csv\"])\n",
    "payload = {\"generated_utc\": time.strftime(\"%Y-%m-%dT%H:%M:%SZ\", time.gmtime())}\n",
    "lines = []\n",
    "if spike_fp and spike_fp.exists():\n",
    "    S = _load_csv(spike_fp)\n",
    "    s_last = (S.index[S.index<=TODAY][-1] if any(S.index<=TODAY) else S.index[-1])\n",
    "    s_alert = str(S.loc[s_last, \"alert\"])\n",
    "    s_nexus = float(S.loc[s_last, \"NEXUS\"]) if \"NEXUS\" in S.columns and pd.notna(S.loc[s_last, \"NEXUS\"]) else None\n",
    "    lines.append(_status_line(\"SPIKE\", str(s_last.date()), s_alert, [f\"NEXUS={s_nexus:.3f}\"] if s_nexus is not None else []))\n",
    "    s_hist = _transitions(S, \"alert\", n=5)\n",
    "    payload[\"spike\"] = {\"file\": str(spike_fp), \"asof\": str(s_last.date()), \"alert\": s_alert, \"nexus\": s_nexus, \"recent\": s_hist}\n",
    "else:\n",
    "    lines.append(\"SPIKE      — (no recent v0.2b alerts found)\")\n",
    "    payload[\"spike\"] = {\"file\": None, \"alert\": None, \"recent\": []}\n",
    "\n",
    "# REGIME status (from this run)\n",
    "R = _load_csv(RUN / \"gdren_v03a_daily_v02_alerts.csv\")\n",
    "r_last = (R.index[R.index<=TODAY][-1] if any(R.index<=TODAY) else R.index[-1])\n",
    "base_alert = str(R.loc[r_last, \"alert\"])\n",
    "driver_last= float(R.loc[r_last, \"DRIVER\"]) if \"DRIVER\" in R.columns else None\n",
    "risk_last  = float(R.loc[r_last, \"RISK\"])   if \"RISK\"   in R.columns else None\n",
    "Gamma_last = float(R.loc[r_last, \"Gamma_mkt_vix\"]) if \"Gamma_mkt_vix\" in R.columns else 0.0\n",
    "# show PREWARN overlay text if policy pattern holds\n",
    "policy_alert = base_alert\n",
    "persist_hits = int((R[\"DRIVER\"].iloc[max(0, R.index.get_loc(r_last)-2):R.index.get_loc(r_last)+1] >= best[\"thr\"]).sum()) if \"DRIVER\" in R.columns else 0\n",
    "persist_ok   = (persist_hits >= 1)\n",
    "if base_alert!=\"WARNING\" and driver_last is not None and driver_last>=best[\"thr\"] and persist_ok and (Gamma_last >= PREWARN_GAMMA_MIN):\n",
    "    policy_alert = \"PREWARN\"\n",
    "extras = []\n",
    "if risk_last is not None:   extras.append(f\"RISK={risk_last:.3f}\")\n",
    "if driver_last is not None: extras.append(f\"DRIVER={driver_last:.3f}\")\n",
    "if policy_alert == \"PREWARN\" and base_alert != \"WARNING\": extras.append(\"policy=PREWARN(Γ strong)\")\n",
    "lines.append(_status_line(\"REGIME\", str(r_last.date()), policy_alert, extras))\n",
    "r_hist = _transitions(R, \"alert\", n=5)\n",
    "payload[\"regime\"] = {\n",
    "    \"file\": str(RUN / \"gdren_v03a_daily_v02_alerts.csv\"),\n",
    "    \"asof\": str(r_last.date()),\n",
    "    \"alert\": base_alert, \"policy_alert\": policy_alert,\n",
    "    \"driver\": driver_last, \"risk\": risk_last,\n",
    "    \"threshold\": float(best[\"thr\"]), \"q\": float(best[\"q\"]),\n",
    "    \"gate_min_votes\": int(best[\"gate\"]), \"persist_win\": int(best[\"pwin\"]), \"persist_req\": int(best[\"preq\"]),\n",
    "    \"recent\": r_hist\n",
    "}\n",
    "\n",
    "# write dashboard JSON\n",
    "dash_path = DASH / \"g_dren_dashboard_status.json\"\n",
    "dash_path.write_text(json.dumps(payload, indent=2))\n",
    "\n",
    "# transitions CSVs\n",
    "def export_transitions_csv(fp_in, fp_out):\n",
    "    D = _load_csv(fp_in)\n",
    "    hist = _transitions(D, \"alert\", n=9999)\n",
    "    pd.DataFrame(hist, columns=[\"date\",\"state\",\"days\"]).to_csv(fp_out, index=False)\n",
    "\n",
    "if spike_fp and spike_fp.exists():\n",
    "    export_transitions_csv(spike_fp, DASH / \"spike_transitions.csv\")\n",
    "export_transitions_csv(RUN / \"gdren_v03a_daily_v02_alerts.csv\", DASH / \"regime_transitions.csv\")\n",
    "\n",
    "# ------------------------ 9) Print status + artifact locations ------------------------\n",
    "print(\"\\n\".join(lines))\n",
    "print(f\"\\n[dashboard] {dash_path}\")\n",
    "print(f\"[history  ] {DASH/'spike_transitions.csv'} (if SPIKE present)\")\n",
    "print(f\"[history  ] {DASH/'regime_transitions.csv'}\")\n",
    "print(\"Artifacts:\", json.dumps({\n",
    "    \"alerts_csv\": str(RUN / \"gdren_v03a_daily_v02_alerts.csv\"),\n",
    "    \"metrics_json\": str(RUN / \"gdren_v03a_daily_v02_metrics.json\")\n",
    "}, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0bf58d61-a5c2-4317-8e20-dcb601650fbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[override] gate_min_votes=1 active until 2025-11-07 23:59Z\n"
     ]
    }
   ],
   "source": [
    "# BEFORE\n",
    "# exp = pd.Timestamp(_ov.get(\"expires_utc\", \"1970-01-01T00:00:00Z\"))\n",
    "# print(f\"[override] gate_min_votes={override_gate} active until {exp.tz_localize('UTC')}\")\n",
    "\n",
    "# AFTER\n",
    "now_utc = pd.Timestamp.now(tz=\"UTC\")\n",
    "exp = pd.to_datetime(_ov.get(\"expires_utc\", \"1970-01-01T00:00:00Z\"), utc=True)\n",
    "if now_utc < exp:\n",
    "    override_gate = int(_ov.get(\"gate_min_votes_override\", 1))\n",
    "    print(f\"[override] gate_min_votes={override_gate} active until {exp.strftime('%Y-%m-%d %H:%MZ')}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc6e4b96-de88-4090-b6da-12f46339f154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[run-card] saved → E:\\CNT\\artifacts\\g_dren\\warning_runs\\2025-10-28\n",
      "{\n",
      "  \"start_ts\": \"2025-10-28\",\n",
      "  \"driver\": 1.0,\n",
      "  \"risk\": 9.357622968839301e-14,\n",
      "  \"threshold\": 1.0,\n",
      "  \"q\": 0.965,\n",
      "  \"gate_min_votes\": 1,\n",
      "  \"persist_win\": 3,\n",
      "  \"persist_req\": 1,\n",
      "  \"votes\": {\n",
      "    \"Theta_vix\": 0.015625,\n",
      "    \"Theta_cred\": 0.0234375,\n",
      "    \"Theta_mkt\": 0.015625,\n",
      "    \"Gamma_mkt_vix\": 0.7633608406051142,\n",
      "    \"slope7\": 0.0,\n",
      "    \"total\": 1\n",
      "  },\n",
      "  \"persistence_hits_last3\": 3,\n",
      "  \"persistence_ok\": true,\n",
      "  \"artifacts\": {\n",
      "    \"alerts_csv\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251106-033119Z\\\\v03a_daily_v02\\\\gdren_v03a_daily_v02_alerts.csv\",\n",
      "    \"metrics_json\": \"E:\\\\CNT\\\\artifacts\\\\g_dren\\\\20251106-033119Z\\\\v03a_daily_v02\\\\gdren_v03a_daily_v02_metrics.json\"\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === G-DREN Warning Run Card v0.1 — snapshot the latest WARNING start ===\n",
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "CNT  = Path(\"E:/CNT\")\n",
    "ROOT = CNT / \"artifacts\" / \"g_dren\"\n",
    "TODAY = pd.Timestamp.today().normalize()\n",
    "\n",
    "def _latest(globs):\n",
    "    c=[]\n",
    "    for g in globs: c += list(ROOT.glob(g))\n",
    "    return sorted(c, key=lambda p: p.stat().st_mtime, reverse=True)[0] if c else None\n",
    "\n",
    "# Use the latest Daily v0.2 outputs you just created\n",
    "alerts_fp  = _latest([\"*/v03a_daily_v02/gdren_v03a_daily_v02_alerts.csv\"])\n",
    "metrics_fp = _latest([\"*/v03a_daily_v02/gdren_v03a_daily_v02_metrics.json\"])\n",
    "assert alerts_fp and metrics_fp, \"No v03a_daily_v02 artifacts found.\"\n",
    "\n",
    "A = pd.read_csv(alerts_fp, index_col=0, parse_dates=True).sort_index()\n",
    "A.index = A.index.tz_localize(None).normalize()\n",
    "M = json.loads(metrics_fp.read_text())\n",
    "\n",
    "# Find the most recent WARNING start\n",
    "starts = (A[\"alert\"].eq(\"WARNING\") & ~A[\"alert\"].shift(1).eq(\"WARNING\")).fillna(False)\n",
    "if not starts.any():\n",
    "    raise SystemExit(\"No WARNING start found in this file.\")\n",
    "t_start = A.index[starts].max()\n",
    "\n",
    "# Pull context around the start\n",
    "ctx = A.loc[:t_start].tail(8).copy()\n",
    "thr = float(M.get(\"thr\", M.get(\"threshold\", 1.0)))\n",
    "q   = float(M.get(\"q\", M.get(\"calibrated_q_train\", 0.97)))\n",
    "gate= int(M.get(\"gate_min_votes\", 2))\n",
    "pwin= int(M.get(\"persist_win\", 3)); preq = int(M.get(\"persist_req\", 1))\n",
    "\n",
    "# Compute votes & persistence at start\n",
    "def _get(row, k, default=0.0): \n",
    "    return float(row[k]) if k in row and pd.notna(row[k]) else default\n",
    "\n",
    "row = A.loc[t_start]\n",
    "driver  = _get(row, \"DRIVER\", np.nan)\n",
    "risk    = _get(row, \"RISK\",   np.nan)\n",
    "Theta_m = _get(row, \"Theta_mkt\")\n",
    "Theta_v = _get(row, \"Theta_vix\")\n",
    "Theta_c = _get(row, \"Theta_cred\")\n",
    "Gamma_v = _get(row, \"Gamma_mkt_vix\")\n",
    "# 7d slope on DRIVER (if available)\n",
    "i = A.index.get_loc(t_start)\n",
    "slope7 = float(A[\"DRIVER\"].iloc[i] - A[\"DRIVER\"].iloc[i-7]) if (\"DRIVER\" in A.columns and i>=7) else 0.0\n",
    "# persistence over last 3 days ≥ thr\n",
    "persist_hits = int((A[\"DRIVER\"].iloc[max(0, i-2):i+1] >= thr).sum()) if \"DRIVER\" in A.columns else 0\n",
    "persist_ok   = bool(persist_hits >= preq)\n",
    "\n",
    "votes = int(Theta_v>=0.25) + int(Theta_c>=0.25) + int(Theta_m>=0.25) + int(Gamma_v>=0.08) + int(slope7>0)\n",
    "\n",
    "# Write run card\n",
    "RUNDIR = ROOT / \"warning_runs\" / t_start.strftime(\"%Y-%m-%d\")\n",
    "RUNDIR.mkdir(parents=True, exist_ok=True)\n",
    "card = {\n",
    "  \"start_ts\": str(t_start.date()),\n",
    "  \"driver\": driver, \"risk\": risk,\n",
    "  \"threshold\": thr, \"q\": q,\n",
    "  \"gate_min_votes\": gate, \"persist_win\": pwin, \"persist_req\": preq,\n",
    "  \"votes\": {\"Theta_vix\": Theta_v, \"Theta_cred\": Theta_c, \"Theta_mkt\": Theta_m, \"Gamma_mkt_vix\": Gamma_v, \"slope7\": slope7, \"total\": int(votes)},\n",
    "  \"persistence_hits_last3\": int(persist_hits), \"persistence_ok\": bool(persist_ok),\n",
    "  \"artifacts\": {\"alerts_csv\": str(alerts_fp), \"metrics_json\": str(metrics_fp)}\n",
    "}\n",
    "(RUNDIR / \"run_card.json\").write_text(json.dumps(card, indent=2))\n",
    "ctx.to_csv(RUNDIR / \"context_last8_days.csv\")\n",
    "\n",
    "print(f\"[run-card] saved → {RUNDIR}\")\n",
    "print(json.dumps(card, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6aeb24-4bc9-4e83-adde-a26985059da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
