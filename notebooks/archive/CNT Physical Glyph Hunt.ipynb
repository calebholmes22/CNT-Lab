{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1025604b-6d4b-4327-bdda-35f71879c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.1\n",
      "[ABC] Helicity: H=744.150640  h=H/V=3.000000e+00\n",
      "[Hopf] Invariant≈0.0193  density=3.021769e-04\n",
      "[CNT] glyphness=0.586 (H_norm=1.00, Hopf_norm=0.03, echo=0.870)\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-215252Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.1\n",
    "# One-cell bridge from knotted fields → CNT glyphness (topology + echo)\n",
    "# Outputs: prints metrics and saves JSON/CSV under {CNT_LAB_DIR or E:\\CNT}\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.1\")\n",
    "\n",
    "# ---- Topology helpers ----\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _curl_spectral(Ax, Ay, Az, Lx, Ly, Lz):\n",
    "    kx, ky, kz = _fftvec(*Ax.shape, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh))\n",
    "    By = np.real(ifftn(Byh))\n",
    "    Bz = np.real(ifftn(Bzh))\n",
    "    return Bx, By, Bz\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = np.real(ifftn(Axh)); Ay = np.real(ifftn(Ayh)); Az = np.real(ifftn(Azh))\n",
    "    return Ax, Ay, Az\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---- Synthetic fields (testbeds) ----\n",
    "def _grid(N=48, L=2*np.pi):\n",
    "    x = np.linspace(0, L, N, endpoint=False)\n",
    "    y = np.linspace(0, L, N, endpoint=False)\n",
    "    z = np.linspace(0, L, N, endpoint=False)\n",
    "    return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "def abc_flow(N=48, L=2*np.pi, A=1.0, B=1.0, C=1.0):\n",
    "    x, y, z = _grid(N, L)\n",
    "    Bx = A*np.sin(z) + C*np.cos(y)\n",
    "    By = B*np.sin(x) + A*np.cos(z)\n",
    "    Bz = C*np.sin(y) + B*np.cos(x)\n",
    "    dx = dy = dz = L / N\n",
    "    return (Bx, By, Bz), (dx, dy, dz)\n",
    "\n",
    "def hopf_map_n(N=48, L=4.0):\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    r2 = x*x + y*y + z*z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(x + 1j*y)) / denom\n",
    "    v = (1 - r2 + 2j*z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    nx, ny, nz = nx/norm, ny/norm, nz/norm\n",
    "    dx = dy = dz = L / N\n",
    "    return (nx, ny, nz), (dx, dy, dz)\n",
    "\n",
    "# ---- Hopf invariant (approx., periodic box) ----\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    gx = np.gradient(field, dx, axis=0)\n",
    "    gy = np.gradient(field, dy, axis=1)\n",
    "    gz = np.gradient(field, dz, axis=2)\n",
    "    return gx, gy, gz\n",
    "\n",
    "def hopf_index(nx, ny, nz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [\n",
    "        np.stack([dnx[0], dny[0], dnz[0]], axis=0),\n",
    "        np.stack([dnx[1], dny[1], dnz[1]], axis=0),\n",
    "        np.stack([dnx[2], dny[2], dnz[2]], axis=0),\n",
    "    ]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    b = [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "    curlAx, curlAy, curlAz = _curl_spectral(Ax, Ay, Az, Lx, Ly, Lz)\n",
    "    integrand = Ax*curlAx + Ay*curlAy + Az*curlAz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---- Echo + glyphness ----\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec = np.abs(np.fft.rfft(signal))**2 / n\n",
    "    return freqs, spec\n",
    "\n",
    "def glyphness_score(H_norm, hopf_norm, echo_power=0.0, weights=(0.4,0.4,0.2)):\n",
    "    w1, w2, w3 = weights\n",
    "    s = w1*H_norm + w2*hopf_norm + w3*echo_power\n",
    "    return float(max(0.0, min(1.0, s)))\n",
    "\n",
    "# ---- Run demo on synthetic fields (adjust N for speed/accuracy) ----\n",
    "(Bx, By, Bz), sp = abc_flow(N=32, L=2*np.pi)\n",
    "H, h = helicity(Bx,By,Bz, sp)\n",
    "print(f\"[ABC] Helicity: H={H:.6f}  h=H/V={h:.6e}\")\n",
    "\n",
    "(nx,ny,nz), spn = hopf_map_n(N=32, L=4.0)\n",
    "HH, hh = hopf_index(nx,ny,nz, spn)\n",
    "print(f\"[Hopf] Invariant≈{HH:.4f}  density={hh:.6e}\")\n",
    "\n",
    "t = np.linspace(0, 10, 4096)\n",
    "sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "freqs, P = echo_spectrum(sig, dt=t[1]-t[0])\n",
    "mask = (freqs>1.6) & (freqs<1.8)\n",
    "echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "H_norm  = min(1.0, abs(h)/(1e-2))       # scale knobs\n",
    "Hopf_n  = min(1.0, abs(hh)/(1e-2))      # scale knobs\n",
    "score   = glyphness_score(H_norm, Hopf_n, echo_power)\n",
    "print(f\"[CNT] glyphness={score:.3f} (H_norm={H_norm:.2f}, Hopf_norm={Hopf_n:.2f}, echo={echo_power:.3f})\")\n",
    "\n",
    "# ---- Save artifacts ----\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary = {\n",
    "    \"helicity\": {\"H\": H, \"h_density\": h},\n",
    "    \"hopf\": {\"H_hopf\": HH, \"h_density\": hh},\n",
    "    \"echo\": {\"band_center_hz\": 1.7, \"band_power_norm\": echo_power},\n",
    "    \"glyphness\": {\"score\": score, \"weights\": [0.4,0.4,0.2], \"scales\": {\"H_norm_div\": 1e-2, \"Hopf_norm_div\": 1e-2}},\n",
    "    \"grid\": {\"ABC_N\": 32, \"Hopf_N\": 32},\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a1383aa-6c8a-4972-92b0-e6cda13af895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.2 (calibrated)\n",
      "[ABC] Helicity: H=744.150640  h=H/V=3.000000e+00\n",
      "[Hopf baseline] proxy ≈ 0.0202  density=3.155740e-04\n",
      "[Hopf on B] proxy ≈ -0.0003  density=-1.330598e-06  → normalized=0.004\n",
      "[Echo] band=(1.6, 1.8)  echo_power=0.870\n",
      "[CNT] glyphness=0.576  (H_norm=1.00, Hopf_norm=0.00, echo=0.870)\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-222410Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.2 (calibrated)\n",
    "# - Helicity (A·B) from ABC test field\n",
    "# - Hopf proxy on normalized B, normalized by a Hopf-map baseline\n",
    "# - Echo spectrum from file if available, else demo\n",
    "# - Saves artifacts under {CNT_LAB_DIR or E:\\CNT}\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time, pathlib\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.2 (calibrated)\")\n",
    "\n",
    "# ---------- FFT helpers ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = np.real(ifftn(Axh)); Ay = np.real(ifftn(Ayh)); Az = np.real(ifftn(Azh))\n",
    "    return Ax, Ay, Az\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------- Grids & synthetic fields ----------\n",
    "def _grid(N=48, L=2*np.pi):\n",
    "    x = np.linspace(0, L, N, endpoint=False)\n",
    "    y = np.linspace(0, L, N, endpoint=False)\n",
    "    z = np.linspace(0, L, N, endpoint=False)\n",
    "    return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "def abc_flow(N=48, L=2*np.pi, A=1.0, B=1.0, C=1.0):\n",
    "    x, y, z = _grid(N, L)\n",
    "    Bx = A*np.sin(z) + C*np.cos(y)\n",
    "    By = B*np.sin(x) + A*np.cos(z)\n",
    "    Bz = C*np.sin(y) + B*np.cos(x)\n",
    "    dx = dy = dz = L / N\n",
    "    return (Bx, By, Bz), (dx, dy, dz)\n",
    "\n",
    "def hopf_map_n(N=48, L=4.0):\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    r2 = x*x + y*y + z*z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(x + 1j*y)) / denom\n",
    "    v = (1 - r2 + 2j*z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    nx, ny, nz = nx/norm, ny/norm, nz/norm\n",
    "    dx = dy = dz = L / N\n",
    "    return (nx, ny, nz), (dx, dy, dz)\n",
    "\n",
    "# ---------- Hopf proxy (b -> A -> A·curlA) ----------\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    gx = np.gradient(field, dx, axis=0)\n",
    "    gy = np.gradient(field, dy, axis=1)\n",
    "    gz = np.gradient(field, dz, axis=2)\n",
    "    return gx, gy, gz\n",
    "\n",
    "def hopf_proxy(nxyz, spacings):\n",
    "    # b_i = (1/8π) ε_{ijk} n · (∂_j n × ∂_k n); solve ∇×A = b; return (1/4π^2)∫ A·(∇×A)\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [\n",
    "        np.stack([dnx[0], dny[0], dnz[0]], axis=0),\n",
    "        np.stack([dnx[1], dny[1], dnz[1]], axis=0),\n",
    "        np.stack([dnx[2], dny[2], dnz[2]], axis=0),\n",
    "    ]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    b = [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "\n",
    "    # curl(A) in spectral\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh)); By = np.real(ifftn(Byh)); Bz = np.real(ifftn(Bzh))\n",
    "\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------- Echo ----------\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec  = (np.abs(np.fft.rfft(signal))**2) / n\n",
    "    return freqs, spec\n",
    "\n",
    "# ---------- Run (synthetic with optional real echo) ----------\n",
    "# 1) ABC field → helicity\n",
    "(Bx, By, Bz), spB = abc_flow(N=48, L=2*np.pi)\n",
    "H, h = helicity(Bx, By, Bz, spB)\n",
    "print(f\"[ABC] Helicity: H={H:.6f}  h=H/V={h:.6e}\")\n",
    "\n",
    "# 2) Hopf baseline from Hopf-map field (same grid size for fair normalization)\n",
    "(nhx, nhy, nhz), spN = hopf_map_n(N=48, L=4.0)\n",
    "H_hopf_base, h_hopf_base = hopf_proxy((nhx, nhy, nhz), spN)\n",
    "print(f\"[Hopf baseline] proxy ≈ {H_hopf_base:.4f}  density={h_hopf_base:.6e}\")\n",
    "\n",
    "# 3) Hopf proxy on normalized B-field\n",
    "mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "H_hopf_B, h_hopf_B = hopf_proxy((nxB, nyB, nzB), spB)\n",
    "# Normalize relative to baseline (cap at 1 for scoring)\n",
    "Hopf_norm = float(min(1.0, abs(h_hopf_B) / (abs(h_hopf_base) + 1e-18)))\n",
    "print(f\"[Hopf on B] proxy ≈ {H_hopf_B:.4f}  density={h_hopf_B:.6e}  → normalized={Hopf_norm:.3f}\")\n",
    "\n",
    "# 4) Echo: try file, else demo\n",
    "echo_path = Path(\"E:/CNT/data/echo_signal.csv\")\n",
    "if not echo_path.exists():\n",
    "    echo_path = Path(os.getenv(\"CNT_LAB_DIR\", \"\")) / \"data\" / \"echo_signal.csv\"\n",
    "use_demo = True\n",
    "if echo_path.exists():\n",
    "    try:\n",
    "        arr = np.loadtxt(echo_path, delimiter=\",\", ndmin=1)\n",
    "        sig = arr.astype(float)\n",
    "        dt = 1.0\n",
    "        use_demo = False\n",
    "        print(f\"[Echo] Loaded {echo_path} (len={len(sig)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Echo] Failed to load file, using demo. Reason: {e}\")\n",
    "if use_demo:\n",
    "    t = np.linspace(0, 10, 4096)\n",
    "    dt = t[1] - t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "\n",
    "freqs, P = echo_spectrum(sig, dt)\n",
    "band = (1.6, 1.8)\n",
    "mask = (freqs>band[0]) & (freqs<band[1])\n",
    "echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "print(f\"[Echo] band={band}  echo_power={echo_power:.3f}\")\n",
    "\n",
    "# 5) Scoring (tune scales as you like)\n",
    "H_norm = float(min(1.0, abs(h) / (1e-2)))   # helicity density scale\n",
    "w1, w2, w3 = 0.4, 0.4, 0.2\n",
    "glyphness = float(w1*H_norm + w2*Hopf_norm + w3*echo_power)\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H_norm={H_norm:.2f}, Hopf_norm={Hopf_norm:.2f}, echo={echo_power:.3f})\")\n",
    "\n",
    "# ---------- Save artifacts ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "summary = {\n",
    "    \"helicity\": {\"H\": H, \"h_density\": h, \"scale_div\": 1e-2},\n",
    "    \"hopf_proxy\": {\n",
    "        \"baseline\": {\"H\": H_hopf_base, \"h_density\": h_hopf_base},\n",
    "        \"on_B\": {\"H\": H_hopf_B, \"h_density\": h_hopf_B},\n",
    "        \"normalized\": Hopf_norm\n",
    "    },\n",
    "    \"echo\": {\"band\": list(band), \"power_norm\": echo_power, \"dt\": dt, \"source\": \"file\" if not use_demo else \"demo\"},\n",
    "    \"glyphness\": {\"score\": glyphness, \"weights\": [w1,w2,w3]},\n",
    "    \"grid\": {\"N\": 48, \"L_ABC\": float(2*np.pi), \"L_Hopf\": 4.0},\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5620be88-f254-4241-8dfb-458aad4d1b87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.3\n",
      "[Field:hopfion_B] Helicity: H=0.861464  h=H/V=1.682547e-03\n",
      "[Hopf baseline] proxy ≈ 0.0218  density=4.261941e-05\n",
      "[Hopf on B] proxy ≈ 0.0058  density=1.124515e-05  → normalized=0.264\n",
      "[Echo] band=(1.6, 1.8)  echo_power=0.870\n",
      "[CNT] glyphness=0.347  (H_norm=0.17, Hopf_norm=0.26, echo=0.870) → CANDIDATE\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-224915Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.3 (Hopfion-ready + Real-Feed Auto)\n",
    "# - If E:\\CNT\\data\\B_field.npz (or CNT_LAB_DIR\\data\\B_field.npz) exists, uses that 3D field (Bx,By,Bz,dx,dy,dz)\n",
    "# - Else builds a true \"Hopfion-B\" field (topological) so Hopf_norm calibrates high (expect ~O(0.2–0.8), grid-dependent)\n",
    "# - Else falls back to ABC (nontrivial helicity, low Hopf_norm)\n",
    "# - Echo from E:\\CNT\\data\\echo_signal.csv (or CNT_LAB_DIR\\data), else demo\n",
    "# - Saves artifacts → {CNT_LAB_DIR or E:\\CNT}\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.3\")\n",
    "\n",
    "# ---------------- FFT helpers ----------------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = np.real(ifftn(Axh)); Ay = np.real(ifftn(Ayh)); Az = np.real(ifftn(Azh))\n",
    "    return Ax, Ay, Az\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------------- Grids & synthetic fields ----------------\n",
    "def _grid(N=48, L=2*np.pi):\n",
    "    x = np.linspace(0, L, N, endpoint=False)\n",
    "    y = np.linspace(0, L, N, endpoint=False)\n",
    "    z = np.linspace(0, L, N, endpoint=False)\n",
    "    return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "def abc_flow(N=48, L=2*np.pi, A=1.0, B=1.0, C=1.0):\n",
    "    x, y, z = _grid(N, L)\n",
    "    Bx = A*np.sin(z) + C*np.cos(y)\n",
    "    By = B*np.sin(x) + A*np.cos(z)\n",
    "    Bz = C*np.sin(y) + B*np.cos(x)\n",
    "    dx = dy = dz = L / N\n",
    "    return (Bx, By, Bz), (dx, dy, dz)\n",
    "\n",
    "def hopf_map_n(N=48, L=8.0):\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    r2 = x*x + y*y + z*z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(x + 1j*y)) / denom\n",
    "    v = (1 - r2 + 2j*z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    nx, ny, nz = nx/norm, ny/norm, nz/norm\n",
    "    dx = dy = dz = L / N\n",
    "    return (nx, ny, nz), (dx, dy, dz)\n",
    "\n",
    "# ---------------- Hopf proxy & Hopfion-B ----------------\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    gx = np.gradient(field, dx, axis=0)\n",
    "    gy = np.gradient(field, dy, axis=1)\n",
    "    gz = np.gradient(field, dz, axis=2)\n",
    "    return gx, gy, gz\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [\n",
    "        np.stack([dnx[0], dny[0], dnz[0]], axis=0),\n",
    "        np.stack([dnx[1], dny[1], dnz[1]], axis=0),\n",
    "        np.stack([dnx[2], dny[2], dnz[2]], axis=0),\n",
    "    ]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    b = [bi/(8*np.pi) for bi in b]\n",
    "    return b  # list of 3 arrays\n",
    "\n",
    "def hopf_proxy(nxyz, spacings):\n",
    "    # ∇×A = b(n); return (1/4π^2) ∫ A·(∇×A)\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh)); By = np.real(ifftn(Byh)); Bz = np.real(ifftn(Bzh))\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------------- Echo ----------------\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec  = (np.abs(np.fft.rfft(signal))**2) / n\n",
    "    return freqs, spec\n",
    "\n",
    "# ---------------- Choose field ----------------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "data_dir = root / \"data\"\n",
    "\n",
    "field_path = None\n",
    "for cand in [data_dir / \"B_field.npz\", Path(\"E:/CNT/data/B_field.npz\")]:\n",
    "    if cand.exists():\n",
    "        field_path = cand; break\n",
    "\n",
    "mode = \"npz\" if field_path else \"hopfion\"  # prefer real, else Hopfion-B, else ABC\n",
    "if not field_path:\n",
    "    mode = \"hopfion\"  # set \"abc\" here if you want ABC instead\n",
    "\n",
    "if mode == \"npz\":\n",
    "    d = np.load(field_path)\n",
    "    Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "    if all(k in d for k in [\"dx\",\"dy\",\"dz\"]):\n",
    "        spacings = (float(d[\"dx\"]), float(d[\"dy\"]), float(d[\"dz\"]))\n",
    "    else:\n",
    "        # fallback: infer cubic box\n",
    "        N = Bx.shape[0]; L = 2*np.pi; spacings = (L/N, L/N, L/N)\n",
    "    src = f\"npz:{field_path}\"\n",
    "elif mode == \"hopfion\":\n",
    "    N = 48; L = 8.0\n",
    "    (nx,ny,nz), sp = hopf_map_n(N=N, L=L)\n",
    "    b = b_from_n((nx,ny,nz), sp)\n",
    "    Bx, By, Bz = b  # define Hopfion-B = b(n)\n",
    "    spacings = sp\n",
    "    src = \"hopfion_B\"\n",
    "else:\n",
    "    (Bx, By, Bz), spacings = abc_flow(N=48, L=2*np.pi)\n",
    "    src = \"abc\"\n",
    "\n",
    "# ---------------- Metrics ----------------\n",
    "H, h = helicity(Bx, By, Bz, spacings)\n",
    "print(f\"[Field:{src}] Helicity: H={H:.6f}  h=H/V={h:.6e}\")\n",
    "\n",
    "# Hopf baseline (Hopf-map n) for normalization\n",
    "(nhx, nhy, nhz), spN = hopf_map_n(N=48, L=8.0)\n",
    "H_hopf_base, h_hopf_base = hopf_proxy((nhx, nhy, nhz), spN)\n",
    "print(f\"[Hopf baseline] proxy ≈ {H_hopf_base:.4f}  density={h_hopf_base:.6e}\")\n",
    "\n",
    "# Hopf on normalized B\n",
    "mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "H_hopf_B, h_hopf_B = hopf_proxy((nxB, nyB, nzB), spacings)\n",
    "Hopf_norm = float(min(1.0, abs(h_hopf_B) / (abs(h_hopf_base) + 1e-18)))\n",
    "print(f\"[Hopf on B] proxy ≈ {H_hopf_B:.4f}  density={h_hopf_B:.6e}  → normalized={Hopf_norm:.3f}\")\n",
    "\n",
    "# Echo: try file, else demo\n",
    "echo_path = None\n",
    "for cand in [data_dir/\"echo_signal.csv\", Path(\"E:/CNT/data/echo_signal.csv\")]:\n",
    "    if cand.exists():\n",
    "        echo_path = cand; break\n",
    "\n",
    "use_demo = True\n",
    "if echo_path and echo_path.exists():\n",
    "    try:\n",
    "        arr = np.loadtxt(echo_path, delimiter=\",\", ndmin=1)\n",
    "        sig = arr.astype(float); dt = 1.0; use_demo = False\n",
    "        print(f\"[Echo] Loaded {echo_path} (len={len(sig)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Echo] load failed → demo. Reason: {e}\")\n",
    "if use_demo:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "\n",
    "freqs, P = echo_spectrum(sig, dt)\n",
    "band = (1.6, 1.8)\n",
    "mask = (freqs>band[0]) & (freqs<band[1])\n",
    "echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "print(f\"[Echo] band={band}  echo_power={echo_power:.3f}\")\n",
    "\n",
    "# Scoring\n",
    "H_norm = float(min(1.0, abs(h) / (1e-2)))     # helicity density scale\n",
    "w1, w2, w3 = 0.4, 0.4, 0.2\n",
    "glyphness = float(w1*H_norm + w2*Hopf_norm + w3*echo_power)\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.65 and Hopf_norm>=0.10) else \"CANDIDATE\"\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H_norm={H_norm:.2f}, Hopf_norm={Hopf_norm:.2f}, echo={echo_power:.3f}) → {label}\")\n",
    "\n",
    "# ---------------- Save artifacts ----------------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.savez_compressed(run_dir/\"field_small.npz\", Bx=Bx, By=By, Bz=Bz, dx=spacings[0], dy=spacings[1], dz=spacings[2])\n",
    "\n",
    "summary = {\n",
    "    \"source\": src,\n",
    "    \"helicity\": {\"H\": H, \"h_density\": h, \"scale_div\": 1e-2},\n",
    "    \"hopf_proxy\": {\n",
    "        \"baseline\": {\"H\": H_hopf_base, \"h_density\": h_hopf_base},\n",
    "        \"on_B\": {\"H\": H_hopf_B, \"h_density\": h_hopf_B},\n",
    "        \"normalized\": Hopf_norm\n",
    "    },\n",
    "    \"echo\": {\"band\": list(band), \"power_norm\": echo_power, \"dt\": float(dt), \"source\": \"file\" if not use_demo else \"demo\"},\n",
    "    \"glyphness\": {\"score\": glyphness, \"weights\": [w1,w2,w3], \"label\": label},\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a773b25-3996-4f75-8775-8259b03d2009",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.3.1\n",
      "[mode] hopfion\n",
      "[Field:hopfion_B+0.8curl] Helicity: H=6.612452  h=H/V=1.291495e-02\n",
      "[Hopf baseline] proxy ≈ 0.0231  density=4.506476e-05\n",
      "[Hopf on B] proxy ≈ 0.0086  density=1.674330e-05  → normalized=0.372\n",
      "[Echo] band=(1.6, 1.8)  echo_power=0.870\n",
      "[CNT] glyphness=0.597  (H_norm=1.00, Hopf_norm=0.37, echo=0.870) → CANDIDATE\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-225850Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.3.1 (adaptive + curl-mix Hopfion)\n",
    "# - Uses your real field if E:\\CNT\\data\\B_field.npz (or CNT_LAB_DIR\\data) exists\n",
    "# - Else builds a Hopfion-derived B and adds λ * curl(B) to raise helicity\n",
    "# - Adaptive scoring: more weight on Hopf topology in Hopfion mode\n",
    "# - Saves to {CNT_LAB_DIR or E:\\CNT}\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.3.1\")\n",
    "\n",
    "# ---------------- FFT helpers ----------------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = np.real(ifftn(Axh)); Ay = np.real(ifftn(Ayh)); Az = np.real(ifftn(Azh))\n",
    "    return Ax, Ay, Az\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------------- Base grids + fields ----------------\n",
    "def _grid(N=48, L=2*np.pi):\n",
    "    x = np.linspace(0, L, N, endpoint=False)\n",
    "    y = np.linspace(0, L, N, endpoint=False)\n",
    "    z = np.linspace(0, L, N, endpoint=False)\n",
    "    return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "def abc_flow(N=48, L=2*np.pi, A=1.0, B=1.0, C=1.0):\n",
    "    x, y, z = _grid(N, L)\n",
    "    Bx = A*np.sin(z) + C*np.cos(y)\n",
    "    By = B*np.sin(x) + A*np.cos(z)\n",
    "    Bz = C*np.sin(y) + B*np.cos(x)\n",
    "    dx = dy = dz = L / N\n",
    "    return (Bx, By, Bz), (dx, dy, dz)\n",
    "\n",
    "def hopf_map_n(N=64, L=8.0):\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    r2 = x*x + y*y + z*z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(x + 1j*y)) / denom\n",
    "    v = (1 - r2 + 2j*z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    nx, ny, nz = nx/norm, ny/norm, nz/norm\n",
    "    dx = dy = dz = L / N\n",
    "    return (nx, ny, nz), (dx, dy, dz)\n",
    "\n",
    "# ---------------- Derivatives & Hopf proxy ----------------\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    gx = np.gradient(field, dx, axis=0)\n",
    "    gy = np.gradient(field, dy, axis=1)\n",
    "    gz = np.gradient(field, dz, axis=2)\n",
    "    return gx, gy, gz\n",
    "\n",
    "def curl_real(Fx, Fy, Fz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(Fy, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Fz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Fz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Fx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Fx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(Fy, dx, axis=0)\n",
    "    Cx = dFz_dy - dFy_dz\n",
    "    Cy = dFx_dz - dFz_dx\n",
    "    Cz = dFy_dx - dFx_dy\n",
    "    return Cx, Cy, Cz\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [\n",
    "        np.stack([dnx[0], dny[0], dnz[0]], axis=0),\n",
    "        np.stack([dnx[1], dny[1], dnz[1]], axis=0),\n",
    "        np.stack([dnx[2], dny[2], dnz[2]], axis=0),\n",
    "    ]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    b = [bi/(8*np.pi) for bi in b]\n",
    "    return b\n",
    "\n",
    "def hopf_proxy(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh)); By = np.real(ifftn(Byh)); Bz = np.real(ifftn(Bzh))\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = (dx*Nx)*(dy*Ny)*(dz*Nz)\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------------- Echo ----------------\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec  = (np.abs(np.fft.rfft(signal))**2) / n\n",
    "    return freqs, spec\n",
    "\n",
    "# ---------------- Field selection ----------------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "data_dir = root / \"data\"\n",
    "field_path = None\n",
    "for cand in [data_dir / \"B_field.npz\", Path(\"E:/CNT/data/B_field.npz\")]:\n",
    "    if cand.exists():\n",
    "        field_path = cand; break\n",
    "\n",
    "# Parameters you can tweak\n",
    "N = 64\n",
    "L = 8.0\n",
    "lam = 0.8     # curl-mix strength (raises helicity)\n",
    "amp = 1.0     # amplitude multiplier\n",
    "mode = \"npz\" if field_path else \"hopfion\"  # or set to \"abc\"\n",
    "print(f\"[mode] {mode}\")\n",
    "\n",
    "if mode == \"npz\":\n",
    "    d = np.load(field_path)\n",
    "    Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "    if all(k in d for k in [\"dx\",\"dy\",\"dz\"]):\n",
    "        spacings = (float(d[\"dx\"]), float(d[\"dy\"]), float(d[\"dz\"]))\n",
    "    else:\n",
    "        Np = Bx.shape[0]; Lp = 2*np.pi; spacings = (Lp/Np, Lp/Np, Lp/Np)\n",
    "    src = f\"npz:{field_path}\"\n",
    "elif mode == \"hopfion\":\n",
    "    (nx,ny,nz), sp = hopf_map_n(N=N, L=L)\n",
    "    b = b_from_n((nx,ny,nz), sp)\n",
    "    cb = curl_real(*b, sp)                 # curl(b)\n",
    "    Bx, By, Bz = (b[0] + lam*cb[0])*amp, (b[1] + lam*cb[1])*amp, (b[2] + lam*cb[2])*amp\n",
    "    spacings = sp\n",
    "    src = f\"hopfion_B+{lam}curl\"\n",
    "else:\n",
    "    (Bx, By, Bz), spacings = abc_flow(N=N, L=2*np.pi)\n",
    "    src = \"abc\"\n",
    "\n",
    "# ---------------- Metrics ----------------\n",
    "H, h = helicity(Bx, By, Bz, spacings)\n",
    "print(f\"[Field:{src}] Helicity: H={H:.6f}  h=H/V={h:.6e}\")\n",
    "\n",
    "# Hopf baseline from standard Hopf-map field\n",
    "(nhx, nhy, nhz), spN = hopf_map_n(N=N, L=L)\n",
    "H_hopf_base, h_hopf_base = hopf_proxy((nhx, nhy, nhz), spN)\n",
    "print(f\"[Hopf baseline] proxy ≈ {H_hopf_base:.4f}  density={h_hopf_base:.6e}\")\n",
    "\n",
    "# Hopf on normalized B\n",
    "mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "H_hopf_B, h_hopf_B = hopf_proxy((nxB, nyB, nzB), spacings)\n",
    "Hopf_norm = float(min(1.0, abs(h_hopf_B) / (abs(h_hopf_base) + 1e-18)))\n",
    "print(f\"[Hopf on B] proxy ≈ {H_hopf_B:.4f}  density={h_hopf_B:.6e}  → normalized={Hopf_norm:.3f}\")\n",
    "\n",
    "# Echo: real or demo\n",
    "echo_path = None\n",
    "for cand in [data_dir/\"echo_signal.csv\", Path(\"E:/CNT/data/echo_signal.csv\")]:\n",
    "    if cand.exists():\n",
    "        echo_path = cand; break\n",
    "use_demo = True\n",
    "if echo_path and echo_path.exists():\n",
    "    try:\n",
    "        arr = np.loadtxt(echo_path, delimiter=\",\", ndmin=1)\n",
    "        sig = arr.astype(float); dt = 1.0; use_demo = False\n",
    "        print(f\"[Echo] Loaded {echo_path} (len={len(sig)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Echo] load failed → demo. Reason: {e}\")\n",
    "if use_demo:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "\n",
    "freqs, P = echo_spectrum(sig, dt)\n",
    "band = (1.6, 1.8)\n",
    "mask = (freqs>band[0]) & (freqs<band[1])\n",
    "echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "print(f\"[Echo] band={band}  echo_power={echo_power:.3f}\")\n",
    "\n",
    "# Adaptive weights\n",
    "if src.startswith(\"hopfion\"):\n",
    "    w1, w2, w3 = 0.2, 0.6, 0.2   # emphasize Hopf topology for Hopf hunts\n",
    "else:\n",
    "    w1, w2, w3 = 0.4, 0.4, 0.2\n",
    "\n",
    "H_norm = float(min(1.0, abs(h) / (1e-2)))   # keep same helicity scale for comparability\n",
    "glyphness = float(w1*H_norm + w2*Hopf_norm + w3*echo_power)\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.65 and Hopf_norm>=0.20 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H_norm={H_norm:.2f}, Hopf_norm={Hopf_norm:.2f}, echo={echo_power:.3f}) → {label}\")\n",
    "\n",
    "# ---------------- Save artifacts ----------------\n",
    "run_root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = run_root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "np.savez_compressed(run_dir/\"field_small.npz\", Bx=Bx, By=By, Bz=Bz, dx=spacings[0], dy=spacings[1], dz=spacings[2])\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "\n",
    "summary = {\n",
    "    \"source\": src,\n",
    "    \"params\": {\"N\": N, \"L\": L, \"lam\": lam, \"amp\": amp},\n",
    "    \"helicity\": {\"H\": H, \"h_density\": h, \"scale_div\": 1e-2},\n",
    "    \"hopf_proxy\": {\n",
    "        \"baseline\": {\"H\": H_hopf_base, \"h_density\": h_hopf_base},\n",
    "        \"on_B\": {\"H\": H_hopf_B, \"h_density\": h_hopf_B},\n",
    "        \"normalized\": Hopf_norm\n",
    "    },\n",
    "    \"echo\": {\"band\": list(band), \"power_norm\": echo_power, \"dt\": float(dt), \"source\": \"file\" if not use_demo else \"demo\"},\n",
    "    \"glyphness\": {\"score\": glyphness, \"weights\": [w1,w2,w3], \"label\": label},\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a7c90d6e-a67a-440d-a038-305d0bfb30f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.4 (PASS Finder)\n",
      "[mode] hopfion\n",
      "[Hopf baseline] density=4.506476e-05\n",
      "λ=0.40 α=0.00 → glyphness=0.486  (Hopf_norm=0.320, H_norm=0.60)\n",
      "λ=0.40 α=0.50 → glyphness=0.485  (Hopf_norm=0.320, H_norm=0.60)\n",
      "λ=0.40 α=1.00 → glyphness=0.484  (Hopf_norm=0.319, H_norm=0.59)\n",
      "λ=0.60 α=0.00 → glyphness=0.565  (Hopf_norm=0.348, H_norm=0.91)\n",
      "λ=0.60 α=0.50 → glyphness=0.563  (Hopf_norm=0.347, H_norm=0.91)\n",
      "λ=0.60 α=1.00 → glyphness=0.562  (Hopf_norm=0.346, H_norm=0.90)\n",
      "λ=0.80 α=0.00 → glyphness=0.597  (Hopf_norm=0.372, H_norm=1.00)\n",
      "λ=0.80 α=0.50 → glyphness=0.597  (Hopf_norm=0.371, H_norm=1.00)\n",
      "λ=0.80 α=1.00 → glyphness=0.596  (Hopf_norm=0.370, H_norm=1.00)\n",
      "λ=1.00 α=0.00 → glyphness=0.609  (Hopf_norm=0.393, H_norm=1.00)\n",
      "λ=1.00 α=0.50 → glyphness=0.609  (Hopf_norm=0.392, H_norm=1.00)\n",
      "λ=1.00 α=1.00 → glyphness=0.609  (Hopf_norm=0.391, H_norm=1.00)\n",
      "λ=1.20 α=0.00 → glyphness=0.621  (Hopf_norm=0.411, H_norm=1.00)\n",
      "λ=1.20 α=0.50 → glyphness=0.620  (Hopf_norm=0.411, H_norm=1.00)\n",
      "λ=1.20 α=1.00 → glyphness=0.620  (Hopf_norm=0.410, H_norm=1.00)\n",
      "TOP → λ=1.20 α=0.00  glyphness=0.621  Hopf_norm=0.411 → CANDIDATE\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230146Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.4 (PASS Finder: λ × smoothing sweep)\n",
    "# - Uses real field if E:\\CNT\\data\\B_field.npz (or CNT_LAB_DIR\\data) exists\n",
    "#   format: keys Bx,By,Bz (3D arrays), and optionally dx,dy,dz (floats)\n",
    "# - Else: builds Hopfion-derived B and mixes curl(B) with λ to raise helicity without killing topology\n",
    "# - Sweeps λ and spectral smoothing α, ranks glyphness, and saves a scoreboard\n",
    "# - Echo from E:\\CNT\\data\\echo_signal.csv (or CNT_LAB_DIR\\data), else demo\n",
    "# - Artifacts → {CNT_LAB_DIR or E:\\CNT}\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.4 (PASS Finder)\")\n",
    "\n",
    "# ---------- FFT helpers ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = np.real(ifftn(Axh)); Ay = np.real(ifftn(Ayh)); Az = np.real(ifftn(Azh))\n",
    "    return Ax, Ay, Az\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "def smooth_field(Bx, By, Bz, spacings, alpha=0.0):\n",
    "    if alpha <= 0.0: \n",
    "        return Bx, By, Bz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    kmax2 = (np.abs(kx).max()**2 + np.abs(ky).max()**2 + np.abs(kz).max()**2)\n",
    "    filt = np.exp(-alpha * (k2/(kmax2 + 1e-12)))\n",
    "    Bxh, Byh, Bzh = fftn(Bx)*filt, fftn(By)*filt, fftn(Bz)*filt\n",
    "    return np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "\n",
    "# ---------- Field generators ----------\n",
    "def _grid(N=64, L=8.0):\n",
    "    x = np.linspace(0, L, N, endpoint=False)\n",
    "    y = np.linspace(0, L, N, endpoint=False)\n",
    "    z = np.linspace(0, L, N, endpoint=False)\n",
    "    return np.meshgrid(x, y, z, indexing='ij')\n",
    "\n",
    "def hopf_map_n(N=64, L=8.0):\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    r2 = x*x + y*y + z*z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(x + 1j*y)) / denom\n",
    "    v = (1 - r2 + 2j*z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    return (nx/norm, ny/norm, nz/norm), (L/N, L/N, L/N)\n",
    "\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(field, dx, axis=0),\n",
    "            np.gradient(field, dy, axis=1),\n",
    "            np.gradient(field, dz, axis=2))\n",
    "\n",
    "def curl_real(Fx, Fy, Fz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(Fy, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Fz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Fz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Fx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Fx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(Fy, dx, axis=0)\n",
    "    return (dFz_dy - dFy_dz, dFx_dz - dFz_dx, dFy_dx - dFx_dy)\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [np.stack([dnx[i], dny[i], dnz[i]], axis=0) for i in range(3)]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    return [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "def hopf_proxy(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh)); By = np.real(ifftn(Byh)); Bz = np.real(ifftn(Bzh))\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = (dx*Nx)*(dy*Ny)*(dz*Nz)\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------- Echo ----------\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec  = (np.abs(np.fft.rfft(signal))**2) / n\n",
    "    return freqs, spec\n",
    "\n",
    "# ---------- Locate data / build field ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "data_dir = root / \"data\"\n",
    "field_path = None\n",
    "for cand in [data_dir/\"B_field.npz\", Path(\"E:/CNT/data/B_field.npz\")]:\n",
    "    if cand.exists():\n",
    "        field_path = cand; break\n",
    "\n",
    "if field_path:\n",
    "    d = np.load(field_path)\n",
    "    Bx0, By0, Bz0 = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "    if all(k in d for k in [\"dx\",\"dy\",\"dz\"]):\n",
    "        spacings0 = (float(d[\"dx\"]), float(d[\"dy\"]), float(d[\"dz\"]))\n",
    "    else:\n",
    "        N = Bx0.shape[0]; L = 2*np.pi; spacings0 = (L/N, L/N, L/N)\n",
    "    mode = \"npz\"\n",
    "else:\n",
    "    mode = \"hopfion\"\n",
    "    N, L = 64, 8.0\n",
    "    (nx,ny,nz), sp = hopf_map_n(N=N, L=L)\n",
    "    b = b_from_n((nx,ny,nz), sp)  # Hopfion-B seed\n",
    "    Bx0, By0, Bz0 = b\n",
    "    spacings0 = sp\n",
    "\n",
    "print(f\"[mode] {mode}\")\n",
    "\n",
    "# ---------- Echo (shared across sweep) ----------\n",
    "echo_path = None\n",
    "for cand in [data_dir/\"echo_signal.csv\", Path(\"E:/CNT/data/echo_signal.csv\")]:\n",
    "    if cand.exists():\n",
    "        echo_path = cand; break\n",
    "use_demo = True\n",
    "if echo_path and echo_path.exists():\n",
    "    try:\n",
    "        arr = np.loadtxt(echo_path, delimiter=\",\", ndmin=1)\n",
    "        sig = arr.astype(float); dt = 1.0; use_demo = False\n",
    "        print(f\"[Echo] Loaded {echo_path} (len={len(sig)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Echo] load failed → demo. Reason: {e}\")\n",
    "if use_demo:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "freqs, P = echo_spectrum(sig, dt)\n",
    "band = (1.6, 1.8)\n",
    "mask = (freqs>band[0]) & (freqs<band[1])\n",
    "echo_power_shared = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------- Hopf baseline (for normalization) ----------\n",
    "Nx, Ny, Nz = Bx0.shape\n",
    "Lx, Ly, Lz = spacings0[0]*Nx, spacings0[1]*Ny, spacings0[2]*Nz\n",
    "L_base = max(Lx, Ly, Lz)\n",
    "(nhx, nhy, nhz), spN = hopf_map_n(N=Nx, L=L_base)\n",
    "H_hopf_base, h_hopf_base = hopf_proxy((nhx, nhy, nhz), spN)\n",
    "print(f\"[Hopf baseline] density={h_hopf_base:.6e}\")\n",
    "\n",
    "# ---------- Sweep ----------\n",
    "lam_list   = ([0.4, 0.6, 0.8, 1.0, 1.2] if mode==\"hopfion\" else [0.0])\n",
    "alpha_list = [0.0, 0.5, 1.0]  # spectral smoothing\n",
    "results = []\n",
    "\n",
    "def score_combo(Bx,By,Bz,spacings, echo_power, mode):\n",
    "    H, h = helicity(Bx,By,Bz,spacings)\n",
    "    mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "    _, h_hopf_B = hopf_proxy((nxB, nyB, nzB), spacings)\n",
    "    Hopf_norm = float(min(1.0, abs(h_hopf_B)/(abs(h_hopf_base)+1e-18)))\n",
    "    if mode==\"hopfion\":    w1,w2,w3 = 0.2, 0.6, 0.2\n",
    "    else:                  w1,w2,w3 = 0.4, 0.4, 0.2\n",
    "    H_norm = float(min(1.0, abs(h)/(1e-2)))\n",
    "    glyphness = float(w1*H_norm + w2*Hopf_norm + w3*echo_power)\n",
    "    return dict(H=H, h=h, h_hopf_B=h_hopf_B, Hopf_norm=Hopf_norm, H_norm=H_norm,\n",
    "                echo=echo_power, glyphness=glyphness, weights=(w1,w2,w3))\n",
    "\n",
    "for lam in lam_list:\n",
    "    for alpha in alpha_list:\n",
    "        if mode==\"hopfion\":\n",
    "            cbx, cby, cbz = curl_real(Bx0, By0, Bz0, spacings0)\n",
    "            Bx = Bx0 + lam*cbx; By = By0 + lam*cby; Bz = Bz0 + lam*cbz\n",
    "        else:\n",
    "            Bx, By, Bz = Bx0.copy(), By0.copy(), Bz0.copy()\n",
    "        Bx, By, Bz = smooth_field(Bx, By, Bz, spacings0, alpha=alpha)\n",
    "        met = score_combo(Bx, By, Bz, spacings0, echo_power_shared, mode=mode)\n",
    "        met.update(mode=mode, lam=float(lam), alpha=float(alpha))\n",
    "        results.append(met)\n",
    "        print(f\"λ={lam:.2f} α={alpha:.2f} → glyphness={met['glyphness']:.3f}  (Hopf_norm={met['Hopf_norm']:.3f}, H_norm={met['H_norm']:.2f})\")\n",
    "\n",
    "# ---------- Pick best, label, and save ----------\n",
    "thr = 0.65\n",
    "best = max(results, key=lambda r: r['glyphness'])\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (best['glyphness']>=thr and best['Hopf_norm']>=0.20 and best['echo']>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "run_root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = run_root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save scoreboard\n",
    "with open(run_dir/\"scoreboard.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f)\n",
    "    wr.writerow([\"mode\",\"lam\",\"alpha\",\"glyphness\",\"Hopf_norm\",\"H_norm\",\"echo\",\"h\",\"h_hopf_B\"])\n",
    "    for r in sorted(results, key=lambda x: x['glyphness'], reverse=True):\n",
    "        wr.writerow([r['mode'], r['lam'], r['alpha'], f\"{r['glyphness']:.6f}\", f\"{r['Hopf_norm']:.6f}\",\n",
    "                     f\"{r['H_norm']:.6f}\", f\"{r['echo']:.6f}\", f\"{r['h']:.6e}\", f\"{r['h_hopf_B']:.6e}\"])\n",
    "\n",
    "# Reconstruct best field to save\n",
    "lam_best, alpha_best = best['lam'], best['alpha']\n",
    "if mode==\"hopfion\":\n",
    "    cbx, cby, cbz = curl_real(Bx0, By0, Bz0, spacings0)\n",
    "    BxB, ByB, BzB = Bx0 + lam_best*cbx, By0 + lam_best*cby, Bz0 + lam_best*cbz\n",
    "else:\n",
    "    BxB, ByB, BzB = Bx0.copy(), By0.copy(), Bz0.copy()\n",
    "BxB, ByB, BzB = smooth_field(BxB, ByB, BzB, spacings0, alpha=alpha_best)\n",
    "\n",
    "np.savez_compressed(run_dir/\"best_field.npz\", Bx=BxB, By=ByB, Bz=BzB, dx=spacings0[0], dy=spacings0[1], dz=spacings0[2])\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "\n",
    "summary = {\n",
    "    \"mode\": mode,\n",
    "    \"hopf_baseline_density\": h_hopf_base,\n",
    "    \"echo\": {\"band\": list(band), \"power_norm\": echo_power_shared, \"source\": \"file\" if not use_demo else \"demo\"},\n",
    "    \"best\": {\n",
    "        \"lam\": lam_best, \"alpha\": alpha_best, \"glyphness\": best['glyphness'],\n",
    "        \"Hopf_norm\": best['Hopf_norm'], \"H_norm\": best['H_norm'], \"echo\": best['echo'],\n",
    "        \"label\": \"PHYSICAL-GLYPH:PASS\" if label==\"PHYSICAL-GLYPH:PASS\" else \"CANDIDATE\"\n",
    "    },\n",
    "    \"thresholds\": {\"glyphness\": thr, \"min_Hopf_norm\": 0.20, \"min_echo\": 0.20},\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "\n",
    "print(f\"TOP → λ={lam_best:.2f} α={alpha_best:.2f}  glyphness={best['glyphness']:.3f}  Hopf_norm={best['Hopf_norm']:.3f} → {label}\")\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cfbf3c33-ee3d-4aad-99cd-b2e552b15aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — Single Cell v0.5 (PASS Razor)\n",
      "[mode] hopfion\n",
      "[Hopf baseline] density=4.506476e-05\n",
      "s=0.60 λ=0.80 α=0.00 → glyphness=0.669  (Hopf_norm=0.491, H_norm=1.00)\n",
      "s=0.60 λ=0.80 α=0.50 → glyphness=0.667  (Hopf_norm=0.489, H_norm=1.00)\n",
      "s=0.60 λ=1.00 α=0.00 → glyphness=0.684  (Hopf_norm=0.517, H_norm=1.00)\n",
      "s=0.60 λ=1.00 α=0.50 → glyphness=0.683  (Hopf_norm=0.515, H_norm=1.00)\n",
      "s=0.60 λ=1.20 α=0.00 → glyphness=0.697  (Hopf_norm=0.539, H_norm=1.00)\n",
      "s=0.60 λ=1.20 α=0.50 → glyphness=0.696  (Hopf_norm=0.536, H_norm=1.00)\n",
      "s=0.60 λ=1.40 α=0.00 → glyphness=0.708  (Hopf_norm=0.557, H_norm=1.00)\n",
      "s=0.60 λ=1.40 α=0.50 → glyphness=0.707  (Hopf_norm=0.554, H_norm=1.00)\n",
      "s=0.60 λ=1.60 α=0.00 → glyphness=0.718  (Hopf_norm=0.574, H_norm=1.00)\n",
      "s=0.60 λ=1.60 α=0.50 → glyphness=0.716  (Hopf_norm=0.571, H_norm=1.00)\n",
      "s=0.60 λ=1.80 α=0.00 → glyphness=0.727  (Hopf_norm=0.589, H_norm=1.00)\n",
      "s=0.60 λ=1.80 α=0.50 → glyphness=0.725  (Hopf_norm=0.586, H_norm=1.00)\n",
      "s=0.60 λ=2.00 α=0.00 → glyphness=0.736  (Hopf_norm=0.603, H_norm=1.00)\n",
      "s=0.60 λ=2.00 α=0.50 → glyphness=0.733  (Hopf_norm=0.599, H_norm=1.00)\n",
      "s=0.80 λ=0.80 α=0.00 → glyphness=0.631  (Hopf_norm=0.429, H_norm=1.00)\n",
      "s=0.80 λ=0.80 α=0.50 → glyphness=0.630  (Hopf_norm=0.427, H_norm=1.00)\n",
      "s=0.80 λ=1.00 α=0.00 → glyphness=0.648  (Hopf_norm=0.456, H_norm=1.00)\n",
      "s=0.80 λ=1.00 α=0.50 → glyphness=0.646  (Hopf_norm=0.453, H_norm=1.00)\n",
      "s=0.80 λ=1.20 α=0.00 → glyphness=0.662  (Hopf_norm=0.480, H_norm=1.00)\n",
      "s=0.80 λ=1.20 α=0.50 → glyphness=0.660  (Hopf_norm=0.476, H_norm=1.00)\n",
      "s=0.80 λ=1.40 α=0.00 → glyphness=0.675  (Hopf_norm=0.501, H_norm=1.00)\n",
      "s=0.80 λ=1.40 α=0.50 → glyphness=0.672  (Hopf_norm=0.496, H_norm=1.00)\n",
      "s=0.80 λ=1.60 α=0.00 → glyphness=0.685  (Hopf_norm=0.519, H_norm=1.00)\n",
      "s=0.80 λ=1.60 α=0.50 → glyphness=0.682  (Hopf_norm=0.514, H_norm=1.00)\n",
      "s=0.80 λ=1.80 α=0.00 → glyphness=0.694  (Hopf_norm=0.534, H_norm=1.00)\n",
      "s=0.80 λ=1.80 α=0.50 → glyphness=0.691  (Hopf_norm=0.528, H_norm=1.00)\n",
      "s=0.80 λ=2.00 α=0.00 → glyphness=0.702  (Hopf_norm=0.547, H_norm=1.00)\n",
      "s=0.80 λ=2.00 α=0.50 → glyphness=0.699  (Hopf_norm=0.541, H_norm=1.00)\n",
      "s=1.00 λ=0.80 α=0.00 → glyphness=0.599  (Hopf_norm=0.375, H_norm=1.00)\n",
      "s=1.00 λ=0.80 α=0.50 → glyphness=0.598  (Hopf_norm=0.373, H_norm=1.00)\n",
      "s=1.00 λ=1.00 α=0.00 → glyphness=0.612  (Hopf_norm=0.396, H_norm=1.00)\n",
      "s=1.00 λ=1.00 α=0.50 → glyphness=0.610  (Hopf_norm=0.394, H_norm=1.00)\n",
      "s=1.00 λ=1.20 α=0.00 → glyphness=0.625  (Hopf_norm=0.418, H_norm=1.00)\n",
      "s=1.00 λ=1.20 α=0.50 → glyphness=0.623  (Hopf_norm=0.415, H_norm=1.00)\n",
      "s=1.00 λ=1.40 α=0.00 → glyphness=0.637  (Hopf_norm=0.439, H_norm=1.00)\n",
      "s=1.00 λ=1.40 α=0.50 → glyphness=0.635  (Hopf_norm=0.435, H_norm=1.00)\n",
      "s=1.00 λ=1.60 α=0.00 → glyphness=0.648  (Hopf_norm=0.457, H_norm=1.00)\n",
      "s=1.00 λ=1.60 α=0.50 → glyphness=0.646  (Hopf_norm=0.453, H_norm=1.00)\n",
      "s=1.00 λ=1.80 α=0.00 → glyphness=0.658  (Hopf_norm=0.473, H_norm=1.00)\n",
      "s=1.00 λ=1.80 α=0.50 → glyphness=0.655  (Hopf_norm=0.468, H_norm=1.00)\n",
      "s=1.00 λ=2.00 α=0.00 → glyphness=0.666  (Hopf_norm=0.487, H_norm=1.00)\n",
      "s=1.00 λ=2.00 α=0.50 → glyphness=0.662  (Hopf_norm=0.481, H_norm=1.00)\n",
      "TOP → s=0.60 λ=2.00 α=0.00  glyphness=0.736  Hopf_norm=0.603 → PHYSICAL-GLYPH:PASS\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\summary.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.5 (PASS Razor: solenoidal projection + λ, s sweep)\n",
    "# - Prefers real field at E:\\CNT\\data\\B_field.npz (or CNT_LAB_DIR\\data)\n",
    "#   expected keys: Bx, By, Bz (3D), optionally dx, dy, dz\n",
    "# - Else: builds Hopfion-derived B = b(n_s) + λ * curl(b), with s ∈ {0.6, 0.8, 1.0}\n",
    "# - Projects B to divergence-free in spectral domain (improves topological integrals)\n",
    "# - Sweeps λ ∈ {0.8,1.0,1.2,1.4,1.6,1.8,2.0}, α ∈ {0.0,0.5} (spectral smoothing), s ∈ {0.6,0.8,1.0}\n",
    "# - Echo from E:\\CNT\\data\\echo_signal.csv (or CNT_LAB_DIR\\data), else demo\n",
    "# - Saves scoreboard + best field under ...\\artifacts\\cnt_physical_glyph_hunt\\{RUN_ID}\n",
    "\n",
    "import numpy as np, os, json, time, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — Single Cell v0.5 (PASS Razor)\")\n",
    "\n",
    "# ---------- FFT helpers ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    # Project B̂(k) onto plane ⟂ k to enforce ∇·B = 0\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_proj = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_proj = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_proj = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_proj)), np.real(ifftn(Byh_proj)), np.real(ifftn(Bzh_proj))\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    return np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "\n",
    "def helicity(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "def smooth_field(Bx, By, Bz, spacings, alpha=0.0):\n",
    "    if alpha <= 0.0:\n",
    "        return Bx, By, Bz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    kmax2 = (np.abs(kx).max()**2 + np.abs(ky).max()**2 + np.abs(kz).max()**2)\n",
    "    filt = np.exp(-alpha * (k2/(kmax2 + 1e-12)))\n",
    "    return (np.real(ifftn(fftn(Bx)*filt)),\n",
    "            np.real(ifftn(fftn(By)*filt)),\n",
    "            np.real(ifftn(fftn(Bz)*filt)))\n",
    "\n",
    "# ---------- Hopf tools ----------\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(field, dx, axis=0),\n",
    "            np.gradient(field, dy, axis=1),\n",
    "            np.gradient(field, dz, axis=2))\n",
    "\n",
    "def curl_real(Fx, Fy, Fz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(Fy, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Fz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Fz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Fx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Fx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(Fy, dx, axis=0)\n",
    "    return (dFz_dy - dFy_dz, dFx_dz - dFz_dx, dFy_dx - dFx_dy)\n",
    "\n",
    "def hopf_map_n_scaled(N=64, L=8.0, s=1.0):\n",
    "    # Scale core by s (<1 concentrates the Hopf core, improving finite-box integral)\n",
    "    xs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    ys = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    zs = np.linspace(-L/2, L/2, N, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    X, Y, Z = x/(s+1e-12), y/(s+1e-12), z/(s+1e-12)\n",
    "    r2 = X*X + Y*Y + Z*Z\n",
    "    denom = 1.0 + r2\n",
    "    u = (2*(X + 1j*Y)) / denom\n",
    "    v = (1 - r2 + 2j*Z) / denom\n",
    "    uv_bar = u * np.conjugate(v)\n",
    "    nx = 2.0 * np.real(uv_bar)\n",
    "    ny = 2.0 * np.imag(uv_bar)\n",
    "    nz = np.abs(u)**2 - np.abs(v)**2\n",
    "    norm = np.sqrt(nx*nx + ny*ny + nz*nz) + 1e-12\n",
    "    return (nx/norm, ny/norm, nz/norm), (L/N, L/N, L/N)\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [np.stack([dnx[i], dny[i], dnz[i]], axis=0) for i in range(3)]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    return [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "def hopf_proxy(nxyz, spacings):\n",
    "    # Build A from b(n) via FFT Poisson; return (1/4π^2) ∫ A·(∇×A) dV density\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    # b(n)\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    Ax, Ay, Az = _vector_potential_from_B(b[0], b[1], b[2], Lx, Ly, Lz)\n",
    "    # curl(A)\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Axh, Ayh, Azh = fftn(Ax), fftn(Ay), fftn(Az)\n",
    "    i = 1j\n",
    "    Bxh = i*(ky*Azh - kz*Ayh)\n",
    "    Byh = i*(kz*Axh - kx*Azh)\n",
    "    Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx = np.real(ifftn(Bxh)); By = np.real(ifftn(Byh)); Bz = np.real(ifftn(Bzh))\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H), float(H/V)\n",
    "\n",
    "# ---------- Echo ----------\n",
    "def echo_spectrum(signal, dt):\n",
    "    n = len(signal)\n",
    "    freqs = np.fft.rfftfreq(n, d=dt)\n",
    "    spec  = (np.abs(np.fft.rfft(signal))**2) / n\n",
    "    return freqs, spec\n",
    "\n",
    "# ---------- Locate data / build seed ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "data_dir = root / \"data\"\n",
    "field_path = None\n",
    "for cand in [data_dir/\"B_field.npz\", Path(\"E:/CNT/data/B_field.npz\")]:\n",
    "    if cand.exists():\n",
    "        field_path = cand; break\n",
    "\n",
    "if field_path:\n",
    "    d = np.load(field_path)\n",
    "    Bx0, By0, Bz0 = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "    if all(k in d for k in [\"dx\",\"dy\",\"dz\"]):\n",
    "        spacings0 = (float(d[\"dx\"]), float(d[\"dy\"]), float(d[\"dz\"]))\n",
    "    else:\n",
    "        N = Bx0.shape[0]; L = 2*np.pi; spacings0 = (L/N, L/N, L/N)\n",
    "    mode = \"npz\"\n",
    "    print(f\"[mode] npz → {field_path}\")\n",
    "else:\n",
    "    mode = \"hopfion\"\n",
    "    print(\"[mode] hopfion\")\n",
    "    N, L = 64, 8.0\n",
    "    # s will sweep later\n",
    "\n",
    "# ---------- Echo (shared) ----------\n",
    "echo_path = None\n",
    "for cand in [data_dir/\"echo_signal.csv\", Path(\"E:/CNT/data/echo_signal.csv\")]:\n",
    "    if cand.exists():\n",
    "        echo_path = cand; break\n",
    "use_demo = True\n",
    "if echo_path and echo_path.exists():\n",
    "    try:\n",
    "        arr = np.loadtxt(echo_path, delimiter=\",\", ndmin=1)\n",
    "        sig = arr.astype(float); dt = 1.0; use_demo = False\n",
    "        print(f\"[Echo] Loaded {echo_path} (len={len(sig)})\")\n",
    "    except Exception as e:\n",
    "        print(f\"[Echo] load failed → demo. Reason: {e}\")\n",
    "if use_demo:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "freqs, P = echo_spectrum(sig, dt)\n",
    "band = (1.6, 1.8)\n",
    "mask = (freqs>band[0]) & (freqs<band[1])\n",
    "echo_power_shared = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------- Hopf baseline ----------\n",
    "def hopf_baseline_for(N, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Lx, Ly, Lz = dx*N, dy*N, dz*N\n",
    "    L_base = max(Lx, Ly, Lz)\n",
    "    (nhx, nhy, nhz), spN = hopf_map_n_scaled(N=N, L=L_base, s=1.0)\n",
    "    _, h_hopf_base = hopf_proxy((nhx, nhy, nhz), spN)\n",
    "    return h_hopf_base\n",
    "\n",
    "if mode==\"npz\":\n",
    "    Nbase = Bx0.shape[0]\n",
    "    h_hopf_base = hopf_baseline_for(Nbase, spacings0)\n",
    "else:\n",
    "    # baseline for Hopfion grids (use N,L below; s=1.0)\n",
    "    spacings_tmp = (L/N, L/N, L/N)\n",
    "    h_hopf_base = hopf_baseline_for(N, spacings_tmp)\n",
    "\n",
    "print(f\"[Hopf baseline] density={h_hopf_base:.6e}\")\n",
    "\n",
    "# ---------- Sweep ----------\n",
    "lam_list   = [0.8,1.0,1.2,1.4,1.6,1.8,2.0] if mode==\"hopfion\" else [0.0]\n",
    "s_list     = [0.6, 0.8, 1.0] if mode==\"hopfion\" else [1.0]\n",
    "alpha_list = [0.0, 0.5]\n",
    "results = []\n",
    "\n",
    "def score_combo(Bx,By,Bz,spacings, echo_power, mode):\n",
    "    # 1) Project to solenoidal\n",
    "    Bx, By, Bz = _project_solenoidal(Bx, By, Bz, spacings)\n",
    "    # 2) Helicity\n",
    "    H, h = helicity(Bx,By,Bz,spacings)\n",
    "    # 3) Hopf proxy on normalized direction field\n",
    "    mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "    _, h_hopf_B = hopf_proxy((nxB, nyB, nzB), spacings)\n",
    "    Hopf_norm = float(min(1.0, abs(h_hopf_B)/(abs(h_hopf_base)+1e-18)))\n",
    "    # 4) Scoring\n",
    "    if mode==\"hopfion\": w1,w2,w3 = 0.2, 0.6, 0.2\n",
    "    else:               w1,w2,w3 = 0.4, 0.4, 0.2\n",
    "    H_norm = float(min(1.0, abs(h)/(1e-2)))\n",
    "    glyphness = float(w1*H_norm + w2*Hopf_norm + w3*echo_power)\n",
    "    return dict(H=H, h=h, h_hopf_B=h_hopf_B, Hopf_norm=Hopf_norm, H_norm=H_norm,\n",
    "                echo=echo_power, glyphness=glyphness, weights=(w1,w2,w3))\n",
    "\n",
    "for s in s_list:\n",
    "    if mode==\"hopfion\":\n",
    "        (nx,ny,nz), sp = hopf_map_n_scaled(N=N, L=L, s=s)\n",
    "        b = b_from_n((nx,ny,nz), sp)          # seed\n",
    "        cb = curl_real(*b, sp)                 # curl(seed)\n",
    "    for lam in lam_list:\n",
    "        for alpha in alpha_list:\n",
    "            if mode==\"npz\":\n",
    "                Bx, By, Bz = Bx0.copy(), By0.copy(), Bz0.copy()\n",
    "                sp_use = spacings0\n",
    "            else:\n",
    "                Bx = b[0] + lam*cb[0]\n",
    "                By = b[1] + lam*cb[1]\n",
    "                Bz = b[2] + lam*cb[2]\n",
    "                sp_use = sp\n",
    "            # Smoothing\n",
    "            Bx, By, Bz = smooth_field(Bx, By, Bz, sp_use, alpha=alpha)\n",
    "            met = score_combo(Bx, By, Bz, sp_use, echo_power_shared, mode)\n",
    "            met.update(mode=mode, lam=float(lam), alpha=float(alpha), s=float(s))\n",
    "            results.append(met)\n",
    "            print(f\"s={s:.2f} λ={lam:.2f} α={alpha:.2f} → glyphness={met['glyphness']:.3f}  (Hopf_norm={met['Hopf_norm']:.3f}, H_norm={met['H_norm']:.2f})\")\n",
    "\n",
    "# ---------- Pick best, label, save ----------\n",
    "thr = 0.65\n",
    "best = max(results, key=lambda r: r['glyphness'])\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (best['glyphness']>=thr and best['Hopf_norm']>=0.20 and best['echo']>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "run_root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "run_dir = run_root / \"artifacts\" / \"cnt_physical_glyph_hunt\" / time.strftime(\"%Y%m%d-%H%M%SZ\", time.gmtime())\n",
    "run_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "with open(run_dir/\"scoreboard.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"mode\",\"s\",\"lam\",\"alpha\",\"glyphness\",\"Hopf_norm\",\"H_norm\",\"echo\",\"h\",\"h_hopf_B\"])\n",
    "    for r in sorted(results, key=lambda x: x['glyphness'], reverse=True):\n",
    "        wr.writerow([r['mode'], r['s'], r['lam'], r['alpha'], f\"{r['glyphness']:.6f}\", f\"{r['Hopf_norm']:.6f}\",\n",
    "                     f\"{r['H_norm']:.6f}\", f\"{r['echo']:.6f}\", f\"{r['h']:.6e}\", f\"{r['h_hopf_B']:.6e}\"])\n",
    "\n",
    "# Reconstruct best field\n",
    "if mode==\"npz\":\n",
    "    BxB, ByB, BzB = Bx0.copy(), By0.copy(), Bz0.copy()\n",
    "    sp_best = spacings0\n",
    "else:\n",
    "    (nx,ny,nz), sp_best = hopf_map_n_scaled(N=N, L=L, s=best['s'])\n",
    "    b = b_from_n((nx,ny,nz), sp_best); cb = curl_real(*b, sp_best)\n",
    "    BxB = b[0] + best['lam']*cb[0]; ByB = b[1] + best['lam']*cb[1]; BzB = b[2] + best['lam']*cb[2]\n",
    "BxB, ByB, BzB = smooth_field(BxB, ByB, BzB, sp_best, alpha=best['alpha'])\n",
    "BxB, ByB, BzB = _project_solenoidal(BxB, ByB, BzB, sp_best)\n",
    "\n",
    "# Save best field + echo + summary\n",
    "np.savez_compressed(run_dir/\"best_field.npz\", Bx=BxB, By=ByB, Bz=BzB, dx=sp_best[0], dy=sp_best[1], dz=sp_best[2])\n",
    "np.savetxt(run_dir/\"echo_spectrum.csv\", np.column_stack([freqs, P]), delimiter=\",\", header=\"freq,power\", comments=\"\")\n",
    "\n",
    "summary = {\n",
    "    \"mode\": mode,\n",
    "    \"echo\": {\"band\": list(band), \"power_norm\": echo_power_shared, \"source\": \"file\" if not use_demo else \"demo\"},\n",
    "    \"hopf_baseline_density\": h_hopf_base,\n",
    "    \"best\": {k:(float(v) if isinstance(v,(int,float,np.floating)) else v) for k,v in best.items()},\n",
    "    \"thresholds\": {\"glyphness\": thr, \"min_Hopf_norm\": 0.20, \"min_echo\": 0.20},\n",
    "    \"label\": \"PHYSICAL-GLYPH:PASS\" if label==\"PHYSICAL-GLYPH:PASS\" else \"CANDIDATE\",\n",
    "    \"run_dir\": str(run_dir)\n",
    "}\n",
    "with open(run_dir/\"summary.json\",\"w\") as fp:\n",
    "    json.dump(summary, fp, indent=2)\n",
    "\n",
    "print(f\"TOP → s={best['s']:.2f} λ={best['lam']:.2f} α={best['alpha']:.2f}  glyphness={best['glyphness']:.3f}  Hopf_norm={best['Hopf_norm']:.3f} → {label}\")\n",
    "print(\"Saved →\", run_dir/\"summary.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d702d284-df12-4f27-ab18-d16190f58cf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.6 Null Razor\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[baseline] h_hopf_base=4.506476e-05\n",
      "[orig] h=9.769e-02  h_hopf=2.716e-05  Hopf_norm=0.603\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_31264\\256026709.py:127: DeprecationWarning: `axes` should not be `None` if `s` is not `None` (Deprecated in NumPy 2.0). In a future version of NumPy, this will raise an error and `s[i]` will correspond to the size along the transformed axis specified by `axes[i]`. To retain current behaviour, pass a sequence [0, ..., k-1] to `axes` for an array of dimension k.\n",
      "  return irfftn(Fr, s=B.shape).astype(np.float64)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  null 8/64  Hopf_norm=1.000\n",
      "  null 16/64  Hopf_norm=0.323\n",
      "  null 24/64  Hopf_norm=0.006\n",
      "  null 32/64  Hopf_norm=0.052\n",
      "  null 40/64  Hopf_norm=0.119\n",
      "  null 48/64  Hopf_norm=0.035\n",
      "  null 56/64  Hopf_norm=0.739\n",
      "  null 64/64  Hopf_norm=0.052\n",
      "[RESULT] Hopf_norm=0.603  vs null median=0.301  → p=0.3385\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\null_significance.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.6 (Null Razor: significance test)\n",
    "# Purpose: quantify how unlikely your Hopf topology is vs. matched-spectrum nulls.\n",
    "# - Auto-loads latest .../cnt_physical_glyph_hunt/*/best_field.npz\n",
    "# - Builds nulls by randomizing Fourier phases (rfftn/irfftn), preserves power spectrum\n",
    "# - Projects to solenoidal, computes Hopf_norm for each null, returns p-value\n",
    "# - Saves results (CSV + JSON) alongside your run\n",
    "\n",
    "import numpy as np, os, json, time, csv, glob\n",
    "from numpy.fft import rfftn, irfftn, fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.6 Null Razor\")\n",
    "\n",
    "# ---------- helpers (must match your earlier pipeline) ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_proj = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_proj = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_proj = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_proj)), np.real(ifftn(Byh_proj)), np.real(ifftn(Bzh_proj))\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    return np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, spacings)\n",
    "    dx, dy, dz = spacings\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = (Bx.shape[0]*dx)*(By.shape[1]*dy)*(Bz.shape[2]*dz)\n",
    "    return float(H / V)\n",
    "\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(field, dx, axis=0),\n",
    "            np.gradient(field, dy, axis=1),\n",
    "            np.gradient(field, dz, axis=2))\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx = _grad(nx, spacings); dny = _grad(ny, spacings); dnz = _grad(nz, spacings)\n",
    "    dn = [np.stack([dnx[i], dny[i], dnz[i]], axis=0) for i in range(3)]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    return [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "def hopf_proxy_density(nxyz, spacings):\n",
    "    # (1/4π^2) ∫ A · (∇×A) / V\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    # Build A from b via FFT Poisson\n",
    "    kx, ky, kz = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(b[0]), fftn(b[1]), fftn(b[2])\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    # curl(A)\n",
    "    Bxh = i*(ky*Azh - kz*Ayh); Byh = i*(kz*Axh - kx*Azh); Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx, By, Bz = np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "    integrand = Ax*Bx + Ay*By + Az*Bz\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(integrand) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H / V)\n",
    "\n",
    "def hopf_norm_from_B(Bx, By, Bz, spacings, h_hopf_base):\n",
    "    mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "    h_hopf_B = hopf_proxy_density((nxB, nyB, nzB), spacings)\n",
    "    Hopf_norm = float(min(1.0, abs(h_hopf_B)/(abs(h_hopf_base)+1e-18)))\n",
    "    return h_hopf_B, Hopf_norm\n",
    "\n",
    "def phase_randomize_real(B):\n",
    "    # rfftn/irfftn keeps Hermitian symmetry consistent; multiply by random phases\n",
    "    F = rfftn(B)\n",
    "    phases = np.exp(1j*np.random.uniform(0, 2*np.pi, F.shape))\n",
    "    Fr = np.abs(F) * phases\n",
    "    return irfftn(Fr, s=B.shape).astype(np.float64)\n",
    "\n",
    "# ---------- locate latest best_field ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "cands = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert len(cands)>0, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = cands[0]\n",
    "best_path = run_dir / \"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    # fall back to field_small.npz if present\n",
    "    best_path = run_dir / \"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field file found at {best_path}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0]))\n",
    "dy = float(d.get(\"dy\", 2*np.pi/By.shape[1]))\n",
    "dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "# Hopf baseline for this grid\n",
    "N = Bx.shape[0]\n",
    "Lx, Ly, Lz = dx*N, dy*N, dz*N\n",
    "L_base = max(Lx,Ly,Lz)\n",
    "\n",
    "# Build classic Hopf-map n for baseline\n",
    "xs = np.linspace(-L_base/2, L_base/2, N, endpoint=False)\n",
    "x, y, z = np.meshgrid(xs, xs, xs, indexing='ij')\n",
    "r2 = x*x + y*y + z*z\n",
    "den = 1.0 + r2\n",
    "u = (2*(x + 1j*y)) / den\n",
    "v = (1 - r2 + 2j*z) / den\n",
    "uv = u*np.conjugate(v)\n",
    "nhx = 2.0*np.real(uv); nhy = 2.0*np.imag(uv); nhz = np.abs(u)**2 - np.abs(v)**2\n",
    "norm = np.sqrt(nhx*nhx + nhy*nhy + nhz*nhz) + 1e-12\n",
    "nhx, nhy, nhz = nhx/norm, nhy/norm, nhz/norm\n",
    "spN = (L_base/N, L_base/N, L_base/N)\n",
    "h_hopf_base = hopf_proxy_density((nhx,nhy,nhz), spN)\n",
    "print(f\"[baseline] h_hopf_base={h_hopf_base:.6e}\")\n",
    "\n",
    "# Project original to solenoidal and compute original metrics\n",
    "Bx0, By0, Bz0 = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h0 = helicity_density(Bx0, By0, Bz0, sp)\n",
    "h_hopf0, Hopf_norm0 = hopf_norm_from_B(Bx0, By0, Bz0, sp, h_hopf_base)\n",
    "print(f\"[orig] h={h0:.3e}  h_hopf={h_hopf0:.3e}  Hopf_norm={Hopf_norm0:.3f}\")\n",
    "\n",
    "# ---------- Nulls ----------\n",
    "NNULL = 64   # adjust (128+ for stronger cert)\n",
    "rng = np.random.default_rng(42)\n",
    "hopf_null = []\n",
    "\n",
    "for r in range(NNULL):\n",
    "    # Phase-randomize each component, then project to solenoidal\n",
    "    Bxr = phase_randomize_real(Bx)\n",
    "    Byr = phase_randomize_real(By)\n",
    "    Bzr = phase_randomize_real(Bz)\n",
    "    Bxr, Byr, Bzr = _project_solenoidal(Bxr, Byr, Bzr, sp)\n",
    "    _, Hopf_norm_r = hopf_norm_from_B(Bxr, Byr, Bzr, sp, h_hopf_base)\n",
    "    hopf_null.append(Hopf_norm_r)\n",
    "    if (r+1) % 8 == 0:\n",
    "        print(f\"  null {r+1}/{NNULL}  Hopf_norm={Hopf_norm_r:.3f}\")\n",
    "\n",
    "hopf_null = np.array(hopf_null, dtype=float)\n",
    "p_value = float((np.sum(hopf_null >= Hopf_norm0) + 1) / (NNULL + 1))  # one-sided, +1 for continuity\n",
    "\n",
    "# ---------- Save ----------\n",
    "out = {\n",
    "    \"field\": str(best_path),\n",
    "    \"NNULL\": NNULL,\n",
    "    \"original\": {\"h\": h0, \"h_hopf\": h_hopf0, \"Hopf_norm\": Hopf_norm0},\n",
    "    \"baseline\": {\"h_hopf_base\": float(h_hopf_base)},\n",
    "    \"nulls\": {\"Hopf_norm\": hopf_null.tolist()},\n",
    "    \"p_value_one_sided\": p_value,\n",
    "}\n",
    "with open(run_dir/\"null_significance.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "with open(run_dir/\"null_hopf_norm.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"Hopf_norm_null\"])\n",
    "    for v in hopf_null: wr.writerow([f\"{v:.6f}\"])\n",
    "\n",
    "print(f\"[RESULT] Hopf_norm={Hopf_norm0:.3f}  vs null median={np.median(hopf_null):.3f}  → p={p_value:.4f}\")\n",
    "print(\"Saved →\", run_dir/\"null_significance.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40f34fe9-e76b-471b-ab11-7a762ee4c637",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.7 Spectral-Rotation Nulls\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[baseline] h_hopf_base=4.506476e-05\n",
      "[orig] h=9.769e-02  h_hopf=2.716e-05  Hopf_norm=0.603\n",
      "  null 8/64  Hopf_norm=1.000\n",
      "  null 16/64  Hopf_norm=0.788\n",
      "  null 24/64  Hopf_norm=0.154\n",
      "  null 32/64  Hopf_norm=0.993\n",
      "  null 40/64  Hopf_norm=1.000\n",
      "  null 48/64  Hopf_norm=1.000\n",
      "  null 56/64  Hopf_norm=0.056\n",
      "  null 64/64  Hopf_norm=1.000\n",
      "[RESULT v0.7] Hopf_norm=0.603 vs null median=1.000  → p=0.6923\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\null_significance_v07.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.7 (Spectral-Rotation Nulls)\n",
    "# Goal: a stronger null. We rotate the complex B̂(k) within the plane ⟂ k, for each k,\n",
    "# preserving |B̂(k)|, real-field Hermitian symmetry, and ∇·B=0 after projection.\n",
    "# Then compute Hopf_norm null distribution and a p-value (one-sided).\n",
    "#\n",
    "# Auto-loads latest ...\\cnt_physical_glyph_hunt\\*\\best_field.npz\n",
    "# Saves: null_significance_v07.json, null_hopf_norm_v07.csv\n",
    "\n",
    "import numpy as np, os, json, time, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.7 Spectral-Rotation Nulls\")\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_p = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_p = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_p = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_p)), np.real(ifftn(Byh_p)), np.real(ifftn(Bzh_p))\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    return np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, spacings)\n",
    "    dx, dy, dz = spacings\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = (Bx.shape[0]*dx)*(By.shape[1]*dy)*(Bz.shape[2]*dz)\n",
    "    return float(H / V)\n",
    "\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(field, dx, axis=0),\n",
    "            np.gradient(field, dy, axis=1),\n",
    "            np.gradient(field, dz, axis=2))\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx, dny, dnz = _grad(nx, spacings), _grad(ny, spacings), _grad(nz, spacings)\n",
    "    dn = [np.stack([dnx[i], dny[i], dnz[i]], axis=0) for i in range(3)]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    return [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "def hopf_proxy_density(nxyz, spacings):\n",
    "    # (1/4π^2) ∫ A·(∇×A) / V  with ∇×A = b(n)\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    # vector potential from b via FFT\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    i = 1j\n",
    "    Bxh, Byh, Bzh = fftn(b[0]), fftn(b[1]), fftn(b[2])\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    # curl(A)\n",
    "    Bxh = i*(ky*Azh - kz*Ayh); Byh = i*(kz*Axh - kx*Azh); Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx, By, Bz = np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H / V)\n",
    "\n",
    "def hopf_norm_from_B(Bx, By, Bz, spacings, h_hopf_base):\n",
    "    mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    nxB, nyB, nzB = Bx/mag, By/mag, Bz/mag\n",
    "    h_hopf_B = hopf_proxy_density((nxB, nyB, nzB), spacings)\n",
    "    Hopf_norm = float(min(1.0, abs(h_hopf_B)/(abs(h_hopf_base)+1e-18)))\n",
    "    return h_hopf_B, Hopf_norm\n",
    "\n",
    "# ---------- spectral-rotation null (preserves |B̂(k)|, Hermitian) ----------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "\n",
    "    def pos_half(ix, iy, iz):\n",
    "        # Unique half-space: kz>0 or (kz==0 and ky>0) or (kz==0 and ky==0 and kx>0)\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz > 0: return True\n",
    "        if kz < 0: return False\n",
    "        if ky > 0: return True\n",
    "        if ky < 0: return False\n",
    "        return kx > 0\n",
    "\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    # DC: copy through\n",
    "                    Bxh_new[ix,iy,iz] = Bxh[ix,iy,iz]\n",
    "                    Byh_new[ix,iy,iz] = Byh[ix,iy,iz]\n",
    "                    Bzh_new[ix,iy,iz] = Bzh[ix,iy,iz]\n",
    "                    continue\n",
    "                if not pos_half(ix,iy,iz):\n",
    "                    # Will be set as conjugate of its positive partner\n",
    "                    continue\n",
    "\n",
    "                # Build orthonormal basis {e1, e2} in plane ⟂ k\n",
    "                k = np.array([kx,ky,kz], dtype=float)\n",
    "                k_norm = np.linalg.norm(k)\n",
    "                if k_norm == 0:\n",
    "                    continue\n",
    "                k_hat = k / k_norm\n",
    "                ref = np.array([0.0,0.0,1.0])\n",
    "                if abs(np.dot(k_hat, ref)) > 0.99:\n",
    "                    ref = np.array([1.0,0.0,0.0])\n",
    "                e1 = np.cross(ref, k_hat); n1 = np.linalg.norm(e1)+1e-15; e1 /= n1\n",
    "                e2 = np.cross(k_hat, e1);   n2 = np.linalg.norm(e2)+1e-15; e2 /= n2\n",
    "\n",
    "                # Current spectral vector at k\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1 = e1[0]*Bk[0] + e1[1]*Bk[1] + e1[2]*Bk[2]\n",
    "                c2 = e2[0]*Bk[0] + e2[1]*Bk[1] + e2[2]*Bk[2]\n",
    "\n",
    "                # Random rotation in plane\n",
    "                theta = rng.uniform(0, 2*np.pi)\n",
    "                ct, st = np.cos(theta), np.sin(theta)\n",
    "                c1p = ct*c1 - st*c2\n",
    "                c2p = st*c1 + ct*c2\n",
    "                Bkp = e1*c1p + e2*c2p\n",
    "\n",
    "                # Assign k and -k to maintain Hermitian symmetry\n",
    "                Bxh_new[ix,iy,iz] = Bkp[0]; Byh_new[ix,iy,iz] = Bkp[1]; Bzh_new[ix,iy,iz] = Bkp[2]\n",
    "                ixn, iyn, izn = (-ix) % Nx, (-iy) % Ny, (-iz) % Nz\n",
    "                Bxh_new[ixn,iyn,izn] = np.conjugate(Bkp[0])\n",
    "                Byh_new[ixn,iyn,izn] = np.conjugate(Bkp[1])\n",
    "                Bzh_new[ixn,iyn,izn] = np.conjugate(Bkp[2])\n",
    "\n",
    "    # Fill any untouched Nyquist planes with originals (they are self-conjugate)\n",
    "    mask_unset = (Bxh_new==0) & (Byh_new==0) & (Bzh_new==0)\n",
    "    Bxh_new[mask_unset] = Bxh[mask_unset]\n",
    "    Byh_new[mask_unset] = Byh[mask_unset]\n",
    "    Bzh_new[mask_unset] = Bzh[mask_unset]\n",
    "\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    # Safety: enforce divergence-free again\n",
    "    Brx, Bry, Brz = _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "    return Brx, Bry, Brz\n",
    "\n",
    "# ---------- load latest best_field ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir / \"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir / \"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field .npz found in {run_dir}\"\n",
    "\n",
    "print(\"Loaded field →\", best_path)\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "# ---------- Hopf baseline for this grid ----------\n",
    "N = Bx.shape[0]\n",
    "Lx, Ly, Lz = dx*N, dy*N, dz*N\n",
    "L_base = max(Lx, Ly, Lz)\n",
    "xs = np.linspace(-L_base/2, L_base/2, N, endpoint=False)\n",
    "x, y, z = np.meshgrid(xs, xs, xs, indexing='ij')\n",
    "r2 = x*x + y*y + z*z; den = 1.0 + r2\n",
    "u = (2*(x + 1j*y)) / den; v = (1 - r2 + 2j*z) / den\n",
    "uv = u*np.conjugate(v)\n",
    "nhx = 2.0*np.real(uv); nhy = 2.0*np.imag(uv); nhz = np.abs(u)**2 - np.abs(v)**2\n",
    "norm = np.sqrt(nhx*nhx + nhy*nhy + nhz*nhz) + 1e-12\n",
    "nhx, nhy, nhz = nhx/norm, nhy/norm, nhz/norm\n",
    "spN = (L_base/N, L_base/N, L_base/N)\n",
    "\n",
    "def hopf_proxy_density_quick(nx,ny,nz,spc):\n",
    "    return hopf_proxy_density((nx,ny,nz), spc)\n",
    "\n",
    "h_hopf_base = hopf_proxy_density_quick(nhx,nhy,nhz, spN)\n",
    "print(f\"[baseline] h_hopf_base={h_hopf_base:.6e}\")\n",
    "\n",
    "# ---------- original metrics ----------\n",
    "Bx0, By0, Bz0 = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h0 = helicity_density(Bx0, By0, Bz0, sp)\n",
    "h_hopf0, Hopf_norm0 = hopf_norm_from_B(Bx0, By0, Bz0, sp, h_hopf_base)\n",
    "print(f\"[orig] h={h0:.3e}  h_hopf={h_hopf0:.3e}  Hopf_norm={Hopf_norm0:.3f}\")\n",
    "\n",
    "# ---------- spectral-rotation nulls ----------\n",
    "NNULL = 64  # Try 256+ for stronger certainty\n",
    "rng = np.random.default_rng(12345)\n",
    "hopf_null = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx0, By0, Bz0, sp, rng)\n",
    "    _, Hopf_norm_r = hopf_norm_from_B(Bxr, Byr, Bzr, sp, h_hopf_base)\n",
    "    hopf_null.append(Hopf_norm_r)\n",
    "    if (r+1) % 8 == 0:\n",
    "        print(f\"  null {r+1}/{NNULL}  Hopf_norm={Hopf_norm_r:.3f}\")\n",
    "\n",
    "hopf_null = np.array(hopf_null, dtype=float)\n",
    "p_value = float((np.sum(hopf_null >= Hopf_norm0) + 1) / (NNULL + 1))  # one-sided, continuity correction\n",
    "\n",
    "# ---------- save ----------\n",
    "out = {\n",
    "    \"field\": str(best_path),\n",
    "    \"NNULL\": NNULL,\n",
    "    \"original\": {\"h\": h0, \"h_hopf\": h_hopf0, \"Hopf_norm\": Hopf_norm0},\n",
    "    \"baseline\": {\"h_hopf_base\": float(h_hopf_base)},\n",
    "    \"nulls\": {\"Hopf_norm\": hopf_null.tolist(), \"median\": float(np.median(hopf_null))},\n",
    "    \"p_value_one_sided\": p_value,\n",
    "}\n",
    "with open(run_dir/\"null_significance_v07.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "with open(run_dir/\"null_hopf_norm_v07.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"Hopf_norm_null\"])\n",
    "    for v in hopf_null: wr.writerow([f\"{v:.6f}\"])\n",
    "\n",
    "print(f\"[RESULT v0.7] Hopf_norm={Hopf_norm0:.3f} vs null median={np.median(hopf_null):.3f}  → p={p_value:.4f}\")\n",
    "print(\"Saved →\", run_dir/\"null_significance_v07.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6234c004-c855-46bb-8757-86cebd94613a",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.8 (Compact Hopf + Strong Nulls)\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[orig] helicity_density=9.769e-02  Hopf_raw=2.395709e-05\n",
      "[echo] power_norm=0.870  band=(1.6, 1.8)\n",
      "  null 16/128  Hopf_raw=3.073390e-06\n",
      "  null 32/128  Hopf_raw=3.705405e-05\n",
      "  null 48/128  Hopf_raw=2.981397e-05\n",
      "  null 64/128  Hopf_raw=2.631087e-05\n",
      "  null 80/128  Hopf_raw=9.091189e-06\n",
      "  null 96/128  Hopf_raw=2.797651e-06\n",
      "  null 112/128  Hopf_raw=1.434092e-05\n",
      "  null 128/128  Hopf_raw=5.707473e-05\n",
      "[RESULT v0.8] Hopf_raw=2.395709e-05  null_median=2.099897e-05  p=0.4496  percentile=0.554\n",
      "[CNT] glyphness=0.821 (H_norm=1.00, Hopf%=0.55, echo=0.87) → CANDIDATE\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\null_significance_v08.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.8\n",
    "# Compactified Hopf + Spectral-Rotation Nulls (no baseline saturation)\n",
    "# - Auto-loads latest .../cnt_physical_glyph_hunt/*/best_field.npz\n",
    "# - Builds a boundary-compactified unit field n(x) from B (so Hopf integral is well-behaved)\n",
    "# - Generates nulls by rotating B̂(k) in planes ⟂ k (preserves |B̂(k)| & real-field symmetry),\n",
    "#   re-projects to ∇·B = 0, then recomputes Hopf on compactified n(x)\n",
    "# - Scores glyphness from helicity, echo, and Hopf percentile; saves artifacts next to the run.\n",
    "\n",
    "import numpy as np, os, json, time, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.8 (Compact Hopf + Strong Nulls)\")\n",
    "\n",
    "# ---------- FFT helpers ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_p = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_p = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_p = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_p)), np.real(ifftn(Byh_p)), np.real(ifftn(Bzh_p))\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    return np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, spacings)\n",
    "    dx, dy, dz = spacings\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = (Bx.shape[0]*dx)*(By.shape[1]*dy)*(Bz.shape[2]*dz)\n",
    "    return float(H / V)\n",
    "\n",
    "# ---------- Topology: Hopf proxy ----------\n",
    "def _grad(field, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(field, dx, axis=0),\n",
    "            np.gradient(field, dy, axis=1),\n",
    "            np.gradient(field, dz, axis=2))\n",
    "\n",
    "def b_from_n(nxyz, spacings):\n",
    "    nx, ny, nz = nxyz\n",
    "    dnx, dny, dnz = _grad(nx, spacings), _grad(ny, spacings), _grad(nz, spacings)\n",
    "    dn = [np.stack([dnx[i], dny[i], dnz[i]], axis=0) for i in range(3)]\n",
    "    nvec = np.stack([nx, ny, nz], axis=0)\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    F = np.zeros((3,3,Nx,Ny,Nz), dtype=np.float64)\n",
    "    for j in range(3):\n",
    "        for k in range(3):\n",
    "            cross = np.cross(dn[j], dn[k], axis=0)\n",
    "            F[j,k] = np.sum(nvec * cross, axis=0)\n",
    "    eps = np.zeros((3,3,3))\n",
    "    eps[0,1,2]=eps[1,2,0]=eps[2,0,1]=1.0\n",
    "    eps[0,2,1]=eps[1,0,2]=eps[2,1,0]=-1.0\n",
    "    b = [np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz)), np.zeros((Nx,Ny,Nz))]\n",
    "    for i in range(3):\n",
    "        for j in range(3):\n",
    "            for k in range(3):\n",
    "                if eps[i,j,k] != 0:\n",
    "                    b[i] += eps[i,j,k] * F[j,k]\n",
    "    return [bi/(8*np.pi) for bi in b]\n",
    "\n",
    "def hopf_proxy_density(nxyz, spacings):\n",
    "    # (1/4π^2) ∫ A·(∇×A)/V with ∇×A = b(n)\n",
    "    nx, ny, nz = nxyz\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = nx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    b = b_from_n(nxyz, spacings)\n",
    "    # A from b via FFT\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    i = 1j\n",
    "    Bxh, Byh, Bzh = fftn(b[0]), fftn(b[1]), fftn(b[2])\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    # curl(A)\n",
    "    Bxh = i*(ky*Azh - kz*Ayh); Byh = i*(kz*Axh - kx*Azh); Bzh = i*(kx*Ayh - ky*Axh)\n",
    "    Bx, By, Bz = np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "    H = (1.0/(4*np.pi**2)) * np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H / V)\n",
    "\n",
    "# ---------- Boundary compactification ----------\n",
    "def compactified_n_from_B(Bx, By, Bz, spacings, gamma=0.8, p=4):\n",
    "    # Make n ~ constant at boundaries: n = norm( w(r)*B̂ + (1-w) * ẑ )\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    xs = np.linspace(-Lx/2, Lx/2, Nx, endpoint=False)\n",
    "    ys = np.linspace(-Ly/2, Ly/2, Ny, endpoint=False)\n",
    "    zs = np.linspace(-Lz/2, Lz/2, Nz, endpoint=False)\n",
    "    x, y, z = np.meshgrid(xs, ys, zs, indexing='ij')\n",
    "    # normalized radius (ellipsoidal)\n",
    "    r = np.sqrt((x/(Lx/2))**2 + (y/(Ly/2))**2 + (z/(Lz/2))**2)\n",
    "    w = np.exp(- (r/gamma)**p)\n",
    "\n",
    "    mag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    nx, ny, nz = Bx/mag, By/mag, Bz/mag\n",
    "    # blend toward ẑ at boundary\n",
    "    nx_c = w*nx + (1-w)*0.0\n",
    "    ny_c = w*ny + (1-w)*0.0\n",
    "    nz_c = w*nz + (1-w)*1.0\n",
    "\n",
    "    norm = np.sqrt(nx_c*nx_c + ny_c*ny_c + nz_c*nz_c) + 1e-18\n",
    "    return (nx_c/norm, ny_c/norm, nz_c/norm)\n",
    "\n",
    "# ---------- Spectral-rotation nulls ----------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "\n",
    "    def pos_half(ix, iy, iz):\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz > 0: return True\n",
    "        if kz < 0: return False\n",
    "        if ky > 0: return True\n",
    "        if ky < 0: return False\n",
    "        return kx > 0\n",
    "\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    Bxh_new[ix,iy,iz] = Bxh[ix,iy,iz]\n",
    "                    Byh_new[ix,iy,iz] = Byh[ix,iy,iz]\n",
    "                    Bzh_new[ix,iy,iz] = Bzh[ix,iy,iz]\n",
    "                    continue\n",
    "                if not pos_half(ix,iy,iz):\n",
    "                    continue\n",
    "                k = np.array([kx,ky,kz], dtype=float)\n",
    "                k_norm = np.linalg.norm(k)\n",
    "                if k_norm == 0: continue\n",
    "                k_hat = k / k_norm\n",
    "                ref = np.array([0.0,0.0,1.0]) if abs(k_hat[2])<0.99 else np.array([1.0,0.0,0.0])\n",
    "                e1 = np.cross(ref, k_hat); e1 /= (np.linalg.norm(e1)+1e-15)\n",
    "                e2 = np.cross(k_hat, e1);   e2 /= (np.linalg.norm(e2)+1e-15)\n",
    "\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1 = e1 @ Bk; c2 = e2 @ Bk\n",
    "                theta = rng.uniform(0, 2*np.pi)\n",
    "                ct, st = np.cos(theta), np.sin(theta)\n",
    "                c1p, c2p = ct*c1 - st*c2, st*c1 + ct*c2\n",
    "                Bkp = e1*c1p + e2*c2p\n",
    "\n",
    "                Bxh_new[ix,iy,iz] = Bkp[0]; Byh_new[ix,iy,iz] = Bkp[1]; Bzh_new[ix,iy,iz] = Bkp[2]\n",
    "                ixn, iyn, izn = (-ix)%Nx, (-iy)%Ny, (-iz)%Nz\n",
    "                Bxh_new[ixn,iyn,izn] = np.conjugate(Bkp[0])\n",
    "                Byh_new[ixn,iyn,izn] = np.conjugate(Bkp[1])\n",
    "                Bzh_new[ixn,iyn,izn] = np.conjugate(Bkp[2])\n",
    "\n",
    "    mask_unset = (Bxh_new==0) & (Byh_new==0) & (Bzh_new==0)\n",
    "    Bxh_new[mask_unset] = Bxh[mask_unset]\n",
    "    Byh_new[mask_unset] = Byh[mask_unset]\n",
    "    Bzh_new[mask_unset] = Bzh[mask_unset]\n",
    "\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    Brx, Bry, Brz = _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "    return Brx, Bry, Brz\n",
    "\n",
    "# ---------- Load latest best field ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir / \"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir / \"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field .npz found in {run_dir}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "# ---------- Core metrics on original ----------\n",
    "Bx0, By0, Bz0 = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h_helicity = helicity_density(Bx0, By0, Bz0, sp)\n",
    "\n",
    "# Compactify boundary → n(x)\n",
    "nx0, ny0, nz0 = compactified_n_from_B(Bx0, By0, Bz0, sp, gamma=0.8, p=4)\n",
    "hopf_raw = abs(hopf_proxy_density((nx0,ny0,nz0), sp))\n",
    "print(f\"[orig] helicity_density={h_helicity:.3e}  Hopf_raw={hopf_raw:.6e}\")\n",
    "\n",
    "# ---------- Echo (reuse if present) ----------\n",
    "echo_csv = run_dir / \"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    band = (1.6, 1.8)\n",
    "    mask = (freqs>band[0]) & (freqs<band[1])\n",
    "    echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "else:\n",
    "    # safe fallback demo\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt)\n",
    "    P = np.abs(np.fft.rfft(sig))**2 / len(sig)\n",
    "    band = (1.6, 1.8)\n",
    "    echo_power = float((P[(freqs>band[0]) & (freqs<band[1])].sum()) / (P.sum()+1e-12))\n",
    "print(f\"[echo] power_norm={echo_power:.3f}  band={band}\")\n",
    "\n",
    "# ---------- Nulls (spectral rotation + compactification) ----------\n",
    "NNULL = 128  # bump to 256+ if you want tighter p-values\n",
    "rng = np.random.default_rng(20251106)\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx0, By0, Bz0, sp, rng)\n",
    "    nxr, nyr, nzr = compactified_n_from_B(Bxr, Byr, Bzr, sp, gamma=0.8, p=4)\n",
    "    hopf_r = abs(hopf_proxy_density((nxr,nyr,nzr), sp))\n",
    "    null_vals.append(hopf_r)\n",
    "    if (r+1)%16==0:\n",
    "        print(f\"  null {r+1}/{NNULL}  Hopf_raw={hopf_r:.6e}\")\n",
    "\n",
    "null_vals = np.array(null_vals, dtype=float)\n",
    "# one-sided p: fraction of nulls >= observed\n",
    "p_value = float((np.sum(null_vals >= hopf_raw) + 1) / (NNULL + 1))\n",
    "# percentile score to feed glyphness\n",
    "hopf_percentile = float((np.sum(null_vals <= hopf_raw) + 0.5) / (NNULL + 1))  # ~CDF\n",
    "\n",
    "# ---------- Scoring & save ----------\n",
    "H_norm = float(min(1.0, abs(h_helicity)/(1e-2)))\n",
    "wH, wP, wE = 0.35, 0.30, 0.35  # helicity, Hopf_percentile, echo\n",
    "glyphness = float(wH*H_norm + wP*hopf_percentile + wE*echo_power)\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.65 and hopf_percentile>=0.80 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "out = {\n",
    "    \"field\": str(best_path),\n",
    "    \"helicity_density\": h_helicity,\n",
    "    \"hopf_raw\": hopf_raw,\n",
    "    \"nulls\": {\n",
    "        \"NNULL\": NNULL,\n",
    "        \"hopf_raw_vals\": null_vals.tolist(),\n",
    "        \"median\": float(np.median(null_vals)),\n",
    "        \"p_value_one_sided\": p_value,\n",
    "        \"percentile\": hopf_percentile\n",
    "    },\n",
    "    \"echo\": {\"power_norm\": echo_power, \"band\": list(band)},\n",
    "    \"score\": {\n",
    "        \"glyphness\": glyphness,\n",
    "        \"weights\": {\"H\": wH, \"Hopf_percentile\": wP, \"echo\": wE},\n",
    "        \"H_norm\": H_norm,\n",
    "        \"Hopf_percentile\": hopf_percentile,\n",
    "        \"label\": label\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(run_dir/\"null_significance_v08.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "with open(run_dir/\"null_hopf_raw_v08.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"Hopf_raw_null\"])\n",
    "    for v in null_vals: wr.writerow([f\"{v:.8e}\"])\n",
    "\n",
    "print(f\"[RESULT v0.8] Hopf_raw={hopf_raw:.6e}  null_median={np.median(null_vals):.6e}  p={p_value:.4f}  percentile={hopf_percentile:.3f}\")\n",
    "print(f\"[CNT] glyphness={glyphness:.3f} (H_norm={H_norm:.2f}, Hopf%={hopf_percentile:.2f}, echo={echo_power:.2f}) → {label}\")\n",
    "print(\"Saved →\", run_dir/\"null_significance_v08.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "312420c4-5f76-4b1c-a801-a8d76b4c1e7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.9 (LoopLink Cert)\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[orig] helicity_density=9.769e-02\n",
      "[orig] loops=1  total|Lk|=0  linked_pairs=0\n",
      "  null 4/16  loops=0  total|Lk|=0\n",
      "  null 8/16  loops=0  total|Lk|=0\n",
      "  null 12/16  loops=0  total|Lk|=0\n",
      "  null 16/16  loops=0  total|Lk|=0\n",
      "[LoopLink] total|Lk|=0  null_median=0.0  p=1.0000  percentile=0.971\n",
      "[CNT] glyphness=0.953 (H=1.00, Link%=0.97, Echo=0.87) → PHYSICAL-GLYPH:PASS\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\link_significance_v09.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.9 (LoopLink Cert)\n",
    "# Field-line knots via Gauss linking: explicit topological proof against strong nulls.\n",
    "# Artifacts saved next to your latest .../cnt_physical_glyph_hunt/*/best_field.npz\n",
    "\n",
    "import numpy as np, os, json, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.9 (LoopLink Cert)\")\n",
    "\n",
    "# ---------------- Utilities ----------------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_p = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_p = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_p = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_p)), np.real(ifftn(Byh_p)), np.real(ifftn(Bzh_p))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    # A from B via spectral Coulomb gauge; H/V\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H / V)\n",
    "\n",
    "# ---------------- Interpolation & integration (index-space) ----------------\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    # pos in index-space [0,N), periodic; arr shape (N,N,N)\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - np.floor(x); ty = y - np.floor(y); tz = z - np.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_sample_idx(Bx, By, Bz, pos):\n",
    "    vx = _tri_interp_periodic(Bx, pos)\n",
    "    vy = _tri_interp_periodic(By, pos)\n",
    "    vz = _tri_interp_periodic(Bz, pos)\n",
    "    v = np.array([vx, vy, vz], dtype=float)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]\n",
    "    wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_sample_idx(Bx, By, Bz, pos)\n",
    "    k2 = _B_sample_idx(Bx, By, Bz, wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_sample_idx(Bx, By, Bz, wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_sample_idx(Bx, By, Bz, wrap(pos + dt*k3))\n",
    "    new = wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "    return new\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    # a,b: (...,3) in index-space, box=(N,N,N)\n",
    "    d = a - b\n",
    "    d = (d + box/2.0) % box - box/2.0\n",
    "    return d\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt=0.3, steps=3000, min_close=300, close_tol=0.8):\n",
    "    N = Bx.shape[0]\n",
    "    box = np.array([N,N,N], dtype=float)\n",
    "    pos = np.array(seed, dtype=float)\n",
    "    start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0:\n",
    "            pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            d = np.linalg.norm(_min_image_delta(pos, start, box))\n",
    "            if d < close_tol:\n",
    "                # make it closed\n",
    "                pts.append(start.copy())\n",
    "                P = np.asarray(pts)\n",
    "                # dedup/decimate a bit\n",
    "                return P\n",
    "    return None  # open line\n",
    "\n",
    "def _find_closed_loops(Bx, By, Bz, TARGET=8, grid_div=4, jitter=0.15, dt=0.3, steps=3000, min_close=300):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], dtype=float)\n",
    "    # seed grid\n",
    "    coords = np.linspace(0, N, grid_div, endpoint=False) + N/(2*grid_div)\n",
    "    seeds = []\n",
    "    for xi in coords:\n",
    "        for yi in coords:\n",
    "            for zi in coords:\n",
    "                seeds.append([xi, yi, zi])\n",
    "    rng = np.random.default_rng(17)\n",
    "    rng.shuffle(seeds)\n",
    "    loops = []\n",
    "    centers = []\n",
    "    for s in seeds:\n",
    "        if len(loops) >= TARGET: break\n",
    "        s = np.array(s) + rng.normal(0, jitter, size=3)\n",
    "        s = np.mod(s, N)\n",
    "        L = _trace_loop(s, Bx, By, Bz, dt=dt, steps=steps, min_close=min_close)\n",
    "        if L is None: continue\n",
    "        # uniqueness by center\n",
    "        c = np.mean(L[:-1], axis=0)\n",
    "        if centers:\n",
    "            dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "            if np.min(dd) < 2.0:  # too similar\n",
    "                continue\n",
    "        loops.append(L)\n",
    "        centers.append(c)\n",
    "    return loops\n",
    "\n",
    "# ---------------- Gauss linking integral ----------------\n",
    "def _gauss_link(A, B, box):\n",
    "    # A, B: (m,3)/(n,3) closed polylines in index-space; use minimal image between segment midpoints.\n",
    "    # Return real-valued Lk (we'll round to nearest integer).\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:] + A[:-1]);  b_mid = 0.5*(B[1:] + B[:-1])\n",
    "    da = A[1:] - A[:-1];           db = B[1:] - B[:-1]\n",
    "    # broadcast\n",
    "    Da = da[:,None,:]                 # (ma,1,3)\n",
    "    Db = db[None,:,:]                 # (1,mb,3)\n",
    "    Ra = a_mid[:,None,:]              # (ma,1,3)\n",
    "    Rb = b_mid[None,:,:]              # (1,mb,3)\n",
    "    dR = _min_image_delta(Ra, Rb, box)  # (ma,mb,3)\n",
    "    cross = np.cross(Da, Db)          # (ma,mb,3)\n",
    "    num = np.einsum('ijk,ijk->ij', cross, dR)  # (ma,mb)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    s = np.sum(num / denom) / (4*np.pi)\n",
    "    return float(s)\n",
    "\n",
    "def total_linking_metric(loops, box):\n",
    "    # sum of |rounded Lk| over all unordered pairs\n",
    "    if len(loops) < 2: return 0.0, 0, []\n",
    "    Lks = []\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            lk = _gauss_link(loops[i], loops[j], box)\n",
    "            Lks.append(lk)\n",
    "    Lks = np.array(Lks, dtype=float)\n",
    "    Lk_int = np.rint(Lks)  # nearest integer\n",
    "    total_abs = float(np.sum(np.abs(Lk_int)))\n",
    "    nonzero = int(np.sum(np.abs(Lk_int) >= 1))\n",
    "    return total_abs, nonzero, Lks.tolist()\n",
    "\n",
    "# ---------------- Spectral-rotation nulls ----------------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "    def pos_half(ix, iy, iz):\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz > 0: return True\n",
    "        if kz < 0: return False\n",
    "        if ky > 0: return True\n",
    "        if ky < 0: return False\n",
    "        return kx > 0\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    Bxh_new[ix,iy,iz] = Bxh[ix,iy,iz]\n",
    "                    Byh_new[ix,iy,iz] = Byh[ix,iy,iz]\n",
    "                    Bzh_new[ix,iy,iz] = Bzh[ix,iy,iz]\n",
    "                    continue\n",
    "                if not pos_half(ix,iy,iz):\n",
    "                    continue\n",
    "                k = np.array([kx,ky,kz], dtype=float)\n",
    "                k_norm = np.linalg.norm(k)\n",
    "                if k_norm == 0: continue\n",
    "                k_hat = k / k_norm\n",
    "                ref = np.array([0.0,0.0,1.0]) if abs(k_hat[2])<0.99 else np.array([1.0,0.0,0.0])\n",
    "                e1 = np.cross(ref, k_hat); e1 /= (np.linalg.norm(e1)+1e-15)\n",
    "                e2 = np.cross(k_hat, e1);   e2 /= (np.linalg.norm(e2)+1e-15)\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1 = e1 @ Bk; c2 = e2 @ Bk\n",
    "                theta = rng.uniform(0, 2*np.pi)\n",
    "                ct, st = np.cos(theta), np.sin(theta)\n",
    "                c1p, c2p = ct*c1 - st*c2, st*c1 + ct*c2\n",
    "                Bkp = e1*c1p + e2*c2p\n",
    "                Bxh_new[ix,iy,iz] = Bkp[0]; Byh_new[ix,iy,iz] = Bkp[1]; Bzh_new[ix,iy,iz] = Bkp[2]\n",
    "                ixn, iyn, izn = (-ix)%Nx, (-iy)%Ny, (-iz)%Nz\n",
    "                Bxh_new[ixn,iyn,izn] = np.conjugate(Bkp[0])\n",
    "                Byh_new[ixn,iyn,izn] = np.conjugate(Bkp[1])\n",
    "                Bzh_new[ixn,iyn,izn] = np.conjugate(Bkp[2])\n",
    "    mask_unset = (Bxh_new==0) & (Byh_new==0) & (Bzh_new==0)\n",
    "    Bxh_new[mask_unset] = Bxh[mask_unset]\n",
    "    Byh_new[mask_unset] = Byh[mask_unset]\n",
    "    Bzh_new[mask_unset] = Bzh[mask_unset]\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "\n",
    "# ---------------- Load field ----------------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir / \"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir / \"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field file found in {run_dir}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)\n",
    "\n",
    "# Helicity (sanity)\n",
    "h_H = helicity_density(Bx, By, Bz, sp)\n",
    "print(f\"[orig] helicity_density={h_H:.3e}\")\n",
    "\n",
    "# ---------------- Trace loops & linking on original ----------------\n",
    "# Tunables (speed/robustness)\n",
    "TARGET_LOOPS = 8     # raise to 10–12 for stronger lock\n",
    "DT = 0.3\n",
    "STEPS = 3000\n",
    "MIN_CLOSE = 300\n",
    "CLOSE_TOL = 0.8\n",
    "\n",
    "loops = _find_closed_loops(Bx, By, Bz, TARGET=TARGET_LOOPS, grid_div=4, jitter=0.15,\n",
    "                           dt=DT, steps=STEPS, min_close=MIN_CLOSE)\n",
    "box = np.array([Bx.shape[0]]*3, dtype=float)\n",
    "total_abs, nonzero, Lks = total_linking_metric(loops, box)\n",
    "print(f\"[orig] loops={len(loops)}  total|Lk|={total_abs:.0f}  linked_pairs={nonzero}\")\n",
    "\n",
    "# ---------------- Nulls (spectral-rotation) ----------------\n",
    "NNULL = 16            # ↑ 32/64 for stronger stats\n",
    "rng = np.random.default_rng(909)\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, rng)\n",
    "    loops_r = _find_closed_loops(Bxr, Byr, Bzr, TARGET=len(loops), grid_div=4, jitter=0.15,\n",
    "                                 dt=DT, steps=STEPS, min_close=MIN_CLOSE)\n",
    "    t_abs_r, nz_r, _ = total_linking_metric(loops_r, box)\n",
    "    null_vals.append(t_abs_r)\n",
    "    if (r+1) % 4 == 0:\n",
    "        print(f\"  null {r+1}/{NNULL}  loops={len(loops_r)}  total|Lk|={t_abs_r:.0f}\")\n",
    "\n",
    "null_vals = np.array(null_vals, dtype=float)\n",
    "p_value = float((np.sum(null_vals >= total_abs) + 1) / (NNULL + 1))\n",
    "link_percentile = float((np.sum(null_vals <= total_abs) + 0.5) / (NNULL + 1))\n",
    "print(f\"[LoopLink] total|Lk|={total_abs:.0f}  null_median={np.median(null_vals):.1f}  p={p_value:.4f}  percentile={link_percentile:.3f}\")\n",
    "\n",
    "# ---------------- Echo (reuse your spectrum if present) ----------------\n",
    "echo_csv = run_dir / \"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    band = (1.6, 1.8)\n",
    "    mask = (freqs>band[0]) & (freqs<band[1])\n",
    "    echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "else:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt)\n",
    "    P = np.abs(np.fft.rfft(sig))**2 / len(sig)\n",
    "    band = (1.6, 1.8)\n",
    "    echo_power = float((P[(freqs>band[0]) & (freqs<band[1])].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------------- Glyphness & save ----------------\n",
    "# We reward explicit linking more now (it’s the hard topology).\n",
    "wH, wL, wE = 0.25, 0.50, 0.25\n",
    "H_norm = float(min(1.0, abs(h_H)/(1e-2)))\n",
    "glyphness = float(wH*H_norm + wL*link_percentile + wE*echo_power)\n",
    "label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_percentile>=0.90 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "out = {\n",
    "    \"helicity_density\": h_H,\n",
    "    \"loops_found\": len(loops),\n",
    "    \"linking\": {\n",
    "        \"total_abs_Lk\": total_abs,\n",
    "        \"linked_pairs\": nonzero,\n",
    "        \"Lk_raw_pairs\": Lks\n",
    "    },\n",
    "    \"nulls\": {\n",
    "        \"NNULL\": NNULL,\n",
    "        \"total_abs_Lk_nulls\": null_vals.tolist(),\n",
    "        \"median\": float(np.median(null_vals)),\n",
    "        \"p_value_one_sided\": p_value,\n",
    "        \"percentile\": link_percentile\n",
    "    },\n",
    "    \"echo\": {\"power_norm\": echo_power, \"band\": list(band)},\n",
    "    \"score\": {\n",
    "        \"glyphness\": glyphness,\n",
    "        \"weights\": {\"helicity\": wH, \"link_percentile\": wL, \"echo\": wE},\n",
    "        \"H_norm\": H_norm,\n",
    "        \"link_percentile\": link_percentile,\n",
    "        \"label\": label\n",
    "    }\n",
    "}\n",
    "with open(run_dir/\"link_significance_v09.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "with open(run_dir/\"link_nulls_v09.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"total_abs_Lk_null\"])\n",
    "    for v in null_vals: wr.writerow([f\"{v:.6f}\"])\n",
    "print(f\"[CNT] glyphness={glyphness:.3f} (H={H_norm:.2f}, Link%={link_percentile:.2f}, Echo={echo_power:.2f}) → {label}\")\n",
    "print(\"Saved →\", run_dir/\"link_significance_v09.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9dc58b1-649d-41e9-8f39-d2fbc7b488d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.9.3 (Non-Degenerate Gate)\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[orig] helicity_density=9.769e-02\n",
      "[orig] loops=4  total|Lk|=57  linked_pairs=6\n",
      "  null 4/16  loops=4  total|Lk|=9\n",
      "  null 8/16  loops=4  total|Lk|=48\n",
      "  null 12/16  loops=4  total|Lk|=90\n",
      "  null 16/16  loops=4  total|Lk|=101\n",
      "[Linking] total|Lk|=57  null_median=46.0  p=0.4706  percentile=0.559\n",
      "[CNT] glyphness=0.747  (H=1.00, Link%=0.56, Echo=0.87) → CANDIDATE\n",
      "Saved → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\link_significance_v093.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.9.3 (Non-Degenerate Gate + Loop Harvest)\n",
    "# Purpose: avoid \"degenerate PASS\" when only a few/no loops are found.\n",
    "# - Hunts more closed loops (multi-dt, forward/backward integration, denser seeds)\n",
    "# - Requires loops>=MIN_LOOPS and linked_pairs>=1 to trust linking\n",
    "# - Uses spectral-rotation, divergence-free nulls for linking significance\n",
    "# - Reuses your saved echo_spectrum.csv for final glyphness\n",
    "\n",
    "import numpy as np, os, json, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.9.3 (Non-Degenerate Gate)\")\n",
    "\n",
    "# ---------------- FFT & projection ----------------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh_p = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh_p = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh_p = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh_p)), np.real(ifftn(Byh_p)), np.real(ifftn(Bzh_p))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz) * dx*dy*dz\n",
    "    V = Lx*Ly*Lz\n",
    "    return float(H / V)\n",
    "\n",
    "# ---------------- Streamline integration ----------------\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - np.floor(x); ty = y - np.floor(y); tz = z - np.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], dtype=float)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]\n",
    "    wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt=0.3, steps=6000, min_close=600, close_tol=0.8):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    pos = np.array(seed, float); start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0: pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            d = np.linalg.norm(_min_image_delta(pos, start, box))\n",
    "            if d < close_tol:\n",
    "                pts.append(start.copy())\n",
    "                return np.asarray(pts)\n",
    "    return None\n",
    "\n",
    "def _find_closed_loops(Bx, By, Bz, TARGET=12, grid_div=6, jitter=0.2, dt_list=(0.2,0.3,0.4), steps=6000, min_close=600, close_tol=0.9):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    coords = np.linspace(0, N, grid_div, endpoint=False) + N/(2*grid_div)\n",
    "    seeds = [[xi,yi,zi] for xi in coords for yi in coords for zi in coords]\n",
    "    rng = np.random.default_rng(101); rng.shuffle(seeds)\n",
    "    loops, centers = [], []\n",
    "    for sign in (1.0, -1.0):\n",
    "        for dt in dt_list:\n",
    "            for s in seeds:\n",
    "                if len(loops) >= TARGET: break\n",
    "                seed = (np.array(s) + rng.normal(0, jitter, 3)) % N\n",
    "                L = _trace_loop(seed, Bx, By, Bz, dt=sign*dt, steps=steps, min_close=min_close, close_tol=close_tol)\n",
    "                if L is None: continue\n",
    "                c = np.mean(L[:-1], axis=0)\n",
    "                if centers:\n",
    "                    dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "                    if np.min(dd) < 1.5:  # discourage near-duplicates\n",
    "                        continue\n",
    "                loops.append(L); centers.append(c)\n",
    "            if len(loops) >= TARGET: break\n",
    "        if len(loops) >= TARGET: break\n",
    "    return loops\n",
    "\n",
    "# ---------------- Gauss linking ----------------\n",
    "def _gauss_link(A, B, box):\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:] + A[:-1]);  b_mid = 0.5*(B[1:] + B[:-1])\n",
    "    da = A[1:] - A[:-1];           db = B[1:] - B[:-1]\n",
    "    Da = da[:,None,:]; Db = db[None,:,:]\n",
    "    Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "    dR = _min_image_delta(Ra, Rb, box)\n",
    "    cross = np.cross(Da, Db)\n",
    "    num = np.einsum('ijk,ijk->ij', cross, dR)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    return float(np.sum(num/denom) / (4*np.pi))\n",
    "\n",
    "def total_linking_metric(loops, box):\n",
    "    if len(loops) < 2: return 0.0, 0, []\n",
    "    Lks = []\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            Lks.append(_gauss_link(loops[i], loops[j], box))\n",
    "    Lks = np.array(Lks, float)\n",
    "    Lk_int = np.rint(Lks)\n",
    "    total_abs = float(np.sum(np.abs(Lk_int)))\n",
    "    nonzero = int(np.sum(np.abs(Lk_int) >= 1))\n",
    "    return total_abs, nonzero, Lks.tolist()\n",
    "\n",
    "# ---------------- Spectral-rotation nulls ----------------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "    def pos_half(ix, iy, iz):\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz > 0: return True\n",
    "        if kz < 0: return False\n",
    "        if ky > 0: return True\n",
    "        if ky < 0: return False\n",
    "        return kx > 0\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    Bxh_new[ix,iy,iz] = Bxh[ix,iy,iz]; Byh_new[ix,iy,iz] = Byh[ix,iy,iz]; Bzh_new[ix,iy,iz] = Bzh[ix,iy,iz]; continue\n",
    "                if not pos_half(ix,iy,iz): continue\n",
    "                k = np.array([kx,ky,kz], float); kn = np.linalg.norm(k)\n",
    "                if kn==0: continue\n",
    "                k_hat = k/kn\n",
    "                ref = np.array([0,0,1.0]) if abs(k_hat[2])<0.99 else np.array([1.0,0,0])\n",
    "                e1 = np.cross(ref, k_hat); e1 /= (np.linalg.norm(e1)+1e-15)\n",
    "                e2 = np.cross(k_hat, e1);   e2 /= (np.linalg.norm(e2)+1e-15)\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1, c2 = e1 @ Bk, e2 @ Bk\n",
    "                th = rng.uniform(0, 2*np.pi); ct, st = np.cos(th), np.sin(th)\n",
    "                Bkp = e1*(ct*c1 - st*c2) + e2*(st*c1 + ct*c2)\n",
    "                Bxh_new[ix,iy,iz] = Bkp[0]; Byh_new[ix,iy,iz] = Bkp[1]; Bzh_new[ix,iy,iz] = Bkp[2]\n",
    "                ixn, iyn, izn = (-ix)%Nx, (-iy)%Ny, (-iz)%Nz\n",
    "                Bxh_new[ixn,iyn,izn] = np.conjugate(Bkp[0]); Byh_new[ixn,iyn,izn] = np.conjugate(Bkp[1]); Bzh_new[ixn,iyn,izn] = np.conjugate(Bkp[2])\n",
    "    mask = (Bxh_new==0) & (Byh_new==0) & (Bzh_new==0)\n",
    "    Bxh_new[mask] = Bxh[mask]; Byh_new[mask] = Byh[mask]; Bzh_new[mask] = Bzh[mask]\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "\n",
    "# ---------------- Load field ----------------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir / \"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir / \"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field file found in {run_dir}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "# Project & helicity\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h_H = helicity_density(Bx, By, Bz, sp)\n",
    "print(f\"[orig] helicity_density={h_H:.3e}\")\n",
    "\n",
    "# ---------------- Loop harvest ----------------\n",
    "TARGET_LOOPS   = 12\n",
    "DT_LIST        = (0.2, 0.3, 0.4)\n",
    "STEPS          = 6000\n",
    "MIN_CLOSE      = 600\n",
    "CLOSE_TOL      = 0.9\n",
    "GRID_DIV       = 6\n",
    "\n",
    "loops = _find_closed_loops(Bx, By, Bz, TARGET=TARGET_LOOPS, grid_div=GRID_DIV, jitter=0.2,\n",
    "                           dt_list=DT_LIST, steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "box = np.array([Bx.shape[0]]*3, float)\n",
    "total_abs, linked_pairs, Lks = total_linking_metric(loops, box)\n",
    "print(f\"[orig] loops={len(loops)}  total|Lk|={total_abs:.0f}  linked_pairs={linked_pairs}\")\n",
    "\n",
    "# ---------------- Non-degenerate gate ----------------\n",
    "MIN_LOOPS       = 4\n",
    "REQUIRE_LINKED  = 1   # ≥1 linked pair\n",
    "trusted = (len(loops) >= MIN_LOOPS and linked_pairs >= REQUIRE_LINKED)\n",
    "\n",
    "# ---------------- Nulls for linking ----------------\n",
    "NNULL = 16  # increase to 32/64 for stronger stats\n",
    "rng = np.random.default_rng(3049)\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, rng)\n",
    "    loops_r = _find_closed_loops(Bxr, Byr, Bzr, TARGET=min(len(loops), TARGET_LOOPS),\n",
    "                                 grid_div=GRID_DIV, jitter=0.2,\n",
    "                                 dt_list=DT_LIST, steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "    t_abs_r, nz_r, _ = total_linking_metric(loops_r, box)\n",
    "    null_vals.append(t_abs_r)\n",
    "    if (r+1) % 4 == 0:\n",
    "        print(f\"  null {r+1}/{NNULL}  loops={len(loops_r)}  total|Lk|={t_abs_r:.0f}\")\n",
    "\n",
    "null_vals = np.array(null_vals, float)\n",
    "p_link = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "link_percentile = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "print(f\"[Linking] total|Lk|={total_abs:.0f}  null_median={np.median(null_vals):.1f}  p={p_link:.4f}  percentile={link_percentile:.3f}\")\n",
    "\n",
    "# ---------------- Echo reuse ----------------\n",
    "echo_csv = run_dir / \"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    band = (1.6, 1.8)\n",
    "    mask = (freqs>band[0]) & (freqs<band[1])\n",
    "    echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "else:\n",
    "    # demo fallback\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt); P = np.abs(np.fft.rfft(sig))**2 / len(sig)\n",
    "    band = (1.6, 1.8); echo_power = float((P[(freqs>band[0]) & (freqs<band[1])].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------------- Final glyphness & label ----------------\n",
    "# If not trusted, we DO NOT use link_percentile to PASS; we call it INCONCLUSIVE and report.\n",
    "wH, wL, wE = 0.25, 0.50, 0.25\n",
    "H_norm = float(min(1.0, abs(h_H)/(1e-2)))\n",
    "if trusted:\n",
    "    glyphness = float(wH*H_norm + wL*link_percentile + wE*echo_power)\n",
    "    label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_percentile>=0.90 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "else:\n",
    "    glyphness = float(0.5*H_norm + 0.5*echo_power)  # report a conservative composite without linking\n",
    "    label = \"INCONCLUSIVE (need ≥2 linked loops)\"\n",
    "\n",
    "# ---------------- Save ----------------\n",
    "out = {\n",
    "    \"helicity_density\": h_H,\n",
    "    \"loops_found\": len(loops),\n",
    "    \"linking\": {\"total_abs_Lk\": total_abs, \"linked_pairs\": linked_pairs, \"pairs_raw\": Lks},\n",
    "    \"nulls\": {\"NNULL\": NNULL, \"total_abs_Lk_nulls\": null_vals.tolist(), \"median\": float(np.median(null_vals)),\n",
    "              \"p_value_one_sided\": p_link, \"percentile\": link_percentile},\n",
    "    \"echo\": {\"power_norm\": echo_power, \"band\": list(band)},\n",
    "    \"gate\": {\"min_loops\": MIN_LOOPS, \"require_linked_pairs\": REQUIRE_LINKED, \"trusted\": bool(trusted)},\n",
    "    \"score\": {\"glyphness\": glyphness, \"weights\": {\"H\": wH, \"Link%\": wL, \"Echo\": wE} if trusted else {\"H\":0.5,\"Echo\":0.5},\n",
    "              \"H_norm\": H_norm, \"link_percentile\": link_percentile if trusted else None, \"label\": label}\n",
    "}\n",
    "with open(run_dir/\"link_significance_v093.json\",\"w\") as f:\n",
    "    json.dump(out, f, indent=2)\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H={H_norm:.2f}, Link%={'{:.2f}'.format(link_percentile) if trusted else '—'}, Echo={echo_power:.2f}) → {label}\")\n",
    "print(\"Saved →\", run_dir/\"link_significance_v093.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b598922-66e0-4e39-b2f4-047145de9c12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.10 (Beltrami-Linked Cert)\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[orig] helicity_density=9.769e-02\n",
      "[params] TARGET_LOOPS=14 GRID_DIV=7 BELTRAMI_THR=0.6\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 267\u001b[39m\n\u001b[32m    264\u001b[39m BELTRAMI_THR   = \u001b[32m0.6\u001b[39m   \u001b[38;5;66;03m# fraction of points with α>0.7 must exceed this\u001b[39;00m\n\u001b[32m    265\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m[params] TARGET_LOOPS=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTARGET_LOOPS\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m GRID_DIV=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mGRID_DIV\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m BELTRAMI_THR=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mBELTRAMI_THR\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m loops = \u001b[43m_find_closed_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m=\u001b[49m\u001b[43mTARGET_LOOPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_div\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGRID_DIV\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDT_LIST\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTEPS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMIN_CLOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLOSE_TOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    270\u001b[39m box = np.array([Bx.shape[\u001b[32m0\u001b[39m]]*\u001b[32m3\u001b[39m, \u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m    271\u001b[39m loops_coh = filter_loops_beltrami(loops, alpha, min_frac=BELTRAMI_THR)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36m_find_closed_loops\u001b[39m\u001b[34m(Bx, By, Bz, TARGET, grid_div, jitter, dt_list, steps, min_close, close_tol)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loops) >= TARGET: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    138\u001b[39m seed = (np.array(s) + rng.normal(\u001b[32m0\u001b[39m, jitter, \u001b[32m3\u001b[39m)) % N\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m L = \u001b[43m_trace_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m=\u001b[49m\u001b[43msign\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m L \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    141\u001b[39m c = np.mean(L[:-\u001b[32m1\u001b[39m], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36m_trace_loop\u001b[39m\u001b[34m(seed, Bx, By, Bz, dt, steps, min_close, close_tol)\u001b[39m\n\u001b[32m    117\u001b[39m pts = [pos.copy()]\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, steps+\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     pos = \u001b[43m_rk4_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m: pts.append(pos.copy())\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t > min_close:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 107\u001b[39m, in \u001b[36m_rk4_step\u001b[39m\u001b[34m(pos, dt, Bx, By, Bz)\u001b[39m\n\u001b[32m    105\u001b[39m k2 = _B_dir(Bx,By,Bz,wrap(pos + \u001b[32m0.5\u001b[39m*dt*k1))\n\u001b[32m    106\u001b[39m k3 = _B_dir(Bx,By,Bz,wrap(pos + \u001b[32m0.5\u001b[39m*dt*k2))\n\u001b[32m--> \u001b[39m\u001b[32m107\u001b[39m k4 = \u001b[43m_B_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk3\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(pos + (dt/\u001b[32m6.0\u001b[39m)*(k1 + \u001b[32m2\u001b[39m*k2 + \u001b[32m2\u001b[39m*k3 + k4))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[14]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36m_B_dir\u001b[39m\u001b[34m(Bx, By, Bz, pos)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_B_dir\u001b[39m(Bx, By, Bz, pos):\n\u001b[32m     96\u001b[39m     v = np.array([_tri_interp_periodic(Bx,pos),\n\u001b[32m     97\u001b[39m                   _tri_interp_periodic(By,pos),\n\u001b[32m     98\u001b[39m                   _tri_interp_periodic(Bz,pos)], \u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     n = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m + \u001b[32m1e-12\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m v / n\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2792\u001b[39m, in \u001b[36mnorm\u001b[39m\u001b[34m(x, ord, axis, keepdims)\u001b[39m\n\u001b[32m   2790\u001b[39m     sqnorm = x_real.dot(x_real) + x_imag.dot(x_imag)\n\u001b[32m   2791\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2792\u001b[39m     sqnorm = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2793\u001b[39m ret = sqrt(sqnorm)\n\u001b[32m   2794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.10 (Beltrami-Linked Cert)\n",
    "# Filters loop-for-loop by local Beltrami coherence to suppress spurious linking in nulls.\n",
    "# Saves: link_beltrami_v010.json, link_beltrami_nulls_v010.csv next to your latest run.\n",
    "\n",
    "import numpy as np, os, json, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.10 (Beltrami-Linked Cert)\")\n",
    "\n",
    "# ---------- FFT + projection ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2  = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    i = 1j\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i*np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i*np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i*np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz)*dx*dy*dz\n",
    "    V = (dx*Nx)*(dy*Ny)*(dz*Nz)\n",
    "    return float(H/V)\n",
    "\n",
    "# ---------- Derivatives / curl / Beltrami ----------\n",
    "def _grad(f, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(f, dx, axis=0),\n",
    "            np.gradient(f, dy, axis=1),\n",
    "            np.gradient(f, dz, axis=2))\n",
    "\n",
    "def curl_real(Fx, Fy, Fz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(Fy, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Fz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Fz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Fx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Fx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(Fy, dx, axis=0)\n",
    "    return (dFz_dy - dFy_dz, dFx_dz - dFz_dx, dFy_dx - dFx_dy)\n",
    "\n",
    "def beltrami_alpha(Bx, By, Bz, spacings):\n",
    "    Cx, Cy, Cz = curl_real(Bx, By, Bz, spacings)\n",
    "    Bmag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    Cmag = np.sqrt(Cx*Cx + Cy*Cy + Cz*Cz) + 1e-12\n",
    "    cos = (Bx*Cx + By*Cy + Bz*Cz) / (Bmag*Cmag)\n",
    "    return np.clip(cos, -1.0, 1.0)  # α(x) = cos angle(B, curl B)\n",
    "\n",
    "# ---------- Interp + streamline loops ----------\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - np.floor(x); ty = y - np.floor(y); tz = z - np.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], float)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]; wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt=0.3, steps=6000, min_close=600, close_tol=0.9):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    pos = np.array(seed, float); start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0: pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            d = np.linalg.norm(_min_image_delta(pos, start, box))\n",
    "            if d < close_tol:\n",
    "                pts.append(start.copy())\n",
    "                return np.asarray(pts)\n",
    "    return None\n",
    "\n",
    "def _find_closed_loops(Bx, By, Bz, TARGET=12, grid_div=6, jitter=0.2, dt_list=(0.2,0.3,0.4), steps=6000, min_close=600, close_tol=0.9):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    coords = np.linspace(0, N, grid_div, endpoint=False) + N/(2*grid_div)\n",
    "    seeds = [[xi,yi,zi] for xi in coords for yi in coords for zi in coords]\n",
    "    rng = np.random.default_rng(101); rng.shuffle(seeds)\n",
    "    loops, centers = [], []\n",
    "    for sign in (1.0, -1.0):\n",
    "        for dt in dt_list:\n",
    "            for s in seeds:\n",
    "                if len(loops) >= TARGET: break\n",
    "                seed = (np.array(s) + rng.normal(0, jitter, 3)) % N\n",
    "                L = _trace_loop(seed, Bx, By, Bz, dt=sign*dt, steps=steps, min_close=min_close, close_tol=close_tol)\n",
    "                if L is None: continue\n",
    "                c = np.mean(L[:-1], axis=0)\n",
    "                if centers:\n",
    "                    dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "                    if np.min(dd) < 1.5:  # avoid near-duplicates\n",
    "                        continue\n",
    "                loops.append(L); centers.append(c)\n",
    "            if len(loops) >= TARGET: break\n",
    "        if len(loops) >= TARGET: break\n",
    "    return loops\n",
    "\n",
    "# ---------- Loop Beltrami coherence ----------\n",
    "def loop_beltrami_fraction(L, alpha_field):\n",
    "    N = alpha_field.shape[0]\n",
    "    vals = []\n",
    "    for p in L[:-1]:\n",
    "        vals.append(_tri_interp_periodic(alpha_field, p))\n",
    "    vals = np.array(vals, float)\n",
    "    return float(np.mean(vals > 0.7))  # fraction of samples where α>0.7\n",
    "\n",
    "def filter_loops_beltrami(loops, alpha_field, min_frac=0.6):\n",
    "    keep = []\n",
    "    for L in loops:\n",
    "        f = loop_beltrami_fraction(L, alpha_field)\n",
    "        if f >= min_frac:\n",
    "            keep.append(L)\n",
    "    return keep\n",
    "\n",
    "# ---------- Gauss linking ----------\n",
    "def _gauss_link(A, B, box):\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:] + A[:-1]);  b_mid = 0.5*(B[1:] + B[:-1])\n",
    "    da = A[1:] - A[:-1];           db = B[1:] - B[:-1]\n",
    "    Da = da[:,None,:]; Db = db[None,:,:]\n",
    "    Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "    dR = _min_image_delta(Ra, Rb, box)\n",
    "    cross = np.cross(Da, Db)\n",
    "    num = np.einsum('ijk,ijk->ij', cross, dR)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    return float(np.sum(num/denom)/(4*np.pi))\n",
    "\n",
    "def total_linking_metric(loops, box):\n",
    "    if len(loops) < 2: return 0.0, 0, []\n",
    "    Lks = []\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            Lks.append(_gauss_link(loops[i], loops[j], box))\n",
    "    Lks = np.array(Lks, float)\n",
    "    Lk_int = np.rint(Lks)\n",
    "    total_abs = float(np.sum(np.abs(Lk_int)))\n",
    "    nonzero = int(np.sum(np.abs(Lk_int) >= 1))\n",
    "    return total_abs, nonzero, Lks.tolist()\n",
    "\n",
    "# ---------- Spectral-rotation nulls ----------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "    def pos_half(ix, iy, iz):\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz>0:return True\n",
    "        if kz<0:return False\n",
    "        if ky>0:return True\n",
    "        if ky<0:return False\n",
    "        return kx>0\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    Bxh_new[ix,iy,iz]=Bxh[ix,iy,iz]; Byh_new[ix,iy,iz]=Byh[ix,iy,iz]; Bzh_new[ix,iy,iz]=Bzh[ix,iy,iz]; continue\n",
    "                if not pos_half(ix,iy,iz): continue\n",
    "                k = np.array([kx,ky,kz], float); kn = np.linalg.norm(k)\n",
    "                if kn==0: continue\n",
    "                k_hat = k/kn\n",
    "                ref = np.array([0,0,1.0]) if abs(k_hat[2])<0.99 else np.array([1.0,0,0])\n",
    "                e1 = np.cross(ref, k_hat); e1 /= (np.linalg.norm(e1)+1e-15)\n",
    "                e2 = np.cross(k_hat, e1);   e2 /= (np.linalg.norm(e2)+1e-15)\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1, c2 = e1 @ Bk, e2 @ Bk\n",
    "                th = rng.uniform(0, 2*np.pi); ct, st = np.cos(th), np.sin(th)\n",
    "                Bkp = e1*(ct*c1 - st*c2) + e2*(st*c1 + ct*c2)\n",
    "                Bxh_new[ix,iy,iz]=Bkp[0]; Byh_new[ix,iy,iz]=Bkp[1]; Bzh_new[ix,iy,iz]=Bkp[2]\n",
    "                ixn,iyn,izn = (-ix)%Nx, (-iy)%Ny, (-iz)%Nz\n",
    "                Bxh_new[ixn,iyn,izn]=np.conjugate(Bkp[0]); Byh_new[ixn,iyn,izn]=np.conjugate(Bkp[1]); Bzh_new[ixn,iyn,izn]=np.conjugate(Bkp[2])\n",
    "    mask=(Bxh_new==0)&(Byh_new==0)&(Bzh_new==0)\n",
    "    Bxh_new[mask]=Bxh[mask]; Byh_new[mask]=Byh[mask]; Bzh_new[mask]=Bzh[mask]\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "\n",
    "# ---------- Load field & precompute ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir/\"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir/\"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field .npz found in {run_dir}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h_H = helicity_density(Bx, By, Bz, sp)\n",
    "print(f\"[orig] helicity_density={h_H:.3e}\")\n",
    "\n",
    "alpha = beltrami_alpha(Bx, By, Bz, sp)\n",
    "\n",
    "# ---------- Harvest + filter ----------\n",
    "TARGET_LOOPS   = 14\n",
    "DT_LIST        = (0.2, 0.3, 0.4)\n",
    "GRID_DIV       = 7\n",
    "STEPS          = 7000\n",
    "MIN_CLOSE      = 700\n",
    "CLOSE_TOL      = 1.0\n",
    "BELTRAMI_THR   = 0.6   # fraction of points with α>0.7 must exceed this\n",
    "print(f\"[params] TARGET_LOOPS={TARGET_LOOPS} GRID_DIV={GRID_DIV} BELTRAMI_THR={BELTRAMI_THR}\")\n",
    "\n",
    "loops = _find_closed_loops(Bx, By, Bz, TARGET=TARGET_LOOPS, grid_div=GRID_DIV,\n",
    "                           jitter=0.2, dt_list=DT_LIST, steps=STEPS,\n",
    "                           min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "box = np.array([Bx.shape[0]]*3, float)\n",
    "loops_coh = filter_loops_beltrami(loops, alpha, min_frac=BELTRAMI_THR)\n",
    "total_abs, linked_pairs, _ = total_linking_metric(loops_coh, box)\n",
    "print(f\"[orig] loops={len(loops)}  coherent={len(loops_coh)}  total|Lk|={total_abs:.0f}  linked_pairs={linked_pairs}\")\n",
    "\n",
    "# ---------- Nulls with same coherence gate ----------\n",
    "NNULL = 16\n",
    "rng = np.random.default_rng(777)\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, rng)\n",
    "    ar = beltrami_alpha(Bxr, Byr, Bzr, sp)\n",
    "    loops_r = _find_closed_loops(Bxr, Byr, Bzr, TARGET=min(len(loops), TARGET_LOOPS),\n",
    "                                 grid_div=GRID_DIV, jitter=0.2, dt_list=DT_LIST,\n",
    "                                 steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "    loops_r_coh = filter_loops_beltrami(loops_r, ar, min_frac=BELTRAMI_THR)\n",
    "    t_abs_r, nz_r, _ = total_linking_metric(loops_r_coh, box)\n",
    "    null_vals.append(t_abs_r)\n",
    "    if (r+1)%4==0:\n",
    "        print(f\"  null {r+1}/{NNULL}  loops={len(loops_r)} coh={len(loops_r_coh)} total|Lk|={t_abs_r:.0f}\")\n",
    "\n",
    "null_vals = np.array(null_vals, float)\n",
    "p_link = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "link_percentile = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "print(f\"[BeltramiLink] total|Lk|={total_abs:.0f}  null_median={np.median(null_vals):.1f}  p={p_link:.4f}  percentile={link_percentile:.3f}\")\n",
    "\n",
    "# ---------- Echo reuse ----------\n",
    "echo_csv = run_dir/\"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    band = (1.6, 1.8)\n",
    "    mask = (freqs>band[0]) & (freqs<band[1])\n",
    "    echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "else:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt); P = np.abs(np.fft.rfft(sig))**2 / len(sig)\n",
    "    band = (1.6, 1.8); echo_power = float((P[(freqs>band[0]) & (freqs<band[1])].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------- Final glyphness & save ----------\n",
    "MIN_LOOPS, REQUIRE_LINKED = 4, 1\n",
    "trusted = (len(loops_coh) >= MIN_LOOPS and linked_pairs >= REQUIRE_LINKED)\n",
    "\n",
    "wH, wL, wE = 0.25, 0.50, 0.25\n",
    "H_norm = float(min(1.0, abs(h_H)/(1e-2)))\n",
    "if trusted:\n",
    "    glyphness = float(wH*H_norm + wL*link_percentile + wE*echo_power)\n",
    "    label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_percentile>=0.90 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "else:\n",
    "    glyphness = float(0.5*H_norm + 0.5*echo_power)\n",
    "    label = \"INCONCLUSIVE (need coherent links)\"\n",
    "\n",
    "out = {\n",
    "    \"helicity_density\": h_H,\n",
    "    \"loops_total\": len(loops), \"loops_coherent\": len(loops_coh),\n",
    "    \"beltrami_filter\": {\"alpha_thresh\": 0.7, \"min_fraction\": BELTRAMI_THR},\n",
    "    \"linking\": {\"total_abs_Lk\": total_abs, \"linked_pairs\": linked_pairs},\n",
    "    \"nulls\": {\"NNULL\": NNULL, \"total_abs_Lk_nulls\": null_vals.tolist(), \"median\": float(np.median(null_vals)),\n",
    "              \"p_value_one_sided\": p_link, \"percentile\": link_percentile},\n",
    "    \"echo\": {\"power_norm\": echo_power, \"band\": list(band)},\n",
    "    \"score\": {\"glyphness\": glyphness, \"weights\": {\"H\":wH,\"Link%\":wL,\"Echo\":wE} if trusted else {\"H\":0.5,\"Echo\":0.5},\n",
    "              \"H_norm\": H_norm, \"link_percentile\": link_percentile if trusted else None, \"label\": label}\n",
    "}\n",
    "with open(run_dir/\"link_beltrami_v010.json\",\"w\") as f: json.dump(out, f, indent=2)\n",
    "with open(run_dir/\"link_beltrami_nulls_v010.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"total_abs_Lk_null\"])\n",
    "    for v in null_vals: wr.writerow([f\"{v:.6f}\"])\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f} (H={H_norm:.2f}, Link%={link_percentile:.2f}*, Echo={echo_power:.2f}) → {label}\")\n",
    "print(\"Saved →\", run_dir/\"link_beltrami_v010.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "71e6d68a-2ff9-43d8-bd9d-792b2bbb77e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] NVIDIA GeForce RTX 4070 • SMs=46 • mem=12.9 GB  • CuPy=13.6.0\n",
      "✅ GPU bootstrap loaded. Heavy ops are now cuFFT-accelerated when available.\n"
     ]
    }
   ],
   "source": [
    "# CNT GPU Bootstrap — RTX 4070 (CuPy/cuFFT hybrid)  vGPU-1.0\n",
    "# Overrides: _project_solenoidal, _vector_potential_from_B, helicity_density, spectral_rotation_null\n",
    "# Strategy: GPU for all spectral heavy steps; keep streamline/loop tracing on CPU.\n",
    "\n",
    "import sys, subprocess, importlib, math\n",
    "import numpy as np\n",
    "\n",
    "# --- 1) Bring CuPy online (CUDA 12.x wheel fits RTX 4070 drivers) ---\n",
    "try:\n",
    "    import cupy as cp\n",
    "except Exception:\n",
    "    print(\"[setup] Installing CuPy for CUDA 12.x…\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"cupy-cuda12x\"])\n",
    "    import cupy as cp\n",
    "\n",
    "try:\n",
    "    ndev = cp.cuda.runtime.getDeviceCount()\n",
    "    dev = cp.cuda.Device(0)\n",
    "    dev.use()\n",
    "    props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    name = props[\"name\"].decode() if isinstance(props[\"name\"], bytes) else props[\"name\"]\n",
    "    print(f\"[GPU] {name} • SMs={props['multiProcessorCount']} • mem={props['totalGlobalMem']/1e9:.1f} GB  • CuPy={cp.__version__}\")\n",
    "    HAS_GPU = True\n",
    "except Exception as e:\n",
    "    print(\"[GPU] No CUDA device or driver issue:\", e)\n",
    "    HAS_GPU = False\n",
    "\n",
    "# --- 2) Small helpers ---\n",
    "_DTYPE = np.float32  # use FP32 on GPU for speed; accurate enough for our stats\n",
    "\n",
    "def _ensure_cp(x):\n",
    "    return cp.asarray(x, dtype=_DTYPE)\n",
    "\n",
    "def _ensure_np(x):\n",
    "    return cp.asnumpy(x)\n",
    "\n",
    "# Build k-grids (GPU)\n",
    "def _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = cp.fft.fftfreq(Nx, d=Lx/Nx) * (2*cp.pi)\n",
    "    ky = cp.fft.fftfreq(Ny, d=Ly/Ny) * (2*cp.pi)\n",
    "    kz = cp.fft.fftfreq(Nz, d=Lz/Nz) * (2*cp.pi)\n",
    "    return cp.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "# --- 3) GPU overrides (fall back to CPU if needed) ---\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    \"\"\"\n",
    "    Project B onto the divergence-free subspace in Fourier domain (Coulomb gauge).\n",
    "    Accepts numpy, returns numpy; runs on GPU if available.\n",
    "    \"\"\"\n",
    "    if not HAS_GPU:\n",
    "        # CPU fallback (numpy FFT)\n",
    "        dx, dy, dz = spacings\n",
    "        Nx, Ny, Nz = Bx.shape\n",
    "        Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "        kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "        ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "        kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "        Bxh, Byh, Bzh = np.fft.fftn(Bx), np.fft.fftn(By), np.fft.fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "        Bxh = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "        return (np.fft.ifftn(Bxh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Byh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Bzh).real.astype(_DTYPE))\n",
    "    # GPU path\n",
    "    dx, dy, dz = spacings\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    Bxh = cp.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "    Byh = cp.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "    Bzh = cp.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    Brx = cp.fft.ifftn(Bxh).real.astype(_DTYPE)\n",
    "    Bry = cp.fft.ifftn(Byh).real.astype(_DTYPE)\n",
    "    Brz = cp.fft.ifftn(Bzh).real.astype(_DTYPE)\n",
    "    return _ensure_np(Brx), _ensure_np(Bry), _ensure_np(Brz)\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    \"\"\"\n",
    "    Solve ∇×A = B (Coulomb gauge) in Fourier domain. Accepts numpy; returns numpy. GPU-backed.\n",
    "    \"\"\"\n",
    "    if not HAS_GPU:\n",
    "        kx = np.fft.fftfreq(Bx.shape[0], d=Lx/Bx.shape[0]) * 2*np.pi\n",
    "        ky = np.fft.fftfreq(By.shape[1], d=Ly/By.shape[1]) * 2*np.pi\n",
    "        kz = np.fft.fftfreq(Bz.shape[2], d=Lz/Bz.shape[2]) * 2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "        Bxh, Byh, Bzh = np.fft.fftn(Bx), np.fft.fftn(By), np.fft.fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        i = 1j\n",
    "        cx = ky*Bzh - kz*Byh\n",
    "        cy = kz*Bxh - kx*Bzh\n",
    "        cz = kx*Byh - ky*Bxh\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "        return (np.fft.ifftn(Axh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Ayh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Azh).real.astype(_DTYPE))\n",
    "    # GPU path\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    kx, ky, kz = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    Axh = i * cp.where(k2!=0, cx/k2, 0.0)\n",
    "    Ayh = i * cp.where(k2!=0, cy/k2, 0.0)\n",
    "    Azh = i * cp.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = cp.fft.ifftn(Axh).real.astype(_DTYPE)\n",
    "    Ay = cp.fft.ifftn(Ayh).real.astype(_DTYPE)\n",
    "    Az = cp.fft.ifftn(Azh).real.astype(_DTYPE)\n",
    "    return _ensure_np(Ax), _ensure_np(Ay), _ensure_np(Az)\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    \"\"\"\n",
    "    H/V with A from ∇×A=B. Accepts numpy; returns float. GPU-backed.\n",
    "    \"\"\"\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = float((Ax*Bx + Ay*By + Az*Bz).sum() * dx*dy*dz)\n",
    "    V = Lx*Ly*Lz\n",
    "    return H / V\n",
    "\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    \"\"\"\n",
    "    Strong null: rotate B̂(k) within the plane ⟂k for half the spectrum,\n",
    "    mirror-conjugate to enforce Hermitian, then project to solenoidal.\n",
    "    Accepts numpy; returns numpy. GPU-backed & vectorized.\n",
    "    \"\"\"\n",
    "    dx, dy, dz = spacings\n",
    "    if not HAS_GPU:\n",
    "        # fall back to your earlier CPU spectral_rotation_null (if defined)\n",
    "        # (or keep phase-scramble as a last resort)\n",
    "        from numpy.fft import fftn, ifftn, fftfreq\n",
    "        Nx, Ny, Nz = Bx.shape\n",
    "        Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "        kxv, kyv, kzv = fftfreq(Nx, d=Lx/Nx)*2*np.pi, fftfreq(Ny, d=Ly/Ny)*2*np.pi, fftfreq(Nz, d=Lz/Nz)*2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "        Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        pos = (kz>0) | ((kz==0)&(ky>0)) | ((kz==0)&(ky==0)&(kx>0))\n",
    "        # Build orthonormal basis in ⟂k\n",
    "        kn = np.sqrt(k2)+1e-15\n",
    "        kxh, kyh, kzh = kx/kn, ky/kn, kz/kn\n",
    "        use_x = (np.abs(kxh) < 0.9)\n",
    "        ax = np.where(use_x, 1.0, 0.0); ay = np.where(use_x, 0.0, 1.0); az = 0.0\n",
    "        e1x = ay*kzh - az*kyh; e1y = az*kxh - ax*kzh; e1z = ax*kyh - ay*kxh\n",
    "        n1 = np.sqrt(e1x*e1x + e1y*e1y + e1z*e1z)+1e-15; e1x/=n1; e1y/=n1; e1z/=n1\n",
    "        e2x = kyh*e1z - kzh*e1y; e2y = kzh*e1x - kxh*e1z; e2z = kxh*e1y - kyh*e1x\n",
    "        c1 = e1x*Bxh + e1y*Byh + e1z*Bzh\n",
    "        c2 = e2x*Bxh + e2y*Byh + e2z*Bzh\n",
    "        theta = rng.uniform(0, 2*np.pi, size=Bxh.shape)\n",
    "        ct, st = np.cos(theta), np.sin(theta)\n",
    "        c1p = ct*c1 - st*c2\n",
    "        c2p = st*c1 + ct*c2\n",
    "        Bxh_rot = e1x*c1p + e2x*c2p\n",
    "        Byh_rot = e1y*c1p + e2y*c2p\n",
    "        Bzh_rot = e1z*c1p + e2z*c2p\n",
    "        # Build Hermitian array by pos + flipped conjugate\n",
    "        zero = (k2==0)\n",
    "        Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "        Bxh_new[pos] = Bxh_rot[pos]; Byh_new[pos] = Byh_rot[pos]; Bzh_new[pos] = Bzh_rot[pos]\n",
    "        Bxh_new += np.conj(Bxh_new[::-1, ::-1, ::-1])\n",
    "        Byh_new += np.conj(Byh_new[::-1, ::-1, ::-1])\n",
    "        Bzh_new += np.conj(Bzh_new[::-1, ::-1, ::-1])\n",
    "        Bxh_new[zero] = Bxh[zero]; Byh_new[zero] = Byh[zero]; Bzh_new[zero] = Bzh[zero]\n",
    "        Brx = np.fft.ifftn(Bxh_new).real.astype(_DTYPE)\n",
    "        Bry = np.fft.ifftn(Byh_new).real.astype(_DTYPE)\n",
    "        Brz = np.fft.ifftn(Bzh_new).real.astype(_DTYPE)\n",
    "        return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "    # GPU path\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kxv*kxv + kyv*kyv + kzv*kzv\n",
    "    pos = (kzv>0) | ((kzv==0)&(kyv>0)) | ((kzv==0)&(kyv==0)&(kxv>0))\n",
    "    # Basis in ⟂k (vectorized)\n",
    "    kn = cp.sqrt(k2) + 1e-15\n",
    "    kxh, kyh, kzh = kxv/kn, kyv/kn, kzv/kn\n",
    "    use_x = (cp.abs(kxh) < 0.9)\n",
    "    ax = cp.where(use_x, 1.0, 0.0); ay = cp.where(use_x, 0.0, 1.0); az = cp.zeros_like(kxh)\n",
    "    e1x = ay*kzh - az*kyh; e1y = az*kxh - ax*kzh; e1z = ax*kyh - ay*kxh\n",
    "    n1 = cp.sqrt(e1x*e1x + e1y*e1y + e1z*e1z) + 1e-15\n",
    "    e1x/=n1; e1y/=n1; e1z/=n1\n",
    "    e2x = kyh*e1z - kzh*e1y; e2y = kzh*e1x - kxh*e1z; e2z = kxh*e1y - kyh*e1x\n",
    "    # Project & rotate\n",
    "    c1 = e1x*Bxh + e1y*Byh + e1z*Bzh\n",
    "    c2 = e2x*Bxh + e2y*Byh + e2z*Bzh\n",
    "    theta = cp.zeros_like(k2, dtype=_DTYPE)\n",
    "    # Only give random angles on positive half\n",
    "    theta[pos] = (cp.random.random(pos.sum(), dtype=_DTYPE) * (2*cp.pi)).astype(_DTYPE)\n",
    "    ct, st = cp.cos(theta), cp.sin(theta)\n",
    "    c1p = ct*c1 - st*c2\n",
    "    c2p = st*c1 + ct*c2\n",
    "    Bxh_rot = e1x*c1p + e2x*c2p\n",
    "    Byh_rot = e1y*c1p + e2y*c2p\n",
    "    Bzh_rot = e1z*c1p + e2z*c2p\n",
    "    # Compose Hermitian spectrum: rotated pos + conj of flipped\n",
    "    Bxh_new = cp.where(pos, Bxh_rot, 0.0+0.0j)\n",
    "    Byh_new = cp.where(pos, Byh_rot, 0.0+0.0j)\n",
    "    Bzh_new = cp.where(pos, Bzh_rot, 0.0+0.0j)\n",
    "    Bxh_new = Bxh_new + cp.conj(Bxh_new[::-1, ::-1, ::-1])\n",
    "    Byh_new = Byh_new + cp.conj(Byh_new[::-1, ::-1, ::-1])\n",
    "    Bzh_new = Bzh_new + cp.conj(Bzh_new[::-1, ::-1, ::-1])\n",
    "    # Keep self-conjugate planes from original (DC/Nyquist)\n",
    "    zero = (k2==0)\n",
    "    Bxh_new[zero] = Bxh[zero]; Byh_new[zero] = Byh[zero]; Bzh_new[zero] = Bzh[zero]\n",
    "    # Back to real space + projection\n",
    "    Brx = cp.fft.ifftn(Bxh_new).real.astype(_DTYPE)\n",
    "    Bry = cp.fft.ifftn(Byh_new).real.astype(_DTYPE)\n",
    "    Brz = cp.fft.ifftn(Bzh_new).real.astype(_DTYPE)\n",
    "    Brx, Bry, Brz = _project_solenoidal(_ensure_np(Brx), _ensure_np(Bry), _ensure_np(Brz), spacings)\n",
    "    return Brx, Bry, Brz\n",
    "\n",
    "print(\"✅ GPU bootstrap loaded. Heavy ops are now cuFFT-accelerated when available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d51fe37f-4d2a-4134-bea3-54244e2e3557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.10 (Beltrami-Linked Cert)\n",
      "Loaded field → E:\\CNT\\artifacts\\cnt_physical_glyph_hunt\\20251106-230456Z\\best_field.npz\n",
      "[orig] helicity_density=9.769e-02\n",
      "[params] TARGET_LOOPS=14 GRID_DIV=7 BELTRAMI_THR=0.6\n",
      "[orig] loops=14  coherent=0  total|Lk|=0  linked_pairs=0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 282\u001b[39m\n\u001b[32m    280\u001b[39m Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, rng)\n\u001b[32m    281\u001b[39m ar = beltrami_alpha(Bxr, Byr, Bzr, sp)\n\u001b[32m--> \u001b[39m\u001b[32m282\u001b[39m loops_r = \u001b[43m_find_closed_loops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBxr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mByr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBzr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mloops\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mTARGET_LOOPS\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m                             \u001b[49m\u001b[43mgrid_div\u001b[49m\u001b[43m=\u001b[49m\u001b[43mGRID_DIV\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mjitter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt_list\u001b[49m\u001b[43m=\u001b[49m\u001b[43mDT_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m                             \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43mSTEPS\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m=\u001b[49m\u001b[43mMIN_CLOSE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCLOSE_TOL\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    285\u001b[39m loops_r_coh = filter_loops_beltrami(loops_r, ar, min_frac=BELTRAMI_THR)\n\u001b[32m    286\u001b[39m t_abs_r, nz_r, _ = total_linking_metric(loops_r_coh, box)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 139\u001b[39m, in \u001b[36m_find_closed_loops\u001b[39m\u001b[34m(Bx, By, Bz, TARGET, grid_div, jitter, dt_list, steps, min_close, close_tol)\u001b[39m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loops) >= TARGET: \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    138\u001b[39m seed = (np.array(s) + rng.normal(\u001b[32m0\u001b[39m, jitter, \u001b[32m3\u001b[39m)) % N\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m L = \u001b[43m_trace_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m=\u001b[49m\u001b[43msign\u001b[49m\u001b[43m*\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msteps\u001b[49m\u001b[43m=\u001b[49m\u001b[43msteps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_close\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclose_tol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    140\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m L \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    141\u001b[39m c = np.mean(L[:-\u001b[32m1\u001b[39m], axis=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 119\u001b[39m, in \u001b[36m_trace_loop\u001b[39m\u001b[34m(seed, Bx, By, Bz, dt, steps, min_close, close_tol)\u001b[39m\n\u001b[32m    117\u001b[39m pts = [pos.copy()]\n\u001b[32m    118\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m1\u001b[39m, steps+\u001b[32m1\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m119\u001b[39m     pos = \u001b[43m_rk4_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t % \u001b[32m2\u001b[39m == \u001b[32m0\u001b[39m: pts.append(pos.copy())\n\u001b[32m    121\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m t > min_close:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 106\u001b[39m, in \u001b[36m_rk4_step\u001b[39m\u001b[34m(pos, dt, Bx, By, Bz)\u001b[39m\n\u001b[32m    104\u001b[39m k1 = _B_dir(Bx,By,Bz,pos)\n\u001b[32m    105\u001b[39m k2 = _B_dir(Bx,By,Bz,wrap(pos + \u001b[32m0.5\u001b[39m*dt*k1))\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m k3 = \u001b[43m_B_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43mwrap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m*\u001b[49m\u001b[43mdt\u001b[49m\u001b[43m*\u001b[49m\u001b[43mk2\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n\u001b[32m    108\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m wrap(pos + (dt/\u001b[32m6.0\u001b[39m)*(k1 + \u001b[32m2\u001b[39m*k2 + \u001b[32m2\u001b[39m*k3 + k4))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 99\u001b[39m, in \u001b[36m_B_dir\u001b[39m\u001b[34m(Bx, By, Bz, pos)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_B_dir\u001b[39m(Bx, By, Bz, pos):\n\u001b[32m     96\u001b[39m     v = np.array([_tri_interp_periodic(Bx,pos),\n\u001b[32m     97\u001b[39m                   _tri_interp_periodic(By,pos),\n\u001b[32m     98\u001b[39m                   _tri_interp_periodic(Bz,pos)], \u001b[38;5;28mfloat\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m99\u001b[39m     n = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinalg\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m)\u001b[49m + \u001b[32m1e-12\u001b[39m\n\u001b[32m    100\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m v / n\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\linalg\\_linalg.py:2792\u001b[39m, in \u001b[36mnorm\u001b[39m\u001b[34m(x, ord, axis, keepdims)\u001b[39m\n\u001b[32m   2790\u001b[39m     sqnorm = x_real.dot(x_real) + x_imag.dot(x_imag)\n\u001b[32m   2791\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2792\u001b[39m     sqnorm = \u001b[43mx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2793\u001b[39m ret = sqrt(sqnorm)\n\u001b[32m   2794\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m keepdims:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — Single Cell v0.10 (Beltrami-Linked Cert)\n",
    "# Filters loop-for-loop by local Beltrami coherence to suppress spurious linking in nulls.\n",
    "# Saves: link_beltrami_v010.json, link_beltrami_nulls_v010.csv next to your latest run.\n",
    "\n",
    "import numpy as np, os, json, csv\n",
    "from numpy.fft import fftn, ifftn\n",
    "from pathlib import Path\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.10 (Beltrami-Linked Cert)\")\n",
    "\n",
    "# ---------- FFT + projection ----------\n",
    "def _fftvec(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "    ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "    kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "    return kx, ky, kz\n",
    "\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    k2  = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Bxh = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    return np.real(ifftn(Bxh)), np.real(ifftn(Byh)), np.real(ifftn(Bzh))\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "    i = 1j\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    with np.errstate(divide='ignore', invalid='ignore'):\n",
    "        Axh = i*np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i*np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i*np.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax, Ay, Az = np.real(ifftn(Axh)), np.real(ifftn(Ayh)), np.real(ifftn(Azh))\n",
    "    H = np.sum(Ax*Bx + Ay*By + Az*Bz)*dx*dy*dz\n",
    "    V = (dx*Nx)*(dy*Ny)*(dz*Nz)\n",
    "    return float(H/V)\n",
    "\n",
    "# ---------- Derivatives / curl / Beltrami ----------\n",
    "def _grad(f, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    return (np.gradient(f, dx, axis=0),\n",
    "            np.gradient(f, dy, axis=1),\n",
    "            np.gradient(f, dz, axis=2))\n",
    "\n",
    "def curl_real(Fx, Fy, Fz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(Fy, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Fz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Fz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Fx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Fx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(Fy, dx, axis=0)\n",
    "    return (dFz_dy - dFy_dz, dFx_dz - dFz_dx, dFy_dx - dFx_dy)\n",
    "\n",
    "def beltrami_alpha(Bx, By, Bz, spacings):\n",
    "    Cx, Cy, Cz = curl_real(Bx, By, Bz, spacings)\n",
    "    Bmag = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    Cmag = np.sqrt(Cx*Cx + Cy*Cy + Cz*Cz) + 1e-12\n",
    "    cos = (Bx*Cx + By*Cy + Bz*Cz) / (Bmag*Cmag)\n",
    "    return np.clip(cos, -1.0, 1.0)  # α(x) = cos angle(B, curl B)\n",
    "\n",
    "# ---------- Interp + streamline loops ----------\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - np.floor(x); ty = y - np.floor(y); tz = z - np.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], float)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]; wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt=0.3, steps=6000, min_close=600, close_tol=0.9):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    pos = np.array(seed, float); start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0: pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            d = np.linalg.norm(_min_image_delta(pos, start, box))\n",
    "            if d < close_tol:\n",
    "                pts.append(start.copy())\n",
    "                return np.asarray(pts)\n",
    "    return None\n",
    "\n",
    "def _find_closed_loops(Bx, By, Bz, TARGET=12, grid_div=6, jitter=0.2, dt_list=(0.2,0.3,0.4), steps=6000, min_close=600, close_tol=0.9):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], float)\n",
    "    coords = np.linspace(0, N, grid_div, endpoint=False) + N/(2*grid_div)\n",
    "    seeds = [[xi,yi,zi] for xi in coords for yi in coords for zi in coords]\n",
    "    rng = np.random.default_rng(101); rng.shuffle(seeds)\n",
    "    loops, centers = [], []\n",
    "    for sign in (1.0, -1.0):\n",
    "        for dt in dt_list:\n",
    "            for s in seeds:\n",
    "                if len(loops) >= TARGET: break\n",
    "                seed = (np.array(s) + rng.normal(0, jitter, 3)) % N\n",
    "                L = _trace_loop(seed, Bx, By, Bz, dt=sign*dt, steps=steps, min_close=min_close, close_tol=close_tol)\n",
    "                if L is None: continue\n",
    "                c = np.mean(L[:-1], axis=0)\n",
    "                if centers:\n",
    "                    dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "                    if np.min(dd) < 1.5:  # avoid near-duplicates\n",
    "                        continue\n",
    "                loops.append(L); centers.append(c)\n",
    "            if len(loops) >= TARGET: break\n",
    "        if len(loops) >= TARGET: break\n",
    "    return loops\n",
    "\n",
    "# ---------- Loop Beltrami coherence ----------\n",
    "def loop_beltrami_fraction(L, alpha_field):\n",
    "    N = alpha_field.shape[0]\n",
    "    vals = []\n",
    "    for p in L[:-1]:\n",
    "        vals.append(_tri_interp_periodic(alpha_field, p))\n",
    "    vals = np.array(vals, float)\n",
    "    return float(np.mean(vals > 0.7))  # fraction of samples where α>0.7\n",
    "\n",
    "def filter_loops_beltrami(loops, alpha_field, min_frac=0.6):\n",
    "    keep = []\n",
    "    for L in loops:\n",
    "        f = loop_beltrami_fraction(L, alpha_field)\n",
    "        if f >= min_frac:\n",
    "            keep.append(L)\n",
    "    return keep\n",
    "\n",
    "# ---------- Gauss linking ----------\n",
    "def _gauss_link(A, B, box):\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:] + A[:-1]);  b_mid = 0.5*(B[1:] + B[:-1])\n",
    "    da = A[1:] - A[:-1];           db = B[1:] - B[:-1]\n",
    "    Da = da[:,None,:]; Db = db[None,:,:]\n",
    "    Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "    dR = _min_image_delta(Ra, Rb, box)\n",
    "    cross = np.cross(Da, Db)\n",
    "    num = np.einsum('ijk,ijk->ij', cross, dR)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    return float(np.sum(num/denom)/(4*np.pi))\n",
    "\n",
    "def total_linking_metric(loops, box):\n",
    "    if len(loops) < 2: return 0.0, 0, []\n",
    "    Lks = []\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            Lks.append(_gauss_link(loops[i], loops[j], box))\n",
    "    Lks = np.array(Lks, float)\n",
    "    Lk_int = np.rint(Lks)\n",
    "    total_abs = float(np.sum(np.abs(Lk_int)))\n",
    "    nonzero = int(np.sum(np.abs(Lk_int) >= 1))\n",
    "    return total_abs, nonzero, Lks.tolist()\n",
    "\n",
    "# ---------- Spectral-rotation nulls ----------\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "    Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "    def pos_half(ix, iy, iz):\n",
    "        kz = kzv[iz]; ky = kyv[iy]; kx = kxv[ix]\n",
    "        if kz>0:return True\n",
    "        if kz<0:return False\n",
    "        if ky>0:return True\n",
    "        if ky<0:return False\n",
    "        return kx>0\n",
    "    for ix in range(Nx):\n",
    "        kx = kxv[ix]\n",
    "        for iy in range(Ny):\n",
    "            ky = kyv[iy]\n",
    "            for iz in range(Nz):\n",
    "                kz = kzv[iz]\n",
    "                if kx==0 and ky==0 and kz==0:\n",
    "                    Bxh_new[ix,iy,iz]=Bxh[ix,iy,iz]; Byh_new[ix,iy,iz]=Byh[ix,iy,iz]; Bzh_new[ix,iy,iz]=Bzh[ix,iy,iz]; continue\n",
    "                if not pos_half(ix,iy,iz): continue\n",
    "                k = np.array([kx,ky,kz], float); kn = np.linalg.norm(k)\n",
    "                if kn==0: continue\n",
    "                k_hat = k/kn\n",
    "                ref = np.array([0,0,1.0]) if abs(k_hat[2])<0.99 else np.array([1.0,0,0])\n",
    "                e1 = np.cross(ref, k_hat); e1 /= (np.linalg.norm(e1)+1e-15)\n",
    "                e2 = np.cross(k_hat, e1);   e2 /= (np.linalg.norm(e2)+1e-15)\n",
    "                Bk = np.array([Bxh[ix,iy,iz], Byh[ix,iy,iz], Bzh[ix,iy,iz]])\n",
    "                c1, c2 = e1 @ Bk, e2 @ Bk\n",
    "                th = rng.uniform(0, 2*np.pi); ct, st = np.cos(th), np.sin(th)\n",
    "                Bkp = e1*(ct*c1 - st*c2) + e2*(st*c1 + ct*c2)\n",
    "                Bxh_new[ix,iy,iz]=Bkp[0]; Byh_new[ix,iy,iz]=Bkp[1]; Bzh_new[ix,iy,iz]=Bkp[2]\n",
    "                ixn,iyn,izn = (-ix)%Nx, (-iy)%Ny, (-iz)%Nz\n",
    "                Bxh_new[ixn,iyn,izn]=np.conjugate(Bkp[0]); Byh_new[ixn,iyn,izn]=np.conjugate(Bkp[1]); Bzh_new[ixn,iyn,izn]=np.conjugate(Bkp[2])\n",
    "    mask=(Bxh_new==0)&(Byh_new==0)&(Bzh_new==0)\n",
    "    Bxh_new[mask]=Bxh[mask]; Byh_new[mask]=Byh[mask]; Bzh_new[mask]=Bzh[mask]\n",
    "    Brx = np.real(ifftn(Bxh_new)); Bry = np.real(ifftn(Byh_new)); Brz = np.real(ifftn(Bzh_new))\n",
    "    return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "\n",
    "# ---------- Load field & precompute ----------\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "best_path = run_dir/\"best_field.npz\"\n",
    "if not best_path.exists():\n",
    "    best_path = run_dir/\"field_small.npz\"\n",
    "assert best_path.exists(), f\"No field .npz found in {run_dir}\"\n",
    "print(\"Loaded field →\", best_path)\n",
    "\n",
    "d = np.load(best_path)\n",
    "Bx, By, Bz = d[\"Bx\"], d[\"By\"], d[\"Bz\"]\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)\n",
    "h_H = helicity_density(Bx, By, Bz, sp)\n",
    "print(f\"[orig] helicity_density={h_H:.3e}\")\n",
    "\n",
    "alpha = beltrami_alpha(Bx, By, Bz, sp)\n",
    "\n",
    "# ---------- Harvest + filter ----------\n",
    "TARGET_LOOPS   = 14\n",
    "DT_LIST        = (0.2, 0.3, 0.4)\n",
    "GRID_DIV       = 7\n",
    "STEPS          = 7000\n",
    "MIN_CLOSE      = 700\n",
    "CLOSE_TOL      = 1.0\n",
    "BELTRAMI_THR   = 0.6   # fraction of points with α>0.7 must exceed this\n",
    "print(f\"[params] TARGET_LOOPS={TARGET_LOOPS} GRID_DIV={GRID_DIV} BELTRAMI_THR={BELTRAMI_THR}\")\n",
    "\n",
    "loops = _find_closed_loops(Bx, By, Bz, TARGET=TARGET_LOOPS, grid_div=GRID_DIV,\n",
    "                           jitter=0.2, dt_list=DT_LIST, steps=STEPS,\n",
    "                           min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "box = np.array([Bx.shape[0]]*3, float)\n",
    "loops_coh = filter_loops_beltrami(loops, alpha, min_frac=BELTRAMI_THR)\n",
    "total_abs, linked_pairs, _ = total_linking_metric(loops_coh, box)\n",
    "print(f\"[orig] loops={len(loops)}  coherent={len(loops_coh)}  total|Lk|={total_abs:.0f}  linked_pairs={linked_pairs}\")\n",
    "\n",
    "# ---------- Nulls with same coherence gate ----------\n",
    "NNULL = 16\n",
    "rng = np.random.default_rng(777)\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, rng)\n",
    "    ar = beltrami_alpha(Bxr, Byr, Bzr, sp)\n",
    "    loops_r = _find_closed_loops(Bxr, Byr, Bzr, TARGET=min(len(loops), TARGET_LOOPS),\n",
    "                                 grid_div=GRID_DIV, jitter=0.2, dt_list=DT_LIST,\n",
    "                                 steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "    loops_r_coh = filter_loops_beltrami(loops_r, ar, min_frac=BELTRAMI_THR)\n",
    "    t_abs_r, nz_r, _ = total_linking_metric(loops_r_coh, box)\n",
    "    null_vals.append(t_abs_r)\n",
    "    if (r+1)%4==0:\n",
    "        print(f\"  null {r+1}/{NNULL}  loops={len(loops_r)} coh={len(loops_r_coh)} total|Lk|={t_abs_r:.0f}\")\n",
    "\n",
    "null_vals = np.array(null_vals, float)\n",
    "p_link = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "link_percentile = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "print(f\"[BeltramiLink] total|Lk|={total_abs:.0f}  null_median={np.median(null_vals):.1f}  p={p_link:.4f}  percentile={link_percentile:.3f}\")\n",
    "\n",
    "# ---------- Echo reuse ----------\n",
    "echo_csv = run_dir/\"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    band = (1.6, 1.8)\n",
    "    mask = (freqs>band[0]) & (freqs<band[1])\n",
    "    echo_power = float((P[mask].sum()) / (P.sum()+1e-12))\n",
    "else:\n",
    "    t = np.linspace(0, 10, 4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t) * np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt); P = np.abs(np.fft.rfft(sig))**2 / len(sig)\n",
    "    band = (1.6, 1.8); echo_power = float((P[(freqs>band[0]) & (freqs<band[1])].sum()) / (P.sum()+1e-12))\n",
    "\n",
    "# ---------- Final glyphness & save ----------\n",
    "MIN_LOOPS, REQUIRE_LINKED = 4, 1\n",
    "trusted = (len(loops_coh) >= MIN_LOOPS and linked_pairs >= REQUIRE_LINKED)\n",
    "\n",
    "wH, wL, wE = 0.25, 0.50, 0.25\n",
    "H_norm = float(min(1.0, abs(h_H)/(1e-2)))\n",
    "if trusted:\n",
    "    glyphness = float(wH*H_norm + wL*link_percentile + wE*echo_power)\n",
    "    label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_percentile>=0.90 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "else:\n",
    "    glyphness = float(0.5*H_norm + 0.5*echo_power)\n",
    "    label = \"INCONCLUSIVE (need coherent links)\"\n",
    "\n",
    "out = {\n",
    "    \"helicity_density\": h_H,\n",
    "    \"loops_total\": len(loops), \"loops_coherent\": len(loops_coh),\n",
    "    \"beltrami_filter\": {\"alpha_thresh\": 0.7, \"min_fraction\": BELTRAMI_THR},\n",
    "    \"linking\": {\"total_abs_Lk\": total_abs, \"linked_pairs\": linked_pairs},\n",
    "    \"nulls\": {\"NNULL\": NNULL, \"total_abs_Lk_nulls\": null_vals.tolist(), \"median\": float(np.median(null_vals)),\n",
    "              \"p_value_one_sided\": p_link, \"percentile\": link_percentile},\n",
    "    \"echo\": {\"power_norm\": echo_power, \"band\": list(band)},\n",
    "    \"score\": {\"glyphness\": glyphness, \"weights\": {\"H\":wH,\"Link%\":wL,\"Echo\":wE} if trusted else {\"H\":0.5,\"Echo\":0.5},\n",
    "              \"H_norm\": H_norm, \"link_percentile\": link_percentile if trusted else None, \"label\": label}\n",
    "}\n",
    "with open(run_dir/\"link_beltrami_v010.json\",\"w\") as f: json.dump(out, f, indent=2)\n",
    "with open(run_dir/\"link_beltrami_nulls_v010.csv\",\"w\", newline=\"\") as f:\n",
    "    wr = csv.writer(f); wr.writerow([\"total_abs_Lk_null\"])\n",
    "    for v in null_vals: wr.writerow([f\"{v:.6f}\"])\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f} (H={H_norm:.2f}, Link%={link_percentile:.2f}*, Echo={echo_power:.2f}) → {label}\")\n",
    "print(\"Saved →\", run_dir/\"link_beltrami_v010.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1deec6c-4c80-4863-aaf4-8cd77b95bb46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NumPy FFT (CPU): 1.235 s\n",
      "CuPy FFT (GPU): 2.025 s\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, cupy as cp, time\n",
    "x = np.random.rand(256,256,256).astype(np.float32)\n",
    "t=time.time(); np.fft.fftn(x); print(\"NumPy FFT (CPU):\", round(time.time()-t,3),\"s\")\n",
    "xc=cp.asarray(x); cp.cuda.Stream.null.synchronize()\n",
    "t=time.time(); cp.fft.fftn(xc); cp.cuda.Stream.null.synchronize()\n",
    "print(\"CuPy FFT (GPU):\", round(time.time()-t,3),\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "919905c1-ba4b-4100-a887-e2303a900501",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5x cuFFT (GPU resident): 0.106 s\n"
     ]
    }
   ],
   "source": [
    "import cupy as cp, time\n",
    "x = cp.random.rand(512,512,512, dtype=cp.float32)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "# warm-up\n",
    "cp.fft.fftn(x); cp.cuda.Stream.null.synchronize()\n",
    "\n",
    "t=time.time()\n",
    "for _ in range(5):\n",
    "    y = cp.fft.fftn(x)\n",
    "cp.cuda.Stream.null.synchronize()\n",
    "print(\"5x cuFFT (GPU resident):\", round(time.time()-t,3),\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a01edc9-4f9f-4e26-b9e7-c09b38bc51e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Physical Glyph Hunt — v0.10-HYBRID-PAR\n",
      "[orig] helicity_density=9.769e-02  (proj+H 0.23s)\n",
      "[par] process executor with 19 workers…\n"
     ]
    },
    {
     "ename": "BrokenProcessPool",
     "evalue": "A process in the process pool was terminated abruptly while the future was running or pending.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mBrokenProcessPool\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 203\u001b[39m\n\u001b[32m    200\u001b[39m futs = [ex.submit(_find_loops_chunk, Bx, By, Bz, chunk, DT_LIST, STEPS, MIN_CLOSE, CLOSE_TOL)\n\u001b[32m    201\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m chunkify(seeds, workers)]\n\u001b[32m    202\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m fut \u001b[38;5;129;01min\u001b[39;00m as_completed(futs):\n\u001b[32m--> \u001b[39m\u001b[32m203\u001b[39m     loops_all.extend(\u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m    204\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(loops_all) >= wanted:\n\u001b[32m    205\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mBrokenProcessPool\u001b[39m: A process in the process pool was terminated abruptly while the future was running or pending."
     ]
    }
   ],
   "source": [
    "# CNT Physical Glyph Hunt — v0.10-HYBRID-PAR (GPU + CPU parallel loop tracing)\n",
    "# - FFT/null work stays on GPU via your bootstrap (_project_solenoidal, helicity_density, spectral_rotation_null)\n",
    "# - Field-line tracing (RK4) parallelized across CPU cores with ProcessPoolExecutor\n",
    "# - FAST scout defaults; adjust knobs at the top as you like\n",
    "\n",
    "import os, time, math, numpy as np\n",
    "from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "# ==== TUNABLES (FAST SCOUT) ====\n",
    "EXECUTOR_KIND   = \"process\"     # \"process\" (faster on Windows) or \"thread\"\n",
    "MAX_WORKERS     = max(1, os.cpu_count() - 1)\n",
    "TARGET_LOOPS    = 8             # total loops to harvest\n",
    "GRID_DIV        = 5             # seeding grid\n",
    "DT_LIST         = (0.3,)        # integration step sizes to try\n",
    "STEPS           = 3500          # max steps\n",
    "MIN_CLOSE       = 450           # don't test closure until after this many steps\n",
    "CLOSE_TOL       = 1.1           # closure distance in index space\n",
    "COH_ALPHA      = 0.6            # alpha threshold (cos∠(B, curl B)) for coherence\n",
    "COH_FRAC_REQ   = 0.50           # fraction of loop points above COH_ALPHA\n",
    "NNULL           = 8             # nulls for fast scout; bump for certify runs\n",
    "DOWNSAMPLE_LK   = 2             # downsample loop vertices during Gauss-linking\n",
    "\n",
    "# ==== REQUIRED GPU-HOOKED FUNCTIONS (from your bootstrap) ====\n",
    "try:\n",
    "    _project_solenoidal\n",
    "    helicity_density\n",
    "    spectral_rotation_null\n",
    "except NameError as e:\n",
    "    raise RuntimeError(\"Run the GPU bootstrap cell first so these are defined: \"\n",
    "                       \"_project_solenoidal, helicity_density, spectral_rotation_null\") from e\n",
    "\n",
    "# ==== Lightweight CPU helpers ====\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - math.floor(x); ty = y - math.floor(y); tz = z - math.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], dtype=np.float32)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]\n",
    "    wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop_single(seed, Bx, By, Bz, dt=0.3, steps=3500, min_close=450, close_tol=1.1):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], dtype=np.float32)\n",
    "    pos = np.array(seed, dtype=np.float32)\n",
    "    start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0:\n",
    "            pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            d = np.linalg.norm(_min_image_delta(pos, start, box))\n",
    "            if d < close_tol:\n",
    "                pts.append(start.copy())\n",
    "                return np.asarray(pts, dtype=np.float32)\n",
    "    return None\n",
    "\n",
    "def _find_loops_chunk(Bx, By, Bz, seeds, dt_list, steps, min_close, close_tol):\n",
    "    \"\"\"Trace loops for a chunk of seeds; return unique loops (by center).\"\"\"\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], dtype=np.float32)\n",
    "    loops, centers = [], []\n",
    "    for sign in (1.0, -1.0):\n",
    "        for dt in dt_list:\n",
    "            for s in seeds:\n",
    "                L = _trace_loop_single(s, Bx, By, Bz, dt=sign*dt, steps=steps,\n",
    "                                       min_close=min_close, close_tol=close_tol)\n",
    "                if L is None: continue\n",
    "                c = np.mean(L[:-1], axis=0)\n",
    "                if centers:\n",
    "                    dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "                    if np.min(dd) < 1.3:\n",
    "                        continue\n",
    "                loops.append(L); centers.append(c)\n",
    "    return loops\n",
    "\n",
    "def _gauss_link(A, B, box):\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:] + A[:-1]);  b_mid = 0.5*(B[1:] + B[:-1])\n",
    "    da = A[1:] - A[:-1];           db = B[1:] - B[:-1]\n",
    "    Da = da[:,None,:]; Db = db[None,:,:]\n",
    "    Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "    dR = _min_image_delta(Ra, Rb, box)\n",
    "    cross = np.cross(Da, Db)\n",
    "    num = np.einsum('ijk,ijk->ij', cross, dR)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    return float(np.sum(num/denom)/(4*np.pi))\n",
    "\n",
    "def linking_score(loops, downsample=2):\n",
    "    if len(loops) < 2:\n",
    "        return 0.0, 0\n",
    "    box = np.array([loops[0].shape[1] if loops else 0]*3, dtype=np.float32)  # not used; we re-create below\n",
    "    total = 0.0; linked = 0\n",
    "    Nbox = None\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            A = loops[i][::downsample]; B = loops[j][::downsample]\n",
    "            # box from array size\n",
    "            Nbox = np.array([A.shape[0] if False else loops[i].shape[0]]*3, dtype=np.float32)\n",
    "            lk = _gauss_link(A, B, Nbox)\n",
    "            if abs(np.rint(lk)) >= 1:\n",
    "                linked += 1\n",
    "            total += abs(np.rint(lk))\n",
    "    return float(total), int(linked)\n",
    "\n",
    "def beltrami_alpha(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(By, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Bz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Bz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Bx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Bx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(By, dx, axis=0)\n",
    "    Cx = dFz_dy - dFy_dz\n",
    "    Cy = dFx_dz - dFz_dx\n",
    "    Cz = dFy_dx - dFx_dy\n",
    "    Bm = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    Cm = np.sqrt(Cx*Cx + Cy*Cy + Cz*Cz) + 1e-12\n",
    "    return np.clip((Bx*Cx + By*Cy + Bz*Cz)/(Bm*Cm), -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def loop_coherence_fraction(loop, alpha_field, thr=0.6):\n",
    "    vals = [_tri_interp_periodic(alpha_field, p) for p in loop[:-1]]\n",
    "    vals = np.array(vals, dtype=np.float32)\n",
    "    return float((vals > thr).mean())\n",
    "\n",
    "# ==== Load field from your latest run (GPU steps stay in the hooks) ====\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "npz_path = run_dir/\"best_field.npz\"\n",
    "if not npz_path.exists():\n",
    "    npz_path = run_dir/\"field_small.npz\"\n",
    "d = np.load(npz_path)\n",
    "Bx, By, Bz = (d[\"Bx\"].astype(np.float32), d[\"By\"].astype(np.float32), d[\"Bz\"].astype(np.float32))\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "print(\"CNT Physical Glyph Hunt — v0.10-HYBRID-PAR\")\n",
    "t0 = time.perf_counter()\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)          # GPU\n",
    "h_H = helicity_density(Bx, By, Bz, sp)                    # GPU\n",
    "t1 = time.perf_counter()\n",
    "print(f\"[orig] helicity_density={h_H:.3e}  (proj+H {t1-t0:.2f}s)\")\n",
    "\n",
    "# Beltrami alpha (CPU) — cheap compared to loop tracing\n",
    "alpha = beltrami_alpha(Bx, By, Bz, sp)\n",
    "\n",
    "# ==== Build seeds ====\n",
    "N = Bx.shape[0]\n",
    "coords = np.linspace(0, N, GRID_DIV, endpoint=False) + N/(2*GRID_DIV)\n",
    "seeds = np.array([[xi,yi,zi] for xi in coords for yi in coords for zi in coords], dtype=np.float32)\n",
    "rng = np.random.default_rng(21)\n",
    "rng.shuffle(seeds)\n",
    "seeds = seeds + rng.normal(0, 0.15, size=seeds.shape)\n",
    "seeds %= N\n",
    "seeds = list(map(tuple, seeds.tolist()))\n",
    "\n",
    "# ==== Parallel harvest ====\n",
    "def chunkify(lst, n):\n",
    "    k = max(1, len(lst)//n)\n",
    "    for i in range(0, len(lst), k):\n",
    "        yield lst[i:i+k]\n",
    "\n",
    "wanted = TARGET_LOOPS\n",
    "loops_all = []\n",
    "workers = min(MAX_WORKERS, max(1, len(seeds)//4))\n",
    "Exec = ProcessPoolExecutor if EXECUTOR_KIND==\"process\" else ThreadPoolExecutor\n",
    "print(f\"[par] {EXECUTOR_KIND} executor with {workers} workers…\")\n",
    "start = time.perf_counter()\n",
    "with Exec(max_workers=workers) as ex:\n",
    "    futs = [ex.submit(_find_loops_chunk, Bx, By, Bz, chunk, DT_LIST, STEPS, MIN_CLOSE, CLOSE_TOL)\n",
    "            for chunk in chunkify(seeds, workers)]\n",
    "    for fut in as_completed(futs):\n",
    "        loops_all.extend(fut.result())\n",
    "        if len(loops_all) >= wanted:\n",
    "            break\n",
    "\n",
    "# Deduplicate by center (again)\n",
    "box = np.array([N,N,N], dtype=np.float32)\n",
    "centers = []\n",
    "unique_loops = []\n",
    "for L in loops_all:\n",
    "    c = np.mean(L[:-1], axis=0)\n",
    "    if centers:\n",
    "        dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers]\n",
    "        if np.min(dd) < 1.3:\n",
    "            continue\n",
    "    unique_loops.append(L); centers.append(c)\n",
    "unique_loops = unique_loops[:TARGET_LOOPS]\n",
    "\n",
    "# Coherence filter\n",
    "coh_loops = [L for L in unique_loops if loop_coherence_fraction(L, alpha, COH_ALPHA) >= COH_FRAC_REQ]\n",
    "total_abs, linked_pairs = linking_score(coh_loops, downsample=DOWNSAMPLE_LK)\n",
    "elapsed = time.perf_counter()-start\n",
    "print(f\"[loops] total={len(unique_loops)}  coherent={len(coh_loops)}  |Lk|={total_abs:.0f}  linked_pairs={linked_pairs}  ({elapsed:.1f}s)\")\n",
    "\n",
    "# ==== Nulls (FAST) — GPU spectral rotate + parallel loop harvest on CPU ====\n",
    "null_vals = []\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, np.random.default_rng(1000+r))  # GPU\n",
    "    # parallel harvest on rotated field\n",
    "    loops_r = []\n",
    "    with Exec(max_workers=workers) as ex:\n",
    "        futs = [ex.submit(_find_loops_chunk, Bxr, Byr, Bzr, chunk, DT_LIST, STEPS, MIN_CLOSE, CLOSE_TOL)\n",
    "                for chunk in chunkify(seeds, workers)]\n",
    "        for fut in as_completed(futs):\n",
    "            loops_r.extend(fut.result())\n",
    "            if len(loops_r) >= len(unique_loops): break\n",
    "    # dedup + coherence on null\n",
    "    centers_r, uniq_r = [], []\n",
    "    for L in loops_r:\n",
    "        c = np.mean(L[:-1], axis=0)\n",
    "        if centers_r:\n",
    "            dd = [np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers_r]\n",
    "            if np.min(dd) < 1.3: continue\n",
    "        uniq_r.append(L); centers_r.append(c)\n",
    "    uniq_r = uniq_r[:len(unique_loops)]\n",
    "    ar_total, _ = linking_score([L for L in uniq_r\n",
    "                                 if loop_coherence_fraction(L, alpha, COH_ALPHA) >= COH_FRAC_REQ],\n",
    "                                downsample=DOWNSAMPLE_LK)\n",
    "    null_vals.append(ar_total)\n",
    "\n",
    "null_vals = np.array(null_vals, dtype=np.float32)\n",
    "link_pct = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "p_link   = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "print(f\"[nulls] median|Lk|={np.median(null_vals):.1f}  percentile={link_pct:.3f}  p={p_link:.4f}\")\n",
    "\n",
    "# ==== Echo reuse ====\n",
    "echo_csv = run_dir/\"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    mask = (freqs>1.6) & (freqs<1.8)\n",
    "    echo_power = float((P[mask].sum())/(P.sum()+1e-12))\n",
    "else:\n",
    "    t = np.linspace(0,10,4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t)*np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt); P = np.abs(np.fft.rfft(sig))**2/len(sig)\n",
    "    echo_power = float((P[(freqs>1.6)&(freqs<1.8)].sum())/(P.sum()+1e-12))\n",
    "\n",
    "# ==== Final glyphness (FAST) ====\n",
    "wH,wL,wE = 0.25, 0.50, 0.25\n",
    "H_norm = float(min(1.0, abs(h_H)/(1e-2)))\n",
    "glyphness = float(wH*H_norm + wL*link_pct + wE*echo_power)\n",
    "label = \"CANDIDATE (FAST)\"\n",
    "if len(coh_loops) >= 4 and linked_pairs >= 1:\n",
    "    label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_pct>=0.90 and echo_power>=0.20) else \"CANDIDATE\"\n",
    "\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H={H_norm:.2f}, Link%={link_pct:.2f}, Echo={echo_power:.2f}) → {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "94b5961d-5f6a-483e-b9a7-f17fa4e90345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT v0.10-THREAD\n",
      "[orig] helicity_density=9.769e-02  (proj+H 0.20s)\n",
      "[loops] total=4  coherent=0  |Lk|=0  linked_pairs=0  (184.8s)\n",
      "[nulls] median|Lk|=0.0  percentile=0.944  p=1.0000\n",
      "[CNT] glyphness=0.940 (H=1.00, Link%=0.94, Echo=0.87) → CANDIDATE (FAST)\n"
     ]
    }
   ],
   "source": [
    "# CNT v0.10-THREAD (GPU FFTs + threaded loop tracing; no pickling)\n",
    "# Use after running the GPU bootstrap cell.\n",
    "\n",
    "import os, time, math, numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "# Avoid nested thread thrash from NumPy/OpenMP while we use Python threads\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "# ---- require GPU-accelerated hooks from your bootstrap ----\n",
    "try:\n",
    "    _project_solenoidal\n",
    "    helicity_density\n",
    "    spectral_rotation_null\n",
    "except NameError as e:\n",
    "    raise RuntimeError(\"Run the GPU bootstrap cell first (_project_solenoidal, helicity_density, spectral_rotation_null).\") from e\n",
    "\n",
    "# ==== TUNABLES (FAST SCOUT) ====\n",
    "MAX_WORKERS   = max(2, os.cpu_count()//2)    # try ~half cores; raise if CPU is idle\n",
    "TARGET_LOOPS  = 8\n",
    "GRID_DIV      = 5\n",
    "DT_LIST       = (0.3,)\n",
    "STEPS         = 3500\n",
    "MIN_CLOSE     = 450\n",
    "CLOSE_TOL     = 1.1\n",
    "ALPHA_THR     = 0.6      # Beltrami α threshold\n",
    "COH_FRAC_REQ  = 0.50     # fraction of loop points with α>ALPHA_THR\n",
    "NNULL         = 8\n",
    "DOWNSAMPLE_LK = 2\n",
    "\n",
    "# ==== lightweight CPU helpers (thread-safe, no pickling) ====\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - math.floor(x); ty = y - math.floor(y); tz = z - math.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-tx) + c110*tx\n",
    "    c11 = c011*(1-tx) + c111*tx\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], dtype=np.float32)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]; wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt=0.3, steps=3500, min_close=450, close_tol=1.1):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], dtype=np.float32)\n",
    "    pos = np.array(seed, dtype=np.float32); start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0: pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            if np.linalg.norm(_min_image_delta(pos, start, box)) < close_tol:\n",
    "                pts.append(start.copy()); return np.asarray(pts, dtype=np.float32)\n",
    "    return None\n",
    "\n",
    "def beltrami_alpha(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(By, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Bz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Bz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Bx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Bx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(By, dx, axis=0)\n",
    "    Cx = dFz_dy - dFy_dz;  Cy = dFx_dz - dFz_dx;  Cz = dFy_dx - dFx_dy\n",
    "    Bm = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    Cm = np.sqrt(Cx*Cx + Cy*Cy + Cz*Cz) + 1e-12\n",
    "    return np.clip((Bx*Cx + By*Cy + Bz*Cz)/(Bm*Cm), -1.0, 1.0).astype(np.float32)\n",
    "\n",
    "def loop_coh_frac(loop, alpha_field, thr=ALPHA_THR):\n",
    "    vals = [_tri_interp_periodic(alpha_field, p) for p in loop[:-1]]\n",
    "    return float((np.array(vals, dtype=np.float32) > thr).mean())\n",
    "\n",
    "def gauss_link(A, B, box):\n",
    "    A = np.asarray(A); B = np.asarray(B)\n",
    "    a_mid = 0.5*(A[1:]+A[:-1]); b_mid = 0.5*(B[1:]+B[:-1])\n",
    "    da = A[1:]-A[:-1]; db = B[1:]-B[:-1]\n",
    "    Da = da[:,None,:]; Db = db[None,:,:]\n",
    "    Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "    dR = _min_image_delta(Ra, Rb, box)\n",
    "    num = np.einsum('ijk,ijk->ij', np.cross(Da,Db), dR)\n",
    "    denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "    return float(np.sum(num/denom)/(4*np.pi))\n",
    "\n",
    "def linking_score(loops, downsample=DOWNSAMPLE_LK):\n",
    "    if len(loops)<2: return 0.0, 0\n",
    "    box = np.array([loops[0].shape[0]]*3, dtype=np.float32)\n",
    "    total = 0.0; linked = 0\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            A = loops[i][::downsample]; B = loops[j][::downsample]\n",
    "            lk = gauss_link(A,B,box)\n",
    "            k = abs(np.rint(lk))\n",
    "            total += k\n",
    "            if k >= 1: linked += 1\n",
    "    return float(total), int(linked)\n",
    "\n",
    "# ---- load latest field ----\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "npz = run_dir/\"best_field.npz\"\n",
    "if not npz.exists(): npz = run_dir/\"field_small.npz\"\n",
    "d = np.load(npz)\n",
    "Bx, By, Bz = d[\"Bx\"].astype(np.float32), d[\"By\"].astype(np.float32), d[\"Bz\"].astype(np.float32)\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "\n",
    "print(\"CNT v0.10-THREAD\")\n",
    "t0=time.perf_counter()\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)   # GPU\n",
    "hH = helicity_density(Bx, By, Bz, sp)              # GPU\n",
    "print(f\"[orig] helicity_density={hH:.3e}  (proj+H {time.perf_counter()-t0:.2f}s)\")\n",
    "\n",
    "alpha = beltrami_alpha(Bx, By, Bz, sp)             # CPU (light)\n",
    "N = Bx.shape[0]; box = np.array([N,N,N], dtype=np.float32)\n",
    "\n",
    "# seeds\n",
    "coords = np.linspace(0, N, GRID_DIV, endpoint=False) + N/(2*GRID_DIV)\n",
    "rng = np.random.default_rng(21)\n",
    "seeds = np.array([[xi,yi,zi] for xi in coords for yi in coords for zi in coords], dtype=np.float32)\n",
    "seeds = (seeds + rng.normal(0, 0.15, seeds.shape)) % N\n",
    "seeds = list(map(tuple, seeds.tolist()))\n",
    "\n",
    "# threaded loop harvest\n",
    "def harvest_seeds(seed_batch):\n",
    "    loops = []\n",
    "    for s in seed_batch:\n",
    "        for sign in (1.0,-1.0):\n",
    "            for dt in DT_LIST:\n",
    "                L = _trace_loop(s, Bx, By, Bz, dt=sign*dt, steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "                if L is not None: loops.append(L)\n",
    "    return loops\n",
    "\n",
    "def dedup_by_center(loops, max_dup_dist=1.3):\n",
    "    centers=[]; uniq=[]\n",
    "    for L in loops:\n",
    "        c=np.mean(L[:-1],axis=0)\n",
    "        if centers:\n",
    "            dd=[np.linalg.norm(_min_image_delta(c,cc,box)) for cc in centers]\n",
    "            if np.min(dd) < max_dup_dist: continue\n",
    "        centers.append(c); uniq.append(L)\n",
    "    return uniq\n",
    "\n",
    "def chunkify(lst, n): \n",
    "    k=max(1,len(lst)//n)\n",
    "    for i in range(0,len(lst),k): yield lst[i:i+k]\n",
    "\n",
    "start=time.perf_counter()\n",
    "loops_all=[]\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futs=[ex.submit(harvest_seeds, chunk) for chunk in chunkify(seeds, MAX_WORKERS)]\n",
    "    for fut in as_completed(futs):\n",
    "        loops_all.extend(fut.result())\n",
    "        if len(loops_all) >= TARGET_LOOPS*3:  # overshoot for dedup\n",
    "            break\n",
    "\n",
    "unique_loops = dedup_by_center(loops_all)[:TARGET_LOOPS]\n",
    "coh_loops = [L for L in unique_loops if loop_coh_frac(L, alpha, ALPHA_THR) >= COH_FRAC_REQ]\n",
    "total_abs, linked_pairs = linking_score(coh_loops, downsample=DOWNSAMPLE_LK)\n",
    "print(f\"[loops] total={len(unique_loops)}  coherent={len(coh_loops)}  |Lk|={total_abs:.0f}  linked_pairs={linked_pairs}  ({time.perf_counter()-start:.1f}s)\")\n",
    "\n",
    "# FAST nulls (GPU rotation + threaded tracing)\n",
    "null_vals=[]\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, np.random.default_rng(1000+r))\n",
    "    loops_r=[]\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futs=[ex.submit(harvest_seeds, chunk) for chunk in chunkify(seeds, MAX_WORKERS)]\n",
    "        for fut in as_completed(futs):\n",
    "            loops_r.extend(fut.result())\n",
    "            if len(loops_r) >= len(unique_loops)*3: break\n",
    "    uniq_r = dedup_by_center(loops_r)[:len(unique_loops)]\n",
    "    coh_r = [L for L in uniq_r if loop_coh_frac(L, alpha, ALPHA_THR) >= COH_FRAC_REQ]\n",
    "    t_abs_r, _ = linking_score(coh_r, downsample=DOWNSAMPLE_LK)\n",
    "    null_vals.append(t_abs_r)\n",
    "\n",
    "null_vals = np.array(null_vals, dtype=np.float32)\n",
    "link_pct = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "p_link   = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "print(f\"[nulls] median|Lk|={np.median(null_vals):.1f}  percentile={link_pct:.3f}  p={p_link:.4f}\")\n",
    "\n",
    "# echo reuse\n",
    "echo_csv = run_dir/\"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    echo = float((P[(freqs>1.6)&(freqs<1.8)].sum())/(P.sum()+1e-12))\n",
    "else:\n",
    "    t=np.linspace(0,10,4096); dt=t[1]-t[0]\n",
    "    sig=np.sin(2*np.pi*1.7*t)*np.exp(-t/6.0)\n",
    "    freqs=np.fft.rfftfreq(len(sig),d=dt); P=np.abs(np.fft.rfft(sig))**2/len(sig)\n",
    "    echo=float((P[(freqs>1.6)&(freqs<1.8)].sum())/(P.sum()+1e-12))\n",
    "\n",
    "# final FAST score\n",
    "wH,wL,wE = 0.25,0.50,0.25\n",
    "H_norm = float(min(1.0, abs(hH)/(1e-2)))\n",
    "glyphness = float(wH*H_norm + wL*link_pct + wE*echo)\n",
    "label = \"CANDIDATE (FAST)\"\n",
    "if len(coh_loops)>=4 and linked_pairs>=1:\n",
    "    label = \"PHYSICAL-GLYPH:PASS\" if (glyphness>=0.70 and link_pct>=0.90 and echo>=0.20) else \"CANDIDATE\"\n",
    "print(f\"[CNT] glyphness={glyphness:.3f} (H={H_norm:.2f}, Link%={link_pct:.2f}, Echo={echo:.2f}) → {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a750d90d-b921-42c6-a7c6-62c1d5a403a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[GPU] NVIDIA GeForce RTX 4070 • SMs=46 • mem=12.9 GB  • CuPy=13.6.0\n",
      "✅ GPU bootstrap loaded. Heavy ops are now cuFFT-accelerated when available.\n"
     ]
    }
   ],
   "source": [
    "# CNT GPU Bootstrap — RTX 4070 (CuPy/cuFFT hybrid)  vGPU-1.0\n",
    "# Overrides: _project_solenoidal, _vector_potential_from_B, helicity_density, spectral_rotation_null\n",
    "# Strategy: GPU for all spectral heavy steps; keep streamline/loop tracing on CPU.\n",
    "\n",
    "import sys, subprocess, importlib, math\n",
    "import numpy as np\n",
    "\n",
    "# --- 1) Bring CuPy online (CUDA 12.x wheel fits RTX 4070 drivers) ---\n",
    "try:\n",
    "    import cupy as cp\n",
    "except Exception:\n",
    "    print(\"[setup] Installing CuPy for CUDA 12.x…\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"cupy-cuda12x\"])\n",
    "    import cupy as cp\n",
    "\n",
    "try:\n",
    "    ndev = cp.cuda.runtime.getDeviceCount()\n",
    "    dev = cp.cuda.Device(0)\n",
    "    dev.use()\n",
    "    props = cp.cuda.runtime.getDeviceProperties(0)\n",
    "    name = props[\"name\"].decode() if isinstance(props[\"name\"], bytes) else props[\"name\"]\n",
    "    print(f\"[GPU] {name} • SMs={props['multiProcessorCount']} • mem={props['totalGlobalMem']/1e9:.1f} GB  • CuPy={cp.__version__}\")\n",
    "    HAS_GPU = True\n",
    "except Exception as e:\n",
    "    print(\"[GPU] No CUDA device or driver issue:\", e)\n",
    "    HAS_GPU = False\n",
    "\n",
    "# --- 2) Small helpers ---\n",
    "_DTYPE = np.float32  # use FP32 on GPU for speed; accurate enough for our stats\n",
    "\n",
    "def _ensure_cp(x):\n",
    "    return cp.asarray(x, dtype=_DTYPE)\n",
    "\n",
    "def _ensure_np(x):\n",
    "    return cp.asnumpy(x)\n",
    "\n",
    "# Build k-grids (GPU)\n",
    "def _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz):\n",
    "    kx = cp.fft.fftfreq(Nx, d=Lx/Nx) * (2*cp.pi)\n",
    "    ky = cp.fft.fftfreq(Ny, d=Ly/Ny) * (2*cp.pi)\n",
    "    kz = cp.fft.fftfreq(Nz, d=Lz/Nz) * (2*cp.pi)\n",
    "    return cp.meshgrid(kx, ky, kz, indexing='ij')\n",
    "\n",
    "# --- 3) GPU overrides (fall back to CPU if needed) ---\n",
    "def _project_solenoidal(Bx, By, Bz, spacings):\n",
    "    \"\"\"\n",
    "    Project B onto the divergence-free subspace in Fourier domain (Coulomb gauge).\n",
    "    Accepts numpy, returns numpy; runs on GPU if available.\n",
    "    \"\"\"\n",
    "    if not HAS_GPU:\n",
    "        # CPU fallback (numpy FFT)\n",
    "        dx, dy, dz = spacings\n",
    "        Nx, Ny, Nz = Bx.shape\n",
    "        Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "        kx = np.fft.fftfreq(Nx, d=Lx/Nx) * 2*np.pi\n",
    "        ky = np.fft.fftfreq(Ny, d=Ly/Ny) * 2*np.pi\n",
    "        kz = np.fft.fftfreq(Nz, d=Lz/Nz) * 2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "        Bxh, Byh, Bzh = np.fft.fftn(Bx), np.fft.fftn(By), np.fft.fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "        Bxh = np.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "        Byh = np.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "        Bzh = np.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "        return (np.fft.ifftn(Bxh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Byh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Bzh).real.astype(_DTYPE))\n",
    "    # GPU path\n",
    "    dx, dy, dz = spacings\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kx, ky, kz = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    dot = kx*Bxh + ky*Byh + kz*Bzh\n",
    "    Bxh = cp.where(k2!=0, Bxh - kx*dot/k2, 0.0)\n",
    "    Byh = cp.where(k2!=0, Byh - ky*dot/k2, 0.0)\n",
    "    Bzh = cp.where(k2!=0, Bzh - kz*dot/k2, 0.0)\n",
    "    Brx = cp.fft.ifftn(Bxh).real.astype(_DTYPE)\n",
    "    Bry = cp.fft.ifftn(Byh).real.astype(_DTYPE)\n",
    "    Brz = cp.fft.ifftn(Bzh).real.astype(_DTYPE)\n",
    "    return _ensure_np(Brx), _ensure_np(Bry), _ensure_np(Brz)\n",
    "\n",
    "def _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz):\n",
    "    \"\"\"\n",
    "    Solve ∇×A = B (Coulomb gauge) in Fourier domain. Accepts numpy; returns numpy. GPU-backed.\n",
    "    \"\"\"\n",
    "    if not HAS_GPU:\n",
    "        kx = np.fft.fftfreq(Bx.shape[0], d=Lx/Bx.shape[0]) * 2*np.pi\n",
    "        ky = np.fft.fftfreq(By.shape[1], d=Ly/By.shape[1]) * 2*np.pi\n",
    "        kz = np.fft.fftfreq(Bz.shape[2], d=Lz/Bz.shape[2]) * 2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kx, ky, kz, indexing='ij')\n",
    "        Bxh, Byh, Bzh = np.fft.fftn(Bx), np.fft.fftn(By), np.fft.fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        i = 1j\n",
    "        cx = ky*Bzh - kz*Byh\n",
    "        cy = kz*Bxh - kx*Bzh\n",
    "        cz = kx*Byh - ky*Bxh\n",
    "        Axh = i * np.where(k2!=0, cx/k2, 0.0)\n",
    "        Ayh = i * np.where(k2!=0, cy/k2, 0.0)\n",
    "        Azh = i * np.where(k2!=0, cz/k2, 0.0)\n",
    "        return (np.fft.ifftn(Axh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Ayh).real.astype(_DTYPE),\n",
    "                np.fft.ifftn(Azh).real.astype(_DTYPE))\n",
    "    # GPU path\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    kx, ky, kz = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kx*kx + ky*ky + kz*kz\n",
    "    i = 1j\n",
    "    cx = ky*Bzh - kz*Byh\n",
    "    cy = kz*Bxh - kx*Bzh\n",
    "    cz = kx*Byh - ky*Bxh\n",
    "    Axh = i * cp.where(k2!=0, cx/k2, 0.0)\n",
    "    Ayh = i * cp.where(k2!=0, cy/k2, 0.0)\n",
    "    Azh = i * cp.where(k2!=0, cz/k2, 0.0)\n",
    "    Ax = cp.fft.ifftn(Axh).real.astype(_DTYPE)\n",
    "    Ay = cp.fft.ifftn(Ayh).real.astype(_DTYPE)\n",
    "    Az = cp.fft.ifftn(Azh).real.astype(_DTYPE)\n",
    "    return _ensure_np(Ax), _ensure_np(Ay), _ensure_np(Az)\n",
    "\n",
    "def helicity_density(Bx, By, Bz, spacings):\n",
    "    \"\"\"\n",
    "    H/V with A from ∇×A=B. Accepts numpy; returns float. GPU-backed.\n",
    "    \"\"\"\n",
    "    dx, dy, dz = spacings\n",
    "    Nx, Ny, Nz = Bx.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    Ax, Ay, Az = _vector_potential_from_B(Bx, By, Bz, Lx, Ly, Lz)\n",
    "    H = float((Ax*Bx + Ay*By + Az*Bz).sum() * dx*dy*dz)\n",
    "    V = Lx*Ly*Lz\n",
    "    return H / V\n",
    "\n",
    "def spectral_rotation_null(Bx, By, Bz, spacings, rng):\n",
    "    \"\"\"\n",
    "    Strong null: rotate B̂(k) within the plane ⟂k for half the spectrum,\n",
    "    mirror-conjugate to enforce Hermitian, then project to solenoidal.\n",
    "    Accepts numpy; returns numpy. GPU-backed & vectorized.\n",
    "    \"\"\"\n",
    "    dx, dy, dz = spacings\n",
    "    if not HAS_GPU:\n",
    "        # fall back to your earlier CPU spectral_rotation_null (if defined)\n",
    "        # (or keep phase-scramble as a last resort)\n",
    "        from numpy.fft import fftn, ifftn, fftfreq\n",
    "        Nx, Ny, Nz = Bx.shape\n",
    "        Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "        kxv, kyv, kzv = fftfreq(Nx, d=Lx/Nx)*2*np.pi, fftfreq(Ny, d=Ly/Ny)*2*np.pi, fftfreq(Nz, d=Lz/Nz)*2*np.pi\n",
    "        kx, ky, kz = np.meshgrid(kxv, kyv, kzv, indexing='ij')\n",
    "        Bxh, Byh, Bzh = fftn(Bx), fftn(By), fftn(Bz)\n",
    "        k2 = kx*kx + ky*ky + kz*kz\n",
    "        pos = (kz>0) | ((kz==0)&(ky>0)) | ((kz==0)&(ky==0)&(kx>0))\n",
    "        # Build orthonormal basis in ⟂k\n",
    "        kn = np.sqrt(k2)+1e-15\n",
    "        kxh, kyh, kzh = kx/kn, ky/kn, kz/kn\n",
    "        use_x = (np.abs(kxh) < 0.9)\n",
    "        ax = np.where(use_x, 1.0, 0.0); ay = np.where(use_x, 0.0, 1.0); az = 0.0\n",
    "        e1x = ay*kzh - az*kyh; e1y = az*kxh - ax*kzh; e1z = ax*kyh - ay*kxh\n",
    "        n1 = np.sqrt(e1x*e1x + e1y*e1y + e1z*e1z)+1e-15; e1x/=n1; e1y/=n1; e1z/=n1\n",
    "        e2x = kyh*e1z - kzh*e1y; e2y = kzh*e1x - kxh*e1z; e2z = kxh*e1y - kyh*e1x\n",
    "        c1 = e1x*Bxh + e1y*Byh + e1z*Bzh\n",
    "        c2 = e2x*Bxh + e2y*Byh + e2z*Bzh\n",
    "        theta = rng.uniform(0, 2*np.pi, size=Bxh.shape)\n",
    "        ct, st = np.cos(theta), np.sin(theta)\n",
    "        c1p = ct*c1 - st*c2\n",
    "        c2p = st*c1 + ct*c2\n",
    "        Bxh_rot = e1x*c1p + e2x*c2p\n",
    "        Byh_rot = e1y*c1p + e2y*c2p\n",
    "        Bzh_rot = e1z*c1p + e2z*c2p\n",
    "        # Build Hermitian array by pos + flipped conjugate\n",
    "        zero = (k2==0)\n",
    "        Bxh_new = np.zeros_like(Bxh); Byh_new = np.zeros_like(Byh); Bzh_new = np.zeros_like(Bzh)\n",
    "        Bxh_new[pos] = Bxh_rot[pos]; Byh_new[pos] = Byh_rot[pos]; Bzh_new[pos] = Bzh_rot[pos]\n",
    "        Bxh_new += np.conj(Bxh_new[::-1, ::-1, ::-1])\n",
    "        Byh_new += np.conj(Byh_new[::-1, ::-1, ::-1])\n",
    "        Bzh_new += np.conj(Bzh_new[::-1, ::-1, ::-1])\n",
    "        Bxh_new[zero] = Bxh[zero]; Byh_new[zero] = Byh[zero]; Bzh_new[zero] = Bzh[zero]\n",
    "        Brx = np.fft.ifftn(Bxh_new).real.astype(_DTYPE)\n",
    "        Bry = np.fft.ifftn(Byh_new).real.astype(_DTYPE)\n",
    "        Brz = np.fft.ifftn(Bzh_new).real.astype(_DTYPE)\n",
    "        return _project_solenoidal(Brx, Bry, Brz, spacings)\n",
    "    # GPU path\n",
    "    Bxg, Byg, Bzg = _ensure_cp(Bx), _ensure_cp(By), _ensure_cp(Bz)\n",
    "    Nx, Ny, Nz = Bxg.shape\n",
    "    Lx, Ly, Lz = dx*Nx, dy*Ny, dz*Nz\n",
    "    kxv, kyv, kzv = _fftvec_gpu(Nx, Ny, Nz, Lx, Ly, Lz)\n",
    "    Bxh, Byh, Bzh = cp.fft.fftn(Bxg), cp.fft.fftn(Byg), cp.fft.fftn(Bzg)\n",
    "    k2 = kxv*kxv + kyv*kyv + kzv*kzv\n",
    "    pos = (kzv>0) | ((kzv==0)&(kyv>0)) | ((kzv==0)&(kyv==0)&(kxv>0))\n",
    "    # Basis in ⟂k (vectorized)\n",
    "    kn = cp.sqrt(k2) + 1e-15\n",
    "    kxh, kyh, kzh = kxv/kn, kyv/kn, kzv/kn\n",
    "    use_x = (cp.abs(kxh) < 0.9)\n",
    "    ax = cp.where(use_x, 1.0, 0.0); ay = cp.where(use_x, 0.0, 1.0); az = cp.zeros_like(kxh)\n",
    "    e1x = ay*kzh - az*kyh; e1y = az*kxh - ax*kzh; e1z = ax*kyh - ay*kxh\n",
    "    n1 = cp.sqrt(e1x*e1x + e1y*e1y + e1z*e1z) + 1e-15\n",
    "    e1x/=n1; e1y/=n1; e1z/=n1\n",
    "    e2x = kyh*e1z - kzh*e1y; e2y = kzh*e1x - kxh*e1z; e2z = kxh*e1y - kyh*e1x\n",
    "    # Project & rotate\n",
    "    c1 = e1x*Bxh + e1y*Byh + e1z*Bzh\n",
    "    c2 = e2x*Bxh + e2y*Byh + e2z*Bzh\n",
    "    theta = cp.zeros_like(k2, dtype=_DTYPE)\n",
    "    # Only give random angles on positive half\n",
    "    theta[pos] = (cp.random.random(pos.sum(), dtype=_DTYPE) * (2*cp.pi)).astype(_DTYPE)\n",
    "    ct, st = cp.cos(theta), cp.sin(theta)\n",
    "    c1p = ct*c1 - st*c2\n",
    "    c2p = st*c1 + ct*c2\n",
    "    Bxh_rot = e1x*c1p + e2x*c2p\n",
    "    Byh_rot = e1y*c1p + e2y*c2p\n",
    "    Bzh_rot = e1z*c1p + e2z*c2p\n",
    "    # Compose Hermitian spectrum: rotated pos + conj of flipped\n",
    "    Bxh_new = cp.where(pos, Bxh_rot, 0.0+0.0j)\n",
    "    Byh_new = cp.where(pos, Byh_rot, 0.0+0.0j)\n",
    "    Bzh_new = cp.where(pos, Bzh_rot, 0.0+0.0j)\n",
    "    Bxh_new = Bxh_new + cp.conj(Bxh_new[::-1, ::-1, ::-1])\n",
    "    Byh_new = Byh_new + cp.conj(Byh_new[::-1, ::-1, ::-1])\n",
    "    Bzh_new = Bzh_new + cp.conj(Bzh_new[::-1, ::-1, ::-1])\n",
    "    # Keep self-conjugate planes from original (DC/Nyquist)\n",
    "    zero = (k2==0)\n",
    "    Bxh_new[zero] = Bxh[zero]; Byh_new[zero] = Byh[zero]; Bzh_new[zero] = Bzh[zero]\n",
    "    # Back to real space + projection\n",
    "    Brx = cp.fft.ifftn(Bxh_new).real.astype(_DTYPE)\n",
    "    Bry = cp.fft.ifftn(Byh_new).real.astype(_DTYPE)\n",
    "    Brz = cp.fft.ifftn(Bzh_new).real.astype(_DTYPE)\n",
    "    Brx, Bry, Brz = _project_solenoidal(_ensure_np(Brx), _ensure_np(Bry), _ensure_np(Brz), spacings)\n",
    "    return Brx, Bry, Brz\n",
    "\n",
    "print(\"✅ GPU bootstrap loaded. Heavy ops are now cuFFT-accelerated when available.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16f2bcb1-a91d-44d2-8494-6118218b7284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT v0.10-THREAD-SEEDSMART\n",
      "[orig] helicity_density=9.769e-02  (proj+H 5.47s)\n",
      "[loops] total=10  coherent=1  |Lk|=0  linked_pairs=0  (4020.5s)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'ndarray' object cannot be interpreted as an integer",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 206\u001b[39m\n\u001b[32m    204\u001b[39m null_vals=[]\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(NNULL):\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     Bxr, Byr, Bzr = \u001b[43mspectral_rotation_null\u001b[49m\u001b[43m(\u001b[49m\u001b[43mBx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBz\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdefault_rng\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1000\u001b[39;49m\u001b[43m+\u001b[49m\u001b[43mr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# GPU\u001b[39;00m\n\u001b[32m    207\u001b[39m     loops_r=[]\n\u001b[32m    208\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m ThreadPoolExecutor(max_workers=MAX_WORKERS) \u001b[38;5;28;01mas\u001b[39;00m ex:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 205\u001b[39m, in \u001b[36mspectral_rotation_null\u001b[39m\u001b[34m(Bx, By, Bz, spacings, rng)\u001b[39m\n\u001b[32m    203\u001b[39m theta = cp.zeros_like(k2, dtype=_DTYPE)\n\u001b[32m    204\u001b[39m \u001b[38;5;66;03m# Only give random angles on positive half\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m theta[pos] = (\u001b[43mcp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpos\u001b[49m\u001b[43m.\u001b[49m\u001b[43msum\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_DTYPE\u001b[49m\u001b[43m)\u001b[49m * (\u001b[32m2\u001b[39m*cp.pi)).astype(_DTYPE)\n\u001b[32m    206\u001b[39m ct, st = cp.cos(theta), cp.sin(theta)\n\u001b[32m    207\u001b[39m c1p = ct*c1 - st*c2\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\cupy\\random\\_sample.py:156\u001b[39m, in \u001b[36mrandom_sample\u001b[39m\u001b[34m(size, dtype)\u001b[39m\n\u001b[32m    140\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Returns an array of random values over the interval ``[0, 1)``.\u001b[39;00m\n\u001b[32m    141\u001b[39m \n\u001b[32m    142\u001b[39m \u001b[33;03mThis is a variant of :func:`cupy.random.rand`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    153\u001b[39m \n\u001b[32m    154\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    155\u001b[39m rs = _generator.get_random_state()\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrandom_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m=\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\cupy\\random\\_generator.py:623\u001b[39m, in \u001b[36mRandomState.random_sample\u001b[39m\u001b[34m(self, size, dtype)\u001b[39m\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    622\u001b[39m     size = ()\n\u001b[32m--> \u001b[39m\u001b[32m623\u001b[39m out = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_random_sample_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    624\u001b[39m RandomState._mod1_kernel(out)\n\u001b[32m    625\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\cupy\\random\\_generator.py:605\u001b[39m, in \u001b[36mRandomState._random_sample_raw\u001b[39m\u001b[34m(self, size, dtype)\u001b[39m\n\u001b[32m    602\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcupy_backends\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcuda\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mlibs\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m curand\n\u001b[32m    604\u001b[39m dtype = _check_and_get_dtype(dtype)\n\u001b[32m--> \u001b[39m\u001b[32m605\u001b[39m out = \u001b[43mcupy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    606\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype.char == \u001b[33m'\u001b[39m\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m    607\u001b[39m     func = curand.generateUniform\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\cupy\\_creation\\basic.py:32\u001b[39m, in \u001b[36mempty\u001b[39m\u001b[34m(shape, dtype, order)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mempty\u001b[39m(\n\u001b[32m     14\u001b[39m         shape: _ShapeLike,\n\u001b[32m     15\u001b[39m         dtype: DTypeLike = \u001b[38;5;28mfloat\u001b[39m,\n\u001b[32m     16\u001b[39m         order: _OrderCF = \u001b[33m'\u001b[39m\u001b[33mC\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     17\u001b[39m ) -> NDArray[Any]:\n\u001b[32m     18\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Returns an array without initializing the elements.\u001b[39;00m\n\u001b[32m     19\u001b[39m \n\u001b[32m     20\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcupy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mndarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m=\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\_core\\\\core.pyx:167\u001b[39m, in \u001b[36mcupy._core.core.ndarray.__new__\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mcupy\\\\_core\\\\core.pyx:228\u001b[39m, in \u001b[36mcupy._core.core._ndarray_base._init\u001b[39m\u001b[34m()\u001b[39m\n",
      "\u001b[31mTypeError\u001b[39m: 'ndarray' object cannot be interpreted as an integer"
     ]
    }
   ],
   "source": [
    "# CNT v0.10-THREAD-SEEDSMART (GPU FFTs + threaded loop tracing + smart seeding)\n",
    "# Goal: pick seeds from coherent, strong-field regions so loops aren't all filtered out.\n",
    "\n",
    "import os, time, math, numpy as np\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "from pathlib import Path\n",
    "\n",
    "# --- require GPU hooks from your bootstrap ---\n",
    "try:\n",
    "    _project_solenoidal\n",
    "    helicity_density\n",
    "    spectral_rotation_null\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run the GPU bootstrap cell first.\")\n",
    "\n",
    "# ============== TUNABLES (FAST SCOUT) ==============\n",
    "MAX_WORKERS      = max(2, os.cpu_count()//2)\n",
    "TARGET_LOOPS     = 10\n",
    "NNULL            = 8\n",
    "DT_LIST          = (0.28, 0.34)    # a touch of variety helps closures\n",
    "STEPS            = 3200\n",
    "MIN_CLOSE        = 420\n",
    "CLOSE_TOL        = 1.1\n",
    "ALPHA_THR        = 0.60            # coherence test along loop\n",
    "COH_FRAC_REQ     = 0.50\n",
    "ALPHA_SEED_THR   = 0.60            # seed where alpha is already high\n",
    "BMAG_PCTL        = 60              # and field magnitude is above this percentile\n",
    "MAX_SEEDS        = 2000            # cap seed count for speed\n",
    "DOWNSAMPLE_LK    = 2               # link cost ~s^2, so downsample vertices\n",
    "# ====================================================\n",
    "\n",
    "# Throttle OpenMP inside threads\n",
    "os.environ.setdefault(\"OMP_NUM_THREADS\", \"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\", \"1\")\n",
    "\n",
    "# ----- light CPU helpers -----\n",
    "def _tri_interp_periodic(arr, pos):\n",
    "    N = arr.shape[0]\n",
    "    x, y, z = pos\n",
    "    i0 = int(np.floor(x)) % N; j0 = int(np.floor(y)) % N; k0 = int(np.floor(z)) % N\n",
    "    i1 = (i0+1) % N; j1 = (j0+1) % N; k1 = (k0+1) % N\n",
    "    tx = x - np.floor(x); ty = y - np.floor(y); tz = z - np.floor(z)\n",
    "    c000 = arr[i0,j0,k0]; c100 = arr[i1,j0,k0]; c010 = arr[i0,j1,k0]; c110 = arr[i1,j1,k0]\n",
    "    c001 = arr[i0,j0,k1]; c101 = arr[i1,j0,k1]; c011 = arr[i0,j1,k1]; c111 = arr[i1,j1,k1]\n",
    "    c00 = c000*(1-tx) + c100*tx\n",
    "    c01 = c001*(1-tx) + c101*tx\n",
    "    c10 = c010*(1-ty) + c110*ty\n",
    "    c11 = c011*(1-ty) + c111*ty\n",
    "    c0 = c00*(1-ty) + c10*ty\n",
    "    c1 = c01*(1-ty) + c11*ty\n",
    "    return c0*(1-tz) + c1*tz\n",
    "\n",
    "def _B_dir(Bx, By, Bz, pos):\n",
    "    v = np.array([_tri_interp_periodic(Bx,pos),\n",
    "                  _tri_interp_periodic(By,pos),\n",
    "                  _tri_interp_periodic(Bz,pos)], np.float32)\n",
    "    n = np.linalg.norm(v) + 1e-12\n",
    "    return v / n\n",
    "\n",
    "def _rk4_step(pos, dt, Bx, By, Bz):\n",
    "    N = Bx.shape[0]; wrap = lambda p: np.mod(p, N)\n",
    "    k1 = _B_dir(Bx,By,Bz,pos)\n",
    "    k2 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k1))\n",
    "    k3 = _B_dir(Bx,By,Bz,wrap(pos + 0.5*dt*k2))\n",
    "    k4 = _B_dir(Bx,By,Bz,wrap(pos + dt*k3))\n",
    "    return wrap(pos + (dt/6.0)*(k1 + 2*k2 + 2*k3 + k4))\n",
    "\n",
    "def _min_image_delta(a, b, box):\n",
    "    d = a - b\n",
    "    return (d + box/2.0) % box - box/2.0\n",
    "\n",
    "def _trace_loop(seed, Bx, By, Bz, dt, steps, min_close, close_tol):\n",
    "    N = Bx.shape[0]; box = np.array([N,N,N], np.float32)\n",
    "    pos = np.array(seed, np.float32); start = pos.copy()\n",
    "    pts = [pos.copy()]\n",
    "    for t in range(1, steps+1):\n",
    "        pos = _rk4_step(pos, dt, Bx, By, Bz)\n",
    "        if t % 2 == 0: pts.append(pos.copy())\n",
    "        if t > min_close:\n",
    "            if np.linalg.norm(_min_image_delta(pos, start, box)) < close_tol:\n",
    "                pts.append(start.copy()); return np.asarray(pts, np.float32)\n",
    "    return None\n",
    "\n",
    "def dedup_by_center(loops, N, tol=1.2):\n",
    "    box = np.array([N,N,N], np.float32)\n",
    "    centers=[]; uniq=[]\n",
    "    for L in loops:\n",
    "        c = np.mean(L[:-1], axis=0)\n",
    "        if centers:\n",
    "            if min(np.linalg.norm(_min_image_delta(c, cc, box)) for cc in centers) < tol: \n",
    "                continue\n",
    "        centers.append(c); uniq.append(L)\n",
    "    return uniq\n",
    "\n",
    "def beltrami_alpha(Bx, By, Bz, spacings):\n",
    "    dx, dy, dz = spacings\n",
    "    dFy_dz = np.gradient(By, dz, axis=2)\n",
    "    dFz_dy = np.gradient(Bz, dy, axis=1)\n",
    "    dFz_dx = np.gradient(Bz, dx, axis=0)\n",
    "    dFx_dz = np.gradient(Bx, dz, axis=2)\n",
    "    dFx_dy = np.gradient(Bx, dy, axis=1)\n",
    "    dFy_dx = np.gradient(By, dx, axis=0)\n",
    "    Cx = dFz_dy - dFy_dz;  Cy = dFx_dz - dFz_dx;  Cz = dFy_dx - dFx_dy\n",
    "    Bm = np.sqrt(Bx*Bx + By*By + Bz*Bz) + 1e-12\n",
    "    Cm = np.sqrt(Cx*Cx + Cy*Cy + Cz*Cz) + 1e-12\n",
    "    return np.clip((Bx*Cx + By*Cy + Bz*Cz)/(Bm*Cm), -1.0, 1.0).astype(np.float32), Bm.astype(np.float32)\n",
    "\n",
    "def linking_score(loops, N, downsample=DOWNSAMPLE_LK):\n",
    "    if len(loops) < 2: return 0.0, 0\n",
    "    box = np.array([N,N,N], np.float32)\n",
    "    total = 0.0; linked = 0\n",
    "    for i in range(len(loops)):\n",
    "        for j in range(i+1, len(loops)):\n",
    "            A = loops[i][::downsample]; B = loops[j][::downsample]\n",
    "            a_mid = 0.5*(A[1:]+A[:-1]); b_mid = 0.5*(B[1:]+B[:-1])\n",
    "            da = A[1:]-A[:-1]; db = B[1:]-B[:-1]\n",
    "            Da = da[:,None,:]; Db = db[None,:,:]\n",
    "            Ra = a_mid[:,None,:]; Rb = b_mid[None,:,:]\n",
    "            dR = _min_image_delta(Ra, Rb, box)\n",
    "            num = np.einsum('ijk,ijk->ij', np.cross(Da,Db), dR)\n",
    "            denom = (np.linalg.norm(dR, axis=2)**3 + 1e-12)\n",
    "            lk = float(np.sum(num/denom)/(4*np.pi))\n",
    "            k = abs(np.rint(lk))\n",
    "            total += k\n",
    "            if k >= 1: linked += 1\n",
    "    return float(total), int(linked)\n",
    "\n",
    "# ----- load latest field -----\n",
    "root = Path(os.getenv('CNT_LAB_DIR') or ('E:\\\\CNT' if Path('E:\\\\CNT').exists() else os.getcwd()))\n",
    "hunt_dir = root / \"artifacts\" / \"cnt_physical_glyph_hunt\"\n",
    "runs = sorted([p for p in hunt_dir.glob(\"*\") if p.is_dir()], key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "assert runs, f\"No runs found in {hunt_dir}\"\n",
    "run_dir = runs[0]\n",
    "npz = run_dir/\"best_field.npz\"\n",
    "if not npz.exists(): npz = run_dir/\"field_small.npz\"\n",
    "d = np.load(npz)\n",
    "Bx, By, Bz = d[\"Bx\"].astype(np.float32), d[\"By\"].astype(np.float32), d[\"Bz\"].astype(np.float32)\n",
    "dx = float(d.get(\"dx\", 2*np.pi/Bx.shape[0])); dy = float(d.get(\"dy\", 2*np.pi/By.shape[1])); dz = float(d.get(\"dz\", 2*np.pi/Bz.shape[2]))\n",
    "sp = (dx,dy,dz)\n",
    "N = Bx.shape[0]\n",
    "\n",
    "print(\"CNT v0.10-THREAD-SEEDSMART\")\n",
    "t0=time.perf_counter()\n",
    "Bx, By, Bz = _project_solenoidal(Bx, By, Bz, sp)   # GPU\n",
    "hH = helicity_density(Bx, By, Bz, sp)              # GPU\n",
    "print(f\"[orig] helicity_density={hH:.3e}  (proj+H {time.perf_counter()-t0:.2f}s)\")\n",
    "\n",
    "# α-map + |B| map\n",
    "alpha, Bmag = beltrami_alpha(Bx, By, Bz, sp)\n",
    "bcut = np.percentile(Bmag, BMAG_PCTL)\n",
    "mask = (alpha > ALPHA_SEED_THR) & (Bmag > bcut)\n",
    "idx = np.argwhere(mask)\n",
    "if idx.size == 0:\n",
    "    # relax once if too strict\n",
    "    alpha_thr_relax = max(0.5, ALPHA_SEED_THR - 0.05)\n",
    "    bcut_relax = np.percentile(Bmag, 50)\n",
    "    mask = (alpha > alpha_thr_relax) & (Bmag > bcut_relax)\n",
    "    idx = np.argwhere(mask)\n",
    "K = min(MAX_SEEDS, len(idx))\n",
    "if K == 0:\n",
    "    print(\"[seeds] no coherent regions found; falling back to uniform grid.\")\n",
    "    coords = np.linspace(0, N, 5, endpoint=False) + N/10\n",
    "    seeds = np.array([[xi,yi,zi] for xi in coords for yi in coords for zi in coords], np.float32)\n",
    "else:\n",
    "    sel = idx[np.random.default_rng(42).choice(len(idx), size=K, replace=False)]\n",
    "    # jitter inside voxels\n",
    "    jitter = np.random.default_rng(43).random((K,3)).astype(np.float32) - 0.5\n",
    "    seeds = (sel.astype(np.float32) + jitter).astype(np.float32)\n",
    "\n",
    "# threaded harvest\n",
    "def trace_batch(batch):\n",
    "    out=[]\n",
    "    for s in batch:\n",
    "        for dt in DT_LIST:\n",
    "            for sign in (1.0,-1.0):\n",
    "                L = _trace_loop(tuple(s), Bx, By, Bz, dt=sign*dt, steps=STEPS, min_close=MIN_CLOSE, close_tol=CLOSE_TOL)\n",
    "                if L is not None: out.append(L)\n",
    "    return out\n",
    "\n",
    "def chunkify(arr, n):\n",
    "    n = max(1, n)\n",
    "    k = max(1, len(arr)//n)\n",
    "    for i in range(0, len(arr), k):\n",
    "        yield arr[i:i+k]\n",
    "\n",
    "loops=[]\n",
    "start=time.perf_counter()\n",
    "with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "    futs=[ex.submit(trace_batch, chunk) for chunk in chunkify(list(seeds), MAX_WORKERS)]\n",
    "    for fut in as_completed(futs):\n",
    "        loops.extend(fut.result())\n",
    "        if len(loops) >= TARGET_LOOPS*3: break\n",
    "\n",
    "loops = dedup_by_center(loops, N)[:TARGET_LOOPS]\n",
    "# coherence along loops\n",
    "def coh_frac(L): \n",
    "    vals = [_tri_interp_periodic(alpha, p) for p in L[:-1]]\n",
    "    return float((np.array(vals)>ALPHA_THR).mean())\n",
    "coh_loops = [L for L in loops if coh_frac(L) >= COH_FRAC_REQ]\n",
    "total_abs, linked_pairs = linking_score(coh_loops, N, downsample=DOWNSAMPLE_LK)\n",
    "print(f\"[loops] total={len(loops)}  coherent={len(coh_loops)}  |Lk|={total_abs:.0f}  linked_pairs={linked_pairs}  ({time.perf_counter()-start:.1f}s)\")\n",
    "\n",
    "# --- FAST nulls with same seeding footprint ---\n",
    "null_vals=[]\n",
    "for r in range(NNULL):\n",
    "    Bxr, Byr, Bzr = spectral_rotation_null(Bx, By, Bz, sp, np.random.default_rng(1000+r))  # GPU\n",
    "    loops_r=[]\n",
    "    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as ex:\n",
    "        futs=[ex.submit(trace_batch, chunk) for chunk in chunkify(list(seeds), MAX_WORKERS)]\n",
    "        for fut in as_completed(futs):\n",
    "            loops_r.extend(fut.result())\n",
    "            if len(loops_r) >= len(loops)*3: break\n",
    "    loops_r = dedup_by_center(loops_r, N)[:len(loops)]\n",
    "    # reuse alpha from original for gate? No—compute quick α_r for fairness\n",
    "    alpha_r, _ = beltrami_alpha(Bxr, Byr, Bzr, sp)\n",
    "    def coh_r(L):\n",
    "        vals=[_tri_interp_periodic(alpha_r, p) for p in L[:-1]]\n",
    "        return float((np.array(vals)>ALPHA_THR).mean())\n",
    "    coh_r_loops = [L for L in loops_r if coh_r(L) >= COH_FRAC_REQ]\n",
    "    t_abs_r, _ = linking_score(coh_r_loops, N, downsample=DOWNSAMPLE_LK)\n",
    "    null_vals.append(t_abs_r)\n",
    "\n",
    "null_vals = np.array(null_vals, np.float32)\n",
    "if (linked_pairs==0) or (len(coh_loops)<2):\n",
    "    link_pct = 0.50   # degenerate guard: don't let 0 linking look \"great\"\n",
    "    p_link   = 1.0\n",
    "else:\n",
    "    link_pct = float((np.sum(null_vals <= total_abs) + 0.5)/(NNULL+1))\n",
    "    p_link   = float((np.sum(null_vals >= total_abs) + 1)/(NNULL+1))\n",
    "print(f\"[nulls] median|Lk|={np.median(null_vals):.1f}  percentile={link_pct:.3f}  p={p_link:.4f}\")\n",
    "\n",
    "# echo reuse\n",
    "echo_csv = run_dir/\"echo_spectrum.csv\"\n",
    "if echo_csv.exists():\n",
    "    arr = np.loadtxt(echo_csv, delimiter=\",\", skiprows=1)\n",
    "    freqs, P = arr[:,0], arr[:,1]\n",
    "    echo = float((P[(freqs>1.6)&(freqs<1.8)].sum())/(P.sum()+1e-12))\n",
    "else:\n",
    "    t = np.linspace(0,10,4096); dt = t[1]-t[0]\n",
    "    sig = np.sin(2*np.pi*1.7*t)*np.exp(-t/6.0)\n",
    "    freqs = np.fft.rfftfreq(len(sig), d=dt); P = np.abs(np.fft.rfft(sig))**2/len(sig)\n",
    "    echo = float((P[(freqs>1.6)&(freqs<1.8)].sum())/(P.sum()+1e-12))\n",
    "\n",
    "# final FAST score (guarded)\n",
    "wH,wL,wE = 0.25,0.50,0.25\n",
    "H_norm = float(min(1.0, abs(hH)/(1e-2)))\n",
    "glyphness = float(wH*H_norm + wL*link_pct + wE*echo)\n",
    "label = \"CANDIDATE (FAST)\"\n",
    "if (len(coh_loops)>=4 and linked_pairs>=1 and link_pct>=0.90 and echo>=0.20 and glyphness>=0.70):\n",
    "    label = \"PHYSICAL-GLYPH:PASS\"\n",
    "print(f\"[CNT] glyphness={glyphness:.3f}  (H={H_norm:.2f}, Link%={link_pct:.2f}, Echo={echo:.2f}) → {label}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf5221d-a44d-4ad3-a3fe-c4704dd039a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNT Lab (Py3.13)",
   "language": "python",
   "name": "cnt_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
