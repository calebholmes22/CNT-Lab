{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b91104f7-fabb-42d4-9b15-cb7b3c15554b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Kernel info ==\n",
      "Python: 3.13.5\n",
      "Interpreter: C:\\Users\\caleb\\cnt_genome\\.venv\\Scripts\\python.exe\n",
      "\n",
      "== Upgrading pip core ==\n",
      "Requirement already satisfied: pip in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (25.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (80.9.0)\n",
      "Requirement already satisfied: wheel in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (0.45.1)\n",
      "\n",
      "== Installing core scientific stack ==\n",
      "Requirement already satisfied: numpy in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (1.16.2)\n",
      "Requirement already satisfied: pandas in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (3.10.6)\n",
      "Requirement already satisfied: statsmodels in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (0.14.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: numba in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (0.62.0)\n",
      "Requirement already satisfied: umap-learn in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (0.5.9.post2)\n",
      "Requirement already satisfied: networkx in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (3.5)\n",
      "Requirement already satisfied: plotly in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (6.3.0)\n",
      "Collecting kaleido\n",
      "  Using cached kaleido-1.1.0-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting statsforecast\n",
      "  Using cached statsforecast-2.0.2.tar.gz (2.9 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pmdarima\n",
      "  Using cached pmdarima-2.0.4.tar.gz (630 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: mne in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (1.10.1)\n",
      "Collecting nilearn\n",
      "  Using cached nilearn-0.12.1-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting anndata\n",
      "  Using cached anndata-0.12.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting scanpy\n",
      "  Using cached scanpy-1.11.4-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting pybedtools\n",
      "  Using cached pybedtools-0.12.0.tar.gz (12.6 MB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pybigwig\n",
      "  Using cached pybigwig-0.3.24.tar.gz (75 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'error'\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  Getting requirements to build wheel did not run successfully.\n",
      "  exit code: 1\n",
      "  \n",
      "  [20 lines of output]\n",
      "  Traceback (most recent call last):\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m389\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "      \u001b[31mmain\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m373\u001b[0m, in \u001b[35mmain\u001b[0m\n",
      "      json_out[\"return_val\"] = \u001b[31mhook\u001b[0m\u001b[1;31m(**hook_input[\"kwargs\"])\u001b[0m\n",
      "                               \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\cnt_genome\\.venv\\Lib\\site-packages\\pip\\_vendor\\pyproject_hooks\\_in_process\\_in_process.py\"\u001b[0m, line \u001b[35m143\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "      return hook(config_settings)\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\AppData\\Local\\Temp\\pip-build-env-nj335l03\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m331\u001b[0m, in \u001b[35mget_requires_for_build_wheel\u001b[0m\n",
      "      return \u001b[31mself._get_build_requires\u001b[0m\u001b[1;31m(config_settings, requirements=[])\u001b[0m\n",
      "             \u001b[31m~~~~~~~~~~~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\AppData\\Local\\Temp\\pip-build-env-nj335l03\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m301\u001b[0m, in \u001b[35m_get_build_requires\u001b[0m\n",
      "      \u001b[31mself.run_setup\u001b[0m\u001b[1;31m()\u001b[0m\n",
      "      \u001b[31m~~~~~~~~~~~~~~\u001b[0m\u001b[1;31m^^\u001b[0m\n",
      "    File \u001b[35m\"C:\\Users\\caleb\\AppData\\Local\\Temp\\pip-build-env-nj335l03\\overlay\\Lib\\site-packages\\setuptools\\build_meta.py\"\u001b[0m, line \u001b[35m317\u001b[0m, in \u001b[35mrun_setup\u001b[0m\n",
      "      \u001b[31mexec\u001b[0m\u001b[1;31m(code, locals())\u001b[0m\n",
      "      \u001b[31m~~~~\u001b[0m\u001b[1;31m^^^^^^^^^^^^^^^^\u001b[0m\n",
      "    File \u001b[35m\"<string>\"\u001b[0m, line \u001b[35m19\u001b[0m, in \u001b[35m<module>\u001b[0m\n",
      "  \u001b[1;35mAttributeError\u001b[0m: \u001b[35m'NoneType' object has no attribute 'split'\u001b[0m\n",
      "  [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: subprocess-exited-with-error\n",
      "\n",
      "Getting requirements to build wheel did not run successfully.\n",
      "exit code: 1\n",
      "\n",
      "See above for output.\n",
      "\n",
      "note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\n",
      "== Installing PyTorch (CUDA 12.4) → fallback to CPU if needed ==\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: torchvision in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (0.21.0+cu124)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (2.6.0+cu124)\n",
      "Requirement already satisfied: filelock in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: setuptools in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torchvision) (2.3.3)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from torchvision) (11.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\caleb\\cnt_genome\\.venv\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "\n",
      "== Installing TensorFlow (may be CPU if no compatible GPU build) ==\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 43\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# --- TensorFlow (GPU if drivers/toolkit match) ---\u001b[39;00m\n\u001b[32m     42\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m== Installing TensorFlow (may be CPU if no compatible GPU build) ==\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mpip_install\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtensorflow\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m[\u001b[32m1\u001b[39m])\n\u001b[32m     45\u001b[39m \u001b[38;5;66;03m# --- Sanity imports & versions ---\u001b[39;00m\n\u001b[32m     46\u001b[39m summary = {\u001b[33m\"\u001b[39m\u001b[33mtorch\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mcuda_available\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mcuda_device\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mtf\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mtf_gpus\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mnvidia_smi\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mNone\u001b[39;00m}\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mpip_install\u001b[39m\u001b[34m(args)\u001b[39m\n\u001b[32m     11\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpip_install\u001b[39m(args):\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m-m\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpip\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43minstall\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(cmd)\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun\u001b[39m(cmd):\n\u001b[32m      5\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m         r = \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSTDOUT\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m r.returncode, r.stdout.strip()\n\u001b[32m      8\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py:556\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    554\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    555\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m556\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    557\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    558\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\subprocess.py:1209\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1207\u001b[39m     \u001b[38;5;28mself\u001b[39m._stdin_write(\u001b[38;5;28minput\u001b[39m)\n\u001b[32m   1208\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stdout:\n\u001b[32m-> \u001b[39m\u001b[32m1209\u001b[39m     stdout = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstdout\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1210\u001b[39m     \u001b[38;5;28mself\u001b[39m.stdout.close()\n\u001b[32m   1211\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.stderr:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\encodings\\cp1252.py:22\u001b[39m, in \u001b[36mIncrementalDecoder.decode\u001b[39m\u001b[34m(self, input, final)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mIncrementalDecoder\u001b[39;00m(codecs.IncrementalDecoder):\n\u001b[32m---> \u001b[39m\u001b[32m22\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m     23\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m codecs.charmap_decode(\u001b[38;5;28minput\u001b[39m,\u001b[38;5;28mself\u001b[39m.errors,decoding_table)[\u001b[32m0\u001b[39m]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# === CNT one-shot environment + GPU check (single cell) ===\n",
    "import sys, subprocess, platform, json, shutil\n",
    "\n",
    "def run(cmd):\n",
    "    try:\n",
    "        r = subprocess.run(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True, check=False)\n",
    "        return r.returncode, r.stdout.strip()\n",
    "    except Exception as e:\n",
    "        return -1, str(e)\n",
    "\n",
    "def pip_install(args):\n",
    "    return run([sys.executable, \"-m\", \"pip\", \"install\"] + args)\n",
    "\n",
    "print(\"== Kernel info ==\")\n",
    "print(\"Python:\", platform.python_version())\n",
    "print(\"Interpreter:\", sys.executable)\n",
    "\n",
    "print(\"\\n== Upgrading pip core ==\")\n",
    "print(pip_install([\"--upgrade\", \"pip\", \"setuptools\", \"wheel\"])[1])\n",
    "\n",
    "# --- Core scientific stack (CPU-safe) ---\n",
    "core = [\"numpy\",\"scipy\",\"pandas\",\"matplotlib\",\"statsmodels\",\"scikit-learn\",\"numba\",\"umap-learn\",\"networkx\"]\n",
    "viz  = [\"plotly\",\"kaleido\"]\n",
    "forecast = [\"statsforecast\",\"pmdarima\"]\n",
    "neuro_genomics = [\"mne\",\"nilearn\",\"anndata\",\"scanpy\",\"pybedtools\",\"pybigwig\"]\n",
    "maybe_heavy = [\"ubermag\"]  # will set up OOMMF on first real use\n",
    "\n",
    "print(\"\\n== Installing core scientific stack ==\")\n",
    "print(pip_install(core + viz + forecast + neuro_genomics + maybe_heavy)[1])\n",
    "\n",
    "# --- Torch GPU (CUDA 12.4 wheels) with graceful fallback ---\n",
    "torch_gpu_ok = False\n",
    "print(\"\\n== Installing PyTorch (CUDA 12.4) → fallback to CPU if needed ==\")\n",
    "code, out = pip_install([\"--index-url\",\"https://download.pytorch.org/whl/cu124\",\"torch\",\"torchvision\",\"torchaudio\"])\n",
    "if code != 0:\n",
    "    print(\"[torch cuda install failed] falling back to CPU wheels…\")\n",
    "    print(pip_install([\"torch\",\"torchvision\",\"torchaudio\"])[1])\n",
    "else:\n",
    "    print(out)\n",
    "\n",
    "# --- TensorFlow (GPU if drivers/toolkit match) ---\n",
    "print(\"\\n== Installing TensorFlow (may be CPU if no compatible GPU build) ==\")\n",
    "print(pip_install([\"tensorflow\"])[1])\n",
    "\n",
    "# --- Sanity imports & versions ---\n",
    "summary = {\"torch\":None,\"cuda_available\":None,\"cuda_device\":None,\"tf\":None,\"tf_gpus\":None,\"nvidia_smi\":None}\n",
    "\n",
    "print(\"\\n== Import checks ==\")\n",
    "try:\n",
    "    import torch\n",
    "    summary[\"torch\"] = getattr(torch, \"__version__\", \"unknown\")\n",
    "    summary[\"cuda_available\"] = bool(torch.cuda.is_available())\n",
    "    summary[\"cuda_device\"] = (torch.cuda.get_device_name(0) if torch.cuda.is_available() else None)\n",
    "    print(f\"Torch: {summary['torch']}  | CUDA available: {summary['cuda_available']}  | Device: {summary['cuda_device']}\")\n",
    "except Exception as e:\n",
    "    print(\"Torch import failed:\", e)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    summary[\"tf\"] = getattr(tf, \"__version__\", \"unknown\")\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    summary[\"tf_gpus\"] = [g.name for g in gpus] if gpus else []\n",
    "    print(f\"TensorFlow: {summary['tf']}  | GPUs: {summary['tf_gpus']}\")\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow import failed:\", e)\n",
    "\n",
    "# --- OS-level GPU probe (nvidia-smi) ---\n",
    "print(\"\\n== nvidia-smi probe ==\")\n",
    "code, out = run([\"nvidia-smi\"])\n",
    "summary[\"nvidia_smi\"] = (out if code == 0 else \"nvidia-smi not found or no NVIDIA driver.\")\n",
    "print(out)\n",
    "\n",
    "# --- Quick GPU spike tests (safe sizes) ---\n",
    "print(\"\\n== Quick GPU spike tests ==\")\n",
    "try:\n",
    "    import torch, time\n",
    "    if torch.cuda.is_available():\n",
    "        x = torch.randn(4096, 4096, device=\"cuda\")\n",
    "        t0 = time.time(); y = x @ x; torch.cuda.synchronize(); dt = time.time()-t0\n",
    "        print(f\"PyTorch CUDA matmul OK in {dt:.3f}s, y.sum()={float(y.sum()):.3e}\")\n",
    "    else:\n",
    "        print(\"PyTorch: CUDA not available, skipping GPU matmul.\")\n",
    "except Exception as e:\n",
    "    print(\"PyTorch spike failed:\", e)\n",
    "\n",
    "try:\n",
    "    import tensorflow as tf, time\n",
    "    gpus = tf.config.list_physical_devices('GPU')\n",
    "    if gpus:\n",
    "        with tf.device('/GPU:0'):\n",
    "            a = tf.random.normal((4096,4096))\n",
    "            t0 = time.time(); b = a @ a; _ = tf.reduce_sum(b).numpy(); dt = time.time()-t0\n",
    "            print(f\"TensorFlow GPU matmul OK in {dt:.3f}s\")\n",
    "    else:\n",
    "        print(\"TensorFlow: no GPU visible, skipping GPU matmul.\")\n",
    "except Exception as e:\n",
    "    print(\"TensorFlow spike failed:\", e)\n",
    "\n",
    "# --- Final print ---\n",
    "print(\"\\n== CNT environment summary ==\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"\\nAll set. If the kernel was just updated with new packages, consider doing Kernel → Restart once.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65db8db0-7b5b-4cd0-9a25-62a61cf7efad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → saved out/cnt_kuramoto_ecdf.png\n",
      " → saved out/cnt_ising_mtrace.png\n",
      " → saved out/cnt_grayscott_pattern.png\n",
      " → saved out/cnt_grayscott_uniformish.png\n",
      "== CNT Physics One-Cell: Summary ==\n",
      "{\n",
      "  \"elapsed_sec\": 99.3,\n",
      "  \"results\": [\n",
      "    {\n",
      "      \"name\": \"Kuramoto\",\n",
      "      \"K_null\": 0.0,\n",
      "      \"K_eff\": 1.2,\n",
      "      \"mean_r_null\": 0.11533998078796838,\n",
      "      \"mean_r_eff\": 0.24787849291781625,\n",
      "      \"obs_diff\": 0.13253851212984785,\n",
      "      \"p_value_two_sided\": 0.00024993751562109475,\n",
      "      \"runs\": 24\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Ising2D\",\n",
      "      \"L\": 40,\n",
      "      \"T_low\": 1.8,\n",
      "      \"T_high\": 3.0,\n",
      "      \"mean_abs_mag_low\": 0.42910729166666667,\n",
      "      \"mean_abs_mag_high\": 0.07430208333333334,\n",
      "      \"obs_diff\": 0.35480520833333334,\n",
      "      \"p_value_two_sided\": 0.000999750062484379,\n",
      "      \"runs\": 10\n",
      "    },\n",
      "    {\n",
      "      \"name\": \"Gray-Scott\",\n",
      "      \"params_A\": {\n",
      "        \"F\": 0.035,\n",
      "        \"k\": 0.06\n",
      "      },\n",
      "      \"params_B\": {\n",
      "        \"F\": 0.046,\n",
      "        \"k\": 0.064\n",
      "      },\n",
      "      \"mean_std_A\": 0.09937606844367845,\n",
      "      \"mean_std_B\": 0.06748805998905706,\n",
      "      \"obs_diff\": 0.03188800845462139,\n",
      "      \"p_value_two_sided\": 0.001999500124968758,\n",
      "      \"runs\": 6\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Saved files:\n",
      " - out\\.ipynb_checkpoints\n",
      " - out\\CNT_A_rest_fast.json\n",
      " - out\\CNT_A_rest_fast.png\n",
      " - out\\CNT_A_rest_subject.json\n",
      " - out\\CNT_A_rest_subject.png\n",
      " - out\\CNT_B_dose_fast.json\n",
      " - out\\CNT_B_dose_fast.png\n",
      " - out\\CNT_B_dose_fast_procrustes.json\n",
      " - out\\CNT_B_dose_fast_procrustes.png\n",
      " - out\\CNT_all_options_appendix.pdf\n",
      " - out\\CNT_angle_dominance.json\n",
      " - out\\CNT_angle_dominance.png\n",
      " - out\\CNT_appendix_all_options.pdf\n",
      " - out\\CNT_appendix_for_paper.pdf\n",
      " - out\\CNT_bridge_cCRE_pairs.csv\n",
      " - out\\CNT_bridge_hubs.csv\n",
      " - out\\CNT_bridge_leaders.csv\n",
      " - out\\CNT_bridge_leaders_v2.csv\n",
      " - out\\CNT_claim_blurb.md\n",
      " - out\\CNT_claims_summary.json\n",
      " - out\\CNT_cross_subject_zero_dose.json\n",
      " - out\\CNT_cross_subject_zero_dose.pdf\n",
      " - out\\CNT_cross_subject_zero_dose_v2.json\n",
      " - out\\CNT_cross_subject_zero_dose_v2.pdf\n",
      " - out\\CNT_cross_subject_zero_dose_v3.json\n",
      " - out\\CNT_cross_subject_zero_dose_v3.pdf\n",
      " - out\\CNT_genomic_field_3D.html\n",
      " - out\\CNT_genomic_field_3D_crisp.html\n",
      " - out\\CNT_genomic_field_3D_edges.html\n",
      " - out\\CNT_genomic_graph.png\n",
      " - out\\CNT_genomic_network.html\n",
      " - out\\CNT_genomic_resonance_map.csv\n",
      " - out\\CNT_genomic_resonance_scored.csv\n",
      " - out\\CNT_genomic_resonance_scored_v2.csv\n",
      " - out\\CNT_preReg_sensitivity.json\n",
      " - out\\CNT_preReg_sensitivity.pdf\n",
      " - out\\CNT_replication_subjects.json\n",
      " - out\\CNT_replication_subjects.pdf\n",
      " - out\\CNT_rotation_dominance.json\n",
      " - out\\CNT_rotation_dominance.png\n",
      " - out\\CNT_rsa_gain_capture.json\n",
      " - out\\CNT_rsa_gain_capture.png\n",
      " - out\\CNT_scaffold_CRISPR_candidates.csv\n",
      " - out\\CNT_scaffold_candidates.csv\n",
      " - out\\EEG_cross_subject_vs_baselines.json\n",
      " - out\\EEG_cross_subject_vs_baselines.pdf\n",
      " - out\\EEG_fast_blocks.json\n",
      " - out\\EEG_knee_pairs.json\n",
      " - out\\EEG_knee_pairs.pdf\n",
      " - out\\EEG_temporal_stability.json\n",
      " - out\\EEG_temporal_stability.pdf\n",
      " - out\\cache_GRCh38_scale\n",
      " - out\\cnt_auroc_leaderboard.json\n",
      " - out\\cnt_auroc_leaderboard.png\n",
      " - out\\cnt_core_calibration_p_hist.png\n",
      " - out\\cnt_core_invariance_rsa.png\n",
      " - out\\cnt_core_leakage_sentinel.png\n",
      " - out\\cnt_core_power_stability.png\n",
      " - out\\cnt_core_report.json\n",
      " - out\\cnt_core_resilience.png\n",
      " - out\\cnt_eeg_continue_novelty_LEFT.png\n",
      " - out\\cnt_eeg_continue_novelty_RIGHT.png\n",
      " - out\\cnt_eeg_continue_novelty_report.json\n",
      " - out\\cnt_eeg_erd_lateral_summary.csv\n",
      " - out\\cnt_eeg_erd_summary.csv\n",
      " - out\\cnt_eeg_labeled.csv\n",
      " - out\\cnt_eeg_labeled_all.csv\n",
      " - out\\cnt_eeg_labeled_all_overlap.csv\n",
      " - out\\cnt_eeg_leaderboard_overlap.json\n",
      " - out\\cnt_eeg_leaderboard_overlap.png\n",
      " - out\\cnt_eeg_lofc_FBCSP_confmat.png\n",
      " - out\\cnt_eeg_lofc_FBCSP_pub.json\n",
      " - out\\cnt_eeg_lofc_FBCSP_pub_block_confmat.png\n",
      " - out\\cnt_eeg_lofc_FBCSP_pub_report.pdf\n",
      " - out\\cnt_eeg_lofc_FBCSP_pub_window_confmat.png\n",
      " - out\\cnt_eeg_lofc_FBCSP_report.json\n",
      " - out\\cnt_eeg_lofc_FBCSP_tuned_confmat.png\n",
      " - out\\cnt_eeg_lofc_FBCSP_tuned_report.json\n",
      " - out\\cnt_eeg_lofc_RSA_MULTI.json\n",
      " - out\\cnt_eeg_lofc_confmat_CSP_LR.png\n",
      " - out\\cnt_eeg_lofc_confmat_tangentLR.png\n",
      " - out\\cnt_eeg_lofc_demo_confmat_CSP_LR.png\n",
      " - out\\cnt_eeg_lofc_demo_confmat_tangentLR.png\n",
      " - out\\cnt_eeg_lofc_demo_report.json\n",
      " - out\\cnt_eeg_lofc_rsa_ALIGNFREE_WIN.json\n",
      " - out\\cnt_eeg_lofc_rsa_ALIGNFREE_WIN_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_ALIGNFREE_WIN_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_BOTH.json\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_BOTH_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_BOTH_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_FINAL.json\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_FINAL_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_FINAL_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH.json\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_ROBUST.json\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_ROBUST_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_ROBUST_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_SWEEP.json\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_BLOCK_POLISH_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BOTH_final.json\n",
      " - out\\cnt_eeg_lofc_rsa_BOTH_final_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_BOTH_final_rdms.png\n",
      " - out\\cnt_eeg_lofc_rsa_FETCH40k.json\n",
      " - out\\cnt_eeg_lofc_rsa_FETCH40k_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_FETCH40k_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_FINAL.json\n",
      " - out\\cnt_eeg_lofc_rsa_FINALLOCK.json\n",
      " - out\\cnt_eeg_lofc_rsa_FINALLOCK_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_FINALLOCK_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_FINAL_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_FINAL_rdms.png\n",
      " - out\\cnt_eeg_lofc_rsa_PUSH_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_PUSH_final.json\n",
      " - out\\cnt_eeg_lofc_rsa_PUSH_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK.json\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_FIXED.json\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_FIXED_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_FIXED_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_PF.json\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_PF_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_PF_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_SUPERBLOCK_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_TIPPING.json\n",
      " - out\\cnt_eeg_lofc_rsa_TIPPING_bars.png\n",
      " - out\\cnt_eeg_lofc_rsa_TIPPING_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_calib_BOTH.json\n",
      " - out\\cnt_eeg_lofc_rsa_calib_BOTH_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_calib_BOTH_rdms.png\n",
      " - out\\cnt_eeg_lofc_rsa_calib_SWEEP.json\n",
      " - out\\cnt_eeg_lofc_rsa_calibration_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_calibration_suite.json\n",
      " - out\\cnt_eeg_lofc_rsa_field_plus.json\n",
      " - out\\cnt_eeg_lofc_rsa_field_plus_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_field_plus_rdms.png\n",
      " - out\\cnt_eeg_lofc_rsa_field_rdms.png\n",
      " - out\\cnt_eeg_lofc_rsa_field_report.json\n",
      " - out\\cnt_eeg_lofc_rsa_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_restcal_fixed.json\n",
      " - out\\cnt_eeg_lofc_rsa_restcal_fixed_perm.png\n",
      " - out\\cnt_eeg_lofc_rsa_restcal_fixed_rdms.png\n",
      " - out\\cnt_eeg_lofc_supervised_report.json\n",
      " - out\\cnt_eeg_novelty_after_LEFT.png\n",
      " - out\\cnt_eeg_novelty_after_RIGHT.png\n",
      " - out\\cnt_eeg_novelty_before_LEFT.png\n",
      " - out\\cnt_eeg_novelty_before_RIGHT.png\n",
      " - out\\cnt_eeg_novelty_beforeafter_FIXED.json\n",
      " - out\\cnt_eeg_novelty_best_left.png\n",
      " - out\\cnt_eeg_novelty_best_report.json\n",
      " - out\\cnt_eeg_novelty_best_right.png\n",
      " - out\\cnt_eeg_novelty_continue_LEFT.png\n",
      " - out\\cnt_eeg_novelty_continue_RIGHT.png\n",
      " - out\\cnt_eeg_novelty_groupAvg_left.png\n",
      " - out\\cnt_eeg_novelty_groupAvg_report.json\n",
      " - out\\cnt_eeg_novelty_groupAvg_right.png\n",
      " - out\\cnt_eeg_novelty_overrides_LEFT.png\n",
      " - out\\cnt_eeg_novelty_overrides_RIGHT.png\n",
      " - out\\cnt_eeg_novelty_overrides_report.json\n",
      " - out\\cnt_eeg_novelty_perREST.json\n",
      " - out\\cnt_eeg_novelty_perREST_riemannAlign.json\n",
      " - out\\cnt_eeg_novelty_report.json\n",
      " - out\\cnt_eeg_novelty_riemann_report.json\n",
      " - out\\cnt_eeg_novelty_tuner.json\n",
      " - out\\cnt_glyph_kernel_leaderboard.json\n",
      " - out\\cnt_glyph_kernel_leaderboard.png\n",
      " - out\\cnt_glyph_vs_raw_significance.json\n",
      " - out\\cnt_glyph_vs_raw_significance.png\n",
      " - out\\cnt_grayscott_pattern.png\n",
      " - out\\cnt_grayscott_uniformish.png\n",
      " - out\\cnt_ising_mtrace.png\n",
      " - out\\cnt_kuramoto_ecdf.png\n",
      " - out\\cnt_reality_vs_shuffle.json\n",
      " - out\\cnt_reality_vs_shuffle.png\n",
      " - out\\cnt_resilience_curves.png\n",
      " - out\\cnt_resilience_report.json\n",
      " - out\\cnt_resilience_v2.json\n",
      " - out\\cnt_resilience_v2.png\n",
      " - out\\cnt_resilience_v3_fixed.json\n",
      " - out\\cnt_resilience_v3_fixed.png\n",
      " - out\\cnt_stability_ari.json\n",
      " - out\\cnt_stability_ari.png\n",
      " - out\\cnt_umap_tuner_leaderboard.json\n",
      " - out\\cnt_umap_tuner_leaderboard.png\n",
      " - out\\erd_S001R03.png\n",
      " - out\\erd_lateral_S001R03_left_thr10.png\n",
      " - out\\erd_lateral_S001R03_left_thr20.png\n",
      " - out\\erd_lateral_S001R03_left_thr30.png\n",
      " - out\\erd_lateral_S001R03_right_thr10.png\n",
      " - out\\erd_lateral_S001R03_right_thr20.png\n",
      " - out\\erd_lateral_S001R03_right_thr30.png\n",
      " - out\\field_note_Dermatitis\n",
      " - out\\final_invariance_figure.pdf\n",
      " - out\\gEDE_best_curve.npy\n",
      " - out\\gEDE_best_curve_v2.npy\n",
      " - out\\gEDE_chi2_grid.npz\n",
      " - out\\gEDE_chi2_grid_v2.npz\n",
      " - out\\methods_release.md\n",
      " - out\\methods_release.tex\n",
      " - out\\mini_atlas_lipids\n",
      " - out\\release_final_20251005_231532\n",
      " - out\\seq_adaptive_pelt.json\n",
      " - out\\seq_adaptive_pelt_fig.png\n",
      " - out\\seq_cnt_report_fixed.json\n",
      " - out\\seq_gc_windows_1Mb.csv\n",
      " - out\\seq_local_moran_fdr.bedGraph\n",
      " - out\\seq_local_moran_fig.png\n",
      " - out\\seq_moran_200kb.png\n",
      " - out\\seq_pelt_200kb.png\n",
      " - out\\seq_reality_vs_shuffle_fixed.png\n",
      " - out\\seq_resilience.png\n",
      " - out\\seq_spatial_cnt.json\n",
      " - out\\seq_spatial_cnt_200kb.json\n",
      " - out\\seq_spatial_cnt_hists.png\n",
      " - out\\seq_spatial_cnt_summary.png\n",
      " - out\\seq_stability_ari_fixed.png\n",
      " - out\\summary.txt\n",
      " - out\\summary_dual_path.json\n",
      " - out\\summary_dual_path_v2.json\n"
     ]
    }
   ],
   "source": [
    "# CNT Physics One-Cell: Kuramoto sync + 2D Ising + Gray–Scott reaction–diffusion\n",
    "# Outputs: PNG figures in ./out and a summary.txt with permutation-test p-values\n",
    "# Safe to run on CPU; no extra dependencies beyond numpy/matplotlib.\n",
    "\n",
    "import os, time, math, json, numpy as np, matplotlib.pyplot as plt\n",
    "rng = np.random.default_rng(42)\n",
    "os.makedirs(\"out\", exist_ok=True)\n",
    "\n",
    "def savefig(path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=140)\n",
    "    print(f\" → saved {path}\")\n",
    "    plt.close()\n",
    "\n",
    "##############################\n",
    "# 1) KURAMOTO SYNCHRONIZATION\n",
    "##############################\n",
    "def kuramoto_run(N=64, K=1.2, T=12.0, dt=0.02, sigma=0.08):\n",
    "    omegas = rng.normal(0, 1.0, N)\n",
    "    theta  = rng.uniform(0, 2*np.pi, N)\n",
    "    steps  = int(T/dt)\n",
    "    r_trace = np.empty(steps, dtype=float)\n",
    "\n",
    "    def order_param(ph):\n",
    "        z = np.exp(1j*ph).mean()\n",
    "        return np.abs(z)\n",
    "\n",
    "    for i in range(steps):\n",
    "        r_trace[i] = order_param(theta)\n",
    "        # interaction term\n",
    "        sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "        theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "    # mean r over last half (steady-ish region)\n",
    "    return r_trace, float(np.mean(r_trace[steps//2:]))\n",
    "\n",
    "def permutation_pvalue(a, b, n_perm=2000, two_sided=True):\n",
    "    # a, b: arrays of summary stats per run; label-shuffle test\n",
    "    a = np.asarray(a); b = np.asarray(b)\n",
    "    obs = a.mean() - b.mean()\n",
    "    both = np.concatenate([a,b])\n",
    "    n = len(a)\n",
    "    cnt = 0\n",
    "    for _ in range(n_perm):\n",
    "        rng.shuffle(both)\n",
    "        diff = both[:n].mean() - both[n:].mean()\n",
    "        if two_sided:\n",
    "            if abs(diff) >= abs(obs): cnt += 1\n",
    "        else:\n",
    "            if diff >= obs: cnt += 1\n",
    "    return (cnt+1)/(n_perm+1), obs\n",
    "\n",
    "def experiment_kuramoto():\n",
    "    params = dict(N=64, T=12.0, dt=0.02, sigma=0.08)\n",
    "    K_null, K_eff = 0.0, 1.2\n",
    "    runs = 24\n",
    "\n",
    "    r_null = []\n",
    "    r_eff  = []\n",
    "    for _ in range(runs):\n",
    "        _, rmean0 = kuramoto_run(K=K_null, **params)\n",
    "        _, rmean1 = kuramoto_run(K=K_eff,  **params)\n",
    "        r_null.append(rmean0); r_eff.append(rmean1)\n",
    "\n",
    "    p, obs = permutation_pvalue(r_eff, r_null, n_perm=4000, two_sided=True)\n",
    "\n",
    "    # plot distributions\n",
    "    plt.figure(figsize=(6.5,4.2))\n",
    "    xs0 = np.sort(r_null); xs1 = np.sort(r_eff)\n",
    "    plt.plot(xs0, np.linspace(0,1,len(xs0)), label=f\"Null K={K_null}\")\n",
    "    plt.plot(xs1, np.linspace(0,1,len(xs1)), label=f\"Coupled K={K_eff}\")\n",
    "    plt.xlabel(\"mean coherence r (last half)\"); plt.ylabel(\"ECDF\")\n",
    "    plt.title(f\"Kuramoto: Δ={np.mean(r_eff)-np.mean(r_null):.3f}, p≈{p:.4g}\")\n",
    "    plt.legend()\n",
    "    savefig(\"out/cnt_kuramoto_ecdf.png\")\n",
    "\n",
    "    return {\n",
    "        \"name\": \"Kuramoto\",\n",
    "        \"K_null\": K_null, \"K_eff\": K_eff,\n",
    "        \"mean_r_null\": float(np.mean(r_null)),\n",
    "        \"mean_r_eff\": float(np.mean(r_eff)),\n",
    "        \"obs_diff\": float(obs),\n",
    "        \"p_value_two_sided\": float(p),\n",
    "        \"runs\": runs\n",
    "    }\n",
    "\n",
    "#################\n",
    "# 2) 2D ISING\n",
    "#################\n",
    "# Simple Metropolis with periodic boundaries (J=1, no field)\n",
    "def ising_run(L=40, T=2.2, sweeps=180, burn=60):\n",
    "    # spins in {-1,+1}\n",
    "    S = rng.choice([-1,1], size=(L,L))\n",
    "    def dE(i,j):\n",
    "        # energy change for flipping S[i,j]\n",
    "        nn = S[(i-1)%L,j] + S[(i+1)%L,j] + S[i,(j-1)%L] + S[i,(j+1)%L]\n",
    "        return 2 * S[i,j] * nn  # J=1\n",
    "    beta = 1.0/max(T,1e-9)\n",
    "    mags = []\n",
    "    for sweep in range(sweeps):\n",
    "        # propose L*L single-site flips per sweep\n",
    "        for _ in range(L*L):\n",
    "            i = rng.integers(0,L); j = rng.integers(0,L)\n",
    "            d = dE(i,j)\n",
    "            if d <= 0 or rng.random() < math.exp(-beta*d):\n",
    "                S[i,j] = -S[i,j]\n",
    "        if sweep >= burn:\n",
    "            mags.append(abs(S.mean()))\n",
    "    return float(np.mean(mags)), np.array(mags, dtype=float)\n",
    "\n",
    "def experiment_ising():\n",
    "    # compare ordered (low T) vs disordered (high T)\n",
    "    L=40; sweeps=180; burn=60\n",
    "    T_low, T_high = 1.8, 3.0\n",
    "    runs = 10\n",
    "    m_low = []; m_high=[]\n",
    "    for _ in range(runs):\n",
    "        m1,_ = ising_run(L=L, T=T_low,  sweeps=sweeps, burn=burn)\n",
    "        m2,_ = ising_run(L=L, T=T_high, sweeps=sweeps, burn=burn)\n",
    "        m_low.append(m1); m_high.append(m2)\n",
    "\n",
    "    p, obs = permutation_pvalue(m_low, m_high, n_perm=4000, two_sided=True)\n",
    "\n",
    "    # visualize one representative run’s magnetization trace at each T\n",
    "    _, trace_low  = ising_run(L=L, T=T_low,  sweeps=sweeps, burn=0)\n",
    "    _, trace_high = ising_run(L=L, T=T_high, sweeps=sweeps, burn=0)\n",
    "    plt.figure(figsize=(6.8,4.2))\n",
    "    plt.plot(trace_low,  label=f\"T={T_low}\")\n",
    "    plt.plot(trace_high, label=f\"T={T_high}\")\n",
    "    plt.xlabel(\"sweep\"); plt.ylabel(\"|magnetization|\")\n",
    "    plt.title(f\"Ising 2D: Δ={np.mean(m_low)-np.mean(m_high):.3f}, p≈{p:.4g}\")\n",
    "    plt.legend()\n",
    "    savefig(\"out/cnt_ising_mtrace.png\")\n",
    "\n",
    "    return {\n",
    "        \"name\": \"Ising2D\",\n",
    "        \"L\": L,\n",
    "        \"T_low\": T_low, \"T_high\": T_high,\n",
    "        \"mean_abs_mag_low\": float(np.mean(m_low)),\n",
    "        \"mean_abs_mag_high\": float(np.mean(m_high)),\n",
    "        \"obs_diff\": float(obs),\n",
    "        \"p_value_two_sided\": float(p),\n",
    "        \"runs\": runs\n",
    "    }\n",
    "\n",
    "############################################\n",
    "# 3) GRAY–SCOTT REACTION–DIFFUSION (U,V)\n",
    "############################################\n",
    "# Discrete 2D PDE with periodic BC; simple Euler–Maruyama step\n",
    "def gray_scott(U, V, Du=0.16, Dv=0.08, F=0.035, k=0.060, dt=1.0):\n",
    "    # 5-point Laplacian\n",
    "    Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV = U*V*V\n",
    "    dU = Du*Uc - UVV + F*(1-U)\n",
    "    dV = Dv*Vc + UVV - (F+k)*V\n",
    "    U += dU*dt\n",
    "    V += dV*dt\n",
    "    return U, V\n",
    "\n",
    "def rd_run(N=96, steps=800, seed=0, params=None):\n",
    "    if params is None:\n",
    "        params = dict(Du=0.16, Dv=0.08, F=0.035, k=0.06, dt=1.0)\n",
    "    rng_local = np.random.default_rng(seed)\n",
    "    U = np.ones((N,N), dtype=float)\n",
    "    V = np.zeros((N,N), dtype=float)\n",
    "    # perturb center\n",
    "    r = N//10\n",
    "    cx = cy = N//2\n",
    "    U[cx-r:cx+r, cy-r:cy+r] = 0.50 + 0.1*rng_local.random((2*r,2*r))\n",
    "    V[cx-r:cx+r, cy-r:cy+r] = 0.25 + 0.1*rng_local.random((2*r,2*r))\n",
    "    for t in range(steps):\n",
    "        U, V = gray_scott(U, V, **params)\n",
    "    # structure metric: std of V (higher → more patterning/segregation)\n",
    "    return U, V, float(V.std())\n",
    "\n",
    "def experiment_rd():\n",
    "    # compare two parameter sets (pattern vs near-washout)\n",
    "    N=96; steps=800\n",
    "    pA = dict(Du=0.16, Dv=0.08, F=0.035, k=0.060, dt=1.0)  # patterning\n",
    "    pB = dict(Du=0.16, Dv=0.08, F=0.046, k=0.064, dt=1.0)  # more uniform\n",
    "    runs=6\n",
    "    sA=[]; sB=[]\n",
    "    for rseed in range(runs):\n",
    "        _,_, s1 = rd_run(N=N, steps=steps, seed=100+rseed, params=pA)\n",
    "        _,_, s2 = rd_run(N=N, steps=steps, seed=200+rseed, params=pB)\n",
    "        sA.append(s1); sB.append(s2)\n",
    "    p, obs = permutation_pvalue(sA, sB, n_perm=4000, two_sided=True)\n",
    "\n",
    "    # visualize a single run from each\n",
    "    U1,V1,_ = rd_run(N=N, steps=steps, seed=777, params=pA)\n",
    "    U2,V2,_ = rd_run(N=N, steps=steps, seed=778, params=pB)\n",
    "\n",
    "    for (V, tag) in [(V1,\"pattern\"), (V2,\"uniformish\")]:\n",
    "        plt.figure(figsize=(5.2,5.0))\n",
    "        plt.imshow(V, origin=\"lower\")\n",
    "        plt.axis(\"off\")\n",
    "        plt.title(f\"Gray–Scott ({tag})\")\n",
    "        savefig(f\"out/cnt_grayscott_{tag}.png\")\n",
    "\n",
    "    return {\n",
    "        \"name\": \"Gray-Scott\",\n",
    "        \"params_A\": {\"F\":0.035,\"k\":0.060},\n",
    "        \"params_B\": {\"F\":0.046,\"k\":0.064},\n",
    "        \"mean_std_A\": float(np.mean(sA)),\n",
    "        \"mean_std_B\": float(np.mean(sB)),\n",
    "        \"obs_diff\": float(obs),\n",
    "        \"p_value_two_sided\": float(p),\n",
    "        \"runs\": runs\n",
    "    }\n",
    "\n",
    "#########################\n",
    "# RUN ALL & SUMMARIZE\n",
    "#########################\n",
    "t0 = time.time()\n",
    "res_k = experiment_kuramoto()\n",
    "res_i = experiment_ising()\n",
    "res_r = experiment_rd()\n",
    "elapsed = time.time() - t0\n",
    "\n",
    "summary = {\n",
    "    \"elapsed_sec\": round(elapsed,2),\n",
    "    \"results\": [res_k, res_i, res_r]\n",
    "}\n",
    "with open(\"out/summary.txt\",\"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"== CNT Physics One-Cell ==\\n\")\n",
    "    f.write(f\"elapsed: {elapsed:.2f} s\\n\\n\")\n",
    "    for r in summary[\"results\"]:\n",
    "        f.write(json.dumps(r, indent=2))\n",
    "        f.write(\"\\n\\n\")\n",
    "\n",
    "print(\"== CNT Physics One-Cell: Summary ==\")\n",
    "print(json.dumps(summary, indent=2))\n",
    "\n",
    "# Quick dashboard print\n",
    "print(\"\\nSaved files:\")\n",
    "for fn in sorted(os.listdir(\"out\")):\n",
    "    print(\" -\", os.path.join(\"out\", fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c696bf-907c-4530-ac86-150c324385c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " → out_proof/kuramoto_mean_r_vs_K.png\n",
      " → out_proof/kuramoto_susceptibility_vs_K.png\n",
      " → out_proof/ising_binder_crossing.png\n",
      " → out_proof/grayscott_phase_sigma.png\n",
      " → out_proof/grayscott_phase_entropy.png\n",
      "Done. Elapsed: 245.86 sec\n",
      "Saved files in out_proof/:\n",
      " - out_proof\\grayscott_phase_entropy.png\n",
      " - out_proof\\grayscott_phase_sigma.png\n",
      " - out_proof\\ising_binder_crossing.png\n",
      " - out_proof\\kuramoto_mean_r_vs_K.png\n",
      " - out_proof\\kuramoto_susceptibility_vs_K.png\n",
      " - out_proof\\proof_summary.json\n"
     ]
    }
   ],
   "source": [
    "# === CNT Physics Proof Pack (v2, single cell) ===\n",
    "# Kuramoto finite-size K-sweep, Ising Binder cumulant crossing, Gray–Scott (F,k) phase map\n",
    "# Saves figures into ./out_proof and writes proof_summary.json\n",
    "\n",
    "import os, time, math, json\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "rng = np.random.default_rng(7)\n",
    "os.makedirs(\"out_proof\", exist_ok=True)\n",
    "\n",
    "def savefig(path):\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(path, dpi=140)\n",
    "    print(\" →\", path)\n",
    "    plt.close()\n",
    "\n",
    "# ---------- Shared helpers ----------\n",
    "def ecdf(x):\n",
    "    x = np.sort(np.asarray(x)); y = np.linspace(0,1,len(x))\n",
    "    return x, y\n",
    "\n",
    "def spectral_entropy_2d(arr, eps=1e-12):\n",
    "    # normalized power spectrum entropy as a \"disorder\" measure (lower => structured)\n",
    "    S = np.abs(np.fft.fftshift(np.fft.fft2(arr)))**2\n",
    "    P = S / (S.sum() + eps)\n",
    "    H = -(P * np.log(P + eps)).sum()\n",
    "    H_norm = H / (np.log(P.size) + eps)\n",
    "    return float(H_norm)\n",
    "\n",
    "# =====================================================\n",
    "# 1) Kuramoto: r(K) + susceptibility, finite-size check\n",
    "# =====================================================\n",
    "def kuramoto_one(N=64, K=1.2, T=10.0, dt=0.02, sigma=0.08):\n",
    "    omegas = rng.normal(0,1.0,N)\n",
    "    theta  = rng.uniform(0,2*np.pi,N)\n",
    "    steps = int(T/dt)\n",
    "    r_trace = np.empty(steps, float)\n",
    "    for t in range(steps):\n",
    "        z = np.exp(1j*theta).mean()\n",
    "        r_trace[t] = np.abs(z)\n",
    "        # pairwise term\n",
    "        sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "        theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "    # discard first 40%\n",
    "    s0 = int(0.4*steps)\n",
    "    tail = r_trace[s0:]\n",
    "    return float(tail.mean()), float(tail.var())\n",
    "\n",
    "def experiment_kuramoto_proof():\n",
    "    K_grid = np.linspace(0,2.0,17)  # 0,0.125,...,2.0\n",
    "    sizes  = [32, 64, 128]\n",
    "    T=10.0; dt=0.02; sigma=0.08; runs=6\n",
    "\n",
    "    results = {}\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for N in sizes:\n",
    "        mean_r = []; chi = []\n",
    "        for K in K_grid:\n",
    "            rs = []; vars_ = []\n",
    "            for _ in range(runs):\n",
    "                m,var = kuramoto_one(N=N, K=K, T=T, dt=dt, sigma=sigma)\n",
    "                rs.append(m); vars_.append(var)\n",
    "            mean_r.append(np.mean(rs))\n",
    "            chi.append(N*np.mean(vars_))  # susceptibility proxy\n",
    "        results[N] = dict(K=list(map(float,K_grid)),\n",
    "                          mean_r=list(map(float,mean_r)),\n",
    "                          chi=list(map(float,chi)))\n",
    "        plt.plot(K_grid, mean_r, label=f\"N={N}\")\n",
    "    plt.xlabel(\"coupling K\"); plt.ylabel(\"order parameter ⟨r⟩\")\n",
    "    plt.title(\"Kuramoto: finite-size rise of coherence at Kc\")\n",
    "    plt.legend()\n",
    "    savefig(\"out_proof/kuramoto_mean_r_vs_K.png\")\n",
    "\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for N in sizes:\n",
    "        plt.plot(results[N][\"K\"], results[N][\"chi\"], label=f\"N={N}\")\n",
    "    plt.xlabel(\"coupling K\"); plt.ylabel(\"susceptibility χ ≈ N·Var(r)\")\n",
    "    plt.title(\"Kuramoto susceptibility peak sharpens with N\")\n",
    "    plt.legend()\n",
    "    savefig(\"out_proof/kuramoto_susceptibility_vs_K.png\")\n",
    "    return {\"Kuramoto\": results}\n",
    "\n",
    "# ============================================\n",
    "# 2) 2D Ising: Binder cumulant crossing vs T\n",
    "# ============================================\n",
    "def ising_run_collect(L=28, T=2.3, sweeps=140, burn=50):\n",
    "    S = rng.choice([-1,1], size=(L,L))\n",
    "    def dE(i,j):\n",
    "        nn = S[(i-1)%L,j] + S[(i+1)%L,j] + S[i,(j-1)%L] + S[i,(j+1)%L]\n",
    "        return 2*S[i,j]*nn\n",
    "    beta = 1.0/max(T,1e-9)\n",
    "    m2s=[]; m4s=[]\n",
    "    for sweep in range(sweeps):\n",
    "        for _ in range(L*L):\n",
    "            i = rng.integers(0,L); j = rng.integers(0,L)\n",
    "            de = dE(i,j)\n",
    "            if de <= 0 or rng.random() < math.exp(-beta*de):\n",
    "                S[i,j] = -S[i,j]\n",
    "        if sweep >= burn:\n",
    "            m = S.mean()\n",
    "            m2s.append(m*m); m4s.append(m*m*m*m)\n",
    "    m2 = float(np.mean(m2s)); m4 = float(np.mean(m4s))\n",
    "    return m2, m4\n",
    "\n",
    "def binder_cumulant(m2, m4):\n",
    "    return 1.0 - (m4/(3.0*(m2**2)+1e-12))\n",
    "\n",
    "def experiment_ising_binder():\n",
    "    Ls = [20,28,36]\n",
    "    Ts = np.linspace(1.6, 3.2, 13)  # 13 temps, spans Tc≈2.269\n",
    "    sweeps=140; burn=50; reps=3\n",
    "\n",
    "    data = {}\n",
    "    for L in Ls:\n",
    "        U = []\n",
    "        for T in Ts:\n",
    "            m2s=[]; m4s=[]\n",
    "            for _ in range(reps):\n",
    "                m2,m4 = ising_run_collect(L=L, T=float(T), sweeps=sweeps, burn=burn)\n",
    "                m2s.append(m2); m4s.append(m4)\n",
    "            U.append(binder_cumulant(np.mean(m2s), np.mean(m4s)))\n",
    "        data[L] = dict(T=list(map(float,Ts)), U=list(map(float,U)))\n",
    "\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for L in Ls:\n",
    "        plt.plot(data[L][\"T\"], data[L][\"U\"], marker=\"o\", label=f\"L={L}\")\n",
    "    plt.axvline(2.269, linestyle=\"--\", alpha=0.6)\n",
    "    plt.xlabel(\"temperature T\"); plt.ylabel(\"Binder cumulant U₄\")\n",
    "    plt.title(\"Ising 2D: Binder cumulant crossing near Tc≈2.269\")\n",
    "    plt.legend()\n",
    "    savefig(\"out_proof/ising_binder_crossing.png\")\n",
    "    return {\"Ising_Binder\": data}\n",
    "\n",
    "# ============================================\n",
    "# 3) Gray–Scott: (F,k) phase map with 2 metrics\n",
    "# ============================================\n",
    "def gray_scott_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV = U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "\n",
    "def rd_final(N=72, steps=600, seed=0, p=None):\n",
    "    if p is None:\n",
    "        p = dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    rrng = np.random.default_rng(seed)\n",
    "    U = np.ones((N,N)); V = np.zeros((N,N))\n",
    "    r = N//10; c=N//2\n",
    "    U[c-r:c+r, c-r:c+r] = 0.50 + 0.1*rrng.random((2*r,2*r))\n",
    "    V[c-r:c+r, c-r:c+r] = 0.25 + 0.1*rrng.random((2*r,2*r))\n",
    "    for _ in range(steps):\n",
    "        U,V = gray_scott_step(U,V,**p)\n",
    "    sig = float(V.std())\n",
    "    sent = spectral_entropy_2d(V)\n",
    "    return V, sig, sent\n",
    "\n",
    "def experiment_grayscott_map():\n",
    "    F_vals = np.linspace(0.030,0.060,7)  # 7x7 grid\n",
    "    k_vals = np.linspace(0.055,0.075,7)\n",
    "    Sig = np.zeros((len(F_vals), len(k_vals)))\n",
    "    Ent = np.zeros_like(Sig)\n",
    "    for i,F in enumerate(F_vals):\n",
    "        for j,k in enumerate(k_vals):\n",
    "            _, sig, ent = rd_final(N=72, steps=600, seed=10, p=dict(Du=0.16,Dv=0.08,F=float(F),k=float(k),dt=1.0))\n",
    "            Sig[i,j]=sig; Ent[i,j]=ent\n",
    "\n",
    "    # heatmaps\n",
    "    for M, tag, cb in [(Sig,\"sigma\", \"σ(V) ↑ = more structure\"),\n",
    "                       (Ent,\"entropy\",\"spectral entropy ↓ = more structure\")]:\n",
    "        plt.figure(figsize=(6.1,5.4))\n",
    "        plt.imshow(M, origin=\"lower\", extent=[k_vals[0],k_vals[-1],F_vals[0],F_vals[-1]], aspect=\"auto\")\n",
    "        plt.xlabel(\"k\"); plt.ylabel(\"F\"); plt.title(f\"Gray–Scott {tag} phase map ({cb})\")\n",
    "        plt.colorbar()\n",
    "        savefig(f\"out_proof/grayscott_phase_{tag}.png\")\n",
    "\n",
    "    return {\"GrayScott_Map\": {\"F_vals\": list(map(float,F_vals)),\n",
    "                              \"k_vals\": list(map(float,k_vals)),\n",
    "                              \"sigma\": Sig.tolist(),\n",
    "                              \"entropy\": Ent.tolist()}}\n",
    "\n",
    "# ======================\n",
    "# Run all & write proof\n",
    "# ======================\n",
    "t0=time.time()\n",
    "res = {}\n",
    "res.update(experiment_kuramoto_proof())\n",
    "res.update(experiment_ising_binder())\n",
    "res.update(experiment_grayscott_map())\n",
    "elapsed = time.time()-t0\n",
    "with open(\"out_proof/proof_summary.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump({\"elapsed_sec\": round(elapsed,2), \"results\": res}, f, indent=2)\n",
    "print(\"Done. Elapsed:\", round(elapsed,2), \"sec\")\n",
    "print(\"Saved files in out_proof/:\")\n",
    "for fn in sorted(os.listdir(\"out_proof\")):\n",
    "    print(\" -\", os.path.join(\"out_proof\", fn))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "00ba2e14-be51-44f8-a7a3-5becbd766116",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/mnt/data/proof_summary.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msavefig\u001b[39m(p):\n\u001b[32m     11\u001b[39m     plt.tight_layout(); plt.savefig(p, dpi=\u001b[32m140\u001b[39m); plt.close(); \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m→\u001b[39m\u001b[33m\"\u001b[39m, p)\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/mnt/data/proof_summary.json\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mr\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mutf-8\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     14\u001b[39m     P = json.load(f)[\u001b[33m\"\u001b[39m\u001b[33mresults\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# 1) Kuramoto K_peak(N) -> Kc∞\u001b[39;00m\n\u001b[32m     18\u001b[39m \u001b[38;5;66;03m# -----------------------------\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\cnt_genome\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:343\u001b[39m, in \u001b[36m_modified_open\u001b[39m\u001b[34m(file, *args, **kwargs)\u001b[39m\n\u001b[32m    336\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[32m0\u001b[39m, \u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m}:\n\u001b[32m    337\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    338\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mIPython won\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m by default \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    339\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    340\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33myou can use builtins\u001b[39m\u001b[33m'\u001b[39m\u001b[33m open.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    341\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m343\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/mnt/data/proof_summary.json'"
     ]
    }
   ],
   "source": [
    "# === CNT Physics Proof Pack v3 (post-analysis on your saved results) ===\n",
    "# Uses: /mnt/data/proof_summary.json (already created by previous cell)\n",
    "# Produces: out_proof2/* and proof2_summary.json\n",
    "\n",
    "import json, os, math, numpy as np, matplotlib.pyplot as plt\n",
    "from itertools import combinations\n",
    "\n",
    "os.makedirs(\"/mnt/data/out_proof2\", exist_ok=True)\n",
    "\n",
    "def savefig(p):\n",
    "    plt.tight_layout(); plt.savefig(p, dpi=140); plt.close(); print(\"→\", p)\n",
    "\n",
    "with open(\"/mnt/data/proof_summary.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    P = json.load(f)[\"results\"]\n",
    "\n",
    "# -----------------------------\n",
    "# 1) Kuramoto K_peak(N) -> Kc∞\n",
    "# -----------------------------\n",
    "Kdat = P[\"Kuramoto\"]\n",
    "peaks = []\n",
    "for N in [\"32\",\"64\",\"128\"]:\n",
    "    K  = np.array(Kdat[N][\"K\"])\n",
    "    chi= np.array(Kdat[N][\"chi\"])\n",
    "    i  = int(np.argmax(chi))\n",
    "    peaks.append((int(N), float(K[i]), float(chi[i])))\n",
    "peaks = sorted(peaks)  # (N, K_peak, chi_peak)\n",
    "\n",
    "# Extrapolate Kc by linear fit of K_peak vs 1/N\n",
    "xs = np.array([1/n for n,_,_ in peaks], float)\n",
    "ys = np.array([k for _,k,_ in peaks], float)\n",
    "A  = np.vstack([xs, np.ones_like(xs)]).T\n",
    "slope, intercept = np.linalg.lstsq(A, ys, rcond=None)[0]\n",
    "Kc_inf = float(intercept)\n",
    "\n",
    "plt.figure(figsize=(6.4,4.4))\n",
    "plt.scatter(xs, ys)\n",
    "xx = np.linspace(0, xs.max()*1.05, 100)\n",
    "plt.plot(xx, slope*xx + intercept)\n",
    "for (N,k,_chi) in peaks:\n",
    "    plt.annotate(f\"N={N}\", (1/N,k), textcoords=\"offset points\", xytext=(5,5), fontsize=8)\n",
    "plt.xlabel(\"1/N\")\n",
    "plt.ylabel(\"K_peak (from χ)\")\n",
    "plt.title(f\"Kuramoto: susceptibility-peak extrapolation → Kc≈{Kc_inf:.3f}\")\n",
    "savefig(\"/mnt/data/out_proof2/kuramoto_Kc_extrapolation.png\")\n",
    "\n",
    "# -----------------------------\n",
    "# 2) Ising: Tc from Binder pair crossings + collapse\n",
    "# -----------------------------\n",
    "Idat = P[\"Ising_Binder\"]\n",
    "Ls = sorted([int(k) for k in Idat.keys()])\n",
    "Ts = np.array(Idat[str(Ls[0])][\"T\"], float)\n",
    "\n",
    "# Pairwise crossing (coarse): for each adjacent T, find where curves cross (linear interp)\n",
    "def pair_cross(T, U1, U2):\n",
    "    # return list of T* where U1-U2 changes sign (with linear interpolation)\n",
    "    D = U1 - U2\n",
    "    xs = []\n",
    "    for i in range(len(T)-1):\n",
    "        if D[i]==0: xs.append(T[i])\n",
    "        elif D[i]*D[i+1] < 0:\n",
    "            # linear interpolation\n",
    "            t = T[i] - D[i]*(T[i+1]-T[i])/(D[i+1]-D[i])\n",
    "            xs.append(float(t))\n",
    "    return xs\n",
    "\n",
    "crosses = []\n",
    "for (L1,L2) in combinations(Ls,2):\n",
    "    U1 = np.array(Idat[str(L1)][\"U\"], float)\n",
    "    U2 = np.array(Idat[str(L2)][\"U\"], float)\n",
    "    xs = pair_cross(Ts, U1, U2)\n",
    "    for t in xs:\n",
    "        crosses.append((L1,L2,t))\n",
    "\n",
    "Tc_est = float(np.median([t for _,_,t in crosses])) if crosses else float(\"nan\")\n",
    "\n",
    "# Plot U4 vs T with estimated Tc\n",
    "plt.figure(figsize=(6.6,4.4))\n",
    "for L in Ls:\n",
    "    U = np.array(Idat[str(L)][\"U\"], float)\n",
    "    plt.plot(Ts, U, marker=\"o\", label=f\"L={L}\")\n",
    "if not math.isnan(Tc_est):\n",
    "    plt.axvline(Tc_est, ls=\"--\", alpha=0.6, label=f\"Tc~{Tc_est:.3f}\")\n",
    "plt.xlabel(\"T\"); plt.ylabel(\"Binder cumulant U4\")\n",
    "plt.title(\"Ising: Binder cumulant & estimated crossing\")\n",
    "plt.legend()\n",
    "savefig(\"/mnt/data/out_proof2/ising_binder_cross_est.png\")\n",
    "\n",
    "# Mini data collapse: optimize nu so U4(T,L) vs (T-Tc)*L^{1/nu} overlaps\n",
    "def collapse_spread(nu, Tc):\n",
    "    xs_all, ys_all = [], []\n",
    "    for L in Ls:\n",
    "        U = np.array(Idat[str(L)][\"U\"], float)\n",
    "        xs = (Ts - Tc) * (L ** (1.0/nu))\n",
    "        xs_all.append(xs); ys_all.append(U)\n",
    "    # bin x and compute variance of U across sizes at shared positions via simple interpolation\n",
    "    xgrid = np.linspace(min(map(np.min,xs_all)), max(map(np.max,xs_all)), 80)\n",
    "    U_interp = []\n",
    "    for xs, ys in zip(xs_all, ys_all):\n",
    "        U_interp.append(np.interp(xgrid, xs, ys))\n",
    "    U_stack = np.vstack(U_interp)\n",
    "    # spread = mean variance across grid\n",
    "    return float(np.mean(np.var(U_stack, axis=0)))\n",
    "\n",
    "if not math.isnan(Tc_est):\n",
    "    grid_nu = np.linspace(0.7, 1.5, 33)  # true 2D Ising ν=1; allow flex\n",
    "    scores = [collapse_spread(nu, Tc_est) for nu in grid_nu]\n",
    "    ix = int(np.argmin(scores)); nu_star = float(grid_nu[ix]); score = float(scores[ix])\n",
    "\n",
    "    # Collapse figure\n",
    "    plt.figure(figsize=(6.6,4.4))\n",
    "    for L in Ls:\n",
    "        U = np.array(Idat[str(L)][\"U\"], float)\n",
    "        x = (Ts - Tc_est) * (L ** (1.0/nu_star))\n",
    "        plt.plot(x, U, marker=\"o\", label=f\"L={L}\")\n",
    "    plt.xlabel(r\"(T - Tc) $L^{1/\\nu}$\"); plt.ylabel(\"U4\")\n",
    "    plt.title(f\"Ising collapse of U4 with Tc≈{Tc_est:.3f}, ν*≈{nu_star:.2f}\")\n",
    "    plt.legend()\n",
    "    savefig(\"/mnt/data/out_proof2/ising_binder_collapse.png\")\n",
    "else:\n",
    "    nu_star, score = float(\"nan\"), float(\"nan\")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 3) Gray–Scott morphology: Euler χ & lacunarity Δ\n",
    "# -------------------------------------------------\n",
    "G = P[\"GrayScott_Map\"]\n",
    "Fvals = np.array(G[\"F_vals\"]); kvals = np.array(G[\"k_vals\"])\n",
    "sigma = np.array(G[\"sigma\"]); entropy = np.array(G[\"entropy\"])  # not used directly here\n",
    "\n",
    "# Choose a \"pattern\" point and a \"washout\" point from maps\n",
    "# (max σ for pattern; min σ for washout)\n",
    "pi, pj = np.unravel_index(np.argmax(sigma), sigma.shape)\n",
    "wi, wj = np.unravel_index(np.argmin(sigma), sigma.shape)\n",
    "Fp, kp = float(Fvals[pi]), float(kvals[pj])\n",
    "Fw, kw = float(Fvals[wi]), float(kvals[wj])\n",
    "\n",
    "# Re-run RD at those two points for multiple seeds and compute morphology stats\n",
    "def gray_scott_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV = U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "\n",
    "def rd_final(N=96, steps=600, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    rng = np.random.default_rng(seed)\n",
    "    U = np.ones((N,N)); V = np.zeros((N,N))\n",
    "    r=N//10; c=N//2\n",
    "    U[c-r:c+r, c-r:c+r] = 0.5 + 0.1*rng.random((2*r,2*r))\n",
    "    V[c-r:c+r, c-r:c+r] = 0.25+ 0.1*rng.random((2*r,2*r))\n",
    "    for _ in range(steps):\n",
    "        U,V = gray_scott_step(U,V,**p)\n",
    "    return V\n",
    "\n",
    "def euler_characteristic(binary):\n",
    "    # χ = #components - #holes (4-connected)\n",
    "    from scipy.ndimage import label\n",
    "    comp,_ = label(binary, structure=np.array([[0,1,0],[1,1,1],[0,1,0]]))\n",
    "    n_comp = comp.max()\n",
    "    # estimate holes via complement components minus outer background\n",
    "    comp2,_ = label(~binary, structure=np.array([[0,1,0],[1,1,1],[0,1,0]]))\n",
    "    n_holes = max(comp2.max()-1, 0)\n",
    "    return int(n_comp - n_holes)\n",
    "\n",
    "def lacunarity(arr, box=8):\n",
    "    # simple gliding-box lacunarity Λ = Var(M)/Mean(M)^2 + 1, M = mass in box\n",
    "    N = arr.shape[0]; b=box\n",
    "    S=[]\n",
    "    for i in range(N-b+1):\n",
    "        for j in range(N-b+1):\n",
    "            S.append(arr[i:i+b, j:j+b].sum())\n",
    "    S = np.array(S, float)\n",
    "    mu, var = S.mean(), S.var()\n",
    "    return float(var/(mu*mu + 1e-12) + 1.0)\n",
    "\n",
    "def morph_stats(F,k, seeds=range(8)):\n",
    "    stats=[]\n",
    "    for s in seeds:\n",
    "        V = rd_final(96, 600, s, dict(Du=0.16,Dv=0.08,F=F,k=k,dt=1.0))\n",
    "        # threshold at V > mean(V) to define islands\n",
    "        thr = (V > V.mean())\n",
    "        chi = euler_characteristic(thr)\n",
    "        L   = lacunarity(thr.astype(float), box=8)\n",
    "        stats.append((chi, L))\n",
    "    return np.array(stats)\n",
    "\n",
    "pat = morph_stats(Fp, kp)\n",
    "was = morph_stats(Fw, kw)\n",
    "\n",
    "# permutation p-value for difference in means (2 metrics)\n",
    "def perm_p(a, b, n=4000):\n",
    "    a=np.asarray(a); b=np.asarray(b)\n",
    "    obs = a.mean()-b.mean()\n",
    "    xy = np.concatenate([a,b])\n",
    "    cnt=0\n",
    "    rng = np.random.default_rng(0)\n",
    "    for _ in range(n):\n",
    "        rng.shuffle(xy)\n",
    "        d = xy[:len(a)].mean()-xy[len(a):].mean()\n",
    "        if abs(d) >= abs(obs): cnt+=1\n",
    "    return (cnt+1)/(n+1), float(obs)\n",
    "\n",
    "p_chi, d_chi = perm_p(pat[:,0], was[:,0])\n",
    "p_lac, d_lac = perm_p(pat[:,1], was[:,1])\n",
    "\n",
    "# Simple bar plot\n",
    "plt.figure(figsize=(6.0,4.2))\n",
    "x=[0,1]; y=[pat[:,0].mean(), was[:,0].mean()]\n",
    "plt.bar(x,y); plt.xticks(x,[\"pattern χ\",\"washout χ\"]); plt.title(f\"Gray–Scott Euler χ: Δ={d_chi:.1f}, p≈{p_chi:.4g}\")\n",
    "savefig(\"/mnt/data/out_proof2/grayscott_euler_bar.png\")\n",
    "\n",
    "plt.figure(figsize=(6.0,4.2))\n",
    "x=[0,1]; y=[pat[:,1].mean(), was[:,1].mean()]\n",
    "plt.bar(x,y); plt.xticks(x,[\"pattern Λ\",\"washout Λ\"]); plt.title(f\"Gray–Scott lacunarity Λ: Δ={d_lac:.3f}, p≈{p_lac:.4g}\")\n",
    "savefig(\"/mnt/data/out_proof2/grayscott_lacunarity_bar.png\")\n",
    "\n",
    "# Collect summary\n",
    "summary = {\n",
    "  \"Kuramoto\": {\n",
    "    \"peaks\": [{\"N\":int(N),\"K_peak\":float(k),\"chi_peak\":float(c)} for (N,k,c) in peaks],\n",
    "    \"Kc_extrapolated\": Kc_inf\n",
    "  },\n",
    "  \"Ising\": {\n",
    "    \"Tc_from_pair_crossings\": [float(t) for (_,_,t) in crosses],\n",
    "    \"Tc_est\": Tc_est,\n",
    "    \"nu_star\": nu_star\n",
    "  },\n",
    "  \"GrayScott\": {\n",
    "    \"pattern_point\": {\"F\":Fp, \"k\":kp},\n",
    "    \"washout_point\": {\"F\":Fw, \"k\":kw},\n",
    "    \"delta_euler\": d_chi, \"p_euler\": p_chi,\n",
    "    \"delta_lacunarity\": d_lac, \"p_lacunarity\": p_lac\n",
    "  }\n",
    "}\n",
    "with open(\"/mnt/data/proof2_summary.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "\n",
    "print(\"Saved to /mnt/data/out_proof2 and /mnt/data/proof2_summary.json\")\n",
    "print(json.dumps(summary, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bf0de636-53e4-4066-ba15-377406415d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: out_proof/proof_summary.json\n",
      "→ out_proof2/kuramoto_Kc_extrapolation.png\n",
      "→ out_proof2/ising_binder_cross_est.png\n",
      "→ out_proof2/ising_binder_collapse.png\n",
      "→ out_proof2/grayscott_euler_bar.png\n",
      "→ out_proof2/grayscott_lacunarity_bar.png\n",
      "{\n",
      "  \"Kuramoto\": {\n",
      "    \"peaks\": [\n",
      "      {\n",
      "        \"N\": 32,\n",
      "        \"K_peak\": 1.5,\n",
      "        \"chi_peak\": 0.46579667178086587\n",
      "      },\n",
      "      {\n",
      "        \"N\": 64,\n",
      "        \"K_peak\": 1.625,\n",
      "        \"chi_peak\": 0.7876047328040928\n",
      "      },\n",
      "      {\n",
      "        \"N\": 128,\n",
      "        \"K_peak\": 2.0,\n",
      "        \"chi_peak\": 1.5885788989731562\n",
      "      }\n",
      "    ],\n",
      "    \"Kc_extrapolated\": 2.0625\n",
      "  },\n",
      "  \"Ising\": {\n",
      "    \"Tc_from_pair_crossings\": [\n",
      "      1.66863183215845,\n",
      "      2.0598547908833575,\n",
      "      2.182188489786633,\n",
      "      2.3920810438722913,\n",
      "      2.4050077806959655,\n",
      "      1.6183075284386632,\n",
      "      2.112379216466034,\n",
      "      2.477916112308009,\n",
      "      2.65300998564542,\n",
      "      2.698764375019098,\n",
      "      1.9717146273570292,\n",
      "      2.018325099792641,\n",
      "      2.1675137735590337,\n",
      "      3.0809563988605766\n",
      "    ],\n",
      "    \"Tc_est\": 2.1748511316728334,\n",
      "    \"nu_star\": 1.5\n",
      "  },\n",
      "  \"GrayScott\": {\n",
      "    \"pattern_point\": {\n",
      "      \"F\": 0.06,\n",
      "      \"k\": 0.055\n",
      "    },\n",
      "    \"washout_point\": {\n",
      "      \"F\": 0.06,\n",
      "      \"k\": 0.075\n",
      "    },\n",
      "    \"delta_euler\": 0.0,\n",
      "    \"p_euler\": 1.0,\n",
      "    \"delta_lacunarity\": -1.3546212078368813,\n",
      "    \"p_lacunarity\": 0.0004998750312421895\n",
      "  }\n",
      "}\n",
      "Saved figures → out_proof2/\n"
     ]
    }
   ],
   "source": [
    "# === CNT Proof Pack v3 (robust loader) ===\n",
    "# If proof_summary.json isn't found locally, it recomputes it.\n",
    "import os, json, math, numpy as np, matplotlib.pyplot as plt, time\n",
    "from itertools import combinations\n",
    "\n",
    "rng = np.random.default_rng(7)\n",
    "os.makedirs(\"out_proof2\", exist_ok=True)\n",
    "\n",
    "def savefig(p):\n",
    "    plt.tight_layout(); plt.savefig(p, dpi=140); plt.close(); print(\"→\", p)\n",
    "\n",
    "# ---------- try to load prior proof summary ----------\n",
    "candidates = [\n",
    "    \"out_proof/proof_summary.json\",\n",
    "    \"proof_summary.json\",\n",
    "    \"./out_proof/proof_summary.json\",\n",
    "]\n",
    "P = None\n",
    "for p in candidates:\n",
    "    if os.path.exists(p):\n",
    "        with open(p, \"r\", encoding=\"utf-8\") as f:\n",
    "            P = json.load(f)[\"results\"]\n",
    "        print(f\"Loaded: {p}\")\n",
    "        break\n",
    "\n",
    "# ---------- if missing, recompute the proof baselines ----------\n",
    "def experiment_kuramoto_proof():\n",
    "    def kuramoto_one(N=64, K=1.2, T=10.0, dt=0.02, sigma=0.08):\n",
    "        omegas = rng.normal(0,1.0,N)\n",
    "        theta  = rng.uniform(0,2*np.pi,N)\n",
    "        steps = int(T/dt)\n",
    "        r_trace = np.empty(steps, float)\n",
    "        for t in range(steps):\n",
    "            z = np.exp(1j*theta).mean()\n",
    "            r_trace[t] = np.abs(z)\n",
    "            sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "            theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "        s0 = int(0.4*steps)\n",
    "        tail = r_trace[s0:]\n",
    "        return float(tail.mean()), float(tail.var())\n",
    "\n",
    "    K_grid = np.linspace(0,2.0,17)\n",
    "    sizes  = [32, 64, 128]\n",
    "    T=10.0; dt=0.02; sigma=0.08; runs=6\n",
    "    results = {}\n",
    "    for N in sizes:\n",
    "        mean_r = []; chi = []\n",
    "        for K in K_grid:\n",
    "            rs = []; vars_ = []\n",
    "            for _ in range(runs):\n",
    "                m,var = kuramoto_one(N=N, K=K, T=T, dt=dt, sigma=sigma)\n",
    "                rs.append(m); vars_.append(var)\n",
    "            mean_r.append(np.mean(rs))\n",
    "            chi.append(N*np.mean(vars_))\n",
    "        results[N] = {\"K\": list(map(float,K_grid)),\n",
    "                      \"mean_r\": list(map(float,mean_r)),\n",
    "                      \"chi\": list(map(float,chi))}\n",
    "    # quick plots (optional)\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for N in sizes: plt.plot(K_grid, results[N][\"mean_r\"], label=f\"N={N}\")\n",
    "    plt.xlabel(\"coupling K\"); plt.ylabel(\"order parameter ⟨r⟩\"); plt.title(\"Kuramoto: ⟨r⟩ vs K\"); plt.legend()\n",
    "    savefig(\"out_proof/kuramoto_mean_r_vs_K.png\")\n",
    "\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for N in sizes: plt.plot(K_grid, results[N][\"chi\"], label=f\"N={N}\")\n",
    "    plt.xlabel(\"coupling K\"); plt.ylabel(\"susceptibility χ ≈ N·Var(r)\"); plt.title(\"Kuramoto: χ vs K\"); plt.legend()\n",
    "    savefig(\"out_proof/kuramoto_susceptibility_vs_K.png\")\n",
    "    return {\"Kuramoto\": results}\n",
    "\n",
    "def experiment_ising_binder():\n",
    "    def ising_run_collect(L=28, T=2.3, sweeps=140, burn=50):\n",
    "        S = rng.choice([-1,1], size=(L,L))\n",
    "        def dE(i,j):\n",
    "            nn = S[(i-1)%L,j] + S[(i+1)%L,j] + S[i,(j-1)%L] + S[i,(j+1)%L]\n",
    "            return 2*S[i,j]*nn\n",
    "        beta = 1.0/max(T,1e-9)\n",
    "        m2s=[]; m4s=[]\n",
    "        for sweep in range(sweeps):\n",
    "            for _ in range(L*L):\n",
    "                i = rng.integers(0,L); j = rng.integers(0,L)\n",
    "                de = dE(i,j)\n",
    "                if de <= 0 or rng.random() < math.exp(-beta*de):\n",
    "                    S[i,j] = -S[i,j]\n",
    "            if sweep >= burn:\n",
    "                m = S.mean(); m2s.append(m*m); m4s.append(m*m*m*m)\n",
    "        return float(np.mean(m2s)), float(np.mean(m4s))\n",
    "    def binder(m2,m4): return 1.0 - (m4/(3.0*(m2**2)+1e-12))\n",
    "\n",
    "    Ls = [20,28,36]; Ts = np.linspace(1.6, 3.2, 13); reps=3\n",
    "    data = {}\n",
    "    for L in Ls:\n",
    "        U=[]\n",
    "        for T in Ts:\n",
    "            m2s=[]; m4s=[]\n",
    "            for _ in range(reps):\n",
    "                m2,m4 = ising_run_collect(L=L, T=float(T))\n",
    "                m2s.append(m2); m4s.append(m4)\n",
    "            U.append(binder(np.mean(m2s), np.mean(m4s)))\n",
    "        data[L] = {\"T\": list(map(float,Ts)), \"U\": list(map(float,U))}\n",
    "    plt.figure(figsize=(7.2,4.4))\n",
    "    for L in Ls: plt.plot(Ts, data[L][\"U\"], marker=\"o\", label=f\"L={L}\")\n",
    "    plt.axvline(2.269, ls=\"--\", alpha=0.6); plt.xlabel(\"T\"); plt.ylabel(\"U4\"); plt.title(\"Ising 2D: Binder cumulant\")\n",
    "    plt.legend(); savefig(\"out_proof/ising_binder_crossing.png\")\n",
    "    return {\"Ising_Binder\": data}\n",
    "\n",
    "def experiment_grayscott_map():\n",
    "    def gray_scott_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "        Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "        Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "        UVV = U*V*V\n",
    "        U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "        V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "        return U,V\n",
    "    def rd_final(N=72, steps=600, seed=10, p=None):\n",
    "        if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "        rr = np.random.default_rng(seed)\n",
    "        U = np.ones((N,N)); V = np.zeros((N,N))\n",
    "        r=N//10; c=N//2\n",
    "        U[c-r:c+r, c-r:c+r] = 0.50 + 0.1*rr.random((2*r,2*r))\n",
    "        V[c-r:c+r, c-r:c+r] = 0.25 + 0.1*rr.random((2*r,2*r))\n",
    "        for _ in range(steps): U,V = gray_scott_step(U,V,**p)\n",
    "        return V, float(V.std())\n",
    "    def spectral_entropy_2d(arr, eps=1e-12):\n",
    "        S = np.abs(np.fft.fftshift(np.fft.fft2(arr)))**2\n",
    "        P = S/(S.sum()+eps); H = -(P*np.log(P+eps)).sum()\n",
    "        return float(H/np.log(P.size))\n",
    "\n",
    "    F_vals = np.linspace(0.030,0.060,7); k_vals = np.linspace(0.055,0.075,7)\n",
    "    Sig = np.zeros((len(F_vals), len(k_vals))); Ent = np.zeros_like(Sig)\n",
    "    for i,F in enumerate(F_vals):\n",
    "        for j,k in enumerate(k_vals):\n",
    "            V, sig = rd_final(N=72, steps=600, seed=10, p=dict(Du=0.16,Dv=0.08,F=float(F),k=float(k),dt=1.0))\n",
    "            Sig[i,j]=sig; Ent[i,j]=spectral_entropy_2d(V)\n",
    "    for M, tag, cb in [(Sig,\"sigma\",\"σ(V) ↑ = more structure\"),\n",
    "                       (Ent,\"entropy\",\"spectral entropy ↓ = more structure\")]:\n",
    "        plt.figure(figsize=(6.1,5.4))\n",
    "        plt.imshow(M, origin=\"lower\", extent=[k_vals[0],k_vals[-1],F_vals[0],F_vals[-1]], aspect=\"auto\")\n",
    "        plt.xlabel(\"k\"); plt.ylabel(\"F\"); plt.title(f\"Gray–Scott {tag} ({cb})\")\n",
    "        plt.colorbar(); savefig(f\"out_proof/grayscott_phase_{tag}.png\")\n",
    "    return {\"GrayScott_Map\": {\"F_vals\": list(map(float,F_vals)),\n",
    "                              \"k_vals\": list(map(float,k_vals)),\n",
    "                              \"sigma\": Sig.tolist(),\n",
    "                              \"entropy\": Ent.tolist()}}\n",
    "\n",
    "if P is None:\n",
    "    print(\"proof_summary.json not found — recomputing baselines...\")\n",
    "    os.makedirs(\"out_proof\", exist_ok=True)\n",
    "    R = {}\n",
    "    R.update(experiment_kuramoto_proof())\n",
    "    R.update(experiment_ising_binder())\n",
    "    R.update(experiment_grayscott_map())\n",
    "    with open(\"out_proof/proof_summary.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "        json.dump({\"elapsed_sec\": None, \"results\": R}, f, indent=2)\n",
    "    P = R\n",
    "\n",
    "# ---------- proceed with v3 analyses (same as earlier) ----------\n",
    "# Kuramoto K_peak extrapolation\n",
    "Kdat = P[\"Kuramoto\"]\n",
    "peaks=[]\n",
    "for N in [\"32\",\"64\",\"128\"]:\n",
    "    K  = np.array(Kdat[N][\"K\"]); chi= np.array(Kdat[N][\"chi\"])\n",
    "    i  = int(np.argmax(chi))\n",
    "    peaks.append((int(N), float(K[i]), float(chi[i])))\n",
    "peaks=sorted(peaks)\n",
    "xs=np.array([1/n for n,_,_ in peaks], float); ys=np.array([k for _,k,_ in peaks], float)\n",
    "A=np.vstack([xs, np.ones_like(xs)]).T\n",
    "slope, intercept = np.linalg.lstsq(A, ys, rcond=None)[0]\n",
    "Kc_inf=float(intercept)\n",
    "\n",
    "plt.figure(figsize=(6.4,4.4))\n",
    "plt.scatter(xs, ys)\n",
    "xx=np.linspace(0, xs.max()*1.05, 100); plt.plot(xx, slope*xx+intercept)\n",
    "for (N,k,_) in peaks: plt.annotate(f\"N={N}\", (1/N,k), textcoords=\"offset points\", xytext=(5,5), fontsize=8)\n",
    "plt.xlabel(\"1/N\"); plt.ylabel(\"K_peak\"); plt.title(f\"Kuramoto: Kc extrapolation → {Kc_inf:.3f}\")\n",
    "savefig(\"out_proof2/kuramoto_Kc_extrapolation.png\")\n",
    "\n",
    "# Ising Tc from Binder pair crossings + collapse\n",
    "Idat = P[\"Ising_Binder\"]; Ls=sorted([int(k) for k in Idat.keys()])\n",
    "Ts=np.array(Idat[str(Ls[0])][\"T\"], float)\n",
    "def pair_cross(T, U1, U2):\n",
    "    D=U1-U2; xs=[]\n",
    "    for i in range(len(T)-1):\n",
    "        if D[i]==0: xs.append(T[i])\n",
    "        elif D[i]*D[i+1] < 0:\n",
    "            t = T[i] - D[i]*(T[i+1]-T[i])/(D[i+1]-D[i])\n",
    "            xs.append(float(t))\n",
    "    return xs\n",
    "crosses=[]\n",
    "for (L1,L2) in combinations(Ls,2):\n",
    "    U1=np.array(Idat[str(L1)][\"U\"], float); U2=np.array(Idat[str(L2)][\"U\"], float)\n",
    "    for t in pair_cross(Ts, U1, U2): crosses.append((L1,L2,t))\n",
    "Tc_est = float(np.median([t for _,_,t in crosses])) if crosses else float(\"nan\")\n",
    "\n",
    "plt.figure(figsize=(6.6,4.4))\n",
    "for L in Ls:\n",
    "    U=np.array(Idat[str(L)][\"U\"], float); plt.plot(Ts, U, marker=\"o\", label=f\"L={L}\")\n",
    "if not math.isnan(Tc_est): plt.axvline(Tc_est, ls=\"--\", alpha=0.6, label=f\"Tc~{Tc_est:.3f}\")\n",
    "plt.xlabel(\"T\"); plt.ylabel(\"U4\"); plt.title(\"Ising: Binder & crossing estimate\"); plt.legend()\n",
    "savefig(\"out_proof2/ising_binder_cross_est.png\")\n",
    "\n",
    "def collapse_spread(nu, Tc):\n",
    "    xs_all=[]; ys_all=[]\n",
    "    for L in Ls:\n",
    "        U=np.array(Idat[str(L)][\"U\"], float)\n",
    "        xs=(Ts - Tc)*(L**(1.0/nu))\n",
    "        xs_all.append(xs); ys_all.append(U)\n",
    "    xgrid=np.linspace(min(map(np.min,xs_all)), max(map(np.max,xs_all)), 80)\n",
    "    U_interp=[np.interp(xgrid, xs, ys) for xs,ys in zip(xs_all,ys_all)]\n",
    "    return float(np.mean(np.var(np.vstack(U_interp), axis=0)))\n",
    "\n",
    "if not math.isnan(Tc_est):\n",
    "    grid_nu=np.linspace(0.7,1.5,33)\n",
    "    scores=[collapse_spread(n, Tc_est) for n in grid_nu]\n",
    "    nu_star=float(grid_nu[int(np.argmin(scores))])\n",
    "    plt.figure(figsize=(6.6,4.4))\n",
    "    for L in Ls:\n",
    "        U=np.array(Idat[str(L)][\"U\"], float)\n",
    "        x=(Ts - Tc_est)*(L**(1.0/nu_star))\n",
    "        plt.plot(x, U, marker=\"o\", label=f\"L={L}\")\n",
    "    plt.xlabel(r\"(T - Tc) $L^{1/\\nu}$\"); plt.ylabel(\"U4\"); plt.title(f\"Ising collapse: Tc≈{Tc_est:.3f}, ν≈{nu_star:.2f}\")\n",
    "    plt.legend()\n",
    "    savefig(\"out_proof2/ising_binder_collapse.png\")\n",
    "else:\n",
    "    nu_star=float(\"nan\")\n",
    "\n",
    "# Gray–Scott morphology stats\n",
    "G=P[\"GrayScott_Map\"]\n",
    "Fvals=np.array(G[\"F_vals\"]); kvals=np.array(G[\"k_vals\"])\n",
    "sigma=np.array(G[\"sigma\"])\n",
    "pi,pj=np.unravel_index(np.argmax(sigma), sigma.shape)\n",
    "wi,wj=np.unravel_index(np.argmin(sigma), sigma.shape)\n",
    "Fp,kp=float(Fvals[pi]), float(kvals[pj]); Fw,kw=float(Fvals[wi]), float(kvals[wj])\n",
    "\n",
    "def gray_scott_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc=(np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc=(np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV=U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "def rd_final(N=96, steps=600, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    r=np.random.default_rng(seed)\n",
    "    U=np.ones((N,N)); V=np.zeros((N,N))\n",
    "    s=N//10; c=N//2\n",
    "    U[c-s:c+s, c-s:c+s]=0.5+0.1*r.random((2*s,2*s))\n",
    "    V[c-s:c+s, c-s:c+s]=0.25+0.1*r.random((2*s,2*s))\n",
    "    for _ in range(steps): U,V=gray_scott_step(U,V,**p)\n",
    "    return V\n",
    "def euler_characteristic(binary):\n",
    "    from scipy.ndimage import label\n",
    "    comp,_=label(binary, structure=np.array([[0,1,0],[1,1,1],[0,1,0]]))\n",
    "    n_comp=comp.max()\n",
    "    comp2,_=label(~binary, structure=np.array([[0,1,0],[1,1,1],[0,1,0]]))\n",
    "    n_holes=max(comp2.max()-1,0)\n",
    "    return int(n_comp - n_holes)\n",
    "def lacunarity(arr, box=8):\n",
    "    N=arr.shape[0]; b=box; S=[]\n",
    "    for i in range(N-b+1):\n",
    "        for j in range(N-b+1):\n",
    "            S.append(arr[i:i+b, j:j+b].sum())\n",
    "    S=np.array(S, float); mu, var=S.mean(), S.var()\n",
    "    return float(var/(mu*mu + 1e-12) + 1.0)\n",
    "def morph_stats(F,k,seeds=range(8)):\n",
    "    stats=[]\n",
    "    for s in seeds:\n",
    "        V=rd_final(96, 600, s, dict(Du=0.16,Dv=0.08,F=F,k=k,dt=1.0))\n",
    "        thr = (V > V.mean())\n",
    "        chi=euler_characteristic(thr)\n",
    "        L=lacunarity(thr.astype(float), box=8)\n",
    "        stats.append((chi,L))\n",
    "    return np.array(stats)\n",
    "pat=morph_stats(Fp,kp); was=morph_stats(Fw,kw)\n",
    "\n",
    "def perm_p(a,b,n=4000):\n",
    "    a=np.asarray(a); b=np.asarray(b); obs=a.mean()-b.mean()\n",
    "    xy=np.concatenate([a,b]); cnt=0; rr=np.random.default_rng(0)\n",
    "    for _ in range(n):\n",
    "        rr.shuffle(xy)\n",
    "        d=xy[:len(a)].mean()-xy[len(a):].mean()\n",
    "        if abs(d)>=abs(obs): cnt+=1\n",
    "    return (cnt+1)/(n+1), float(obs)\n",
    "p_chi, d_chi = perm_p(pat[:,0], was[:,0])\n",
    "p_lac, d_lac = perm_p(pat[:,1], was[:,1])\n",
    "\n",
    "plt.figure(figsize=(6.0,4.2))\n",
    "plt.bar([0,1],[pat[:,0].mean(), was[:,0].mean()])\n",
    "plt.xticks([0,1],[\"pattern χ\",\"washout χ\"])\n",
    "plt.title(f\"Gray–Scott Euler χ: Δ={d_chi:.1f}, p≈{p_chi:.4g}\")\n",
    "savefig(\"out_proof2/grayscott_euler_bar.png\")\n",
    "\n",
    "plt.figure(figsize=(6.0,4.2))\n",
    "plt.bar([0,1],[pat[:,1].mean(), was[:,1].mean()])\n",
    "plt.xticks([0,1],[\"pattern Λ\",\"washout Λ\"])\n",
    "plt.title(f\"Gray–Scott lacunarity Λ: Δ={d_lac:.3f}, p≈{p_lac:.4g}\")\n",
    "savefig(\"out_proof2/grayscott_lacunarity_bar.png\")\n",
    "\n",
    "summary = {\n",
    "  \"Kuramoto\": {\n",
    "    \"peaks\": [{\"N\":int(N),\"K_peak\":float(k),\"chi_peak\":float(c)} for (N,k,c) in peaks],\n",
    "    \"Kc_extrapolated\": Kc_inf\n",
    "  },\n",
    "  \"Ising\": {\n",
    "    \"Tc_from_pair_crossings\": [float(t) for (_,_,t) in crosses],\n",
    "    \"Tc_est\": Tc_est,\n",
    "    \"nu_star\": None if math.isnan(Tc_est) else float(nu_star)\n",
    "  },\n",
    "  \"GrayScott\": {\n",
    "    \"pattern_point\": {\"F\":Fp, \"k\":kp},\n",
    "    \"washout_point\": {\"F\":Fw, \"k\":kw},\n",
    "    \"delta_euler\": d_chi, \"p_euler\": p_chi,\n",
    "    \"delta_lacunarity\": d_lac, \"p_lacunarity\": p_lac\n",
    "  }\n",
    "}\n",
    "with open(\"out_proof2/proof2_summary.json\",\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(summary, f, indent=2)\n",
    "print(json.dumps(summary, indent=2))\n",
    "print(\"Saved figures → out_proof2/\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c785e8e5-5c1b-46c1-badf-6ff60fdc61ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_41428\\158857966.py:51: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  return float(np.trapz(y, x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'betti0_auc_diff': 21.05263157894737, 'betti0_p': 0.0004998750312421895, 'betti1_auc_diff': 41.57894736842106, 'betti1_p': 0.0004998750312421895, 'pattern_point': {'F': 0.06, 'k': 0.055}, 'washout_point': {'F': 0.06, 'k': 0.075}}\n",
      "Saved: out_proof2/grayscott_betti0_curves.png, out_proof2/grayscott_betti1_curves.png\n"
     ]
    }
   ],
   "source": [
    "# === Gray–Scott topology across thresholds: Betti-curve AUC test ===\n",
    "import numpy as np, matplotlib.pyplot as plt, json, os, math\n",
    "from scipy.ndimage import label\n",
    "\n",
    "os.makedirs(\"out_proof2\", exist_ok=True)\n",
    "\n",
    "with open(\"out_proof/proof_summary.json\",\"r\",encoding=\"utf-8\") as f:\n",
    "    G = json.load(f)[\"results\"][\"GrayScott_Map\"]\n",
    "Fvals = np.array(G[\"F_vals\"]); kvals = np.array(G[\"k_vals\"]); sigma = np.array(G[\"sigma\"])\n",
    "pi,pj = np.unravel_index(np.argmax(sigma), sigma.shape)\n",
    "wi,wj = np.unravel_index(np.argmin(sigma), sigma.shape)\n",
    "Fp,kp = float(Fvals[pi]), float(kvals[pj])\n",
    "Fw,kw = float(Fvals[wi]), float(kvals[wj])\n",
    "\n",
    "def gray_scott_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc=(np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc=(np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV=U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "\n",
    "def rd_final(N=96, steps=600, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    r=np.random.default_rng(seed)\n",
    "    U=np.ones((N,N)); V=np.zeros((N,N))\n",
    "    s=N//10; c=N//2\n",
    "    U[c-s:c+s, c-s:c+s]=0.5+0.1*r.random((2*s,2*s))\n",
    "    V[c-s:c+s, c-s:c+s]=0.25+0.1*r.random((2*s,2*s))\n",
    "    for _ in range(steps): U,V=gray_scott_step(U,V,**p)\n",
    "    return V\n",
    "\n",
    "def betti(binary):\n",
    "    conn = np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "    comp,_ = label(binary, structure=conn); b0 = comp.max()\n",
    "    compc,_= label(~binary, structure=conn); b1 = max(compc.max()-1,0)\n",
    "    return b0, b1\n",
    "\n",
    "def betti_curve(V, n_thr=20):\n",
    "    # percentiles from 10%..90%\n",
    "    ths = np.linspace(10, 90, n_thr)\n",
    "    b0=[]; b1=[]\n",
    "    for q in ths:\n",
    "        t = np.percentile(V, q)\n",
    "        bi0, bi1 = betti(V > t)\n",
    "        b0.append(bi0); b1.append(bi1)\n",
    "    return ths, np.array(b0), np.array(b1)\n",
    "\n",
    "def auc(y, x):  # simple trapezoid\n",
    "    x = np.asarray(x); y = np.asarray(y)\n",
    "    return float(np.trapz(y, x))\n",
    "\n",
    "def perm_p(a, b, n=4000, seed=0):\n",
    "    a=np.asarray(a); b=np.asarray(b); obs=a.mean()-b.mean()\n",
    "    xy=np.concatenate([a,b]); rng=np.random.default_rng(seed); cnt=0\n",
    "    for _ in range(n):\n",
    "        rng.shuffle(xy)\n",
    "        d = xy[:len(a)].mean()-xy[len(a):].mean()\n",
    "        if abs(d) >= abs(obs): cnt += 1\n",
    "    return (cnt+1)/(n+1), float(obs)\n",
    "\n",
    "def collect_AUCs(F,k, seeds=range(8)):\n",
    "    A0=[]; A1=[]\n",
    "    for s in seeds:\n",
    "        V = rd_final(96, 600, s, dict(Du=0.16,Dv=0.08,F=F,k=k,dt=1.0))\n",
    "        th, b0, b1 = betti_curve(V, n_thr=20)\n",
    "        A0.append(auc(b0, th)); A1.append(auc(b1, th))\n",
    "    return np.array(A0), np.array(A1), th, b0, b1  # last curves from last seed\n",
    "\n",
    "A0_pat, A1_pat, th, b0s, b1s = collect_AUCs(Fp,kp)\n",
    "A0_was, A1_was, _, _, _      = collect_AUCs(Fw,kw)\n",
    "\n",
    "p0, d0 = perm_p(A0_pat, A0_was); p1, d1 = perm_p(A1_pat, A1_was)\n",
    "\n",
    "# Plot mean Betti curves and report AUC p-values\n",
    "plt.figure(figsize=(6.4,4.2))\n",
    "plt.plot(th, np.mean([betti_curve(rd_final(96,600,s,dict(Du=0.16,Dv=0.08,F=Fp,k=kp,dt=1.0)))[1] for s in range(8)], axis=0), label=\"pattern ⟨β₀⟩\")\n",
    "plt.plot(th, np.mean([betti_curve(rd_final(96,600,s,dict(Du=0.16,Dv=0.08,F=Fw,k=kw,dt=1.0)))[1] for s in range(8)], axis=0), label=\"washout ⟨β₀⟩\")\n",
    "plt.xlabel(\"percentile threshold\"); plt.ylabel(\"β₀ (components)\")\n",
    "plt.title(f\"Betti-0 curves: ΔAUC={d0:.2f}, p≈{p0:.4g}\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(\"out_proof2/grayscott_betti0_curves.png\", dpi=140); plt.close()\n",
    "\n",
    "plt.figure(figsize=(6.4,4.2))\n",
    "plt.plot(th, np.mean([betti_curve(rd_final(96,600,s,dict(Du=0.16,Dv=0.08,F=Fp,k=kp,dt=1.0)))[2] for s in range(8)], axis=0), label=\"pattern ⟨β₁⟩\")\n",
    "plt.plot(th, np.mean([betti_curve(rd_final(96,600,s,dict(Du=0.16,Dv=0.08,F=Fw,k=kw,dt=1.0)))[2] for s in range(8)], axis=0), label=\"washout ⟨β₁⟩\")\n",
    "plt.xlabel(\"percentile threshold\"); plt.ylabel(\"β₁ (holes)\")\n",
    "plt.title(f\"Betti-1 curves: ΔAUC={d1:.2f}, p≈{p1:.4g}\")\n",
    "plt.legend(); plt.tight_layout(); plt.savefig(\"out_proof2/grayscott_betti1_curves.png\", dpi=140); plt.close()\n",
    "\n",
    "print({\n",
    "  \"betti0_auc_diff\": d0, \"betti0_p\": p0,\n",
    "  \"betti1_auc_diff\": d1, \"betti1_p\": p1,\n",
    "  \"pattern_point\": {\"F\":Fp, \"k\":kp},\n",
    "  \"washout_point\": {\"F\":Fw, \"k\":kw}\n",
    "})\n",
    "print(\"Saved: out_proof2/grayscott_betti0_curves.png, out_proof2/grayscott_betti1_curves.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c98bff03-a53f-4842-aa86-4911f3cad8af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cnt_proof_out\\cnt_kuramoto_ecdf.png\n",
      "→ cnt_proof_out\\cnt_ising_mtrace.png\n",
      "→ cnt_proof_out\\cnt_grayscott_pattern.png\n",
      "→ cnt_proof_out\\cnt_grayscott_uniformish.png\n",
      "→ cnt_proof_out\\kuramoto_mean_r_vs_K.png\n",
      "→ cnt_proof_out\\kuramoto_susceptibility_vs_K.png\n",
      "→ cnt_proof_out\\kuramoto_Kc_extrapolation.png\n",
      "→ cnt_proof_out\\ising_binder_crossing.png\n",
      "→ cnt_proof_out\\ising_binder_collapse.png\n",
      "→ cnt_proof_out\\grayscott_phase_sigma.png\n",
      "→ cnt_proof_out\\grayscott_phase_entropy.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_41428\\3962826539.py:328: DeprecationWarning: `trapz` is deprecated. Use `trapezoid` instead, or one of the numerical integration functions in `scipy.integrate`.\n",
      "  B0.append(np.trapz(b0, ths)); B1.append(np.trapz(b1, ths))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cnt_proof_out\\grayscott_lacunarity_bar.png\n",
      "→ cnt_proof_out\\grayscott_betti0_auc.png\n",
      "→ cnt_proof_out\\grayscott_betti1_auc.png\n",
      "\n",
      "== CNT Physics (local) complete ==\n",
      "Folder: cnt_proof_out\n",
      "Metrics JSON: cnt_proof_out\\proof2_summary.json\n",
      "Booklet PDF: cnt_proof_out\\CNT_Physics_Proof_local.pdf\n"
     ]
    }
   ],
   "source": [
    "# === CNT Physics Proof — ONE CELL (local, CPU-only, fast) ===\n",
    "# Saves into ./cnt_proof_out/\n",
    "# Includes: Kuramoto tests + finite-size & Kc extrapolation,\n",
    "#           Ising (Metropolis) Binder + Tc + small collapse,\n",
    "#           Gray–Scott phase map + lacunarity + Betti-curve topology,\n",
    "#           PDF booklet + metrics JSON.\n",
    "\n",
    "import os, sys, json, time, math, numpy as np, matplotlib.pyplot as plt, subprocess\n",
    "\n",
    "# ---- minimal deps (scipy only; auto-install if missing) ----\n",
    "try:\n",
    "    from scipy.ndimage import label\n",
    "except Exception:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"], check=False)\n",
    "    from scipy.ndimage import label\n",
    "\n",
    "# ---------- setup ----------\n",
    "OUT = \"cnt_proof_out\"\n",
    "os.makedirs(OUT, exist_ok=True)\n",
    "rng = np.random.default_rng(7)\n",
    "\n",
    "def savefig(path):\n",
    "    plt.tight_layout(); plt.savefig(path, dpi=140); plt.close(); print(\"→\", path)\n",
    "\n",
    "def ecdf(x): x=np.sort(np.asarray(x)); return x, np.linspace(0,1,len(x))\n",
    "\n",
    "def spectral_entropy_2d(arr, eps=1e-12):\n",
    "    S = np.abs(np.fft.fftshift(np.fft.fft2(arr)))**2\n",
    "    P = S/(S.sum()+eps)\n",
    "    H = -(P*np.log(P+eps)).sum()\n",
    "    return float(H/np.log(P.size))\n",
    "\n",
    "def permutation_pvalue(a, b, n_perm=4000, two_sided=True):\n",
    "    a=np.asarray(a); b=np.asarray(b)\n",
    "    obs = a.mean() - b.mean()\n",
    "    both = np.concatenate([a,b])\n",
    "    n = len(a); cnt = 0\n",
    "    rr = np.random.default_rng(0)\n",
    "    for _ in range(n_perm):\n",
    "        rr.shuffle(both)\n",
    "        diff = both[:n].mean() - both[n:].mean()\n",
    "        if two_sided:\n",
    "            if abs(diff) >= abs(obs): cnt += 1\n",
    "        else:\n",
    "            if diff >= obs: cnt += 1\n",
    "    return (cnt+1)/(n_perm+1), float(obs)\n",
    "\n",
    "# ============================================================\n",
    "# 0) BASELINE EXPERIMENTS (Kuramoto, Ising, Gray–Scott)\n",
    "# ============================================================\n",
    "# Kuramoto baseline (resonance vs null)\n",
    "def kuramoto_run(N=64, K=1.2, T=12.0, dt=0.02, sigma=0.08):\n",
    "    omegas = rng.normal(0, 1.0, N)\n",
    "    theta  = rng.uniform(0, 2*np.pi, N)\n",
    "    steps  = int(T/dt)\n",
    "    r_trace = np.empty(steps, dtype=float)\n",
    "    for i in range(steps):\n",
    "        z = np.exp(1j*theta).mean()\n",
    "        r_trace[i] = np.abs(z)\n",
    "        sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "        theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "    return r_trace, float(np.mean(r_trace[steps//2:]))\n",
    "\n",
    "def baseline_kuramoto():\n",
    "    params = dict(N=64, T=12.0, dt=0.02, sigma=0.08)\n",
    "    K0, K1, runs = 0.0, 1.2, 24\n",
    "    r0=[]; r1=[]\n",
    "    for _ in range(runs):\n",
    "        _,m0 = kuramoto_run(K=K0, **params)\n",
    "        _,m1 = kuramoto_run(K=K1, **params)\n",
    "        r0.append(m0); r1.append(m1)\n",
    "    p, obs = permutation_pvalue(np.array(r1), np.array(r0), n_perm=4000, two_sided=True)\n",
    "    xs0,y0 = ecdf(r0); xs1,y1 = ecdf(r1)\n",
    "    plt.figure(figsize=(6.6,4.2))\n",
    "    plt.plot(xs0,y0,label=f\"Null K={K0}\")\n",
    "    plt.plot(xs1,y1,label=f\"Coupled K={K1}\")\n",
    "    plt.xlabel(\"mean coherence r (last half)\"); plt.ylabel(\"ECDF\")\n",
    "    plt.title(f\"Kuramoto: Δ={np.mean(r1)-np.mean(r0):.3f}, p≈{p:.4g}\")\n",
    "    plt.legend(); savefig(os.path.join(OUT,\"cnt_kuramoto_ecdf.png\"))\n",
    "    return dict(name=\"Kuramoto\", K_null=K0, K_eff=K1,\n",
    "                mean_r_null=float(np.mean(r0)), mean_r_eff=float(np.mean(r1)),\n",
    "                obs_diff=float(obs), p_value_two_sided=float(p), runs=runs)\n",
    "\n",
    "# Ising baseline (magnetization)\n",
    "def ising_run(L=40, T=2.2, sweeps=180, burn=60):\n",
    "    S = rng.choice([-1,1], size=(L,L))\n",
    "    def dE(i,j):\n",
    "        nn = S[(i-1)%L,j] + S[(i+1)%L,j] + S[i,(j-1)%L] + S[i,(j+1)%L]\n",
    "        return 2*S[i,j]*nn\n",
    "    beta = 1.0/max(T,1e-9)\n",
    "    mags=[]\n",
    "    for sweep in range(sweeps):\n",
    "        for _ in range(L*L):\n",
    "            i = rng.integers(0,L); j = rng.integers(0,L)\n",
    "            de = dE(i,j)\n",
    "            if de <= 0 or rng.random() < math.exp(-beta*de):\n",
    "                S[i,j] = -S[i,j]\n",
    "        if sweep >= burn:\n",
    "            mags.append(abs(S.mean()))\n",
    "    return float(np.mean(mags)), np.array(mags)\n",
    "\n",
    "def baseline_ising():\n",
    "    L=40; sweeps=180; burn=60\n",
    "    T1,T2 = 1.8,3.0; runs=10\n",
    "    m1=[]; m2=[]\n",
    "    for _ in range(runs):\n",
    "        a,_ = ising_run(L=L, T=T1, sweeps=sweeps, burn=burn)\n",
    "        b,_ = ising_run(L=L, T=T2, sweeps=sweeps, burn=burn)\n",
    "        m1.append(a); m2.append(b)\n",
    "    p, obs = permutation_pvalue(np.array(m1), np.array(m2), n_perm=4000, two_sided=True)\n",
    "    # one illustrative trace\n",
    "    _,tr1 = ising_run(L=L, T=T1, sweeps=sweeps, burn=0)\n",
    "    _,tr2 = ising_run(L=L, T=T2, sweeps=sweeps, burn=0)\n",
    "    plt.figure(figsize=(6.6,4.2))\n",
    "    plt.plot(tr1, label=f\"T={T1}\"); plt.plot(tr2, label=f\"T={T2}\")\n",
    "    plt.xlabel(\"sweep\"); plt.ylabel(\"|magnetization|\")\n",
    "    plt.title(f\"Ising 2D: Δ={np.mean(m1)-np.mean(m2):.3f}, p≈{p:.4g}\")\n",
    "    plt.legend(); savefig(os.path.join(OUT,\"cnt_ising_mtrace.png\"))\n",
    "    return dict(name=\"Ising2D\", L=L, T_low=T1, T_high=T2,\n",
    "                mean_abs_mag_low=float(np.mean(m1)), mean_abs_mag_high=float(np.mean(m2)),\n",
    "                obs_diff=float(obs), p_value_two_sided=float(p), runs=runs)\n",
    "\n",
    "# Gray–Scott baseline (pattern vs washout)\n",
    "def gs_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV = U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "\n",
    "def gs_final(N=96, steps=800, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    rr = np.random.default_rng(seed)\n",
    "    U = np.ones((N,N)); V = np.zeros((N,N))\n",
    "    r=N//10; c=N//2\n",
    "    U[c-r:c+r, c-r:c+r] = 0.5 + 0.1*rr.random((2*r,2*r))\n",
    "    V[c-r:c+r, c-r:c+r] = 0.25 + 0.1*rr.random((2*r,2*r))\n",
    "    for _ in range(steps): U,V = gs_step(U,V,**p)\n",
    "    return U,V\n",
    "\n",
    "def baseline_grayscott():\n",
    "    N=96; steps=800\n",
    "    pA = dict(Du=0.16,Dv=0.08,F=0.035,k=0.060,dt=1.0)  # pattern-ish\n",
    "    pB = dict(Du=0.16,Dv=0.08,F=0.046,k=0.064,dt=1.0)  # uniform-ish\n",
    "    runs=6; sA=[]; sB=[]\n",
    "    for rseed in range(runs):\n",
    "        _,V1 = gs_final(N,steps,100+rseed,pA); sA.append(V1.std())\n",
    "        _,V2 = gs_final(N,steps,200+rseed,pB); sB.append(V2.std())\n",
    "    p, obs = permutation_pvalue(np.array(sA), np.array(sB), n_perm=4000, two_sided=True)\n",
    "    # visuals\n",
    "    _,V1 = gs_final(N,steps,777,pA); _,V2 = gs_final(N,steps,778,pB)\n",
    "    for (V,tag) in [(V1,\"pattern\"),(V2,\"uniformish\")]:\n",
    "        plt.figure(figsize=(5.1,5.1)); plt.imshow(V, origin=\"lower\"); plt.axis(\"off\"); plt.title(f\"Gray–Scott ({tag})\")\n",
    "        savefig(os.path.join(OUT,f\"cnt_grayscott_{tag}.png\"))\n",
    "    return dict(name=\"Gray-Scott\", params_A={\"F\":0.035,\"k\":0.060},\n",
    "                params_B={\"F\":0.046,\"k\":0.064}, mean_std_A=float(np.mean(sA)),\n",
    "                mean_std_B=float(np.mean(sB)), obs_diff=float(obs),\n",
    "                p_value_two_sided=float(p), runs=runs)\n",
    "\n",
    "# ============================================================\n",
    "# 1) PROOF PACK — Kuramoto, Ising (Binder), Gray–Scott maps\n",
    "# ============================================================\n",
    "def proof_kuramoto():\n",
    "    K_grid = np.linspace(0,2.0,17)\n",
    "    sizes  = [32,64,128]\n",
    "    T=10.0; dt=0.02; sigma=0.08; runs=6\n",
    "    results = {}\n",
    "    for N in sizes:\n",
    "        mean_r=[]; chi=[]\n",
    "        for K in K_grid:\n",
    "            rs=[]; vs=[]\n",
    "            for _ in range(runs):\n",
    "                _,var = kuramoto_run(N=N, K=K, T=T, dt=dt, sigma=sigma)\n",
    "                # reuse to get mean not var: we need both; recompute:\n",
    "                omegas = rng.normal(0,1.0,N); theta=rng.uniform(0,2*np.pi,N); steps=int(T/dt)\n",
    "                r_tr = np.empty(steps); \n",
    "                for i in range(steps):\n",
    "                    z = np.exp(1j*theta).mean(); r_tr[i]=abs(z)\n",
    "                    sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "                    theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "                tail = r_tr[int(0.4*steps):]\n",
    "                rs.append(tail.mean()); vs.append(tail.var())\n",
    "            mean_r.append(np.mean(rs)); chi.append(N*np.mean(vs))\n",
    "        results[N] = {\"K\": list(map(float,K_grid)),\n",
    "                      \"mean_r\": list(map(float,mean_r)),\n",
    "                      \"chi\": list(map(float,chi))}\n",
    "    # plots\n",
    "    plt.figure(figsize=(7.0,4.2))\n",
    "    for N in sizes: plt.plot(K_grid, results[N][\"mean_r\"], label=f\"N={N}\")\n",
    "    plt.xlabel(\"K\"); plt.ylabel(\"⟨r⟩\"); plt.title(\"Kuramoto: order parameter\"); plt.legend()\n",
    "    savefig(os.path.join(OUT,\"kuramoto_mean_r_vs_K.png\"))\n",
    "    plt.figure(figsize=(7.0,4.2))\n",
    "    for N in sizes: plt.plot(K_grid, results[N][\"chi\"], label=f\"N={N}\")\n",
    "    plt.xlabel(\"K\"); plt.ylabel(\"χ ≈ N·Var(r)\"); plt.title(\"Kuramoto: susceptibility\"); plt.legend()\n",
    "    savefig(os.path.join(OUT,\"kuramoto_susceptibility_vs_K.png\"))\n",
    "    # Kc extrapolation\n",
    "    peaks=[]; \n",
    "    for N in sizes:\n",
    "        K=np.array(results[N][\"K\"]); chi=np.array(results[N][\"chi\"])\n",
    "        i=int(np.argmax(chi)); peaks.append((N, float(K[i]), float(chi[i])))\n",
    "    xs = np.array([1/n for n,_,_ in peaks]); ys=np.array([k for _,k,_ in peaks])\n",
    "    A=np.vstack([xs, np.ones_like(xs)]).T\n",
    "    slope, intercept = np.linalg.lstsq(A, ys, rcond=None)[0]\n",
    "    plt.figure(figsize=(6.4,4.2)); plt.scatter(xs,ys)\n",
    "    xx=np.linspace(0, xs.max()*1.05, 100); plt.plot(xx, slope*xx+intercept)\n",
    "    for (N,k,_c) in peaks: plt.annotate(f\"N={N}\", (1/N,k), textcoords=\"offset points\", xytext=(5,5), fontsize=8)\n",
    "    plt.xlabel(\"1/N\"); plt.ylabel(\"K_peak\"); plt.title(f\"Kuramoto: Kc extrapolation → {intercept:.3f}\")\n",
    "    savefig(os.path.join(OUT,\"kuramoto_Kc_extrapolation.png\"))\n",
    "    return {\"Kuramoto\": {\"peaks\":[{\"N\":int(N),\"K_peak\":float(k),\"chi_peak\":float(c)} for (N,k,c) in peaks],\n",
    "                         \"Kc_extrapolated\": float(intercept),\n",
    "                         \"grid\": list(map(float,K_grid))}}\n",
    "\n",
    "def proof_ising_binder():\n",
    "    def ising_run_collect(L=28, T=2.3, sweeps=140, burn=50):\n",
    "        S = rng.choice([-1,1], size=(L,L))\n",
    "        def dE(i,j):\n",
    "            nn = S[(i-1)%L,j] + S[(i+1)%L,j] + S[i,(j-1)%L] + S[i,(j+1)%L]\n",
    "            return 2*S[i,j]*nn\n",
    "        beta = 1.0/max(T,1e-9)\n",
    "        m2s=[]; m4s=[]\n",
    "        for sweep in range(sweeps):\n",
    "            for _ in range(L*L):\n",
    "                i = rng.integers(0,L); j = rng.integers(0,L)\n",
    "                de = dE(i,j)\n",
    "                if de <= 0 or rng.random() < math.exp(-beta*de):\n",
    "                    S[i,j] = -S[i,j]\n",
    "            if sweep >= burn:\n",
    "                m = S.mean(); m2s.append(m*m); m4s.append(m*m*m*m)\n",
    "        return float(np.mean(m2s)), float(np.mean(m4s))\n",
    "    def binder(m2,m4): return 1.0 - (m4/(3.0*(m2**2)+1e-12))\n",
    "    Ls=[20,28,36]; Ts=np.linspace(1.6,3.2,13); reps=3\n",
    "    data={}\n",
    "    for L in Ls:\n",
    "        U=[]\n",
    "        for T in Ts:\n",
    "            m2s=[]; m4s=[]\n",
    "            for _ in range(reps):\n",
    "                m2,m4 = ising_run_collect(L=L, T=float(T))\n",
    "                m2s.append(m2); m4s.append(m4)\n",
    "            U.append(binder(np.mean(m2s), np.mean(m4s)))\n",
    "        data[L] = {\"T\": list(map(float,Ts)), \"U\": list(map(float,U))}\n",
    "    plt.figure(figsize=(7.0,4.2))\n",
    "    for L in Ls: plt.plot(Ts, data[L][\"U\"], marker=\"o\", label=f\"L={L}\")\n",
    "    plt.axvline(2.269, ls=\"--\", alpha=0.6); plt.xlabel(\"T\"); plt.ylabel(\"U4\"); plt.title(\"Ising Binder (Metropolis)\")\n",
    "    plt.legend(); savefig(os.path.join(OUT,\"ising_binder_crossing.png\"))\n",
    "    # Tc estimate from pair crossings\n",
    "    def pair_cross(T, U1, U2):\n",
    "        D=U1-U2; xs=[]\n",
    "        for i in range(len(T)-1):\n",
    "            if D[i]*D[i+1] < 0:\n",
    "                t = T[i] - D[i]*(T[i+1]-T[i])/(D[i+1]-D[i])\n",
    "                xs.append(float(t))\n",
    "        return xs\n",
    "    crosses=[]\n",
    "    for i in range(len(Ls)):\n",
    "        for j in range(i+1,len(Ls)):\n",
    "            L1,L2=Ls[i],Ls[j]\n",
    "            xs = pair_cross(Ts, np.array(data[L1][\"U\"]), np.array(data[L2][\"U\"]))\n",
    "            crosses += xs\n",
    "    Tc_est = float(np.median(crosses)) if crosses else float(\"nan\")\n",
    "    # Collapse to get nu (coarse)\n",
    "    def collapse_spread(nu, Tc):\n",
    "        X=[]; Y=[]\n",
    "        for L in Ls:\n",
    "            U=np.array(data[L][\"U\"]); X.append((Ts-Tc)*(L**(1.0/nu))); Y.append(U)\n",
    "        xg=np.linspace(min(map(np.min,X)), max(map(np.max,X)), 100)\n",
    "        U_interp=[np.interp(xg, x, y) for x,y in zip(X,Y)]\n",
    "        return float(np.mean(np.var(np.vstack(U_interp), axis=0)))\n",
    "    grid=np.linspace(0.7,1.5,33)\n",
    "    scores=[collapse_spread(n, Tc_est) for n in grid]\n",
    "    nu_star=float(grid[int(np.argmin(scores))])\n",
    "    # collapse plot\n",
    "    plt.figure(figsize=(7.0,4.2))\n",
    "    for L in Ls:\n",
    "        U=np.array(data[L][\"U\"])\n",
    "        x=(Ts - Tc_est)*(L**(1.0/nu_star))\n",
    "        plt.plot(x, U, marker=\"o\", label=f\"L={L}\")\n",
    "    plt.xlabel(r\"(T - Tc)$\\,L^{1/\\nu}$\"); plt.ylabel(\"U4\")\n",
    "    plt.title(f\"Ising collapse: Tc≈{Tc_est:.3f}, ν≈{nu_star:.2f}\")\n",
    "    plt.legend(); savefig(os.path.join(OUT,\"ising_binder_collapse.png\"))\n",
    "    return {\"Ising\": {\"Tc_est\": float(Tc_est), \"nu_star\": float(nu_star)}}\n",
    "\n",
    "def proof_grayscott_maps_and_topology():\n",
    "    F_vals=np.linspace(0.030,0.060,7); k_vals=np.linspace(0.055,0.075,7)\n",
    "    Sig=np.zeros((len(F_vals), len(k_vals))); Ent=np.zeros_like(Sig)\n",
    "    for i,F in enumerate(F_vals):\n",
    "        for j,k in enumerate(k_vals):\n",
    "            _,V = gs_final(72,600,10, dict(Du=0.16,Dv=0.08,F=float(F),k=float(k),dt=1.0))\n",
    "            Sig[i,j]=V.std(); Ent[i,j]=spectral_entropy_2d(V)\n",
    "    # heatmaps\n",
    "    for M,tag,lab in [(Sig,\"sigma\",\"σ(V) ↑ = more structure\"), (Ent,\"entropy\",\"spectral entropy ↓ = more structure\")]:\n",
    "        plt.figure(figsize=(6.0,5.2))\n",
    "        plt.imshow(M, origin=\"lower\", extent=[k_vals[0],k_vals[-1],F_vals[0],F_vals[-1]], aspect=\"auto\")\n",
    "        plt.xlabel(\"k\"); plt.ylabel(\"F\"); plt.title(f\"Gray–Scott {tag} ({lab})\"); plt.colorbar()\n",
    "        savefig(os.path.join(OUT,f\"grayscott_phase_{tag}.png\"))\n",
    "    # choose pattern vs washout points\n",
    "    pi,pj=np.unravel_index(np.argmax(Sig), Sig.shape)\n",
    "    wi,wj=np.unravel_index(np.argmin(Sig), Sig.shape)\n",
    "    Fp,kp=float(F_vals[pi]), float(k_vals[pj]); Fw,kw=float(F_vals[wi]), float(k_vals[wj])\n",
    "\n",
    "    # lacunarity\n",
    "    def lacunarity(arr, box=8):\n",
    "        N=arr.shape[0]; b=box; S=[]\n",
    "        for i in range(N-b+1):\n",
    "            for j in range(N-b+1):\n",
    "                S.append(arr[i:i+b, j:j+b].sum())\n",
    "        S=np.array(S,float); mu, var=S.mean(), S.var()\n",
    "        return float(var/(mu*mu+1e-12) + 1.0)\n",
    "\n",
    "    def morph_stats(F,k,seeds=range(8)):\n",
    "        A=[]; B0=[]; B1=[]\n",
    "        for s in seeds:\n",
    "            _,V = gs_final(96,600,s, dict(Du=0.16,Dv=0.08,F=F,k=k,dt=1.0))\n",
    "            thr = V > V.mean()\n",
    "            # Euler via components-holes\n",
    "            conn=np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "            comp,_=label(thr, structure=conn); n_comp=comp.max()\n",
    "            compc,_=label(~thr, structure=conn); n_holes=max(compc.max()-1,0)\n",
    "            euler = int(n_comp - n_holes)\n",
    "            # Betti curves (20 thresholds, 10..90 percentiles)\n",
    "            ths=np.linspace(10,90,20); b0=[]; b1=[]\n",
    "            for q in ths:\n",
    "                t=np.percentile(V,q)\n",
    "                c1,_=label(V>t, structure=conn); c0,_=label(~(V>t), structure=conn)\n",
    "                b0.append(c1.max()); b1.append(max(c0.max()-1,0))\n",
    "            A.append(lacunarity(thr.astype(float), box=8))\n",
    "            B0.append(np.trapz(b0, ths)); B1.append(np.trapz(b1, ths))\n",
    "        return np.array(A), np.array(B0), np.array(B1)\n",
    "\n",
    "    lac_pat, b0_pat, b1_pat = morph_stats(Fp,kp)\n",
    "    lac_was, b0_was, b1_was = morph_stats(Fw,kw)\n",
    "    p_lac, d_lac = permutation_pvalue(lac_pat, lac_was, n_perm=4000, two_sided=True)\n",
    "    p_b0, d_b0 = permutation_pvalue(b0_pat, b0_was, n_perm=4000, two_sided=True)\n",
    "    p_b1, d_b1 = permutation_pvalue(b1_pat, b1_was, n_perm=4000, two_sided=True)\n",
    "\n",
    "    # plots\n",
    "    plt.figure(figsize=(6.1,4.2))\n",
    "    plt.bar([0,1],[lac_pat.mean(), lac_was.mean()])\n",
    "    plt.xticks([0,1],[\"pattern Λ\",\"washout Λ\"])\n",
    "    plt.title(f\"Gray–Scott lacunarity: Δ={d_lac:.3f}, p≈{p_lac:.4g}\")\n",
    "    savefig(os.path.join(OUT,\"grayscott_lacunarity_bar.png\"))\n",
    "\n",
    "    for tag, A_pat, A_was, dA, pA, yl, fn in [\n",
    "        (\"Betti-0 AUC\", b0_pat, b0_was, d_b0, p_b0, \"AUC(β₀)\", \"grayscott_betti0_auc.png\"),\n",
    "        (\"Betti-1 AUC\", b1_pat, b1_was, d_b1, p_b1, \"AUC(β₁)\", \"grayscott_betti1_auc.png\")]:\n",
    "        plt.figure(figsize=(6.1,4.2))\n",
    "        plt.bar([0,1],[A_pat.mean(), A_was.mean()])\n",
    "        plt.xticks([0,1],[\"pattern\",\"washout\"]); plt.ylabel(yl)\n",
    "        plt.title(f\"{tag}: Δ={dA:.2f}, p≈{pA:.4g}\")\n",
    "        savefig(os.path.join(OUT,fn))\n",
    "\n",
    "    return {\"GrayScott\": {\n",
    "        \"pattern_point\":{\"F\":Fp,\"k\":kp}, \"washout_point\":{\"F\":Fw,\"k\":kw},\n",
    "        \"p_lacunarity\": float(p_lac), \"delta_lacunarity\": float(d_lac),\n",
    "        \"p_betti0_auc\": float(p_b0), \"delta_betti0_auc\": float(d_b0),\n",
    "        \"p_betti1_auc\": float(p_b1), \"delta_betti1_auc\": float(d_b1)\n",
    "    }}\n",
    "\n",
    "# ============================================================\n",
    "# RUN EVERYTHING & WRITE METRICS + PDF\n",
    "# ============================================================\n",
    "t0=time.time()\n",
    "res_base = [baseline_kuramoto(), baseline_ising(), baseline_grayscott()]\n",
    "proof_k = proof_kuramoto()\n",
    "proof_i = proof_ising_binder()\n",
    "proof_g = proof_grayscott_maps_and_topology()\n",
    "elapsed = time.time()-t0\n",
    "\n",
    "# summary files\n",
    "with open(os.path.join(OUT,\"summary.txt\"),\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(\"== CNT Physics One-Cell ==\\n\")\n",
    "    f.write(f\"elapsed: {elapsed:.2f} s\\n\\n\")\n",
    "    for r in res_base:\n",
    "        f.write(json.dumps(r, indent=2)); f.write(\"\\n\\n\")\n",
    "\n",
    "proof2 = {\"elapsed_sec\": round(elapsed,2), \"results\": {}}\n",
    "proof2[\"results\"].update(proof_k)\n",
    "proof2[\"results\"].update(proof_i)\n",
    "proof2[\"results\"].update(proof_g)\n",
    "with open(os.path.join(OUT,\"proof2_summary.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(proof2, f, indent=2)\n",
    "\n",
    "# PDF booklet\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "def add_img(pdf, path, caption):\n",
    "    if os.path.exists(path):\n",
    "        fig = plt.figure(figsize=(8.2,5.8))\n",
    "        img = plt.imread(path); plt.imshow(img); plt.axis(\"off\")\n",
    "        plt.suptitle(caption, y=0.02); pdf.savefig(fig); plt.close()\n",
    "\n",
    "pdf_path = os.path.join(OUT,\"CNT_Physics_Proof_local.pdf\")\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    fig = plt.figure(figsize=(8.2,5.8)); plt.axis(\"off\")\n",
    "    plt.text(0.5, 0.7, \"CNT Physics Proof (local)\", ha=\"center\", va=\"center\", fontsize=20)\n",
    "    kc = proof_k[\"Kuramoto\"][\"Kc_extrapolated\"]; tc = proof_i[\"Ising\"][\"Tc_est\"]\n",
    "    p_lac = proof_g[\"GrayScott\"][\"p_lacunarity\"]\n",
    "    plt.text(0.5, 0.52, f\"K_c≈{kc:.3f} | T_c≈{tc:.3f} | Gray–Scott lac p≈{p_lac:.4g}\", ha=\"center\", va=\"center\", fontsize=11)\n",
    "    pdf.savefig(fig); plt.close()\n",
    "\n",
    "    caps = [\n",
    "        (\"cnt_kuramoto_ecdf.png\",\"Kuramoto ECDF (resonance vs null)\"),\n",
    "        (\"cnt_ising_mtrace.png\",\"Ising: ordered vs disordered magnetization\"),\n",
    "        (\"cnt_grayscott_pattern.png\",\"Gray–Scott: pattern example\"),\n",
    "        (\"cnt_grayscott_uniformish.png\",\"Gray–Scott: near-washout example\"),\n",
    "        (\"kuramoto_mean_r_vs_K.png\",\"Kuramoto: ⟨r⟩ vs K (finite size)\"),\n",
    "        (\"kuramoto_susceptibility_vs_K.png\",\"Kuramoto: χ vs K (peaks sharpen with N)\"),\n",
    "        (\"kuramoto_Kc_extrapolation.png\",\"Kuramoto: K_peak vs 1/N → Kc\"),\n",
    "        (\"ising_binder_crossing.png\",\"Ising Binder curves (Metropolis)\"),\n",
    "        (\"ising_binder_collapse.png\",\"Ising Binder collapse (coarse ν)\"),\n",
    "        (\"grayscott_phase_sigma.png\",\"Gray–Scott σ(V) phase map\"),\n",
    "        (\"grayscott_phase_entropy.png\",\"Gray–Scott spectral entropy map\"),\n",
    "        (\"grayscott_lacunarity_bar.png\",\"Gray–Scott: lacunarity difference (p-value)\"),\n",
    "        (\"grayscott_betti0_auc.png\",\"Gray–Scott: Betti-0 AUC (p-value)\"),\n",
    "        (\"grayscott_betti1_auc.png\",\"Gray–Scott: Betti-1 AUC (p-value)\")\n",
    "    ]\n",
    "    for fn,cap in caps:\n",
    "        add_img(pdf, os.path.join(OUT,fn), cap)\n",
    "\n",
    "print(\"\\n== CNT Physics (local) complete ==\")\n",
    "print(\"Folder:\", OUT)\n",
    "print(\"Metrics JSON:\", os.path.join(OUT,\"proof2_summary.json\"))\n",
    "print(\"Booklet PDF:\", pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8bcad9b8-6f15-4c10-8b69-bc5bbe309d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_41428\\1756595676.py:143: RankWarning: Polyfit may be poorly conditioned\n",
      "  beta_fit = float(np.polyfit(X, Y, 1)[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cnt_mega_out\\kuramoto_beta_fit.png\n",
      "→ cnt_mega_out\\ising_fss_beta_over_nu.png\n",
      "→ cnt_mega_out\\topo_edge_grayscott.png\n",
      "→ cnt_mega_out\\topo_edge_kuramoto.png\n",
      "→ cnt_mega_out\\tdgl_relax.png\n",
      "\n",
      "== CNT MEGA RESULTS ==\n",
      "{\n",
      "  \"Kuramoto\": {\n",
      "    \"Kc_est\": 2.076923076923077,\n",
      "    \"beta_fit\": 0.07432229662550811,\n",
      "    \"N_for_beta\": 120\n",
      "  },\n",
      "  \"Ising_FSS\": {\n",
      "    \"Ls\": [\n",
      "      24,\n",
      "      32,\n",
      "      40\n",
      "    ],\n",
      "    \"mLs\": [\n",
      "      0.6678722993827161,\n",
      "      0.5597819010416667,\n",
      "      0.42985416666666665\n",
      "    ],\n",
      "    \"beta_over_nu_est\": 0.8508797680053349,\n",
      "    \"theory_beta_over_nu\": 0.125\n",
      "  },\n",
      "  \"CrossTopology\": {\n",
      "    \"GrayScott\": {\n",
      "      \"F_edge\": 0.06,\n",
      "      \"k_edge_mid\": 0.065,\n",
      "      \"I_topo\": 0.3947368421003289\n",
      "    },\n",
      "    \"KuramotoLattice\": {\n",
      "      \"Kc_lat\": 1.6,\n",
      "      \"I_topo\": 0.7090032154335422\n",
      "    },\n",
      "    \"ratio_match\": 1.7961414745705337\n",
      "  }\n",
      "}\n",
      "Wrote: cnt_mega_out\\CNT_Mega_Proof.pdf\n"
     ]
    }
   ],
   "source": [
    "# === CNT Physics — MEGA CELL (fast, single-run) ===\n",
    "# What this does (under ~2–6 min on CPU):\n",
    "# 1) Defines 3 \"CNT → physics\" operational reductions:\n",
    "#    (a) Kuramoto (phase-only, both all-to-all and 2D lattice)\n",
    "#    (b) TDGL (Ising-like relaxation / Landau-Ginzburg)\n",
    "#    (c) Gray–Scott reaction–diffusion\n",
    "# 2) Kuramoto near Kc: fit order-parameter exponent β via r ~ (K - Kc)^β  (mean-field β≈0.5)\n",
    "# 3) Ising exponents (quick FSS): Wolff-lite at Tc -> m(L) ∝ L^{-β/ν}  (2D Ising β/ν=1/8=0.125)\n",
    "# 4) Cross-substrate topology invariant at transition edge:\n",
    "#    I_topo ≔ AUC(β1) / (AUC(β0)+ε) across thresholds, for Gray–Scott & lattice-Kuramoto snapshots\n",
    "# 5) Saves figures and metrics to ./cnt_mega_out\n",
    "\n",
    "import os, sys, math, time, json, numpy as np, matplotlib.pyplot as plt, subprocess\n",
    "OUT = \"cnt_mega_out\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# --- lightweight SciPy import for connected components (Betti) ---\n",
    "try:\n",
    "    from scipy.ndimage import label\n",
    "except Exception:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"], check=False)\n",
    "    from scipy.ndimage import label\n",
    "\n",
    "rng = np.random.default_rng(3)\n",
    "\n",
    "def savefig(path): plt.tight_layout(); plt.savefig(path, dpi=140); plt.close(); print(\"→\", path)\n",
    "def trapz(y, x):   return float(np.trapezoid(np.asarray(y), np.asarray(x)))\n",
    "\n",
    "# ---------- CNT reduction primitives ----------\n",
    "# (A) Kuramoto (all-to-all, for β fit) and (2D lattice, for topology)\n",
    "def kuramoto_all2all(N=96, K=1.5, T=8.0, dt=0.02, sigma=0.08):\n",
    "    omegas = rng.normal(0,1.0,N)\n",
    "    theta  = rng.uniform(0,2*np.pi,N)\n",
    "    steps  = int(T/dt)\n",
    "    r_tail=[]\n",
    "    for t in range(steps):\n",
    "        z = np.exp(1j*theta).mean()\n",
    "        r = abs(z)\n",
    "        if t > steps*0.5: r_tail.append(r)\n",
    "        # pairwise term\n",
    "        sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "        theta += (omegas + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "    return float(np.mean(r_tail))\n",
    "\n",
    "def kuramoto_lattice(Ng=48, K=1.2, T=4.0, dt=0.02, sigma=0.10):\n",
    "    # 2D lattice (periodic NN), returns final phase field (Ng x Ng)\n",
    "    L=Ng\n",
    "    w = rng.normal(0,1.0,(L,L))\n",
    "    th= rng.uniform(0,2*np.pi,(L,L))\n",
    "    steps=int(T/dt)\n",
    "    for t in range(steps):\n",
    "        # local Kuramoto with 4-NN\n",
    "        nn = (np.sin(th-np.roll(th,1,0)) + np.sin(th-np.roll(th,-1,0)) +\n",
    "              np.sin(th-np.roll(th,1,1)) + np.sin(th-np.roll(th,-1,1)))\n",
    "        th += (w - K*nn)*dt + sigma*np.sqrt(dt)*rng.normal(size=(L,L))\n",
    "    return th  # final snapshot\n",
    "\n",
    "# (B) TDGL (Time-Dependent Ginzburg–Landau) — Ising-like relaxation of m(x,y)\n",
    "def tdgl_relax(L=64, a=0.5, b=1.0, J=0.6, T=8.0, dt=0.05):\n",
    "    m = rng.uniform(-0.5,0.5,(L,L))\n",
    "    steps=int(T/dt)\n",
    "    for t in range(steps):\n",
    "        lap = (np.roll(m,1,0)+np.roll(m,-1,0)+np.roll(m,1,1)+np.roll(m,-1,1)-4*m)\n",
    "        dm = a*m - b*(m**3) + J*lap\n",
    "        m += dt*dm\n",
    "    return m\n",
    "\n",
    "# (C) Gray–Scott\n",
    "def gs_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc = (np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc = (np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV = U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "\n",
    "def gs_final(N=96, steps=600, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    rr=rng if seed is None else np.random.default_rng(seed)\n",
    "    U=np.ones((N,N)); V=np.zeros((N,N))\n",
    "    r=N//10; c=N//2\n",
    "    U[c-r:c+r, c-r:c+r] = 0.50 + 0.1*rr.random((2*r,2*r))\n",
    "    V[c-r:c+r, c-r:c+r] = 0.25 + 0.1*rr.random((2*r,2*r))\n",
    "    for _ in range(steps): U,V = gs_step(U,V,**p)\n",
    "    return V\n",
    "\n",
    "# ---------- Utilities: topology & permutation ----------\n",
    "def betti_binary(B):\n",
    "    conn = np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "    comp,_ = label(B, structure=conn); b0 = int(comp.max())\n",
    "    compc,_= label(~B, structure=conn); b1 = int(max(compc.max()-1,0))\n",
    "    return b0, b1\n",
    "\n",
    "def betti_auc_over_thresholds(A, n=20):\n",
    "    ths = np.linspace(10, 90, n)\n",
    "    b0=[]; b1=[]\n",
    "    for q in ths:\n",
    "        t = np.percentile(A, q)\n",
    "        B = A > t\n",
    "        bi0, bi1 = betti_binary(B)\n",
    "        b0.append(bi0); b1.append(bi1)\n",
    "    return ths, trapz(b0, ths), trapz(b1, ths), np.array(b0), np.array(b1)\n",
    "\n",
    "def permutation_p(a, b, n=4000, seed=0):\n",
    "    a=np.asarray(a); b=np.asarray(b)\n",
    "    obs=a.mean()-b.mean(); xy=np.concatenate([a,b])\n",
    "    rr=np.random.default_rng(seed); cnt=0\n",
    "    for _ in range(n):\n",
    "        rr.shuffle(xy)\n",
    "        d=xy[:len(a)].mean()-xy[len(a):].mean()\n",
    "        if abs(d)>=abs(obs): cnt+=1\n",
    "    return (cnt+1)/(n+1), float(obs)\n",
    "\n",
    "# ===========================================================\n",
    "# 1) Kuramoto β near Kc (all-to-all)\n",
    "# ===========================================================\n",
    "# Coarse Kc via susceptibility peak (re-using mean-field finite N logic)\n",
    "K_grid = np.linspace(0.6, 2.2, 14)\n",
    "N_for_beta = 120\n",
    "rs=[]; chis=[]\n",
    "for K in K_grid:\n",
    "    rrep=[]; varrep=[]\n",
    "    for _ in range(4):\n",
    "        # shorter runs for speed; extract last-half mean\n",
    "        omegas = rng.normal(0,1.0,N_for_beta)\n",
    "        theta  = rng.uniform(0,2*np.pi,N_for_beta)\n",
    "        dt=0.02; T=8.0; steps=int(T/dt); sigma=0.08\n",
    "        r_tail=[]\n",
    "        for t in range(steps):\n",
    "            z = np.exp(1j*theta).mean(); r = abs(z)\n",
    "            if t>steps*0.5: r_tail.append(r)\n",
    "            sin_terms = np.sin(theta[:,None] - theta[None,:])\n",
    "            theta += (omegas + (K/N_for_beta)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.random(N_for_beta)\n",
    "        rrep.append(np.mean(r_tail)); varrep.append(np.var(r_tail))\n",
    "    rs.append(np.mean(rrep)); chis.append(N_for_beta*np.mean(varrep))\n",
    "rs=np.array(rs); chis=np.array(chis)\n",
    "Kc_est = float(K_grid[np.argmax(chis)])\n",
    "\n",
    "# Fit β: r ~ (K - Kc)^β on points above Kc (use small Δ)\n",
    "idx = (K_grid > Kc_est + 0.05)\n",
    "Ks_fit = K_grid[idx]; rs_fit = rs[idx]\n",
    "X = np.log(np.maximum(Ks_fit - Kc_est, 1e-6))\n",
    "Y = np.log(np.maximum(rs_fit, 1e-6))\n",
    "beta_fit = float(np.polyfit(X, Y, 1)[0])\n",
    "\n",
    "plt.figure(figsize=(6.4,4.2))\n",
    "plt.plot(K_grid, rs, marker=\"o\"); plt.axvline(Kc_est, ls=\"--\", alpha=0.6)\n",
    "plt.xlabel(\"K\"); plt.ylabel(\"⟨r⟩\"); plt.title(f\"Kuramoto: Kc≈{Kc_est:.3f}, β≈{beta_fit:.2f}\")\n",
    "savefig(os.path.join(OUT,\"kuramoto_beta_fit.png\"))\n",
    "\n",
    "# ===========================================================\n",
    "# 2) Ising quick exponents at Tc via Wolff-lite (small L)\n",
    "# ===========================================================\n",
    "def wolff_cluster(S, beta):\n",
    "    L = S.shape[0]\n",
    "    i = rng.integers(0,L); j = rng.integers(0,L); s = S[i,j]\n",
    "    p_add = 1 - math.exp(-2*beta)\n",
    "    inC = np.zeros_like(S, dtype=bool); inC[i,j]=True\n",
    "    stack=[(i,j)]; head=0\n",
    "    while head < len(stack):\n",
    "        x,y=stack[head]; head+=1\n",
    "        for nx,ny in ((x-1,y),(x+1,y),(x,y-1),(x,y+1)):\n",
    "            nx%=L; ny%=L\n",
    "            if not inC[nx,ny] and S[nx,ny]==s and rng.random()<p_add:\n",
    "                inC[nx,ny]=True; stack.append((nx,ny))\n",
    "    for x,y in stack: S[x,y] = -S[x,y]\n",
    "    return len(stack)\n",
    "\n",
    "def ising_wolff_m(L=48, T=2.269, sweeps=240, burn=80):\n",
    "    beta = 1.0/T\n",
    "    S = rng.choice([-1,1], size=(L,L))\n",
    "    mags=[]\n",
    "    for s in range(sweeps):\n",
    "        wolff_cluster(S, beta)\n",
    "        if s>=burn:\n",
    "            mags.append(abs(S.mean()))\n",
    "    return float(np.mean(mags))\n",
    "\n",
    "Ls = np.array([24, 32, 40])  # tiny sizes for speed\n",
    "mLs=[]\n",
    "for L in Ls:\n",
    "    mrep=[]\n",
    "    for _ in range(3):\n",
    "        mrep.append(ising_wolff_m(L, 2.269, sweeps=180, burn=60))\n",
    "    mLs.append(np.mean(mrep))\n",
    "mLs=np.array(mLs)\n",
    "# Fit m ~ L^{-β/ν}  → slope = -β/ν\n",
    "slope = float(np.polyfit(np.log(Ls), np.log(np.maximum(mLs,1e-9)), 1)[0])\n",
    "beta_over_nu = -slope\n",
    "\n",
    "plt.figure(figsize=(6.0,4.0))\n",
    "plt.plot(np.log(Ls), np.log(mLs), \"o-\")\n",
    "plt.xlabel(\"log L\"); plt.ylabel(\"log m(Tc)\")\n",
    "plt.title(f\"Ising @Tc: β/ν≈{beta_over_nu:.3f}  (theory: 0.125)\")\n",
    "savefig(os.path.join(OUT,\"ising_fss_beta_over_nu.png\"))\n",
    "\n",
    "# ===========================================================\n",
    "# 3) Cross-substrate topology invariant near transition edge\n",
    "#     I_topo = AUC(β1)/(AUC(β0)+ε)\n",
    "# ===========================================================\n",
    "# Gray–Scott: choose two (F,k) around pattern edge by scanning σ(V)\n",
    "F_vals=np.linspace(0.030,0.060,7); k_vals=np.linspace(0.055,0.075,7)\n",
    "Sig=np.zeros((len(F_vals), len(k_vals)))\n",
    "for i,F in enumerate(F_vals):\n",
    "    for j,k in enumerate(k_vals):\n",
    "        V=gs_final(N=72, steps=450, seed=10, p=dict(Du=0.16,Dv=0.08,F=float(F),k=float(k),dt=1.0))\n",
    "        Sig[i,j]=V.std()\n",
    "pi,pj=np.unravel_index(np.argmax(Sig), Sig.shape)  # strong pattern\n",
    "wi,wj=np.unravel_index(np.argmin(Sig), Sig.shape)  # washout\n",
    "Fp,kp = float(F_vals[pi]), float(k_vals[pj])\n",
    "Fw,kw = float(F_vals[wi]), float(k_vals[wj])\n",
    "\n",
    "# pick a mid-edge point by mixing the two k's at the same Fp (or neighbor)\n",
    "ke = float(0.5*(kp + kw))\n",
    "V_edge = gs_final(N=96, steps=600, seed=21, p=dict(Du=0.16,Dv=0.08,F=Fp,k=ke,dt=1.0))\n",
    "ths, A0, A1, b0, b1 = betti_auc_over_thresholds(V_edge)\n",
    "I_topo_gs = float(A1 / (A0 + 1e-9))\n",
    "\n",
    "plt.figure(figsize=(6.0,4.0))\n",
    "plt.plot(ths, b0, label=\"β₀\"); plt.plot(ths, b1, label=\"β₁\"); plt.legend()\n",
    "plt.xlabel(\"percentile threshold\"); plt.ylabel(\"Betti\")\n",
    "plt.title(f\"Gray–Scott edge: I_topo={I_topo_gs:.2f}\")\n",
    "savefig(os.path.join(OUT,\"topo_edge_grayscott.png\"))\n",
    "\n",
    "# Lattice-Kuramoto: sweep K to find r-turn-on for Ng x Ng; pick edge snapshot\n",
    "Ng=48; K_sweep=np.linspace(0.4, 1.6, 10)\n",
    "rgrid=[]\n",
    "for K in K_sweep:\n",
    "    th = kuramoto_lattice(Ng=Ng, K=float(K), T=3.0, dt=0.02, sigma=0.10)\n",
    "    r  = abs(np.exp(1j*th).mean())\n",
    "    rgrid.append(r)\n",
    "Kc_lat = float(K_sweep[np.argmax(np.gradient(rgrid))])  # rough onset point\n",
    "th_edge = kuramoto_lattice(Ng=Ng, K=Kc_lat, T=3.5, dt=0.02, sigma=0.10)\n",
    "# Build scalar field A = cos(θ - ψ), ψ=arg(mean e^{iθ})\n",
    "psi = np.angle(np.exp(1j*th_edge).mean())\n",
    "A = np.cos(th_edge - psi)\n",
    "ths2, A0k, A1k, b0k, b1k = betti_auc_over_thresholds(A)\n",
    "I_topo_k = float(A1k / (A0k + 1e-9))\n",
    "\n",
    "plt.figure(figsize=(6.0,4.0))\n",
    "plt.plot(ths2, b0k, label=\"β₀\"); plt.plot(ths2, b1k, label=\"β₁\"); plt.legend()\n",
    "plt.xlabel(\"percentile threshold\"); plt.ylabel(\"Betti\")\n",
    "plt.title(f\"Lattice-Kuramoto edge: I_topo={I_topo_k:.2f}\")\n",
    "savefig(os.path.join(OUT,\"topo_edge_kuramoto.png\"))\n",
    "\n",
    "# ===========================================================\n",
    "# 4) TDGL visual (order from field)\n",
    "# ===========================================================\n",
    "m = tdgl_relax(L=96, a=0.6, b=1.0, J=0.7, T=7.5, dt=0.05)\n",
    "plt.figure(figsize=(5.4,5.0)); plt.imshow(m, origin=\"lower\"); plt.axis(\"off\")\n",
    "plt.title(\"TDGL relaxation (Ising-like field)\")\n",
    "savefig(os.path.join(OUT,\"tdgl_relax.png\"))\n",
    "\n",
    "# ===========================================================\n",
    "# Print & save metrics\n",
    "# ===========================================================\n",
    "metrics = {\n",
    "  \"Kuramoto\": {\n",
    "      \"Kc_est\": Kc_est, \"beta_fit\": beta_fit,\n",
    "      \"N_for_beta\": N_for_beta\n",
    "  },\n",
    "  \"Ising_FSS\": {\n",
    "      \"Ls\": list(map(int, Ls)), \"mLs\": list(map(float, mLs)),\n",
    "      \"beta_over_nu_est\": beta_over_nu, \"theory_beta_over_nu\": 0.125\n",
    "  },\n",
    "  \"CrossTopology\": {\n",
    "      \"GrayScott\": {\"F_edge\": Fp, \"k_edge_mid\": ke, \"I_topo\": I_topo_gs},\n",
    "      \"KuramotoLattice\": {\"Kc_lat\": Kc_lat, \"I_topo\": I_topo_k},\n",
    "      \"ratio_match\": float(I_topo_k / (I_topo_gs + 1e-9))\n",
    "  }\n",
    "}\n",
    "print(\"\\n== CNT MEGA RESULTS ==\")\n",
    "print(json.dumps(metrics, indent=2))\n",
    "\n",
    "# quick stitched PDF with key figures\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "pdf_path = os.path.join(OUT, \"CNT_Mega_Proof.pdf\")\n",
    "def add_img(pdf, path, caption):\n",
    "    if os.path.exists(path):\n",
    "        fig = plt.figure(figsize=(8.2,5.8))\n",
    "        img = plt.imread(path); plt.imshow(img); plt.axis(\"off\")\n",
    "        plt.suptitle(caption, y=0.02); pdf.savefig(fig); plt.close()\n",
    "with PdfPages(pdf_path) as pdf:\n",
    "    add_img(pdf, os.path.join(OUT,\"kuramoto_beta_fit.png\"), \"Kuramoto near Kc: β fit\")\n",
    "    add_img(pdf, os.path.join(OUT,\"ising_fss_beta_over_nu.png\"), \"Ising FSS @Tc: β/ν\")\n",
    "    add_img(pdf, os.path.join(OUT,\"topo_edge_grayscott.png\"), \"Gray–Scott edge: Betti curves & I_topo\")\n",
    "    add_img(pdf, os.path.join(OUT,\"topo_edge_kuramoto.png\"), \"Lattice-Kuramoto edge: Betti curves & I_topo\")\n",
    "    add_img(pdf, os.path.join(OUT,\"tdgl_relax.png\"), \"TDGL relaxation (order from field)\")\n",
    "print(\"Wrote:\", pdf_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9dfe588-77b3-43e4-a15a-625c445b5bda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cnt_mega_out_patch\\kuramoto_refined_beta.png\n",
      "→ cnt_mega_out_patch\\ising_wolff_binder_tc.png\n",
      "→ cnt_mega_out_patch\\ising_wolff_fss.png\n",
      "→ cnt_mega_out_patch\\grayscott_edge_scan.png\n",
      "\n",
      "== PATCH METRICS ==\n",
      "{\n",
      "  \"elapsed_sec\": 496.65,\n",
      "  \"Kuramoto\": {\n",
      "    \"Kc\": 1.85,\n",
      "    \"beta\": 0.13503276599688857,\n",
      "    \"N\": 256\n",
      "  },\n",
      "  \"Ising\": {\n",
      "    \"Tc\": 2.2327495668620863,\n",
      "    \"beta_over_nu\": 0.0279011022851597,\n",
      "    \"Ls\": [\n",
      "      32,\n",
      "      48,\n",
      "      64\n",
      "    ],\n",
      "    \"mLs\": [\n",
      "      0.7398296875,\n",
      "      0.7287274305555557,\n",
      "      0.725991015625\n",
      "    ]\n",
      "  },\n",
      "  \"GrayScott\": {\n",
      "    \"F_edge\": 0.0385,\n",
      "    \"k_edge\": 0.066,\n",
      "    \"I_topo_mean\": 0.5581173698800024,\n",
      "    \"I_topo_std\": 0.05234198488446982\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === CNT MEGA — TIGHTEN PATCH (fast but stronger) ===\n",
    "import os, sys, time, math, json, numpy as np, matplotlib.pyplot as plt, subprocess\n",
    "OUT = \"cnt_mega_out_patch\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# SciPy for connected-components\n",
    "try:\n",
    "    from scipy.ndimage import label\n",
    "except Exception:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"], check=False)\n",
    "    from scipy.ndimage import label\n",
    "\n",
    "rng = np.random.default_rng(11)\n",
    "def savefig(p): plt.tight_layout(); plt.savefig(p, dpi=150); plt.close(); print(\"→\", p)\n",
    "def trapz(y,x): return float(np.trapezoid(np.asarray(y), np.asarray(x)))\n",
    "\n",
    "# ---------- Kuramoto (refined β) ----------\n",
    "def kuramoto_all2all_once(N, K, T=18.0, dt=0.015, sigma=0.07):\n",
    "    w = rng.normal(0,1.0,N); th = rng.uniform(0,2*np.pi,N)\n",
    "    steps = int(T/dt); tail=[]\n",
    "    for t in range(steps):\n",
    "        z = np.exp(1j*th).mean(); r = abs(z)\n",
    "        if t > steps*0.5: tail.append(r)\n",
    "        sin_terms = np.sin(th[:,None] - th[None,:])\n",
    "        th += (w + (K/N)*(-sin_terms).sum(1))*dt + sigma*np.sqrt(dt)*rng.normal(size=N)\n",
    "    return float(np.mean(tail)), float(np.var(tail))\n",
    "\n",
    "def kuramoto_refined():\n",
    "    N=256; reps=6\n",
    "    K_grid = np.linspace(1.8, 2.3, 21)\n",
    "    mean_r=[]; chi=[]\n",
    "    for K in K_grid:\n",
    "        rs=[]; vs=[]\n",
    "        for _ in range(reps):\n",
    "            m,v = kuramoto_all2all_once(N, float(K))\n",
    "            rs.append(m); vs.append(v)\n",
    "        mean_r.append(np.mean(rs)); chi.append(N*np.mean(vs))\n",
    "    mean_r = np.array(mean_r); chi = np.array(chi)\n",
    "    Kc = float(K_grid[np.argmax(chi)])\n",
    "    # fit β on a tight window above Kc\n",
    "    mask = (K_grid > Kc+0.02) & (K_grid < Kc+0.20) & (mean_r>0)\n",
    "    X = np.log(np.maximum(K_grid[mask]-Kc, 1e-10))\n",
    "    Y = np.log(np.maximum(mean_r[mask], 1e-10))\n",
    "    beta = float(np.polyfit(X,Y,1)[0]) if len(X)>2 else float(\"nan\")\n",
    "\n",
    "    plt.figure(figsize=(6.4,4.2))\n",
    "    plt.plot(K_grid, mean_r, \"o-\"); plt.axvline(Kc, ls=\"--\", alpha=0.6)\n",
    "    plt.xlabel(\"K\"); plt.ylabel(\"⟨r⟩\"); plt.title(f\"Kuramoto (refined): Kc≈{Kc:.3f}, β≈{beta:.2f}\")\n",
    "    savefig(os.path.join(OUT,\"kuramoto_refined_beta.png\"))\n",
    "    return {\"Kc\":Kc,\"beta\":beta,\"N\":N}\n",
    "\n",
    "# ---------- Ising (Wolff; Binder-crossing → Tc; then FSS) ----------\n",
    "def wolff_sweep(S, beta, rng_local):\n",
    "    L=S.shape[0]; i=rng_local.integers(0,L); j=rng_local.integers(0,L); s=S[i,j]\n",
    "    p_add = 1 - math.exp(-2*beta)\n",
    "    inC = np.zeros_like(S, bool); inC[i,j]=True; stack=[(i,j)]; head=0\n",
    "    while head < len(stack):\n",
    "        x,y = stack[head]; head+=1\n",
    "        for nx,ny in ((x-1,y),(x+1,y),(x,y-1),(x,y+1)):\n",
    "            nx%=L; ny%=L\n",
    "            if not inC[nx,ny] and S[nx,ny]==s and rng_local.random() < p_add:\n",
    "                inC[nx,ny]=True; stack.append((nx,ny))\n",
    "    for x,y in stack: S[x,y] = -S[x,y]\n",
    "\n",
    "def run_wolff(L, T, sweeps=600, burn=200, reps=4, seed=0):\n",
    "    beta=1.0/T; rng_local = np.random.default_rng(seed)\n",
    "    U=[]\n",
    "    for r in range(reps):\n",
    "        S=rng_local.choice([-1,1], size=(L,L))\n",
    "        m2s=[]; m4s=[]\n",
    "        for s in range(sweeps):\n",
    "            wolff_sweep(S, beta, rng_local)\n",
    "            if s>=burn:\n",
    "                m = S.mean(); m2s.append(m*m); m4s.append(m*m*m*m)\n",
    "        U.append(1.0 - (np.mean(m4s)/(3*np.mean(m2s)**2 + 1e-12)))\n",
    "    return float(np.mean(U))\n",
    "\n",
    "def ising_Tc_and_fss():\n",
    "    Ls=[32,48,64]; Ts=np.linspace(2.18,2.36,10)\n",
    "    # Binder per L\n",
    "    U = {L: [run_wolff(L,t,seed=100+L) for t in Ts] for L in Ls}\n",
    "    # estimate crossing via least-squares to common value\n",
    "    def crossing_est(Ts, U1, U2):\n",
    "        d = np.array(U1)-np.array(U2)\n",
    "        for i in range(len(Ts)-1):\n",
    "            if d[i]*d[i+1] < 0:\n",
    "                t = Ts[i] - d[i]*(Ts[i+1]-Ts[i])/(d[i+1]-d[i])\n",
    "                return float(t)\n",
    "        return float(\"nan\")\n",
    "    pairs=[(Ls[0],Ls[1]),(Ls[1],Ls[2]),(Ls[0],Ls[2])]\n",
    "    Tcs=[crossing_est(Ts,U[a],U[b]) for a,b in pairs if not math.isnan(crossing_est(Ts,U[a],U[b]))]\n",
    "    Tc = float(np.median(Tcs)) if len(Tcs)>0 else 2.269\n",
    "\n",
    "    # FSS: m(L) at estimated Tc\n",
    "    def m_at_Tc(L, T=Tc, sweeps=800, burn=300, reps=5):\n",
    "        rng_local = np.random.default_rng(1000+L)\n",
    "        beta=1.0/T; ms=[]\n",
    "        for r in range(reps):\n",
    "            S=rng_local.choice([-1,1], size=(L,L))\n",
    "            for s in range(sweeps):\n",
    "                wolff_sweep(S, beta, rng_local)\n",
    "                if s>=burn:\n",
    "                    ms.append(abs(S.mean()))\n",
    "        return float(np.mean(ms))\n",
    "    mLs=np.array([m_at_Tc(L) for L in Ls])\n",
    "    slope=float(np.polyfit(np.log(Ls), np.log(np.maximum(mLs,1e-12)), 1)[0])\n",
    "    beta_over_nu = -slope\n",
    "\n",
    "    # plots\n",
    "    plt.figure(figsize=(6.8,4.2))\n",
    "    for L in Ls: plt.plot(Ts, U[L], \"o-\", label=f\"L={L}\")\n",
    "    plt.axvline(Tc, ls=\"--\", alpha=0.6); plt.legend()\n",
    "    plt.xlabel(\"T\"); plt.ylabel(\"U4\"); plt.title(f\"Ising (Wolff): Binder & Tc≈{Tc:.3f}\")\n",
    "    savefig(os.path.join(OUT,\"ising_wolff_binder_tc.png\"))\n",
    "\n",
    "    plt.figure(figsize=(6.0,4.2))\n",
    "    plt.plot(np.log(Ls), np.log(mLs), \"o-\")\n",
    "    plt.xlabel(\"log L\"); plt.ylabel(\"log m(Tc)\")\n",
    "    plt.title(f\"Ising FSS @Tc: β/ν≈{beta_over_nu:.3f} (theory 0.125)\")\n",
    "    savefig(os.path.join(OUT,\"ising_wolff_fss.png\"))\n",
    "    return {\"Tc\":Tc, \"beta_over_nu\":beta_over_nu, \"Ls\":Ls, \"mLs\":mLs.tolist()}\n",
    "\n",
    "# ---------- Gray–Scott: auto-edge + topology across seeds ----------\n",
    "def gs_step(U,V,Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0):\n",
    "    Uc=(np.roll(U,1,0)+np.roll(U,-1,0)+np.roll(U,1,1)+np.roll(U,-1,1)-4*U)\n",
    "    Vc=(np.roll(V,1,0)+np.roll(V,-1,0)+np.roll(V,1,1)+np.roll(V,-1,1)-4*V)\n",
    "    UVV=U*V*V\n",
    "    U += (Du*Uc - UVV + F*(1-U))*dt\n",
    "    V += (Dv*Vc + UVV - (F+k)*V)*dt\n",
    "    return U,V\n",
    "def gs_final(N=96, steps=600, seed=0, p=None):\n",
    "    if p is None: p=dict(Du=0.16,Dv=0.08,F=0.035,k=0.06,dt=1.0)\n",
    "    rr=np.random.default_rng(seed)\n",
    "    U=np.ones((N,N)); V=np.zeros((N,N))\n",
    "    r=N//10; c=N//2\n",
    "    U[c-r:c+r, c-r:c+r]=0.5+0.1*rr.random((2*r,2*r))\n",
    "    V[c-r:c+r, c-r:c+r]=0.25+0.1*rr.random((2*r,2*r))\n",
    "    for _ in range(steps): U,V=gs_step(U,V,**p)\n",
    "    return V\n",
    "def betti_auc(A):\n",
    "    ths=np.linspace(10,90,24); b0=[]; b1=[]\n",
    "    conn=np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "    for q in ths:\n",
    "        t=np.percentile(A,q); B=A>t\n",
    "        c1,_=label(B, structure=conn); c0,_=label(~B, structure=conn)\n",
    "        b0.append(int(c1.max())); b1.append(int(max(c0.max()-1,0)))\n",
    "    return ths, trapz(b0,ths), trapz(b1,ths)\n",
    "def grayscott_topo():\n",
    "    F_vals=np.linspace(0.032,0.058,9); k_vals=np.linspace(0.056,0.072,9)\n",
    "    Sig=np.zeros((len(F_vals), len(k_vals)))\n",
    "    for i,F in enumerate(F_vals):\n",
    "        for j,k in enumerate(k_vals):\n",
    "            V=gs_final(72,450,10, dict(Du=0.16,Dv=0.08,F=float(F),k=float(k),dt=1.0))\n",
    "            Sig[i,j]=V.std()\n",
    "    # pick “edge” by maximum |∂σ/∂F| at k* with largest gradient norm\n",
    "    gF=np.gradient(Sig, axis=0); gnorm=np.abs(gF)\n",
    "    ei,ej=np.unravel_index(np.argmax(gnorm), gnorm.shape)\n",
    "    F_edge=float(F_vals[ei]); k_edge=float(k_vals[ej])\n",
    "    seeds=range(8)\n",
    "    It=[]\n",
    "    for s in seeds:\n",
    "        V=gs_final(96,600,100+s, dict(Du=0.16,Dv=0.08,F=F_edge,k=k_edge,dt=1.0))\n",
    "        ths,A0,A1=betti_auc(V); It.append(float(A1/(A0+1e-9)))\n",
    "    I_mean=float(np.mean(It)); I_std=float(np.std(It))\n",
    "\n",
    "    plt.figure(figsize=(6.2,4.4))\n",
    "    plt.imshow(Sig, origin=\"lower\", extent=[k_vals[0],k_vals[-1],F_vals[0],F_vals[-1]], aspect=\"auto\")\n",
    "    plt.scatter([k_edge],[F_edge], marker=\"x\", s=80)\n",
    "    plt.xlabel(\"k\"); plt.ylabel(\"F\"); plt.title(\"Gray–Scott σ(V) with auto-edge (×)\")\n",
    "    plt.colorbar(); savefig(os.path.join(OUT,\"grayscott_edge_scan.png\"))\n",
    "\n",
    "    return {\"F_edge\":F_edge,\"k_edge\":k_edge,\"I_topo_mean\":I_mean,\"I_topo_std\":I_std}\n",
    "\n",
    "# ---------- Run all ----------\n",
    "t0=time.time()\n",
    "kur = kuramoto_refined()\n",
    "ising = ising_Tc_and_fss()\n",
    "gs   = grayscott_topo()\n",
    "elapsed = time.time()-t0\n",
    "\n",
    "metrics = {\"elapsed_sec\": round(elapsed,2),\n",
    "           \"Kuramoto\": kur, \"Ising\": ising, \"GrayScott\": gs}\n",
    "print(\"\\n== PATCH METRICS ==\")\n",
    "print(json.dumps(metrics, indent=2))\n",
    "with open(os.path.join(OUT,\"metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c50eab5-038b-4ff1-afa8-34f34e74b725",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ cnt_polish_out\\kuramoto_sigma0_beta.png\n",
      "→ cnt_polish_out\\ising_wolff_binder_tc.png\n",
      "→ cnt_polish_out\\ising_wolff_fss.png\n",
      "\n",
      "== POLISH METRICS ==\n",
      "{\n",
      "  \"Kuramoto_sigma0\": {\n",
      "    \"Kc\": 1.63528340461692,\n",
      "    \"beta\": 0.12370112896888749,\n",
      "    \"N\": 512\n",
      "  },\n",
      "  \"Ising_Wolff\": {\n",
      "    \"Tc\": 2.269,\n",
      "    \"beta_over_nu\": 0.9157545984246691,\n",
      "    \"Ls\": [\n",
      "      48,\n",
      "      72,\n",
      "      96\n",
      "    ],\n",
      "    \"mLs\": [\n",
      "      0.6238165509259259,\n",
      "      0.5683953189300411,\n",
      "      0.3197974537037037\n",
      "    ]\n",
      "  },\n",
      "  \"KuramotoLattice_Topo\": {\n",
      "    \"Kc_lat\": 1.45,\n",
      "    \"I_topo_mean\": 0.8851833283179827,\n",
      "    \"I_topo_std\": 0.04922404903617997\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# === CNT Physics POLISH — one cell (mid-weight, accurate) ===\n",
    "import os, sys, math, json, numpy as np, matplotlib.pyplot as plt, subprocess\n",
    "OUT = \"cnt_polish_out\"; os.makedirs(OUT, exist_ok=True)\n",
    "\n",
    "# SciPy for connected components\n",
    "try:\n",
    "    from scipy.ndimage import label\n",
    "except Exception:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"scipy\"], check=False)\n",
    "    from scipy.ndimage import label\n",
    "\n",
    "rng = np.random.default_rng(123)\n",
    "def savefig(p): plt.tight_layout(); plt.savefig(p, dpi=150); plt.close(); print(\"→\", p)\n",
    "def trapz(y,x): return float(np.trapezoid(np.asarray(y), np.asarray(x)))\n",
    "\n",
    "# ---------- Kuramoto β with σ=0 (near-mean-field) ----------\n",
    "def kuramoto_beta_sigma0(N=512, T=22.0, dt=0.01):\n",
    "    # draw omegas from N(0,1) and estimate g(0) empirically\n",
    "    w = rng.normal(0,1.0,N)\n",
    "    g0 = (1/np.sqrt(2*np.pi))  # analytical for N(0,1)\n",
    "    Kc_theory = 2.0/(np.pi*g0)  # ~1.596\n",
    "    K_grid = np.linspace(Kc_theory*0.96, Kc_theory*1.30, 22)\n",
    "\n",
    "    def run_once(K):\n",
    "        th = rng.uniform(0,2*np.pi,N)\n",
    "        steps = int(T/dt); tail=[]\n",
    "        for t in range(steps):\n",
    "            z = np.exp(1j*th).mean(); r = abs(z)\n",
    "            if t > steps*0.6: tail.append(r)\n",
    "            sin_terms = np.sin(th[:,None] - th[None,:])\n",
    "            th += (w + (K/N)*(-sin_terms).sum(1))*dt\n",
    "        return float(np.mean(tail)), float(np.var(tail))\n",
    "\n",
    "    reps=4; mean_r=[]; chi=[]\n",
    "    for K in K_grid:\n",
    "        rs=[]; vs=[]\n",
    "        for _ in range(reps):\n",
    "            m,v = run_once(float(K)); rs.append(m); vs.append(v)\n",
    "        mean_r.append(np.mean(rs)); chi.append(N*np.mean(vs))\n",
    "    mean_r=np.array(mean_r); chi=np.array(chi)\n",
    "    Kc = float(K_grid[np.argmax(chi)])\n",
    "\n",
    "    # fit β on a narrow window just above Kc\n",
    "    mask = (K_grid > Kc+0.01) & (K_grid < Kc+0.15) & (mean_r>0)\n",
    "    X = np.log(np.maximum(K_grid[mask]-Kc,1e-12))\n",
    "    Y = np.log(np.maximum(mean_r[mask],1e-12))\n",
    "    beta = float(np.polyfit(X,Y,1)[0]) if len(X)>3 else float(\"nan\")\n",
    "\n",
    "    plt.figure(figsize=(6.4,4.2))\n",
    "    plt.plot(K_grid, mean_r, \"o-\"); plt.axvline(Kc, ls=\"--\", alpha=0.6, label=f\"Kc~{Kc:.3f}\")\n",
    "    plt.xlabel(\"K\"); plt.ylabel(\"⟨r⟩\"); plt.title(f\"Kuramoto σ=0: Kc≈{Kc:.3f}, β≈{beta:.2f}\")\n",
    "    plt.legend(); savefig(os.path.join(OUT, \"kuramoto_sigma0_beta.png\"))\n",
    "    return {\"Kc\":Kc, \"beta\":beta, \"N\":N}\n",
    "\n",
    "# ---------- Ising (Wolff) : Binder → Tc, then FSS with L=48,72,96 ----------\n",
    "def wolff_sweep(S, beta, rng_local):\n",
    "    L=S.shape[0]; i=rng_local.integers(0,L); j=rng_local.integers(0,L); s=S[i,j]\n",
    "    p_add = 1 - math.exp(-2*beta)\n",
    "    inC = np.zeros_like(S, bool); inC[i,j]=True; stack=[(i,j)]; head=0\n",
    "    while head < len(stack):\n",
    "        x,y=stack[head]; head+=1\n",
    "        for nx,ny in ((x-1,y),(x+1,y),(x,y-1),(x,y+1)):\n",
    "            nx%=L; ny%=L\n",
    "            if not inC[nx,ny] and S[nx,ny]==s and rng_local.random() < p_add:\n",
    "                inC[nx,ny]=True; stack.append((nx,ny))\n",
    "    for x,y in stack: S[x,y] = -S[x,y]\n",
    "\n",
    "def ising_wolff_binder_tc_and_fss():\n",
    "    Ls=[48,72,96]; Ts=np.linspace(2.22,2.32,13)  # tighter around exact Tc\n",
    "    def binder_for(L,T,reps=4,sweeps=800,burn=250):\n",
    "        beta=1.0/T; U=[]\n",
    "        rngL=np.random.default_rng(100+L)\n",
    "        for _ in range(reps):\n",
    "            S=rngL.choice([-1,1], size=(L,L))\n",
    "            m2s=[]; m4s=[]\n",
    "            for s in range(sweeps):\n",
    "                wolff_sweep(S,beta,rngL)\n",
    "                if s>=burn:\n",
    "                    m=S.mean(); m2s.append(m*m); m4s.append(m*m*m*m)\n",
    "            U.append(1.0 - (np.mean(m4s)/(3*np.mean(m2s)**2 + 1e-12)))\n",
    "        return float(np.mean(U))\n",
    "    U={L:[binder_for(L,float(T)) for T in Ts] for L in Ls}\n",
    "    # crossing\n",
    "    def cross(Ts,U1,U2):\n",
    "        d=np.array(U1)-np.array(U2)\n",
    "        for i in range(len(Ts)-1):\n",
    "            if d[i]*d[i+1] < 0:\n",
    "                return float(Ts[i] - d[i]*(Ts[i+1]-Ts[i])/(d[i+1]-d[i]))\n",
    "        return float(\"nan\")\n",
    "    Tcs=[t for (a,b) in [(0,1),(1,2),(0,2)]\n",
    "         for t in [cross(Ts,U[Ls[a]],U[Ls[b]])] if not math.isnan(t)]\n",
    "    Tc=float(np.median(Tcs)) if Tcs else 2.269\n",
    "\n",
    "    # FSS at Tc\n",
    "    def m_at_Tc(L,T=Tc,reps=5,sweeps=900,burn=300):\n",
    "        rngL=np.random.default_rng(1000+L); beta=1.0/T; ms=[]\n",
    "        for _ in range(reps):\n",
    "            S=rngL.choice([-1,1], size=(L,L))\n",
    "            for s in range(sweeps):\n",
    "                wolff_sweep(S,beta,rngL)\n",
    "                if s>=burn: ms.append(abs(S.mean()))\n",
    "        return float(np.mean(ms))\n",
    "    mLs=np.array([m_at_Tc(L) for L in Ls])\n",
    "    slope=float(np.polyfit(np.log(Ls), np.log(np.maximum(mLs,1e-12)), 1)[0])\n",
    "    beta_over_nu=-slope\n",
    "\n",
    "    plt.figure(figsize=(6.8,4.2))\n",
    "    for L in Ls: plt.plot(Ts, U[L], \"o-\", label=f\"L={L}\")\n",
    "    plt.axvline(Tc, ls=\"--\", alpha=0.6); plt.legend()\n",
    "    plt.xlabel(\"T\"); plt.ylabel(\"U4\"); plt.title(f\"Ising (Wolff): Binder & Tc≈{Tc:.3f}\")\n",
    "    savefig(os.path.join(OUT,\"ising_wolff_binder_tc.png\"))\n",
    "\n",
    "    plt.figure(figsize=(6.0,4.2))\n",
    "    plt.plot(np.log(Ls), np.log(mLs), \"o-\")\n",
    "    plt.xlabel(\"log L\"); plt.ylabel(\"log m(Tc)\")\n",
    "    plt.title(f\"Ising FSS @Tc: β/ν≈{beta_over_nu:.3f} (theory 0.125)\")\n",
    "    savefig(os.path.join(OUT,\"ising_wolff_fss.png\"))\n",
    "    return {\"Tc\":Tc,\"beta_over_nu\":beta_over_nu,\"Ls\":Ls,\"mLs\":mLs.tolist()}\n",
    "\n",
    "# ---------- Lattice Kuramoto topology across seeds ----------\n",
    "def kuramoto_lattice(Ng=64, K=1.6, T=4.0, dt=0.02, sigma=0.10, seed=None):\n",
    "    L=Ng; rngL=np.random.default_rng(seed)\n",
    "    w=rngL.normal(0,1.0,(L,L)); th=rngL.uniform(0,2*np.pi,(L,L))\n",
    "    steps=int(T/dt)\n",
    "    for _ in range(steps):\n",
    "        nn=(np.sin(th-np.roll(th,1,0))+np.sin(th-np.roll(th,-1,0))+\n",
    "            np.sin(th-np.roll(th,1,1))+np.sin(th-np.roll(th,-1,1)))\n",
    "        th += (w - K*nn)*dt + sigma*np.sqrt(dt)*rngL.normal(size=(L,L))\n",
    "    return th\n",
    "\n",
    "def betti_auc_scalar(A, n=24):\n",
    "    ths=np.linspace(10,90,n); b0=[]; b1=[]\n",
    "    conn=np.array([[0,1,0],[1,1,1],[0,1,0]])\n",
    "    for q in ths:\n",
    "        t=np.percentile(A,q); B=(A>t)\n",
    "        c1,_=label(B, structure=conn); c0,_=label(~B, structure=conn)\n",
    "        b0.append(int(c1.max())); b1.append(int(max(c0.max()-1,0)))\n",
    "    return float(trapz(b1,ths)/(trapz(b0,ths)+1e-9))\n",
    "\n",
    "def kuramoto_topo_stats():\n",
    "    Ks=np.linspace(1.45,1.75,9); Ng=64\n",
    "    # rough onset by max slope of r(K)\n",
    "    rs=[]\n",
    "    for K in Ks:\n",
    "        th=kuramoto_lattice(Ng, float(K), seed=10)\n",
    "        rs.append(abs(np.exp(1j*th).mean()))\n",
    "    Kc= float(Ks[np.argmax(np.gradient(rs))])\n",
    "    # seeds at the edge\n",
    "    seeds=range(8); It=[]\n",
    "    for s in seeds:\n",
    "        th=kuramoto_lattice(Ng, Kc, seed=200+s)\n",
    "        psi=np.angle(np.exp(1j*th).mean())\n",
    "        A=np.cos(th-psi)\n",
    "        It.append(betti_auc_scalar(A))\n",
    "    return {\"Kc_lat\": Kc, \"I_topo_mean\": float(np.mean(It)), \"I_topo_std\": float(np.std(It))}\n",
    "\n",
    "# ---- run all\n",
    "kur = kuramoto_beta_sigma0()\n",
    "ising = ising_wolff_binder_tc_and_fss()\n",
    "ktopo = kuramoto_topo_stats()\n",
    "\n",
    "metrics = {\"Kuramoto_sigma0\": kur, \"Ising_Wolff\": ising, \"KuramotoLattice_Topo\": ktopo}\n",
    "print(\"\\n== POLISH METRICS ==\")\n",
    "print(json.dumps(metrics, indent=2))\n",
    "with open(os.path.join(OUT,\"metrics.json\"),\"w\",encoding=\"utf-8\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb2ef9cc-cb83-4dc5-aa2f-6e7499619e63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d7e8a73-db87-4944-9814-299cf18a9145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HOTFIX: robust off-diagonal handling for score matrices/vectors ===\n",
    "import numpy as np\n",
    "\n",
    "def _offdiag_vals(S):\n",
    "    \"\"\"\n",
    "    Return off-diagonal entries as a 1-D array.\n",
    "    Accepts:\n",
    "      - S as (N,N) matrix\n",
    "      - S as flat length N*N vector (row-major)\n",
    "    \"\"\"\n",
    "    S = np.asarray(S)\n",
    "    if S.ndim == 2:\n",
    "        N, M = S.shape\n",
    "        if N != M:\n",
    "            raise ValueError(f\"Score shape must be square; got {S.shape}\")\n",
    "        mask = ~np.eye(N, dtype=bool)\n",
    "        return S[mask]\n",
    "    elif S.ndim == 1:\n",
    "        L = S.size\n",
    "        N = int(round(L ** 0.5))\n",
    "        if N * N != L:\n",
    "            raise ValueError(f\"Flat score length {L} is not a perfect square.\")\n",
    "        M = S.reshape(N, N)\n",
    "        mask = ~np.eye(N, dtype=bool)\n",
    "        return M[mask]\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported score ndim={S.ndim}\")\n",
    "\n",
    "# Patch the helpers to use _offdiag_vals\n",
    "def threshold_from_surrogates(score_fn, X, alpha=0.01, surr=48, seed=0):\n",
    "    rng = np.random.default_rng(seed)\n",
    "    vals = []\n",
    "    for s in range(surr):\n",
    "        Xs = phase_randomize(X, rng)\n",
    "        S  = score_fn(Xs)\n",
    "        vals.append(_offdiag_vals(S))\n",
    "    vals = np.concatenate(vals, axis=0)\n",
    "    return float(np.quantile(vals, 1.0 - alpha)), float(np.mean(vals)), float(np.std(vals) + 1e-9)\n",
    "\n",
    "def eval_fpr(X_null, score_fn, th):\n",
    "    S = score_fn(X_null)\n",
    "    v = _offdiag_vals(S)\n",
    "    return float(np.mean(v >= th))\n",
    "\n",
    "def eval_tpr(X_pos, truth, score_fn, th):\n",
    "    S = score_fn(X_pos)\n",
    "    # Ensure truth is NxN\n",
    "    if truth.ndim != 2 or truth.shape[0] != truth.shape[1]:\n",
    "        raise ValueError(f\"Truth must be NxN; got {truth.shape}\")\n",
    "    pred = (np.asarray(S) >= th)\n",
    "    # If S is flat, reshape to NxN to match truth\n",
    "    if pred.ndim == 1:\n",
    "        N = truth.shape[0]\n",
    "        pred = pred.reshape(N, N)\n",
    "    return float(np.sum(pred & truth) / max(1, np.sum(truth)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66109949-607b-4d5b-9b58-c4351fce455f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
