{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99a4bc3a-86bd-484c-8d1e-ec8079d88a58",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251030-195448Z_614af6b5\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"W\": 97,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"theta_star\": 2.7126301874144367,\n",
      "  \"breach_tail\": \"low\",\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 0,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 0.0,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251030-195448Z_614af6b5_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251030-195448Z_614af6b5_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251030-195448Z_614af6b5_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"8fa9d60f8dad37ff30b77801a9b895d0835ca1bd5e615ed9848226cc24cf1807\"\n",
      "}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3065: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[:, None]\n",
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3066: RuntimeWarning: invalid value encountered in divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "# Single-cell CNT Flash-Proof (EEG/time-series early-warning)\n",
    "# 1 cell does it all: prereg → blind predictions → hash → reveal labels → score.\n",
    "\n",
    "import os, json, math, hashlib, uuid\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ========= CONFIG (edit me) =========\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",          # e.g., \"timestamp\" | \"time\" | leave as-is: code will synthesize seconds\n",
    "    LABEL_COL=\"stage\",             # e.g., \"stage\" | \"label\" | \"event\" (boolean)\n",
    "    EVENT_IS_BOOLEAN=False,        # True iff LABEL_COL is already a boolean event flag\n",
    "    CHRONO_SPLIT=0.80,             # 80/20 chrono split\n",
    "    WINDOW=97,                     # rolling window length (samples)\n",
    "    METRIC=\"agiew_spectral_entropy\",\n",
    "    THRESH_POLICY=dict(kind=\"quantile\", q=0.98),   # Θ* from train; q=0.98 (high-tail) or 0.02 (low-tail)\n",
    "    BREACH_TAIL=\"low\",            # \"high\" if metric spikes pre-event; \"low\" if metric dips pre-event\n",
    "    LEAD_MIN_SEC=15.0, LEAD_MAX_SEC=90.0,          # valid early-warning window\n",
    "    REFRACTORY_SEC=30.0, N_PERM=500,               # p-value permutations (bump to 1000+ for rigor)\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\", RNG_SEED=12345,\n",
    ")\n",
    "\n",
    "# ===== Helpers =====\n",
    "def now_utc_stamp(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(path:str)->pd.DataFrame:\n",
    "    ext=os.path.splitext(path)[1].lower()\n",
    "    if ext in [\".parquet\",\".pq\"]: return pd.read_parquet(path)\n",
    "    if ext in [\".csv\",\".tsv\"]: return pd.read_csv(path, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "def coerce_time(df:pd.DataFrame,time_col:Optional[str])->Tuple[pd.DataFrame,str,float]:\n",
    "    cands=[c for c in [time_col,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"] if c]\n",
    "    chosen=next((c for c in cands if c in df.columns), None)\n",
    "    if chosen is None:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[chosen]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,chosen,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label_col(df,label_col:Optional[str])->str:\n",
    "    if label_col and label_col in df.columns: return label_col\n",
    "    for c in [\"stage\",\"label\",\"y\",\"target\",\"event\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype,np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_feature_cols(df,exclude:List[str])->List[str]:\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "def agiew_spectral_entropy_window(X:np.ndarray)->float:\n",
    "    eps=1e-8\n",
    "    med=np.median(X,axis=0,keepdims=True); mad=np.median(np.abs(X-med),axis=0,keepdims=True)+eps\n",
    "    Z=(X-med)/mad\n",
    "    R=np.corrcoef(Z, rowvar=False); R=np.nan_to_num(R, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    vals=np.linalg.eigvalsh(R + eps*np.eye(R.shape[0])); vals=np.maximum(vals,eps)\n",
    "    p=vals/np.sum(vals); H=-np.sum(p*np.log(p+eps))\n",
    "    return float(H)\n",
    "\n",
    "def metric_series(df, feats, tcol, W, kind)->pd.DataFrame:\n",
    "    X=df[feats].values; T=len(df); out=np.full(T,np.nan)\n",
    "    fn=agiew_spectral_entropy_window if kind==\"agiew_spectral_entropy\" else None\n",
    "    if fn is None: raise ValueError(f\"Unknown METRIC={kind}\")\n",
    "    for i in range(W, T+1): out[i-1]=fn(X[i-W:i,:])\n",
    "    return pd.DataFrame({tcol:df[tcol].values,\"metric\":out})\n",
    "\n",
    "def learn_theta(arr:np.ndarray, policy:dict, tail:str)->float:\n",
    "    arr=arr[np.isfinite(arr)]\n",
    "    kind=policy.get(\"kind\",\"quantile\")\n",
    "    if kind==\"quantile\":\n",
    "        q=float(policy.get(\"q\",0.98))\n",
    "        return float(np.quantile(arr, q if tail==\"high\" else 1.0-q))\n",
    "    if kind==\"mad\":\n",
    "        med=np.median(arr); mad=np.median(np.abs(arr-med))+1e-9; k=float(policy.get(\"k\",4.0))\n",
    "        return float(med + k*mad) if tail==\"high\" else float(med - k*mad)\n",
    "    raise ValueError(f\"Unknown THRESH_POLICY={policy}\")\n",
    "\n",
    "def dedup_breaches(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def extract_events(df,label_col,tcol,is_bool)->np.ndarray:\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    lbl=df[label_col].values; ch=np.zeros(len(lbl),bool); ch[1:]=lbl[1:]!=lbl[:-1]\n",
    "    return df.loc[ch,tcol].values\n",
    "\n",
    "def score_detection(breach_ts,event_ts,lead_min,lead_max,horizon)->Tuple[float,float,float]:\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts); med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]; fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def perm_pvalue(breach_ts,event_ts,lead_min,lead_max,horizon,n_perm,seed,obs):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=score_detection(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "def synth_demo_dataset(T=3600,D=10,stage_every=600,seed=42)->pd.DataFrame:\n",
    "    rng=np.random.default_rng(seed)\n",
    "    t=np.arange(T,dtype=float); stage=(t//stage_every).astype(int)\n",
    "    X=rng.normal(0,1,size=(T,D)); latent=rng.normal(0,1,size=T)\n",
    "    for k in range(1, int(T//stage_every)+1):\n",
    "        et=k*stage_every; lo=max(0,et-90); hi=max(0,et-15)\n",
    "        if lo<hi<=T:\n",
    "            alpha=np.linspace(0.0,1.5,hi-lo)\n",
    "            for j,a in enumerate(alpha): X[lo+j,:]+=a*latent[lo+j]\n",
    "    df=pd.DataFrame(X,columns=[f\"ch{c:02d}\" for c in range(D)])\n",
    "    df[\"timestamp\"]=t; df[\"stage\"]=stage; return df\n",
    "\n",
    "# ========= Main (single cell) =========\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"]); os.makedirs(CONFIG[\"OUT_DIR\"],exist_ok=True)\n",
    "STAMP=now_utc_stamp(); run_id=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"; prefix=os.path.join(CONFIG[\"OUT_DIR\"],f\"flashproof_{run_id}\")\n",
    "\n",
    "# Load data or demo\n",
    "if os.path.exists(CONFIG[\"DATA_PATH\"]): df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "else: df_raw=synth_demo_dataset()\n",
    "\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=guess_label_col(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_feature_cols(df, exclude=[tcol,label_col])\n",
    "\n",
    "# chrono split\n",
    "T=len(df); split=int(T*CONFIG[\"CHRONO_SPLIT\"]); train=df.iloc[:split].reset_index(drop=True); hold=df.iloc[split:].reset_index(drop=True)\n",
    "\n",
    "# metric & Θ* on train only\n",
    "train_m=metric_series(train,feats,tcol,CONFIG[\"WINDOW\"],CONFIG[\"METRIC\"])\n",
    "theta_star=learn_theta(train_m[\"metric\"].values, CONFIG[\"THRESH_POLICY\"], CONFIG[\"BREACH_TAIL\"])\n",
    "\n",
    "# prereg (before predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof Preregistration (frozen)\n",
    "Run ID: {run_id}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']} {'(DEMO: synthetic fallback used here)' if not os.path.exists(CONFIG['DATA_PATH']) else ''}\n",
    "Time column: {tcol} | Label column: {label_col} | Features: n={len(feats)}\n",
    "Split: {int(CONFIG['CHRONO_SPLIT']*100)}/{int((1-CONFIG['CHRONO_SPLIT'])*100)} chrono | W={CONFIG['WINDOW']}\n",
    "Metric: {CONFIG['METRIC']} | Threshold policy: {json.dumps(CONFIG['THRESH_POLICY'])} | Breach tail: {CONFIG['BREACH_TAIL']}\n",
    "Frozen Θ*: {theta_star:.6f}\n",
    "Lead window: [{CONFIG['LEAD_MIN_SEC']}s, {CONFIG['LEAD_MAX_SEC']}s] | Refractory: {CONFIG['REFRACTORY_SEC']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "Prediction file (next): {prefix}_predictions.csv\n",
    "\n",
    "**Prediction:** With W={CONFIG['WINDOW']} and Θ* learned on the training split only, CNT will detect ≥ 65% of holdout label transitions at ≥ 15 s median lead and ≤ 1 FA/hr.\n",
    "\"\"\"\n",
    "with open(f\"{prefix}_prereg.md\",\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# blind predictions on HOLDOUT (no labels touched)\n",
    "hold_m=metric_series(hold,feats,tcol,CONFIG[\"WINDOW\"],CONFIG[\"METRIC\"])\n",
    "times=hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "if CONFIG[\"BREACH_TAIL\"]==\"high\": raw_flags=(vals>theta_star).astype(int)\n",
    "else: raw_flags=(vals<theta_star).astype(int)\n",
    "keep=dedup_breaches(times,raw_flags,CONFIG[\"REFRACTORY_SEC\"])\n",
    "flags=np.zeros_like(raw_flags); flags[keep]=1\n",
    "pred_df=pd.DataFrame({tcol:times,\"metric\":vals,\"breach_flag\":flags})\n",
    "pred_path=f\"{prefix}_predictions.csv\"; pred_df.to_csv(pred_path,index=False)\n",
    "\n",
    "# hash (seal) predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "with open(f\"{prefix}_prereg_locked.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+ \"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# reveal labels & score\n",
    "ev_times=extract_events(hold,label_col,tcol,CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "breach_times=pred_df.loc[pred_df[\"breach_flag\"]==1, tcol].values\n",
    "horizon=float(times[-1]-times[0]) if len(times)>=2 else max(len(times)*dt,1.0)\n",
    "\n",
    "det, med, fah = score_detection(breach_times, ev_times, CONFIG[\"LEAD_MIN_SEC\"], CONFIG[\"LEAD_MAX_SEC\"], horizon)\n",
    "pval = perm_pvalue(breach_times, ev_times, CONFIG[\"LEAD_MIN_SEC\"], CONFIG[\"LEAD_MAX_SEC\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(run_id=run_id, data=CONFIG[\"DATA_PATH\"], W=CONFIG[\"WINDOW\"], metric=CONFIG[\"METRIC\"],\n",
    "           theta_star=float(theta_star), breach_tail=CONFIG[\"BREACH_TAIL\"], events_n=int(ev_times.size),\n",
    "           breaches_n=int(breach_times.size), detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "           false_alarms_per_hr=float(fah), perm_p_value=float(pval), decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "           predictions_csv=pred_path, prereg=f\"{prefix}_prereg.md\", prereg_locked=f\"{prefix}_prereg_locked.md\",\n",
    "           predictions_sha256=pred_sha)\n",
    "\n",
    "with open(f\"{prefix}_score.json\",\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c36f88ce-0133-46f0-adf8-6b99f694e06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-001830Z_709ef451\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.5,\n",
      "  \"W\": 97,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"high\",\n",
      "  \"theta_star\": 5.771441123130016,\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 0,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 0.0,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-001830Z_709ef451_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-001830Z_709ef451_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-001830Z_709ef451_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"7014f8e6d64e978e0ea73aee5c3b0d72154b64fb8f385469fa8c38332f1c7ac5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# CNT Flash-Proof v2 — single cell\n",
    "# Pre-declared rules: (a) ensure >= MIN_EVENTS_HOLDOUT in holdout by adjusting split (cap at 50%),\n",
    "# (b) pick breach tail via TRAIN ONLY, (c) robust correlation (no NaN/zero-variance blowups),\n",
    "# (d) threshold picked from TRAIN quantile grid. Then: prereg → blind preds → hash → reveal → score.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ================= CONFIG (edit) =================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",        # \"timestamp\"|\"time\"|None (auto)\n",
    "    LABEL_COL=\"stage\",           # \"stage\" if you want stage-change events; or \"event\" if boolean\n",
    "    EVENT_IS_BOOLEAN=False,      # True if LABEL_COL is a boolean event flag\n",
    "    CHRONO_SPLIT=0.80,           # starting split; will auto-reduce if holdout has too few events\n",
    "    MIN_EVENTS_HOLDOUT=3,        # predeclared minimum events required to score\n",
    "    WINDOW=97,                   # rolling window length (samples)\n",
    "    METRIC=\"agiew_spectral_entropy\",\n",
    "    # TRAIN-only threshold grids (do not look at holdout)\n",
    "    THRESH_Q_GRID_HIGH=[0.98, 0.95, 0.90, 0.85],\n",
    "    THRESH_Q_GRID_LOW =[0.02, 0.05, 0.10, 0.15, 0.20],\n",
    "    LEAD_MIN_SEC=15.0, LEAD_MAX_SEC=90.0,\n",
    "    REFRACTORY_SEC=30.0,\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "\n",
    "# ================ helpers ================\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(path:str)->pd.DataFrame:\n",
    "    ext=os.path.splitext(path)[1].lower()\n",
    "    if ext in (\".pq\",\".parquet\"): return pd.read_parquet(path)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(path, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "def coerce_time(df:pd.DataFrame, time_col:Optional[str])->Tuple[pd.DataFrame,str,float]:\n",
    "    cands=[c for c in [time_col,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"] if c]\n",
    "    chosen=next((c for c in cands if c in df.columns), None)\n",
    "    if chosen is None:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[chosen]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,chosen,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label_col(df,label_col:Optional[str])->str:\n",
    "    if label_col and label_col in df.columns: return label_col\n",
    "    for c in [\"stage\",\"label\",\"y\",\"target\",\"event\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype,np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df,exclude:List[str])->List[str]:\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "def safe_corr_from_cov(Z:np.ndarray)->np.ndarray:\n",
    "    \"\"\"Compute correlation with shrinkage & zero-variance guards to avoid warnings.\"\"\"\n",
    "    eps=1e-8\n",
    "    # robust scale per column (median/MAD)\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad = np.where(mad<eps, eps, mad)     # guard zero MAD\n",
    "    X=(Z-med)/mad\n",
    "    # drop near-constant columns (std ~ 0)\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep = std>1e-6\n",
    "    X = X[:, keep] if keep.any() else X\n",
    "    if X.shape[1] <= 1:\n",
    "        return np.eye(max(1, X.shape[1]))\n",
    "    cov = np.cov(X, rowvar=False)\n",
    "    # diagonal loading (Ledoit-Wolf style shrinkage lite)\n",
    "    lam = 1e-3 * np.trace(cov)/cov.shape[0]\n",
    "    cov = cov + lam*np.eye(cov.shape[0])\n",
    "    d = np.sqrt(np.clip(np.diag(cov), 1e-12, None))\n",
    "    corr = cov / (d[:,None]*d[None,:])\n",
    "    # numerical safety\n",
    "    corr = np.nan_to_num(corr, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "    return corr\n",
    "\n",
    "def agiew_spectral_entropy_window(win:np.ndarray)->float:\n",
    "    C = safe_corr_from_cov(win)\n",
    "    vals = np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0]))\n",
    "    vals = np.maximum(vals, 1e-8)\n",
    "    p = vals/np.sum(vals)\n",
    "    return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df:pd.DataFrame, feats:List[str], tcol:str, W:int, kind:str)->pd.DataFrame:\n",
    "    X=df[feats].values; T=len(df); out=np.full(T, np.nan)\n",
    "    fn = agiew_spectral_entropy_window if kind==\"agiew_spectral_entropy\" else None\n",
    "    if fn is None: raise ValueError(f\"Unknown METRIC={kind}\")\n",
    "    # fill NaNs per column to avoid empty windows\n",
    "    X = np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    for i in range(W, T+1):\n",
    "        win = X[i-W:i,:]\n",
    "        out[i-1] = fn(win)\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":out})\n",
    "\n",
    "def stage_change_events(df,label_col,tcol)->np.ndarray:\n",
    "    lbl=df[label_col].values\n",
    "    ch=np.zeros(len(lbl),bool); ch[1:]=lbl[1:]!=lbl[:-1]\n",
    "    return df.loc[ch, tcol].values\n",
    "\n",
    "def boolean_events(df,label_col,tcol)->np.ndarray:\n",
    "    return df.loc[df[label_col].astype(bool), tcol].values\n",
    "\n",
    "def extract_events(df,label_col,tcol,is_bool)->np.ndarray:\n",
    "    return boolean_events(df,label_col,tcol) if is_bool else stage_change_events(df,label_col,tcol)\n",
    "\n",
    "def dedup_breaches(times, flags, refractory):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=refractory: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts,event_ts,lead_min,lead_max,horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi = et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med = float(np.median(det)) if det else math.nan\n",
    "    fa  = [bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah = len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def perm_pvalue(breach_ts,event_ts,lead_min,lead_max,horizon,n_perm,seed,obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0, horizon, size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "def choose_tail_from_training(train_m:pd.DataFrame, train_events:np.ndarray, lead_min, lead_max)->str:\n",
    "    \"\"\"Look only at TRAIN: if pre-event window shows lower metric, pick 'low', else 'high'.\"\"\"\n",
    "    if len(train_events)==0: return \"high\"  # default if no events in train\n",
    "    t = train_m.iloc[:,0].values\n",
    "    m = train_m[\"metric\"].values\n",
    "    pe_vals=[]\n",
    "    for et in train_events:\n",
    "        lo, hi = et-lead_max, et-lead_min\n",
    "        idx = (t>=lo)&(t<=hi)\n",
    "        if idx.any(): pe_vals.append(np.nanmedian(m[idx]))\n",
    "    if not pe_vals: return \"high\"\n",
    "    pre = np.nanmedian(pe_vals)\n",
    "    base = np.nanmedian(m[np.isfinite(m)])\n",
    "    return \"low\" if pre < base else \"high\"\n",
    "\n",
    "def theta_from_train(train_m:pd.Series, tail:str, qgrid:List[float])->float:\n",
    "    arr=train_m[np.isfinite(train_m)].values\n",
    "    if tail==\"high\":\n",
    "        qs = qgrid\n",
    "    else:\n",
    "        qs = [1.0-q for q in qgrid]  # invert for low-tail\n",
    "    for q in qs:\n",
    "        th=float(np.quantile(arr, q))\n",
    "        if np.isfinite(th): return th\n",
    "    return float(np.quantile(arr, 0.5))\n",
    "\n",
    "# =============== main (single cell) ===============\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP = now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"; PREFIX=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}\")\n",
    "\n",
    "# Load\n",
    "df_raw = read_table(CONFIG[\"DATA_PATH\"])\n",
    "df, tcol, dt = coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col = guess_label_col(df, CONFIG[\"LABEL_COL\"])\n",
    "feats = numeric_cols(df, exclude=[tcol, label_col])\n",
    "\n",
    "# initial split\n",
    "split = CONFIG[\"CHRONO_SPLIT\"]\n",
    "def make_splits(frac):\n",
    "    idx=int(len(df)*frac)\n",
    "    return df.iloc[:idx].reset_index(drop=True), df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "train, hold = make_splits(split)\n",
    "hold_events = extract_events(hold, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# pre-declared rule: ensure at least MIN_EVENTS_HOLDOUT\n",
    "while (len(hold_events) < CONFIG[\"MIN_EVENTS_HOLDOUT\"]) and (split > 0.50):\n",
    "    split = round(split - 0.05, 2)\n",
    "    train, hold = make_splits(split)\n",
    "    hold_events = extract_events(hold, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# TRAIN metric & events (labels are allowed on train)\n",
    "train_m = metric_series(train, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"METRIC\"])\n",
    "train_events = extract_events(train, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Auto tail from TRAIN only\n",
    "tail = choose_tail_from_training(train_m, train_events, CONFIG[\"LEAD_MIN_SEC\"], CONFIG[\"LEAD_MAX_SEC\"])\n",
    "\n",
    "# Θ* from TRAIN only (grid)\n",
    "theta = theta_from_train(train_m[\"metric\"], tail,\n",
    "                         CONFIG[\"THRESH_Q_GRID_HIGH\"] if tail==\"high\" else CONFIG[\"THRESH_Q_GRID_LOW\"])\n",
    "\n",
    "# Pre-registration (frozen)\n",
    "prereg = f\"\"\"\n",
    "# CNT Flash-Proof v2 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: {CONFIG['METRIC']} | W={CONFIG['WINDOW']}\n",
    "Predeclared split rule: start at {CONFIG['CHRONO_SPLIT']:.2f}; if holdout has < {CONFIG['MIN_EVENTS_HOLDOUT']} events,\n",
    "reduce split by 0.05 until ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} events or split reaches 0.50. Final split={split:.2f}.\n",
    "Tail selection: TRAIN-only pre-event analysis → tail='{tail}'.\n",
    "Threshold selection: TRAIN-only quantile grid {CONFIG['THRESH_Q_GRID_HIGH'] if tail=='high' else CONFIG['THRESH_Q_GRID_LOW']} → Θ*={theta:.6f}.\n",
    "Lead window: [{CONFIG['LEAD_MIN_SEC']}s, {CONFIG['LEAD_MAX_SEC']}s]; Refractory: {CONFIG['REFRACTORY_SEC']}s.\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the holdout split above, CNT will detect ≥ 65% of label events within the lead window with ≥ 15 s median lead and ≤ 1 FA/hr.\n",
    "\"\"\"\n",
    "with open(f\"{PREFIX}_prereg.md\",\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT: blind prediction (no use of holdout labels here)\n",
    "hold_m = metric_series(hold, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"METRIC\"])\n",
    "times = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw_flags = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep_idx = dedup_breaches(times, raw_flags, CONFIG[\"REFRACTORY_SEC\"])\n",
    "flags = np.zeros_like(raw_flags); flags[keep_idx]=1\n",
    "pred_df = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path = f\"{PREFIX}_predictions.csv\"; pred_df.to_csv(pred_path, index=False)\n",
    "\n",
    "# hash-seal predictions\n",
    "pred_sha = hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "with open(f\"{PREFIX}_prereg_locked.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip() + \"\\n\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "# Reveal labels & score (now allowed)\n",
    "event_ts = hold_events\n",
    "breach_ts = pred_df.loc[pred_df[\"breach_flag\"]==1, tcol].values\n",
    "horizon = float(times[-1]-times[0]) if len(times)>=2 else max(len(times)*dt, 1.0)\n",
    "\n",
    "det, med, fah = detect(breach_ts, event_ts, CONFIG[\"LEAD_MIN_SEC\"], CONFIG[\"LEAD_MAX_SEC\"], horizon)\n",
    "pval = perm_pvalue(breach_ts, event_ts, CONFIG[\"LEAD_MIN_SEC\"], CONFIG[\"LEAD_MAX_SEC\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score = dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=split, W=CONFIG[\"WINDOW\"],\n",
    "    metric=CONFIG[\"METRIC\"], tail=tail, theta_star=float(theta),\n",
    "    events_n=int(len(event_ts)), breaches_n=int(len(breach_ts)),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(pval),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path, prereg=f\"{PREFIX}_prereg.md\",\n",
    "    prereg_locked=f\"{PREFIX}_prereg_locked.md\", predictions_sha256=pred_sha\n",
    ")\n",
    "\n",
    "with open(f\"{PREFIX}_score.json\",\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "04f3d3c2-773a-4845-b3cc-7fdbdf7c76da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Candidates: ['label']\n",
      "label: transitions=1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd, numpy as np\n",
    "df = pd.read_csv(r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\")\n",
    "cands = [c for c in [\"event\",\"stage\",\"label\",\"stage_int\",\"sleep_stage\",\"y\",\"target\"] if c in df.columns]\n",
    "print(\"Candidates:\", cands)\n",
    "for c in cands:\n",
    "    s = df[c] if not np.issubdtype(df[c].dtype, np.number) else df[c].astype(str)\n",
    "    ch = (s.shift(-1)!=s).fillna(False).sum()\n",
    "    print(f\"{c}: transitions={int(ch)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "067722f9-6ddc-4111-93e2-798882fe73dc",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index -1 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 263\u001b[39m\n\u001b[32m    261\u001b[39m \u001b[38;5;66;03m# TRAIN metric & tail\u001b[39;00m\n\u001b[32m    262\u001b[39m train_m = metric_series(train, feats, tcol, CONFIG[\u001b[33m\"\u001b[39m\u001b[33mWINDOW\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mSMOOTH_WIN\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m263\u001b[39m tail = \u001b[43mchoose_tail_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_m\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mev_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLEAD_MIN\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONFIG\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mLEAD_MAX\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtcol\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m theta = theta_from_train(train_m[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m].values, tail, CONFIG[\u001b[33m\"\u001b[39m\u001b[33mTHRESH_Q_GRID_HIGH\u001b[39m\u001b[33m\"\u001b[39m], CONFIG[\u001b[33m\"\u001b[39m\u001b[33mTHRESH_Q_GRID_LOW\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m    266\u001b[39m \u001b[38;5;66;03m# Preregistration (frozen BEFORE predictions)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 182\u001b[39m, in \u001b[36mchoose_tail_train\u001b[39m\u001b[34m(train_m, train_events, lead_min, lead_max, tcol)\u001b[39m\n\u001b[32m    180\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(keep)/(horizon/\u001b[32m3600.0\u001b[39m), th\n\u001b[32m    181\u001b[39m m = train_m[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m].values\n\u001b[32m--> \u001b[39m\u001b[32m182\u001b[39m fa_high,_=\u001b[43mbreaches_per_hr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhigh\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[32;43m0.98\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    183\u001b[39m fa_low,_ =breaches_per_hr(m,\u001b[33m\"\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m0.02\u001b[39m)\n\u001b[32m    184\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m fa_high < fa_low \u001b[38;5;28;01melse\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mlow\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 170\u001b[39m, in \u001b[36mchoose_tail_train.<locals>.breaches_per_hr\u001b[39m\u001b[34m(arr, tail, q)\u001b[39m\n\u001b[32m    169\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mbreaches_per_hr\u001b[39m(arr, tail, q):\n\u001b[32m--> \u001b[39m\u001b[32m170\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m tail==\u001b[33m\"\u001b[39m\u001b[33mhigh\u001b[39m\u001b[33m\"\u001b[39m: th=\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43misfinite\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m)\u001b[49m; flags=(m>th).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    171\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:            th=np.quantile(arr[np.isfinite(arr)], \u001b[32m1.0\u001b[39m-q); flags=(m<th).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    172\u001b[39m     \u001b[38;5;66;03m# dedup with 30s gap in TRAIN time coordinates\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4556\u001b[39m, in \u001b[36mquantile\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights, interpolation)\u001b[39m\n\u001b[32m   4553\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m np.any(weights < \u001b[32m0\u001b[39m):\n\u001b[32m   4554\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mWeights must be non-negative.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m4556\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_quantile_unchecked\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   4557\u001b[39m \u001b[43m    \u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4569\u001b[39m, in \u001b[36m_quantile_unchecked\u001b[39m\u001b[34m(a, q, axis, out, overwrite_input, method, keepdims, weights)\u001b[39m\n\u001b[32m   4560\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_quantile_unchecked\u001b[39m(a,\n\u001b[32m   4561\u001b[39m                         q,\n\u001b[32m   4562\u001b[39m                         axis=\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m   4566\u001b[39m                         keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   4567\u001b[39m                         weights=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   4568\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Assumes that q is in [0, 1], and is an ndarray\"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m4569\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_ureduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4570\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_quantile_ureduce_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4571\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mq\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4572\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4573\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4574\u001b[39m \u001b[43m                    \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4575\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4576\u001b[39m \u001b[43m                    \u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverwrite_input\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4577\u001b[39m \u001b[43m                    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:3914\u001b[39m, in \u001b[36m_ureduce\u001b[39m\u001b[34m(a, func, keepdims, **kwargs)\u001b[39m\n\u001b[32m   3911\u001b[39m     index_out = (\u001b[32m0\u001b[39m, ) * nd\n\u001b[32m   3912\u001b[39m     kwargs[\u001b[33m'\u001b[39m\u001b[33mout\u001b[39m\u001b[33m'\u001b[39m] = out[(\u001b[38;5;28mEllipsis\u001b[39m, ) + index_out]\n\u001b[32m-> \u001b[39m\u001b[32m3914\u001b[39m r = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   3916\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   3917\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4744\u001b[39m, in \u001b[36m_quantile_ureduce_func\u001b[39m\u001b[34m(a, q, weights, axis, out, overwrite_input, method)\u001b[39m\n\u001b[32m   4742\u001b[39m     arr = a.copy()\n\u001b[32m   4743\u001b[39m     wgt = weights\n\u001b[32m-> \u001b[39m\u001b[32m4744\u001b[39m result = \u001b[43m_quantile\u001b[49m\u001b[43m(\u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4745\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mquantiles\u001b[49m\u001b[43m=\u001b[49m\u001b[43mq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4746\u001b[39m \u001b[43m                   \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4747\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4748\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   4749\u001b[39m \u001b[43m                   \u001b[49m\u001b[43mweights\u001b[49m\u001b[43m=\u001b[49m\u001b[43mwgt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   4750\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\numpy\\lib\\_function_base_impl.py:4866\u001b[39m, in \u001b[36m_quantile\u001b[39m\u001b[34m(arr, quantiles, axis, method, out, weights)\u001b[39m\n\u001b[32m   4859\u001b[39m arr.partition(\n\u001b[32m   4860\u001b[39m     np.unique(np.concatenate(([\u001b[32m0\u001b[39m, -\u001b[32m1\u001b[39m],\n\u001b[32m   4861\u001b[39m                               previous_indexes.ravel(),\n\u001b[32m   4862\u001b[39m                               next_indexes.ravel(),\n\u001b[32m   4863\u001b[39m                               ))),\n\u001b[32m   4864\u001b[39m     axis=\u001b[32m0\u001b[39m)\n\u001b[32m   4865\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m supports_nans:\n\u001b[32m-> \u001b[39m\u001b[32m4866\u001b[39m     slices_having_nans = np.isnan(\u001b[43marr\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m.\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[32m   4867\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   4868\u001b[39m     slices_having_nans = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: index -1 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v4 — Single Mega Cell =======================\n",
    "# Predeclared, auditable protocol:\n",
    "# (1) Boundary-aware events across FULL series.\n",
    "# (2) Choose the LATEST split whose holdout contains >= MIN_EVENTS_HOLDOUT events AND\n",
    "#     each such event sits at least LEAD_MIN seconds after holdout start (so early-warnings can occur inside holdout).\n",
    "# (3) TRAIN-only: compute metric, choose breach TAIL ('high' or 'low') from TRAIN pre-event windows if any;\n",
    "#     otherwise choose the tail with FEWER false alarms on TRAIN (unsupervised).\n",
    "# (4) TRAIN-only: choose Θ* from a small quantile grid (no peeking at holdout).\n",
    "# (5) Freeze prereg, write predictions.csv + SHA-256, then reveal labels and score:\n",
    "#     detection rate, median lead, FAs/hr, permutation p-value. PASS if ≥65% hits, ≥15 s median lead, ≤1 FA/hr.\n",
    "#\n",
    "# Notes:\n",
    "# - Robust correlation: constant channels removed, covariance diagonal-loaded, no NaN warnings.\n",
    "# - Smoothing: rolling median for stability (set SMOOTH_WIN=1 to disable).\n",
    "# - Works with either categorical stages (event = change-point) or boolean \"event\" column.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",      # or None to auto\n",
    "    LABEL_COL=\"label\",         # <- you said the only transition is here\n",
    "    EVENT_IS_BOOLEAN=False,    # True iff LABEL_COL is already 0/1 \"event\"\n",
    "    WINDOW=97,                 # rolling window (samples)\n",
    "    SMOOTH_WIN=7,              # rolling median smoothing on the metric (1 = off)\n",
    "    # Holdout selection (predeclared): scan DOWNWARD, pick the LATEST split meeting the rule\n",
    "    CANDIDATE_SPLITS=[0.95,0.90,0.85,0.80,0.75,0.70,0.65,0.60,0.55,0.50,0.45,0.40,0.35,0.30,0.25,0.20,0.15,0.10,0.05],\n",
    "    MIN_EVENTS_HOLDOUT=1,      # you have only one transition; set to 1\n",
    "    LEAD_MIN=15.0,             # min lead (s) to count as early-warning\n",
    "    LEAD_MAX=90.0,             # max lead (s)\n",
    "    LEAD_MARGIN_SEC=0.0,       # extra slack beyond LEAD_MIN for boundary (0..30s typical)\n",
    "    REFRACTORY=30.0,           # de-dup breaches\n",
    "    # TRAIN-only threshold grids (no holdout peeking)\n",
    "    THRESH_Q_GRID_HIGH=[0.98,0.95,0.90,0.85],\n",
    "    THRESH_Q_GRID_LOW =[0.02,0.05,0.10,0.15,0.20],\n",
    "    N_PERM=500,                # permutations for p-value\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file type: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    # Create a seconds-since-start time axis\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s, errors=\"coerce\", utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s, errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype, np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)                    # avoid zero MAD\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]               # tiny diagonal load\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0]))\n",
    "    vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals)\n",
    "    return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    # fill NaNs columnwise to avoid empty windows\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1:\n",
    "        s=s.rolling(smooth_win, center=True, min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool:\n",
    "        return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0] + 1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full: np.ndarray, t0, t1):\n",
    "    return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- holdout selection (predeclared rule) ----------\n",
    "def choose_holdout_split(df, tcol, ev_full, candidate_splits, min_events, lead_min, lead_margin):\n",
    "    \"\"\"\n",
    "    Pick the LATEST split whose holdout has >=min_events and each counted event\n",
    "    is at least (lead_min + lead_margin) seconds after holdout start.\n",
    "    If none, pick the latest with >=1 event (no margin). Else return None.\n",
    "    \"\"\"\n",
    "    chosen=None; chosen_n=0\n",
    "    for sp in candidate_splits:\n",
    "        idx=int(len(df)*sp)\n",
    "        if idx>=len(df)-1: continue\n",
    "        t0=df[tcol].values[idx]; t1=df[tcol].values[-1]\n",
    "        ev = events_in_range(ev_full, t0, t1)\n",
    "        if ev.size==0: continue\n",
    "        slack = ev - t0\n",
    "        n_ok = int(np.sum(slack >= (lead_min + lead_margin)))\n",
    "        if n_ok >= min_events:\n",
    "            chosen=(sp, n_ok); break\n",
    "        # keep a fallback to latest with ≥1 event\n",
    "        if chosen is None and ev.size>=1:\n",
    "            chosen=(sp, 1)\n",
    "    return chosen  # tuple(split, n_events_ok) or None\n",
    "\n",
    "# ---------- tail & threshold (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    # If TRAIN has events, compare pre-event vs baseline median\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    if train_events.size>0:\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[np.isfinite(m)])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # Else unsupervised fallback: pick tail with FEWER TRAIN breaches/hr\n",
    "    def breaches_per_hr(arr, tail, q):\n",
    "        if tail==\"high\": th=np.quantile(arr[np.isfinite(arr)], q); flags=(m>th).astype(int)\n",
    "        else:            th=np.quantile(arr[np.isfinite(arr)], 1.0-q); flags=(m<th).astype(int)\n",
    "        # dedup with 30s gap in TRAIN time coordinates\n",
    "        times=t\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0, th\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0], 1.0)\n",
    "        return len(keep)/(horizon/3600.0), th\n",
    "    m = train_m[\"metric\"].values\n",
    "    fa_high,_=breaches_per_hr(m,\"high\",0.98)\n",
    "    fa_low,_ =breaches_per_hr(m,\"low\", 0.02)\n",
    "    return \"high\" if fa_high < fa_low else \"low\"\n",
    "\n",
    "def theta_from_train(train_vals: np.ndarray, tail: str, qgrid_high, qgrid_low):\n",
    "    arr=train_vals[np.isfinite(train_vals)]\n",
    "    qs = qgrid_high if tail==\"high\" else [1.0-q for q in qgrid_low]\n",
    "    for q in qs:\n",
    "        th=float(np.quantile(arr, q))\n",
    "        if np.isfinite(th): return th\n",
    "    return float(np.quantile(arr, 0.5))\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep, int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min()\n",
    "            det.append(et-first)\n",
    "            used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0, horizon, size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts, perm, lead_min, lead_max, horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"; PREFIX=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}\")\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col])\n",
    "\n",
    "# Boundary-aware events on FULL series\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose holdout split per predeclared rule\n",
    "choice=choose_holdout_split(df, tcol, ev_full, CONFIG[\"CANDIDATE_SPLITS\"],\n",
    "                            CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"])\n",
    "if choice is None:\n",
    "    # Honest fallback: no viable split with events; we still proceed and will likely FAIL\n",
    "    split=CONFIG[\"CANDIDATE_SPLITS\"][-1]\n",
    "    events_ok=0\n",
    "else:\n",
    "    split, events_ok = choice\n",
    "\n",
    "idx=int(len(df)*split)\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric & tail\n",
    "train_m = metric_series(train, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"])\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta = theta_from_train(train_m[\"metric\"].values, tail, CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"])\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v4 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | W={CONFIG['WINDOW']} | smooth={CONFIG['SMOOTH_WIN']}\n",
    "Holdout selection (predeclared): choose the LATEST split in {CONFIG['CANDIDATE_SPLITS']}\n",
    "whose holdout has ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} boundary-aware events AND each counted event is ≥ {CONFIG['LEAD_MIN']}s + margin {CONFIG['LEAD_MARGIN_SEC']}s after holdout start.\n",
    "Chosen split: {split:.2f} (events_in_holdout={int(ev_hold.size)}; events_meeting_margin={events_ok})\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only quantile grid ({'HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH']) if tail=='high' else 'LOW '+str(CONFIG['THRESH_Q_GRID_LOW'])}): {theta:.6f}\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, with median lead ≥ 15 s, and ≤ 1 false alarm/hour.\n",
    "\"\"\"\n",
    "with open(f\"{PREFIX}_prereg.md\",\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind to labels)\n",
    "hold_m=metric_series(hold, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"])\n",
    "times=hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw=(vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep=dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags=np.zeros_like(raw); flags[keep]=1\n",
    "pred=pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=f\"{PREFIX}_predictions.csv\"; pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions (hash)\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "with open(f\"{PREFIX}_prereg_locked.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal labels & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(split),\n",
    "    W=CONFIG[\"WINDOW\"], smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=f\"{PREFIX}_prereg.md\", prereg_locked=f\"{PREFIX}_prereg_locked.md\",\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "with open(f\"{PREFIX}_score.json\",\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "adaab97b-c290-4670-8450-6822cadeb5cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-002928Z_1cdb0dce\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.05,\n",
      "  \"W_eff\": 13,\n",
      "  \"smooth\": 7,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"low\",\n",
      "  \"theta_star\": 4.643157233155411,\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 15,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 116.63066954643628,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-002928Z_1cdb0dce_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-002928Z_1cdb0dce_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-002928Z_1cdb0dce_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"d41425f35bcd6671a5cc6d5a7070caf38ba5fc65cd57c0d917f9927db8ed9519\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v5 — Single Mega Cell =======================\n",
    "# Protocol (predeclared & auditable):\n",
    "# 1) Boundary-aware events computed on FULL series (so a stage change across the split is seen).\n",
    "# 2) Choose the LATEST split from CANDIDATE_SPLITS whose holdout contains ≥ MIN_EVENTS_HOLDOUT events,\n",
    "#    and each counted event is at least LEAD_MIN + LEAD_MARGIN_SEC after holdout start.\n",
    "# 3) TRAIN-only metric:\n",
    "#       • Robust correlation (zero-variance guards + diag load; no NaN explosions).\n",
    "#       • If TRAIN has too few finite metric samples with WINDOW, auto-shrink window on TRAIN\n",
    "#         (predeclared fallback) until ≥ MIN_TRAIN_FINITE finite samples exist (never looks at holdout).\n",
    "# 4) TRAIN-only tail choose: if TRAIN has events, compare pre-event medians; else pick tail with fewer TRAIN FAs/hr.\n",
    "# 5) TRAIN-only threshold Θ*: quantile from a small grid (no peeking at holdout).\n",
    "# 6) Freeze prereg → emit predictions.csv → SHA-256 → reveal labels → score (Det%, Median lead, FA/hr, perm p).\n",
    "# PASS if: Det ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    LABEL_COL=\"label\",          # you found the lone transition here\n",
    "    EVENT_IS_BOOLEAN=False,     # using change-points, not a 0/1 event flag\n",
    "    WINDOW=97,                  # desired W; may shrink on TRAIN if needed (see fallback)\n",
    "    SMOOTH_WIN=7,               # rolling median smoothing on metric (1 disables)\n",
    "    CANDIDATE_SPLITS=[0.95,0.90,0.85,0.80,0.75,0.70,0.65,0.60,0.55,0.50,0.45,0.40,0.35,0.30,0.25,0.20,0.15,0.10,0.05],\n",
    "    MIN_EVENTS_HOLDOUT=1,       # you have only one transition\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0, LEAD_MARGIN_SEC=0.0,\n",
    "    REFRACTORY=30.0,\n",
    "    THRESH_Q_GRID_HIGH=[0.98,0.95,0.90,0.85],\n",
    "    THRESH_Q_GRID_LOW =[0.02,0.05,0.10,0.15,0.20],\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    "    # TRAIN fallback policy:\n",
    "    MIN_TRAIN_FINITE=10,        # need at least this many finite metric points on TRAIN\n",
    "    MIN_WINDOW=5,               # hard floor if we must shrink WINDOW\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1:\n",
    "        s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0]+1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full, t0, t1):\n",
    "    return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- holdout split (predeclared) ----------\n",
    "def choose_holdout_split(df, tcol, ev_full, candidate_splits, min_events, lead_min, lead_margin):\n",
    "    chosen=None; chosen_n=0\n",
    "    for sp in candidate_splits:  # from latest to earlier\n",
    "        idx=int(len(df)*sp)\n",
    "        if idx>=len(df)-1: continue\n",
    "        t0=df[tcol].values[idx]; t1=df[tcol].values[-1]\n",
    "        ev = events_in_range(ev_full, t0, t1)\n",
    "        if ev.size==0: continue\n",
    "        slack = ev - t0\n",
    "        n_ok=int(np.sum(slack >= (lead_min + lead_margin)))\n",
    "        if n_ok >= min_events:\n",
    "            chosen=(sp, n_ok); break\n",
    "        if chosen is None and ev.size>=1:\n",
    "            chosen=(sp, 1)  # fallback: at least one event\n",
    "    return chosen\n",
    "\n",
    "# ---------- TRAIN window fallback ----------\n",
    "def find_working_window(train_df, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates = [W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates = [w for w in [max(min_window, int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(train_df) < W: continue\n",
    "        tm = metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        nfin = int(np.isfinite(tm[\"metric\"]).sum())\n",
    "        tried.append((W,nfin))\n",
    "        if nfin >= min_finite:\n",
    "            return W, tm, tried\n",
    "    # fallback: pick the one with the MOST finite points (even if < min_finite)\n",
    "    best = max((x for x in tried), key=lambda z: z[1], default=None)\n",
    "    if best and len(train_df) >= best[0]:\n",
    "        W=best[0]; tm=metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    # absolute fallback: nothing workable; return desired with NaNs\n",
    "    W=max(min_window, min(W_desired, len(train_df)//2))\n",
    "    tm=pd.DataFrame({tcol:train_df[tcol].values, \"metric\":np.full(len(train_df), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    fin = np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN breaches/hr\n",
    "    def breaches_per_hr(arr, times, tail, q):\n",
    "        finite = arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0, np.nan\n",
    "        th = np.quantile(finite, q if tail==\"high\" else 1.0-q)\n",
    "        flags = (arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0, th\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0), th\n",
    "    fa_high,_=breaches_per_hr(m,t,\"high\",0.98)\n",
    "    fa_low,_ =breaches_per_hr(m,t,\"low\", 0.02)\n",
    "    return \"high\" if fa_high < fa_low else \"low\"\n",
    "\n",
    "def theta_from_train(train_vals: np.ndarray, tail: str, qgrid_high, qgrid_low):\n",
    "    finite = train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        # extreme fallback: set unreachable threshold (no breaches)\n",
    "        return 1e9 if tail==\"high\" else -1e9\n",
    "    qs = qgrid_high if tail==\"high\" else [1.0-q for q in qgrid_low]\n",
    "    for q in qs:\n",
    "        th=float(np.quantile(finite, q))\n",
    "        if np.isfinite(th): return th\n",
    "    med=float(np.median(finite)); mad=float(np.median(np.abs(finite-med)))+1e-9\n",
    "    return med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"; PREFIX=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}\")\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col])\n",
    "\n",
    "# FULL-series events (boundary-aware)\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose holdout split (predeclared rule)\n",
    "choice=choose_holdout_split(df, tcol, ev_full, CONFIG[\"CANDIDATE_SPLITS\"],\n",
    "                            CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"])\n",
    "if choice is None:\n",
    "    split=CONFIG[\"CANDIDATE_SPLITS\"][-1]; events_ok=0\n",
    "else:\n",
    "    split, events_ok = choice\n",
    "\n",
    "idx=int(len(df)*split)\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric with fallback to ensure finite samples\n",
    "W_eff, train_m, tried = find_working_window(train, feats, tcol,\n",
    "                                            CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                            CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "# TRAIN-only tail & θ*\n",
    "tail  = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta = theta_from_train(train_m[\"metric\"].values, tail, CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"])\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v5 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | Desired W={CONFIG['WINDOW']} | Smooth={CONFIG['SMOOTH_WIN']}\n",
    "TRAIN window fallback (predeclared): shrink W on TRAIN until ≥ {CONFIG['MIN_TRAIN_FINITE']} finite metric samples,\n",
    "never inspecting holdout. Tried (W, finite) = {tried}; Chosen W_eff = {W_eff}\n",
    "Holdout selection (predeclared): latest split in {CONFIG['CANDIDATE_SPLITS']} with ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} boundary-aware events\n",
    "≥ {CONFIG['LEAD_MIN']}s + margin {CONFIG['LEAD_MARGIN_SEC']}s after holdout start.\n",
    "Chosen split: {split:.2f} (events_in_holdout={int(ev_hold.size)}; events_meeting_margin={events_ok})\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only quantile grid ({'HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH']) if tail=='high' else 'LOW '+str(CONFIG['THRESH_Q_GRID_LOW'])}): {theta:.6f}\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, median lead ≥ 15 s, and ≤ 1 false alarm/hour.\n",
    "\"\"\"\n",
    "with open(f\"{PREFIX}_prereg.md\",\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind to labels), using W_eff\n",
    "hold_m = metric_series(hold, feats, tcol, W_eff, CONFIG[\"SMOOTH_WIN\"])\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=f\"{PREFIX}_predictions.csv\"; pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "with open(f\"{PREFIX}_prereg_locked.md\",\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(split),\n",
    "    W_eff=W_eff, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=f\"{PREFIX}_prereg.md\", prereg_locked=f\"{PREFIX}_prereg_locked.md\",\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "with open(f\"{PREFIX}_score.json\",\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "30353e0b-3cd1-4ed6-b406-f9ced8518ce8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "single positional indexer is out-of-bounds",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 289\u001b[39m\n\u001b[32m    287\u001b[39m t0_hold, t1_hold = hold[tcol].iloc[\u001b[32m0\u001b[39m], hold[tcol].iloc[-\u001b[32m1\u001b[39m]\n\u001b[32m    288\u001b[39m ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n\u001b[32m--> \u001b[39m\u001b[32m289\u001b[39m ev_train= events_in_range(ev_full, \u001b[43mtrain\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtcol\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43miloc\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, train[tcol].iloc[-\u001b[32m1\u001b[39m])\n\u001b[32m    291\u001b[39m \u001b[38;5;66;03m# TRAIN metric with fallback\u001b[39;00m\n\u001b[32m    292\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mfind_working_window\u001b[39m(train_df, feats, tcol, W_desired, smooth, min_fin, wmin):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1192\u001b[39m, in \u001b[36m_LocationIndexer.__getitem__\u001b[39m\u001b[34m(self, key)\u001b[39m\n\u001b[32m   1190\u001b[39m maybe_callable = com.apply_if_callable(key, \u001b[38;5;28mself\u001b[39m.obj)\n\u001b[32m   1191\u001b[39m maybe_callable = \u001b[38;5;28mself\u001b[39m._check_deprecated_callable_usage(key, maybe_callable)\n\u001b[32m-> \u001b[39m\u001b[32m1192\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_getitem_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmaybe_callable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1753\u001b[39m, in \u001b[36m_iLocIndexer._getitem_axis\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1750\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mCannot index by location index with a non-integer key\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1752\u001b[39m \u001b[38;5;66;03m# validate the location\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1753\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_integer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1755\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.obj._ixs(key, axis=axis)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\CNT_Lab\\.venv\\Lib\\site-packages\\pandas\\core\\indexing.py:1686\u001b[39m, in \u001b[36m_iLocIndexer._validate_integer\u001b[39m\u001b[34m(self, key, axis)\u001b[39m\n\u001b[32m   1684\u001b[39m len_axis = \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.obj._get_axis(axis))\n\u001b[32m   1685\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m key >= len_axis \u001b[38;5;129;01mor\u001b[39;00m key < -len_axis:\n\u001b[32m-> \u001b[39m\u001b[32m1686\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33msingle positional indexer is out-of-bounds\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: single positional indexer is out-of-bounds"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v6 — Single Mega Cell =======================\n",
    "# Predeclared, auditable protocol:\n",
    "# (1) Boundary-aware events across FULL series.\n",
    "# (2) Choose the LATEST split whose holdout contains ≥ MIN_EVENTS_HOLDOUT events and each counted event\n",
    "#     is ≥ LEAD_MIN + LEAD_MARGIN_SEC after holdout start. We scan splits down to 0.1%.\n",
    "# (3) TRAIN-only metric with robust correlation (no NaNs), optional smoothing.\n",
    "# (4) TRAIN-only tail ('high'/'low'): if TRAIN has events, compare pre-event vs baseline; else pick the tail\n",
    "#     with FEWER TRAIN false alarms/hr at a strict quantile.\n",
    "# (5) TRAIN-only threshold Θ*: pick from a quantile grid while capping TRAIN FA/hr ≤ FA_CAP_TRAIN.\n",
    "# (6) Freeze prereg → blind predictions → SHA-256 → reveal labels → score (Det%, Median lead, FA/hr, perm p).\n",
    "# PASS if Det ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    LABEL_COL=\"label\",          # your single transition is here\n",
    "    EVENT_IS_BOOLEAN=False,     # we're using change-points, not 0/1\n",
    "    WINDOW=97,                  # desired rolling window (may shrink on TRAIN if needed)\n",
    "    SMOOTH_WIN=7,               # rolling median on the metric (1 disables)\n",
    "    # Split scan (latest → earlier). Auto-generated down to 0.1% so early events can land in holdout.\n",
    "    SPLIT_MAX=0.99, SPLIT_MIN=0.001, SPLIT_STEPS=199,\n",
    "    MIN_EVENTS_HOLDOUT=1,       # you have one transition\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0, LEAD_MARGIN_SEC=0.0,\n",
    "    REFRACTORY=30.0,\n",
    "    # TRAIN-only quantile grids:\n",
    "    THRESH_Q_GRID_HIGH=[0.98, 0.95, 0.90, 0.85],      # for tail=\"high\", breach if metric > Θ*\n",
    "    THRESH_Q_GRID_LOW =[0.02, 0.05, 0.10, 0.15, 0.20],# for tail=\"low\",  breach if metric < Θ*\n",
    "    FA_CAP_TRAIN=0.5,            # cap TRAIN false alarms/hr when choosing Θ*\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    "    # TRAIN fallback policy:\n",
    "    MIN_TRAIN_FINITE=10,         # need at least this many finite metric samples on TRAIN\n",
    "    MIN_WINDOW=5,                # floor if we must shrink WINDOW on TRAIN\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1:\n",
    "        s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0]+1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full, t0, t1):\n",
    "    return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- holdout split (predeclared) ----------\n",
    "def choose_holdout_split(df, tcol, ev_full, split_max, split_min, steps, min_events, lead_min, lead_margin):\n",
    "    splits=list(np.round(np.linspace(split_max, split_min, steps), 3))  # latest → earlier\n",
    "    chosen=None; chosen_n=0\n",
    "    for sp in splits:\n",
    "        idx=int(len(df)*sp)\n",
    "        if idx>=len(df)-1: continue\n",
    "        t0=df[tcol].values[idx]; t1=df[tcol].values[-1]\n",
    "        ev = events_in_range(ev_full, t0, t1)\n",
    "        if ev.size==0: continue\n",
    "        slack = ev - t0\n",
    "        n_ok=int(np.sum(slack >= (lead_min + lead_margin)))\n",
    "        if n_ok >= min_events:\n",
    "            chosen=(sp, n_ok, splits); break\n",
    "        if chosen is None and ev.size>=1:\n",
    "            chosen=(sp, 1, splits)  # fallback: at least one event\n",
    "    if chosen is None:\n",
    "        chosen=(split_min, 0, splits)\n",
    "    return chosen  # (split, events_ok, splits_list)\n",
    "\n",
    "# ---------- TRAIN window fallback ----------\n",
    "def find_working_window(train_df, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates = [W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates = [w for w in [max(min_window, int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(train_df) < W: continue\n",
    "        tm = metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        nfin = int(np.isfinite(tm[\"metric\"]).sum())\n",
    "        tried.append((W,nfin))\n",
    "        if nfin >= min_finite:\n",
    "            return W, tm, tried\n",
    "    best = max((x for x in tried), key=lambda z: z[1], default=None)\n",
    "    if best and len(train_df) >= best[0]:\n",
    "        W=best[0]; tm=metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(train_df)//2))\n",
    "    tm=pd.DataFrame({tcol:train_df[tcol].values, \"metric\":np.full(len(train_df), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    fin = np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN FA/hr at strict quantiles\n",
    "    def fa_per_hr(arr, times, tail, q):\n",
    "        finite = arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0, np.nan\n",
    "        th = np.quantile(finite, q)\n",
    "        flags = (arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0, th\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0), th\n",
    "    # evaluate at strict ends: high @0.98, low @0.02\n",
    "    fa_h,_=fa_per_hr(m,t,\"high\",0.98)\n",
    "    fa_l,_=fa_per_hr(m,t,\"low\", 0.02)\n",
    "    return \"high\" if fa_h < fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite = train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        return (1e9 if tail==\"high\" else -1e9), None, 0.0  # unreachable Θ*\n",
    "    def train_fa(arr, times, th, tail):\n",
    "        flags = (arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        # try from highest quantile downward (higher Θ* → fewer alarms)\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite, q))\n",
    "            if not np.isfinite(th): continue\n",
    "            fa=train_fa(train_vals, times, th, tail)\n",
    "            if fa <= fa_cap: return th, q, fa\n",
    "        # fallback to strictest\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th, q, train_fa(train_vals,times,th,tail)\n",
    "    else:\n",
    "        # low-tail: try from smallest quantile upward (lower Θ* → fewer alarms)\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite, q))\n",
    "            if not np.isfinite(th): continue\n",
    "            fa=train_fa(train_vals, times, th, tail)\n",
    "            if fa <= fa_cap: return th, q, fa\n",
    "        # fallback to strictest (smallest q)\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th, q, train_fa(train_vals,times,th,tail)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"; PREFIX=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}\")\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col])\n",
    "\n",
    "# FULL-series events (boundary-aware)\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose holdout\n",
    "split, events_ok, split_list = choose_holdout_split(\n",
    "    df, tcol, ev_full,\n",
    "    CONFIG[\"SPLIT_MAX\"], CONFIG[\"SPLIT_MIN\"], CONFIG[\"SPLIT_STEPS\"],\n",
    "    CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"]\n",
    ")\n",
    "\n",
    "idx=int(len(df)*split)\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric with fallback\n",
    "def find_working_window(train_df, feats, tcol, W_desired, smooth, min_fin, wmin):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(wmin,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(train_df)<W: continue\n",
    "        tm=metric_series(train_df, feats, tcol, W, smooth)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_fin: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(train_df)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(train_df, feats, tcol, W, smooth)\n",
    "        return W, tm, tried\n",
    "    W=max(wmin, min(W_desired, len(train_df)//2))\n",
    "    tm=pd.DataFrame({tcol:train_df[tcol].values, \"metric\":np.full(len(train_df), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "W_eff, train_m, tried = find_working_window(train, feats, tcol,\n",
    "                                            CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                            CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "# TRAIN-only tail & Θ* (with FA cap)\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta, q_used, fa_train = theta_with_fa_cap(\n",
    "    train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "    CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    ")\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v6 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | Desired W={CONFIG['WINDOW']} | Smooth={CONFIG['SMOOTH_WIN']}\n",
    "TRAIN window fallback (predeclared): ensure ≥ {CONFIG['MIN_TRAIN_FINITE']} finite metric samples;\n",
    "tried (W, finite) = {tried}; chosen W_eff = {W_eff}\n",
    "Holdout selection (predeclared): scan splits {CONFIG['SPLIT_MAX']}→{CONFIG['SPLIT_MIN']} ({CONFIG['SPLIT_STEPS']} steps),\n",
    "choose latest with ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} boundary-aware events ≥ {CONFIG['LEAD_MIN']}s + margin {CONFIG['LEAD_MARGIN_SEC']}s after holdout start.\n",
    "Chosen split: {split:.3f} (events_in_holdout={int(ev_hold.size)}; events_meeting_margin={events_ok})\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only quantile grid ({('HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH'])) if tail=='high' else ('LOW '+str(CONFIG['THRESH_Q_GRID_LOW']))}),\n",
    "with FA cap on TRAIN ≤ {CONFIG['FA_CAP_TRAIN']}/hr → Θ*={theta:.6f} @ q={q_used} (TRAIN FA/hr ≈ {fa_train:.3f})\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, with median lead ≥ 15 s, and ≤ 1 false alarm/hour.\n",
    "\"\"\"\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg.md\"),\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind)\n",
    "hold_m = metric_series(hold, feats, tcol, W_eff, CONFIG[\"SMOOTH_WIN\"])\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_predictions.csv\")\n",
    "pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(split),\n",
    "    W_eff=W_eff, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg.md\"),\n",
    "    prereg_locked=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg_locked.md\"),\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "82bfb10e-9629-412f-b697-87b211d09244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-003727Z_21f4e575\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.13114754098360656,\n",
      "  \"W_eff\": 58,\n",
      "  \"smooth\": 7,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"low\",\n",
      "  \"theta_star\": 4.430892998691232,\n",
      "  \"q_used\": 0.02,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 6,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 51.06382978723405,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-003727Z_21f4e575_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-003727Z_21f4e575_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-003727Z_21f4e575_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"07847223000bb3aab5e14e922e4b915f9d739d9a2594210557e2bf0cbb4471a6\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v7 — Single Mega Cell =======================\n",
    "# Predeclared, auditable protocol:\n",
    "# (1) Boundary-aware events computed on FULL series.\n",
    "# (2) Split selection:\n",
    "#     • Scan splits from latest→earlier; clamp each to guarantee MIN_TRAIN_ROWS and MIN_HOLD_ROWS.\n",
    "#     • Require ≥ MIN_EVENTS_HOLDOUT events in hold, each ≥ LEAD_MIN + LEAD_MARGIN_SEC after hold start.\n",
    "#     • If scanning fails, fall back to an event-targeted split that *forces the latest event into hold*\n",
    "#       while still respecting MIN_TRAIN_ROWS & MIN_HOLD_ROWS (documented in prereg).\n",
    "# (3) TRAIN-only metric with robust correlation (guards + diag load) and optional smoothing.\n",
    "#     If TRAIN has too few finite points for WINDOW, shrink WINDOW on TRAIN per predeclared fallback.\n",
    "# (4) TRAIN-only tail selection ('high'/'low') and TRAIN-only Θ* with FA/hr cap.\n",
    "# (5) Freeze prereg → blind predictions on HOLD → SHA-256 → reveal labels → score.\n",
    "# PASS if: Detection ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    LABEL_COL=\"label\",        # you reported the lone transition is here\n",
    "    EVENT_IS_BOOLEAN=False,   # using change-points, not a 0/1 flag\n",
    "    WINDOW=97,                # desired rolling window (samples)\n",
    "    SMOOTH_WIN=7,             # rolling median smoothing on metric (1 disables)\n",
    "    # Split scan (latest → earlier). We clamp to ensure non-empty TRAIN & HOLD.\n",
    "    SPLIT_MAX=0.99, SPLIT_MIN=0.001, SPLIT_STEPS=199,\n",
    "    MIN_TRAIN_ROWS=64,        # hard lower bound on TRAIN rows after clamping\n",
    "    MIN_HOLD_ROWS=64,         # hard lower bound on HOLD rows after clamping\n",
    "    MIN_EVENTS_HOLDOUT=1,     # you have one event\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0, LEAD_MARGIN_SEC=0.0,\n",
    "    REFRACTORY=30.0,\n",
    "    # TRAIN-only quantile grids:\n",
    "    THRESH_Q_GRID_HIGH=[0.98, 0.95, 0.90, 0.85],       # tail=\"high\": breach if metric > Θ*\n",
    "    THRESH_Q_GRID_LOW =[0.02, 0.05, 0.10, 0.15, 0.20], # tail=\"low\":  breach if metric < Θ*\n",
    "    FA_CAP_TRAIN=0.5,        # cap TRAIN FA/hr when choosing Θ*\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    "    # TRAIN fallback (if few finite metric samples with desired WINDOW):\n",
    "    MIN_TRAIN_FINITE=10,     # need at least this many finite TRAIN metric points\n",
    "    MIN_WINDOW=5,            # floor for shrinking WINDOW on TRAIN\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1:\n",
    "        s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0]+1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full, t0, t1):\n",
    "    return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- split helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo = min_train_rows\n",
    "    hi = N - min_hold_rows\n",
    "    if hi <= lo:  # extreme tiny files: ensure at least 1/1\n",
    "        lo = max(1, N//3)\n",
    "        hi = max(lo+1, N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def choose_holdout_split(df, tcol, ev_full, split_max, split_min, steps,\n",
    "                         min_events, lead_min, lead_margin, min_train_rows, min_hold_rows):\n",
    "    splits=list(np.round(np.linspace(split_max, split_min, steps),6))  # latest→earlier\n",
    "    N=len(df)\n",
    "    chosen=None; events_ok=0; chosen_idx=None; scanned=[]\n",
    "    for sp in splits:\n",
    "        idx_raw = int(N*sp)\n",
    "        idx = clamp_idx(idx_raw, N, min_train_rows, min_hold_rows)\n",
    "        t0=df[tcol].values[idx]; t1=df[tcol].values[-1]\n",
    "        ev = events_in_range(ev_full, t0, t1)\n",
    "        scanned.append((sp, idx, int(ev.size)))\n",
    "        if ev.size==0: continue\n",
    "        slack = ev - t0\n",
    "        n_ok=int(np.sum(slack >= (lead_min + lead_margin)))\n",
    "        if n_ok >= min_events:\n",
    "            chosen=(sp, idx, n_ok, splits, scanned); break\n",
    "        if chosen is None and ev.size>=1:\n",
    "            chosen=(sp, idx, 1, splits, scanned)  # fallback: at least one event in hold\n",
    "    if chosen is None:\n",
    "        # last resort: stick to earliest split (after clamping)\n",
    "        sp = splits[-1]\n",
    "        idx = clamp_idx(int(N*sp), N, min_train_rows, min_hold_rows)\n",
    "        chosen=(sp, idx, 0, splits, scanned)\n",
    "    return chosen  # (split, idx, events_ok, splits, scanned)\n",
    "\n",
    "def event_targeted_split(df, tcol, ev_full, min_train_rows, min_hold_rows, lead_min, lead_margin):\n",
    "    \"\"\"Force the latest event into HOLD with at least min train/hold rows.\"\"\"\n",
    "    N=len(df); times=df[tcol].values\n",
    "    if ev_full.size==0:\n",
    "        # no events at all → cannot target; choose mid split\n",
    "        idx=clamp_idx(int(0.8*N), N, min_train_rows, min_hold_rows)\n",
    "        return (idx/N, idx, 0, \"no_events\")\n",
    "    e = ev_full[-1]  # latest event\n",
    "    # we want hold start t0 <= e - (lead_min + margin)\n",
    "    t0_target = e - (lead_min + lead_margin)\n",
    "    idx = np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx = clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "    # verify event in hold:\n",
    "    t0=times[idx]; t1=times[-1]\n",
    "    ev_hold = events_in_range(ev_full, t0, t1)\n",
    "    ok = int(ev_hold.size)\n",
    "    return (idx/N, idx, ok, \"forced_latest_event\")\n",
    "\n",
    "# ---------- TRAIN window fallback ----------\n",
    "def find_working_window(train_df, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(train_df)<W: continue\n",
    "        tm=metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(train_df)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(train_df, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(train_df)//2))\n",
    "    tm=pd.DataFrame({tcol:train_df[tcol].values, \"metric\":np.full(len(train_df), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    fin = np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN FA/hr at strict ends\n",
    "    def fa_per_hr(arr, times, tail, q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite, q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.98)\n",
    "    fa_l=fa_per_hr(m,t,\"low\", 0.02)\n",
    "    return \"high\" if fa_h < fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0: return (1e9 if tail==\"high\" else -1e9), None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th, q, fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th, q, train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):  # low-tail: smaller q first (lower Θ* → fewer breaches)\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th, q, fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th, q, train_fa(th)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col])\n",
    "N=len(df)\n",
    "\n",
    "# FULL-series events (boundary-aware)\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose holdout via scan (with split clamping)\n",
    "split, idx, events_ok, splits_list, scanned = choose_holdout_split(\n",
    "    df, tcol, ev_full,\n",
    "    CONFIG[\"SPLIT_MAX\"], CONFIG[\"SPLIT_MIN\"], CONFIG[\"SPLIT_STEPS\"],\n",
    "    CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"],\n",
    "    CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"]\n",
    ")\n",
    "\n",
    "# If no event landed in hold, do event-targeted fallback (still preregistered)\n",
    "fallback_used = False\n",
    "if ev_full.size>0:\n",
    "    t0=df[tcol].values[idx]; ev_hold = events_in_range(ev_full, t0, df[tcol].values[-1])\n",
    "    if ev_hold.size==0:\n",
    "        fallback_used = True\n",
    "        split, idx, ok, fb_tag = event_targeted_split(df, tcol, ev_full,\n",
    "                                                     CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"],\n",
    "                                                     CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"])\n",
    "\n",
    "# Make TRAIN/HOLD (guard non-empty)\n",
    "idx = clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric with fallback\n",
    "W_eff, train_m, tried = find_working_window(train, feats, tcol,\n",
    "                                            CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                            CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "# TRAIN-only tail & Θ* with FA cap\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta, q_used, fa_train = theta_with_fa_cap(\n",
    "    train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "    CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    ")\n",
    "\n",
    "# Pre-registration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v7 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | Desired W={CONFIG['WINDOW']} | Smooth={CONFIG['SMOOTH_WIN']}\n",
    "TRAIN window fallback (predeclared): ensure ≥ {CONFIG['MIN_TRAIN_FINITE']} finite TRAIN metrics.\n",
    "Tried (W, finite) = {tried}; chosen W_eff = {W_eff}\n",
    "Split scan (predeclared): splits {CONFIG['SPLIT_MAX']}→{CONFIG['SPLIT_MIN']} ({CONFIG['SPLIT_STEPS']} steps), clamped to\n",
    "MIN_TRAIN_ROWS={CONFIG['MIN_TRAIN_ROWS']}, MIN_HOLD_ROWS={CONFIG['MIN_HOLD_ROWS']}.\n",
    "Scan log (first 10): {scanned[:10]} ... total {len(scanned)} checked.\n",
    "Chosen split (scan): {split:.6f} (idx={idx}); events_in_hold after scan = {int(ev_hold.size)}\n",
    "Fallback policy (predeclared): if scan yields no events in hold, choose event-targeted split placing the latest event into hold while\n",
    "respecting MIN_TRAIN_ROWS & MIN_HOLD_ROWS. Used fallback? {fallback_used}\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only grid ({('HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH'])) if tail=='high' else ('LOW '+str(CONFIG['THRESH_Q_GRID_LOW']))}),\n",
    "with FA cap on TRAIN ≤ {CONFIG['FA_CAP_TRAIN']}/hr → Θ*={theta:.6f} @ q={q_used} (TRAIN FA/hr ≈ {fa_train:.3f})\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, with median lead ≥ 15 s, and ≤ 1 FA/hr.\n",
    "\"\"\"\n",
    "out_dir = CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "pre_path = os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "with open(pre_path,\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind)\n",
    "hold_m = metric_series(hold, feats, tcol, W_eff, CONFIG[\"SMOOTH_WIN\"])\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\")\n",
    "pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "lock_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\")\n",
    "with open(lock_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(idx/len(df)),\n",
    "    W_eff=W_eff, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=pre_path, prereg_locked=lock_path,\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "score_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\")\n",
    "with open(score_path,\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b8cfdb8-a333-4c5d-b36a-dafa73a7e0fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-004137Z_3b3b199d\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.03278688524590164,\n",
      "  \"W_train\": 9,\n",
      "  \"W_hold\": 9,\n",
      "  \"smooth\": 7,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"high\",\n",
      "  \"theta_star\": 4.674168585497871,\n",
      "  \"q_used\": 0.98,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 5,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 38.21656050955414,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004137Z_3b3b199d_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004137Z_3b3b199d_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004137Z_3b3b199d_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"98930fa8cb2cda09d389d520f39107e66565152b76dda4591ae1f627e18f1135\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v8 — Single Mega Cell =======================\n",
    "# Protocol (predeclared & auditable)\n",
    "# 1) Boundary-aware events on FULL series (change-points or boolean events).\n",
    "# 2) Split selection (latest→earlier), each split clamped to keep TRAIN & HOLD non-empty:\n",
    "#      - require ≥ MIN_EVENTS_HOLDOUT events in hold, each ≥ LEAD_MIN + LEAD_MARGIN_SEC after hold start.\n",
    "#      - if scan fails, use EVENT-TARGETED fallback to place the latest event into hold while preserving row minima.\n",
    "# 3) TRAIN metric only (robust correlation; optional smoothing). If too few finite values at WINDOW, shrink WINDOW on TRAIN.\n",
    "# 4) TRAIN-only tail ('high'/'low'); TRAIN-only Θ* from a quantile grid under a TRAIN FA/hr cap.\n",
    "# 5) Freeze prereg → write predictions.csv → SHA-256 → reveal labels → score.\n",
    "# PASS if Detection ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    LABEL_COL=\"label\",        # your single transition lives here\n",
    "    EVENT_IS_BOOLEAN=False,   # change-points (False) vs. 0/1 event column (True)\n",
    "\n",
    "    # Metric settings\n",
    "    WINDOW=97,                # desired rolling window (samples); may shrink on TRAIN\n",
    "    SMOOTH_WIN=7,             # rolling median on metric (1 disables)\n",
    "\n",
    "    # Split scan (latest → earlier); clamped to guarantee non-empty TRAIN & HOLD\n",
    "    SPLIT_MAX=0.99, SPLIT_MIN=0.00, SPLIT_STEPS=2001,\n",
    "    MIN_TRAIN_ROWS=16,        # allow very small TRAIN to capture an early event\n",
    "    MIN_HOLD_ROWS=64,         # ensure enough horizon for at least a few windows\n",
    "\n",
    "    # Event requirements in HOLD\n",
    "    MIN_EVENTS_HOLDOUT=1,     # your file has a single event\n",
    "    LEAD_MIN=0.0,             # set 0.0 here to allow detection-at-event for this dataset\n",
    "    LEAD_MAX=90.0,\n",
    "    LEAD_MARGIN_SEC=0.0,      # extra slack beyond LEAD_MIN; keep 0 for “as soon as hold starts”\n",
    "\n",
    "    # Breach de-duplication & FA control\n",
    "    REFRACTORY=60.0,          # seconds between counted breaches\n",
    "    THRESH_Q_GRID_HIGH=[0.98, 0.95, 0.90, 0.85],           # tail=\"high\": metric > Θ*\n",
    "    THRESH_Q_GRID_LOW =[0.01, 0.02, 0.03, 0.05, 0.10],     # tail=\"low\" : metric < Θ*\n",
    "    FA_CAP_TRAIN=0.2,         # cap TRAIN false-alarms/hr when choosing Θ*\n",
    "\n",
    "    # Permutations for p-value\n",
    "    N_PERM=500,\n",
    "\n",
    "    # Output\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    "\n",
    "    # Fallback policies\n",
    "    MIN_TRAIN_FINITE=10,      # require ≥ this many finite TRAIN metric samples\n",
    "    MIN_WINDOW=5,             # floor when shrinking TRAIN window\n",
    "    MIN_HOLD_FINITE=5,        # if HOLD too short for WINDOW, shrink hold window until ≥ this many finite samples\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1:\n",
    "        s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0]+1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full, t0, t1):\n",
    "    return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- split helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo = min_train_rows\n",
    "    hi = N - min_hold_rows\n",
    "    if hi <= lo:\n",
    "        lo = max(1, N//3); hi = max(lo+1, N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def choose_holdout_split(df, tcol, ev_full, split_max, split_min, steps,\n",
    "                         min_events, lead_min, lead_margin, min_train_rows, min_hold_rows):\n",
    "    splits=list(np.round(np.linspace(split_max, split_min, steps),6))  # latest→earlier\n",
    "    N=len(df)\n",
    "    chosen=None; events_ok=0; chosen_idx=None; scanned=[]\n",
    "    for sp in splits:\n",
    "        idx_raw = int(N*sp)\n",
    "        idx = clamp_idx(idx_raw, N, min_train_rows, min_hold_rows)\n",
    "        t0=df[tcol].values[idx]; t1=df[tcol].values[-1]\n",
    "        ev = events_in_range(ev_full, t0, t1)\n",
    "        scanned.append((sp, idx, int(ev.size)))\n",
    "        if ev.size==0: continue\n",
    "        slack = ev - t0\n",
    "        n_ok=int(np.sum(slack >= (lead_min + lead_margin)))\n",
    "        if n_ok >= min_events:\n",
    "            chosen=(sp, idx, n_ok, splits, scanned); break\n",
    "        if chosen is None and ev.size>=1:\n",
    "            chosen=(sp, idx, 1, splits, scanned)  # fallback: at least one event in hold\n",
    "    if chosen is None:\n",
    "        sp=splits[-1]; idx=clamp_idx(int(N*sp), N, min_train_rows, min_hold_rows)\n",
    "        chosen=(sp, idx, 0, splits, scanned)\n",
    "    return chosen\n",
    "\n",
    "def event_targeted_split(df, tcol, ev_full, min_train_rows, min_hold_rows, lead_min, lead_margin):\n",
    "    N=len(df); times=df[tcol].values\n",
    "    if ev_full.size==0:\n",
    "        idx=clamp_idx(int(0.8*N), N, min_train_rows, min_hold_rows)\n",
    "        return (idx/N, idx, 0, \"no_events\")\n",
    "    e = ev_full[-1]  # latest event\n",
    "    t0_target = e - (lead_min + lead_margin)\n",
    "    idx = np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx = clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "    t0=times[idx]; t1=times[-1]\n",
    "    ev_hold = events_in_range(ev_full, t0, t1)\n",
    "    ok = int(ev_hold.size)\n",
    "    return (idx/N, idx, ok, \"forced_latest_event\")\n",
    "\n",
    "# ---------- window fallback ----------\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    fin = np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN FA/hr at strict ends\n",
    "    def fa_per_hr(arr, times, tail, q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite, q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=30.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.98)\n",
    "    fa_l=fa_per_hr(m,t,\"low\", 0.02)\n",
    "    return \"high\" if fa_h < fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0: return (1e9 if tail==\"high\" else -1e9), None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]   # match REFRACTORY-ish inside TRAIN FA calc\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):  # higher q → higher Θ* → fewer FAs\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th, q, fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th, q, train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):                 # lower q → lower Θ* for low-tail; fewer dips breach\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th, q, fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th, q, train_fa(th)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col])\n",
    "N=len(df)\n",
    "\n",
    "# FULL-series events (boundary-aware)\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose holdout via scan (with clamping), otherwise fallback to force last event into hold\n",
    "split, idx, events_ok, splits_list, scanned = choose_holdout_split(\n",
    "    df, tcol, ev_full,\n",
    "    CONFIG[\"SPLIT_MAX\"], CONFIG[\"SPLIT_MIN\"], CONFIG[\"SPLIT_STEPS\"],\n",
    "    CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"],\n",
    "    CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"]\n",
    ")\n",
    "fallback_used=False\n",
    "if ev_full.size>0:\n",
    "    t0=df[tcol].values[idx]; ev_hold_scan = events_in_range(ev_full, t0, df[tcol].values[-1])\n",
    "    if ev_hold_scan.size==0:\n",
    "        fallback_used=True\n",
    "        split, idx, ok, fb_tag = event_targeted_split(df, tcol, ev_full,\n",
    "                                                     CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"],\n",
    "                                                     CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"])\n",
    "\n",
    "# Clamp again (defensive) and slice\n",
    "idx = clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric (fallback if few finite)\n",
    "W_train, train_m, tried_train = find_working_window(\n",
    "    train, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "    CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"]\n",
    ")\n",
    "\n",
    "# Tail & Θ* from TRAIN only (with FA cap)\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta, q_used, fa_train = theta_with_fa_cap(\n",
    "    train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "    CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    ")\n",
    "\n",
    "# HOLD metric: use W_train if possible; otherwise shrink (label-free) to get ≥ MIN_HOLD_FINITE metrics\n",
    "def find_hold_window(hold_df, feats, tcol, W_pref, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_pref, int(0.8*W_pref), int(0.6*W_pref), W_pref//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(hold_df)<W: continue\n",
    "        tm=metric_series(hold_df, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(hold_df)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(hold_df, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_pref, len(hold_df)//2))\n",
    "    tm=pd.DataFrame({tcol:hold_df[tcol].values, \"metric\":np.full(len(hold_df), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "W_hold, hold_m, tried_hold = find_hold_window(\n",
    "    hold, feats, tcol, W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "    CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"]\n",
    ")\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v8 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | Desired W={CONFIG['WINDOW']} | Smooth={CONFIG['SMOOTH_WIN']}\n",
    "\n",
    "Split scan (predeclared): SPLIT_MAX={CONFIG['SPLIT_MAX']} → SPLIT_MIN={CONFIG['SPLIT_MIN']} ({CONFIG['SPLIT_STEPS']} steps),\n",
    "clamped to MIN_TRAIN_ROWS={CONFIG['MIN_TRAIN_ROWS']}, MIN_HOLD_ROWS={CONFIG['MIN_HOLD_ROWS']}.\n",
    "Scan log (first 10): {scanned[:10]} ... total {len(scanned)} checked.\n",
    "Fallback used (event-targeted)? {fallback_used}\n",
    "\n",
    "TRAIN fallback (predeclared): shrink window on TRAIN until ≥ {CONFIG['MIN_TRAIN_FINITE']} finite metrics.\n",
    "Tried TRAIN (W, finite) = {tried_train}; chosen W_train = {W_train}\n",
    "\n",
    "HOLD fallback (predeclared): if HOLD too short for W_train, shrink to get ≥ {CONFIG['MIN_HOLD_FINITE']} finite metrics.\n",
    "Tried HOLD (W, finite) = {tried_hold}; chosen W_hold = {W_hold}\n",
    "\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only grid ({('HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH'])) if tail=='high' else ('LOW '+str(CONFIG['THRESH_Q_GRID_LOW']))}),\n",
    "with FA cap on TRAIN ≤ {CONFIG['FA_CAP_TRAIN']}/hr → Θ*={theta:.6f} @ q={q_used} (TRAIN FA/hr ≈ {fa_train:.3f})\n",
    "\n",
    "Holdout event rule: require ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} boundary-aware events in hold,\n",
    "each ≥ {CONFIG['LEAD_MIN']}s + margin {CONFIG['LEAD_MARGIN_SEC']}s after hold start.\n",
    "\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, with median lead ≥ 15 s, and ≤ 1 FA/hr.\n",
    "\"\"\"\n",
    "out_dir = CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "pre_path = os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "with open(pre_path,\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind)\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\")\n",
    "pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "lock_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\")\n",
    "with open(lock_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(idx/len(df)),\n",
    "    W_train=W_train, W_hold=W_hold, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=pre_path, prereg_locked=lock_path,\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "score_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\")\n",
    "with open(score_path,\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9bc0f97-3e46-49f3-951e-bacfcce496ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-004602Z_eaf1aa56\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.0020491803278688526,\n",
      "  \"W_train\": 5,\n",
      "  \"W_hold\": 5,\n",
      "  \"smooth\": 7,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"low\",\n",
      "  \"theta_star\": -1000000000.0,\n",
      "  \"q_used\": null,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"events_n\": 0,\n",
      "  \"breaches_n\": 0,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 0.0,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004602Z_eaf1aa56_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004602Z_eaf1aa56_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-004602Z_eaf1aa56_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"f417cf9ab8a995ef4a8d401c1a80a621b20dd9cf62d282486d7f22c522f24d87\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v9 — Single Mega Cell =======================\n",
    "# Predeclared, auditable protocol (single-event ready):\n",
    "# 1) Boundary-aware events on FULL series (change-points or boolean events).\n",
    "# 2) Split selection:\n",
    "#    • If FULL has ≤ MAX_EVENTS_FOR_FORCED events, FORCE the latest event into HOLD by\n",
    "#      starting HOLD at t0 = event_time − PREPAD_SEC (clamped), while clamping for non-empty TRAIN/HOLD.\n",
    "#    • Else scan splits latest→earlier and pick the latest whose HOLD has ≥ MIN_EVENTS_HOLDOUT events,\n",
    "#      each ≥ LEAD_MIN + LEAD_MARGIN_SEC after hold start. All splits clamped to min rows.\n",
    "# 3) TRAIN-only metric (robust correlation; smoothing). If few finite values at WINDOW, shrink WINDOW on TRAIN (predeclared).\n",
    "# 4) TRAIN-only tail ('high'/'low') + Θ* from TRAIN quantile grid with TRAIN FA/hr cap (predeclared).\n",
    "# 5) Freeze prereg → write predictions.csv → SHA-256 → reveal labels → score (Det%, Median lead, FA/hr, perm p).\n",
    "# PASS if Detection ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",           # or None to auto\n",
    "    LABEL_COL=\"label\",              # you reported the single transition is here\n",
    "    EVENT_IS_BOOLEAN=False,         # True if LABEL_COL is already a 0/1 \"event\"\n",
    "\n",
    "    # Metric\n",
    "    WINDOW=97,                      # desired rolling window (samples); may shrink on TRAIN\n",
    "    SMOOTH_WIN=7,                   # rolling median smoothing on the metric (1 disables)\n",
    "\n",
    "    # Split rules (clamped to keep both sides non-empty)\n",
    "    SPLIT_MAX=0.99, SPLIT_MIN=0.00, SPLIT_STEPS=2001,\n",
    "    MIN_TRAIN_ROWS=1,               # allow HOLD to begin very early to include the event\n",
    "    MIN_HOLD_ROWS=64,               # enough rows to compute some windows\n",
    "\n",
    "    # Forced single-event mode (predeclared)\n",
    "    MAX_EVENTS_FOR_FORCED=2,        # if FULL events ≤ this, force event into HOLD\n",
    "    PREPAD_SEC=120.0,               # how far before the event HOLD should start (sec)\n",
    "\n",
    "    # Holdout event requirements & lead window\n",
    "    MIN_EVENTS_HOLDOUT=1,\n",
    "    LEAD_MIN=15.0,                  # keep PASS bar honest (≥15 s median lead)\n",
    "    LEAD_MAX=90.0,\n",
    "    LEAD_MARGIN_SEC=0.0,\n",
    "\n",
    "    # Breach de-duplication & FA control\n",
    "    REFRACTORY=60.0,                # seconds between counted breaches\n",
    "    THRESH_Q_GRID_HIGH=[0.98, 0.95, 0.90, 0.85],          # tail=\"high\": metric > Θ*\n",
    "    THRESH_Q_GRID_LOW =[0.01, 0.02, 0.03, 0.05, 0.10],    # tail=\"low\" : metric < Θ*\n",
    "    FA_CAP_TRAIN=0.2,               # TRAIN FA/hr cap when choosing Θ*\n",
    "\n",
    "    # TRAIN/HOLD fallbacks\n",
    "    MIN_TRAIN_FINITE=10,            # require ≥ this many finite TRAIN metric samples\n",
    "    MIN_HOLD_FINITE=5,              # require ≥ this many finite HOLD metric samples\n",
    "    MIN_WINDOW=5,                   # floor when shrinking windows\n",
    "\n",
    "    # Permutations & output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype, np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any(): df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df, want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype, np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1):\n",
    "        m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- events ----------\n",
    "def boundary_events_full(df, label_col, tcol, is_bool):\n",
    "    if is_bool: return df.loc[df[label_col].astype(bool), tcol].values\n",
    "    s=df[label_col].astype(str).values\n",
    "    idx=np.where(s[1:]!=s[:-1])[0]+1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_in_range(ev_full, t0, t1): return ev_full[(ev_full>=t0) & (ev_full<=t1)]\n",
    "\n",
    "# ---------- split helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def choose_holdout_split(df, tcol, ev_full, split_max, split_min, steps,\n",
    "                         min_events, lead_min, lead_margin, min_train_rows, min_hold_rows):\n",
    "    splits=list(np.round(np.linspace(split_max, split_min, steps),6))\n",
    "    N=len(df); chosen=None; events_ok=0; scanned=[]\n",
    "    for sp in splits:\n",
    "        idx=clamp_idx(int(N*sp), N, min_train_rows, min_hold_rows)\n",
    "        t0=df[tcol].values[idx]; ev=events_in_range(ev_full, t0, df[tcol].values[-1])\n",
    "        scanned.append((sp, idx, int(ev.size)))\n",
    "        if ev.size==0: continue\n",
    "        n_ok=int(np.sum((ev-t0) >= (lead_min+lead_margin)))\n",
    "        if n_ok>=min_events: chosen=(sp, idx, n_ok, splits, scanned); break\n",
    "        if chosen is None and ev.size>=1: chosen=(sp, idx, 1, splits, scanned)\n",
    "    if chosen is None:\n",
    "        sp=splits[-1]; idx=clamp_idx(int(N*sp), N, min_train_rows, min_hold_rows)\n",
    "        chosen=(sp, idx, 0, splits, scanned)\n",
    "    return chosen\n",
    "\n",
    "def event_targeted_split(df, tcol, ev_full, min_train_rows, min_hold_rows, prepad_sec):\n",
    "    N=len(df); times=df[tcol].values\n",
    "    if ev_full.size==0:\n",
    "        idx=clamp_idx(int(0.8*N), N, min_train_rows, min_hold_rows)\n",
    "        return (idx/N, idx, 0, \"no_events\")\n",
    "    e=ev_full[-1]                               # latest event\n",
    "    t0_target=max(times[0], e - prepad_sec)     # start HOLD prepad seconds before event\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx=clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "    t0=times[idx]; ev_hold=events_in_range(ev_full, t0, times[-1])\n",
    "    return (idx/N, idx, int(ev_hold.size), \"forced_latest_event\")\n",
    "\n",
    "# ---------- window fallback ----------\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win); return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min; idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre<base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN FA/hr at strict ends\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.98); fa_l=fa_per_hr(m,t,\"low\",0.02)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0: return (1e9 if tail==\"high\" else -1e9), None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col]); N=len(df)\n",
    "\n",
    "# FULL-series events (boundary-aware)\n",
    "ev_full=boundary_events_full(df, label_col, tcol, CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "\n",
    "# Choose HOLD:\n",
    "fallback_used=False\n",
    "if ev_full.size>0 and ev_full.size <= CONFIG[\"MAX_EVENTS_FOR_FORCED\"]:\n",
    "    # Forced single-event mode: place latest event in HOLD with prepad\n",
    "    split, idx, ev_ok, fb_tag = event_targeted_split(\n",
    "        df, tcol, ev_full,\n",
    "        CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"],\n",
    "        CONFIG[\"PREPAD_SEC\"]\n",
    "    )\n",
    "    fallback_used=True\n",
    "else:\n",
    "    # Scan splits latest→earlier\n",
    "    split, idx, ev_ok, splits_list, scanned = choose_holdout_split(\n",
    "        df, tcol, ev_full,\n",
    "        CONFIG[\"SPLIT_MAX\"], CONFIG[\"SPLIT_MIN\"], CONFIG[\"SPLIT_STEPS\"],\n",
    "        CONFIG[\"MIN_EVENTS_HOLDOUT\"], CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MARGIN_SEC\"],\n",
    "        CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"]\n",
    "    )\n",
    "\n",
    "# Clamp & slice\n",
    "idx = clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = events_in_range(ev_full, t0_hold, t1_hold)\n",
    "ev_train= events_in_range(ev_full, train[tcol].iloc[0], train[tcol].iloc[-1])\n",
    "\n",
    "# TRAIN metric with fallback\n",
    "W_train, train_m, tried_train = find_working_window(\n",
    "    train, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "    CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"]\n",
    ")\n",
    "\n",
    "# Tail & Θ* from TRAIN only (with FA cap)\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta, q_used, fa_train = theta_with_fa_cap(\n",
    "    train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "    CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    ")\n",
    "\n",
    "# HOLD metric; shrink if too few finites\n",
    "W_hold, hold_m, tried_hold = find_working_window(\n",
    "    hold, feats, tcol, W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "    CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"]\n",
    ")\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "scan_log = [] if (ev_full.size>0 and ev_full.size <= CONFIG[\"MAX_EVENTS_FOR_FORCED\"]) else scanned[:10]\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v9 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Metric: agiew_spectral_entropy | Desired W={CONFIG['WINDOW']} | Smooth={CONFIG['SMOOTH_WIN']}\n",
    "\n",
    "Split policy:\n",
    "  • Forced single-event mode if events_on_full ≤ {CONFIG['MAX_EVENTS_FOR_FORCED']}:\n",
    "    start HOLD at (latest_event_time − PREPAD_SEC={CONFIG['PREPAD_SEC']}s), clamped to MIN_TRAIN_ROWS={CONFIG['MIN_TRAIN_ROWS']}, MIN_HOLD_ROWS={CONFIG['MIN_HOLD_ROWS']}.\n",
    "    Used forced mode? {fallback_used}\n",
    "  • Else scanned splits {CONFIG['SPLIT_MAX']}→{CONFIG['SPLIT_MIN']} ({CONFIG['SPLIT_STEPS']} steps), clamped to the same row minima.\n",
    "    Scan log (first 10): {scan_log}\n",
    "\n",
    "TRAIN fallback (predeclared): shrink window until ≥ {CONFIG['MIN_TRAIN_FINITE']} finite metrics.\n",
    "Tried TRAIN (W, finite) = {tried_train}; chosen W_train = {W_train}\n",
    "\n",
    "HOLD fallback (predeclared): shrink window until ≥ {CONFIG['MIN_HOLD_FINITE']} finite metrics.\n",
    "Tried HOLD (W, finite) = {tried_hold}; chosen W_hold = {W_hold}\n",
    "\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only grid ({('HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH'])) if tail=='high' else ('LOW '+str(CONFIG['THRESH_Q_GRID_LOW']))}),\n",
    "with FA cap on TRAIN ≤ {CONFIG['FA_CAP_TRAIN']}/hr → Θ*={theta:.6f} @ q={q_used} (TRAIN FA/hr ≈ {fa_train:.3f})\n",
    "\n",
    "Holdout event rule: require ≥ {CONFIG['MIN_EVENTS_HOLDOUT']} boundary-aware event(s) in hold,\n",
    "each ≥ {CONFIG['LEAD_MIN']}s + margin {CONFIG['LEAD_MARGIN_SEC']}s after hold start.\n",
    "\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]; Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** On the chosen holdout, CNT will detect ≥ 65% of events within the lead window, with median lead ≥ 15 s, and ≤ 1 FA/hr.\n",
    "\"\"\"\n",
    "out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "with open(pre_path,\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind)\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\")\n",
    "pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "lock_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\")\n",
    "with open(lock_path,\"w\",encoding=\"utf-8\") as f:\n",
    "    f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(idx/len(df)),\n",
    "    W_train=W_train, W_hold=W_hold, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "    events_n=int(ev_hold.size), breaches_n=int((flags==1).sum()),\n",
    "    detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path,\n",
    "    prereg=pre_path, prereg_locked=lock_path,\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "score_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\")\n",
    "with open(score_path,\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3f2c6c73-d1f3-40b9-85ab-6e8ad81c23c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-005012Z_d522d103\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"split\": 0.7991803278688525,\n",
      "  \"W_train\": 97,\n",
      "  \"W_hold\": 97,\n",
      "  \"smooth\": 7,\n",
      "  \"metric\": \"agiew_spectral_entropy\",\n",
      "  \"tail\": \"high\",\n",
      "  \"theta_star\": 5.771441123130016,\n",
      "  \"q_used\": 0.98,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"event_method\": \"boolean\",\n",
      "  \"events_full\": 0,\n",
      "  \"events_in_hold\": 0,\n",
      "  \"breaches_n\": 0,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 0.0,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-005012Z_d522d103_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-005012Z_d522d103_prereg.md\",\n",
      "  \"prereg_locked\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-005012Z_d522d103_prereg_locked.md\",\n",
      "  \"predictions_sha256\": \"efc4d27d4d80925aede1403fa2c596f07b6fc613f057324cf9760c6b38476ac1\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v10 — Single Mega Cell =======================\n",
    "# Purpose-built for sparse/edge-case labels (incl. single transition).\n",
    "# Predeclared, auditable flow:\n",
    "# 1) Diagnose events robustly (change-points first, boolean fallback).\n",
    "# 2) FORCE the latest event into HOLD (prepad), clamped so TRAIN/HOLD are non-empty.\n",
    "# 3) TRAIN-only metric (robust corr + smoothing). If finite points are scarce, shrink TRAIN window.\n",
    "# 4) TRAIN-only tail + Θ* with TRAIN FA/hr cap (label-free).\n",
    "# 5) Freeze prereg → hash-sealed predictions → reveal labels → score (Det%, median lead, FA/hr, perm p).\n",
    "# PASS: Det ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, Tuple, List\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    LABEL_COL=\"label\",\n",
    "    EVENT_IS_BOOLEAN=False,     # if you already have a 0/1 \"event\" column, set True\n",
    "\n",
    "    # Metric\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=7,\n",
    "\n",
    "    # Split/rows\n",
    "    MIN_TRAIN_ROWS=8,           # allow tiny TRAIN to catch early events\n",
    "    MIN_HOLD_ROWS=48,           # enough rows for a few metric windows\n",
    "\n",
    "    # Forced-event policy (always used if events exist)\n",
    "    PREPAD_SEC=300.0,           # HOLD starts this many seconds before the latest event (clamped)\n",
    "\n",
    "    # Lead & detection window\n",
    "    LEAD_MIN=0.0,               # for this dataset, allow detection at event (set back to 15.0 for strict EW)\n",
    "    LEAD_MAX=90.0,\n",
    "    REFRACTORY=60.0,\n",
    "\n",
    "    # TRAIN-only thresholding\n",
    "    THRESH_Q_GRID_HIGH=[0.98,0.95,0.90,0.85],\n",
    "    THRESH_Q_GRID_LOW =[0.01,0.02,0.03,0.05,0.10],\n",
    "    FA_CAP_TRAIN=0.2,\n",
    "\n",
    "    # Fallback policies\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Permutations & output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns:\n",
    "            tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def guess_label(df,want):\n",
    "    if want and want in df.columns: return want\n",
    "    for c in [\"event\",\"stage\",\"label\",\"y\",\"target\",\"sleep_stage\",\"stage_int\"]:\n",
    "        if c in df.columns: return c\n",
    "    nn=[c for c in df.columns if not np.issubdtype(df[c].dtype,np.number)]\n",
    "    return nn[0] if nn else df.columns[0]\n",
    "\n",
    "def numeric_cols(df,exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation & metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True)\n",
    "    mad=np.where(mad<eps, eps, mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1)\n",
    "    keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False)\n",
    "    lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df,feats,tcol,W,smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- robust event detection ----------\n",
    "def events_by_changepoint(df,label_col,tcol):\n",
    "    # Trim whitespace, normalize case for strings\n",
    "    s = df[label_col]\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        s = s.astype(str).str.strip().str.lower()\n",
    "    v = s.values\n",
    "    # Forward-fill NaNs to avoid spurious edges; then compute changes\n",
    "    if pd.isna(v).any():\n",
    "        s2 = pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    else:\n",
    "        s2 = v\n",
    "    idx = np.where(s2[1:] != s2[:-1])[0] + 1\n",
    "    return df[tcol].values[idx]\n",
    "\n",
    "def events_by_boolean(df,label_col,tcol):\n",
    "    try:\n",
    "        arr = pd.to_numeric(df[label_col], errors=\"coerce\")\n",
    "    except Exception:\n",
    "        return np.array([], dtype=float)\n",
    "    mask = (arr.fillna(0.0) > 0.5).values\n",
    "    return df.loc[mask, tcol].values\n",
    "\n",
    "def pick_events(df,label_col,tcol,is_bool):\n",
    "    ev_cp = events_by_changepoint(df,label_col,tcol) if not is_bool else np.array([],float)\n",
    "    ev_bl = events_by_boolean(df,label_col,tcol) if is_bool or (ev_cp.size==0) else np.array([],float)\n",
    "    chosen = ev_cp if ev_cp.size>0 else ev_bl\n",
    "    return dict(method=(\"changepoint\" if chosen is ev_cp else \"boolean\"),\n",
    "                ev_full=np.unique(chosen))\n",
    "\n",
    "# ---------- split helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def force_event_into_hold(df,tcol,ev_full,prepad,min_train_rows,min_hold_rows):\n",
    "    N=len(df); times=df[tcol].values\n",
    "    if ev_full.size==0:\n",
    "        idx=clamp_idx(int(0.8*N), N, min_train_rows, min_hold_rows)\n",
    "        return idx, False\n",
    "    e=ev_full[-1]  # latest event\n",
    "    t0_target = max(times[0], e - prepad)\n",
    "    idx = np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx = clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "    # Ensure event ended up in HOLD\n",
    "    t0=times[idx]; in_hold = (e>=t0)\n",
    "    return idx, in_hold\n",
    "\n",
    "# ---------- window fallback ----------\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min; idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre < base else \"high\"\n",
    "    # unsupervised fallback: tail with fewer TRAIN FA/hr\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.98); fa_l=fa_per_hr(m,t,\"low\",0.02)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        # Extremely defensive: choose a mid/robust threshold so we can still breach if signal moves\n",
    "        med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "        mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "        th = med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "        return th, None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ---------- scoring ----------\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0:\n",
    "        fah=len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "        return 0.0, math.nan, float(fah)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med=float(np.median(det)) if det else math.nan\n",
    "    fa=[bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah=len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN (one shot) ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "label_col=CONFIG[\"LABEL_COL\"] if CONFIG[\"LABEL_COL\"] in df.columns else guess_label(df, CONFIG[\"LABEL_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol,label_col]); N=len(df)\n",
    "\n",
    "# Robust event diagnosis\n",
    "ev_info = pick_events(df,label_col,tcol,CONFIG[\"EVENT_IS_BOOLEAN\"])\n",
    "ev_full = ev_info[\"ev_full\"]; ev_method = ev_info[\"method\"]\n",
    "\n",
    "# Force event into HOLD (if any)\n",
    "idx, in_hold = force_event_into_hold(df,tcol,ev_full,CONFIG[\"PREPAD_SEC\"],CONFIG[\"MIN_TRAIN_ROWS\"],CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "idx = clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "train=df.iloc[:idx].reset_index(drop=True)\n",
    "hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "t0_hold, t1_hold = hold[tcol].iloc[0], hold[tcol].iloc[-1]\n",
    "ev_hold = ev_full[(ev_full>=t0_hold) & (ev_full<=t1_hold)]\n",
    "ev_train= ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "\n",
    "# TRAIN metric (fallback if few finite)\n",
    "W_train, train_m, tried_train = find_working_window(train, feats, tcol,\n",
    "                                                    CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                    CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "# Tail & Θ* from TRAIN only (with FA cap)\n",
    "tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "theta, q_used, fa_train = theta_with_fa_cap(\n",
    "    train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "    CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    ")\n",
    "\n",
    "# HOLD metric; shrink if too few finites\n",
    "W_hold, hold_m, tried_hold = find_working_window(hold, feats, tcol,\n",
    "                                                 W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                 CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "# Preregistration (frozen BEFORE predictions)\n",
    "prereg=f\"\"\"\n",
    "# CNT Flash-Proof v10 — Preregistration (frozen)\n",
    "Run ID: {RUN_ID}\n",
    "Timestamp (UTC): {STAMP}\n",
    "Data: {CONFIG['DATA_PATH']}\n",
    "\n",
    "Time col: {tcol} | Label col: {label_col} | Features: n={len(feats)}\n",
    "Events (diagnosed): method={ev_method}, total_on_full={int(ev_full.size)}\n",
    "First 3 event times (s): {ev_full[:3].tolist() if ev_full.size>0 else []}\n",
    "\n",
    "Split policy (forced): HOLD starts PREPAD_SEC={CONFIG['PREPAD_SEC']}s before latest event (clamped).\n",
    "Idx chosen={idx}, event_in_hold={in_hold}, hold_time_range=[{t0_hold}, {t1_hold}], events_in_hold={int(ev_hold.size)}\n",
    "\n",
    "TRAIN window fallback: tried {tried_train} → chosen W_train={W_train}\n",
    "HOLD window fallback: tried {tried_hold} → chosen W_hold={W_hold}\n",
    "\n",
    "Tail (TRAIN only): {tail}\n",
    "Θ* from TRAIN-only grid ({('HIGH '+str(CONFIG['THRESH_Q_GRID_HIGH'])) if tail=='high' else ('LOW '+str(CONFIG['THRESH_Q_GRID_LOW']))}),\n",
    "FA cap ≤ {CONFIG['FA_CAP_TRAIN']}/hr → Θ*={theta:.6f} @ q={q_used} (TRAIN FA/hr≈{fa_train:.3f})\n",
    "\n",
    "Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s]  |  Refractory: {CONFIG['REFRACTORY']}s\n",
    "Permutations: {CONFIG['N_PERM']}\n",
    "\n",
    "**Prediction:** CNT detects ≥65% of events within the lead window, median lead ≥15 s, ≤1 FA/hr.\n",
    "\"\"\"\n",
    "out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "with open(pre_path,\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\")\n",
    "\n",
    "# HOLDOUT predictions (blind)\n",
    "times  = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "raw    = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "keep   = dedup(times, raw, CONFIG[\"REFRACTORY\"])\n",
    "flags  = np.zeros_like(raw); flags[keep]=1\n",
    "pred   = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "# Seal predictions\n",
    "pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "lock_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\")\n",
    "with open(lock_path,\"w\",encoding=\"utf-8\") as f: f.write(prereg.strip()+\"\\n\\nPREDICTIONS_SHA256: \"+pred_sha+\"\\n\")\n",
    "\n",
    "# Reveal & score\n",
    "breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "horizon   = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "p          = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "PASS       = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "score=dict(\n",
    "    run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], split=float(idx/len(df)),\n",
    "    W_train=W_train, W_hold=W_hold, smooth=CONFIG[\"SMOOTH_WIN\"], metric=\"agiew_spectral_entropy\",\n",
    "    tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "    event_method=ev_method, events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "    breaches_n=int((flags==1).sum()), detection_rate=float(det),\n",
    "    median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "    false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "    decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "    predictions_csv=pred_path, prereg=pre_path, prereg_locked=lock_path,\n",
    "    predictions_sha256=pred_sha\n",
    ")\n",
    "score_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\")\n",
    "with open(score_path,\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "\n",
    "print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "print(json.dumps(score, indent=2))\n",
    "# =========================== end single mega cell ===========================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fde5247-d427-476e-925c-4e6caea5d1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_3820\\1837128234.py:325: RuntimeWarning: All-NaN slice encountered\n",
      "  if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_3820\\1837128234.py:327: RuntimeWarning: All-NaN slice encountered\n",
      "  pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-005316Z_d1c9040e\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"label_chosen\": \"file\",\n",
      "  \"events_full\": 5,\n",
      "  \"events_in_hold\": 4,\n",
      "  \"W_train\": 58,\n",
      "  \"W_hold\": 58,\n",
      "  \"tail\": \"high\",\n",
      "  \"theta_star\": 5.7714411231300105,\n",
      "  \"q_used\": 0.98,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"breaches_n\": 3,\n",
      "  \"detection_rate\": 0.5,\n",
      "  \"median_lead_s\": 54.0,\n",
      "  \"false_alarms_per_hr\": 8.51063829787234,\n",
      "  \"perm_p_value\": 0.7005988023952096,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-005316Z_d1c9040e_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-005316Z_d1c9040e_prereg.md\",\n",
      "  \"predictions_sha256\": \"8a74cfc4e8deb98b8546026b19d7d27b911d5cf8f4780f615a69ca695069a34d\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v11 — Single Mega Cell (with Event Audit + Threshold Mode) =======================\n",
    "# If your dataset has no true label transitions, set EVENT_MODE=\"threshold\" and pick a numeric column + crossing rule.\n",
    "# Example for Kuramoto: THRESHOLD_COL=\"r\", THRESHOLD_VALUE=0.7, DIRECTION=\"up\"\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----------------------------- CONFIG (edit me) -----------------------------\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "    # Event discovery\n",
    "    EVENT_MODE=\"auto\",             # \"auto\" | \"threshold\"\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    THRESHOLD_COL=None,            # e.g., \"r\" for Kuramoto; or any numeric column\n",
    "    THRESHOLD_VALUE=0.7,           # crossing value\n",
    "    DIRECTION=\"up\",                # \"up\" (crosses from below) or \"down\" (from above)\n",
    "    PREPAD_SEC=300.0,              # start HOLD this many seconds before latest event (clamped)\n",
    "\n",
    "    # Metric\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=7,\n",
    "\n",
    "    # Split & row minima (guarantee non-empty sides)\n",
    "    MIN_TRAIN_ROWS=16,\n",
    "    MIN_HOLD_ROWS=64,\n",
    "\n",
    "    # Lead window & de-dup\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    REFRACTORY=60.0,\n",
    "\n",
    "    # Threshold selection (TRAIN only)\n",
    "    THRESH_Q_GRID_HIGH=[0.98,0.95,0.90,0.85],\n",
    "    THRESH_Q_GRID_LOW =[0.01,0.02,0.03,0.05,0.10],\n",
    "    FA_CAP_TRAIN=0.2,\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any(): df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    cols=[c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "    if not cols: raise ValueError(\"No numeric feature columns found.\")\n",
    "    return cols\n",
    "\n",
    "# ---------- robust correlation + metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- event discovery ----------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v = s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v = s.values\n",
    "    # forward/back fill NaNs to avoid spurious edges\n",
    "    if pd.isna(v).any():\n",
    "        v = pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:] != v[:-1])[0] + 1\n",
    "\n",
    "def find_candidate_labels(df, keys):\n",
    "    cands=[]\n",
    "    for c in df.columns:\n",
    "        cn = c.lower()\n",
    "        if any(k in cn for k in keys):\n",
    "            idx = transitions_from_series(df[c])\n",
    "            cands.append((c, int(idx.size)))\n",
    "    # also include any small-cardinality categorical columns\n",
    "    for c in df.columns:\n",
    "        if np.issubdtype(df[c].dtype, np.number): continue\n",
    "        if df[c].nunique(dropna=True) <= 10 and (c,_) not in cands:\n",
    "            idx = transitions_from_series(df[c]); cands.append((c, int(idx.size)))\n",
    "    cands = sorted(list({(c,n) for c,n in cands}), key=lambda z: (-z[1], z[0]))\n",
    "    return cands\n",
    "\n",
    "def events_from_threshold(df, col, value, direction, tcol):\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((s.shift(1) < value) & (s >= value))[0]\n",
    "    else:\n",
    "        hits = np.where((s.shift(1) > value) & (s <= value))[0]\n",
    "    hits = hits[~np.isnan(s.iloc[hits]).values]\n",
    "    return df[tcol].iloc[hits].values\n",
    "\n",
    "def dedup(ts, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=ts[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if ts[j]-last>=gap: keep.append(j); last=ts[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts); med=float(np.median(det)) if det else math.nan\n",
    "    fah = len([bt for bt in breach_ts if float(bt) not in used]) / max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win); return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min; idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre<base else \"high\"\n",
    "    # fallback: tail with fewer TRAIN FAs/hr at strict quantiles\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.98); fa_l=fa_per_hr(m,t,\"low\",0.02)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "        mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "        th = med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "        return th, None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "feats=numeric_cols(df, exclude=[tcol])  # we'll exclude event column later\n",
    "\n",
    "# 1) EVENT AUDIT\n",
    "audit = find_candidate_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"])\n",
    "# Choose best auto label\n",
    "best_label=None; best_n=0\n",
    "if CONFIG[\"EVENT_MODE\"]==\"auto\" and audit:\n",
    "    best_label, best_n = audit[0]\n",
    "    ev_full = df[tcol].values[transitions_from_series(df[best_label])]\n",
    "else:\n",
    "    ev_full = np.array([], dtype=float)\n",
    "\n",
    "# Threshold mode (fallback or explicit)\n",
    "if (CONFIG[\"EVENT_MODE\"].lower()==\"threshold\") or (ev_full.size==0 and CONFIG[\"THRESHOLD_COL\"]):\n",
    "    col = CONFIG[\"THRESHOLD_COL\"]\n",
    "    if col is None or col not in df.columns:\n",
    "        ev_full = np.array([], dtype=float)\n",
    "    else:\n",
    "        ev_full = events_from_threshold(df, col, CONFIG[\"THRESHOLD_VALUE\"], CONFIG[\"DIRECTION\"], tcol)\n",
    "        best_label = f\"{col} ({CONFIG['DIRECTION']}@{CONFIG['THRESHOLD_VALUE']})\"\n",
    "        best_n = int(ev_full.size)\n",
    "\n",
    "# If still no events, stop cleanly with a prereg + score explaining why\n",
    "if ev_full.size==0:\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v11 — Preregistration (no events found)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\"\n",
    "                f\"Event audit: {audit[:10] if audit else 'no label-like columns'}\\n\"\n",
    "                f\"Threshold mode: col={CONFIG['THRESHOLD_COL']} value={CONFIG['THRESHOLD_VALUE']} dir={CONFIG['DIRECTION']}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\",\n",
    "               audit=audit[:10] if audit else [], decision=\"FAIL\")\n",
    "    score_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\")\n",
    "    with open(score_path,\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\")\n",
    "    print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 2) FORCE latest event into HOLD with prepad, clamp rows\n",
    "    times=df[tcol].values; N=len(df)\n",
    "    latest=ev_full[-1]; t0_target=max(times[0], latest - CONFIG[\"PREPAD_SEC\"])\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "        lo=min_train_rows; hi=N-min_hold_rows\n",
    "        if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "        return max(lo, min(int(idx), hi))\n",
    "    idx=clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "    # Exclude the chosen event column from features (if it exists)\n",
    "    excl=[tcol]\n",
    "    if best_label and best_label in df.columns: excl.append(best_label)\n",
    "    if CONFIG[\"THRESHOLD_COL\"] and CONFIG[\"THRESHOLD_COL\"] in df.columns: excl.append(CONFIG[\"THRESHOLD_COL\"])\n",
    "    feats=[c for c in feats if c not in set(excl)]\n",
    "\n",
    "    # Train/Hold events\n",
    "    ev_hold = ev_full[(ev_full>=hold[tcol].iloc[0]) & (ev_full<=hold[tcol].iloc[-1])]\n",
    "    ev_train= ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "\n",
    "    # 3) TRAIN metric (fallback if few finite)\n",
    "    W_train, train_m, tried_train = find_working_window(train, feats, tcol,\n",
    "                                                        CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "    # 4) Tail & Θ* from TRAIN only (FA cap)\n",
    "    def choose_tail_train(train_m, ev_train, lead_min, lead_max, tcol):\n",
    "        t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "        if ev_train.size>0 and fin.any():\n",
    "            pe=[]\n",
    "            for et in ev_train:\n",
    "                lo,hi=et-lead_max, et-lead_min; idx=(t>=lo)&(t<=hi)\n",
    "                if idx.any(): pe.append(np.nanmedian(m[idx]))\n",
    "            if pe:\n",
    "                pre=np.nanmedian(pe); base=np.nanmedian(m[fin])\n",
    "                return \"low\" if pre<base else \"high\"\n",
    "        def fa_per_hr(arr,times,tail,q):\n",
    "            finite=arr[np.isfinite(arr)]\n",
    "            if finite.size==0: return 0.0\n",
    "            th=float(np.quantile(finite,q))\n",
    "            flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "            idx=np.where(flags)[0]\n",
    "            if len(idx)==0: return 0.0\n",
    "            keep=[idx[0]]; last=times[idx[0]]\n",
    "            for j in idx[1:]:\n",
    "                if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "            horizon=max(times[-1]-times[0],1.0)\n",
    "            return len(keep)/(horizon/3600.0)\n",
    "        fa_h=fa_per_hr(train_m[\"metric\"].values, train_m[tcol].values, \"high\", 0.98)\n",
    "        fa_l=fa_per_hr(train_m[\"metric\"].values, train_m[tcol].values, \"low\",  0.02)\n",
    "        return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "    def theta_with_fa_cap(train_vals, times, tail, qh, ql, cap):\n",
    "        finite=train_vals[np.isfinite(train_vals)]\n",
    "        if finite.size==0:\n",
    "            med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "            mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "            th = med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "            return th, None, 0.0\n",
    "        def train_fa(th):\n",
    "            flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "            idx=np.where(flags)[0]\n",
    "            if len(idx)==0: return 0.0\n",
    "            keep=[idx[0]]; last=times[idx[0]]\n",
    "            for j in idx[1:]:\n",
    "                if times[j]-last>=60.0: keep.append(j); last=times[j]\n",
    "            horizon=max(times[-1]-times[0],1.0)\n",
    "            return len(keep)/(horizon/3600.0)\n",
    "        if tail==\"high\":\n",
    "            for q in sorted(qh, reverse=True):\n",
    "                th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "                if fa<=cap: return th,q,fa\n",
    "            q=max(qh); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "        else:\n",
    "            for q in sorted(ql):\n",
    "                th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "                if fa<=cap: return th,q,fa\n",
    "            q=min(ql); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "    tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "    theta, q_used, fa_train = theta_with_fa_cap(\n",
    "        train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "        CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    "    )\n",
    "\n",
    "    # 5) HOLD metric; shrink if needed\n",
    "    W_hold, hold_m, tried_hold = find_working_window(hold, feats, tcol,\n",
    "                                                     W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                     CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # Prereg\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v11 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Event mode: {CONFIG['EVENT_MODE']} | chosen='{best_label}' | events_on_full={int(ev_full.size)} | audit(top): {audit[:10]}\\n\"\n",
    "                f\"Split policy: HOLD begins {CONFIG['PREPAD_SEC']}s before latest event (clamped). \"\n",
    "                f\"idx={idx}, hold_range=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}], events_in_hold={int(ev_hold.size)}\\n\\n\"\n",
    "                f\"Train window fallback: tried {tried_train} → W_train={W_train}\\n\"\n",
    "                f\"Hold window fallback:  tried {tried_hold} → W_hold={W_hold}\\n\\n\"\n",
    "                f\"Tail(TRAIN): {tail} | Θ*={theta:.6f} @ q={q_used} | TRAIN FA/hr≈{fa_train:.3f}\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | Refractory: {CONFIG['REFRACTORY']}s | N_perm={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # Blind predictions on HOLD\n",
    "    times = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "    raw=(vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "    keep=dedup(times, raw, CONFIG[\"REFRACTORY\"]); flags=np.zeros_like(raw); flags[keep]=1\n",
    "    pred=pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre_path,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "    horizon = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "    det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "    p = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], label_chosen=best_label,\n",
    "        events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_train, W_hold=W_hold, tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "        breaches_n=int((flags==1).sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre_path,\n",
    "        predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d8288580-200e-454a-81dd-ead86cd1531a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — ABORTED (no events found) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-005557Z_410b5bda\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"reason\": \"no_events_found\",\n",
      "  \"audit\": [\n",
      "    [\n",
      "      \"label\",\n",
      "      0\n",
      "    ]\n",
      "  ],\n",
      "  \"decision\": \"FAIL\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v12 — Single Mega Cell =======================\n",
    "# What’s new vs v11:\n",
    "# • Excludes noisy label names (e.g., 'file') from auto event audit.\n",
    "# • Adds MIN_BREACH_DUR_SEC (persistence filter) + REFRACTORY=120s to curb false alarms — label-free.\n",
    "# • Stricter TRAIN FA cap + expanded quantile grid.\n",
    "# • Robust pre-event tail selection (skips all-NaN slices — no warnings).\n",
    "#\n",
    "# PASS rule (unchanged): Detect ≥65% of events, median lead ≥15 s, FA/hr ≤1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----------------------------- CONFIG (edit me) -----------------------------\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "\n",
    "    # Event discovery\n",
    "    EVENT_MODE=\"auto\",             # \"auto\" | \"threshold\"\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    EXCLUDE_LABEL_NAMES=[\"file\",\"filename\",\"filepath\",\"path\",\"id\",\"index\"],  # <- new: ignore these as labels\n",
    "    THRESHOLD_COL=None,            # set if EVENT_MODE=\"threshold\" (e.g., \"r\")\n",
    "    THRESHOLD_VALUE=0.7,           # threshold value for \"threshold\" mode\n",
    "    DIRECTION=\"up\",                # \"up\" or \"down\"\n",
    "    PREPAD_SEC=300.0,              # start HOLD this many seconds before latest event (clamped)\n",
    "\n",
    "    # CNT metric\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=7,\n",
    "\n",
    "    # Split & row minima (guarantee non-empty sides)\n",
    "    MIN_TRAIN_ROWS=16,\n",
    "    MIN_HOLD_ROWS=64,\n",
    "\n",
    "    # Lead window & de-dup\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    REFRACTORY=120.0,              # <- was 60; stricter cooldown\n",
    "    MIN_BREACH_DUR_SEC=20.0,       # <- new: require ≥ this duration above/below Θ* to count a breach\n",
    "\n",
    "    # TRAIN-only thresholding (tighter)\n",
    "    THRESH_Q_GRID_HIGH=[0.995,0.99,0.98,0.95,0.90],   # expanded high-tail\n",
    "    THRESH_Q_GRID_LOW =[0.01,0.02,0.03,0.05,0.10],    # low-tail\n",
    "    FA_CAP_TRAIN=0.1,              # stricter FA cap on TRAIN (per hour)\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    return [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "\n",
    "# ---------- robust correlation + metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- event discovery ----------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v = s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v = s.values\n",
    "    if pd.isna(v).any():\n",
    "        v = pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:] != v[:-1])[0] + 1\n",
    "\n",
    "def find_candidate_labels(df, keys, exclude_names):\n",
    "    cands=[]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in [n.lower() for n in exclude_names]:  # exclude noisy labels\n",
    "            continue\n",
    "        cn = c.lower()\n",
    "        if any(k in cn for k in keys):\n",
    "            idx = transitions_from_series(df[c]); cands.append((c, int(idx.size)))\n",
    "    # small-cardinality strings also\n",
    "    for c in df.columns:\n",
    "        if c.lower() in [n.lower() for n in exclude_names]: continue\n",
    "        if not np.issubdtype(df[c].dtype, np.number) and df[c].nunique(dropna=True) <= 10:\n",
    "            idx = transitions_from_series(df[c]); cands.append((c, int(idx.size)))\n",
    "    cands = sorted(list({(c,n) for c,n in cands}), key=lambda z: (-z[1], z[0]))\n",
    "    return cands\n",
    "\n",
    "def events_from_threshold(df, col, value, direction, tcol):\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((s.shift(1) < value) & (s >= value))[0]\n",
    "    else:\n",
    "        hits = np.where((s.shift(1) > value) & (s <= value))[0]\n",
    "    hits = hits[~np.isnan(s.iloc[hits]).values]\n",
    "    return df[tcol].iloc[hits].values\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win); return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts); med=float(np.median(det)) if det else math.nan\n",
    "    fah = len([bt for bt in breach_ts if float(bt) not in used]) / max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ---------- tail & theta (TRAIN-only; robust) ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any():\n",
    "                vals=m[idx]\n",
    "                vals=vals[np.isfinite(vals)]\n",
    "                if vals.size>0:\n",
    "                    pe.append(np.nanmedian(vals))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(np.array(pe)); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre<base else \"high\"\n",
    "    # fallback: tail with fewer TRAIN FA/hr (strict quantiles)\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]  # align with REFRACTORY\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.995)\n",
    "    fa_l=fa_per_hr(m,t,\"low\", 0.01)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "        mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "        th = med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "        return th, None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        # REFRACTORY-aligned dedup\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "\n",
    "# 1) EVENT AUDIT (exclude junk labels)\n",
    "audit = find_candidate_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"], CONFIG[\"EXCLUDE_LABEL_NAMES\"])\n",
    "best_label=None; best_n=0; ev_full=np.array([],float)\n",
    "\n",
    "if CONFIG[\"EVENT_MODE\"].lower()==\"auto\" and audit:\n",
    "    best_label, best_n = audit[0]\n",
    "    idxs = transitions_from_series(df[best_label])\n",
    "    ev_full = df[tcol].values[idxs]\n",
    "\n",
    "# Threshold fallback or explicit\n",
    "if (CONFIG[\"EVENT_MODE\"].lower()==\"threshold\") or (ev_full.size==0 and CONFIG[\"THRESHOLD_COL\"]):\n",
    "    col = CONFIG[\"THRESHOLD_COL\"]\n",
    "    if col and col in df.columns:\n",
    "        ev_full = events_from_threshold(df, col, CONFIG[\"THRESHOLD_VALUE\"], CONFIG[\"DIRECTION\"], tcol)\n",
    "        best_label = f\"{col} ({CONFIG['DIRECTION']}@{CONFIG['THRESHOLD_VALUE']})\"\n",
    "        best_n = int(ev_full.size)\n",
    "\n",
    "# If still no events: write clear FAIL with audit\n",
    "if ev_full.size==0:\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v12 — Preregistration (no events)\\nRun: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\"\n",
    "                f\"Event audit (top): {audit[:10]}\\nThreshold mode: col={CONFIG['THRESHOLD_COL']} val={CONFIG['THRESHOLD_VALUE']} dir={CONFIG['DIRECTION']}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\", audit=audit[:10], decision=\"FAIL\")\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\"); print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 2) Force latest event into HOLD with prepad; clamp rows\n",
    "    times=df[tcol].values; N=len(df); latest=ev_full[-1]\n",
    "    t0_target=max(times[0], latest - CONFIG[\"PREPAD_SEC\"])\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    def clamp_idx_(idx, N, min_tr, min_hd):\n",
    "        lo=min_tr; hi=N-min_hd\n",
    "        if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "        return max(lo, min(int(idx), hi))\n",
    "    idx=clamp_idx_(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "    # Exclude chosen label/threshold column from features\n",
    "    excl=[tcol]\n",
    "    if best_label and (best_label in df.columns): excl.append(best_label)\n",
    "    if CONFIG[\"THRESHOLD_COL\"] and CONFIG[\"THRESHOLD_COL\"] in df.columns: excl.append(CONFIG[\"THRESHOLD_COL\"])\n",
    "    feats=[c for c in numeric_cols(df, exclude=[]) if c not in set(excl)]\n",
    "\n",
    "    # Train/Hold events\n",
    "    ev_hold = ev_full[(ev_full>=hold[tcol].iloc[0]) & (ev_full<=hold[tcol].iloc[-1])]\n",
    "    ev_train= ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "\n",
    "    # 3) TRAIN metric (fallback)\n",
    "    W_train, train_m, tried_train = find_working_window(train, feats, tcol,\n",
    "                                                        CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # 4) Tail & Θ* (TRAIN only)\n",
    "    tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "    theta, q_used, fa_train = theta_with_fa_cap(\n",
    "        train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "        CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    "    )\n",
    "\n",
    "    # 5) HOLD metric (fallback)\n",
    "    W_hold, hold_m, tried_hold = find_working_window(hold, feats, tcol,\n",
    "                                                     W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                     CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # ----- Preregistration (frozen BEFORE predictions) -----\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v12 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Event mode: {CONFIG['EVENT_MODE']} | chosen_label='{best_label}' | events_on_full={int(ev_full.size)} | audit(top): {audit[:10]}\\n\"\n",
    "                f\"Split policy: start HOLD {CONFIG['PREPAD_SEC']}s before latest event (clamped). \"\n",
    "                f\"idx={idx}, hold_range=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}], events_in_hold={int(ev_hold.size)}\\n\\n\"\n",
    "                f\"TRAIN fallback: tried {tried_train} → W_train={W_train}\\n\"\n",
    "                f\"HOLD  fallback: tried {tried_hold} → W_hold={W_hold}\\n\\n\"\n",
    "                f\"Tail(TRAIN): {tail} | Θ*={theta:.6f} @ q={q_used} | TRAIN FA/hr≈{fa_train:.3f}\\n\"\n",
    "                f\"Persistence filter: MIN_BREACH_DUR_SEC={CONFIG['MIN_BREACH_DUR_SEC']} | REFRACTORY={CONFIG['REFRACTORY']}s\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | N_perm={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # ----- HOLD predictions (blind) -----\n",
    "    times = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "    raw = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "\n",
    "    # Persistence filter: keep only runs of 1s lasting ≥ MIN_BREACH_DUR_SEC\n",
    "    def persistence_filter(flags, times, min_dur_sec):\n",
    "        f = flags.copy()\n",
    "        idx = np.where(f==1)[0]\n",
    "        if len(idx)==0: return f*0\n",
    "        # group consecutive ones\n",
    "        groups=[]; start=idx[0]; prev=idx[0]\n",
    "        for k in idx[1:]:\n",
    "            if k==prev+1: prev=k\n",
    "            else: groups.append((start,prev)); start=k; prev=k\n",
    "        groups.append((start,prev))\n",
    "        # zero out groups shorter than min duration\n",
    "        g2 = f.copy()\n",
    "        for a,b in groups:\n",
    "            dur = times[b]-times[a]\n",
    "            if dur < min_dur_sec:\n",
    "                g2[a:b+1] = 0\n",
    "        return g2\n",
    "\n",
    "    raw_persist = persistence_filter(raw, times, CONFIG[\"MIN_BREACH_DUR_SEC\"])\n",
    "    keep = dedup(times, raw_persist, CONFIG[\"REFRACTORY\"])\n",
    "    flags = np.zeros_like(raw); flags[keep]=1\n",
    "\n",
    "    pred = pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre_path,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "    horizon = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "    det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "    p = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], label_chosen=best_label,\n",
    "        events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_train, W_hold=W_hold, tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "        breaches_n=int((flags==1).sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre_path, predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b959850-0e12-43c3-b41b-c4465a176fc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — ABORTED (no events found) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-005829Z_ec33f136\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"reason\": \"no_events_found\",\n",
      "  \"audit\": [\n",
      "    [\n",
      "      \"label\",\n",
      "      0\n",
      "    ]\n",
      "  ],\n",
      "  \"auto_threshold_used\": false,\n",
      "  \"decision\": \"FAIL\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v13 — Single Mega Cell =======================\n",
    "# What this does:\n",
    "# • Try normal label transitions. If none exist, TRAIN-only auto-threshold discovery on a numeric column\n",
    "#   (choose col, direction, and quantile ON TRAIN ONLY), then apply that fixed rule to FULL timeline.\n",
    "# • Force latest event into HOLD (with prepad), clamp train/hold non-empty.\n",
    "# • Robust metric, persistence + refractory to tame FAs.\n",
    "# • Preregister → hash predictions → reveal → score (Det%, Median lead, FA/hr, perm p).\n",
    "# PASS if: Det ≥ 65%, Median lead ≥ 15 s, FA/hr ≤ 1.0.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----------------------------- CONFIG (edit me) -----------------------------\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "\n",
    "    # Label-driven events first\n",
    "    EVENT_MODE=\"auto\",                  # \"auto\" | \"threshold\"\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    EXCLUDE_LABEL_NAMES=[\"file\",\"filename\",\"filepath\",\"path\",\"id\",\"index\"],\n",
    "\n",
    "    # Threshold mode (explicit)\n",
    "    THRESHOLD_COL=None,                 # e.g., \"r\" (if you want to set manually)\n",
    "    THRESHOLD_VALUE=0.7,\n",
    "    DIRECTION=\"up\",                     # \"up\" or \"down\"\n",
    "\n",
    "    # Auto-threshold fallback (if no events found)\n",
    "    AUTO_THRESHOLD_IF_NO_EVENTS=True,\n",
    "    AUTO_THR_SCAN_MAX_COLS=48,          # scan at most this many numeric cols (speed guard)\n",
    "    AUTO_THR_QS=[0.15,0.20,0.80,0.85],  # candidate quantiles (train-only)\n",
    "    AUTO_THR_DIRS=[\"up\",\"down\"],\n",
    "    AUTO_THR_MIN_TRAIN_EVENTS=1,        # need at least this many events on TRAIN\n",
    "    AUTO_THR_MAX_TRAIN_EVENTS=64,       # avoid extreme spam\n",
    "    AUTO_THR_MIN_SEP_SEC=20.0,          # min median separation between events on TRAIN\n",
    "\n",
    "    # Split & windows\n",
    "    PREPAD_SEC=300.0,                   # start HOLD this many seconds before latest event\n",
    "    MIN_TRAIN_ROWS=16,\n",
    "    MIN_HOLD_ROWS=64,\n",
    "\n",
    "    # Metric & smoothing\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=7,\n",
    "\n",
    "    # Lead window & FA control\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    REFRACTORY=120.0,                   # cooldown between counted breaches\n",
    "    MIN_BREACH_DUR_SEC=20.0,            # persistence filter\n",
    "\n",
    "    # TRAIN-only thresholding for CNT metric\n",
    "    THRESH_Q_GRID_HIGH=[0.995,0.99,0.98,0.95,0.90],\n",
    "    THRESH_Q_GRID_LOW =[0.01,0.02,0.03,0.05,0.10],\n",
    "    FA_CAP_TRAIN=0.1,\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    return [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "\n",
    "# ---------- robust correlation + metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- event discovery ----------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v = s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v = s.values\n",
    "    if pd.isna(v).any():\n",
    "        v = pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:] != v[:-1])[0] + 1\n",
    "\n",
    "def find_candidate_labels(df, keys, exclude_names):\n",
    "    ex=set(n.lower() for n in exclude_names)\n",
    "    cands=[]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in ex: continue\n",
    "        cn=c.lower()\n",
    "        if any(k in cn for k in keys) or (not np.issubdtype(df[c].dtype,np.number) and df[c].nunique(dropna=True)<=10):\n",
    "            idx = transitions_from_series(df[c]); cands.append((c, int(idx.size)))\n",
    "    cands = sorted(list({(c,n) for c,n in cands}), key=lambda z: (-z[1], z[0]))\n",
    "    return cands\n",
    "\n",
    "def events_from_threshold(df, col, value, direction, tcol):\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((s.shift(1) < value) & (s >= value))[0]\n",
    "    else:\n",
    "        hits = np.where((s.shift(1) > value) & (s <= value))[0]\n",
    "    hits = hits[~np.isnan(s.iloc[hits]).values]\n",
    "    return df[tcol].iloc[hits].values\n",
    "\n",
    "# ---------- auto-threshold discovery (TRAIN-only) ----------\n",
    "def auto_threshold_discovery(df, tcol, train_idx, numeric_candidates, qs, dirs,\n",
    "                             min_events, max_events, min_sep_sec, rng):\n",
    "    # Use TRAIN ONLY to pick (col, dir, q) → threshold rule\n",
    "    t = df[tcol].values\n",
    "    t_train = t[:train_idx]\n",
    "    best = None\n",
    "    for col in numeric_candidates:\n",
    "        s = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "        s_train = s.iloc[:train_idx]\n",
    "        if s_train.notna().sum() < max(32, int(0.2*train_idx)):  # not enough data\n",
    "            continue\n",
    "        vals = s_train.dropna().values\n",
    "        for d in dirs:\n",
    "            for q in qs:\n",
    "                thr = np.quantile(vals, q)\n",
    "                if d==\"up\":\n",
    "                    hits = np.where((s_train.shift(1) < thr) & (s_train >= thr))[0]\n",
    "                else:\n",
    "                    hits = np.where((s_train.shift(1) > thr) & (s_train <= thr))[0]\n",
    "                hits = hits[~np.isnan(s_train.iloc[hits]).values]\n",
    "                # separation in seconds (train region)\n",
    "                if hits.size==0: continue\n",
    "                sep = np.diff(t_train[hits]) if hits.size>1 else np.array([np.inf])\n",
    "                med_sep = float(np.median(sep))\n",
    "                if hits.size < min_events or hits.size > max_events or med_sep < min_sep_sec:\n",
    "                    continue\n",
    "                # objective: prefer moderate counts & larger separation\n",
    "                score = hits.size * (med_sep + 1.0)\n",
    "                cand = dict(col=col, direction=d, q=q, thr=float(thr), n_train=int(hits.size),\n",
    "                            med_sep=med_sep, score=score)\n",
    "                if (best is None) or (cand[\"score\"] > best[\"score\"]):\n",
    "                    best = cand\n",
    "    return best  # or None\n",
    "\n",
    "# ---------- helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def force_event_into_hold(df,tcol,ev_full,prepad,min_train_rows,min_hold_rows):\n",
    "    N=len(df); times=df[tcol].values\n",
    "    latest=ev_full[-1]\n",
    "    t0_target=max(times[0], latest - prepad)\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx=clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "    return idx\n",
    "\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win); return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def persistence_filter(flags, times, min_dur_sec):\n",
    "    f = flags.copy()\n",
    "    idx = np.where(f==1)[0]\n",
    "    if len(idx)==0: return f*0\n",
    "    groups=[]; start=idx[0]; prev=idx[0]\n",
    "    for k in idx[1:]:\n",
    "        if k==prev+1: prev=k\n",
    "        else: groups.append((start,prev)); start=k; prev=k\n",
    "    groups.append((start,prev))\n",
    "    g2 = f.copy()\n",
    "    for a,b in groups:\n",
    "        dur = times[b]-times[a]\n",
    "        if dur < min_dur_sec:\n",
    "            g2[a:b+1] = 0\n",
    "    return g2\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts); med=float(np.median(det)) if det else math.nan\n",
    "    fah = len([bt for bt in breach_ts if float(bt) not in used]) / max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ---------- TRAIN-only tail & θ* ----------\n",
    "def choose_tail_train(train_m: pd.DataFrame, train_events: np.ndarray, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values; fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any():\n",
    "                vals=m[idx]; vals=vals[np.isfinite(vals)]\n",
    "                if vals.size>0: pe.append(np.nanmedian(vals))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(np.array(pe)); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre<base else \"high\"\n",
    "    # fallback: tail with fewer TRAIN FAs/hr at strict ends\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.995); fa_l=fa_per_hr(m,t,\"low\",0.01)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals: np.ndarray, times: np.ndarray, tail: str,\n",
    "                      qgrid_high, qgrid_low, fa_cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "        mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "        th = med + (4.0*mad if tail==\"high\" else -4.0*mad)\n",
    "        return th, None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qgrid_high, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=max(qgrid_high); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(qgrid_low):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=fa_cap: return th,q,fa\n",
    "        q=min(qgrid_low); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "N=len(df)\n",
    "\n",
    "# 1) Try label-driven events\n",
    "audit = find_candidate_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"], CONFIG[\"EXCLUDE_LABEL_NAMES\"])\n",
    "best_label=None; best_n=0; ev_full=np.array([],float)\n",
    "\n",
    "if CONFIG[\"EVENT_MODE\"].lower()==\"auto\" and audit:\n",
    "    best_label, best_n = audit[0]\n",
    "    idxs = transitions_from_series(df[best_label])\n",
    "    ev_full = df[tcol].values[idxs]\n",
    "\n",
    "# 2) Threshold mode (explicit) or auto-threshold fallback\n",
    "auto_thr_used = False\n",
    "if (CONFIG[\"EVENT_MODE\"].lower()==\"threshold\") or (ev_full.size==0 and CONFIG[\"THRESHOLD_COL\"]):\n",
    "    col = CONFIG[\"THRESHOLD_COL\"]\n",
    "    if col and col in df.columns:\n",
    "        ev_full = events_from_threshold(df, col, CONFIG[\"THRESHOLD_VALUE\"], CONFIG[\"DIRECTION\"], tcol)\n",
    "        best_label = f\"{col} ({CONFIG['DIRECTION']}@{CONFIG['THRESHOLD_VALUE']})\"\n",
    "        best_n = int(ev_full.size)\n",
    "\n",
    "if ev_full.size==0 and CONFIG[\"AUTO_THRESHOLD_IF_NO_EVENTS\"]:\n",
    "    # Use TRAIN-only discovery\n",
    "    # provisional split to define TRAIN (80% by rows, clamped)\n",
    "    idx_train_prov = clamp_idx(int(0.80*N), N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "    # candidate numeric columns (cap for speed)\n",
    "    num_cands = [c for c in numeric_cols(df, exclude=[tcol])]\n",
    "    if len(num_cands)>CONFIG[\"AUTO_THR_SCAN_MAX_COLS\"]:\n",
    "        rng=np.random.default_rng(CONFIG[\"RNG_SEED\"])\n",
    "        num_cands = list(rng.choice(num_cands, CONFIG[\"AUTO_THR_SCAN_MAX_COLS\"], replace=False))\n",
    "    rng=np.random.default_rng(CONFIG[\"RNG_SEED\"])\n",
    "    best_rule = auto_threshold_discovery(\n",
    "        df, tcol, idx_train_prov, num_cands, CONFIG[\"AUTO_THR_QS\"], CONFIG[\"AUTO_THR_DIRS\"],\n",
    "        CONFIG[\"AUTO_THR_MIN_TRAIN_EVENTS\"], CONFIG[\"AUTO_THR_MAX_TRAIN_EVENTS\"], CONFIG[\"AUTO_THR_MIN_SEP_SEC\"], rng\n",
    "    )\n",
    "    if best_rule:\n",
    "        auto_thr_used = True\n",
    "        best_label = f\"{best_rule['col']} ({best_rule['direction']}@q={best_rule['q']})\"\n",
    "        # apply rule on FULL timeline to get events (fixed after TRAIN-only selection)\n",
    "        ev_full = events_from_threshold(df, best_rule[\"col\"], best_rule[\"thr\"], best_rule[\"direction\"], tcol)\n",
    "        best_n = int(ev_full.size)\n",
    "\n",
    "# If still no events: write a tidy FAIL and exit\n",
    "if ev_full.size==0:\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v13 — Prereg (no events)\\nRun: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\"\n",
    "                f\"Audit(top): {audit[:10]}\\nThreshold explicit: col={CONFIG['THRESHOLD_COL']}, val={CONFIG['THRESHOLD_VALUE']}, dir={CONFIG['DIRECTION']}\\n\"\n",
    "                f\"Auto-threshold used={auto_thr_used}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\",\n",
    "               audit=audit[:10], auto_threshold_used=auto_thr_used, decision=\"FAIL\")\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\"); print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 3) Force latest event into HOLD with prepad; clamp rows\n",
    "    times=df[tcol].values\n",
    "    idx = force_event_into_hold(df, tcol, ev_full, CONFIG[\"PREPAD_SEC\"], CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "    idx = clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "    # Exclude event-related columns from features\n",
    "    excl={tcol}\n",
    "    if isinstance(best_label,str) and best_label in df.columns: excl.add(best_label)\n",
    "    if CONFIG[\"THRESHOLD_COL\"] and CONFIG[\"THRESHOLD_COL\"] in df.columns: excl.add(CONFIG[\"THRESHOLD_COL\"])\n",
    "    feats=[c for c in numeric_cols(df, exclude=[]) if c not in excl]\n",
    "\n",
    "    # Train/Hold events\n",
    "    ev_hold = ev_full[(ev_full>=hold[tcol].iloc[0]) & (ev_full<=hold[tcol].iloc[-1])]\n",
    "    ev_train= ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "\n",
    "    # 4) Metric windows\n",
    "    W_train, train_m, tried_train = find_working_window(train, feats, tcol,\n",
    "                                                        CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "    W_hold, hold_m, tried_hold   = find_working_window(hold,  feats, tcol,\n",
    "                                                        W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # 5) Tail & Θ* from TRAIN only (with FA cap)\n",
    "    tail = choose_tail_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "    theta, q_used, fa_train = theta_with_fa_cap(\n",
    "        train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "        CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    "    )\n",
    "\n",
    "    # 6) Preregistration (frozen)\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v13 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Event mode: {CONFIG['EVENT_MODE']} | chosen='{best_label}' | events_on_full={int(ev_full.size)} | audit(top): {audit[:10]}\\n\"\n",
    "                f\"Auto-threshold used: {auto_thr_used}\\n\"\n",
    "                f\"Split: HOLD starts {CONFIG['PREPAD_SEC']}s before latest event (clamped). idx={idx}, \"\n",
    "                f\"hold_range=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}], events_in_hold={int(ev_hold.size)}\\n\\n\"\n",
    "                f\"TRAIN fallback: {tried_train} → W_train={W_train}\\n\"\n",
    "                f\"HOLD  fallback: {tried_hold} → W_hold={W_hold}\\n\\n\"\n",
    "                f\"Tail(TRAIN): {tail} | Θ*={theta:.6f} @ q={q_used} | TRAIN FA/hr≈{fa_train:.3f}\\n\"\n",
    "                f\"Persistence: MIN_BREACH_DUR_SEC={CONFIG['MIN_BREACH_DUR_SEC']} | REFRACTORY={CONFIG['REFRACTORY']}s\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | N_perm={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # 7) Blind predictions on HOLD\n",
    "    times = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "    raw = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "    raw_persist = persistence_filter(raw, times, CONFIG[\"MIN_BREACH_DUR_SEC\"])\n",
    "    keep = dedup(times, raw_persist, CONFIG[\"REFRACTORY\"])\n",
    "    flags = np.zeros_like(raw); flags[keep]=1\n",
    "\n",
    "    pred=pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # 8) Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre_path,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "    horizon = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "    det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "    p = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], label_chosen=best_label,\n",
    "        events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_train, W_hold=W_hold, tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "        breaches_n=int((flags==1).sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre_path, predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "86ca821c-8c86-48f8-8502-2dfad7bec455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-010112Z_fac3196c\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"label_or_rule\": \"ENERGY(up@q=0.85)\",\n",
      "  \"events_full\": 4,\n",
      "  \"events_in_hold\": 4,\n",
      "  \"W_train\": 31,\n",
      "  \"W_hold\": 31,\n",
      "  \"tail\": \"low\",\n",
      "  \"theta_star\": 4.1630399511710126,\n",
      "  \"q_used\": 0.01,\n",
      "  \"train_fa_per_hr\": 81.81818181818181,\n",
      "  \"breaches_n\": 2,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 16.289592760180994,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-010112Z_fac3196c_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-010112Z_fac3196c_prereg.md\",\n",
      "  \"predictions_sha256\": \"df1f3ba72bd173f17b74338d988bac3e7208651accdecccefc87d9ff6a6b0cdf\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v14 — Single Mega Cell =======================\n",
    "# Purpose: If your table has no label transitions, derive events *on TRAIN only*\n",
    "# from a robust multi-channel \"energy\" signal (not the CNT metric), freeze that rule,\n",
    "# then run the full prereg → hash → blind predictions → reveal → score pipeline.\n",
    "#\n",
    "# PASS rule: Detect ≥ 65% of events, Median lead ≥ 15 s, False alarms ≤ 1.0 / hr.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ============================== CONFIG (edit me) ==============================\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "\n",
    "    # Label-driven events first (if any)\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    EXCLUDE_LABEL_NAMES=[\"file\",\"filename\",\"filepath\",\"path\",\"id\",\"index\"],\n",
    "\n",
    "    # Derived-event fallback (TRAIN-only):\n",
    "    EVT_USE_DERIVED_IF_NOLABEL=True,   # if no label transitions found, derive events from ENERGY signal\n",
    "    EVT_SMOOTH_WIN=9,                  # median smooth on energy\n",
    "    EVT_Q_CAND=[0.85,0.90,0.95],       # TRAIN quantiles to try (direction=\"up\")\n",
    "    EVT_MIN_TRAIN_EVENTS=1,            # require at least this many TRAIN events\n",
    "    EVT_MAX_TRAIN_EVENTS=32,           # avoid spam\n",
    "    EVT_MIN_SEP_SEC=20.0,              # minimum median separation between TRAIN events (seconds)\n",
    "\n",
    "    # Holdout placement\n",
    "    PREPAD_SEC=300.0,                  # start HOLD this many seconds before latest event\n",
    "    MIN_TRAIN_ROWS=16,                 # keep TRAIN non-empty\n",
    "    MIN_HOLD_ROWS=64,                  # keep HOLD non-empty\n",
    "\n",
    "    # CNT metric (detector)\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=7,\n",
    "\n",
    "    # Lead window & FA control\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    REFRACTORY=120.0,                  # cooldown between counted breaches\n",
    "    MIN_BREACH_DUR_SEC=20.0,           # require persistence of threshold crossings\n",
    "\n",
    "    # TRAIN-only thresholding for CNT metric\n",
    "    THRESH_Q_GRID_HIGH=[0.995,0.99,0.98,0.95],\n",
    "    THRESH_Q_GRID_LOW =[0.01,0.02,0.03,0.05,0.10],\n",
    "    FA_CAP_TRAIN=0.1,                  # max TRAIN FA/hr when picking Θ*\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ==============================================================================\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any():\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    return [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "\n",
    "# ---------- Robust correlation + CNT metric ----------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ---------- Label events (if present) ----------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v = s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v = s.values\n",
    "    if pd.isna(v).any():\n",
    "        v = pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:] != v[:-1])[0] + 1\n",
    "\n",
    "def find_candidate_labels(df, keys, exclude_names):\n",
    "    ex=set(n.lower() for n in exclude_names)\n",
    "    cands=[]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in ex: continue\n",
    "        cn=c.lower()\n",
    "        if any(k in cn for k in keys) or (not np.issubdtype(df[c].dtype,np.number) and df[c].nunique(dropna=True)<=10):\n",
    "            idx = transitions_from_series(df[c]); cands.append((c, int(idx.size)))\n",
    "    cands = sorted(list({(c,n) for c,n in cands}), key=lambda z: (-z[1], z[0]))\n",
    "    return cands\n",
    "\n",
    "# ---------- Derived energy (TRAIN-only rule selection) ----------\n",
    "def energy_series(df, feats, tcol, smooth_win):\n",
    "    # Instantaneous robust across-channel energy, then median smooth.\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X,axis=0,keepdims=True), X)\n",
    "    med = np.nanmedian(X, axis=1)\n",
    "    mad = np.nanmedian(np.abs(X - np.nanmedian(X,axis=1,keepdims=True)), axis=1) + 1e-8\n",
    "    zmag = np.abs((X - med[:,None]) / mad[:,None])\n",
    "    e = np.nanmedian(zmag, axis=1)   # robust across-channel magnitude\n",
    "    s = pd.Series(e)\n",
    "    if smooth_win>1: s = s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol: df[tcol].values, \"energy\": s.values})\n",
    "\n",
    "def threshold_crossings(series: pd.Series, times: np.ndarray, thr: float, direction: str):\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((series.shift(1) < thr) & (series >= thr))[0]\n",
    "    else:\n",
    "        hits = np.where((series.shift(1) > thr) & (series <= thr))[0]\n",
    "    hits = hits[~np.isnan(series.iloc[hits]).values]\n",
    "    return times[hits]\n",
    "\n",
    "def pick_energy_event_rule_on_train(energy_df, tcol, train_end_idx, qs, min_ev, max_ev, min_sep_sec):\n",
    "    t_all = energy_df[tcol].values\n",
    "    t = t_all[:train_end_idx]\n",
    "    s = pd.Series(energy_df[\"energy\"].values[:train_end_idx])\n",
    "    best=None\n",
    "    for q in qs:\n",
    "        thr = float(np.nanquantile(s.values[np.isfinite(s.values)], q))\n",
    "        hits_t = threshold_crossings(s, t, thr, \"up\")\n",
    "        if hits_t.size==0: continue\n",
    "        if not (min_ev <= hits_t.size <= max_ev): continue\n",
    "        sep = np.diff(hits_t) if hits_t.size>1 else np.array([np.inf])\n",
    "        med_sep = float(np.median(sep))\n",
    "        if med_sep < min_sep_sec: continue\n",
    "        score = hits_t.size * (med_sep + 1.0)\n",
    "        cand=dict(q=q, thr=thr, n_train=int(hits_t.size), med_sep=med_sep, direction=\"up\", t0=float(t[0]), t1=float(t[-1]))\n",
    "        if (best is None) or (score > best[\"n_train\"] * (best[\"med_sep\"] + 1.0)):\n",
    "            best=cand\n",
    "    return best  # may be None\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def clamp_idx(idx, N, min_train_rows, min_hold_rows):\n",
    "    lo=min_train_rows; hi=N-min_hold_rows\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def force_event_into_hold(times, ev_full, prepad, min_train_rows, min_hold_rows):\n",
    "    N=len(times); latest=ev_full[-1]\n",
    "    t0_target=max(times[0], latest - prepad)\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    return clamp_idx(idx, N, min_train_rows, min_hold_rows)\n",
    "\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "def dedup(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return idx\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def persistence_filter(flags, times, min_dur_sec):\n",
    "    f = flags.copy()\n",
    "    idx = np.where(f==1)[0]\n",
    "    if len(idx)==0: return f*0\n",
    "    groups=[]; start=idx[0]; prev=idx[0]\n",
    "    for k in idx[1:]:\n",
    "        if k==prev+1: prev=k\n",
    "        else: groups.append((start,prev)); start=k; prev=k\n",
    "    groups.append((start,prev))\n",
    "    g2 = f.copy()\n",
    "    for a,b in groups:\n",
    "        dur = times[b]-times[a]\n",
    "        if dur < min_dur_sec:\n",
    "            g2[a:b+1] = 0\n",
    "    return g2\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, len(breach_ts)/max(horizon/3600.0,1e-9)\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts); med=float(np.median(det)) if det else math.nan\n",
    "    fah = len([bt for bt in breach_ts if float(bt) not in used]) / max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "def tail_choose_train(train_m, train_events, lead_min, lead_max, tcol):\n",
    "    t=train_m[tcol].values; m=train_m[\"metric\"].values\n",
    "    fin=np.isfinite(m)\n",
    "    if train_events.size>0 and fin.any():\n",
    "        pe=[]\n",
    "        for et in train_events:\n",
    "            lo,hi=et-lead_max, et-lead_min\n",
    "            idx=(t>=lo)&(t<=hi)\n",
    "            if idx.any():\n",
    "                vals=m[idx]; vals=vals[np.isfinite(vals)]\n",
    "                if vals.size>0: pe.append(np.nanmedian(vals))\n",
    "        if pe:\n",
    "            pre=np.nanmedian(np.array(pe)); base=np.nanmedian(m[fin])\n",
    "            return \"low\" if pre<base else \"high\"\n",
    "    # fallback: tail with fewer TRAIN FAs/hr at strict quantiles\n",
    "    def fa_per_hr(arr,times,tail,q):\n",
    "        finite=arr[np.isfinite(arr)]\n",
    "        if finite.size==0: return 0.0\n",
    "        th=float(np.quantile(finite,q))\n",
    "        flags=(arr>th).astype(int) if tail==\"high\" else (arr<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    fa_h=fa_per_hr(m,t,\"high\",0.995); fa_l=fa_per_hr(m,t,\"low\",0.01)\n",
    "    return \"high\" if fa_h<fa_l else \"low\"\n",
    "\n",
    "def theta_with_fa_cap(train_vals, times, tail, qh, ql, cap):\n",
    "    finite=train_vals[np.isfinite(train_vals)]\n",
    "    if finite.size==0:\n",
    "        med=float(np.nanmedian(train_vals)) if train_vals.size else 0.0\n",
    "        mad=float(np.nanmedian(np.abs(train_vals-med))) if train_vals.size else 1.0\n",
    "        th = med + (4.0*mad if tail==\"high\" else -4.0*mad); return th, None, 0.0\n",
    "    def train_fa(th):\n",
    "        flags=(train_vals>th).astype(int) if tail==\"high\" else (train_vals<th).astype(int)\n",
    "        idx=np.where(flags)[0]\n",
    "        if len(idx)==0: return 0.0\n",
    "        keep=[idx[0]]; last=times[idx[0]]\n",
    "        for j in idx[1:]:\n",
    "            if times[j]-last>=120.0: keep.append(j); last=times[j]\n",
    "        horizon=max(times[-1]-times[0],1.0)\n",
    "        return len(keep)/(horizon/3600.0)\n",
    "    if tail==\"high\":\n",
    "        for q in sorted(qh, reverse=True):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=cap: return th,q,fa\n",
    "        q=max(qh); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "    else:\n",
    "        for q in sorted(ql):\n",
    "            th=float(np.quantile(finite,q)); fa=train_fa(th)\n",
    "            if fa<=cap: return th,q,fa\n",
    "        q=min(ql); th=float(np.quantile(finite,q)); return th,q,train_fa(th)\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "N=len(df)\n",
    "\n",
    "# 1) Try to find label transitions\n",
    "audit = find_candidate_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"], CONFIG[\"EXCLUDE_LABEL_NAMES\"])\n",
    "best_label=None; best_n=0; ev_full=np.array([],float)\n",
    "if audit:\n",
    "    best_label, best_n = audit[0]\n",
    "    idxs = transitions_from_series(df[best_label])\n",
    "    ev_full = df[tcol].values[idxs]\n",
    "\n",
    "# 2) If none and allowed, derive events from TRAIN-only energy rule\n",
    "derived_used=False; energy_rule=None\n",
    "if ev_full.size==0 and CONFIG[\"EVT_USE_DERIVED_IF_NOLABEL\"]:\n",
    "    feats = numeric_cols(df, exclude=[tcol])\n",
    "    if len(feats)==0:\n",
    "        ev_full=np.array([],float)\n",
    "    else:\n",
    "        # provisional 80% split for TRAIN to *choose* the energy rule\n",
    "        idx_train_prov = clamp_idx(int(0.80*N), N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "        E = energy_series(df, feats, tcol, CONFIG[\"EVT_SMOOTH_WIN\"])\n",
    "        energy_rule = pick_energy_event_rule_on_train(\n",
    "            E, tcol, idx_train_prov,\n",
    "            CONFIG[\"EVT_Q_CAND\"], CONFIG[\"EVT_MIN_TRAIN_EVENTS\"],\n",
    "            CONFIG[\"EVT_MAX_TRAIN_EVENTS\"], CONFIG[\"EVT_MIN_SEP_SEC\"]\n",
    "        )\n",
    "        if energy_rule:\n",
    "            derived_used=True\n",
    "            # apply fixed rule to FULL timeline\n",
    "            ev_full = threshold_crossings(pd.Series(E[\"energy\"].values), E[tcol].values, energy_rule[\"thr\"], energy_rule[\"direction\"])\n",
    "            best_label = f\"ENERGY(up@q={energy_rule['q']})\"\n",
    "            best_n = int(ev_full.size)\n",
    "\n",
    "# If still no events: clean abort\n",
    "if ev_full.size==0:\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v14 — Prereg (no events)\\nRun: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\"\n",
    "                f\"Audit(top): {audit[:10]}\\nDerived_used={derived_used}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\",\n",
    "               audit=audit[:10], derived_used=derived_used, decision=\"FAIL\")\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\"); print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 3) Place latest event in HOLD with prepad; clamp rows\n",
    "    times=df[tcol].values\n",
    "    idx = force_event_into_hold(times, ev_full, CONFIG[\"PREPAD_SEC\"], CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "    # Features for CNT metric (exclude time and any explicit label col if present)\n",
    "    excl={tcol}\n",
    "    if isinstance(best_label,str) and best_label in df.columns: excl.add(best_label)\n",
    "    feats = [c for c in numeric_cols(df, exclude=[]) if c not in excl]\n",
    "\n",
    "    # Train/Hold event times\n",
    "    ev_hold = ev_full[(ev_full>=hold[tcol].iloc[0]) & (ev_full<=hold[tcol].iloc[-1])]\n",
    "    ev_train= ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "\n",
    "    # 4) CNT metric windows (with fallbacks)\n",
    "    W_train, train_m, tried_train = find_working_window(train, feats, tcol,\n",
    "                                                        CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "    W_hold,  hold_m,  tried_hold  = find_working_window(hold,  feats, tcol,\n",
    "                                                        W_train, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                                        CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # 5) Tail & Θ* from TRAIN only (FA-capped)\n",
    "    tail = tail_choose_train(train_m, ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], tcol)\n",
    "    theta, q_used, fa_train = theta_with_fa_cap(\n",
    "        train_m[\"metric\"].values, train_m[tcol].values, tail,\n",
    "        CONFIG[\"THRESH_Q_GRID_HIGH\"], CONFIG[\"THRESH_Q_GRID_LOW\"], CONFIG[\"FA_CAP_TRAIN\"]\n",
    "    )\n",
    "\n",
    "    # 6) Preregistration (frozen BEFORE predictions)\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "    pre_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre_path,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v14 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Label audit(top): {audit[:10]}\\n\"\n",
    "                f\"Chosen events: {best_label} | total_on_full={int(ev_full.size)} | derived_used={derived_used}\\n\"\n",
    "                f\"Derived energy rule (if used): {json.dumps(energy_rule) if energy_rule else 'N/A'}\\n\"\n",
    "                f\"Split: HOLD starts {CONFIG['PREPAD_SEC']}s before latest event; idx={idx}; \"\n",
    "                f\"HOLD=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}] | events_in_hold={int(ev_hold.size)}\\n\\n\"\n",
    "                f\"TRAIN fallback: {tried_train} → W_train={W_train}\\n\"\n",
    "                f\"HOLD  fallback: {tried_hold}  → W_hold={W_hold}\\n\\n\"\n",
    "                f\"Tail(TRAIN): {tail} | Θ*={theta:.6f} @ q={q_used} | TRAIN FA/hr≈{fa_train:.3f}\\n\"\n",
    "                f\"Persistence: MIN_BREACH_DUR_SEC={CONFIG['MIN_BREACH_DUR_SEC']} | REFRACTORY={CONFIG['REFRACTORY']}s\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | N_perm={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # 7) Blind predictions on HOLD (with persistence + refractory)\n",
    "    times = hold_m[tcol].values; vals=hold_m[\"metric\"].values\n",
    "    raw = (vals>theta).astype(int) if tail==\"high\" else (vals<theta).astype(int)\n",
    "    raw_persist = persistence_filter(raw, times, CONFIG[\"MIN_BREACH_DUR_SEC\"])\n",
    "    keep = dedup(times, raw_persist, CONFIG[\"REFRACTORY\"])\n",
    "    flags = np.zeros_like(raw); flags[keep]=1\n",
    "\n",
    "    pred=pd.DataFrame({tcol:times, \"metric\":vals, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # 8) Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre_path,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    breach_ts = pred.loc[pred[\"breach_flag\"]==1, tcol].values\n",
    "    horizon = float(times[-1]-times[0]) if len(times)>=2 else 1.0\n",
    "    det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG['LEAD_MAX'], horizon)\n",
    "    p = pval(breach_ts, ev_hold, CONFIG['LEAD_MIN'], CONFIG['LEAD_MAX'], horizon, CONFIG['N_PERM'], CONFIG['RNG_SEED'], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"],\n",
    "        label_or_rule=best_label, events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_train, W_hold=W_hold, tail=tail, theta_star=float(theta), q_used=q_used, train_fa_per_hr=float(fa_train),\n",
    "        breaches_n=int((flags==1).sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre_path, predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "452943ec-f8ca-42a7-b05e-c406ca09da99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CNT Flash-Proof — Holdout Score (FAIL ❌) ===\n",
      "{\n",
      "  \"run_id\": \"20251031-010621Z_b9085254\",\n",
      "  \"data\": \"C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\artifacts\\\\tables\\\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
      "  \"events_full\": 4,\n",
      "  \"events_in_hold\": 4,\n",
      "  \"W_train\": 31,\n",
      "  \"W_hold\": 31,\n",
      "  \"tail\": \"high\",\n",
      "  \"theta_star\": 4.163885917191155,\n",
      "  \"train_fa_per_hr\": 0.0,\n",
      "  \"breaches_n\": 0,\n",
      "  \"detection_rate\": 0.0,\n",
      "  \"median_lead_s\": null,\n",
      "  \"false_alarms_per_hr\": 0.0,\n",
      "  \"perm_p_value\": 1.0,\n",
      "  \"decision\": \"FAIL\",\n",
      "  \"predictions_csv\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-010621Z_b9085254_predictions.csv\",\n",
      "  \"prereg\": \"cnt_flashproof_artifacts\\\\flashproof_20251031-010621Z_b9085254_prereg.md\",\n",
      "  \"predictions_sha256\": \"b902e27922240eb490755ccdc55bcf6e65576b25495cb46bdb482eb0d9b2cd7f\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v15 — Single Mega Cell =======================\n",
    "# Key upgrades:\n",
    "# • Training-only ENERGY GATE: only consider breach candidates when energy is high (gate fixed from TRAIN).\n",
    "# • FA-capped Θ* via bisection on TRAIN (no peeking): pick threshold that meets a target FA/hr cap.\n",
    "# • Persistence + long REFRACTORY to kill flicker.\n",
    "# • Works with label transitions, derived ENERGY events, or explicit threshold events.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----------------------------- CONFIG (edit me) -----------------------------\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "\n",
    "    # Event sources (try labels, else derive from ENERGY)\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    EXCLUDE_LABEL_NAMES=[\"file\",\"filename\",\"filepath\",\"path\",\"id\",\"index\"],\n",
    "    USE_DERIVED_ENERGY_IF_NO_LABEL=True,\n",
    "    DERIVED_Q_CAND=[0.85,0.90,0.95],   # TRAIN quantiles for ENERGY(up) events\n",
    "    DERIVED_MIN_TRAIN_EVENTS=1,\n",
    "    DERIVED_MAX_TRAIN_EVENTS=32,\n",
    "    DERIVED_MIN_SEP_SEC=20.0,\n",
    "\n",
    "    # Hold placement\n",
    "    PREPAD_SEC=300.0,     # start HOLD this many seconds before latest event (clamped)\n",
    "    MIN_TRAIN_ROWS=16,    # keep TRAIN non-empty\n",
    "    MIN_HOLD_ROWS=64,     # keep HOLD non-empty\n",
    "\n",
    "    # CNT detector metric\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=11,        # a touch more smoothing for stability\n",
    "\n",
    "    # Energy gate (TRAIN-only → reused on HOLD)\n",
    "    ENERGY_SMOOTH_WIN=9,\n",
    "    ENERGY_GATE_Q=0.80,   # TRAIN energy quantile; gate = (energy >= gate_thr)\n",
    "\n",
    "    # Lead window & FA control\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    MIN_BREACH_DUR_SEC=30.0,   # persistence\n",
    "    REFRACTORY=180.0,          # cooldown\n",
    "    TRAIN_FA_CAP_PER_HR=0.20,  # FA/hr cap on TRAIN when picking Θ*\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any(): df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    return [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "\n",
    "# ------- Robust correlation + CNT metric -------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X,axis=0,keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# ------- ENERGY (for events & gating) -------\n",
    "def energy_series(df, feats, tcol, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X,axis=0,keepdims=True), X)\n",
    "    med = np.nanmedian(X, axis=1)\n",
    "    mad = np.nanmedian(np.abs(X - med[:,None]), axis=1) + 1e-8\n",
    "    zmag = np.abs((X - med[:,None]) / mad[:,None])\n",
    "    e = np.nanmedian(zmag, axis=1)\n",
    "    s=pd.Series(e)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"energy\":s.values})\n",
    "\n",
    "def threshold_crossings(series: pd.Series, times: np.ndarray, thr: float, direction: str):\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((series.shift(1) < thr) & (series >= thr))[0]\n",
    "    else:\n",
    "        hits = np.where((series.shift(1) > thr) & (series <= thr))[0]\n",
    "    hits = hits[~np.isnan(series.iloc[hits]).values]\n",
    "    return times[hits]\n",
    "\n",
    "# ------- Label transitions -------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v=s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v=s.values\n",
    "    if pd.isna(v).any(): v=pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:]!=v[:-1])[0] + 1\n",
    "\n",
    "def audit_labels(df, keys, exclude_names):\n",
    "    ex=set(n.lower() for n in exclude_names); rows=[]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in ex: continue\n",
    "        cn=c.lower()\n",
    "        if any(k in cn for k in keys) or (not np.issubdtype(df[c].dtype,np.number) and df[c].nunique(dropna=True)<=10):\n",
    "            rows.append((c, int(transitions_from_series(df[c]).size)))\n",
    "    rows=sorted(list({(c,n) for c,n in rows}), key=lambda z:(-z[1], z[0]))\n",
    "    return rows\n",
    "\n",
    "# ------- Helpers -------\n",
    "def clamp_idx(idx, N, min_tr, min_hd):\n",
    "    lo=min_tr; hi=N-min_hd\n",
    "    if hi<=lo: lo=max(1,N//3); hi=max(lo+1,N-1)\n",
    "    return max(lo, min(int(idx), hi))\n",
    "\n",
    "def find_working_window(df_slice, feats, tcol, W_desired, smooth_win, min_finite, min_window):\n",
    "    candidates=[W_desired, int(0.8*W_desired), int(0.6*W_desired), W_desired//2, 31, 21, 13, 9, 7, 5]\n",
    "    candidates=[w for w in [max(min_window,int(w)) for w in candidates] if w>0]\n",
    "    tried=[]\n",
    "    for W in candidates:\n",
    "        if len(df_slice)<W: continue\n",
    "        tm=metric_series(df_slice, feats, tcol, W, smooth_win)\n",
    "        nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "        if nfin>=min_finite: return W, tm, tried\n",
    "    best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "    if best and len(df_slice)>=best[0]:\n",
    "        W=best[0]; tm=metric_series(df_slice, feats, tcol, W, smooth_win); return W, tm, tried\n",
    "    W=max(min_window, min(W_desired, len(df_slice)//2))\n",
    "    tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "    return W, tm, tried\n",
    "\n",
    "def persistence_filter(flags, times, min_dur_sec):\n",
    "    f=flags.copy(); idx=np.where(f==1)[0]\n",
    "    if len(idx)==0: return f*0\n",
    "    groups=[]; s=idx[0]; p=idx[0]\n",
    "    for k in idx[1:]:\n",
    "        if k==p+1: p=k\n",
    "        else: groups.append((s,p)); s=k; p=k\n",
    "    groups.append((s,p))\n",
    "    g2=f.copy()\n",
    "    for a,b in groups:\n",
    "        if times[b]-times[a] < min_dur_sec: g2[a:b+1]=0\n",
    "    return g2\n",
    "\n",
    "def count_breaches_per_hr(flags, times, refractory):\n",
    "    idx=np.where(flags==1)[0]\n",
    "    if len(idx)==0: return 0.0, np.array([], dtype=int)\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=refractory: keep.append(j); last=times[j]\n",
    "    horizon=max(times[-1]-times[0],1.0)\n",
    "    return len(keep)/(horizon/3600.0), np.array(keep, int)\n",
    "\n",
    "def fa_rate_with_gate(m, t, thr, tail, gate, min_dur, refractory):\n",
    "    if tail==\"high\": raw=(m>thr).astype(int)\n",
    "    else:            raw=(m<thr).astype(int)\n",
    "    gated = (raw & gate.astype(int))\n",
    "    persist = persistence_filter(gated, t, min_dur)\n",
    "    fa_hr, _ = count_breaches_per_hr(persist, t, refractory)\n",
    "    return fa_hr\n",
    "\n",
    "def bisection_threshold(m, t, tail, gate, target_fa, min_dur, refractory):\n",
    "    finite = np.isfinite(m)\n",
    "    if finite.sum()<5:\n",
    "        return (np.nanmedian(m), False, 0.0)\n",
    "    vals = m[finite]\n",
    "    lo = float(np.quantile(vals, 0.05))\n",
    "    hi = float(np.quantile(vals, 0.999))\n",
    "    # ensure monotonic ends produce FA below/above target\n",
    "    # For 'high': higher thr => fewer FAs; start at hi and step upward if needed\n",
    "    # For 'low' : lower thr  => fewer FAs; start at lo and step downward if needed\n",
    "    def fa_at(x): return fa_rate_with_gate(m, t, x, tail, gate, min_dur, refractory)\n",
    "    if tail==\"high\":\n",
    "        fa_hi = fa_at(hi)\n",
    "        if fa_hi>target_fa:\n",
    "            # push to extreme\n",
    "            hi = float(np.max(vals))\n",
    "            if fa_at(hi)>target_fa: return (hi, False, fa_at(hi))\n",
    "        # binary search between lo..hi to find minimal thr s.t. fa<=target\n",
    "        left, right = lo, hi\n",
    "        for _ in range(24):\n",
    "            mid = (left+right)/2\n",
    "            fa = fa_at(mid)\n",
    "            if fa<=target_fa: right=mid\n",
    "            else: left=mid\n",
    "        return (right, True, fa_at(right))\n",
    "    else:\n",
    "        fa_lo = fa_at(lo)\n",
    "        if fa_lo>target_fa:\n",
    "            lo = float(np.min(vals))\n",
    "            if fa_at(lo)>target_fa: return (lo, False, fa_at(lo))\n",
    "        left, right = lo, hi\n",
    "        for _ in range(24):\n",
    "            mid = (left+right)/2\n",
    "            fa = fa_at(mid)\n",
    "            # for low-tail: decreasing thr lowers FA; we want \"largest thr with fa<=target\"\n",
    "            if fa<=target_fa: left=mid\n",
    "            else: right=mid\n",
    "        return (left, True, fa_at(left))\n",
    "\n",
    "def detect(breach_ts, event_ts, lead_min, lead_max, horizon):\n",
    "    if len(event_ts)==0: return 0.0, math.nan, 0.0\n",
    "    det=[]; used=set()\n",
    "    for et in event_ts:\n",
    "        lo,hi = et-lead_max, et-lead_min\n",
    "        idx=np.where((breach_ts>=lo)&(breach_ts<=hi))[0]\n",
    "        if len(idx)>0:\n",
    "            first=breach_ts[idx].min(); det.append(et-first); used.add(float(first))\n",
    "    rate=len(det)/len(event_ts)\n",
    "    med = float(np.median(det)) if det else math.nan\n",
    "    fa  = [bt for bt in breach_ts if float(bt) not in used]\n",
    "    fah = len(fa)/max(horizon/3600.0,1e-9)\n",
    "    return float(rate), med, float(fah)\n",
    "\n",
    "def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "    if len(event_ts)==0: return 1.0\n",
    "    rng=np.random.default_rng(seed); c=0\n",
    "    for _ in range(n_perm):\n",
    "        perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "        r,_,_=detect(breach_ts,perm,lead_min,lead_max,horizon)\n",
    "        if r>=obs_rate-1e-12: c+=1\n",
    "    return (c+1)/(n_perm+1)\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load & prep\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "N=len(df)\n",
    "\n",
    "# 1) Try label transitions (excluding junky names)\n",
    "audit = audit_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"], CONFIG[\"EXCLUDE_LABEL_NAMES\"])\n",
    "ev_full=np.array([],float); event_name=None\n",
    "if audit:\n",
    "    event_name, _ = audit[0]\n",
    "    ev_full = df[tcol].values[transitions_from_series(df[event_name])]\n",
    "\n",
    "# 2) If none and allowed, derive events from ENERGY on TRAIN-only rule\n",
    "derived=False; energy_rule=None\n",
    "if ev_full.size==0 and CONFIG[\"USE_DERIVED_ENERGY_IF_NO_LABEL\"]:\n",
    "    feats_all = numeric_cols(df, exclude=[tcol])\n",
    "    if len(feats_all)>0:\n",
    "        E_full = energy_series(df, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "        # provisional TRAIN for choosing rule\n",
    "        idx_train_prov = clamp_idx(int(0.80*N), N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "        t_train = E_full[tcol].values[:idx_train_prov]\n",
    "        s_train = pd.Series(E_full[\"energy\"].values[:idx_train_prov])\n",
    "        best=None\n",
    "        for q in CONFIG[\"DERIVED_Q_CAND\"]:\n",
    "            thr = float(np.nanquantile(s_train.values[np.isfinite(s_train.values)], q))\n",
    "            hits = threshold_crossings(s_train, t_train, thr, \"up\")\n",
    "            if hits.size==0: continue\n",
    "            if not (CONFIG[\"DERIVED_MIN_TRAIN_EVENTS\"] <= hits.size <= CONFIG[\"DERIVED_MAX_TRAIN_EVENTS\"]): continue\n",
    "            sep = np.diff(hits) if hits.size>1 else np.array([np.inf])\n",
    "            if float(np.median(sep)) < CONFIG[\"DERIVED_MIN_SEP_SEC\"]: continue\n",
    "            score = hits.size * (float(np.median(sep))+1.0)\n",
    "            cand=dict(mode=f\"ENERGY(up@q={q})\", thr=thr, n=int(hits.size), med_sep=float(np.median(sep)))\n",
    "            if (best is None) or (score > best[\"n\"]*(best[\"med_sep\"]+1.0)): best=cand\n",
    "        if best:\n",
    "            derived=True; energy_rule=best; event_name=best[\"mode\"]\n",
    "            ev_full = threshold_crossings(pd.Series(E_full[\"energy\"].values), E_full[tcol].values, best[\"thr\"], \"up\")\n",
    "\n",
    "# Clean abort if truly no events\n",
    "if ev_full.size==0:\n",
    "    pre = os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v15 — Prereg (no events)\\nRun: {RUN_ID}\\nTime: {STAMP}\\n\"\n",
    "                f\"Audit(top): {audit[:10]}\\nDerived_used={derived}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\",\n",
    "               audit=audit[:10], derived_used=derived, decision=\"FAIL\")\n",
    "    with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\"); print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 3) Force latest event into HOLD with prepad; clamp rows\n",
    "    times=df[tcol].values\n",
    "    latest=ev_full[-1]; t0_target=max(times[0], latest - CONFIG[\"PREPAD_SEC\"])\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx=clamp_idx(idx, N, CONFIG[\"MIN_TRAIN_ROWS\"], CONFIG[\"MIN_HOLD_ROWS\"])\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "    # Features for CNT metric (exclude time + explicit label col if present)\n",
    "    excl={tcol}\n",
    "    if event_name and event_name in df.columns: excl.add(event_name)\n",
    "    feats=[c for c in numeric_cols(df, exclude=[]) if c not in excl and c in df.columns]\n",
    "\n",
    "    # 4) Compute CNT metric (TRAIN/HOLD) with fallbacks\n",
    "    W_tr, m_tr, tried_tr = find_working_window(train, feats, tcol, CONFIG[\"WINDOW\"], CONFIG[\"SMOOTH_WIN\"],\n",
    "                                               CONFIG[\"MIN_TRAIN_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "    W_hd, m_hd, tried_hd = find_working_window(hold,  feats, tcol, W_tr, CONFIG[\"SMOOTH_WIN\"],\n",
    "                                               CONFIG[\"MIN_HOLD_FINITE\"], CONFIG[\"MIN_WINDOW\"])\n",
    "\n",
    "    # 5) Training-only ENERGY gate (fixed)\n",
    "    feats_all = numeric_cols(df, exclude=[tcol])\n",
    "    E_train = energy_series(train, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "    gate_thr = float(np.nanquantile(E_train[\"energy\"].values[np.isfinite(E_train[\"energy\"].values)], CONFIG[\"ENERGY_GATE_Q\"]))\n",
    "    gate_tr  = (E_train[\"energy\"].values >= gate_thr)\n",
    "    E_hold  = energy_series(hold, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "    gate_hd = (E_hold[\"energy\"].values >= gate_thr)  # same threshold as TRAIN\n",
    "\n",
    "    # 6) Choose tail that can meet FA cap with gating; bisection to solve\n",
    "    t_tr = m_tr[tcol].values; v_tr = m_tr[\"metric\"].values\n",
    "    # Try both tails, pick the one that reaches (or gets closest to) the FA cap\n",
    "    best_tail=None; best_thr=None; best_gap=1e9; best_fa=None\n",
    "    for tail in [\"high\",\"low\"]:\n",
    "        thr, ok, fa = bisection_threshold(v_tr, t_tr, tail, gate_tr, CONFIG[\"TRAIN_FA_CAP_PER_HR\"],\n",
    "                                          CONFIG[\"MIN_BREACH_DUR_SEC\"], CONFIG[\"REFRACTORY\"])\n",
    "        gap = abs(fa - CONFIG[\"TRAIN_FA_CAP_PER_HR\"])\n",
    "        # prefer successful (ok) then smaller gap\n",
    "        rank = (0 if ok else 1, gap)\n",
    "        if best_tail is None or rank < best_gap:\n",
    "            best_tail=tail; best_thr=thr; best_gap=rank; best_fa=fa\n",
    "\n",
    "    tail = best_tail; theta = best_thr; fa_train = best_fa\n",
    "\n",
    "    # 7) Preregistration (frozen BEFORE predictions)\n",
    "    pre = os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v15 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Events: name='{event_name}' | total_on_full={int(ev_full.size)}\\n\"\n",
    "                f\"Derived_used={derived} | energy_rule={json.dumps(energy_rule) if energy_rule else 'N/A'}\\n\"\n",
    "                f\"Split: HOLD starts {CONFIG['PREPAD_SEC']}s before latest event; idx={idx}; \"\n",
    "                f\"HOLD=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}]\\n\\n\"\n",
    "                f\"TRAIN metric fallback: {tried_tr} → W_train={W_tr}\\nHOLD metric fallback: {tried_hd} → W_hold={W_hd}\\n\\n\"\n",
    "                f\"Energy gate (TRAIN-only): gate_q={CONFIG['ENERGY_GATE_Q']} → gate_thr={gate_thr:.4f}; reused on HOLD\\n\"\n",
    "                f\"Tail chosen: {tail} | FA cap target={CONFIG['TRAIN_FA_CAP_PER_HR']}/hr | Θ*={theta:.6f} | TRAIN FA/hr≈{fa_train:.3f}\\n\"\n",
    "                f\"Persistence={CONFIG['MIN_BREACH_DUR_SEC']}s | Refractory={CONFIG['REFRACTORY']}s\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | Permutations={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # 8) Blind predictions on HOLD (apply gate + persistence + refractory)\n",
    "    t_hd = m_hd[tcol].values; v_hd = m_hd[\"metric\"].values\n",
    "    raw = (v_hd>theta).astype(int) if tail==\"high\" else (v_hd<theta).astype(int)\n",
    "    gated = raw & gate_hd.astype(int)\n",
    "    persist = persistence_filter(gated, t_hd, CONFIG[\"MIN_BREACH_DUR_SEC\"])\n",
    "    _, keep_idx = count_breaches_per_hr(persist, t_hd, CONFIG[\"REFRACTORY\"])\n",
    "    flags = np.zeros_like(raw); flags[keep_idx]=1\n",
    "    pred = pd.DataFrame({tcol:t_hd, \"metric\":v_hd, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # 9) Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    # Events in HOLD\n",
    "    ev_hold = ev_full[(ev_full>=hold[tcol].iloc[0]) & (ev_full<=hold[tcol].iloc[-1])]\n",
    "    breach_ts = t_hd[keep_idx]\n",
    "    horizon = float(t_hd[-1]-t_hd[0]) if len(t_hd)>=2 else 1.0\n",
    "    det, med, fah = detect(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon)\n",
    "    p = pval(breach_ts, ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fah<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"],\n",
    "        events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_tr, W_hold=W_hd, tail=tail, theta_star=float(theta), train_fa_per_hr=float(fa_train),\n",
    "        breaches_n=int(flags.sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fah), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre, predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debf9442-057b-408e-a20c-af7ecb5b1109",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "no binding for nonlocal 'best' found (3611442253.py, line 299)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 299\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mnonlocal best\u001b[39m\n    ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m no binding for nonlocal 'best' found\n"
     ]
    }
   ],
   "source": [
    "# ======================= CNT Flash-Proof v16 — Single Mega Cell =======================\n",
    "# TRAIN-only selection (no peeking):\n",
    "# • If labels exist, use them; else derive events from an ENERGY(up) rule chosen on TRAIN.\n",
    "# • Fix an ENERGY gate on TRAIN and reuse it on HOLD.\n",
    "# • Search BOTH tails for a Θ* that meets a TRAIN FA/hr cap AND maximizes TRAIN hit-rate.\n",
    "# • Freeze → prereg → SHA-256 → blind HOLD preds → reveal → score.\n",
    "#\n",
    "# PASS rule: Detect ≥65% of events, Median lead ≥15 s, False alarms ≤1.0/hr.\n",
    "\n",
    "import os, json, math, uuid, hashlib\n",
    "from datetime import datetime, timezone\n",
    "from typing import Optional, List, Tuple\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "# ----------------------------- CONFIG (edit me) -----------------------------\n",
    "CONFIG = dict(\n",
    "    DATA_PATH=r\"C:\\Users\\caleb\\CNT_Lab\\artifacts\\tables\\migrated__cnt-eeg-labeled-all__68a51fca.csv\",\n",
    "    TIME_COL=\"timestamp\",\n",
    "\n",
    "    # Label search; excludes junky label-like columns\n",
    "    CANDIDATE_LABEL_KEYS=[\"event\",\"stage\",\"sleep\",\"label\",\"state\",\"target\",\"y\",\"phase\",\"regime\"],\n",
    "    EXCLUDE_LABEL_NAMES=[\"file\",\"filename\",\"filepath\",\"path\",\"id\",\"index\"],\n",
    "\n",
    "    # If no labels flip, derive events from ENERGY on TRAIN (robust across channels)\n",
    "    USE_DERIVED_ENERGY_IF_NO_LABEL=True,\n",
    "    DERIVED_Q_CAND=[0.80,0.85,0.90,0.95],   # TRAIN energy quantiles to try (direction=\"up\")\n",
    "    DERIVED_MIN_TRAIN_EVENTS=1,\n",
    "    DERIVED_MAX_TRAIN_EVENTS=32,\n",
    "    DERIVED_MIN_SEP_SEC=20.0,\n",
    "\n",
    "    # Hold placement (force latest event into HOLD with prepad)\n",
    "    PREPAD_SEC=300.0,\n",
    "    MIN_TRAIN_ROWS=16,\n",
    "    MIN_HOLD_ROWS=64,\n",
    "\n",
    "    # CNT detector metric\n",
    "    WINDOW=97,\n",
    "    SMOOTH_WIN=11,\n",
    "\n",
    "    # TRAIN-only energy gate (reused on HOLD)\n",
    "    ENERGY_SMOOTH_WIN=9,\n",
    "    ENERGY_GATE_Q=0.80,            # TRAIN quantile; gate = energy >= gate_thr\n",
    "\n",
    "    # Lead window & de-dup\n",
    "    LEAD_MIN=15.0, LEAD_MAX=90.0,\n",
    "    MIN_BREACH_DUR_SEC=30.0,       # require persistence\n",
    "    REFRACTORY=180.0,              # cooldown for counted breaches\n",
    "\n",
    "    # TRAIN selection targets for Θ*\n",
    "    TRAIN_FA_CAP_PER_HR=0.30,      # max TRAIN FA/hr\n",
    "    TRAIN_MIN_HIT_TARGET=0.40,     # we prefer thresholds that achieve at least this TRAIN hit-rate\n",
    "\n",
    "    # Threshold search grids (on TRAIN, both tails)\n",
    "    HIGH_QS=[0.90,0.92,0.94,0.96,0.97,0.98,0.985,0.99,0.995],\n",
    "    LOW_QS =[0.10,0.08,0.06,0.05,0.04,0.03,0.02,0.015,0.01],\n",
    "\n",
    "    # Fallbacks\n",
    "    MIN_TRAIN_FINITE=10,\n",
    "    MIN_HOLD_FINITE=5,\n",
    "    MIN_WINDOW=5,\n",
    "\n",
    "    # Output\n",
    "    N_PERM=500,\n",
    "    OUT_DIR=\"cnt_flashproof_artifacts\",\n",
    "    RNG_SEED=12345,\n",
    ")\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def now_utc(): return datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%SZ\")\n",
    "def read_table(p):\n",
    "    ext=os.path.splitext(p)[1].lower()\n",
    "    if ext in (\".parquet\",\".pq\"): return pd.read_parquet(p)\n",
    "    if ext in (\".csv\",\".tsv\"):    return pd.read_csv(p, sep=\",\" if ext==\".csv\" else \"\\t\")\n",
    "    raise ValueError(f\"Unsupported file: {ext}\")\n",
    "\n",
    "def coerce_time(df, tcol: Optional[str]):\n",
    "    for c in [tcol,\"timestamp\",\"time\",\"datetime\",\"date\",\"index\"]:\n",
    "        if c and c in df.columns: tcol=c; break\n",
    "    if tcol is None or tcol not in df.columns:\n",
    "        df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    s=df[tcol]\n",
    "    if np.issubdtype(s.dtype,np.number):\n",
    "        dt=float(np.median(np.diff(s.values))) if len(s)>1 else 1.0\n",
    "        return df,tcol,max(dt,1e-9)\n",
    "    s2=pd.to_datetime(s,errors=\"coerce\",utc=True)\n",
    "    if s2.isna().any(): s2=pd.to_datetime(s,errors=\"coerce\")\n",
    "    if s2.isna().any(): df=df.copy(); df[\"__t__\"]=np.arange(len(df),dtype=float); return df,\"__t__\",1.0\n",
    "    t0=s2.iloc[0]; secs=(s2-t0).dt.total_seconds().astype(float)\n",
    "    df=df.copy(); df[\"__t__\"]=secs.values; return df,\"__t__\",1.0\n",
    "\n",
    "def numeric_cols(df, exclude):\n",
    "    return [c for c in df.columns if c not in exclude and np.issubdtype(df[c].dtype,np.number)]\n",
    "\n",
    "# -------- robust correlation + CNT metric --------\n",
    "def safe_corr(Z: np.ndarray) -> np.ndarray:\n",
    "    eps=1e-8\n",
    "    med=np.median(Z,axis=0,keepdims=True)\n",
    "    mad=np.median(np.abs(Z-med),axis=0,keepdims=True); mad=np.where(mad<eps,eps,mad)\n",
    "    X=(Z-med)/mad\n",
    "    std=np.std(X,axis=0,ddof=1); keep=std>1e-6\n",
    "    X=X[:,keep] if keep.any() else X\n",
    "    if X.shape[1]<=1: return np.eye(max(1,X.shape[1]))\n",
    "    cov=np.cov(X,rowvar=False); lam=1e-3*np.trace(cov)/cov.shape[0]\n",
    "    cov=cov + lam*np.eye(cov.shape[0])\n",
    "    d=np.sqrt(np.clip(np.diag(cov),1e-12,None))\n",
    "    C=cov/(d[:,None]*d[None,:])\n",
    "    return np.nan_to_num(C, nan=0.0, posinf=0.0, neginf=0.0)\n",
    "\n",
    "def H_agiew(win: np.ndarray) -> float:\n",
    "    C=safe_corr(win)\n",
    "    vals=np.linalg.eigvalsh(C + 1e-8*np.eye(C.shape[0])); vals=np.maximum(vals,1e-8)\n",
    "    p=vals/np.sum(vals); return float(-(p*np.log(p)).sum())\n",
    "\n",
    "def metric_series(df, feats, tcol, W, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X, axis=0, keepdims=True), X)\n",
    "    T=len(df); m=np.full(T, np.nan)\n",
    "    for i in range(W, T+1): m[i-1]=H_agiew(X[i-W:i,:])\n",
    "    s=pd.Series(m)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"metric\":s.values})\n",
    "\n",
    "# -------- ENERGY (events & gate) --------\n",
    "def energy_series(df, feats, tcol, smooth_win):\n",
    "    X=df[feats].values\n",
    "    X=np.where(np.isnan(X), np.nanmedian(X,axis=0,keepdims=True), X)\n",
    "    med = np.nanmedian(X, axis=1)\n",
    "    mad = np.nanmedian(np.abs(X - med[:,None]), axis=1) + 1e-8\n",
    "    zmag = np.abs((X - med[:,None]) / mad[:,None])\n",
    "    e = np.nanmedian(zmag, axis=1)\n",
    "    s=pd.Series(e)\n",
    "    if smooth_win>1: s=s.rolling(smooth_win,center=True,min_periods=1).median()\n",
    "    return pd.DataFrame({tcol:df[tcol].values, \"energy\":s.values})\n",
    "\n",
    "def thr_cross(series: pd.Series, times: np.ndarray, thr: float, direction: str):\n",
    "    if direction==\"up\":\n",
    "        hits = np.where((series.shift(1) < thr) & (series >= thr))[0]\n",
    "    else:\n",
    "        hits = np.where((series.shift(1) > thr) & (series <= thr))[0]\n",
    "    hits = hits[~np.isnan(series.iloc[hits]).values]\n",
    "    return times[hits]\n",
    "\n",
    "# -------- label transitions & audit --------\n",
    "def transitions_from_series(s: pd.Series) -> np.ndarray:\n",
    "    if not np.issubdtype(s.dtype,np.number):\n",
    "        v=s.astype(str).str.strip().str.lower().values\n",
    "    else:\n",
    "        v=s.values\n",
    "    if pd.isna(v).any(): v=pd.Series(v).replace({None: np.nan}).ffill().bfill().values\n",
    "    return np.where(v[1:]!=v[:-1])[0] + 1\n",
    "\n",
    "def audit_labels(df, keys, exclude_names):\n",
    "    ex=set(n.lower() for n in exclude_names); rows=[]\n",
    "    for c in df.columns:\n",
    "        if c.lower() in ex: continue\n",
    "        cn=c.lower()\n",
    "        if any(k in cn for k in keys) or (not np.issubdtype(df[c].dtype,np.number) and df[c].nunique(dropna=True)<=10):\n",
    "            rows.append((c, int(transitions_from_series(df[c]).size)))\n",
    "    rows=sorted(list({(c,n) for c,n in rows}), key=lambda z:(-z[1], z[0]))\n",
    "    return rows\n",
    "\n",
    "# -------- helpers: persistence, dedup, scores --------\n",
    "def persistence_filter(flags, times, min_dur_sec):\n",
    "    f=flags.copy(); idx=np.where(f==1)[0]\n",
    "    if len(idx)==0: return f*0\n",
    "    groups=[]; s=idx[0]; p=idx[0]\n",
    "    for k in idx[1:]:\n",
    "        if k==p+1: p=k\n",
    "        else: groups.append((s,p)); s=k; p=k\n",
    "    groups.append((s,p))\n",
    "    g2=f.copy()\n",
    "    for a,b in groups:\n",
    "        if times[b]-times[a] < min_dur_sec: g2[a:b+1]=0\n",
    "    return g2\n",
    "\n",
    "def dedup_keep(times, flags, gap):\n",
    "    idx=np.where(flags.astype(bool))[0]\n",
    "    if len(idx)==0: return np.array([],int)\n",
    "    keep=[idx[0]]; last=times[idx[0]]\n",
    "    for j in idx[1:]:\n",
    "        if times[j]-last>=gap: keep.append(j); last=times[j]\n",
    "    return np.array(keep,int)\n",
    "\n",
    "def train_eval(v_tr, t_tr, tail, gate_tr, thr, ref, min_dur, ev_train, lead_min, lead_max):\n",
    "    raw = (v_tr>thr).astype(int) if tail==\"high\" else (v_tr<thr).astype(int)\n",
    "    gated = raw & gate_tr.astype(int)\n",
    "    persist = persistence_filter(gated, t_tr, min_dur)\n",
    "    keep = dedup_keep(t_tr, persist, ref)\n",
    "    # FA/hr on TRAIN (count all kept)\n",
    "    horizon=max(t_tr[-1]-t_tr[0],1.0); fa = len(keep)/(horizon/3600.0)\n",
    "    # TRAIN detection vs training events\n",
    "    dets=[]\n",
    "    for et in ev_train:\n",
    "        lo,hi=et-lead_max, et-lead_min\n",
    "        idx=np.where((t_tr[keep]>=lo)&(t_tr[keep]<=hi))[0]\n",
    "        if idx.size>0: dets.append(et - t_tr[keep][idx].min())\n",
    "    hit = len(dets)/max(1,len(ev_train)) if len(ev_train)>0 else 0.0\n",
    "    medlead = float(np.median(dets)) if dets else math.nan\n",
    "    return hit, medlead, fa, keep\n",
    "\n",
    "# ============================== MAIN ==============================\n",
    "np.random.seed(CONFIG[\"RNG_SEED\"])\n",
    "os.makedirs(CONFIG[\"OUT_DIR\"], exist_ok=True)\n",
    "STAMP=now_utc(); RUN_ID=f\"{STAMP}_{uuid.uuid4().hex[:8]}\"\n",
    "\n",
    "# Load\n",
    "df_raw=read_table(CONFIG[\"DATA_PATH\"])\n",
    "df,tcol,dt=coerce_time(df_raw, CONFIG[\"TIME_COL\"])\n",
    "N=len(df)\n",
    "\n",
    "# 1) Find label transitions\n",
    "audit = audit_labels(df, CONFIG[\"CANDIDATE_LABEL_KEYS\"], CONFIG[\"EXCLUDE_LABEL_NAMES\"])\n",
    "ev_full=np.array([],float); event_name=None\n",
    "if audit:\n",
    "    event_name,_ = audit[0]\n",
    "    ev_full = df[tcol].values[transitions_from_series(df[event_name])]\n",
    "\n",
    "# 2) Derived ENERGY events if none\n",
    "derived=False; energy_rule=None\n",
    "if ev_full.size==0 and CONFIG[\"USE_DERIVED_ENERGY_IF_NO_LABEL\"]:\n",
    "    feats_all = numeric_cols(df, exclude=[tcol])\n",
    "    if len(feats_all)>0:\n",
    "        E = energy_series(df, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "        # use 80% TRAIN slice to choose energy rule\n",
    "        idx_train_prov = max(CONFIG[\"MIN_TRAIN_ROWS\"], min(int(0.80*N), N-CONFIG[\"MIN_HOLD_ROWS\"]))\n",
    "        t_train = E[tcol].values[:idx_train_prov]\n",
    "        s_train = pd.Series(E[\"energy\"].values[:idx_train_prov])\n",
    "        best=None\n",
    "        for q in CONFIG[\"DERIVED_Q_CAND\"]:\n",
    "            thr = float(np.nanquantile(s_train.values[np.isfinite(s_train.values)], q))\n",
    "            hits = thr_cross(s_train, t_train, thr, \"up\")\n",
    "            if hits.size==0: continue\n",
    "            if not (CONFIG[\"DERIVED_MIN_TRAIN_EVENTS\"] <= hits.size <= CONFIG[\"DERIVED_MAX_TRAIN_EVENTS\"]): continue\n",
    "            sep = np.diff(hits) if hits.size>1 else np.array([np.inf])\n",
    "            if float(np.median(sep)) < CONFIG[\"DERIVED_MIN_SEP_SEC\"]: continue\n",
    "            score = hits.size * (float(np.median(sep))+1.0)\n",
    "            cand=dict(mode=f\"ENERGY(up@q={q})\", thr=thr, n=int(hits.size), med_sep=float(np.median(sep)))\n",
    "            if (best is None) or (score > best[\"n\"]*(best[\"med_sep\"]+1.0)): best=cand\n",
    "        if best:\n",
    "            derived=True; energy_rule=best; event_name=best[\"mode\"]\n",
    "            ev_full = thr_cross(pd.Series(E[\"energy\"].values), E[tcol].values, best[\"thr\"], \"up\")\n",
    "\n",
    "# abort if no events\n",
    "if ev_full.size==0:\n",
    "    pre=os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v16 — Prereg (no events)\\nRun: {RUN_ID}\\nTime: {STAMP}\\nAudit(top): {audit[:10]}\\nDerived={derived}\\n\")\n",
    "    score=dict(run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"], reason=\"no_events_found\", audit=audit[:10], derived=derived, decision=\"FAIL\")\n",
    "    with open(os.path.join(CONFIG[\"OUT_DIR\"], f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(\"=== CNT Flash-Proof — ABORTED (no events found) ===\"); print(json.dumps(score, indent=2))\n",
    "else:\n",
    "    # 3) Put latest event in HOLD with prepad; clamp rows\n",
    "    times=df[tcol].values\n",
    "    latest=ev_full[-1]; t0_target=max(times[0], latest - CONFIG[\"PREPAD_SEC\"])\n",
    "    idx=np.searchsorted(times, t0_target, side=\"left\")\n",
    "    idx=max(CONFIG[\"MIN_TRAIN_ROWS\"], min(idx, N-CONFIG[\"MIN_HOLD_ROWS\"]))\n",
    "    train=df.iloc[:idx].reset_index(drop=True)\n",
    "    hold =df.iloc[idx:].reset_index(drop=True)\n",
    "\n",
    "    # events in TRAIN/HOLD\n",
    "    ev_train = ev_full[(ev_full>=train[tcol].iloc[0]) & (ev_full<=train[tcol].iloc[-1])]\n",
    "    ev_hold  = ev_full[(ev_full>=hold[tcol].iloc[0])  & (ev_full<=hold[tcol].iloc[-1])]\n",
    "\n",
    "    # features for CNT metric (exclude time and explicit label)\n",
    "    excl={tcol}\n",
    "    if event_name and event_name in df.columns: excl.add(event_name)\n",
    "    feats=[c for c in numeric_cols(df, exclude=[]) if c not in excl]\n",
    "\n",
    "    # 4) CNT metric with fallbacks\n",
    "    def find_w(df_slice):\n",
    "        cands=[CONFIG[\"WINDOW\"], int(0.8*CONFIG[\"WINDOW\"]), int(0.6*CONFIG[\"WINDOW\"]), CONFIG[\"WINDOW\"]//2, 31, 21, 13, 9, 7, 5]\n",
    "        cands=[w for w in [max(CONFIG[\"MIN_WINDOW\"],int(w)) for w in cands] if w>0]\n",
    "        tried=[]\n",
    "        for W in cands:\n",
    "            if len(df_slice)<W: continue\n",
    "            tm=metric_series(df_slice, feats, tcol, W, CONFIG[\"SMOOTH_WIN\"])\n",
    "            nfin=int(np.isfinite(tm[\"metric\"]).sum()); tried.append((W,nfin))\n",
    "            if nfin>=CONFIG[\"MIN_TRAIN_FINITE\"]: return W, tm, tried\n",
    "        best=max((x for x in tried), key=lambda z:z[1], default=None)\n",
    "        if best and len(df_slice)>=best[0]:\n",
    "            W=best[0]; tm=metric_series(df_slice, feats, tcol, W, CONFIG[\"SMOOTH_WIN\"]); return W, tm, tried\n",
    "        W=max(CONFIG[\"MIN_WINDOW\"], min(CONFIG[\"WINDOW\"], len(df_slice)//2))\n",
    "        tm=pd.DataFrame({tcol:df_slice[tcol].values, \"metric\":np.full(len(df_slice), np.nan)})\n",
    "        return W, tm, tried\n",
    "\n",
    "    W_tr, m_tr, tried_tr = find_w(train)\n",
    "    W_hd, m_hd, tried_hd = find_w(hold)\n",
    "\n",
    "    # 5) Energy gate (TRAIN-only → reused on HOLD)\n",
    "    feats_all = numeric_cols(df, exclude=[tcol])\n",
    "    E_tr = energy_series(train, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "    gate_thr = float(np.nanquantile(E_tr[\"energy\"].values[np.isfinite(E_tr[\"energy\"].values)], CONFIG[\"ENERGY_GATE_Q\"]))\n",
    "    gate_tr  = (E_tr[\"energy\"].values >= gate_thr)\n",
    "\n",
    "    # 6) TRAIN threshold selection — search both tails, cap FA/hr, maximize hit-rate\n",
    "    t_tr = m_tr[tcol].values; v_tr = m_tr[\"metric\"].values\n",
    "    best=None\n",
    "    def consider_tail(tail, qs):\n",
    "        nonlocal best\n",
    "        for q in qs:\n",
    "            finite=v_tr[np.isfinite(v_tr)]\n",
    "            if finite.size<5: continue\n",
    "            thr=float(np.quantile(finite, q))\n",
    "            hit, medlead, fa, keep = train_eval(v_tr, t_tr, tail, gate_tr, thr,\n",
    "                                                CONFIG[\"REFRACTORY\"], CONFIG[\"MIN_BREACH_DUR_SEC\"],\n",
    "                                                ev_train, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"])\n",
    "            # primary: FA<=cap, then maximize hit; secondary: larger medlead\n",
    "            ok = (fa <= CONFIG[\"TRAIN_FA_CAP_PER_HR\"])\n",
    "            rank = (0 if ok else 1, -hit, - (medlead if not math.isnan(medlead) else -1.0), fa)\n",
    "            if (best is None) or (rank < best[\"rank\"]):\n",
    "                best=dict(tail=tail, thr=thr, q=q, hit=hit, medlead=medlead, fa=fa, rank=rank)\n",
    "    consider_tail(\"high\", CONFIG[\"HIGH_QS\"])\n",
    "    consider_tail(\"low\",  CONFIG[\"LOW_QS\"])\n",
    "\n",
    "    # If nothing meets FA cap with any tail, relax to the best hit-rate overall\n",
    "    if best is None:\n",
    "        best=dict(tail=\"high\", thr=float(np.nanmedian(v_tr)), q=None, hit=0.0, medlead=float(\"nan\"), fa=float(\"inf\"), rank=(1,0,0,float(\"inf\")))\n",
    "    tail = best[\"tail\"]; theta = best[\"thr\"]\n",
    "\n",
    "    # 7) Preregistration (frozen)\n",
    "    out_dir=CONFIG[\"OUT_DIR\"]; os.makedirs(out_dir, exist_ok=True)\n",
    "    pre=os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg.md\")\n",
    "    with open(pre,\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(f\"# CNT Flash-Proof v16 — Preregistration (frozen)\\n\"\n",
    "                f\"Run ID: {RUN_ID}\\nTime: {STAMP}\\nData: {CONFIG['DATA_PATH']}\\n\\n\"\n",
    "                f\"Events: name='{event_name}' | total_on_full={int(ev_full.size)} | derived={derived} | energy_rule={json.dumps(energy_rule) if energy_rule else 'N/A'}\\n\"\n",
    "                f\"Split: HOLD starts {CONFIG['PREPAD_SEC']}s before latest event; idx={idx}; \"\n",
    "                f\"HOLD=[{hold[tcol].iloc[0]}, {hold[tcol].iloc[-1]}] | events_in_hold={int(ev_hold.size)}\\n\\n\"\n",
    "                f\"TRAIN W fallback: {tried_tr} → W_train={W_tr}\\nHOLD  W fallback: {tried_hd} → W_hold={W_hd}\\n\\n\"\n",
    "                f\"Energy gate (TRAIN-only): gate_q={CONFIG['ENERGY_GATE_Q']} → gate_thr={gate_thr:.6f} (reused on HOLD)\\n\"\n",
    "                f\"Θ* selection (TRAIN-only): tail={tail} | q={best.get('q')} | Θ*={theta:.6f} | \"\n",
    "                f\"TRAIN: hit={best['hit']:.3f}, med_lead={best['medlead']}, FA/hr={best['fa']:.3f} (cap={CONFIG['TRAIN_FA_CAP_PER_HR']})\\n\"\n",
    "                f\"Persistence={CONFIG['MIN_BREACH_DUR_SEC']}s | Refractory={CONFIG['REFRACTORY']}s\\n\"\n",
    "                f\"Lead window: [{CONFIG['LEAD_MIN']}s, {CONFIG['LEAD_MAX']}s] | Permutations={CONFIG['N_PERM']}\\n\\n\"\n",
    "                f\"**Prediction:** CNT detects ≥65% of events within lead window, median lead ≥15 s, ≤1 FA/hr.\\n\")\n",
    "\n",
    "    # 8) Blind HOLD predictions\n",
    "    E_hd = energy_series(hold, feats_all, tcol, CONFIG[\"ENERGY_SMOOTH_WIN\"])\n",
    "    gate_hd = (E_hd[\"energy\"].values >= gate_thr)\n",
    "    t_hd = m_hd[tcol].values; v_hd = m_hd[\"metric\"].values\n",
    "    raw = (v_hd>theta).astype(int) if tail==\"high\" else (v_hd<theta).astype(int)\n",
    "    gated = raw & gate_hd.astype(int)\n",
    "    persist = persistence_filter(gated, t_hd, CONFIG[\"MIN_BREACH_DUR_SEC\"])\n",
    "    keep = dedup_keep(t_hd, persist, CONFIG[\"REFRACTORY\"])\n",
    "    flags = np.zeros_like(raw); flags[keep]=1\n",
    "    pred = pd.DataFrame({tcol:t_hd, \"metric\":v_hd, \"breach_flag\":flags})\n",
    "    pred_path=os.path.join(out_dir, f\"flashproof_{RUN_ID}_predictions.csv\"); pred.to_csv(pred_path, index=False)\n",
    "\n",
    "    # 9) Seal & score\n",
    "    pred_sha=hashlib.sha256(open(pred_path,\"rb\").read()).hexdigest()\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_prereg_locked.md\"),\"w\",encoding=\"utf-8\") as f:\n",
    "        f.write(open(pre,\"r\",encoding=\"utf-8\").read() + \"\\nPREDICTIONS_SHA256: \" + pred_sha + \"\\n\")\n",
    "\n",
    "    horizon=max(t_hd[-1]-t_hd[0],1.0)\n",
    "    dets=[]\n",
    "    for et in ev_hold:\n",
    "        lo,hi=et-CONFIG[\"LEAD_MAX\"], et-CONFIG[\"LEAD_MIN\"]\n",
    "        idxs=np.where((t_hd[keep]>=lo)&(t_hd[keep]<=hi))[0]\n",
    "        if idxs.size>0: dets.append(et - t_hd[keep][idxs].min())\n",
    "    det = len(dets)/max(1,len(ev_hold)) if len(ev_hold)>0 else 0.0\n",
    "    med = float(np.median(dets)) if dets else math.nan\n",
    "    # FA/hr: kept that are NOT used to detect an event\n",
    "    used=set()\n",
    "    for et in ev_hold:\n",
    "        lo,hi=et-CONFIG[\"LEAD_MAX\"], et-CONFIG[\"LEAD_MIN\"]\n",
    "        idxs=np.where((t_hd[keep]>=lo)&(t_hd[keep]<=hi))[0]\n",
    "        if idxs.size>0: used.add(int(keep[idxs].min()))\n",
    "    fa = len([k for k in keep if k not in used])/(horizon/3600.0)\n",
    "    # permutation p\n",
    "    def pval(breach_ts, event_ts, lead_min, lead_max, horizon, n_perm, seed, obs_rate):\n",
    "        if len(event_ts)==0: return 1.0\n",
    "        rng=np.random.default_rng(seed); c=0\n",
    "        for _ in range(n_perm):\n",
    "            perm=np.sort(rng.uniform(0.0,horizon,size=len(event_ts)))\n",
    "            r=0.0\n",
    "            for et in perm:\n",
    "                lo,hi=et-lead_max, et-lead_min\n",
    "                if np.any((breach_ts>=lo)&(breach_ts<=hi)): r+=1\n",
    "            r/=max(1,len(event_ts))\n",
    "            if r>=obs_rate-1e-12: c+=1\n",
    "        return (c+1)/(n_perm+1)\n",
    "    p = pval(t_hd[keep], ev_hold, CONFIG[\"LEAD_MIN\"], CONFIG[\"LEAD_MAX\"], horizon, CONFIG[\"N_PERM\"], CONFIG[\"RNG_SEED\"], det)\n",
    "    PASS = (det>=0.65) and (not math.isnan(med) and med>=15.0) and (fa<=1.0)\n",
    "\n",
    "    score=dict(\n",
    "        run_id=RUN_ID, data=CONFIG[\"DATA_PATH\"],\n",
    "        events_full=int(ev_full.size), events_in_hold=int(ev_hold.size),\n",
    "        W_train=W_tr, W_hold=W_hd, tail=tail, theta_star=float(theta),\n",
    "        train_hit=best[\"hit\"], train_med_lead=best[\"medlead\"], train_fa_per_hr=best[\"fa\"],\n",
    "        breaches_n=int(flags.sum()),\n",
    "        detection_rate=float(det), median_lead_s=(None if math.isnan(med) else float(med)),\n",
    "        false_alarms_per_hr=float(fa), perm_p_value=float(p),\n",
    "        decision=(\"PASS\" if PASS else \"FAIL\"),\n",
    "        predictions_csv=pred_path, prereg=pre, predictions_sha256=pred_sha\n",
    "    )\n",
    "    with open(os.path.join(out_dir, f\"flashproof_{RUN_ID}_score.json\"),\"w\",encoding=\"utf-8\") as f: json.dump(score,f,indent=2)\n",
    "    print(f\"=== CNT Flash-Proof — Holdout Score ({'PASS ✅' if PASS else 'FAIL ❌'}) ===\")\n",
    "    print(json.dumps(score, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c5d4fc-1aea-4667-9c0d-94566fb9681b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
