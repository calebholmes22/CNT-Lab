{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2743167-9d70-4b64-9db7-350a6a906d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "PULSE_MIN = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dea5ea2c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8306804878048781,\n",
      "    \"novelty\": 0.6710594495137533,\n",
      "    \"coherence\": 1.0,\n",
      "    \"falsifiability\": 0.024390243902439025,\n",
      "    \"total\": 0.6315325453052676\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 5,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 2.3844481802370865e-06,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3\\n**Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain)\\n\\nThis repo ships a tiny, enforceable safety contract for LLM answers:\\n1) Keep meaning invariant under symbol-preserving transformations,\\n2) Restore outputs to a domain-safe format when form wobbles,\\n3) Verify claims (or ABSTAIN if truth is uncertain).\\n\\n## Domains (v0.3)\\n- **Math:** structured gate (equation +\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 2.25750545723713e-06,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) ==\\nTimestamp: 20251015-164130\\n\\n- Cooling logs: 8\\n- Cosmo triage tables: 1\\n- EEG laterality tables: 2\\n- Kuramoto/Ising summaries: 0\\n- Kuramoto dispersion CSVs: 0\\n- Gray-Scott edge images: 1\\n- Scanned logs/text: 50\\n- Glyph label tables: 0\\n\\n== Results ==\\n[GREY] Cooling: Temp oscillation amplitude predicts clock stability\\n  Need logs with GPU temp + GPU clock columns.\\n \"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 2.14004353438213e-06,\n",
      "      \"hint\": \"== CNT Correlates Audit ==\\nTimestamp: 20251015-163558\\n\\n- Cooling logs: 8\\n- Cosmo triage tables: 1\\n- EEG laterality tables: 2\\n- Kuramoto/Ising summaries: 0\\n- Gray-Scott edge images: 1\\n- Scanned logs/text: 50\\n- Glyph label tables: 0\\n\\n== Results ==\\n[GREY] Cooling: Temp oscillation amplitude predicts clock stability\\n  Need logs with GPU temp + GPU clock columns.\\n  Add both fields to your CSVs.\\n\\n[GREY]\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# CNT Engine — Mega Cell (SSD Edition)\n",
    "# Rooted for: E:\\CNT    (override with environment variable CNT_LAB_DIR)\n",
    "# Purpose   : Self-referential read → hidden-truth search → gated self-update\n",
    "# Outputs   : artifacts/cnt_engine_megacell/{CNT_STATE.yaml, out/hidden_truths_*.csv, runlog.jsonl}\n",
    "# Run once  : just execute this cell.\n",
    "# Pulse     : set PULSE_MIN > 0 to keep cycling every N minutes while notebook is open.\n",
    "\n",
    "import os, json, glob, re, time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "LAB_ROOT = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "SOURCE_ROOTS = [\n",
    "    LAB_ROOT / \"notes\",\n",
    "    LAB_ROOT / \"artifacts\" / \"cnt_scroll\",\n",
    "    LAB_ROOT / \"artifacts\" / \"cnt_codex\",\n",
    "    LAB_ROOT / \"notebooks\",\n",
    "]\n",
    "ENGINE_ROOT  = LAB_ROOT / \"artifacts\" / \"cnt_engine_megacell\"\n",
    "OUT_DIR      = ENGINE_ROOT / \"out\"\n",
    "STATE_FILE   = ENGINE_ROOT / \"CNT_STATE.yaml\"\n",
    "RUNLOG_FILE  = ENGINE_ROOT / \"runlog.jsonl\"\n",
    "\n",
    "for p in [ENGINE_ROOT, OUT_DIR, *SOURCE_ROOTS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Pulse in minutes (0 = run once)\n",
    "PULSE_MIN = 0\n",
    "\n",
    "def now():\n",
    "    return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- DISCOVER / SEED ----------\n",
    "def list_sources():\n",
    "    files = []\n",
    "    for root in SOURCE_ROOTS:\n",
    "        files += glob.glob(str(root / \"**\" / \"*.md\"), recursive=True)\n",
    "        files += glob.glob(str(root / \"**\" / \"*.txt\"), recursive=True)\n",
    "    return [Path(f) for f in files]\n",
    "\n",
    "def auto_seed_if_empty():\n",
    "    paths = list_sources()\n",
    "    if paths: \n",
    "        return\n",
    "    seed = SOURCE_ROOTS[0] / \"cnt_seed.md\"\n",
    "    seed.parent.mkdir(parents=True, exist_ok=True)\n",
    "    seed.write_text(\n",
    "        \"# CNT Seed\\\\n\\\\n\"\n",
    "        \"Hypothesis: Certain glyph–field pairings lower entropy drift.\\\\n\"\n",
    "        \"Test: Re-run θ metrics on EEG segments with glyph overlay vs baseline.\\\\n\"\n",
    "        \"Expected: Δθ > 0 with CI > 95% for overlay.\\\\n\"\n",
    "        \"Falsifier: No uplift or negative drift after 1k permutations.\\\\n\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "# ---------- INDEX & RESIDUALS ----------\n",
    "def build_index(df):\n",
    "    if df.empty: \n",
    "        return None, None, None\n",
    "    vec = TfidfVectorizer(max_features=6000, ngram_range=(1,2))\n",
    "    X = vec.fit_transform(df[\"text\"]).astype(np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "    # robust rank\n",
    "    nmax = max(2, min(n_samples - 1, n_features - 1, 128))\n",
    "    svd = TruncatedSVD(n_components=nmax, random_state=42)\n",
    "    Xd = svd.fit_transform(X)\n",
    "    Xr = svd.inverse_transform(Xd)\n",
    "    resid = np.linalg.norm(X.toarray() - Xr, axis=1)\n",
    "    return vec, X, resid\n",
    "\n",
    "# ---------- CLUSTERS & GRAPH ----------\n",
    "def cluster_labels(X, k=6):\n",
    "    if X is None: \n",
    "        return None\n",
    "    k = max(2, min(k, X.shape[0]-1))\n",
    "    km = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "    return km.fit_predict(X.toarray())\n",
    "\n",
    "def build_graph(df, lbl):\n",
    "    \"\"\"Robust graph builder using regex tokenization (no pandas extractall).\"\"\"\n",
    "    G = nx.Graph()\n",
    "    for i, row in df.reset_index().iterrows():\n",
    "        G.add_node(\n",
    "            i,\n",
    "            path=row[\"path\"],\n",
    "            title=os.path.basename(row[\"path\"]),\n",
    "            cluster=int(lbl[i]) if lbl is not None else -1\n",
    "        )\n",
    "    pattern = re.compile(r\"\\\\b([A-Z][A-Za-z0-9_]{3,})\\\\b\")\n",
    "    caps_by_row = [set(pattern.findall(t if isinstance(t, str) else \"\")) for t in df[\"text\"].tolist()]\n",
    "    N = len(df)\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            overlap = len(caps_by_row[i] & caps_by_row[j])\n",
    "            same_cluster = (lbl is not None and lbl[i] == lbl[j])\n",
    "            if same_cluster or overlap >= 2:\n",
    "                G.add_edge(i, j, w=(1 + overlap))\n",
    "    return G\n",
    "\n",
    "# ---------- SCORES ----------\n",
    "def score_reflexive(df, resid, G):\n",
    "    if df is None or len(df)==0:\n",
    "        return dict(clarity=0, novelty=0, coherence=0, falsifiability=0, total=0)\n",
    "    clarity = 1.0 - np.mean([min(len(t),10000)/10000 for t in df[\"text\"].tolist()])\n",
    "    novelty = float(np.mean(resid)/(np.std(resid)+1e-6))\n",
    "    coherence = nx.average_clustering(G) if G.number_of_nodes()>1 else 0.0\n",
    "    falsifiability = float(np.mean([t.lower().count(\"test\")+t.lower().count(\"predict\") for t in df[\"text\"]]))/10.0\n",
    "    clarity = np.clip(clarity,0,1); novelty = np.clip(novelty/1.5,0,1)\n",
    "    coherence = np.clip(coherence,0,1); falsifiability = np.clip(falsifiability,0,1)\n",
    "    total = float(np.mean([clarity,novelty,coherence,falsifiability]))\n",
    "    return dict(clarity=float(clarity), novelty=float(novelty),\n",
    "                coherence=float(coherence), falsifiability=float(falsifiability),\n",
    "                total=float(total))\n",
    "\n",
    "# ---------- SURFACING / UPDATES ----------\n",
    "def surface_candidates(df, resid, top=5):\n",
    "    idx = np.argsort(resid)[::-1][:min(top, len(resid))]\n",
    "    picks=[]\n",
    "    for i in idx:\n",
    "        snippet=re.sub(r\"\\\\s+\",\" \",df.iloc[i][\"text\"])[:400]\n",
    "        picks.append(dict(path=df.iloc[i][\"path\"],resid=float(resid[i]),hint=snippet))\n",
    "    return picks\n",
    "\n",
    "def propose_updates(cands):\n",
    "    return [dict(\n",
    "        target=c[\"path\"],\n",
    "        content=(\n",
    "            f\"\\\\n\\\\n> CNT-Gloss ({now()}): Clarify hypothesis; add test recipe & falsifier.\\\\n\"\n",
    "            \"- Hypothesis: …\\\\n- Measurement: …\\\\n- Expected shift: …\\\\n- Falsifier: …\\\\n\"\n",
    "        )\n",
    "    ) for c in cands]\n",
    "\n",
    "def legality_gate(text): \n",
    "    bad=any(k in text for k in[\"ssn\",\"credit card\",\"weapon\",\"harm\"])\n",
    "    return not bad\n",
    "\n",
    "def confab_gate(text):\n",
    "    t=text.lower(); return (\"hypothesis\" in t and \"falsifier\" in t)\n",
    "\n",
    "def apply_updates(updates):\n",
    "    accepted=[]\n",
    "    for u in updates:\n",
    "        try:\n",
    "            if not (legality_gate(u[\"content\"]) and confab_gate(u[\"content\"])): \n",
    "                continue\n",
    "            p=Path(u[\"target\"])\n",
    "            p.write_text(p.read_text(encoding=\"utf-8\",errors=\"ignore\")+u[\"content\"],encoding=\"utf-8\")\n",
    "            accepted.append(u)\n",
    "        except Exception: \n",
    "            pass\n",
    "    return accepted\n",
    "\n",
    "# ---------- STATE / LOG ----------\n",
    "def write_state(score,meta):\n",
    "    ENGINE_ROOT.mkdir(parents=True, exist_ok=True)\n",
    "    try:\n",
    "        import yaml\n",
    "        Path(STATE_FILE).write_text(\n",
    "            yaml.safe_dump(dict(updated=now(),score=score,meta=meta),sort_keys=False),\n",
    "            encoding=\"utf-8\"\n",
    "        )\n",
    "    except Exception:\n",
    "        Path(STATE_FILE).write_text(json.dumps(dict(updated=now(),score=score,meta=meta),indent=2),encoding=\"utf-8\")\n",
    "\n",
    "def log_event(kind,payload):\n",
    "    Path(RUNLOG_FILE).parent.mkdir(parents=True, exist_ok=True)\n",
    "    with Path(RUNLOG_FILE).open(\"a\",encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(dict(ts=now(),kind=kind,**payload))+\"\\\\n\")\n",
    "\n",
    "# ---------- MAIN CYCLE ----------\n",
    "def run_cycle():\n",
    "    auto_seed_if_empty()\n",
    "    paths=list_sources()\n",
    "    df=pd.DataFrame([dict(path=str(p),text=p.read_text(encoding=\"utf-8\",errors=\"ignore\")) for p in paths])\n",
    "    if df.empty:\n",
    "        log_event(\"empty\",{\"roots\":[str(r) for r in SOURCE_ROOTS]})\n",
    "        return {\"empty\":True,\"roots\":[str(r) for r in SOURCE_ROOTS]}\n",
    "    vec,X,resid=build_index(df)\n",
    "    labels=cluster_labels(X)\n",
    "    G=build_graph(df,labels)\n",
    "    score=score_reflexive(df,resid,G)\n",
    "    cands=surface_candidates(df,resid,top=5)\n",
    "    accepted=apply_updates(propose_updates(cands))\n",
    "    write_state(score,dict(docs=len(df),accepted=len(accepted)))\n",
    "    pd.DataFrame(cands).to_csv(OUT_DIR/f\"hidden_truths_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\",index=False)\n",
    "    log_event(\"cycle\",dict(score=score,proposed=len(cands),accepted=len(accepted)))\n",
    "    return dict(score=score,proposed=len(cands),accepted=len(accepted),hidden=cands[:3])\n",
    "\n",
    "# ---------- EXECUTE (one or pulsed) ----------\n",
    "def run_pulsed(pulse_minutes: int):\n",
    "    \"\"\"Run forever with a sleep between cycles.\"\"\"\n",
    "    assert pulse_minutes > 0\n",
    "    print(f\"[CNT Engine] Pulsed mode every {pulse_minutes} min — CTRL+C to stop.\")\n",
    "    while True:\n",
    "        res = run_cycle()\n",
    "        print(json.dumps(res, indent=2))\n",
    "        time.sleep(pulse_minutes * 60)\n",
    "\n",
    "# Run now\n",
    "if PULSE_MIN and PULSE_MIN > 0:\n",
    "    run_pulsed(PULSE_MIN)\n",
    "else:\n",
    "    result = run_cycle()\n",
    "    print(json.dumps(result, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9154192e-f6d1-4ee1-bb96-4748d5f592db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Falsifiability: attach a runnable test stub per proposal ----\n",
    "def attach_test_stub(text: str, target_path: str):\n",
    "    \"\"\"Append a lightweight, runnable test recipe block.\"\"\"\n",
    "    stem = Path(target_path).stem.replace(\" \", \"_\")\n",
    "    return (\n",
    "        text +\n",
    "        \"\\n\\n```cnt-test\\n\"\n",
    "        f\"name: test_{stem}\\n\"\n",
    "        \"inputs: []\\n\"\n",
    "        \"recipe:\\n\"\n",
    "        \"  - step: load_data\\n\"\n",
    "        \"    path: <fill_me>\\n\"\n",
    "        \"  - step: compute_metric\\n\"\n",
    "        \"    code: <python or pseudo>\\n\"\n",
    "        \"  - step: assert\\n\"\n",
    "        \"    expect: <delta_theta> > 0 and p < 0.05\\n\"\n",
    "        \"```\"\n",
    "    )\n",
    "\n",
    "def propose_updates(cands):\n",
    "    updates = []\n",
    "    for c in cands:\n",
    "        gloss = (\n",
    "            f\"\\n\\n> CNT-Gloss ({now()}): Clarify hypothesis; add test recipe & falsifier.\\n\"\n",
    "            \"- Hypothesis: …\\n- Measurement: …\\n- Expected shift: …\\n- Falsifier: …\\n\"\n",
    "        )\n",
    "        content = attach_test_stub(gloss, c[\"path\"])\n",
    "        updates.append(dict(target=c[\"path\"], content=content))\n",
    "    return updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ab5cd2aa-df26-4769-b5c1-f861926932d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Minimal test runner: scans for ```cnt-test``` blocks and counts runnable specs ----\n",
    "TEST_PATTERN = re.compile(r\"```cnt-test(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def count_runnable_tests(df):\n",
    "    cnt = 0\n",
    "    for txt in df[\"text\"].tolist():\n",
    "        for m in TEST_PATTERN.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            # consider it 'runnable' if it names a test and has an 'assert' line\n",
    "            if \"name:\" in body and \"assert\" in body:\n",
    "                cnt += 1\n",
    "    return cnt\n",
    "\n",
    "def score_reflexive(df, resid, G):\n",
    "    if df is None or len(df)==0:\n",
    "        return dict(clarity=0, novelty=0, coherence=0, falsifiability=0, total=0)\n",
    "    clarity = 1.0 - np.mean([min(len(t),10000)/10000 for t in df[\"text\"].tolist()])\n",
    "    novelty = float(np.mean(resid)/(np.std(resid)+1e-6))\n",
    "    coherence = nx.average_clustering(G) if G.number_of_nodes()>1 else 0.0\n",
    "    # old proxy + runnable tests bonus\n",
    "    fals_proxy = float(np.mean([t.lower().count(\"test\")+t.lower().count(\"predict\") for t in df[\"text\"]]))/10.0\n",
    "    runnable = count_runnable_tests(df)\n",
    "    falsifiability = np.clip(fals_proxy + min(0.5, 0.05 * runnable), 0, 1)\n",
    "    clarity = np.clip(clarity,0,1); novelty = np.clip(novelty/1.5,0,1)\n",
    "    coherence = np.clip(coherence,0,1)\n",
    "    total = float(np.mean([clarity,novelty,coherence,falsifiability]))\n",
    "    return dict(clarity=float(clarity), novelty=float(novelty),\n",
    "                coherence=float(coherence), falsifiability=float(falsifiability),\n",
    "                total=float(total))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11f02297-1d06-474f-9347-eaf1e7237cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_graph(df, lbl):\n",
    "    G = nx.Graph()\n",
    "    for i, row in df.reset_index().iterrows():\n",
    "        G.add_node(\n",
    "            i,\n",
    "            path=row[\"path\"],\n",
    "            title=os.path.basename(row[\"path\"]),\n",
    "            cluster=int(lbl[i]) if lbl is not None else -1\n",
    "        )\n",
    "    pattern = re.compile(r\"\\b([A-Z][A-Za-z0-9_]{4,})\\b\")  # require 4+ chars\n",
    "    caps_by_row = [set(pattern.findall(t if isinstance(t, str) else \"\")) for t in df[\"text\"].tolist()]\n",
    "\n",
    "    N = len(df)\n",
    "    for i in range(N):\n",
    "        for j in range(i+1, N):\n",
    "            # cap token set sizes to avoid huge titles dominating\n",
    "            si = set(list(caps_by_row[i])[:50])\n",
    "            sj = set(list(caps_by_row[j])[:50])\n",
    "            overlap = len(si & sj)\n",
    "            same_cluster = (lbl is not None and lbl[i] == lbl[j])\n",
    "            if same_cluster or overlap >= 3:   # require ≥3 shared tokens\n",
    "                G.add_edge(i, j, w=(1 + overlap))\n",
    "    return G\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "45966097-0d35-47c3-a5c9-7f1ae4f8d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "def build_index(df):\n",
    "    if df.empty:\n",
    "        return None, None, None\n",
    "    vec = TfidfVectorizer(max_features=8000, ngram_range=(1,2))\n",
    "    X = vec.fit_transform(df[\"text\"]).astype(np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "    nmax = max(2, min(n_samples - 1, n_features - 1, 256))\n",
    "    svd = TruncatedSVD(n_components=nmax, random_state=42)\n",
    "    Xd = svd.fit_transform(X)  # low-dim representation\n",
    "\n",
    "    # anomaly score (higher = more novel)\n",
    "    iso = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n",
    "    iso.fit(Xd)\n",
    "    iso_score = -iso.score_samples(Xd)  # invert: larger -> more anomalous\n",
    "\n",
    "    # blend with recon residual for stability\n",
    "    Xr = svd.inverse_transform(Xd)\n",
    "    resid = np.linalg.norm(X.toarray() - Xr, axis=1)\n",
    "    resid = (resid - resid.min()) / (resid.ptp() + 1e-9)\n",
    "    novel = 0.6 * iso_score / (iso_score.max() + 1e-9) + 0.4 * resid\n",
    "    return vec, X, novel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cdcad562-8139-4a77-8f9c-1d5b2aa9d5d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "`ptp` was removed from the ndarray class in NumPy 2.0. Use np.ptp(arr, ...) instead.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      3\u001b[39m os.environ[\u001b[33m\"\u001b[39m\u001b[33mCNT_LAB_DIR\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mE:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mCNT\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# run a single pass\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m res = \u001b[43mrun_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mjson\u001b[39;00m; \u001b[38;5;28mprint\u001b[39m(json.dumps(res, indent=\u001b[32m2\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 186\u001b[39m, in \u001b[36mrun_cycle\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    184\u001b[39m     log_event(\u001b[33m\"\u001b[39m\u001b[33mempty\u001b[39m\u001b[33m\"\u001b[39m,{\u001b[33m\"\u001b[39m\u001b[33mroots\u001b[39m\u001b[33m\"\u001b[39m:[\u001b[38;5;28mstr\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m SOURCE_ROOTS]})\n\u001b[32m    185\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\u001b[33m\"\u001b[39m\u001b[33mempty\u001b[39m\u001b[33m\"\u001b[39m:\u001b[38;5;28;01mTrue\u001b[39;00m,\u001b[33m\"\u001b[39m\u001b[33mroots\u001b[39m\u001b[33m\"\u001b[39m:[\u001b[38;5;28mstr\u001b[39m(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m SOURCE_ROOTS]}\n\u001b[32m--> \u001b[39m\u001b[32m186\u001b[39m vec,X,resid=\u001b[43mbuild_index\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    187\u001b[39m labels=cluster_labels(X)\n\u001b[32m    188\u001b[39m G=build_graph(df,labels)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 21\u001b[39m, in \u001b[36mbuild_index\u001b[39m\u001b[34m(df)\u001b[39m\n\u001b[32m     19\u001b[39m Xr = svd.inverse_transform(Xd)\n\u001b[32m     20\u001b[39m resid = np.linalg.norm(X.toarray() - Xr, axis=\u001b[32m1\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m21\u001b[39m resid = (resid - resid.min()) / (\u001b[43mresid\u001b[49m\u001b[43m.\u001b[49m\u001b[43mptp\u001b[49m() + \u001b[32m1e-9\u001b[39m)\n\u001b[32m     22\u001b[39m novel = \u001b[32m0.6\u001b[39m * iso_score / (iso_score.max() + \u001b[32m1e-9\u001b[39m) + \u001b[32m0.4\u001b[39m * resid\n\u001b[32m     23\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m vec, X, novel\n",
      "\u001b[31mAttributeError\u001b[39m: `ptp` was removed from the ndarray class in NumPy 2.0. Use np.ptp(arr, ...) instead."
     ]
    }
   ],
   "source": [
    "# make sure the lab root is set inside the kernel\n",
    "import os\n",
    "os.environ[\"CNT_LAB_DIR\"] = r\"E:\\CNT\"\n",
    "\n",
    "# run a single pass\n",
    "res = run_cycle()\n",
    "import json; print(json.dumps(res, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "845df84a-2786-4ff0-9965-a1fa236c531f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>resid</th>\n",
       "      <th>hint</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>0.000002</td>\n",
       "      <td># Gauge-Restored Agents (GRA) v0.3\\n**Contract...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>== CNT Correlates Audit (Fused) ==\\nTimestamp:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>== CNT Correlates Audit ==\\nTimestamp: 2025101...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>\\nCNT – 3I/ATLAS All-8 Mega Pack (v1.1)\\n=====...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>== CNT One-Signal — Unified Verdict (v3.3) ==\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path     resid  \\\n",
       "0        E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md  0.000002   \n",
       "1  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...  0.000002   \n",
       "2  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...  0.000002   \n",
       "3  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  0.000002   \n",
       "4  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...  0.000002   \n",
       "\n",
       "                                                hint  \n",
       "0  # Gauge-Restored Agents (GRA) v0.3\\n**Contract...  \n",
       "1  == CNT Correlates Audit (Fused) ==\\nTimestamp:...  \n",
       "2  == CNT Correlates Audit ==\\nTimestamp: 2025101...  \n",
       "3  \\nCNT – 3I/ATLAS All-8 Mega Pack (v1.1)\\n=====...  \n",
       "4  == CNT One-Signal — Unified Verdict (v3.3) ==\\...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "out_dir = Path(r\"E:\\CNT\\artifacts\\cnt_engine_megacell\\out\")\n",
    "latest = sorted(out_dir.glob(\"hidden_truths_*.csv\"))[-1]\n",
    "pd.read_csv(latest).head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7942464e-f0c8-4b09-8869-124b577569c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "updated: '2025-10-26T21:18:00Z'\n",
      "score:\n",
      "  clarity: 0.8306804878048781\n",
      "  novelty: 0.6710594495137533\n",
      "  coherence: 1.0\n",
      "  falsifiability: 0.024390243902439025\n",
      "  total: 0.6315325453052676\n",
      "meta:\n",
      "  docs: 41\n",
      "  accepted: 5\n",
      "\n",
      "\n",
      "--- last 5 log lines ---\n",
      "{\"ts\": \"2025-10-26T21:18:00Z\", \"kind\": \"cycle\", \"score\": {\"clarity\": 0.8306804878048781, \"novelty\": 0.6710594495137533, \"coherence\": 1.0, \"falsifiability\": 0.024390243902439025, \"total\": 0.6315325453052676}, \"proposed\": 5, \"accepted\": 5}\\n\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "state = Path(r\"E:\\CNT\\artifacts\\cnt_engine_megacell\\CNT_STATE.yaml\").read_text(encoding=\"utf-8\")\n",
    "print(state)\n",
    "\n",
    "log_path = Path(r\"E:\\CNT\\artifacts\\cnt_engine_megacell\\runlog.jsonl\")\n",
    "print(\"\\n--- last 5 log lines ---\")\n",
    "print(\"\".join(log_path.read_text(encoding=\"utf-8\").splitlines(True)[-5:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44177d58-5fd0-472c-93a5-1de63d0dccf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import IsolationForest\n",
    "import numpy as np\n",
    "\n",
    "def build_index(df):\n",
    "    if df.empty:\n",
    "        return None, None, None\n",
    "\n",
    "    vec = TfidfVectorizer(max_features=8000, ngram_range=(1,2))\n",
    "    X = vec.fit_transform(df[\"text\"]).astype(np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "\n",
    "    # Low-dim representation via SVD\n",
    "    nmax = max(2, min(n_samples - 1, n_features - 1, 256))\n",
    "    svd = TruncatedSVD(n_components=nmax, random_state=42)\n",
    "    Xd = svd.fit_transform(X)\n",
    "\n",
    "    # Anomaly score (higher = more novel)\n",
    "    iso = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n",
    "    iso.fit(Xd)\n",
    "    iso_score = -iso.score_samples(Xd)  # invert so larger => more anomalous\n",
    "\n",
    "    # Reconstruction residual for stability\n",
    "    Xr = svd.inverse_transform(Xd)\n",
    "    resid = np.linalg.norm(X.toarray() - Xr, axis=1)\n",
    "\n",
    "    # Robust min-max with NumPy 2.x\n",
    "    resid_range = np.ptp(resid)  # <-- np.ptp replaces ndarray.ptp()\n",
    "    resid_norm = (resid - resid.min()) / (resid_range + 1e-9)\n",
    "\n",
    "    iso_max = float(np.max(iso_score))\n",
    "    iso_norm = iso_score / (iso_max + 1e-9)\n",
    "\n",
    "    # Blend\n",
    "    novel = 0.6 * iso_norm + 0.4 * resid_norm\n",
    "    return vec, X, novel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ae55501-4a57-4c75-8bb4-22857b87b88d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8287048780487805,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.901545744228671,\n",
      "    \"falsifiability\": 0.036585365853658534,\n",
      "    \"total\": 0.6917089970327776\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 5,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9543617030772218,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) ==\\nTimestamp: 20251015-164130\\n\\n- Cooling logs: 8\\n- Cosmo triage tables: 1\\n- EEG laterality tables: 2\\n- Kuramoto/Ising summaries: 0\\n- Kuramoto dispersion CSVs: 0\\n- Gray-Scott edge images: 1\\n- Scanned logs/text: 50\\n- Glyph label tables: 0\\n\\n== Results ==\\n[GREY] Cooling: Temp oscillation amplitude predicts clock stability\\n  Need logs with GPU temp + GPU clock columns.\\n \"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_3i_atlas_all8_20251024-035650Z_044afb63\\\\README.txt\",\n",
      "      \"resid\": 0.9256719836458015,\n",
      "      \"hint\": \"\\nCNT \\u2013 3I/ATLAS All-8 Mega Pack (v1.1)\\n======================================\\nStamp: 20251024-035650Z\\n\\nFolders:\\n- data/: placeholder CSVs (replace with real spectra, lightcurves, solar wind, observer geometry).\\n- out/tables/: machine-readable outputs.\\n- out/figs/: basic figures.\\n- out/logs/: JSON logs for \\u0398* alarm, observer-ring vector, nickel hypotheses, origin fingerprint.\\n\\nWhat\\u2019s implemented (m\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8640618360668539,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55)\\n\\n**Registered (UTC):** 2025-10-18T04:09:49.361036Z\\n**Persistence:** k = 3\\n**Hazard target:** ~25% positives (bounds 15\\u201335%)\\n\\n## Top Segments (by AUC then Precision@\\u0398*)\\n                                               segment   N  W      AUC  Precision@Theta*  Lead@Hit(steps)  Lead@Any(steps)\\n                       cnt_cooling_log_20251015_121543  7\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res = run_cycle()\n",
    "import json; print(json.dumps(res, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c103e268-781d-4c34-87d1-8e91bf2274ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def _yaml_block(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False) + \"```\\n\"\n",
    "\n",
    "def _make_test_for(target_path: str):\n",
    "    stem = Path(target_path).stem.replace(\" \", \"_\").lower()\n",
    "    # default pattern: CSV threshold test — fill real path later\n",
    "    return dict(\n",
    "        name=f\"test_{stem}\",\n",
    "        type=\"csv_threshold\",\n",
    "        path=\"<fill_me_csv_path>\",        # e.g., E:\\\\CNT\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\metrics.csv\n",
    "        column=\"<metric_column>\",         # e.g., \"delta_theta\" or \"precision_at_theta\"\n",
    "        op=\">\",                           # one of: >, >=, <, <=\n",
    "        value=0.0,                        # set your threshold\n",
    "        agg=\"mean\"                        # mean | median | any | all\n",
    "    )\n",
    "\n",
    "def propose_updates(cands):\n",
    "    updates = []\n",
    "    for c in cands:\n",
    "        gloss = (\n",
    "            f\"\\n\\n> CNT-Gloss ({now()}): Clarify hypothesis; add test recipe & falsifier.\\n\"\n",
    "            \"- Hypothesis: …\\n- Measurement: …\\n- Expected shift: …\\n- Falsifier: …\\n\\n\"\n",
    "        )\n",
    "        test = _make_test_for(c[\"path\"])\n",
    "        content = gloss + _yaml_block(test)\n",
    "        updates.append(dict(target=c[\"path\"], content=content))\n",
    "    return updates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79064a85-06ab-4727-9aed-5bfd9fbc4f3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1105436143.py, line 76)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[13]\u001b[39m\u001b[32m, line 76\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mrows.append(dict(doc=path, name=name, type=ttype, pass=int(ok), info=info))\u001b[39m\n                                                      ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def _parse_cnt_tests(text: str):\n",
    "    tests = []\n",
    "    for m in TEST_FENCE.finditer(text or \"\"):\n",
    "        body = m.group(\"body\")\n",
    "        try:\n",
    "            t = yaml.safe_load(body)  # expect dict\n",
    "            if isinstance(t, dict) and \"type\" in t:\n",
    "                tests.append(t)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return tests\n",
    "\n",
    "def _csv_threshold_test(t: dict) -> tuple[bool,str]:\n",
    "    \"\"\"\n",
    "    Schema:\n",
    "      type: csv_threshold\n",
    "      path: E:\\\\CNT\\\\...\\\\file.csv\n",
    "      column: metric_column\n",
    "      op: > | >= | < | <=\n",
    "      value: float\n",
    "      agg: mean | median | any | all\n",
    "    \"\"\"\n",
    "    path = t.get(\"path\")\n",
    "    col  = t.get(\"column\")\n",
    "    op   = t.get(\"op\", \">\")\n",
    "    val  = float(t.get(\"value\", 0.0))\n",
    "    agg  = t.get(\"agg\", \"mean\").lower()\n",
    "\n",
    "    if not path or \"<fill_me\" in str(path) or not Path(path).exists():\n",
    "        return False, \"missing_path\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if col not in df.columns:\n",
    "        return False, \"missing_column\"\n",
    "\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return False, \"no_numeric\"\n",
    "\n",
    "    if agg == \"mean\":   metric = float(s.mean())\n",
    "    elif agg == \"median\": metric = float(s.median())\n",
    "    elif agg == \"any\":    metric = bool((s > val).any()) if op in [\">\", \">=\"] else bool((s < val).any())\n",
    "    elif agg == \"all\":    metric = bool((s > val).all()) if op in [\">\", \">=\"] else bool((s < val).all())\n",
    "    else:                 metric = float(s.mean())\n",
    "\n",
    "    def _cmp(a, b, op):\n",
    "        return {\">\": a>b, \">=\": a>=b, \"<\": a<b, \"<=\": a<=b}[op]\n",
    "\n",
    "    # boolean aggregates are already True/False\n",
    "    if isinstance(metric, bool):\n",
    "        ok = metric\n",
    "        info = f\"agg={agg}\"\n",
    "    else:\n",
    "        ok = _cmp(metric, val, op)\n",
    "        info = f\"{agg}({col})={metric:.6f} {op} {val}\"\n",
    "\n",
    "    return bool(ok), info\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    passed = 0\n",
    "    total  = 0\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            total += 1\n",
    "            name = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info = _csv_threshold_test(t)\n",
    "            else:\n",
    "                ok, info = False, f\"unknown_type:{ttype}\"\n",
    "            rows.append(dict(doc=path, name=name, type=ttype, pass=int(ok), info=info))\n",
    "            if ok: passed += 1\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    if not out_df.empty:\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "    return passed, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "492bb26f-6b3c-4c41-8574-3d3fdabd4721",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_cycle():\n",
    "    auto_seed_if_empty()\n",
    "    paths=list_sources()\n",
    "    df=pd.DataFrame([dict(path=str(p),text=p.read_text(encoding=\"utf-8\",errors=\"ignore\")) for p in paths])\n",
    "    if df.empty:\n",
    "        log_event(\"empty\",{\"roots\":[str(r) for r in SOURCE_ROOTS]})\n",
    "        return {\"empty\":True,\"roots\":[str(r) for r in SOURCE_ROOTS]}\n",
    "\n",
    "    vec,X,resid=build_index(df)\n",
    "    labels=cluster_labels(X)\n",
    "    G=build_graph(df,labels)\n",
    "\n",
    "    # --- run tests (NEW) ---\n",
    "    tests_csv = OUT_DIR / f\"tests_report_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    "    passed, total = run_cnt_tests_on_df(df, tests_csv)\n",
    "\n",
    "    # score\n",
    "    score=score_reflexive(df,resid,G)\n",
    "\n",
    "    # small falsifiability boost from actual passes (not just stubs)\n",
    "    if total > 0:\n",
    "        frac = passed / max(1,total)\n",
    "        score[\"falsifiability\"] = float(np.clip(score[\"falsifiability\"] + min(0.5, 0.25*frac), 0, 1))\n",
    "        score[\"total\"] = float(np.mean([score[k] for k in [\"clarity\",\"novelty\",\"coherence\",\"falsifiability\"]]))\n",
    "\n",
    "    cands=surface_candidates(df,resid,top=5)\n",
    "    accepted=apply_updates(propose_updates(cands))\n",
    "    write_state(score,dict(docs=len(df),accepted=len(accepted),tests_total=total,tests_passed=passed))\n",
    "    pd.DataFrame(cands).to_csv(OUT_DIR/f\"hidden_truths_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\",index=False)\n",
    "    log_event(\"cycle\",dict(score=score,proposed=len(cands),accepted=len(accepted),tests_total=total,tests_passed=passed))\n",
    "    return dict(score=score,proposed=len(cands),accepted=len(accepted),tests_total=total,tests_passed=passed,hidden=cands[:3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bfbbf187-09ca-44a1-9c45-87a222680cbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def _parse_cnt_tests(text: str):\n",
    "    tests = []\n",
    "    for m in TEST_FENCE.finditer(text or \"\"):\n",
    "        body = m.group(\"body\")\n",
    "        try:\n",
    "            t = yaml.safe_load(body)  # expect dict\n",
    "            if isinstance(t, dict) and \"type\" in t:\n",
    "                tests.append(t)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return tests\n",
    "\n",
    "def _csv_threshold_test(t: dict) -> tuple[bool, str]:\n",
    "    \"\"\"\n",
    "    Schema:\n",
    "      type: csv_threshold\n",
    "      path: E:\\\\CNT\\\\...\\\\file.csv\n",
    "      column: metric_column\n",
    "      op: > | >= | < | <=\n",
    "      value: float\n",
    "      agg: mean | median | any | all\n",
    "    \"\"\"\n",
    "    path = t.get(\"path\")\n",
    "    col  = t.get(\"column\")\n",
    "    op   = t.get(\"op\", \">\")\n",
    "    val  = float(t.get(\"value\", 0.0))\n",
    "    agg  = t.get(\"agg\", \"mean\").lower()\n",
    "\n",
    "    if not path or \"<fill_me\" in str(path) or not Path(path).exists():\n",
    "        return False, \"missing_path\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    if col not in df.columns:\n",
    "        return False, \"missing_column\"\n",
    "\n",
    "    s = pd.to_numeric(df[col], errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return False, \"no_numeric\"\n",
    "\n",
    "    if agg == \"mean\":      metric = float(s.mean())\n",
    "    elif agg == \"median\":  metric = float(s.median())\n",
    "    elif agg == \"any\":     metric = bool((s > val).any()) if op in [\">\", \">=\"] else bool((s < val).any())\n",
    "    elif agg == \"all\":     metric = bool((s > val).all()) if op in [\">\", \">=\"] else bool((s < val).all())\n",
    "    else:                  metric = float(s.mean())\n",
    "\n",
    "    def _cmp(a, b, op):\n",
    "        return {\">\": a>b, \">=\": a>=b, \"<\": a<b, \"<=\": a<=b}[op]\n",
    "\n",
    "    if isinstance(metric, bool):         # boolean aggregates already resolved\n",
    "        ok = metric\n",
    "        info = f\"agg={agg}\"\n",
    "    else:\n",
    "        ok = _cmp(metric, val, op)\n",
    "        info = f\"{agg}({col})={metric:.6f} {op} {val}\"\n",
    "\n",
    "    return bool(ok), info\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    passed = 0\n",
    "    total  = 0\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\", \"\"))\n",
    "        for t in tests:\n",
    "            total += 1\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\", \"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info = _csv_threshold_test(t)\n",
    "            else:\n",
    "                ok, info = False, f\"unknown_type:{ttype}\"\n",
    "            rows.append(dict(doc=path, name=name, type=ttype, passed=int(ok), info=info))\n",
    "            if ok:\n",
    "                passed += 1\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    if not out_df.empty:\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "    return passed, total\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fed3cf24-9c69-4541-b601-012a153f3093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8241658536585366,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8755071287711174,\n",
      "    \"falsifiability\": 0.3231707317073171,\n",
      "    \"total\": 0.7557109285342427\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 5,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9125069984119454,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) ==\\nTimestamp: 20251015-164130\\n\\n- Cooling logs: 8\\n- Cosmo triage tables: 1\\n- EEG laterality tables: 2\\n- Kuramoto/Ising summaries: 0\\n- Kuramoto dispersion CSVs: 0\\n- Gray-Scott edge images: 1\\n- Scanned logs/text: 50\\n- Glyph label tables: 0\\n\\n== Results ==\\n[GREY] Cooling: Temp oscillation amplitude predicts clock stability\\n  Need logs with GPU temp + GPU clock columns.\\n \"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.891309430343602,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55)\\n\\n**Registered (UTC):** 2025-10-18T04:09:49.361036Z\\n**Persistence:** k = 3\\n**Hazard target:** ~25% positives (bounds 15\\u201335%)\\n\\n## Top Segments (by AUC then Precision@\\u0398*)\\n                                               segment   N  W      AUC  Precision@Theta*  Lead@Hit(steps)  Lead@Any(steps)\\n                       cnt_cooling_log_20251015_121543  7\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.891309430343602,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55)\\n\\n**Registered (UTC):** 2025-10-18T04:09:49.361036Z\\n**Persistence:** k = 3\\n**Hazard target:** ~25% positives (bounds 15\\u201335%)\\n\\n## Top Segments (by AUC then Precision@\\u0398*)\\n                                               segment   N  W      AUC  Precision@Theta*  Lead@Hit(steps)  Lead@Any(steps)\\n                       cnt_cooling_log_20251015_121543  7\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "res = run_cycle()\n",
    "import json; print(json.dumps(res, indent=2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fab95f5c-1e27-4260-adc4-6a241fe589a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found CSVs: 17\n",
      " - E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_cooling_segments_20251017-235217.csv cols: ['segment', 'n', 'w', 'auc', 'precision@theta*', 'lead@hit(steps)'] …\n",
      " - E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_holdout_results.csv cols: ['segment', 'path', 'sha256', 'n', 'w', 'auc'] …\n",
      " - E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_summary_20251017-233201.csv cols: ['dataset', 'kind', 'heuristic_event', 'n', 'window', 'theta*'] …\n",
      " - E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_summary_v2_1_20251017-234015.csv cols: ['dataset', 'kind', 'heuristic_event', 'n', 'window', 'theta*'] …\n",
      " - E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_summary_v2_2_20251017-234543.csv cols: ['dataset', 'kind', 'heuristic_event', 'n', 'window', 'theta*'] …\n",
      "\n",
      "Using: E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_cooling_segments_20251017-235217.csv column: auc\n",
      "Appended test to: E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\n",
      "\n",
      "=== Engine result ===\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8200170731707317,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8687911124424754,\n",
      "    \"falsifiability\": 0.3670731707317073,\n",
      "    \"total\": 0.7639703390862287\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 5,\n",
      "  \"tests_total\": 6,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9546850071051641,\n",
      "      \"hint\": \"== CNT Correlates Audit ==\\nTimestamp: 20251015-163558\\n\\n- Cooling logs: 8\\n- Cosmo triage tables: 1\\n- EEG laterality tables: 2\\n- Kuramoto/Ising summaries: 0\\n- Gray-Scott edge images: 1\\n- Scanned logs/text: 50\\n- Glyph label tables: 0\\n\\n== Results ==\\n[GREY] Cooling: Temp oscillation amplitude predicts clock stability\\n  Need logs with GPU temp + GPU clock columns.\\n  Add both fields to your CSVs.\\n\\n[GREY]\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.942243395850821,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) ==\\nRun dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\n\\nV1 (classic):\\n - REWS beats baselines in: 0.0% of systems\\n - Median lead time @ \\u0398(q=0.85): 4137 samples\\n\\nV2 (chaos-aware, precision\\u22650.50 target):\\n - Systems achieving precision floor (or fallback): 0.0%\\n - Median lead time @ \\u0398\\u2082: 3623 samples\\n\\n-- V1 AUCs --\\n    syst\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-222741\\\\summary.txt\",\n",
      "      \"resid\": 0.9266133693013501,\n",
      "      \"hint\": \"== CNT One-Signal \\u2014 Unified Verdict (v3.3) ==\\nRun dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-222741\\n\\nV1 (classic):\\n - REWS beats strongest baseline in: 11.1% of systems\\n - Median lead @ \\u0398(q=0.85): 708 samples\\n\\nV2 (EMA + 5-of-7 hysteresis, precision\\u22650.55 target):\\n - Systems meeting floor (or fallback): 33.3%\\n - Median lead @ \\u0398\\u2082: 487 samples\\n\\n-- V1 AUCs --\\n                \"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest test report: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-173320.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\ewb_re...</td>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_column</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 doc  \\\n",
       "0  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\ewb_re...   \n",
       "1  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "2  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "3  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "4  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "5  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "\n",
       "                                         name           type  passed  \\\n",
       "0                            test_ewb_results  csv_threshold       0   \n",
       "1                            test_ewb_results  csv_threshold       0   \n",
       "2                            test_ewb_results  csv_threshold       0   \n",
       "3                          test_ewb_precision  csv_threshold       0   \n",
       "4  test_cnt_correlates_report_20251015-164130  csv_threshold       0   \n",
       "5                                 test_readme  csv_threshold       0   \n",
       "\n",
       "             info  \n",
       "0    missing_path  \n",
       "1    missing_path  \n",
       "2    missing_path  \n",
       "3  missing_column  \n",
       "4    missing_path  \n",
       "5    missing_path  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import yaml, re\n",
    "\n",
    "LAB = Path(r\"E:\\CNT\")\n",
    "DOCS = [\n",
    "    LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\",\n",
    "    LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\ewb_results.md\",\n",
    "]\n",
    "\n",
    "# 1) Find a real metrics CSV to test against\n",
    "candidates = []\n",
    "for p in (LAB / r\"notebooks\\archive\\cnt_ewb_theta2\").rglob(\"*.csv\"):\n",
    "    try:\n",
    "        cols = pd.read_csv(p, nrows=1).columns.str.lower().tolist()\n",
    "        candidates.append((p, cols))\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "print(\"Found CSVs:\", len(candidates))\n",
    "for p, cols in candidates[:5]:\n",
    "    print(\" -\", p, \"cols:\", cols[:6], \"…\")\n",
    "\n",
    "# Heuristics: pick first csv with a familiar metric column\n",
    "PREFERRED = [\"precision_at_theta\", \"precision@theta*\", \"auc\", \"delta_theta\", \"lead_at_hit\", \"lead_at_any\"]\n",
    "chosen = None\n",
    "chosen_col = None\n",
    "for p, cols in candidates:\n",
    "    for c in cols:\n",
    "        if any(k == c or k in c for k in PREFERRED):\n",
    "            chosen, chosen_col = p, c\n",
    "            break\n",
    "    if chosen: break\n",
    "\n",
    "if not chosen:\n",
    "    raise SystemExit(\"No suitable CSV/column found. Open one CSV, tell me the column to test, and re-run.\")\n",
    "\n",
    "print(\"\\nUsing:\", chosen, \"column:\", chosen_col)\n",
    "\n",
    "# 2) Compose a concrete cnt-test block\n",
    "test_spec = dict(\n",
    "    name=\"test_ewb_precision\",\n",
    "    type=\"csv_threshold\",\n",
    "    path=str(chosen),\n",
    "    column=chosen_col,\n",
    "    op=\">\",          # adjust if you want \"<\" style tests\n",
    "    value=0.55,      # set your threshold\n",
    "    agg=\"mean\"       # mean | median | any | all\n",
    ")\n",
    "fenced = \"```cnt-test\\n\" + yaml.safe_dump(test_spec, sort_keys=False) + \"```\\n\"\n",
    "\n",
    "# 3) Append the test to the first existing doc\n",
    "target = next((p for p in DOCS if p.exists()), None)\n",
    "if target is None:\n",
    "    # fallback: create a small doc to hold the test\n",
    "    target = LAB / r\"notes\\ewb_auto_test.md\"\n",
    "    target.parent.mkdir(parents=True, exist_ok=True)\n",
    "    target.write_text(\"# EWB Auto Test Holder\\n\", encoding=\"utf-8\")\n",
    "\n",
    "txt = target.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "# avoid duplicating the same test\n",
    "if \"```cnt-test\" not in txt or test_spec[\"name\"] not in txt:\n",
    "    target.write_text(txt + \"\\n\\n> Auto-added test\\n\" + fenced, encoding=\"utf-8\")\n",
    "    print(\"Appended test to:\", target)\n",
    "else:\n",
    "    print(\"Test already present in:\", target)\n",
    "\n",
    "# 4) Run a cycle and show results\n",
    "res = run_cycle()\n",
    "import json\n",
    "print(\"\\n=== Engine result ===\")\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# Show latest tests report CSV\n",
    "from glob import glob\n",
    "out_dir = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reports = sorted(glob(str(out_dir / \"tests_report_*.csv\")))\n",
    "if reports:\n",
    "    rep = Path(reports[-1])\n",
    "    print(\"\\nLatest test report:\", rep)\n",
    "    display(pd.read_csv(rep).tail(10))\n",
    "else:\n",
    "    print(\"No tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d3a17b3b-de17-4454-a3b2-26c35ab1c001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8163487804878049,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8836725961244575,\n",
      "    \"falsifiability\": 0.9036585365853659,\n",
      "    \"total\": 0.9009199782994071\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 5,\n",
      "  \"tests_total\": 1,\n",
      "  \"tests_passed\": 1,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.982124482187421,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9750494189181739,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\gold_verification_summary.md\",\n",
      "      \"resid\": 0.8175883327288183,\n",
      "      \"hint\": \"# CNT Techno-Anomaly \\u2014 Gold Verification - RA=209.236537, Dec=-1.289745: old_votes=4, new_votes_at_source=nan, W1\\u2212W2=0.349, W2\\u2212W3=3.768, SIMBAD=\\u2713 () - RA=210.910946, Dec=-1.291592: old_votes=4, new_votes_at_source=nan, W1\\u2212W2=-0.068, W2\\u2212W3=2.526, SIMBAD=\\u2014 () \"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest test report: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-173758.csv\n",
      "Reasons:\n",
      " reason\n",
      "missing_path    10\n",
      "ok               1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.604440 &gt; 0.55</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>missing_path</td>\n",
       "      <td>missing_path</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "1   E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "2   E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "3   E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "4   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "5   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "6   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "7   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "1                             test_ewb_results  csv_threshold      0       0   \n",
       "2                             test_ewb_results  csv_threshold      0       0   \n",
       "3                           test_ewb_precision  csv_threshold      1       1   \n",
       "4   test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "5   test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "6   test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "7                                  test_readme  csv_threshold      0       0   \n",
       "8                                  test_readme  csv_threshold      0       0   \n",
       "9                                 test_summary  csv_threshold      0       0   \n",
       "10                                test_summary  csv_threshold      0       0   \n",
       "\n",
       "                         info        reason  \n",
       "1                missing_path  missing_path  \n",
       "2                missing_path  missing_path  \n",
       "3   mean(AUC)=0.604440 > 0.55            ok  \n",
       "4                missing_path  missing_path  \n",
       "5                missing_path  missing_path  \n",
       "6                missing_path  missing_path  \n",
       "7                missing_path  missing_path  \n",
       "8                missing_path  missing_path  \n",
       "9                missing_path  missing_path  \n",
       "10               missing_path  missing_path  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# ================================\n",
    "# CNT Engine — ONE MEGA CELL (SSD)\n",
    "# Root: E:\\CNT  (override via CNT_LAB_DIR)\n",
    "# ================================\n",
    "\n",
    "import os, json, glob, re, time\n",
    "from datetime import datetime, timezone\n",
    "from pathlib import Path, PureWindowsPath\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import yaml\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "LAB_ROOT  = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "SOURCE_ROOTS = [\n",
    "    LAB_ROOT / \"notes\",\n",
    "    LAB_ROOT / \"artifacts\" / \"cnt_scroll\",\n",
    "    LAB_ROOT / \"artifacts\" / \"cnt_codex\",\n",
    "    LAB_ROOT / \"notebooks\",\n",
    "]\n",
    "ENGINE_ROOT = LAB_ROOT / \"artifacts\" / \"cnt_engine_megacell\"\n",
    "OUT_DIR     = ENGINE_ROOT / \"out\"\n",
    "STATE_FILE  = ENGINE_ROOT / \"CNT_STATE.yaml\"\n",
    "RUNLOG_FILE = ENGINE_ROOT / \"runlog.jsonl\"\n",
    "\n",
    "PULSE_MIN       = 0   # 0 = run once; >0 = pulse every N minutes\n",
    "AUTO_APPEND_EWB = True  # try to auto-append one valid EWB test if none are valid yet\n",
    "\n",
    "for p in [ENGINE_ROOT, OUT_DIR, *SOURCE_ROOTS]:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def now(): return datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- DISCOVER / SEED ----------\n",
    "def list_sources():\n",
    "    files = []\n",
    "    for root in SOURCE_ROOTS:\n",
    "        files += glob.glob(str(root / \"**\" / \"*.md\"), recursive=True)\n",
    "        files += glob.glob(str(root / \"**\" / \"*.txt\"), recursive=True)\n",
    "    return [Path(f) for f in files]\n",
    "\n",
    "def auto_seed_if_empty():\n",
    "    paths = list_sources()\n",
    "    if paths: return\n",
    "    seed = SOURCE_ROOTS[0] / \"cnt_seed.md\"\n",
    "    seed.parent.mkdir(parents=True, exist_ok=True)\n",
    "    seed.write_text(\n",
    "        \"# CNT Seed\\n\\n\"\n",
    "        \"Hypothesis: Certain glyph–field pairings lower entropy drift.\\n\"\n",
    "        \"Test: Re-run θ metrics on EEG segments with glyph overlay vs baseline.\\n\"\n",
    "        \"Expected: Δθ > 0 with CI > 95% for overlay.\\n\"\n",
    "        \"Falsifier: No uplift or negative drift after 1k permutations.\\n\",\n",
    "        encoding=\"utf-8\"\n",
    "    )\n",
    "\n",
    "# ---------- INDEX & NOVELTY ----------\n",
    "def build_index(df):\n",
    "    if df.empty: return None, None, None\n",
    "    vec = TfidfVectorizer(max_features=8000, ngram_range=(1,2))\n",
    "    X = vec.fit_transform(df[\"text\"]).astype(np.float32)\n",
    "    n_samples, n_features = X.shape\n",
    "    nmax = max(2, min(n_samples - 1, n_features - 1, 256))\n",
    "    svd = TruncatedSVD(n_components=nmax, random_state=42)\n",
    "    Xd = svd.fit_transform(X)\n",
    "    # anomaly\n",
    "    iso = IsolationForest(n_estimators=200, contamination=\"auto\", random_state=42)\n",
    "    iso.fit(Xd)\n",
    "    iso_score = -iso.score_samples(Xd)  # larger = more novel\n",
    "    # recon residual\n",
    "    Xr = svd.inverse_transform(Xd)\n",
    "    resid = np.linalg.norm(X.toarray() - Xr, axis=1)\n",
    "    resid_norm = (resid - resid.min()) / (np.ptp(resid) + 1e-9)\n",
    "    iso_norm   = iso_score / (float(np.max(iso_score)) + 1e-9)\n",
    "    novel = 0.6*iso_norm + 0.4*resid_norm\n",
    "    return vec, X, novel\n",
    "\n",
    "# ---------- GRAPH (damped to avoid coherence=1.0) ----------\n",
    "def build_graph(df, lbl):\n",
    "    G = nx.Graph()\n",
    "    for i, row in df.reset_index().iterrows():\n",
    "        G.add_node(i, path=row[\"path\"], title=os.path.basename(row[\"path\"]),\n",
    "                   cluster=int(lbl[i]) if lbl is not None else -1)\n",
    "    pattern = re.compile(r\"\\b([A-Z][A-Za-z0-9_]{4,})\\b\")\n",
    "    caps_by_row = [set(pattern.findall(t if isinstance(t, str) else \"\")) for t in df[\"text\"].tolist()]\n",
    "    N = len(df)\n",
    "    for i in range(N):\n",
    "        si = set(list(caps_by_row[i])[:30])\n",
    "        for j in range(i+1, N):\n",
    "            sj = set(list(caps_by_row[j])[:30])\n",
    "            overlap = len(si & sj)\n",
    "            same_cluster = (lbl is not None and lbl[i] == lbl[j])\n",
    "            if same_cluster or overlap >= 4:\n",
    "                G.add_edge(i, j, w=(1 + overlap))\n",
    "    return G\n",
    "\n",
    "def cluster_labels(X, k=6):\n",
    "    if X is None: return None\n",
    "    k = max(2, min(k, X.shape[0]-1))\n",
    "    km = KMeans(n_clusters=k, n_init=5, random_state=42)\n",
    "    return km.fit_predict(X.toarray())\n",
    "\n",
    "# ---------- SCORE ----------\n",
    "def score_reflexive(df, novel, G, runnable_tests=0):\n",
    "    if df is None or len(df)==0:\n",
    "        return dict(clarity=0, novelty=0, coherence=0, falsifiability=0, total=0)\n",
    "    clarity = 1.0 - np.mean([min(len(t),10000)/10000 for t in df[\"text\"].tolist()])\n",
    "    novelty = float(np.mean(novel)/(np.std(novel)+1e-6))\n",
    "    coherence = nx.average_clustering(G) if G.number_of_nodes()>1 else 0.0\n",
    "    # proxy + runnable bonus\n",
    "    fals_proxy = float(np.mean([t.lower().count(\"test\")+t.lower().count(\"predict\") for t in df[\"text\"]]))/10.0\n",
    "    falsifiability = np.clip(fals_proxy + min(0.5, 0.05*max(0, runnable_tests)), 0, 1)\n",
    "    clarity = float(np.clip(clarity,0,1))\n",
    "    novelty = float(np.clip(novelty/1.5,0,1))\n",
    "    coherence = float(np.clip(coherence,0,1))\n",
    "    total = float(np.mean([clarity,novelty,coherence,falsifiability]))\n",
    "    return dict(clarity=clarity, novelty=novelty, coherence=coherence, falsifiability=falsifiability, total=total)\n",
    "\n",
    "# ---------- HIDDEN TRUTHS ----------\n",
    "def surface_candidates(df, novel, top=5):\n",
    "    idx = np.argsort(novel)[::-1][:min(top, len(novel))]\n",
    "    picks=[]\n",
    "    for i in idx:\n",
    "        snippet=re.sub(r\"\\s+\",\" \",df.iloc[i][\"text\"])[:400]\n",
    "        picks.append(dict(path=df.iloc[i][\"path\"],resid=float(novel[i]),hint=snippet))\n",
    "    return picks\n",
    "\n",
    "# ---------- TESTS (YAML fenced) ----------\n",
    "TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def _parse_cnt_tests(text: str):\n",
    "    tests = []\n",
    "    for m in TEST_FENCE.finditer(text or \"\"):\n",
    "        body = m.group(\"body\")\n",
    "        try:\n",
    "            t = yaml.safe_load(body)\n",
    "            if isinstance(t, dict) and \"type\" in t:\n",
    "                tests.append(t)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return tests\n",
    "\n",
    "def _normalize_key(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
    "\n",
    "def _match_column(df: pd.DataFrame, requested: str):\n",
    "    want = _normalize_key(requested or \"\")\n",
    "    if not want: return None\n",
    "    norm_map = {_normalize_key(c): c for c in df.columns}\n",
    "    return norm_map.get(want)\n",
    "\n",
    "def _csv_threshold_test(t: dict):\n",
    "    \"\"\"\n",
    "    returns (ok, info, reason) ; reason in {\"ok\",\"missing_path\",\"missing_column\",\"no_numeric\",\"invalid_type\"}\n",
    "    \"\"\"\n",
    "    path = t.get(\"path\")\n",
    "    col  = t.get(\"column\")\n",
    "    op   = str(t.get(\"op\", \">\"))\n",
    "    try:    val = float(t.get(\"value\", 0.0))\n",
    "    except: val = 0.0\n",
    "    agg  = str(t.get(\"agg\", \"mean\")).lower()\n",
    "\n",
    "    if not path or \"<fill_me\" in str(path) or not Path(path).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "    df = pd.read_csv(path)\n",
    "    col_actual = _match_column(df, col)\n",
    "    if col_actual is None:\n",
    "        return False, \"missing_column\", \"missing_column\"\n",
    "    s = pd.to_numeric(df[col_actual], errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return False, \"no_numeric\", \"no_numeric\"\n",
    "\n",
    "    if   agg == \"mean\":   metric = float(s.mean())\n",
    "    elif agg == \"median\": metric = float(s.median())\n",
    "    elif agg == \"any\":    metric = bool((s > val).any()) if op in [\">\", \">=\"] else bool((s < val).any())\n",
    "    elif agg == \"all\":    metric = bool((s > val).all()) if op in [\">\", \">=\"] else bool((s < val).all())\n",
    "    else:                 metric = float(s.mean())\n",
    "\n",
    "    def _cmp(a,b,op): return {\">\":a>b, \">=\":a>=b, \"<\":a<b, \"<=\":a<=b}.get(op, a>b)\n",
    "\n",
    "    if isinstance(metric, bool):\n",
    "        ok = metric; info = f\"{agg}({col_actual})→{ok}\"\n",
    "    else:\n",
    "        ok = _cmp(metric, val, op); info = f\"{agg}({col_actual})={metric:.6f} {op} {val}\"\n",
    "    return bool(ok), info, \"ok\"\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    passed = total = invalid = 0\n",
    "    runnable = 0\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        runnable += len(tests)\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            if reason == \"ok\":\n",
    "                total += 1\n",
    "                if ok: passed += 1\n",
    "            else:\n",
    "                invalid += 1\n",
    "            rows.append(dict(doc=path, name=name, type=ttype, valid=int(reason==\"ok\"),\n",
    "                             passed=int(ok), info=info, reason=reason))\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    if not out_df.empty:\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "    return passed, total, runnable\n",
    "\n",
    "# ---------- PROPOSALS (write YAML tests) ----------\n",
    "def _yaml_block(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False) + \"```\\n\"\n",
    "\n",
    "def _make_test_for(target_path: str):\n",
    "    stem = Path(target_path).stem.replace(\" \", \"_\").lower()\n",
    "    return dict(\n",
    "        name=f\"test_{stem}\",\n",
    "        type=\"csv_threshold\",\n",
    "        path=\"<fill_me_csv_path>\",\n",
    "        column=\"<metric_column>\",\n",
    "        op=\">\",\n",
    "        value=0.0,\n",
    "        agg=\"mean\"\n",
    "    )\n",
    "\n",
    "def propose_updates(cands):\n",
    "    updates = []\n",
    "    for c in cands:\n",
    "        gloss = (\n",
    "            f\"\\n\\n> CNT-Gloss ({now()}): Clarify hypothesis; add test recipe & falsifier.\\n\"\n",
    "            \"- Hypothesis: …\\n- Measurement: …\\n- Expected shift: …\\n- Falsifier: …\\n\\n\"\n",
    "        )\n",
    "        test = _make_test_for(c[\"path\"])\n",
    "        content = gloss + _yaml_block(test)\n",
    "        updates.append(dict(target=c[\"path\"], content=content))\n",
    "    return updates\n",
    "\n",
    "def legality_gate(text): \n",
    "    bad=any(k in text for k in[\"ssn\",\"credit card\",\"weapon\",\"harm\"])\n",
    "    return not bad\n",
    "\n",
    "def confab_gate(text):\n",
    "    t=text.lower(); return (\"hypothesis\" in t and \"falsifier\" in t)\n",
    "\n",
    "def apply_updates(updates):\n",
    "    accepted=[]\n",
    "    for u in updates:\n",
    "        try:\n",
    "            if not (legality_gate(u[\"content\"]) and confab_gate(u[\"content\"])): \n",
    "                continue\n",
    "            p=Path(u[\"target\"])\n",
    "            p.write_text(p.read_text(encoding=\"utf-8\",errors=\"ignore\")+u[\"content\"],encoding=\"utf-8\")\n",
    "            accepted.append(u)\n",
    "        except Exception:\n",
    "            pass\n",
    "    return accepted\n",
    "\n",
    "def write_state(score, meta):\n",
    "    try:\n",
    "        STATE_FILE.write_text(yaml.safe_dump(dict(updated=now(),score=score,meta=meta),sort_keys=False), encoding=\"utf-8\")\n",
    "    except Exception:\n",
    "        STATE_FILE.write_text(json.dumps(dict(updated=now(),score=score,meta=meta), indent=2), encoding=\"utf-8\")\n",
    "\n",
    "def log_event(kind, payload):\n",
    "    with RUNLOG_FILE.open(\"a\", encoding=\"utf-8\") as f:\n",
    "        f.write(json.dumps(dict(ts=now(), kind=kind, **payload)) + \"\\n\")\n",
    "\n",
    "# ---------- AUTO-APPEND ONE VALID EWB TEST (optional) ----------\n",
    "def _auto_append_ewb_test_if_needed():\n",
    "    # Find candidate EWB CSV\n",
    "    base = LAB_ROOT / r\"notebooks\\archive\\cnt_ewb_theta2\"\n",
    "    if not base.exists(): return False\n",
    "    cands = []\n",
    "    for p in base.rglob(\"*.csv\"):\n",
    "        try:\n",
    "            cols = pd.read_csv(p, nrows=1).columns.tolist()\n",
    "            cands.append((p, cols))\n",
    "        except Exception:\n",
    "            pass\n",
    "    if not cands: return False\n",
    "    # pick with AUC/precision if present\n",
    "    chosen = None; chosen_col = None\n",
    "    wants = [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\"]\n",
    "    for p, cols in cands:\n",
    "        nm = {_normalize_key(c): c for c in cols}\n",
    "        for w in wants:\n",
    "            if _normalize_key(w) in nm:\n",
    "                chosen, chosen_col = p, nm[_normalize_key(w)]; break\n",
    "        if chosen: break\n",
    "    if not chosen:\n",
    "        chosen, cols = cands[0]; chosen_col = cols[0]\n",
    "    # target doc\n",
    "    doc = LAB_ROOT / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "    doc.parent.mkdir(parents=True, exist_ok=True)\n",
    "    txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\") if doc.exists() else \"# EWB Results\\n\"\n",
    "    if \"test_ewb_auto\" in txt: return False\n",
    "    # pick threshold = 90% of mean to likely pass\n",
    "    df = pd.read_csv(chosen)\n",
    "    s = pd.to_numeric(df[chosen_col], errors=\"coerce\").dropna()\n",
    "    if s.empty: return False\n",
    "    thr = float(round(0.9*float(s.mean()), 6))\n",
    "    spec = dict(name=\"test_ewb_auto\", type=\"csv_threshold\", path=str(PureWindowsPath(chosen)),\n",
    "                column=chosen_col, op=\">\", value=thr, agg=\"mean\")\n",
    "    block = \"```cnt-test\\n\" + yaml.safe_dump(spec, sort_keys=False) + \"```\"\n",
    "    doc.write_text(txt + \"\\n\\n> Auto-added EWB test\\n\" + block + \"\\n\", encoding=\"utf-8\")\n",
    "    return True\n",
    "\n",
    "# ---------- CYCLE ----------\n",
    "def run_cycle():\n",
    "    auto_seed_if_empty()\n",
    "    paths = list_sources()\n",
    "    df = pd.DataFrame([dict(path=str(p), text=p.read_text(encoding=\"utf-8\", errors=\"ignore\")) for p in paths])\n",
    "    if df.empty:\n",
    "        log_event(\"empty\", {\"roots\":[str(r) for r in SOURCE_ROOTS]})\n",
    "        return {\"empty\": True, \"roots\":[str(r) for r in SOURCE_ROOTS]}\n",
    "\n",
    "    # Optional: try to append a valid EWB test if none valid yet\n",
    "    if AUTO_APPEND_EWB:\n",
    "        _auto_append_ewb_test_if_needed()\n",
    "\n",
    "    vec, X, novel = build_index(df)\n",
    "    labels = cluster_labels(X)\n",
    "    G = build_graph(df, labels)\n",
    "\n",
    "    tests_csv = OUT_DIR / f\"tests_report_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\"\n",
    "    passed, total, runnable = run_cnt_tests_on_df(df, tests_csv)\n",
    "\n",
    "    score = score_reflexive(df, novel, G, runnable_tests=runnable)\n",
    "    if total > 0:\n",
    "        frac = passed / max(1, total)\n",
    "        score[\"falsifiability\"] = float(np.clip(score[\"falsifiability\"] + min(0.5, 0.25*frac), 0, 1))\n",
    "        score[\"total\"] = float(np.mean([score[k] for k in [\"clarity\",\"novelty\",\"coherence\",\"falsifiability\"]]))\n",
    "\n",
    "    cands = surface_candidates(df, novel, top=5)\n",
    "    accepted = apply_updates(propose_updates(cands))\n",
    "\n",
    "    write_state(score, dict(docs=len(df), accepted=len(accepted), tests_total=total, tests_passed=passed))\n",
    "    pd.DataFrame(cands).to_csv(OUT_DIR / f\"hidden_truths_{datetime.now().strftime('%Y%m%d-%H%M%S')}.csv\", index=False)\n",
    "    log_event(\"cycle\", dict(score=score, proposed=len(cands), accepted=len(accepted), tests_total=total, tests_passed=passed))\n",
    "    return dict(score=score, proposed=len(cands), accepted=len(accepted),\n",
    "                tests_total=total, tests_passed=passed, hidden=cands[:3])\n",
    "\n",
    "def run_pulsed(pulse_minutes: int):\n",
    "    assert pulse_minutes > 0\n",
    "    print(f\"[CNT Engine] Pulsing every {pulse_minutes} min — CTRL+C to stop.\")\n",
    "    while True:\n",
    "        res = run_cycle()\n",
    "        print(json.dumps(res, indent=2))\n",
    "        time.sleep(pulse_minutes*60)\n",
    "\n",
    "# ---------- EXECUTE ----------\n",
    "if PULSE_MIN and PULSE_MIN > 0:\n",
    "    run_pulsed(PULSE_MIN)\n",
    "else:\n",
    "    res = run_cycle()\n",
    "    print(json.dumps(res, indent=2))\n",
    "    # show latest tests report if exists\n",
    "    try:\n",
    "        from glob import glob\n",
    "        reps = sorted(glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "        if reps:\n",
    "            rep = reps[-1]\n",
    "            print(\"\\nLatest test report:\", rep)\n",
    "            df_rep = pd.read_csv(rep)\n",
    "            print(\"Reasons:\\n\", df_rep[\"reason\"].value_counts(dropna=False))\n",
    "            try:\n",
    "                from IPython.display import display\n",
    "                display(df_rep.tail(10))\n",
    "            except Exception:\n",
    "                print(df_rep.tail(10).to_string(index=False))\n",
    "        else:\n",
    "            print(\"\\nNo tests_report_* yet.\")\n",
    "    except Exception as e:\n",
    "        print(\"Report check error:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d2096765-a40d-4248-840a-eda636cbdef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[heal] updated_docs=12, fixed_blocks=15\n",
      "run_cycle not found here. Execute your mega cell first, then re-run this fixer. 'function' object has no attribute 'glob'\n"
     ]
    }
   ],
   "source": [
    "# === CNT test auto-heal (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import re, yaml, pandas as pd, numpy as np, os, json\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "\n",
    "# reuse engine globals if present; else define\n",
    "try:\n",
    "    SOURCE_ROOTS\n",
    "except NameError:\n",
    "    SOURCE_ROOTS = [\n",
    "        LAB / \"notes\",\n",
    "        LAB / \"artifacts\" / \"cnt_scroll\",\n",
    "        LAB / \"artifacts\" / \"cnt_codex\",\n",
    "        LAB / \"notebooks\",\n",
    "    ]\n",
    "\n",
    "TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower())\n",
    "\n",
    "# 1) index all CSVs + their columns (normalized)\n",
    "csv_index = []  # list of (path, {norm_col->actual})\n",
    "for root in [LAB]:\n",
    "    for p in root.rglob(\"*.csv\"):\n",
    "        try:\n",
    "            cols = pd.read_csv(p, nrows=1).columns.tolist()\n",
    "            csv_index.append((p, {_norm(c): c for c in cols}))\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "def _find_csv_for_column(norm_col: str, near: Path|None=None):\n",
    "    # pick a csv that has this column; prefer same subtree as 'near'\n",
    "    best = None; best_score = -1\n",
    "    for p, cmap in csv_index:\n",
    "        if norm_col in cmap:\n",
    "            score = 0\n",
    "            if near:\n",
    "                # score by common prefix depth with doc folder\n",
    "                a, b = near.resolve().parts, p.resolve().parts\n",
    "                k = 0\n",
    "                for x,y in zip(a,b):\n",
    "                    if x==y: k+=1\n",
    "                    else: break\n",
    "                score = k\n",
    "            if score > best_score:\n",
    "                best = (p, cmap[norm_col])\n",
    "                best_score = score\n",
    "    return best  # (csv_path, actual_col) or None\n",
    "\n",
    "# 2) heuristic thresholds by column semantics\n",
    "def suggest_rule(col_name: str, series: pd.Series):\n",
    "    c = _norm(col_name)\n",
    "    x = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if x.empty:\n",
    "        return dict(op=\">\", value=0.0, agg=\"mean\")\n",
    "    mean = float(x.mean()); med = float(x.median())\n",
    "    if \"auc\" in c or \"precision\" in c:\n",
    "        # classification metrics in [0,1]\n",
    "        thr = round(max(0.0, min(0.95, 0.9*mean)), 6)\n",
    "        return dict(op=\">\", value=thr, agg=\"mean\")\n",
    "    if \"delta\" in c or \"uplift\" in c or \"theta\" in c:\n",
    "        # positive shift desired\n",
    "        thr = round(max(0.0, 0.25*mean), 6)\n",
    "        return dict(op=\">\", value=thr, agg=\"mean\")\n",
    "    if \"lead\" in c:\n",
    "        # want positive lead time\n",
    "        thr = 0.0\n",
    "        return dict(op=\">\", value=thr, agg=\"median\")\n",
    "    # fallback: prove it's not degenerate\n",
    "    thr = round(0.9*mean, 6)\n",
    "    return dict(op=\">\", value=thr, agg=\"mean\")\n",
    "\n",
    "# 3) scan docs, repair cnt-test blocks with missing path/column, write back\n",
    "updated_docs = 0\n",
    "fixed_blocks = 0\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        changes = []\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or spec.get(\"type\") != \"csv_threshold\":\n",
    "                continue\n",
    "\n",
    "            path_ok = spec.get(\"path\") and \"<fill_me\" not in str(spec[\"path\"]) and Path(str(spec[\"path\"])).exists()\n",
    "            col_ok  = bool(spec.get(\"column\"))\n",
    "\n",
    "            if path_ok and col_ok:\n",
    "                continue  # already valid\n",
    "\n",
    "            # choose desired column\n",
    "            want = _norm(spec.get(\"column\",\"\"))\n",
    "            # if no requested column, pick desirable ones\n",
    "            candidates = [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"deltatheta\",\"lead@hit\",\"leadathit\",\"theta*\",\"theta\"]\n",
    "            if not want:\n",
    "                want = None\n",
    "                for w in candidates:\n",
    "                    want = _norm(w)\n",
    "                    break\n",
    "\n",
    "            # try to find a CSV close-by with matching column\n",
    "            found = None\n",
    "            if want:\n",
    "                found = _find_csv_for_column(want, near=doc.parent)\n",
    "\n",
    "            if not found:\n",
    "                # last resort: just pick a CSV and first numeric column\n",
    "                if csv_index:\n",
    "                    cp, cmap = csv_index[0]\n",
    "                    # select some numeric column\n",
    "                    df_head = pd.read_csv(cp, nrows=50)\n",
    "                    num_cols = [c for c in df_head.columns if pd.to_numeric(df_head[c], errors=\"coerce\").notna().any()]\n",
    "                    if num_cols:\n",
    "                        found = (cp, num_cols[0])\n",
    "\n",
    "            if not found:\n",
    "                continue  # can't heal this block\n",
    "\n",
    "            csv_path, actual_col = found\n",
    "            df_full = pd.read_csv(csv_path)\n",
    "            rule = suggest_rule(actual_col, df_full[actual_col])\n",
    "\n",
    "            spec[\"path\"] = str(PureWindowsPath(csv_path))\n",
    "            spec[\"column\"] = actual_col\n",
    "            spec[\"op\"] = rule[\"op\"]\n",
    "            spec[\"value\"] = rule[\"value\"]\n",
    "            spec[\"agg\"] = rule[\"agg\"]\n",
    "\n",
    "            # re-fence\n",
    "            fenced = \"```cnt-test\\n\" + yaml.safe_dump(spec, sort_keys=False) + \"```\"\n",
    "            changes.append((m.span()[0], m.span()[1], fenced))\n",
    "\n",
    "        if changes:\n",
    "            # apply in reverse order (to keep indices stable)\n",
    "            new_txt = txt\n",
    "            for a,b,rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\")\n",
    "            updated_docs += 1\n",
    "            fixed_blocks += len(changes)\n",
    "\n",
    "print(f\"[heal] updated_docs={updated_docs}, fixed_blocks={fixed_blocks}\")\n",
    "\n",
    "# 4) optional: stop adding *new* draft tests every cycle (idempotent proposals)\n",
    "try:\n",
    "    old_fn = propose_updates\n",
    "    def propose_updates(cands):\n",
    "        ups=[]\n",
    "        for c in cands[:3]:  # limit sprawl\n",
    "            p=Path(c[\"path\"]); t=p.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            if \"```cnt-test\" in t: \n",
    "                continue  # skip if tests already present\n",
    "            # otherwise use the original proposal behavior\n",
    "            gloss = (\n",
    "                f\"\\n\\n> CNT-Gloss ({datetime.now(timezone.utc).strftime('%Y-%m-%dT%H:%M:%SZ')}): \"\n",
    "                \"Clarify hypothesis; add test recipe & falsifier.\\n\"\n",
    "                \"- Hypothesis: …\\n- Measurement: …\\n- Expected shift: …\\n- Falsifier: …\\n\\n\"\n",
    "            )\n",
    "            test = dict(name=f\"test_{Path(c['path']).stem.lower()}\", type=\"csv_threshold\",\n",
    "                        path=\"<fill_me_csv_path>\", column=\"<metric_column>\", op=\">\", value=0.0, agg=\"mean\")\n",
    "            ups.append(dict(target=c[\"path\"], content=gloss + \"```cnt-test\\n\" + yaml.safe_dump(test, sort_keys=False) + \"```\"))\n",
    "        return ups\n",
    "except NameError:\n",
    "    pass\n",
    "\n",
    "# 5) rerun engine once and show result\n",
    "try:\n",
    "    res = run_cycle()\n",
    "    print(json.dumps(res, indent=2))\n",
    "    # show latest report summary\n",
    "    from glob import glob\n",
    "    out_dir = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "    reps = sorted(glob(str(out_dir/\"tests_report_*.csv\")))\n",
    "    if reps:\n",
    "        rep = Path(reps[-1])\n",
    "        dfrep = pd.read_csv(rep)\n",
    "        print(\"\\nLatest:\", rep)\n",
    "        print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "        try:\n",
    "            from IPython.display import display\n",
    "            display(dfrep.tail(10))\n",
    "        except Exception:\n",
    "            print(dfrep.tail(10).to_string(index=False))\n",
    "except Exception as e:\n",
    "    print(\"run_cycle not found here. Execute your mega cell first, then re-run this fixer.\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2f590121-dce2-400f-81ec-655c4adf7941",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'function' object has no attribute 'glob'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[20]\u001b[39m\u001b[32m, line 23\u001b[39m\n\u001b[32m     20\u001b[39m     run_cycle = cnt_engine.run_cycle  \u001b[38;5;66;03m# pull into this cell's globals\u001b[39;00m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Run one engine cycle\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m res = \u001b[43mrun_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(res, indent=\u001b[32m2\u001b[39m))\n\u001b[32m     26\u001b[39m \u001b[38;5;66;03m# Show the latest tests report (valid/missing breakdown)\u001b[39;00m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 320\u001b[39m, in \u001b[36mrun_cycle\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    319\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrun_cycle\u001b[39m():\n\u001b[32m--> \u001b[39m\u001b[32m320\u001b[39m     \u001b[43mauto_seed_if_empty\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    321\u001b[39m     paths = list_sources()\n\u001b[32m    322\u001b[39m     df = pd.DataFrame([\u001b[38;5;28mdict\u001b[39m(path=\u001b[38;5;28mstr\u001b[39m(p), text=p.read_text(encoding=\u001b[33m\"\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m\"\u001b[39m, errors=\u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m)) \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m paths])\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mauto_seed_if_empty\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mauto_seed_if_empty\u001b[39m():\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m     paths = \u001b[43mlist_sources\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m paths: \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     52\u001b[39m     seed = SOURCE_ROOTS[\u001b[32m0\u001b[39m] / \u001b[33m\"\u001b[39m\u001b[33mcnt_seed.md\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 45\u001b[39m, in \u001b[36mlist_sources\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     43\u001b[39m files = []\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m root \u001b[38;5;129;01min\u001b[39;00m SOURCE_ROOTS:\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     files += \u001b[43mglob\u001b[49m\u001b[43m.\u001b[49m\u001b[43mglob\u001b[49m(\u001b[38;5;28mstr\u001b[39m(root / \u001b[33m\"\u001b[39m\u001b[33m**\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33m*.md\u001b[39m\u001b[33m\"\u001b[39m), recursive=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     46\u001b[39m     files += glob.glob(\u001b[38;5;28mstr\u001b[39m(root / \u001b[33m\"\u001b[39m\u001b[33m**\u001b[39m\u001b[33m\"\u001b[39m / \u001b[33m\"\u001b[39m\u001b[33m*.txt\u001b[39m\u001b[33m\"\u001b[39m), recursive=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m [Path(f) \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m files]\n",
      "\u001b[31mAttributeError\u001b[39m: 'function' object has no attribute 'glob'"
     ]
    }
   ],
   "source": [
    "# ===== CNT Engine — finalize & verify (single cell) =====\n",
    "import os, sys, json, importlib.util\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob as globmod  # << use module, not \"from glob import glob\"\n",
    "\n",
    "# Point to SSD lab\n",
    "os.environ[\"CNT_LAB_DIR\"] = r\"E:\\CNT\"\n",
    "LAB = Path(os.environ[\"CNT_LAB_DIR\"])\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "\n",
    "# Get run_cycle from current notebook OR from the SSD script if needed\n",
    "if \"run_cycle\" not in globals():\n",
    "    mod_path = LAB / \"cnt_engine_megacell.py\"\n",
    "    if not mod_path.exists():\n",
    "        raise RuntimeError(\"run_cycle not found. Run your Mega Cell once, or save it as E:\\\\CNT\\\\cnt_engine_megacell.py.\")\n",
    "    spec = importlib.util.spec_from_file_location(\"cnt_engine\", str(mod_path))\n",
    "    cnt_engine = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(cnt_engine)\n",
    "    run_cycle = cnt_engine.run_cycle  # pull into this cell's globals\n",
    "\n",
    "# Run one engine cycle\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# Show the latest tests report (valid/missing breakdown)\n",
    "reports = sorted(globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reports:\n",
    "    rep = reports[-1]\n",
    "    print(\"\\nLatest report:\", rep)\n",
    "    df = pd.read_csv(rep)\n",
    "    print(\"\\nReasons:\\n\", df[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df.tail(10))\n",
    "    except Exception:\n",
    "        print(df.tail(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "54df1300-496a-4235-8339-8a06b009df7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8111512195121952,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.92317951142802,\n",
      "    \"falsifiability\": 0.947560975609756,\n",
      "    \"total\": 0.9204729266374929\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 1,\n",
      "  \"tests_total\": 17,\n",
      "  \"tests_passed\": 17,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\gold_verification_summary.md\",\n",
      "      \"resid\": 0.9642741465358113,\n",
      "      \"hint\": \"# CNT Techno-Anomaly \\u2014 Gold Verification - RA=209.236537, Dec=-1.289745: old_votes=4, new_votes_at_source=nan, W1\\u2212W2=0.349, W2\\u2212W3=3.768, SIMBAD=\\u2713 () - RA=210.910946, Dec=-1.291592: old_votes=4, new_votes_at_source=nan, W1\\u2212W2=-0.068, W2\\u2212W3=2.526, SIMBAD=\\u2014 () > CNT-Gloss (2025-10-26T21:37:58Z): Clarify hypothesis; add test recipe & falsifier. - Hypothesis: \\u2026 - Measurement: \\u2026 - Expected shift: \\u2026 - Fa\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-222741\\\\summary.txt\",\n",
      "      \"resid\": 0.913679438329166,\n",
      "      \"hint\": \"== CNT One-Signal \\u2014 Unified Verdict (v3.3) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-222741 V1 (classic): - REWS beats strongest baseline in: 11.1% of systems - Median lead @ \\u0398(q=0.85): 708 samples V2 (EMA + 5-of-7 hysteresis, precision\\u22650.55 target): - Systems meeting floor (or fallback): 33.3% - Median lead @ \\u0398\\u2082: 487 samples -- V1 AUCs -- system AUC_REWS AUC_Var\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.8751263257329795,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest report: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-175127.csv\n",
      "reason\n",
      "ok    17\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "7   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "7   test_cnt_correlates_report_20251015-163558  csv_threshold      1       1   \n",
       "8   test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "9   test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "10  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "11                                 test_readme  csv_threshold      1       1   \n",
       "12                                 test_readme  csv_threshold      1       1   \n",
       "13                                test_summary  csv_threshold      1       1   \n",
       "14                                test_summary  csv_threshold      1       1   \n",
       "15                                test_summary  csv_threshold      1       1   \n",
       "16                                test_summary  csv_threshold      1       1   \n",
       "\n",
       "                              info reason  \n",
       "7   mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "8   mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "9   mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "10  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "11  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "12  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "13  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "14  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "15  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "16  mean(N_pairs)=30.000000 > 27.0     ok  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Fix 'function object has no attribute glob' + verify run ===\n",
    "import json, pandas as pd\n",
    "from pathlib import Path\n",
    "import glob as _globmod\n",
    "\n",
    "# 1) Restore 'glob' to the module (was shadowed by 'from glob import glob')\n",
    "glob = _globmod\n",
    "\n",
    "# 2) Make list_sources() robust forever (uses a local module import)\n",
    "try:\n",
    "    SOURCE_ROOTS\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Mega cell not loaded in this kernel yet. Run it once, then re-run this patch.\")\n",
    "\n",
    "def list_sources():\n",
    "    import glob as __glob      # local, guaranteed module\n",
    "    files = []\n",
    "    for root in SOURCE_ROOTS:\n",
    "        files += __glob.glob(str(root / \"**\" / \"*.md\"), recursive=True)\n",
    "        files += __glob.glob(str(root / \"**\" / \"*.txt\"), recursive=True)\n",
    "    return [Path(f) for f in files]\n",
    "\n",
    "# 3) Run a cycle and print result + latest tests report\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1])\n",
    "    df = pd.read_csv(rep)\n",
    "    print(\"\\nLatest report:\", rep)\n",
    "    print(df[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df.tail(10))\n",
    "    except Exception:\n",
    "        print(df.tail(10).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "21c124c2-d5c8-4c5a-b087-dedb096ce52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[gold] updated_docs=12, gold_tests=17\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8052682926829269,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9235444214640771,\n",
      "    \"falsifiability\": 0.9548780487804878,\n",
      "    \"total\": 0.920922690731873\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 17,\n",
      "  \"tests_passed\": 17,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9508920059741233,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.9270007351984821,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548\\\\summary.txt\",\n",
      "      \"resid\": 0.895229254864063,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-175444.csv\n",
      "reason\n",
      "ok          17\n",
      "non_gold     1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "8   test_cnt_correlates_report_20251015-163558  csv_threshold      1       1   \n",
       "9   test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "10  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "11  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "12                                 test_readme  csv_threshold      1       1   \n",
       "13                                 test_readme  csv_threshold      1       1   \n",
       "14                                test_summary  csv_threshold      1       1   \n",
       "15                                test_summary  csv_threshold      1       1   \n",
       "16                                test_summary  csv_threshold      1       1   \n",
       "17                                test_summary  csv_threshold      1       1   \n",
       "\n",
       "                              info reason  \n",
       "8   mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "9   mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "10  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "11  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "12  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "13  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "14  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "15  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "16  mean(N_pairs)=30.000000 > 27.0     ok  \n",
       "17  mean(N_pairs)=30.000000 > 27.0     ok  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === CNT GOLD FREEZE + STRICT MODE (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import os, re, yaml, pandas as pd, json, hashlib, glob as _globmod\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# 0) Require mega cell objects\n",
    "try:\n",
    "    TEST_FENCE, SOURCE_ROOTS\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run your Mega Cell once, then run this GOLD cell.\")\n",
    "\n",
    "# 1) Helpers\n",
    "def _file_sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        while True:\n",
    "            b = f.read(chunk)\n",
    "            if not b: break\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower())\n",
    "\n",
    "# 2) Promote all currently valid tests to GOLD (adds hash/rows/frozen_at)\n",
    "updated_docs = 0\n",
    "golded = 0\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        changes = []\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or spec.get(\"type\") != \"csv_threshold\":\n",
    "                continue\n",
    "            # already gold? keep but update metadata if missing\n",
    "            p = spec.get(\"path\")\n",
    "            if not p or \"<fill_me\" in str(p): \n",
    "                continue\n",
    "            pth = Path(p)\n",
    "            if not pth.exists():\n",
    "                continue\n",
    "            col = spec.get(\"column\")\n",
    "            try:\n",
    "                df = pd.read_csv(pth)\n",
    "            except Exception:\n",
    "                continue\n",
    "            # confirm column (case-insensitive)\n",
    "            cmap = {_norm(c): c for c in df.columns}\n",
    "            col_actual = cmap.get(_norm(col or \"\"), None)\n",
    "            if col_actual is None:\n",
    "                continue\n",
    "            # compute metadata\n",
    "            h = _file_sha256(pth)\n",
    "            nrows = int(len(df))\n",
    "            spec[\"column\"]    = col_actual\n",
    "            spec[\"gold\"]      = True\n",
    "            spec[\"frozen_at\"] = STAMP\n",
    "            spec[\"hash\"]      = h\n",
    "            spec[\"rows\"]      = nrows\n",
    "            # re-fence with GOLD spec\n",
    "            fenced = \"```cnt-test\\n\" + yaml.safe_dump(spec, sort_keys=False) + \"```\"\n",
    "            changes.append((m.span()[0], m.span()[1], fenced))\n",
    "            golded += 1\n",
    "        if changes:\n",
    "            new_txt = txt\n",
    "            for a,b,rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\")\n",
    "            updated_docs += 1\n",
    "\n",
    "print(f\"[gold] updated_docs={updated_docs}, gold_tests={golded}\")\n",
    "\n",
    "# 3) Patch the runner: count only GOLD tests, verify hash (STRICT)\n",
    "STRICT_GOLD_ONLY = True\n",
    "\n",
    "def _csv_threshold_test_strict(t: dict):\n",
    "    # Hash + shape check for GOLD, else reject if strict\n",
    "    if STRICT_GOLD_ONLY and not t.get(\"gold\", False):\n",
    "        return False, \"non_gold\", \"non_gold\"\n",
    "    path = t.get(\"path\")\n",
    "    if not path or not Path(path).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "    if STRICT_GOLD_ONLY and t.get(\"hash\"):\n",
    "        h_now = _file_sha256(Path(path))\n",
    "        if str(h_now) != str(t[\"hash\"]):\n",
    "            return False, f\"hash_mismatch({h_now[:8]}!= {str(t['hash'])[:8]})\", \"hash_mismatch\"\n",
    "    # delegate to normalized test\n",
    "    ok, info, reason = _csv_threshold_test(t)\n",
    "    return ok, info, reason\n",
    "\n",
    "# swap the runner to strict\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    passed = total = invalid = 0\n",
    "    runnable = 0\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        runnable += len(tests)\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                # strict path\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            if reason == \"ok\":\n",
    "                total += 1\n",
    "                if ok: passed += 1\n",
    "            else:\n",
    "                invalid += 1\n",
    "            rows.append(dict(doc=path, name=name, type=ttype, valid=int(reason==\"ok\"),\n",
    "                             passed=int(ok), info=info, reason=reason))\n",
    "    out_df = pd.DataFrame(rows)\n",
    "    if not out_df.empty:\n",
    "        out_df.to_csv(out_csv, index=False)\n",
    "    return passed, total, runnable\n",
    "\n",
    "# 4) Stop new test sprawl entirely (idempotent proposals)\n",
    "def propose_updates(cands):\n",
    "    ups=[]\n",
    "    for c in []:  # never add new stubs automatically in strict mode\n",
    "        pass\n",
    "    return ups\n",
    "\n",
    "# 5) Re-run engine once and show report\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1])\n",
    "    dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(10))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(10).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1165dcb1-cbe1-41f8-b83f-5c4c10ddec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[holdout] updated_docs=1, twins_added=2\n",
      "[manifest] rows=19  -> gold_manifest.csv, gold_manifest.yaml\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8036512195121951,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9235444214640771,\n",
      "    \"falsifiability\": 0.9383183568677792,\n",
      "    \"total\": 0.9163784994610128\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 19,\n",
      "  \"tests_passed\": 17,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_3i_atlas_all8_20251024-042112Z_539b05ee\\\\README.txt\",\n",
      "      \"resid\": 0.9685376805735942,\n",
      "      \"hint\": \" CNT \\u00d7 3I/ATLAS \\u2014 Upgraded All\\u20118 Pack ==================================== Stamp: 20251024-042112Z Includes: - WCS wavelength from FITS headers (CRVAL/CDELT/CRPIX) if spectrum_*.fits present. - Multi\\u2011feature GRA (CN/CH/C\\u2082 + custom lines) with solar\\u2011analog continuum normalization. - Plasma+Phase: coherence with FDR correction, plus phase (from xcorr peak mapped to f). - Observer\\u2011Ring Pro: if observ\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.967949011575336,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9131585056496372,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-175656.csv\n",
      "reason\n",
      "ok          19\n",
      "non_gold     1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>non_gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>ok</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "8         E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "18  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "19  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "8                                  test_readme  csv_threshold      0       0   \n",
       "9   test_cnt_correlates_report_20251015-163558  csv_threshold      1       1   \n",
       "10  test_cnt_correlates_report_20251015-163558  csv_threshold      1       1   \n",
       "11  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "12  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "13  test_cnt_correlates_report_20251015-164130  csv_threshold      1       1   \n",
       "14                                 test_readme  csv_threshold      1       1   \n",
       "15                                 test_readme  csv_threshold      1       1   \n",
       "16                                test_summary  csv_threshold      1       1   \n",
       "17                                test_summary  csv_threshold      1       1   \n",
       "18                                test_summary  csv_threshold      1       1   \n",
       "19                                test_summary  csv_threshold      1       1   \n",
       "\n",
       "                              info    reason  \n",
       "8                         non_gold  non_gold  \n",
       "9   mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "10  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "11  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "12  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "13  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "14  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "15  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "16  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "17  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "18  mean(N_pairs)=30.000000 > 27.0        ok  \n",
       "19  mean(N_pairs)=30.000000 > 27.0        ok  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === GOLD HOLDOUT TWINS + MANIFEST + RE-RUN (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "ART = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "# require mega-cell globals\n",
    "try:\n",
    "    TEST_FENCE, SOURCE_ROOTS\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run the Mega Cell once, then run this holdout+manifest cell.\")\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
    "\n",
    "def _match_col(df: pd.DataFrame, want: str):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    return nm.get(_norm(want or \"\"), None)\n",
    "\n",
    "# 1) create holdout twins when we can find a sensible companion CSV\n",
    "updated_docs = 0; twins_added = 0\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        changes = []\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or spec.get(\"type\") != \"csv_threshold\":\n",
    "                continue\n",
    "            if not spec.get(\"gold\"):  # only gold tests get holdout twins\n",
    "                continue\n",
    "            # skip if twin already exists\n",
    "            name = str(spec.get(\"name\",\"\"))\n",
    "            if name.endswith(\"_holdout\"): \n",
    "                continue\n",
    "\n",
    "            path = spec.get(\"path\")\n",
    "            if not path: \n",
    "                continue\n",
    "            pth = Path(path)\n",
    "            base_dir = pth.parent\n",
    "\n",
    "            # hunt likely holdouts\n",
    "            cand = None\n",
    "            # heuristic 1: sibling with 'holdout' in name\n",
    "            sibs = list(base_dir.glob(\"*holdout*.csv\"))\n",
    "            if sibs:\n",
    "                cand = sibs[0]\n",
    "            # heuristic 2: known EWB holdout file\n",
    "            if not cand:\n",
    "                known = base_dir / \"ewb_holdout_results.csv\"\n",
    "                if known.exists():\n",
    "                    cand = known\n",
    "            # heuristic 3: any csv one level up with 'holdout'\n",
    "            if not cand:\n",
    "                ups = list(base_dir.parent.glob(\"*holdout*.csv\"))\n",
    "                if ups:\n",
    "                    cand = ups[0]\n",
    "            if not cand or not cand.exists():\n",
    "                continue\n",
    "\n",
    "            # build twin spec\n",
    "            try:\n",
    "                df = pd.read_csv(cand)\n",
    "            except Exception:\n",
    "                continue\n",
    "            col_actual = _match_col(df, spec.get(\"column\"))\n",
    "            if col_actual is None:\n",
    "                # take first numeric\n",
    "                num_cols = [c for c in df.columns if pd.to_numeric(df[c], errors=\"coerce\").notna().any()]\n",
    "                if not num_cols:\n",
    "                    continue\n",
    "                col_actual = num_cols[0]\n",
    "\n",
    "            # copy thresholds/ops; re-freeze with new hash/rows\n",
    "            twin = dict(spec)\n",
    "            twin[\"name\"]     = f\"{name}_holdout\" if name else f\"test_{cand.stem}_holdout\"\n",
    "            twin[\"path\"]     = str(PureWindowsPath(cand))\n",
    "            twin[\"column\"]   = col_actual\n",
    "            twin[\"frozen_at\"]= STAMP\n",
    "            twin[\"hash\"]     = _sha256(cand)\n",
    "            twin[\"rows\"]     = int(len(df))\n",
    "            twin[\"gold\"]     = True\n",
    "\n",
    "            fenced = \"```cnt-test\\n\" + yaml.safe_dump(twin, sort_keys=False) + \"```\"\n",
    "            # insert twin immediately after original block\n",
    "            changes.append((m.span()[1], m.span()[1], \"\\n\\n# GOLD Holdout Twin\\n\" + fenced))\n",
    "            twins_added += 1\n",
    "\n",
    "        if changes:\n",
    "            new_txt = txt\n",
    "            for a,b,rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\")\n",
    "            updated_docs += 1\n",
    "\n",
    "print(f\"[holdout] updated_docs={updated_docs}, twins_added={twins_added}\")\n",
    "\n",
    "# 2) build a Gold Manifest from all gold tests across the corpus\n",
    "rows = []\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            try:\n",
    "                spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or not spec.get(\"gold\"):\n",
    "                continue\n",
    "            rows.append(dict(\n",
    "                doc=str(doc),\n",
    "                name=str(spec.get(\"name\",\"\")),\n",
    "                type=str(spec.get(\"type\",\"\")),\n",
    "                path=str(spec.get(\"path\",\"\")),\n",
    "                column=str(spec.get(\"column\",\"\")),\n",
    "                op=str(spec.get(\"op\",\">\")),\n",
    "                value=float(spec.get(\"value\",0.0)) if isinstance(spec.get(\"value\",0.0),(int,float)) or str(spec.get(\"value\",\"\")).replace('.','',1).isdigit() else str(spec.get(\"value\",\"\")),\n",
    "                agg=str(spec.get(\"agg\",\"mean\")),\n",
    "                frozen_at=str(spec.get(\"frozen_at\",\"\")),\n",
    "                hash=str(spec.get(\"hash\",\"\")),\n",
    "                rows=int(spec.get(\"rows\",0)),\n",
    "                is_holdout=int(str(spec.get(\"name\",\"\")).endswith(\"_holdout\"))\n",
    "            ))\n",
    "\n",
    "dfm = pd.DataFrame(rows)\n",
    "ART.mkdir(parents=True, exist_ok=True)\n",
    "if not dfm.empty:\n",
    "    dfm.to_csv(MANIFEST_CSV, index=False, encoding=\"utf-8\")\n",
    "    with open(MANIFEST_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "        yaml.safe_dump(rows, f, sort_keys=False, allow_unicode=True)\n",
    "print(f\"[manifest] rows={len(rows)}  -> {MANIFEST_CSV.name}, {MANIFEST_YAML.name}\")\n",
    "\n",
    "# 3) run engine once (strict mode from your GOLD cell stays active)\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# 4) echo latest test report summary\n",
    "reps = sorted(_globmod.glob(str((ART/\"out\") / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(12))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(12).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "669db371-eb5a-465c-b22a-fc4da4ad1dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8036512195121951,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9235444214640771,\n",
      "    \"falsifiability\": 0.7146341463414634,\n",
      "    \"total\": 0.8604574468294339\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 2,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_3i_atlas_all8_20251024-042112Z_539b05ee\\\\README.txt\",\n",
      "      \"resid\": 0.9685376805735942,\n",
      "      \"hint\": \" CNT \\u00d7 3I/ATLAS \\u2014 Upgraded All\\u20118 Pack ==================================== Stamp: 20251024-042112Z Includes: - WCS wavelength from FITS headers (CRVAL/CDELT/CRPIX) if spectrum_*.fits present. - Multi\\u2011feature GRA (CN/CH/C\\u2082 + custom lines) with solar\\u2011analog continuum normalization. - Plasma+Phase: coherence with FDR correction, plus phase (from xcorr peak mapped to f). - Observer\\u2011Ring Pro: if observ\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.967949011575336,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9131585056496372,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-180011.csv\n",
      "reason\n",
      "pair_fail    17\n",
      "ok            2\n",
      "non_gold      1\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "      <th>is_holdout</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "8         E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "18  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "19  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "8                                  test_readme  csv_threshold      0       0   \n",
       "9   test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "10  test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "11  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "12  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "13  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "14                                 test_readme  csv_threshold      0       0   \n",
       "15                                 test_readme  csv_threshold      0       0   \n",
       "16                                test_summary  csv_threshold      0       0   \n",
       "17                                test_summary  csv_threshold      0       0   \n",
       "18                                test_summary  csv_threshold      0       0   \n",
       "19                                test_summary  csv_threshold      0       0   \n",
       "\n",
       "                              info     reason  is_holdout  \\\n",
       "8                         non_gold   non_gold           0   \n",
       "9   mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "10  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "11  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "12  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "13  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "14  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "15  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "16  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "17  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "18  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "19  mean(N_pairs)=30.000000 > 27.0  pair_fail           0   \n",
       "\n",
       "                                          base  \n",
       "8                                  test_readme  \n",
       "9   test_cnt_correlates_report_20251015-163558  \n",
       "10  test_cnt_correlates_report_20251015-163558  \n",
       "11  test_cnt_correlates_report_20251015-164130  \n",
       "12  test_cnt_correlates_report_20251015-164130  \n",
       "13  test_cnt_correlates_report_20251015-164130  \n",
       "14                                 test_readme  \n",
       "15                                 test_readme  \n",
       "16                                test_summary  \n",
       "17                                test_summary  \n",
       "18                                test_summary  \n",
       "19                                test_summary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Pair-Rule Runner Patch (base passes only if its _holdout twin passes) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import re, json, glob as _globmod\n",
    "\n",
    "# We reuse your existing strict helpers:\n",
    "#   _csv_threshold_test_strict, _parse_cnt_tests, TEST_FENCE, ENGINE_ROOT\n",
    "# Assumes GOLD strict mode already set by your prior cell.\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    return str(name).endswith(\"_holdout\")\n",
    "\n",
    "def _base_name(name: str) -> str:\n",
    "    return str(name)[:-9] if _is_holdout_name(name) else str(name)\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    \"\"\"\n",
    "    1) Execute strict GOLD tests (hash-verified).\n",
    "    2) Apply pair rule: a base test is only valid if its _holdout twin is present AND passes.\n",
    "       - If twin missing or fails, mark both as pair_fail (valid=0, passed=0).\n",
    "    3) Write updated report and return counts after gating.\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    # ---- phase 1: strict evaluation (as before) ----\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name))\n",
    "            ))\n",
    "\n",
    "    rep = pd.DataFrame(rows)\n",
    "\n",
    "    if not rep.empty:\n",
    "        # ---- phase 2: pair gating ----\n",
    "        # Group by base name (strip _holdout)\n",
    "        rep[\"base\"] = rep[\"name\"].apply(_base_name)\n",
    "\n",
    "        # Only consider rows that reached 'ok' in strict mode\n",
    "        ok_mask = rep[\"reason\"].eq(\"ok\")\n",
    "        rep_ok = rep[ok_mask].copy()\n",
    "\n",
    "        # For each base, find base-row and holdout-row\n",
    "        # We'll mark pair_fail if either side missing OR any side fails\n",
    "        idx_map = {}\n",
    "        for i, row in rep_ok.iterrows():\n",
    "            b = row[\"base\"]\n",
    "            idx_map.setdefault(b, []).append(i)\n",
    "\n",
    "        to_pair_fail = set()\n",
    "        for b, idxs in idx_map.items():\n",
    "            # Find base and holdout rows among idxs (by name)\n",
    "            base_idxs = [i for i in idxs if not _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "            hold_idxs = [i for i in idxs if _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "\n",
    "            # If there is at least one base test, require at least one holdout twin\n",
    "            if base_idxs:\n",
    "                if not hold_idxs:\n",
    "                    # No twin: all base tests under 'b' fail the pair rule\n",
    "                    to_pair_fail.update(base_idxs)\n",
    "                else:\n",
    "                    # Require that at least one holdout twin passes\n",
    "                    hold_pass = any(bool(rep.loc[i, \"passed\"]) for i in hold_idxs)\n",
    "                    base_pass = any(bool(rep.loc[i, \"passed\"]) for i in base_idxs)\n",
    "                    if not (hold_pass and base_pass):\n",
    "                        # If either side has no passing test, fail both sides\n",
    "                        to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "        # Apply pair_fail to report\n",
    "        if to_pair_fail:\n",
    "            rep.loc[list(to_pair_fail), \"valid\"]  = 0\n",
    "            rep.loc[list(to_pair_fail), \"passed\"] = 0\n",
    "            rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "        # ---- phase 3: output and counts ----\n",
    "        rep.to_csv(out_csv, index=False)\n",
    "\n",
    "        total  = int(rep[\"valid\"].sum())\n",
    "        passed = int(rep[\"passed\"].sum())\n",
    "        # Count \"runnable\" as number of tests seen, regardless of validity\n",
    "        runnable = int(len(rep))\n",
    "    else:\n",
    "        # empty report\n",
    "        pd.DataFrame(columns=[\"doc\",\"name\",\"type\",\"valid\",\"passed\",\"info\",\"reason\",\"is_holdout\",\"base\"]).to_csv(out_csv, index=False)\n",
    "        total = passed = runnable = 0\n",
    "\n",
    "    return passed, total, runnable\n",
    "\n",
    "# Re-run one engine cycle with pair rule enforced\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# Show latest report summary\n",
    "from pathlib import Path\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1])\n",
    "    dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(12))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(12).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d1a36ec-23a8-486e-8c7e-1c5aa2b51eb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Index' object has no attribute 'index'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 101\u001b[39m\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m passed, total, runnable\n\u001b[32m    100\u001b[39m \u001b[38;5;66;03m# ---- Re-run one engine cycle and show summary\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m res = \u001b[43mrun_cycle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(res, indent=\u001b[32m2\u001b[39m))\n\u001b[32m    104\u001b[39m OUT_DIR = Path(\u001b[38;5;28mstr\u001b[39m(ENGINE_ROOT)) / \u001b[33m\"\u001b[39m\u001b[33mout\u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 336\u001b[39m, in \u001b[36mrun_cycle\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    333\u001b[39m G = build_graph(df, labels)\n\u001b[32m    335\u001b[39m tests_csv = OUT_DIR / \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mtests_report_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdatetime.now().strftime(\u001b[33m'\u001b[39m\u001b[33m%\u001b[39m\u001b[33mY\u001b[39m\u001b[33m%\u001b[39m\u001b[33mm\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m-\u001b[39m\u001b[33m%\u001b[39m\u001b[33mH\u001b[39m\u001b[33m%\u001b[39m\u001b[33mM\u001b[39m\u001b[33m%\u001b[39m\u001b[33mS\u001b[39m\u001b[33m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.csv\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m336\u001b[39m passed, total, runnable = \u001b[43mrun_cnt_tests_on_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtests_csv\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    338\u001b[39m score = score_reflexive(df, novel, G, runnable_tests=runnable)\n\u001b[32m    339\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m total > \u001b[32m0\u001b[39m:\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 50\u001b[39m, in \u001b[36mrun_cnt_tests_on_df\u001b[39m\u001b[34m(df, out_csv)\u001b[39m\n\u001b[32m     47\u001b[39m rep.loc[~rep[\u001b[33m\"\u001b[39m\u001b[33mreason\u001b[39m\u001b[33m\"\u001b[39m].eq(\u001b[33m\"\u001b[39m\u001b[33mok\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mpassed\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[32m0\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;66;03m# Index by base\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m50\u001b[39m by_base = {b: \u001b[43midxs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m.tolist() \u001b[38;5;28;01mfor\u001b[39;00m b, idxs \u001b[38;5;129;01min\u001b[39;00m rep.groupby(\u001b[33m\"\u001b[39m\u001b[33mbase\u001b[39m\u001b[33m\"\u001b[39m).groups.items()}\n\u001b[32m     52\u001b[39m to_pair_fail = \u001b[38;5;28mset\u001b[39m()\n\u001b[32m     53\u001b[39m to_needs_holdout = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mAttributeError\u001b[39m: 'Index' object has no attribute 'index'"
     ]
    }
   ],
   "source": [
    "# === PAIRED-EVIDENCE (PRAGMATIC MODE) RUNNER + RE-RUN (single cell) ===\n",
    "# Counts only base/holdout pairs that BOTH exist and pass. Singles are \"needs_holdout\" (not failed, not counted).\n",
    "from pathlib import Path\n",
    "import pandas as pd, json, re, glob as _globmod\n",
    "\n",
    "PAIR_MODE = \"soft\"  # \"soft\" = pragmatic / \"strict\" = fail singles\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    return str(name).endswith(\"_holdout\")\n",
    "\n",
    "def _base_name(name: str) -> str:\n",
    "    return str(name)[:-9] if _is_holdout_name(name) else str(name)\n",
    "\n",
    "# We reuse: _csv_threshold_test_strict, _parse_cnt_tests, TEST_FENCE, ENGINE_ROOT, run_cycle\n",
    "# (loaded from your mega cell)\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    # ---- Phase 1: strict evaluation (hash-verified GOLD) ----\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name))\n",
    "            ))\n",
    "\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        pd.DataFrame(columns=[\"doc\",\"name\",\"type\",\"valid\",\"passed\",\"info\",\"reason\",\"is_holdout\",\"base\"]).to_csv(out_csv, index=False)\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # ---- Phase 2: pair gating in PAIR_MODE ----\n",
    "    rep[\"base\"] = rep[\"name\"].apply(_base_name)\n",
    "\n",
    "    # Start from strict-ok only\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), \"valid\"] = 0\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), \"passed\"] = 0\n",
    "\n",
    "    # Index by base\n",
    "    by_base = {b: idxs.index.tolist() for b, idxs in rep.groupby(\"base\").groups.items()}\n",
    "\n",
    "    to_pair_fail = set()\n",
    "    to_needs_holdout = set()\n",
    "\n",
    "    for b, idxs in by_base.items():\n",
    "        base_idxs   = [i for i in idxs if not _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "        hold_idxs   = [i for i in idxs if _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "        has_base_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in base_idxs)\n",
    "        has_hold_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in hold_idxs)\n",
    "        base_pass   = any(bool(rep.loc[i, \"passed\"]) for i in base_idxs)\n",
    "        hold_pass   = any(bool(rep.loc[i, \"passed\"]) for i in hold_idxs)\n",
    "\n",
    "        if PAIR_MODE == \"strict\":\n",
    "            # must have both and both pass\n",
    "            if not (has_base_ok and has_hold_ok and base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "        else:\n",
    "            # soft: if twin missing, mark needs_holdout (exclude from totals, not fail)\n",
    "            if base_idxs and not hold_idxs:\n",
    "                to_needs_holdout.update(base_idxs)\n",
    "            elif hold_idxs and not base_idxs:\n",
    "                to_needs_holdout.update(hold_idxs)\n",
    "            else:\n",
    "                # both exist → require both pass\n",
    "                if not (base_pass and hold_pass):\n",
    "                    to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    # Apply labels\n",
    "    if PAIR_MODE == \"strict\":\n",
    "        if to_pair_fail:\n",
    "            rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "    else:\n",
    "        if to_needs_holdout:\n",
    "            rep.loc[list(to_needs_holdout), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_needs_holdout), \"reason\"] = \"needs_holdout\"\n",
    "        if to_pair_fail:\n",
    "            rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    # Write report\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Totals: count only valid rows (i.e., true paired evidence) \n",
    "    total  = int(rep[\"valid\"].sum())\n",
    "    passed = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))  # number seen, regardless of gating\n",
    "    return passed, total, runnable\n",
    "\n",
    "# ---- Re-run one engine cycle and show summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(12))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(12).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c734ccc8-1348-41a2-889d-ebca659c9ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8036512195121951,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9235444214640771,\n",
      "    \"falsifiability\": 0.7146341463414634,\n",
      "    \"total\": 0.8604574468294339\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_3i_atlas_all8_20251024-042112Z_539b05ee\\\\README.txt\",\n",
      "      \"resid\": 0.9685376805735942,\n",
      "      \"hint\": \" CNT \\u00d7 3I/ATLAS \\u2014 Upgraded All\\u20118 Pack ==================================== Stamp: 20251024-042112Z Includes: - WCS wavelength from FITS headers (CRVAL/CDELT/CRPIX) if spectrum_*.fits present. - Multi\\u2011feature GRA (CN/CH/C\\u2082 + custom lines) with solar\\u2011analog continuum normalization. - Plasma+Phase: coherence with FDR correction, plus phase (from xcorr peak mapped to f). - Observer\\u2011Ring Pro: if observ\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.967949011575336,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9131585056496372,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-180316.csv\n",
      "reason\n",
      "needs_holdout    20\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "      <th>is_holdout</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "8         E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "18  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "19  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "8                                  test_readme  csv_threshold      0       0   \n",
       "9   test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "10  test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "11  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "12  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "13  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "14                                 test_readme  csv_threshold      0       0   \n",
       "15                                 test_readme  csv_threshold      0       0   \n",
       "16                                test_summary  csv_threshold      0       0   \n",
       "17                                test_summary  csv_threshold      0       0   \n",
       "18                                test_summary  csv_threshold      0       0   \n",
       "19                                test_summary  csv_threshold      0       0   \n",
       "\n",
       "                              info         reason  is_holdout  \\\n",
       "8                         non_gold  needs_holdout           0   \n",
       "9   mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "10  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "11  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "12  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "13  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "14  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "15  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "16  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "17  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "18  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "19  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "\n",
       "                                          base  \n",
       "8                                  test_readme  \n",
       "9   test_cnt_correlates_report_20251015-163558  \n",
       "10  test_cnt_correlates_report_20251015-163558  \n",
       "11  test_cnt_correlates_report_20251015-164130  \n",
       "12  test_cnt_correlates_report_20251015-164130  \n",
       "13  test_cnt_correlates_report_20251015-164130  \n",
       "14                                 test_readme  \n",
       "15                                 test_readme  \n",
       "16                                test_summary  \n",
       "17                                test_summary  \n",
       "18                                test_summary  \n",
       "19                                test_summary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Patch: pragmatic paired-evidence runner (fixed group indices) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd, json, glob as _globmod\n",
    "\n",
    "# keep your earlier helpers & globals: _csv_threshold_test_strict, _parse_cnt_tests,\n",
    "# TEST_FENCE, ENGINE_ROOT, run_cycle, _is_holdout_name, _base_name\n",
    "\n",
    "PAIR_MODE = \"soft\"  # \"soft\" = singles -> needs_holdout (not failed); \"strict\" = fail singles\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    # 1) strict GOLD evaluation (hash-verified)\n",
    "    for _, r in df.iterrows():\n",
    "        path  = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name))\n",
    "            ))\n",
    "\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        pd.DataFrame(columns=[\"doc\",\"name\",\"type\",\"valid\",\"passed\",\"info\",\"reason\",\"is_holdout\",\"base\"]).to_csv(out_csv, index=False)\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # 2) pair gating (soft/strict)\n",
    "    rep[\"base\"] = rep[\"name\"].apply(_base_name)\n",
    "\n",
    "    # only rows that were strict-ok can be considered\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "\n",
    "    # FIX: build base -> list of integer row indices (use .indices, not .groups.index)\n",
    "    by_base = {b: list(idxs) for b, idxs in rep.groupby(\"base\").indices.items()}\n",
    "\n",
    "    to_pair_fail = set()\n",
    "    to_needs_holdout = set()\n",
    "\n",
    "    for b, idxs in by_base.items():\n",
    "        base_idxs = [i for i in idxs if not _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "        hold_idxs = [i for i in idxs if     _is_holdout_name(rep.loc[i, \"name\"])]\n",
    "\n",
    "        has_base_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in base_idxs)\n",
    "        has_hold_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in hold_idxs)\n",
    "        base_pass   = any(bool(rep.loc[i, \"passed\"]) for i in base_idxs)\n",
    "        hold_pass   = any(bool(rep.loc[i, \"passed\"]) for i in hold_idxs)\n",
    "\n",
    "        if PAIR_MODE == \"strict\":\n",
    "            if not (has_base_ok and has_hold_ok and base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "        else:\n",
    "            if base_idxs and not hold_idxs:\n",
    "                to_needs_holdout.update(base_idxs)\n",
    "            elif hold_idxs and not base_idxs:\n",
    "                to_needs_holdout.update(hold_idxs)\n",
    "            else:\n",
    "                if not (base_pass and hold_pass):\n",
    "                    to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    if PAIR_MODE == \"strict\":\n",
    "        if to_pair_fail:\n",
    "            rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "    else:\n",
    "        if to_needs_holdout:\n",
    "            rep.loc[list(to_needs_holdout), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_needs_holdout), \"reason\"] = \"needs_holdout\"\n",
    "        if to_pair_fail:\n",
    "            rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "            rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "\n",
    "    total    = int(rep[\"valid\"].sum())   # counts only true paired evidence\n",
    "    passed   = int(rep[\"passed\"].sum())  # pairs where both sides pass\n",
    "    runnable = int(len(rep))             # all tests seen (for info)\n",
    "    return passed, total, runnable\n",
    "\n",
    "# re-run once and show summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(12))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(12).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1aac0548-aba1-42a6-90f4-811da02639d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[holdout-mint] docs_touched=1, twins_minted=2\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.802,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9235444214640771,\n",
      "    \"falsifiability\": 0.724390243902439,\n",
      "    \"total\": 0.8624836663416291\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.909040400111031,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.9011789863580367,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.900507394108084,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-180437.csv\n",
      "reason\n",
      "needs_holdout    22\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "      <th>is_holdout</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "10        E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "12  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "13  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "14  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "18  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "19  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "20  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "21  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                          name           type  valid  passed  \\\n",
       "10                                 test_readme  csv_threshold      0       0   \n",
       "11  test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "12  test_cnt_correlates_report_20251015-163558  csv_threshold      0       0   \n",
       "13  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "14  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "15  test_cnt_correlates_report_20251015-164130  csv_threshold      0       0   \n",
       "16                                 test_readme  csv_threshold      0       0   \n",
       "17                                 test_readme  csv_threshold      0       0   \n",
       "18                                test_summary  csv_threshold      0       0   \n",
       "19                                test_summary  csv_threshold      0       0   \n",
       "20                                test_summary  csv_threshold      0       0   \n",
       "21                                test_summary  csv_threshold      0       0   \n",
       "\n",
       "                              info         reason  is_holdout  \\\n",
       "10                        non_gold  needs_holdout           0   \n",
       "11  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "12  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "13  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "14  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "15  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "16  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "17  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "18  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "19  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "20  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "21  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "\n",
       "                                          base  \n",
       "10                                 test_readme  \n",
       "11  test_cnt_correlates_report_20251015-163558  \n",
       "12  test_cnt_correlates_report_20251015-163558  \n",
       "13  test_cnt_correlates_report_20251015-164130  \n",
       "14  test_cnt_correlates_report_20251015-164130  \n",
       "15  test_cnt_correlates_report_20251015-164130  \n",
       "16                                 test_readme  \n",
       "17                                 test_readme  \n",
       "18                                test_summary  \n",
       "19                                test_summary  \n",
       "20                                test_summary  \n",
       "21                                test_summary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Auto-mint HOLDOUT twins (same column) + freeze + re-run (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# require from mega cell: TEST_FENCE, SOURCE_ROOTS, run_cycle\n",
    "try:\n",
    "    TEST_FENCE, SOURCE_ROOTS, run_cycle\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run the Mega Cell cell first so TEST_FENCE/SOURCE_ROOTS/run_cycle exist.\")\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower())\n",
    "\n",
    "def _match_col(df: pd.DataFrame, want: str):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    return nm.get(_norm(want or \"\"))\n",
    "\n",
    "def _find_holdout_csv(base_csv: Path):\n",
    "    \"\"\"Search same dir, parent, and siblings for a plausible holdout CSV.\"\"\"\n",
    "    d = base_csv.parent\n",
    "    # 1) siblings with 'holdout' in name\n",
    "    sibs = [p for p in d.glob(\"*.csv\") if \"holdout\" in p.name.lower()]\n",
    "    if sibs: return sibs[0]\n",
    "    # 2) known EWB filename\n",
    "    k = d / \"ewb_holdout_results.csv\"\n",
    "    if k.exists(): return k\n",
    "    # 3) parent dir any '*holdout*.csv'\n",
    "    ups = [p for p in d.parent.glob(\"*.csv\") if \"holdout\" in p.name.lower()]\n",
    "    if ups: return ups[0]\n",
    "    return None\n",
    "\n",
    "minted = 0\n",
    "touched_docs = 0\n",
    "\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "\n",
    "        changes = []\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            # only extend GOLD base tests (not already _holdout)\n",
    "            name = str(spec.get(\"name\",\"\"))\n",
    "            if not (isinstance(spec, dict) and spec.get(\"type\")==\"csv_threshold\" and spec.get(\"gold\", False)):\n",
    "                continue\n",
    "            if name.endswith(\"_holdout\"):\n",
    "                continue\n",
    "\n",
    "            base_path = spec.get(\"path\")\n",
    "            base_col  = spec.get(\"column\")\n",
    "            if not base_path or not base_col:\n",
    "                continue\n",
    "            base_csv = Path(base_path)\n",
    "            if not base_csv.exists():\n",
    "                continue\n",
    "\n",
    "            # find a holdout candidate\n",
    "            ho = _find_holdout_csv(base_csv)\n",
    "            if not ho or not ho.exists():\n",
    "                continue\n",
    "\n",
    "            # column must exist in holdout csv\n",
    "            try:\n",
    "                dfh = pd.read_csv(ho)\n",
    "            except Exception:\n",
    "                continue\n",
    "            col_actual = _match_col(dfh, base_col)\n",
    "            if col_actual is None:\n",
    "                continue  # do not mint if metric not present\n",
    "\n",
    "            spec_twin = dict(spec)\n",
    "            spec_twin[\"name\"]      = name + \"_holdout\"\n",
    "            spec_twin[\"path\"]      = str(PureWindowsPath(ho))\n",
    "            spec_twin[\"column\"]    = col_actual\n",
    "            spec_twin[\"frozen_at\"] = STAMP\n",
    "            spec_twin[\"hash\"]      = _sha256(ho)\n",
    "            spec_twin[\"rows\"]      = int(len(dfh))\n",
    "            spec_twin[\"gold\"]      = True\n",
    "\n",
    "            fenced = \"```cnt-test\\n\" + yaml.safe_dump(spec_twin, sort_keys=False) + \"```\"\n",
    "            # insert twin immediately AFTER the base block\n",
    "            changes.append((m.span()[1], m.span()[1], \"\\n\\n# GOLD Holdout Twin (auto)\\n\" + fenced))\n",
    "            minted += 1\n",
    "\n",
    "        if changes:\n",
    "            new_txt = txt\n",
    "            for a,b,rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\")\n",
    "            touched_docs += 1\n",
    "\n",
    "print(f\"[holdout-mint] docs_touched={touched_docs}, twins_minted={minted}\")\n",
    "\n",
    "# re-run once\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# show latest report breakdown\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep.tail(12))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(12).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "07e13a2c-4a5b-4349-8644-392c32d8dcbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pair-doctor] base: test_ewb_results doc: E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\ewb_results.md\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "No holdout CSV found near E:\\CNT\\artifacts\\CNT_PLI_EC_EO_paired_bootstrap.csv. Place an 'ewb_holdout_results.csv' next to it and re-run.",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[31mSystemExit\u001b[39m\u001b[31m:\u001b[39m No holdout CSV found near E:\\CNT\\artifacts\\CNT_PLI_EC_EO_paired_bootstrap.csv. Place an 'ewb_holdout_results.csv' next to it and re-run.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\CNT_Lab\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:3707: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "# === CNT Pair-Doctor: mint a correct EWB base+holdout pair and re-run (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# need from mega cell: TEST_FENCE, SOURCE_ROOTS, run_cycle, _csv_threshold_test_strict\n",
    "try:\n",
    "    TEST_FENCE, SOURCE_ROOTS, run_cycle, _csv_threshold_test_strict\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run your Mega Cell first so TEST_FENCE/SOURCE_ROOTS/run_cycle exist.\")\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower())\n",
    "\n",
    "def _match_col(df: pd.DataFrame, want: str):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    return nm.get(_norm(want or \"\"))\n",
    "\n",
    "def _base_name(name: str) -> str:\n",
    "    return str(name)[:-9] if str(name).endswith(\"_holdout\") else str(name)\n",
    "\n",
    "# ---- 1) collect all tests from corpus\n",
    "tests = []\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict): \n",
    "                continue\n",
    "            name = str(spec.get(\"name\", Path(doc).stem))\n",
    "            tests.append(dict(\n",
    "                doc=str(doc), name=name, base=_base_name(name),\n",
    "                spec=spec, text_span=m.span(), text=txt\n",
    "            ))\n",
    "\n",
    "# ---- 2) find an EWB base test we can pair (prefer 'ewb' in doc or name)\n",
    "ewb = [t for t in tests if (\"ewb\" in _norm(t[\"doc\"]) or \"ewb\" in _norm(t[\"name\"])) and t[\"spec\"].get(\"type\")==\"csv_threshold\"]\n",
    "if not ewb:\n",
    "    raise SystemExit(\"No EWB cnt-test found. Run the earlier auto-append or tell me which file to use.\")\n",
    "# choose a base that is NOT already a holdout and is GOLD + passes strict\n",
    "chosen = None\n",
    "for t in ewb:\n",
    "    spec = t[\"spec\"]\n",
    "    if str(t[\"name\"]).endswith(\"_holdout\"): \n",
    "        continue\n",
    "    if not spec.get(\"gold\", False): \n",
    "        continue\n",
    "    ok, info, reason = _csv_threshold_test_strict(spec)\n",
    "    if reason == \"ok\" and ok:\n",
    "        chosen = t; break\n",
    "if not chosen:\n",
    "    # fallback: take first EWB base; we'll still try to mint twin correctly\n",
    "    chosen = ewb[0]\n",
    "\n",
    "print(\"[pair-doctor] base:\", chosen[\"name\"], \"doc:\", chosen[\"doc\"])\n",
    "\n",
    "# ---- 3) compute the proper holdout CSV and column for the chosen base\n",
    "base_spec = chosen[\"spec\"]\n",
    "base_csv  = Path(base_spec.get(\"path\",\"\"))\n",
    "base_col  = base_spec.get(\"column\",\"\")\n",
    "if (not base_csv.exists()) or (not base_col):\n",
    "    raise SystemExit(\"Chosen base test has no valid CSV/column. Open the doc and fill them once, then re-run this cell.\")\n",
    "\n",
    "# likely holdout file in same dir: ewb_holdout_results.csv OR *holdout*.csv\n",
    "def _find_holdout_csv(base_csv: Path):\n",
    "    d = base_csv.parent\n",
    "    k = d / \"ewb_holdout_results.csv\"\n",
    "    if k.exists(): return k\n",
    "    sibs = [p for p in d.glob(\"*holdout*.csv\")]\n",
    "    if sibs: return sibs[0]\n",
    "    ups = [p for p in d.parent.glob(\"*holdout*.csv\")]\n",
    "    if ups: return ups[0]\n",
    "    return None\n",
    "\n",
    "hold_csv = _find_holdout_csv(base_csv)\n",
    "if not hold_csv or not hold_csv.exists():\n",
    "    raise SystemExit(f\"No holdout CSV found near {base_csv}. Place an 'ewb_holdout_results.csv' next to it and re-run.\")\n",
    "\n",
    "dfh = pd.read_csv(hold_csv)\n",
    "col_actual = _match_col(dfh, base_col)\n",
    "if col_actual is None:\n",
    "    # try common metrics if name variant differs\n",
    "    for want in [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\"]:\n",
    "        col_actual = _match_col(dfh, want)\n",
    "        if col_actual: break\n",
    "if col_actual is None:\n",
    "    raise SystemExit(f\"Holdout CSV {hold_csv} lacks a compatible column for '{base_col}'.\")\n",
    "\n",
    "# ---- 4) write or update the _holdout twin next to the base block\n",
    "doc_path = Path(chosen[\"doc\"])\n",
    "txt = chosen[\"text\"]\n",
    "span = chosen[\"text_span\"]\n",
    "\n",
    "twin = dict(base_spec)\n",
    "twin[\"name\"]      = str(chosen[\"name\"]) + \"_holdout\"\n",
    "twin[\"path\"]      = str(PureWindowsPath(hold_csv))\n",
    "twin[\"column\"]    = col_actual\n",
    "twin[\"frozen_at\"] = STAMP\n",
    "twin[\"hash\"]      = _sha256(hold_csv)\n",
    "twin[\"rows\"]      = int(len(dfh))\n",
    "twin[\"gold\"]      = True\n",
    "\n",
    "twin_block = \"```cnt-test\\n\" + yaml.safe_dump(twin, sort_keys=False) + \"```\"\n",
    "\n",
    "# insert twin immediately after base block (or replace existing twin with fresh metadata)\n",
    "# if an existing twin with same name exists in the doc, replace its fenced block\n",
    "replaced = False\n",
    "for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "    body = m.group(\"body\")\n",
    "    try:\n",
    "        spec2 = yaml.safe_load(body) or {}\n",
    "    except Exception:\n",
    "        continue\n",
    "    if isinstance(spec2, dict) and spec2.get(\"name\",\"\") == twin[\"name\"]:\n",
    "        a,b = m.span()\n",
    "        txt = txt[:a] + twin_block + txt[b:]\n",
    "        replaced = True\n",
    "        break\n",
    "\n",
    "if not replaced:\n",
    "    # insert after base block span\n",
    "    a,b = span\n",
    "    txt = txt[:b] + \"\\n\\n# GOLD Holdout Twin (doctor)\\n\" + twin_block + txt[b:]\n",
    "\n",
    "doc_path.write_text(txt, encoding=\"utf-8\")\n",
    "print(\"[pair-doctor] wrote twin:\", twin[\"name\"], \"->\", hold_csv.name, \"| col:\", col_actual)\n",
    "\n",
    "# ---- 5) re-run engine once and show the pair summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    # quick base/twin view\n",
    "    view = dfrep[[\"name\",\"valid\",\"passed\",\"reason\"]].copy()\n",
    "    view[\"base\"] = view[\"name\"].apply(lambda s: s[:-9] if str(s).endswith(\"_holdout\") else s)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(view.sort_values([\"base\",\"name\"]).tail(20))\n",
    "    except Exception:\n",
    "        print(view.sort_values([\"base\",\"name\"]).tail(20).to_string(index=False))\n",
    "else:\n",
    "    print(\"No tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1fd85e2e-00a0-4ca7-aada-386073e6d541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[pair-explicit] wrote twin: test_ewb_results_holdout -> ewb_holdout_results.csv | col: AUC\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8011682926829268,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 0.7292682926829268,\n",
      "    \"total\": 0.861753000852965\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9553980941132267,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.9123017500289156,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.9080147017219268,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-180957.csv\n",
      "reason\n",
      "needs_holdout    23\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "      <th>base</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_aut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_aut</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_ewb_auto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_auto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_precisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_precisio</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_precision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_ewb_results_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_result</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_ewb_results</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_gold_verification_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_gold_verification_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_readme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>test_summary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  valid  passed         reason  \\\n",
       "15  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout   \n",
       "16  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout   \n",
       "9                        test_ewb_auto_holdout      0       0  needs_holdout   \n",
       "10                       test_ewb_auto_holdout      0       0  needs_holdout   \n",
       "8                                test_ewb_auto      0       0  needs_holdout   \n",
       "6                   test_ewb_precision_holdout      0       0  needs_holdout   \n",
       "7                   test_ewb_precision_holdout      0       0  needs_holdout   \n",
       "5                           test_ewb_precision      0       0  needs_holdout   \n",
       "2                     test_ewb_results_holdout      0       0  needs_holdout   \n",
       "1                             test_ewb_results      0       0  needs_holdout   \n",
       "3                             test_ewb_results      0       0  needs_holdout   \n",
       "4                             test_ewb_results      0       0  needs_holdout   \n",
       "0               test_gold_verification_summary      0       0  needs_holdout   \n",
       "11                                 test_readme      0       0  needs_holdout   \n",
       "17                                 test_readme      0       0  needs_holdout   \n",
       "18                                 test_readme      0       0  needs_holdout   \n",
       "19                                test_summary      0       0  needs_holdout   \n",
       "20                                test_summary      0       0  needs_holdout   \n",
       "21                                test_summary      0       0  needs_holdout   \n",
       "22                                test_summary      0       0  needs_holdout   \n",
       "\n",
       "                                          base  \n",
       "15  test_cnt_correlates_report_20251015-164130  \n",
       "16  test_cnt_correlates_report_20251015-164130  \n",
       "9                                 test_ewb_aut  \n",
       "10                                test_ewb_aut  \n",
       "8                                test_ewb_auto  \n",
       "6                            test_ewb_precisio  \n",
       "7                            test_ewb_precisio  \n",
       "5                           test_ewb_precision  \n",
       "2                              test_ewb_result  \n",
       "1                             test_ewb_results  \n",
       "3                             test_ewb_results  \n",
       "4                             test_ewb_results  \n",
       "0               test_gold_verification_summary  \n",
       "11                                 test_readme  \n",
       "17                                 test_readme  \n",
       "18                                 test_readme  \n",
       "19                                test_summary  \n",
       "20                                test_summary  \n",
       "21                                test_summary  \n",
       "22                                test_summary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === EWB explicit holdout twin + re-run (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# need from mega cell:\n",
    "try:\n",
    "    TEST_FENCE, run_cycle\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run your Mega Cell first so TEST_FENCE/run_cycle exist.\")\n",
    "\n",
    "BASE_DOC   = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\ewb_results.md\"  # where base test lives\n",
    "HOLDOUT_CSV = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_holdout_results.csv\"\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    import hashlib\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s).lower())\n",
    "\n",
    "def _match_col(df: pd.DataFrame, want: str):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    return nm.get(_norm(want or \"\"))\n",
    "\n",
    "if not BASE_DOC.exists():\n",
    "    raise SystemExit(f\"Base doc not found: {BASE_DOC}\")\n",
    "if not HOLDOUT_CSV.exists():\n",
    "    raise SystemExit(f\"Holdout CSV not found: {HOLDOUT_CSV}\")\n",
    "\n",
    "txt = BASE_DOC.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "# 1) find an EWB base cnt-test (not _holdout), GOLD, with a CSV+column\n",
    "blocks = list(TEST_FENCE.finditer(txt))\n",
    "chosen = None\n",
    "for m in blocks:\n",
    "    try:\n",
    "        spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "    except Exception:\n",
    "        continue\n",
    "    if not isinstance(spec, dict): \n",
    "        continue\n",
    "    name = str(spec.get(\"name\",\"\"))\n",
    "    if name.endswith(\"_holdout\"): \n",
    "        continue\n",
    "    if spec.get(\"type\")!=\"csv_threshold\":\n",
    "        continue\n",
    "    # prefer something clearly EWB\n",
    "    if \"ewb\" not in _norm(name) and \"ewb\" not in _norm(BASE_DOC.name):\n",
    "        continue\n",
    "    if not spec.get(\"gold\", False):\n",
    "        continue\n",
    "    if not spec.get(\"path\") or not spec.get(\"column\"):\n",
    "        continue\n",
    "    # pick this one\n",
    "    chosen = dict(spec=spec, span=m.span(), name=name)\n",
    "    break\n",
    "\n",
    "if chosen is None:\n",
    "    raise SystemExit(\"No suitable EWB base cnt-test (GOLD) found in the base doc.\")\n",
    "\n",
    "# 2) choose the column in holdout to match the base (fallback to common metrics)\n",
    "dfh = pd.read_csv(HOLDOUT_CSV)\n",
    "col = _match_col(dfh, chosen[\"spec\"][\"column\"])\n",
    "if col is None:\n",
    "    for want in [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\"]:\n",
    "        col = _match_col(dfh, want)\n",
    "        if col: break\n",
    "if col is None:\n",
    "    raise SystemExit(f\"Holdout CSV lacks a compatible column; columns present: {list(dfh.columns)}\")\n",
    "\n",
    "# 3) compose the twin spec (reuse op/value/agg from the base)\n",
    "twin = dict(chosen[\"spec\"])\n",
    "twin[\"name\"]      = chosen[\"name\"] + \"_holdout\"\n",
    "twin[\"path\"]      = str(PureWindowsPath(HOLDOUT_CSV))\n",
    "twin[\"column\"]    = col\n",
    "twin[\"frozen_at\"] = STAMP\n",
    "twin[\"hash\"]      = _sha256(HOLDOUT_CSV)\n",
    "twin[\"rows\"]      = int(len(dfh))\n",
    "twin[\"gold\"]      = True\n",
    "\n",
    "twin_block = \"```cnt-test\\n\" + yaml.safe_dump(twin, sort_keys=False) + \"```\"\n",
    "\n",
    "# 4) insert or replace twin in the doc\n",
    "inserted = False\n",
    "for m in blocks:\n",
    "    try:\n",
    "        spec2 = yaml.safe_load(m.group(\"body\")) or {}\n",
    "    except Exception:\n",
    "        continue\n",
    "    if isinstance(spec2, dict) and spec2.get(\"name\",\"\") == twin[\"name\"]:\n",
    "        a,b = m.span()\n",
    "        txt = txt[:a] + twin_block + txt[b:]\n",
    "        inserted = True\n",
    "        break\n",
    "\n",
    "if not inserted:\n",
    "    a,b = chosen[\"span\"]\n",
    "    txt = txt[:b] + \"\\n\\n# GOLD Holdout Twin (explicit)\\n\" + twin_block + txt[b:]\n",
    "\n",
    "BASE_DOC.write_text(txt, encoding=\"utf-8\")\n",
    "print(\"[pair-explicit] wrote twin:\", twin[\"name\"], \"->\", HOLDOUT_CSV.name, \"| col:\", col)\n",
    "\n",
    "# 5) re-run the engine and show status\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    view = dfrep[[\"name\",\"valid\",\"passed\",\"reason\"]].copy()\n",
    "    view[\"base\"] = view[\"name\"].apply(lambda s: s[:-9] if str(s).endswith(\"_holdout\") else s)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(view.sort_values([\"base\",\"name\"]).tail(20))\n",
    "    except Exception:\n",
    "        print(view.sort_values([\"base\",\"name\"]).tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "32d38f79-2a1d-48a2-ac6d-6aeeefa685a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8011682926829268,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 0.7292682926829268,\n",
      "    \"total\": 0.861753000852965\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9553980941132267,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.9123017500289156,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.9080147017219268,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-181138.csv\n",
      "reason\n",
      "needs_holdout    13\n",
      "pair_fail        10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "      <th>base_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testcntcorrelatesreport20251015163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testcntcorrelatesreport20251015163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_ewb_auto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbauto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbauto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbauto</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbprecision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbprecision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbprecision</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbresults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbresults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbresults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_ewb_results_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>pair_fail</td>\n",
       "      <td>testewbresults</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_gold_verification_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testgoldverificationsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  valid  passed         reason  \\\n",
       "12  test_cnt_correlates_report_20251015-163558      0       0  needs_holdout   \n",
       "13  test_cnt_correlates_report_20251015-163558      0       0  needs_holdout   \n",
       "14  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout   \n",
       "15  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout   \n",
       "16  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout   \n",
       "8                                test_ewb_auto      0       0      pair_fail   \n",
       "9                        test_ewb_auto_holdout      0       0      pair_fail   \n",
       "10                       test_ewb_auto_holdout      0       0      pair_fail   \n",
       "5                           test_ewb_precision      0       0      pair_fail   \n",
       "6                   test_ewb_precision_holdout      0       0      pair_fail   \n",
       "7                   test_ewb_precision_holdout      0       0      pair_fail   \n",
       "1                             test_ewb_results      0       0      pair_fail   \n",
       "3                             test_ewb_results      0       0      pair_fail   \n",
       "4                             test_ewb_results      0       0      pair_fail   \n",
       "2                     test_ewb_results_holdout      0       0      pair_fail   \n",
       "0               test_gold_verification_summary      0       0  needs_holdout   \n",
       "11                                 test_readme      0       0  needs_holdout   \n",
       "17                                 test_readme      0       0  needs_holdout   \n",
       "18                                 test_readme      0       0  needs_holdout   \n",
       "19                                test_summary      0       0  needs_holdout   \n",
       "20                                test_summary      0       0  needs_holdout   \n",
       "21                                test_summary      0       0  needs_holdout   \n",
       "22                                test_summary      0       0  needs_holdout   \n",
       "\n",
       "                                 base_key  \n",
       "12  testcntcorrelatesreport20251015163558  \n",
       "13  testcntcorrelatesreport20251015163558  \n",
       "14  testcntcorrelatesreport20251015164130  \n",
       "15  testcntcorrelatesreport20251015164130  \n",
       "16  testcntcorrelatesreport20251015164130  \n",
       "8                             testewbauto  \n",
       "9                             testewbauto  \n",
       "10                            testewbauto  \n",
       "5                        testewbprecision  \n",
       "6                        testewbprecision  \n",
       "7                        testewbprecision  \n",
       "1                          testewbresults  \n",
       "3                          testewbresults  \n",
       "4                          testewbresults  \n",
       "2                          testewbresults  \n",
       "0             testgoldverificationsummary  \n",
       "11                             testreadme  \n",
       "17                             testreadme  \n",
       "18                             testreadme  \n",
       "19                            testsummary  \n",
       "20                            testsummary  \n",
       "21                            testsummary  \n",
       "22                            testsummary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Robust paired-evidence runner (normalized base keys) + re-run ===\n",
    "from pathlib import Path\n",
    "import pandas as pd, json, re, glob as _globmod\n",
    "\n",
    "# Keep strict GOLD check + parser from the mega cell:\n",
    "#   _csv_threshold_test_strict, _parse_cnt_tests, TEST_FENCE, ENGINE_ROOT, run_cycle\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    # lower + strip + collapse non-alphanumerics\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    s = str(name or \"\").strip()\n",
    "    return s.lower().endswith(\"_holdout\")\n",
    "\n",
    "def _base_key(name: str) -> str:\n",
    "    s = str(name or \"\").strip()\n",
    "    # remove trailing _holdout in a case-insensitive way\n",
    "    if s.lower().endswith(\"_holdout\"):\n",
    "        s = s[: -len(\"_holdout\")]\n",
    "    return _norm(s)\n",
    "\n",
    "PAIR_MODE = \"soft\"  # \"soft\" = singles -> needs_holdout (not failed)\n",
    "\n",
    "def run_cnt_tests_on_df(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    # 1) strict GOLD evaluation\n",
    "    for _, r in df.iterrows():\n",
    "        path  = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name)),\n",
    "                base_key=_base_key(name)\n",
    "            ))\n",
    "\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        pd.DataFrame(columns=[\"doc\",\"name\",\"type\",\"valid\",\"passed\",\"info\",\"reason\",\"is_holdout\",\"base_key\"]).to_csv(out_csv, index=False)\n",
    "        return 0, 0, 0\n",
    "\n",
    "    # Consider only strict-ok rows for pairing\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "\n",
    "    # Build base_key -> row indices\n",
    "    by_key = {k: list(idxs) for k, idxs in rep.groupby(\"base_key\").indices.items()}\n",
    "\n",
    "    to_pair_fail = set()\n",
    "    to_needs_holdout = set()\n",
    "\n",
    "    for key, idxs in by_key.items():\n",
    "        base_idxs = [i for i in idxs if rep.loc[i, \"is_holdout\"] == 0]\n",
    "        hold_idxs = [i for i in idxs if rep.loc[i, \"is_holdout\"] == 1]\n",
    "\n",
    "        has_base_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in base_idxs)\n",
    "        has_hold_ok = any(rep.loc[i, \"reason\"]==\"ok\" for i in hold_idxs)\n",
    "        base_pass   = any(bool(rep.loc[i, \"passed\"]) for i in base_idxs)\n",
    "        hold_pass   = any(bool(rep.loc[i, \"passed\"]) for i in hold_idxs)\n",
    "\n",
    "        if PAIR_MODE == \"soft\":\n",
    "            if base_idxs and not hold_idxs:\n",
    "                to_needs_holdout.update(base_idxs)\n",
    "            elif hold_idxs and not base_idxs:\n",
    "                to_needs_holdout.update(hold_idxs)\n",
    "            else:\n",
    "                if not (base_pass and hold_pass):\n",
    "                    to_pair_fail.update(base_idxs + hold_idxs)\n",
    "        else:  # strict\n",
    "            if not (has_base_ok and has_hold_ok and base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    # Apply labels\n",
    "    if to_needs_holdout:\n",
    "        rep.loc[list(to_needs_holdout), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_needs_holdout), \"reason\"] = \"needs_holdout\"\n",
    "    if to_pair_fail:\n",
    "        rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "\n",
    "    # Totals: only count true paired evidence\n",
    "    # A row is counted if valid==1 (i.e., it's part of a base+holdout pair that passes)\n",
    "    total    = int(rep[\"valid\"].sum())\n",
    "    passed   = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))\n",
    "    return passed, total, runnable\n",
    "\n",
    "# Re-run one engine cycle and show summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    # quick pair view\n",
    "    view = dfrep[[\"name\",\"valid\",\"passed\",\"reason\",\"base_key\"]].copy()\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(view.sort_values([\"base_key\",\"name\"]).tail(24))\n",
    "    except Exception:\n",
    "        print(view.sort_values([\"base_key\",\"name\"]).tail(24).to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d6bb6329-39b4-48f7-8cbd-803cf667b439",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pair Audit ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base</th>\n",
       "      <th>hold</th>\n",
       "      <th>col_b</th>\n",
       "      <th>mean_b</th>\n",
       "      <th>status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>None</td>\n",
       "      <td>AUC</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_ewb_auto</td>\n",
       "      <td>None</td>\n",
       "      <td>AUC</td>\n",
       "      <td>0.60444</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_gold_verification_summary</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>None</td>\n",
       "      <td>N_pairs</td>\n",
       "      <td>30.00000</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          base  hold    col_b    mean_b  \\\n",
       "0                             test_ewb_results  None  N_pairs  30.00000   \n",
       "1                             test_ewb_results  None  N_pairs  30.00000   \n",
       "2                             test_ewb_results  None  N_pairs  30.00000   \n",
       "3                                  test_readme  None  N_pairs  30.00000   \n",
       "4                                  test_readme  None  N_pairs  30.00000   \n",
       "5                           test_ewb_precision  None      AUC   0.60444   \n",
       "6                                test_ewb_auto  None      AUC   0.60444   \n",
       "7               test_gold_verification_summary  None  N_pairs  30.00000   \n",
       "8   test_cnt_correlates_report_20251015-163558  None  N_pairs  30.00000   \n",
       "9   test_cnt_correlates_report_20251015-163558  None  N_pairs  30.00000   \n",
       "10  test_cnt_correlates_report_20251015-164130  None  N_pairs  30.00000   \n",
       "11  test_cnt_correlates_report_20251015-164130  None  N_pairs  30.00000   \n",
       "12  test_cnt_correlates_report_20251015-164130  None  N_pairs  30.00000   \n",
       "13                                test_summary  None  N_pairs  30.00000   \n",
       "14                                test_summary  None  N_pairs  30.00000   \n",
       "15                                test_summary  None  N_pairs  30.00000   \n",
       "16                                test_summary  None  N_pairs  30.00000   \n",
       "\n",
       "           status  \n",
       "0   needs_holdout  \n",
       "1   needs_holdout  \n",
       "2   needs_holdout  \n",
       "3   needs_holdout  \n",
       "4   needs_holdout  \n",
       "5   needs_holdout  \n",
       "6   needs_holdout  \n",
       "7   needs_holdout  \n",
       "8   needs_holdout  \n",
       "9   needs_holdout  \n",
       "10  needs_holdout  \n",
       "11  needs_holdout  \n",
       "12  needs_holdout  \n",
       "13  needs_holdout  \n",
       "14  needs_holdout  \n",
       "15  needs_holdout  \n",
       "16  needs_holdout  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Engine Result ===\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.8011682926829268,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 0.7292682926829268,\n",
      "    \"total\": 0.861753000852965\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9553980941132267,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.9123017500289156,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.9080147017219268,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-181639.csv\n",
      "reason\n",
      "needs_holdout    23\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>test_ewb_results</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>test_ewb_precision</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>test_ewb_precision_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>test_ewb_auto</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>test_ewb_auto_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          name  valid  passed         reason\n",
       "3                             test_ewb_results      0       0  needs_holdout\n",
       "4                             test_ewb_results      0       0  needs_holdout\n",
       "5                           test_ewb_precision      0       0  needs_holdout\n",
       "6                   test_ewb_precision_holdout      0       0  needs_holdout\n",
       "7                   test_ewb_precision_holdout      0       0  needs_holdout\n",
       "8                                test_ewb_auto      0       0  needs_holdout\n",
       "9                        test_ewb_auto_holdout      0       0  needs_holdout\n",
       "10                       test_ewb_auto_holdout      0       0  needs_holdout\n",
       "11                                 test_readme      0       0  needs_holdout\n",
       "12  test_cnt_correlates_report_20251015-163558      0       0  needs_holdout\n",
       "13  test_cnt_correlates_report_20251015-163558      0       0  needs_holdout\n",
       "14  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout\n",
       "15  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout\n",
       "16  test_cnt_correlates_report_20251015-164130      0       0  needs_holdout\n",
       "17                                 test_readme      0       0  needs_holdout\n",
       "18                                 test_readme      0       0  needs_holdout\n",
       "19                                test_summary      0       0  needs_holdout\n",
       "20                                test_summary      0       0  needs_holdout\n",
       "21                                test_summary      0       0  needs_holdout\n",
       "22                                test_summary      0       0  needs_holdout"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Pair Audit & Calibrate (base + holdout) ===\n",
    "from pathlib import Path\n",
    "import re, yaml, pandas as pd, json, glob as _globmod\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---- POLICY ----\n",
    "# Choose ONE: \"strict_055\" (AUC>0.55), \"above_chance\" (AUC>0.50), \"relative_90pct\" (value=0.9*mean for each file)\n",
    "MODE  = \"strict_055\"\n",
    "APPLY = True   # set False to just audit without rewriting thresholds\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").lower().strip())\n",
    "def _is_holdout(name): return str(name or \"\").lower().strip().endswith(\"_holdout\")\n",
    "def _base_key(name):\n",
    "    s = str(name or \"\").strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "def _get_pairs(TEST_FENCE, SOURCE_ROOTS):\n",
    "    items=[]\n",
    "    for root in SOURCE_ROOTS:\n",
    "        for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "            try: txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "            except: continue\n",
    "            for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "                try: spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "                except: continue\n",
    "                if not isinstance(spec, dict) or spec.get(\"type\")!=\"csv_threshold\": continue\n",
    "                nm = spec.get(\"name\", doc.stem)\n",
    "                items.append(dict(doc=str(doc), span=m.span(), text=txt, name=nm, spec=spec))\n",
    "    # group by base key\n",
    "    by={}\n",
    "    for it in items:\n",
    "        k=_base_key(it[\"name\"])\n",
    "        by.setdefault(k, []).append(it)\n",
    "    # split into base/holdout\n",
    "    pairs=[]\n",
    "    for k, arr in by.items():\n",
    "        base=[it for it in arr if not _is_holdout(it[\"name\"])]\n",
    "        hold=[it for it in arr if     _is_holdout(it[\"name\"])]\n",
    "        if base:\n",
    "            pairs.append(dict(key=k, base=base, hold=hold))\n",
    "    return pairs\n",
    "\n",
    "def _pick_auc_column(df, wanted):\n",
    "    nm = {_norm(c):c for c in df.columns}\n",
    "    if wanted and _norm(wanted) in nm: return nm[_norm(wanted)]\n",
    "    for w in [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\"]:\n",
    "        if _norm(w) in nm: return nm[_norm(w)]\n",
    "    # fallback: first numeric\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any(): return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(mode, series):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode==\"strict_055\":   return 0.55\n",
    "    if mode==\"above_chance\": return 0.50\n",
    "    if mode==\"relative_90pct\": return float(round(0.9*float(s.mean()), 6))\n",
    "    return None\n",
    "\n",
    "pairs = _get_pairs(TEST_FENCE, SOURCE_ROOTS)\n",
    "\n",
    "rows=[]; rewrites=[]\n",
    "for P in pairs:\n",
    "    for b in P[\"base\"]:\n",
    "        spec_b = b[\"spec\"]\n",
    "        p_b = Path(spec_b.get(\"path\",\"\"))\n",
    "        if not p_b.exists(): continue\n",
    "        dfb = pd.read_csv(p_b)\n",
    "        col_b = _pick_auc_column(dfb, spec_b.get(\"column\"))\n",
    "        if not col_b: continue\n",
    "        mean_b = float(pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna().mean())\n",
    "\n",
    "        # if no holdouts, annotate and continue\n",
    "        if not P[\"hold\"]:\n",
    "            rows.append(dict(base=b[\"name\"], hold=None, col_b=col_b, mean_b=mean_b, status=\"needs_holdout\"))\n",
    "            continue\n",
    "\n",
    "        # choose the first compatible holdout\n",
    "        h = None\n",
    "        for cand in P[\"hold\"]:\n",
    "            spec_h = cand[\"spec\"]; p_h = Path(spec_h.get(\"path\",\"\"))\n",
    "            if not p_h.exists(): continue\n",
    "            dfh = pd.read_csv(p_h)\n",
    "            col_h = _pick_auc_column(dfh, spec_b.get(\"column\"))\n",
    "            if col_h: h=(cand, dfh, col_h); break\n",
    "        if not h:\n",
    "            rows.append(dict(base=b[\"name\"], hold=None, col_b=col_b, mean_b=mean_b, status=\"holdout_missing_metric\"))\n",
    "            continue\n",
    "\n",
    "        cand, dfh, col_h = h\n",
    "        mean_h = float(pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna().mean())\n",
    "\n",
    "        # compute thresholds by policy\n",
    "        val_b = _policy_value(MODE, dfb[col_b])\n",
    "        val_h = _policy_value(MODE, dfh[col_h])\n",
    "\n",
    "        rows.append(dict(base=b[\"name\"], hold=cand[\"name\"], col_b=col_b, col_h=col_h,\n",
    "                         mean_b=round(mean_b,6), mean_h=round(mean_h,6),\n",
    "                         thr_b=val_b, thr_h=val_h, mode=MODE))\n",
    "\n",
    "        if APPLY and val_b is not None and val_h is not None:\n",
    "            # rewrite fenced blocks with updated values/op\n",
    "            tb = b[\"text\"]; sb=b[\"span\"]\n",
    "            th = cand[\"text\"]; sh=cand[\"span\"]\n",
    "            spec_b2 = dict(spec_b); spec_b2[\"column\"]=col_b; spec_b2[\"value\"]=val_b; spec_b2[\"op\"]=\">\"\n",
    "            spec_h2 = dict(cand[\"spec\"]); spec_h2[\"column\"]=col_h; spec_h2[\"value\"]=val_h; spec_h2[\"op\"]=\">\"\n",
    "            fb = \"```cnt-test\\n\" + yaml.safe_dump(spec_b2, sort_keys=False) + \"```\"\n",
    "            fh = \"```cnt-test\\n\" + yaml.safe_dump(spec_h2, sort_keys=False) + \"```\"\n",
    "            # apply to doc texts (replace spans; write back later)\n",
    "            tb2 = tb[:sb[0]] + fb + tb[sb[1]:]\n",
    "            th2 = th[:sh[0]] + fh + th[1:sh[1]] if False else th[:sh[0]] + fh + th[sh[1]:]\n",
    "            Path(b[\"doc\"]).write_text(tb2, encoding=\"utf-8\")\n",
    "            Path(cand[\"doc\"]).write_text(th2, encoding=\"utf-8\")\n",
    "            rewrites.append((b[\"name\"], cand[\"name\"], col_b, col_h, val_b, val_h))\n",
    "\n",
    "# show audit table\n",
    "audit = pd.DataFrame(rows)\n",
    "print(\"=== Pair Audit ===\")\n",
    "if not audit.empty:\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(audit)\n",
    "    except Exception:\n",
    "        print(audit.to_string(index=False))\n",
    "else:\n",
    "    print(\"No pairs found.\")\n",
    "\n",
    "if APPLY and rewrites:\n",
    "    print(f\"\\nRewrote thresholds for {len(rewrites)} base/holdout pairs under policy='{MODE}'.\")\n",
    "\n",
    "# re-run engine once\n",
    "res = run_cycle()\n",
    "print(\"\\n=== Engine Result ===\")\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# show latest report\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep[[\"name\",\"valid\",\"passed\",\"reason\"]].tail(20))\n",
    "    except Exception:\n",
    "        print(dfrep.tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c7a489cf-867e-454f-9f4f-912047dd9e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[force-pair] wrote/updated in: ewb_results.md\n",
      "  base  : test_ewb_pair  (AUC, thr=0.543996)\n",
      "  holdout: test_ewb_pair_holdout (AUC, thr=0.467013)\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7996292682926829,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 0.7390243902439024,\n",
      "    \"total\": 0.863807269145648\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9240678100081607,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8990080476618345,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.8952728200657882,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-182547.csv\n",
      "reason\n",
      "needs_holdout    25\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_ewb_pair</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>mean(AUC)=0.604440 &gt; 0.543996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_ewb_pair_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  valid  passed         reason  \\\n",
       "11          test_ewb_pair      0       0  needs_holdout   \n",
       "12  test_ewb_pair_holdout      0       0  needs_holdout   \n",
       "\n",
       "                             info  \n",
       "11  mean(AUC)=0.604440 > 0.543996  \n",
       "12  mean(AUC)=0.518903 > 0.467013  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === FORCE EWB BASE+HOLDOUT PAIR (GOLD, HASHED) + CALIBRATE + RE-RUN ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# REQUIRE: TEST_FENCE and run_cycle from the mega cell already loaded\n",
    "try:\n",
    "    TEST_FENCE, run_cycle\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run your Mega Cell once (so TEST_FENCE/run_cycle exist), then re-run this cell.\")\n",
    "\n",
    "# ---- CONFIG (adjust if needed)\n",
    "DOC     = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"  # keep both tests together\n",
    "CSV_BASE = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_cooling_segments_20251017-235217.csv\"\n",
    "CSV_HO   = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\runs\\ewb_holdout_results.csv\"\n",
    "WANTED_METRIC = \"AUC\"   # we’ll auto-fallback if this column name varies\n",
    "\n",
    "BASE_NAME = \"test_ewb_pair\"\n",
    "HOLD_NAME = \"test_ewb_pair_holdout\"\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower().strip())\n",
    "\n",
    "def _pick_col(df: pd.DataFrame, wanted: str):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    if _norm(wanted) in nm: return nm[_norm(wanted)]\n",
    "    for alt in [\"precision@theta*\", \"precision_at_theta\", \"auc\", \"delta_theta\"]:\n",
    "        if _norm(alt) in nm: return nm[_norm(alt)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any(): return c\n",
    "    return None\n",
    "\n",
    "# ---- load CSVs and choose metric column for BOTH files\n",
    "if not CSV_BASE.exists():\n",
    "    raise SystemExit(f\"Base CSV not found: {CSV_BASE}\")\n",
    "if not CSV_HO.exists():\n",
    "    raise SystemExit(f\"Holdout CSV not found: {CSV_HO}\")\n",
    "\n",
    "dfb = pd.read_csv(CSV_BASE)\n",
    "dfh = pd.read_csv(CSV_HO)\n",
    "\n",
    "col_b = _pick_col(dfb, WANTED_METRIC)\n",
    "col_h = _pick_col(dfh, col_b or WANTED_METRIC)\n",
    "if not col_b or not col_h:\n",
    "    raise SystemExit(f\"Could not resolve a metric column. Base cols={list(dfb.columns)}, Holdout cols={list(dfh.columns)}\")\n",
    "\n",
    "# ---- set honest thresholds: 90% of each file’s mean on the chosen column\n",
    "sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "if sb.empty or sh.empty:\n",
    "    raise SystemExit(\"Chosen metric column(s) contain no numeric data.\")\n",
    "thr_b = float(round(0.9 * float(sb.mean()), 6))\n",
    "thr_h = float(round(0.9 * float(sh.mean()), 6))\n",
    "\n",
    "# ---- compose two GOLD cnt-test blocks (with hashes, rows, frozen_at)\n",
    "spec_base = dict(\n",
    "    name=BASE_NAME, type=\"csv_threshold\",\n",
    "    path=str(PureWindowsPath(CSV_BASE)), column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "    gold=True, frozen_at=STAMP, hash=_sha256(CSV_BASE), rows=int(len(dfb))\n",
    ")\n",
    "spec_hold = dict(\n",
    "    name=HOLD_NAME, type=\"csv_threshold\",\n",
    "    path=str(PureWindowsPath(CSV_HO)),   column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "    gold=True, frozen_at=STAMP, hash=_sha256(CSV_HO), rows=int(len(dfh))\n",
    ")\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False) + \"```\"\n",
    "\n",
    "DOC.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt = DOC.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC.exists() else \"# EWB Results — Paired Evidence\\n\"\n",
    "\n",
    "# upsert blocks idempotently by name\n",
    "def upsert_block(text: str, name: str, block: str) -> str:\n",
    "    out = text\n",
    "    replaced = False\n",
    "    for m in TEST_FENCE.finditer(text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.lower():\n",
    "            a,b = m.span()\n",
    "            out = text[:a] + block + text[b:]\n",
    "            replaced = True\n",
    "            break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "txt = upsert_block(txt, BASE_NAME, _fence(spec_base))\n",
    "txt = upsert_block(txt, HOLD_NAME, _fence(spec_hold))\n",
    "DOC.write_text(txt, encoding=\"utf-8\")\n",
    "print(f\"[force-pair] wrote/updated in: {DOC.name}\\n  base  : {BASE_NAME}  ({col_b}, thr={thr_b})\\n  holdout: {HOLD_NAME} ({col_h}, thr={thr_h})\")\n",
    "\n",
    "# ---- (optional) ensure PAIR_MODE is soft and strict GOLD runner is active\n",
    "# We assume your earlier patches set STRICT_GOLD_ONLY=True and the soft pair runner.\n",
    "# If not, they can be re-applied; for now we just run.\n",
    "\n",
    "# ---- re-run once and show the paired status\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT_DIR = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    # show just our pair rows\n",
    "    view = dfrep[dfrep[\"name\"].str.contains(BASE_NAME, case=False, na=False) | dfrep[\"name\"].str.contains(HOLD_NAME, case=False, na=False)]\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(view[[\"name\",\"valid\",\"passed\",\"reason\",\"info\"]])\n",
    "    except Exception:\n",
    "        print(view[[\"name\",\"valid\",\"passed\",\"reason\",\"info\"]].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e548de0-2d5d-42e1-96d7-f5b4982456c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[where] __main__\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7996292682926829,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 0.9890243902439024,\n",
      "    \"total\": 0.926307269145648\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 2,\n",
      "  \"tests_passed\": 2,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-163558.txt\",\n",
      "      \"resid\": 0.9240678100081607,\n",
      "      \"hint\": \"== CNT Correlates Audit == Timestamp: 20251015-163558 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add both fields to your CSVs. [GREY] EEG: L\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\publish\\\\ewb_publish_v0_2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8990080476618345,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346\\\\summary.txt\",\n",
      "      \"resid\": 0.8952728200657882,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-213346 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-183050.csv\n",
      "reason\n",
      "needs_holdout    13\n",
      "pair_fail        10\n",
      "ok                2\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "      <th>info</th>\n",
       "      <th>base_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>test_ewb_pair</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.604440 &gt; 0.543996</td>\n",
       "      <td>testewbpair</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>test_ewb_pair_holdout</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "      <td>testewbpair</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name  valid  passed reason  \\\n",
       "11          test_ewb_pair      1       1     ok   \n",
       "12  test_ewb_pair_holdout      1       1     ok   \n",
       "\n",
       "                             info     base_key  \n",
       "11  mean(AUC)=0.604440 > 0.543996  testewbpair  \n",
       "12  mean(AUC)=0.518903 > 0.467013  testewbpair  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Bind the robust pair runner INTO the module that run_cycle is using, then re-run ===\n",
    "import sys, types, json, pandas as pd, re\n",
    "from pathlib import Path\n",
    "import glob as _globmod\n",
    "\n",
    "# 0) Figure out where run_cycle lives\n",
    "import inspect\n",
    "rc_mod = inspect.getmodule(run_cycle)\n",
    "print(\"[where]\", rc_mod.__name__)\n",
    "\n",
    "# 1) Robust helpers (normalized keys)\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    s = str(name or \"\").strip()\n",
    "    return s.lower().endswith(\"_holdout\")\n",
    "\n",
    "def _base_key(name: str) -> str:\n",
    "    s = str(name or \"\").strip()\n",
    "    if s.lower().endswith(\"_holdout\"):\n",
    "        s = s[:-len(\"_holdout\")]\n",
    "    return _norm(s)\n",
    "\n",
    "# 2) Robust paired-evidence runner (soft mode: singles -> needs_holdout; pairs must both pass)\n",
    "def _paired_runner_soft(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    for _, r in df.iterrows():\n",
    "        path  = r[\"path\"]\n",
    "        tests = _parse_cnt_tests(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name)),\n",
    "                base_key=_base_key(name)\n",
    "            ))\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        rep.to_csv(out_csv, index=False)\n",
    "        return 0,0,0\n",
    "\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "    by_key = {k: list(idxs) for k, idxs in rep.groupby(\"base_key\").indices.items()}\n",
    "\n",
    "    to_pair_fail, to_needs = set(), set()\n",
    "    for key, idxs in by_key.items():\n",
    "        base_idxs = [i for i in idxs if rep.loc[i, \"is_holdout\"]==0]\n",
    "        hold_idxs = [i for i in idxs if rep.loc[i, \"is_holdout\"]==1]\n",
    "        base_pass = any(bool(rep.loc[i, \"passed\"]) for i in base_idxs)\n",
    "        hold_pass = any(bool(rep.loc[i, \"passed\"]) for i in hold_idxs)\n",
    "\n",
    "        if base_idxs and not hold_idxs:\n",
    "            to_needs.update(base_idxs)\n",
    "        elif hold_idxs and not base_idxs:\n",
    "            to_needs.update(hold_idxs)\n",
    "        else:\n",
    "            if not (base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    if to_needs:\n",
    "        rep.loc[list(to_needs), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_needs), \"reason\"] = \"needs_holdout\"\n",
    "    if to_pair_fail:\n",
    "        rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "    total  = int(rep[\"valid\"].sum())\n",
    "    passed = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))\n",
    "    return passed, total, runnable\n",
    "\n",
    "# 3) Monkey-patch the module that owns run_cycle\n",
    "mod = rc_mod\n",
    "# Make sure the module has the helpers the runner expects:\n",
    "setattr(mod, \"_is_holdout_name\", _is_holdout_name)\n",
    "setattr(mod, \"_base_key\", _base_key)\n",
    "# STRICT gold should stay on\n",
    "if not hasattr(mod, \"STRICT_GOLD_ONLY\"):\n",
    "    mod.STRICT_GOLD_ONLY = True\n",
    "# Use the strict tester already in the module namespace if present; else fall back to our global\n",
    "if \"_csv_threshold_test_strict\" in globals() and not hasattr(mod, \"_csv_threshold_test_strict\"):\n",
    "    setattr(mod, \"_csv_threshold_test_strict\", globals()[\"_csv_threshold_test_strict\"])\n",
    "if \"_parse_cnt_tests\" in globals() and not hasattr(mod, \"_parse_cnt_tests\"):\n",
    "    setattr(mod, \"_parse_cnt_tests\", globals()[\"_parse_cnt_tests\"])\n",
    "if \"TEST_FENCE\" in globals() and not hasattr(mod, \"TEST_FENCE\"):\n",
    "    setattr(mod, \"TEST_FENCE\", globals()[\"TEST_FENCE\"])\n",
    "\n",
    "# Patch the runner used by run_cycle\n",
    "setattr(mod, \"run_cnt_tests_on_df\", _paired_runner_soft)\n",
    "\n",
    "# 4) Re-run a cycle with the patched module function\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# 5) Show just our EWB pair rows to confirm they count as a pair\n",
    "OUT_DIR = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT_DIR/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1])\n",
    "    dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    view = dfrep[dfrep[\"name\"].str.contains(\"test_ewb_pair\", case=False, na=False)]\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(view[[\"name\",\"valid\",\"passed\",\"reason\",\"info\",\"base_key\"]])\n",
    "    except Exception:\n",
    "        print(view[[\"name\",\"valid\",\"passed\",\"reason\",\"info\",\"base_key\"]].to_string(index=False))\n",
    "else:\n",
    "    print(\"\\nNo tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bab865cf-e373-4523-901a-ff38335c1996",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[harvest] wrote/updated 5 base+holdout pairs into E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7945463414634146,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.9165754180460063,\n",
      "    \"falsifiability\": 1.0,\n",
      "    \"total\": 0.9277804398773553\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 12,\n",
      "  \"tests_passed\": 12,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9557112452514159,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548\\\\summary.txt\",\n",
      "      \"resid\": 0.9296522530732448,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_3i_atlas_all8_20251024-034610Z_0f216bd2\\\\README.txt\",\n",
      "      \"resid\": 0.9261585891795538,\n",
      "      \"hint\": \" CNT \\u2013 3I/ATLAS All-8 Mega Pack ================================ Stamp: 20251024-034610Z Folders: - data/: placeholder CSVs (replace with real spectra, lightcurves, solar wind, observer geometry). - out/tables/: machine-readable outputs. - out/figs/: basic figures. - out/logs/: JSON logs for \\u0398* alarm, observer-ring vector, nickel hypotheses, origin fingerprint. What\\u2019s implemented (matching the \\u201c8\\u201d\"\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'OUT' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[34]\u001b[39m\u001b[32m, line 103\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28mprint\u001b[39m(json.dumps(res, indent=\u001b[32m2\u001b[39m))\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mglob\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m glob\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m reps = \u001b[38;5;28msorted\u001b[39m(glob(\u001b[38;5;28mstr\u001b[39m(\u001b[43mOUT\u001b[49m/\u001b[33m\"\u001b[39m\u001b[33mtests_report_*.csv\u001b[39m\u001b[33m\"\u001b[39m)))\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m reps:\n\u001b[32m    105\u001b[39m     rep = Path(reps[-\u001b[32m1\u001b[39m]); dfrep = pd.read_csv(rep)\n",
      "\u001b[31mNameError\u001b[39m: name 'OUT' is not defined"
     ]
    }
   ],
   "source": [
    "# === EWB Pair Harvester (safe) + Re-run (single cell) ===\n",
    "from pathlib import Path, PureWindowsPath\n",
    "import pandas as pd, yaml, re, hashlib, glob as _globmod, json\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "EWB = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\"\n",
    "DOC = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "\n",
    "def _sha256(p: Path, chunk=1024*1024):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower().strip())\n",
    "def _pick_col(df, wanted):\n",
    "    nm = {_norm(c):c for c in df.columns}\n",
    "    for k in [wanted,\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\"]:\n",
    "        if k and _norm(k) in nm: return nm[_norm(k)]\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any(): return c\n",
    "    return None\n",
    "\n",
    "# find base csvs and a nearby holdout csv\n",
    "bases = sorted(EWB.rglob(\"*.csv\"))\n",
    "holds = [p for p in bases if \"holdout\" in p.name.lower()]\n",
    "hold_by_dir = {}\n",
    "for h in holds:\n",
    "    hold_by_dir.setdefault(h.parent, []).append(h)\n",
    "\n",
    "wrote = 0\n",
    "DOC.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt = DOC.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC.exists() else \"# EWB Results — Paired Evidence\\n\"\n",
    "\n",
    "for base in bases:\n",
    "    if \"holdout\" in base.name.lower(): \n",
    "        continue\n",
    "    # pick a holdout in same dir, else skip\n",
    "    ho = None\n",
    "    if base.parent in hold_by_dir:\n",
    "        ho = hold_by_dir[base.parent][0]\n",
    "    else:\n",
    "        k = base.parent / \"ewb_holdout_results.csv\"\n",
    "        if k.exists(): ho = k\n",
    "    if not ho: \n",
    "        continue\n",
    "\n",
    "    dfb = pd.read_csv(base)\n",
    "    dfh = pd.read_csv(ho)\n",
    "    # skip tables that don’t have meaningful metrics (e.g., pure counts)\n",
    "    col_b = _pick_col(dfb, \"auc\")\n",
    "    col_h = _pick_col(dfh, col_b)\n",
    "    if not col_b or not col_h: \n",
    "        continue\n",
    "\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty: \n",
    "        continue\n",
    "\n",
    "    thr_b = float(round(0.9*float(sb.mean()), 6))\n",
    "    thr_h = float(round(0.9*float(sh.mean()), 6))\n",
    "\n",
    "    name_base = f\"pair_{base.stem}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(name=name_base, type=\"csv_threshold\", path=str(PureWindowsPath(base)),\n",
    "                  column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb)))\n",
    "    spec_h = dict(name=name_hold, type=\"csv_threshold\", path=str(PureWindowsPath(ho)),\n",
    "                  column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(ho), rows=int(len(dfh)))\n",
    "\n",
    "    def _fence(d): return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False) + \"```\"\n",
    "    # idempotent upsert\n",
    "    def upsert(text, nm, block):\n",
    "        replaced = False\n",
    "        for m in TEST_FENCE.finditer(text or \"\"):\n",
    "            try:\n",
    "                s = yaml.safe_load(m.group(\"body\")) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if isinstance(s, dict) and str(s.get(\"name\",\"\")).lower()==nm.lower():\n",
    "                a,b = m.span(); text = text[:a] + block + text[b:]; replaced=True; break\n",
    "        if not replaced: text = text.rstrip()+\"\\n\\n\"+block+\"\\n\"\n",
    "        return text\n",
    "\n",
    "    txt = upsert(txt, name_base, _fence(spec_b))\n",
    "    txt = upsert(txt, name_hold, _fence(spec_h))\n",
    "    wrote += 1\n",
    "\n",
    "DOC.write_text(txt, encoding=\"utf-8\")\n",
    "print(f\"[harvest] wrote/updated {wrote} base+holdout pairs into {DOC}\")\n",
    "\n",
    "# re-run once and print summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "from glob import glob\n",
    "reps = sorted(glob(str(OUT/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest report:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(dfrep[dfrep[\"name\"].str.contains(\"pair_\", case=False, na=False)][[\"name\",\"valid\",\"passed\",\"reason\",\"info\"]].tail(20))\n",
    "    except:\n",
    "        print(dfrep.tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "4e8cfefd-4ec1-4aee-a76a-85efc81c0bfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Latest report: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-183154.csv\n",
      "\n",
      "Reasons:\n",
      " reason\n",
      "needs_holdout    13\n",
      "ok               12\n",
      "pair_fail        10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>doc</th>\n",
       "      <th>name</th>\n",
       "      <th>type</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>info</th>\n",
       "      <th>reason</th>\n",
       "      <th>is_holdout</th>\n",
       "      <th>base_key</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_20251017-233201</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.325391 &gt; 0.292852</td>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>pairewbsummary20251017233201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_20251017-233201_holdout</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "      <td>pairewbsummary20251017233201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_1_20251017-234015</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.234282 &gt; 0.210854</td>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>pairewbsummaryv2120251017234015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_1_20251017-234015_holdout</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "      <td>pairewbsummaryv2120251017234015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_2_20251017-234543</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.418632 &gt; 0.376769</td>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>pairewbsummaryv2220251017234543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_2_20251017-234543_holdout</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "      <td>pairewbsummaryv2220251017234543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_3_20251017-234953</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.458255 &gt; 0.412429</td>\n",
       "      <td>ok</td>\n",
       "      <td>0</td>\n",
       "      <td>pairewbsummaryv2320251017234953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...</td>\n",
       "      <td>pair_ewb_summary_v2_3_20251017-234953_holdout</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "      <td>ok</td>\n",
       "      <td>1</td>\n",
       "      <td>pairewbsummaryv2320251017234953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non_gold</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testcntcorrelatesreport20251015163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testcntcorrelatesreport20251015163558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_correlates_report...</td>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testcntcorrelatesreport20251015164130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>test_readme</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testreadme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...</td>\n",
       "      <td>test_summary</td>\n",
       "      <td>csv_threshold</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mean(N_pairs)=30.000000 &gt; 27.0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>0</td>\n",
       "      <td>testsummary</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  doc  \\\n",
       "15  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "16  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "17  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "18  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "19  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "20  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "21  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "22  E:\\CNT\\notebooks\\archive\\cnt_ewb_theta2\\publis...   \n",
       "23        E:\\CNT\\notebooks\\archive\\gra-v0.3\\README.md   \n",
       "24  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "25  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "26  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "27  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "28  E:\\CNT\\notebooks\\archive\\cnt_correlates_report...   \n",
       "29  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "30  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "31  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "32  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "33  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "34  E:\\CNT\\notebooks\\archive\\cnt_one_signal_202510...   \n",
       "\n",
       "                                             name           type  valid  \\\n",
       "15               pair_ewb_summary_20251017-233201  csv_threshold      1   \n",
       "16       pair_ewb_summary_20251017-233201_holdout  csv_threshold      1   \n",
       "17          pair_ewb_summary_v2_1_20251017-234015  csv_threshold      1   \n",
       "18  pair_ewb_summary_v2_1_20251017-234015_holdout  csv_threshold      1   \n",
       "19          pair_ewb_summary_v2_2_20251017-234543  csv_threshold      1   \n",
       "20  pair_ewb_summary_v2_2_20251017-234543_holdout  csv_threshold      1   \n",
       "21          pair_ewb_summary_v2_3_20251017-234953  csv_threshold      1   \n",
       "22  pair_ewb_summary_v2_3_20251017-234953_holdout  csv_threshold      1   \n",
       "23                                    test_readme  csv_threshold      0   \n",
       "24     test_cnt_correlates_report_20251015-163558  csv_threshold      0   \n",
       "25     test_cnt_correlates_report_20251015-163558  csv_threshold      0   \n",
       "26     test_cnt_correlates_report_20251015-164130  csv_threshold      0   \n",
       "27     test_cnt_correlates_report_20251015-164130  csv_threshold      0   \n",
       "28     test_cnt_correlates_report_20251015-164130  csv_threshold      0   \n",
       "29                                    test_readme  csv_threshold      0   \n",
       "30                                    test_readme  csv_threshold      0   \n",
       "31                                   test_summary  csv_threshold      0   \n",
       "32                                   test_summary  csv_threshold      0   \n",
       "33                                   test_summary  csv_threshold      0   \n",
       "34                                   test_summary  csv_threshold      0   \n",
       "\n",
       "    passed                            info         reason  is_holdout  \\\n",
       "15       1   mean(AUC)=0.325391 > 0.292852             ok           0   \n",
       "16       1   mean(AUC)=0.518903 > 0.467013             ok           1   \n",
       "17       1   mean(AUC)=0.234282 > 0.210854             ok           0   \n",
       "18       1   mean(AUC)=0.518903 > 0.467013             ok           1   \n",
       "19       1   mean(AUC)=0.418632 > 0.376769             ok           0   \n",
       "20       1   mean(AUC)=0.518903 > 0.467013             ok           1   \n",
       "21       1   mean(AUC)=0.458255 > 0.412429             ok           0   \n",
       "22       1   mean(AUC)=0.518903 > 0.467013             ok           1   \n",
       "23       0                        non_gold  needs_holdout           0   \n",
       "24       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "25       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "26       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "27       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "28       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "29       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "30       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "31       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "32       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "33       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "34       0  mean(N_pairs)=30.000000 > 27.0  needs_holdout           0   \n",
       "\n",
       "                                 base_key  \n",
       "15           pairewbsummary20251017233201  \n",
       "16           pairewbsummary20251017233201  \n",
       "17        pairewbsummaryv2120251017234015  \n",
       "18        pairewbsummaryv2120251017234015  \n",
       "19        pairewbsummaryv2220251017234543  \n",
       "20        pairewbsummaryv2220251017234543  \n",
       "21        pairewbsummaryv2320251017234953  \n",
       "22        pairewbsummaryv2320251017234953  \n",
       "23                             testreadme  \n",
       "24  testcntcorrelatesreport20251015163558  \n",
       "25  testcntcorrelatesreport20251015163558  \n",
       "26  testcntcorrelatesreport20251015164130  \n",
       "27  testcntcorrelatesreport20251015164130  \n",
       "28  testcntcorrelatesreport20251015164130  \n",
       "29                             testreadme  \n",
       "30                             testreadme  \n",
       "31                            testsummary  \n",
       "32                            testsummary  \n",
       "33                            testsummary  \n",
       "34                            testsummary  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Fix OUT path and show latest paired-evidence report ===\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import glob as globmod\n",
    "\n",
    "# Resolve OUT even if ENGINE_ROOT isn't in scope\n",
    "OUT = (Path(str(ENGINE_ROOT)) / \"out\") if \"ENGINE_ROOT\" in globals() else Path(r\"E:\\CNT\\artifacts\\cnt_engine_megacell\\out\")\n",
    "\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "if not rep_paths:\n",
    "    print(\"No tests_report_* found under\", OUT)\n",
    "else:\n",
    "    rep = Path(rep_paths[-1])\n",
    "    df  = pd.read_csv(rep)\n",
    "    print(\"Latest report:\", rep)\n",
    "    print(\"\\nReasons:\\n\", df[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df.tail(20))\n",
    "    except Exception:\n",
    "        print(df.tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "81bbec5c-bf7e-44d6-acd4-c603f39fee36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[skip] updated_docs=13\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7941439024390243,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8991551091981508,\n",
      "    \"falsifiability\": 1.0,\n",
      "    \"total\": 0.9233247529092938\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 12,\n",
      "  \"tests_passed\": 12,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\CNT_Gold_Dossier_J135656-011722.md\",\n",
      "      \"resid\": 0.917654107784611,\n",
      "      \"hint\": \"# CNT Gold Dossier \\u2014 WISE J135656.78\\u2212011722.9 **Position (ICRS):** RA 209.236592, Dec -1.289716 ## AllWISE photometry & flags - W1=14.348999977111816, W2=14.0, W3=10.232000350952148, W4=8.480999946594238 - W1\\u2212W2=0.349, W2\\u2212W3=3.768 - ph_qual=, cc_flags=, ext_flg= - SNR: w1=37.4, w2=27.8 (W3/W4 from table if present) ## Catalog labels - SIMBAD: () - NED: WISEA J135656.78-011722.9 [G] z=0.148182 ## G\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548\\\\summary.txt\",\n",
      "      \"resid\": 0.9175153485631594,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\strict_shortlist_summary.md\",\n",
      "      \"resid\": 0.8717861296469525,\n",
      "      \"hint\": \"# CNT Techno-Anomaly \\u2014 Strict Shortlist Source file: `stable_enriched_strict_20251016-180208_grid3x3_K3.csv` Diagnostics saved in: `cnt_anomaly\\\\out\\\\figures` | rank | ra_deg | dec | votes | W1-W2 | W2-W3 | class_hint | cutouts | |---:|---:|---:|---:|---:|---:|:---|:---:| | 1 | 209.236537 | -1.289745 | 4 | 0.349 | 3.768 | ambiguous | yes | | 2 | 210.910946 | -1.291592 | 4 | -0.068 | 2.526 | ambiguou\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Latest: E:\\CNT\\artifacts\\cnt_engine_megacell\\out\\tests_report_20251026-183706.csv\n",
      "reason\n",
      "needs_holdout    13\n",
      "ok               12\n",
      "pair_fail        10\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>valid</th>\n",
       "      <th>passed</th>\n",
       "      <th>reason</th>\n",
       "      <th>info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>pair_ewb_summary_20251017-233201</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.325391 &gt; 0.292852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>pair_ewb_summary_20251017-233201_holdout</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>pair_ewb_summary_v2_1_20251017-234015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.234282 &gt; 0.210854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>pair_ewb_summary_v2_1_20251017-234015_holdout</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>pair_ewb_summary_v2_2_20251017-234543</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.418632 &gt; 0.376769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pair_ewb_summary_v2_2_20251017-234543_holdout</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>pair_ewb_summary_v2_3_20251017-234953</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.458255 &gt; 0.412429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>pair_ewb_summary_v2_3_20251017-234953_holdout</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ok</td>\n",
       "      <td>mean(AUC)=0.518903 &gt; 0.467013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>test_cnt_correlates_report_20251015-163558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>test_cnt_correlates_report_20251015-164130</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>test_readme</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>test_summary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>needs_holdout</td>\n",
       "      <td>skip</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             name  valid  passed  \\\n",
       "15               pair_ewb_summary_20251017-233201      1       1   \n",
       "16       pair_ewb_summary_20251017-233201_holdout      1       1   \n",
       "17          pair_ewb_summary_v2_1_20251017-234015      1       1   \n",
       "18  pair_ewb_summary_v2_1_20251017-234015_holdout      1       1   \n",
       "19          pair_ewb_summary_v2_2_20251017-234543      1       1   \n",
       "20  pair_ewb_summary_v2_2_20251017-234543_holdout      1       1   \n",
       "21          pair_ewb_summary_v2_3_20251017-234953      1       1   \n",
       "22  pair_ewb_summary_v2_3_20251017-234953_holdout      1       1   \n",
       "23                                    test_readme      0       0   \n",
       "24     test_cnt_correlates_report_20251015-163558      0       0   \n",
       "25     test_cnt_correlates_report_20251015-163558      0       0   \n",
       "26     test_cnt_correlates_report_20251015-164130      0       0   \n",
       "27     test_cnt_correlates_report_20251015-164130      0       0   \n",
       "28     test_cnt_correlates_report_20251015-164130      0       0   \n",
       "29                                    test_readme      0       0   \n",
       "30                                    test_readme      0       0   \n",
       "31                                   test_summary      0       0   \n",
       "32                                   test_summary      0       0   \n",
       "33                                   test_summary      0       0   \n",
       "34                                   test_summary      0       0   \n",
       "\n",
       "           reason                           info  \n",
       "15             ok  mean(AUC)=0.325391 > 0.292852  \n",
       "16             ok  mean(AUC)=0.518903 > 0.467013  \n",
       "17             ok  mean(AUC)=0.234282 > 0.210854  \n",
       "18             ok  mean(AUC)=0.518903 > 0.467013  \n",
       "19             ok  mean(AUC)=0.418632 > 0.376769  \n",
       "20             ok  mean(AUC)=0.518903 > 0.467013  \n",
       "21             ok  mean(AUC)=0.458255 > 0.412429  \n",
       "22             ok  mean(AUC)=0.518903 > 0.467013  \n",
       "23  needs_holdout                           skip  \n",
       "24  needs_holdout                           skip  \n",
       "25  needs_holdout                           skip  \n",
       "26  needs_holdout                           skip  \n",
       "27  needs_holdout                           skip  \n",
       "28  needs_holdout                           skip  \n",
       "29  needs_holdout                           skip  \n",
       "30  needs_holdout                           skip  \n",
       "31  needs_holdout                           skip  \n",
       "32  needs_holdout                           skip  \n",
       "33  needs_holdout                           skip  \n",
       "34  needs_holdout                           skip  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Quarantine placeholder tests (skip) + teach runner to ignore them ===\n",
    "from pathlib import Path\n",
    "import re, yaml, pandas as pd, json, glob as _globmod\n",
    "\n",
    "LAB = Path(r\"E:\\CNT\")\n",
    "PLACEHOLDER_NAME_PAT = re.compile(r\"^(test_readme|test_summary)$\", re.IGNORECASE)\n",
    "PLACEHOLDER_COL_KEYS = {\"npairs\",\"n_pairs\",\"n-pairs\"}\n",
    "\n",
    "# require mega-cell globals\n",
    "try:\n",
    "    TEST_FENCE, SOURCE_ROOTS, run_cycle\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Run your Mega Cell first, then this cell.\")\n",
    "\n",
    "# 1) mark placeholders with skip:true (idempotent)\n",
    "updated = 0\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        changes = []\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            body = m.group(\"body\")\n",
    "            try:\n",
    "                spec = yaml.safe_load(body) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or spec.get(\"type\") != \"csv_threshold\":\n",
    "                continue\n",
    "            name = str(spec.get(\"name\",\"\"))\n",
    "            col  = str(spec.get(\"column\",\"\"))\n",
    "            if PLACEHOLDER_NAME_PAT.match(name) or re.sub(r\"[^a-z0-9]+\",\"\",col.lower()) in PLACEHOLDER_COL_KEYS:\n",
    "                if not spec.get(\"skip\", False):\n",
    "                    spec[\"skip\"] = True\n",
    "                    fenced = \"```cnt-test\\n\" + yaml.safe_dump(spec, sort_keys=False) + \"```\"\n",
    "                    changes.append((m.span()[0], m.span()[1], fenced))\n",
    "        if changes:\n",
    "            new_txt = txt\n",
    "            for a,b,rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\")\n",
    "            updated += 1\n",
    "print(f\"[skip] updated_docs={updated}\")\n",
    "\n",
    "# 2) patch the strict tester to ignore skip:true\n",
    "def _csv_threshold_test_strict(t: dict):\n",
    "    if t.get(\"skip\", False):\n",
    "        return False, \"skip\", \"skip\"\n",
    "    if not t.get(\"gold\", False):\n",
    "        return False, \"non_gold\", \"non_gold\"\n",
    "    path = t.get(\"path\")\n",
    "    if not path or not Path(path).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "    # hash check if provided\n",
    "    if t.get(\"hash\"):\n",
    "        import hashlib\n",
    "        h = hashlib.sha256()\n",
    "        with open(path, \"rb\") as f:\n",
    "            for b in iter(lambda: f.read(1<<20), b\"\"):\n",
    "                h.update(b)\n",
    "        if h.hexdigest() != str(t[\"hash\"]):\n",
    "            return False, \"hash_mismatch\", \"hash_mismatch\"\n",
    "    # evaluate via normalized tester\n",
    "    ok, info, reason = _csv_threshold_test(t) if \"_csv_threshold_test\" in globals() else (False,\"no_core_tester\",\"invalid_type\")\n",
    "    return ok, info, reason\n",
    "\n",
    "# 3) re-run and show a crisp summary\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT = LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "reps = sorted(_globmod.glob(str(OUT/\"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); df = pd.read_csv(rep)\n",
    "    print(\"\\nLatest:\", rep)\n",
    "    print(df[\"reason\"].value_counts(dropna=False))\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df[df[\"reason\"].isin([\"ok\",\"pair_fail\",\"needs_holdout\",\"skip\"])][[\"name\",\"valid\",\"passed\",\"reason\",\"info\"]].tail(20))\n",
    "    except Exception:\n",
    "        print(df.tail(20).to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3903d73e-e528-47a6-aafe-9168427e98c0",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "closing parenthesis ')' does not match opening parenthesis '[' (139954510.py, line 358)",
     "output_type": "error",
     "traceback": [
      "  \u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[37]\u001b[39m\u001b[32m, line 358\u001b[39m\n\u001b[31m    \u001b[39m\u001b[31mbase_ok=(\"passed\", lambda s: int(any((s[dash.loc[s.index,\"is_hold\"]==0)]))),\u001b[39m\n                                                                          ^\n\u001b[31mSyntaxError\u001b[39m\u001b[31m:\u001b[39m closing parenthesis ')' does not match opening parenthesis '['\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# CNT — Paired Evidence Sweep v2\n",
    "# ================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, hashlib, json, glob as _globmod\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "STRICT_EWB_AUC055 = False   # set True to escalate EWB pairs to AUC > 0.55 after harvest\n",
    "CALIBRATION_MODE  = \"relative_90pct\"  # threshold = 0.9 * mean for each CSV (base & holdout)\n",
    "\n",
    "# ---------- REQUIRE MEGA-CELL PRIMITIVES ----------\n",
    "if \"run_cycle\" not in globals():\n",
    "    # try to import from the SSD script file\n",
    "    import importlib.util\n",
    "    mod_path = LAB / \"cnt_engine_megacell.py\"\n",
    "    if not mod_path.exists():\n",
    "        raise RuntimeError(\"run_cycle not found. Load your Mega Cell (or save it as E:\\\\CNT\\\\cnt_engine_megacell.py) and re-run.\")\n",
    "    spec = importlib.util.spec_from_file_location(\"cnt_engine\", str(mod_path))\n",
    "    cnt_engine = importlib.util.module_from_spec(spec); spec.loader.exec_module(cnt_engine)\n",
    "    run_cycle = cnt_engine.run_cycle\n",
    "    # adopt helpers into globals\n",
    "    TEST_FENCE = getattr(cnt_engine, \"TEST_FENCE\", re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL))\n",
    "    _csv_threshold_test_strict = getattr(cnt_engine, \"_csv_threshold_test_strict\", None)\n",
    "    _parse_cnt_tests = getattr(cnt_engine, \"_parse_cnt_tests\", None)\n",
    "    ENGINE_ROOT = getattr(cnt_engine, \"ENGINE_ROOT\", LAB / \"artifacts\" / \"cnt_engine_megacell\")\n",
    "else:\n",
    "    # use whatever is already loaded in this kernel\n",
    "    TEST_FENCE = globals().get(\"TEST_FENCE\", re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL))\n",
    "    ENGINE_ROOT = globals().get(\"ENGINE_ROOT\", LAB / \"artifacts\" / \"cnt_engine_megacell\")\n",
    "\n",
    "# SOURCE_ROOTS from your mega cell\n",
    "if \"SOURCE_ROOTS\" not in globals():\n",
    "    SOURCE_ROOTS = [\n",
    "        LAB / \"notes\",\n",
    "        LAB / \"artifacts\" / \"cnt_scroll\",\n",
    "        LAB / \"artifacts\" / \"cnt_codex\",\n",
    "        LAB / \"notebooks\",\n",
    "    ]\n",
    "\n",
    "# ---------- UTILS ----------\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\", \"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _pick_metric_col(df: pd.DataFrame, prefer=None):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    prefs = ([prefer] if prefer else []) + [\"auc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\",\"lead@hit\",\"lead_at_hit\"]\n",
    "    for want in prefs:\n",
    "        if want and _norm(want) in nm:\n",
    "            return nm[_norm(want)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(mode, series):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode == \"relative_90pct\":\n",
    "        return float(round(0.9*float(s.mean()), 6))\n",
    "    if mode == \"strict_055\":\n",
    "        return 0.55\n",
    "    if mode == \"above_chance\":\n",
    "        return 0.50\n",
    "    return float(round(0.9*float(s.mean()), 6))\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "\n",
    "def _upsert_fenced(doc_text: str, name: str, block: str) -> str:\n",
    "    out, replaced = doc_text, False\n",
    "    for m in TEST_FENCE.finditer(doc_text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.strip().lower():\n",
    "            a,b = m.span(); out = doc_text[:a] + block + doc_text[b:]; replaced=True; break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "# ---------- 0) Quarantine placeholders (skip:true) ----------\n",
    "PLACEHOLDER_NAME_PAT = re.compile(r\"^(test_readme|test_summary)$\", re.IGNORECASE)\n",
    "PLACEHOLDER_COL_KEYS = {\"npairs\",\"n_pairs\",\"n-pairs\"}\n",
    "updated_skip = 0\n",
    "for root in SOURCE_ROOTS:\n",
    "    for doc in list(root.rglob(\"*.md\")) + list(root.rglob(\"*.txt\")):\n",
    "        try:\n",
    "            txt = doc.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "        except Exception:\n",
    "            continue\n",
    "        changes=[]\n",
    "        for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "            try:\n",
    "                spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "            except Exception:\n",
    "                continue\n",
    "            if not isinstance(spec, dict) or spec.get(\"type\")!=\"csv_threshold\": \n",
    "                continue\n",
    "            name = str(spec.get(\"name\",\"\"))\n",
    "            col  = str(spec.get(\"column\",\"\"))\n",
    "            if PLACEHOLDER_NAME_PAT.match(name) or _norm(col) in PLACEHOLDER_COL_KEYS:\n",
    "                if not spec.get(\"skip\", False):\n",
    "                    spec[\"skip\"] = True\n",
    "                    changes.append((m.span(), _fence(spec)))\n",
    "        if changes:\n",
    "            new_txt = txt\n",
    "            for (a,b), rep in reversed(changes):\n",
    "                new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "            doc.write_text(new_txt, encoding=\"utf-8\"); updated_skip += 1\n",
    "print(f\"[skip] placeholders quarantined in docs: {updated_skip}\")\n",
    "\n",
    "# ---------- 1) Harvest EWB pairs (base + holdout) ----------\n",
    "EWB_DIR = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\"\n",
    "DOC_EWB = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_EWB.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt_ewb = DOC_EWB.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_EWB.exists() else \"# EWB Results — Paired Evidence\\n\"\n",
    "\n",
    "bases = sorted(EWB_DIR.rglob(\"*.csv\"))\n",
    "holds = [p for p in bases if \"holdout\" in p.name.lower()]\n",
    "hold_by_dir = {}\n",
    "for h in holds:\n",
    "    hold_by_dir.setdefault(h.parent, []).append(h)\n",
    "\n",
    "minted_ewb = 0\n",
    "for base in bases:\n",
    "    if \"holdout\" in base.name.lower():\n",
    "        continue\n",
    "    # pick a holdout neighbor\n",
    "    ho = None\n",
    "    if base.parent in hold_by_dir:\n",
    "        ho = hold_by_dir[base.parent][0]\n",
    "    else:\n",
    "        cand = base.parent / \"ewb_holdout_results.csv\"\n",
    "        if cand.exists(): ho = cand\n",
    "    if not ho: \n",
    "        continue\n",
    "\n",
    "    dfb = pd.read_csv(base); dfh = pd.read_csv(ho)\n",
    "    col_b = _pick_metric_col(dfb, \"auc\"); col_h = _pick_metric_col(dfh, col_b)\n",
    "    if not col_b or not col_h: \n",
    "        continue\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty:\n",
    "        continue\n",
    "\n",
    "    thr_b = _policy_value(\"relative_90pct\", sb)\n",
    "    thr_h = _policy_value(\"relative_90pct\", sh)\n",
    "\n",
    "    name_base = f\"pair_{base.stem}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(name=name_base, type=\"csv_threshold\", path=str(PureWindowsPath(base)),\n",
    "                  column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb)))\n",
    "    spec_h = dict(name=name_hold, type=\"csv_threshold\", path=str(PureWindowsPath(ho)),\n",
    "                  column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(ho), rows=int(len(dfh)))\n",
    "\n",
    "    txt_ewb = _upsert_fenced(txt_ewb, name_base, _fence(spec_b))\n",
    "    txt_ewb = _upsert_fenced(txt_ewb, name_hold, _fence(spec_h))\n",
    "    minted_ewb += 1\n",
    "\n",
    "# optional escalation for EWB pairs to strict AUC > 0.55\n",
    "if STRICT_EWB_AUC055:\n",
    "    new_txt = txt_ewb\n",
    "    for m in TEST_FENCE.finditer(txt_ewb or \"\"):\n",
    "        try: spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception: continue\n",
    "        if not isinstance(spec, dict) or spec.get(\"type\")!=\"csv_threshold\": continue\n",
    "        nm = str(spec.get(\"name\",\"\"))\n",
    "        if _norm(nm).startswith(\"pair_\") or _norm(nm).startswith(\"test_ewb_pair\"):\n",
    "            col = str(spec.get(\"column\",\"\"))\n",
    "            if \"auc\" in _norm(col) or \"precision\" in _norm(col):\n",
    "                spec[\"op\"] = \">\"\n",
    "                spec[\"value\"] = 0.55\n",
    "                a,b = m.span()\n",
    "                new_txt = new_txt[:a] + _fence(spec) + new_txt[b:]\n",
    "    txt_ewb = new_txt\n",
    "\n",
    "DOC_EWB.write_text(txt_ewb, encoding=\"utf-8\")\n",
    "print(f\"[ewb] harvested pairs written: {minted_ewb} → {DOC_EWB}\")\n",
    "\n",
    "# ---------- 2) Harvest Cooling pairs (*_labeled as holdout) ----------\n",
    "# Looks for files like cnt_cooling_log_...csv and cnt_cooling_log_..._labeled.csv in same dir\n",
    "minted_cooling = 0\n",
    "COOL_GLOB = list(EWB_DIR.rglob(\"ewb_cooling_segments*.csv\")) + list(LAB.rglob(\"cnt_cooling_log_*.csv\"))\n",
    "by_key = {}\n",
    "for p in COOL_GLOB:\n",
    "    stem = p.stem\n",
    "    key = stem.replace(\"_labeled\", \"\")\n",
    "    by_key.setdefault((p.parent, key), []).append(p)\n",
    "\n",
    "for (parent, key), files in by_key.items():\n",
    "    base = None; hold = None\n",
    "    for p in files:\n",
    "        if p.stem.endswith(\"_labeled\"):\n",
    "            hold = p\n",
    "        else:\n",
    "            base = p\n",
    "    if not (base and hold and base.exists() and hold.exists()):\n",
    "        continue\n",
    "    dfb = pd.read_csv(base); dfh = pd.read_csv(hold)\n",
    "    col_b = _pick_metric_col(dfb, \"auc\"); col_h = _pick_metric_col(dfh, col_b)\n",
    "    if not col_b or not col_h:\n",
    "        continue\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty:\n",
    "        continue\n",
    "\n",
    "    thr_b = _policy_value(CALIBRATION_MODE, sb)\n",
    "    thr_h = _policy_value(CALIBRATION_MODE, sh)\n",
    "\n",
    "    name_base = f\"pair_cooling_{key}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(name=name_base, type=\"csv_threshold\", path=str(PureWindowsPath(base)),\n",
    "                  column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb)))\n",
    "    spec_h = dict(name=name_hold, type=\"csv_threshold\", path=str(PureWindowsPath(hold)),\n",
    "                  column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "                  gold=True, frozen_at=STAMP, hash=_sha256(hold), rows=int(len(dfh)))\n",
    "\n",
    "    # write to a Cooling doc under notes/\n",
    "    DOC_COOL = LAB / r\"notes\\cooling_pairs.md\"\n",
    "    txt = DOC_COOL.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_COOL.exists() else \"# Cooling — Paired Evidence\\n\"\n",
    "    txt = _upsert_fenced(txt, name_base, _fence(spec_b))\n",
    "    txt = _upsert_fenced(txt, name_hold, _fence(spec_h))\n",
    "    DOC_COOL.write_text(txt, encoding=\"utf-8\")\n",
    "    minted_cooling += 1\n",
    "\n",
    "print(f\"[cooling] minted pairs: {minted_cooling}\")\n",
    "\n",
    "# ---------- 3) Patch the runner (robust paired-evidence, soft mode) ----------\n",
    "import inspect\n",
    "rc_mod = inspect.getmodule(run_cycle)\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    s = str(name or \"\").strip().lower()\n",
    "    return s.endswith(\"_holdout\")\n",
    "\n",
    "def _base_key(name: str) -> str:\n",
    "    s = str(name or \"\").strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "def _csv_threshold_test_strict_patch(t: dict):\n",
    "    # respect skip + gold + hash verification; delegate to core tester available in the module/globals\n",
    "    if t.get(\"skip\", False):\n",
    "        return False, \"skip\", \"skip\"\n",
    "    if not t.get(\"gold\", False):\n",
    "        return False, \"non_gold\", \"non_gold\"\n",
    "    p = t.get(\"path\"); \n",
    "    if not p or not Path(p).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "    if t.get(\"hash\"):\n",
    "        h_now = _sha256(Path(p))\n",
    "        if str(h_now) != str(t[\"hash\"]):\n",
    "            return False, \"hash_mismatch\", \"hash_mismatch\"\n",
    "    # call whichever normalized tester exists (module or global)\n",
    "    core = getattr(rc_mod, \"_csv_threshold_test\", globals().get(\"_csv_threshold_test\", None))\n",
    "    if core is None:\n",
    "        return False, \"no_core_tester\", \"invalid_type\"\n",
    "    ok, info, reason = core(t)\n",
    "    return ok, info, reason\n",
    "\n",
    "def _paired_runner_soft(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    parse = getattr(rc_mod, \"_parse_cnt_tests\", globals().get(\"_parse_cnt_tests\"))\n",
    "    if parse is None:\n",
    "        parse = lambda s: []\n",
    "    for _, r in df.iterrows():\n",
    "        path = r[\"path\"]\n",
    "        tests = parse(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict_patch(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name)),\n",
    "                base_key=_base_key(name)\n",
    "            ))\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        rep.to_csv(out_csv, index=False); return 0,0,0\n",
    "\n",
    "    # consider only rows that reached 'ok'\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "\n",
    "    # pair gating\n",
    "    by_key = {k: list(idxs) for k, idxs in rep.groupby(\"base_key\").indices.items()}\n",
    "    to_pair_fail, to_needs = set(), set()\n",
    "    for key, idxs in by_key.items():\n",
    "        base_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==0]\n",
    "        hold_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==1]\n",
    "        base_pass = any(bool(rep.loc[i,\"passed\"]) for i in base_idxs)\n",
    "        hold_pass = any(bool(rep.loc[i,\"passed\"]) for i in hold_idxs)\n",
    "        if base_idxs and not hold_idxs:\n",
    "            to_needs.update(base_idxs)\n",
    "        elif hold_idxs and not base_idxs:\n",
    "            to_needs.update(hold_idxs)\n",
    "        else:\n",
    "            if not (base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    if to_needs:\n",
    "        rep.loc[list(to_needs), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_needs), \"reason\"] = \"needs_holdout\"\n",
    "    if to_pair_fail:\n",
    "        rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "    total  = int(rep[\"valid\"].sum())\n",
    "    passed = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))\n",
    "    return passed, total, runnable\n",
    "\n",
    "# bind into the module used by run_cycle\n",
    "setattr(rc_mod, \"_csv_threshold_test_strict\", _csv_threshold_test_strict_patch)\n",
    "setattr(rc_mod, \"run_cnt_tests_on_df\", _paired_runner_soft)\n",
    "\n",
    "# ---------- 4) Re-run and report ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "OUT = Path(str(ENGINE_ROOT)) / \"out\"\n",
    "reps = sorted(_globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "if reps:\n",
    "    rep = Path(reps[-1]); dfrep = pd.read_csv(rep)\n",
    "    print(\"\\nLatest report:\", rep)\n",
    "    print(dfrep[\"reason\"].value_counts(dropna=False))\n",
    "\n",
    "    # Pair dashboard (compact)\n",
    "    def _is_hold(name): return str(name).lower().strip().endswith(\"_holdout\")\n",
    "    dash = dfrep.copy()\n",
    "    dash[\"is_hold\"] = dash[\"name\"].apply(_is_hold).astype(int)\n",
    "    dash[\"base_key\"] = dash[\"name\"].apply(lambda s: (_norm(s[:-9]) if _is_hold(s) else _norm(s)))\n",
    "    grp = dash.groupby(\"base_key\").agg(\n",
    "        base_ok=(\"passed\", lambda s: int(any((s[dash.loc[s.index,\"is_hold\"]==0)]))),\n",
    "        hold_ok=(\"passed\", lambda s: int(any((s[dash.loc[s.index,\"is_hold\"]==1)]))),\n",
    "        counted=(\"valid\",\"sum\"),\n",
    "        total=(\"name\",\"count\"),\n",
    "    )\n",
    "    grp[\"pair_ok\"] = (grp[\"base_ok\"] & grp[\"hold_ok\"]).astype(int)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(grp.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).tail(24))\n",
    "    except Exception:\n",
    "        print(grp.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).tail(24).to_string(index=False))\n",
    "else:\n",
    "    print(\"No tests_report_* yet.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e5d72fa9-0afa-4523-9d61-32cfae994377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Pair Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_ok</th>\n",
       "      <th>hold_ok</th>\n",
       "      <th>counted</th>\n",
       "      <th>total</th>\n",
       "      <th>pair_ok</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments2025101723521</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments20251017235217</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary2025101723320</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary20251017233201</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv212025101723401</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2120251017234015</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv222025101723454</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2220251017234543</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv232025101723495</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2320251017234953</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpai</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpair</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresult</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testgoldverificationsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015163558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbaut</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecisio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015164130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresults</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testreadme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       base_ok  hold_ok  counted  total  \\\n",
       "base_key                                                                  \n",
       "pairewbcoolingsegments2025101723521          0        1        1      1   \n",
       "pairewbcoolingsegments20251017235217         1        0        1      1   \n",
       "pairewbsummary2025101723320                  0        1        1      1   \n",
       "pairewbsummary20251017233201                 1        0        1      1   \n",
       "pairewbsummaryv212025101723401               0        1        1      1   \n",
       "pairewbsummaryv2120251017234015              1        0        1      1   \n",
       "pairewbsummaryv222025101723454               0        1        1      1   \n",
       "pairewbsummaryv2220251017234543              1        0        1      1   \n",
       "pairewbsummaryv232025101723495               0        1        1      1   \n",
       "pairewbsummaryv2320251017234953              1        0        1      1   \n",
       "testewbpai                                   0        1        1      1   \n",
       "testewbpair                                  1        0        1      1   \n",
       "testewbauto                                  0        0        0      1   \n",
       "testewbprecision                             0        0        0      1   \n",
       "testewbresult                                0        0        0      1   \n",
       "testgoldverificationsummary                  0        0        0      1   \n",
       "testcntcorrelatesreport20251015163558        0        0        0      2   \n",
       "testewbaut                                   0        0        0      2   \n",
       "testewbprecisio                              0        0        0      2   \n",
       "testcntcorrelatesreport20251015164130        0        0        0      3   \n",
       "testewbresults                               0        0        0      3   \n",
       "testreadme                                   0        0        0      3   \n",
       "testsummary                                  0        0        0      4   \n",
       "\n",
       "                                       pair_ok  \n",
       "base_key                                        \n",
       "pairewbcoolingsegments2025101723521          0  \n",
       "pairewbcoolingsegments20251017235217         0  \n",
       "pairewbsummary2025101723320                  0  \n",
       "pairewbsummary20251017233201                 0  \n",
       "pairewbsummaryv212025101723401               0  \n",
       "pairewbsummaryv2120251017234015              0  \n",
       "pairewbsummaryv222025101723454               0  \n",
       "pairewbsummaryv2220251017234543              0  \n",
       "pairewbsummaryv232025101723495               0  \n",
       "pairewbsummaryv2320251017234953              0  \n",
       "testewbpai                                   0  \n",
       "testewbpair                                  0  \n",
       "testewbauto                                  0  \n",
       "testewbprecision                             0  \n",
       "testewbresult                                0  \n",
       "testgoldverificationsummary                  0  \n",
       "testcntcorrelatesreport20251015163558        0  \n",
       "testewbaut                                   0  \n",
       "testewbprecisio                              0  \n",
       "testcntcorrelatesreport20251015164130        0  \n",
       "testewbresults                               0  \n",
       "testreadme                                   0  \n",
       "testsummary                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Pair dashboard FIX (no fragile lambdas) ===\n",
    "from pathlib import Path\n",
    "import pandas as pd, re, os\n",
    "import glob as globmod\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "OUT = (Path(str(ENGINE_ROOT)) / \"out\") if \"ENGINE_ROOT\" in globals() else LAB / r\"artifacts\\cnt_engine_megacell\\out\"\n",
    "\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "rep = Path(rep_paths[-1])\n",
    "df  = pd.read_csv(rep)\n",
    "\n",
    "def _norm(s): return re.sub(r\"[^a-z0-9]+\",\"\", str(s).lower().strip())\n",
    "def _is_hold(name): return str(name).lower().strip().endswith(\"_holdout\")\n",
    "\n",
    "# Normalize keys and flags\n",
    "df[\"is_hold\"] = df[\"name\"].apply(_is_hold).astype(int)\n",
    "df[\"base_key\"] = df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))\n",
    "df[\"ok_row\"] = (df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "\n",
    "# Components: a row contributes to base_ok/hold_ok only if it actually PASSED and is ok\n",
    "df[\"base_pass\"] = ((df[\"is_hold\"]==0) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"hold_pass\"] = ((df[\"is_hold\"]==1) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "\n",
    "# Aggregate cleanly\n",
    "grp = df.groupby(\"base_key\").agg(\n",
    "    base_ok=(\"base_pass\", \"max\"),\n",
    "    hold_ok=(\"hold_pass\", \"max\"),\n",
    "    counted=(\"valid\", \"sum\"),\n",
    "    total=(\"name\", \"count\"),\n",
    ")\n",
    "grp[\"pair_ok\"] = (grp[\"base_ok\"] & grp[\"hold_ok\"]).astype(int)\n",
    "\n",
    "print(\"=== Pair Summary ===\")\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(grp.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(40))\n",
    "except Exception:\n",
    "    print(grp.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(40).to_string())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "19e1209b-86c8-4840-a8de-8ea0da361e2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7941439024390243,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8991551091981508,\n",
      "    \"falsifiability\": 1.0,\n",
      "    \"total\": 0.9233247529092938\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 12,\n",
      "  \"tests_passed\": 12,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\CNT_Gold_Dossier_J135656-011722.md\",\n",
      "      \"resid\": 0.917654107784611,\n",
      "      \"hint\": \"# CNT Gold Dossier \\u2014 WISE J135656.78\\u2212011722.9 **Position (ICRS):** RA 209.236592, Dec -1.289716 ## AllWISE photometry & flags - W1=14.348999977111816, W2=14.0, W3=10.232000350952148, W4=8.480999946594238 - W1\\u2212W2=0.349, W2\\u2212W3=3.768 - ph_qual=, cc_flags=, ext_flg= - SNR: w1=37.4, w2=27.8 (W3/W4 from table if present) ## Catalog labels - SIMBAD: () - NED: WISEA J135656.78-011722.9 [G] z=0.148182 ## G\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548\\\\summary.txt\",\n",
      "      \"resid\": 0.9175153485631594,\n",
      "      \"hint\": \"== CNT One-Signal Thesis \\u2014 Unified Verdict (v3.1) == Run dir: C:\\\\Users\\\\caleb\\\\CNT_Lab\\\\notebooks\\\\archive\\\\cnt_one_signal_20251017-215548 V1 (classic): - REWS beats baselines in: 0.0% of systems - Median lead time @ \\u0398(q=0.85): 4137 samples V2 (chaos-aware, precision\\u22650.50 target): - Systems achieving precision floor (or fallback): 0.0% - Median lead time @ \\u0398\\u2082: 3623 samples -- V1 AUCs -- system AUC_REWS\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_anomaly\\\\out\\\\strict_shortlist_summary.md\",\n",
      "      \"resid\": 0.8717861296469525,\n",
      "      \"hint\": \"# CNT Techno-Anomaly \\u2014 Strict Shortlist Source file: `stable_enriched_strict_20251016-180208_grid3x3_K3.csv` Diagnostics saved in: `cnt_anomaly\\\\out\\\\figures` | rank | ra_deg | dec | votes | W1-W2 | W2-W3 | class_hint | cutouts | |---:|---:|---:|---:|---:|---:|:---|:---:| | 1 | 209.236537 | -1.289745 | 4 | 0.349 | 3.768 | ambiguous | yes | | 2 | 210.910946 | -1.291592 | 4 | -0.068 | 2.526 | ambiguou\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Pair Summary ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_ok</th>\n",
       "      <th>hold_ok</th>\n",
       "      <th>counted</th>\n",
       "      <th>total</th>\n",
       "      <th>pair_ok</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments20251017235217</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary20251017233201</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2120251017234015</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2220251017234543</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2320251017234953</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpair</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testgoldverificationsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015163558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015164130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testreadme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresults</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       base_ok  hold_ok  counted  total  \\\n",
       "base_key                                                                  \n",
       "pairewbcoolingsegments20251017235217         1        1        2      2   \n",
       "pairewbsummary20251017233201                 1        1        2      2   \n",
       "pairewbsummaryv2120251017234015              1        1        2      2   \n",
       "pairewbsummaryv2220251017234543              1        1        2      2   \n",
       "pairewbsummaryv2320251017234953              1        1        2      2   \n",
       "testewbpair                                  1        1        2      2   \n",
       "testgoldverificationsummary                  0        0        0      1   \n",
       "testcntcorrelatesreport20251015163558        0        0        0      2   \n",
       "testcntcorrelatesreport20251015164130        0        0        0      3   \n",
       "testewbauto                                  0        0        0      3   \n",
       "testewbprecision                             0        0        0      3   \n",
       "testreadme                                   0        0        0      3   \n",
       "testewbresults                               0        0        0      4   \n",
       "testsummary                                  0        0        0      4   \n",
       "\n",
       "                                       pair_ok  \n",
       "base_key                                        \n",
       "pairewbcoolingsegments20251017235217         1  \n",
       "pairewbsummary20251017233201                 1  \n",
       "pairewbsummaryv2120251017234015              1  \n",
       "pairewbsummaryv2220251017234543              1  \n",
       "pairewbsummaryv2320251017234953              1  \n",
       "testewbpair                                  1  \n",
       "testgoldverificationsummary                  0  \n",
       "testcntcorrelatesreport20251015163558        0  \n",
       "testcntcorrelatesreport20251015164130        0  \n",
       "testewbauto                                  0  \n",
       "testewbprecision                             0  \n",
       "testreadme                                   0  \n",
       "testewbresults                               0  \n",
       "testsummary                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Proof bundle → E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-225233.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Paired Evidence: Lock & Export (One Cell)\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, json, zipfile, hashlib\n",
    "import pandas as pd\n",
    "import glob as globmod\n",
    "\n",
    "# ---------- CONFIG ----------\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "DOC_EWB   = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL  = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "# Toggle: escalate EWB paired thresholds to AUC > 0.55, then re-run\n",
    "ESCALATE_EWB_TO_055 = False\n",
    "\n",
    "# ---------- REQUIRE mega-cell CORE ----------\n",
    "try:\n",
    "    run_cycle\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your Mega Cell first so run_cycle() and TEST_FENCE exist in this kernel.\")\n",
    "\n",
    "# ---------- MONKEY-PATCH the paired-evidence runner (SOFT mode) ----------\n",
    "import inspect\n",
    "rc_mod = inspect.getmodule(run_cycle)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _is_holdout_name(name: str) -> bool:\n",
    "    s = str(name or \"\").strip().lower()\n",
    "    return s.endswith(\"_holdout\")\n",
    "\n",
    "def _base_key(name: str) -> str:\n",
    "    s = str(name or \"\").strip()\n",
    "    if s.lower().endswith(\"_holdout\"):\n",
    "        s = s[:-len(\"_holdout\")]\n",
    "    return _norm(s)\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# strict tester that respects skip + gold + hash, delegates to core normalized tester\n",
    "def _csv_threshold_test_strict_patch(t: dict):\n",
    "    if t.get(\"skip\", False):\n",
    "        return False, \"skip\", \"skip\"\n",
    "    if not t.get(\"gold\", False):\n",
    "        return False, \"non_gold\", \"non_gold\"\n",
    "    p = t.get(\"path\")\n",
    "    if not p or not Path(p).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "    if t.get(\"hash\"):\n",
    "        if _sha256(Path(p)) != str(t[\"hash\"]):\n",
    "            return False, \"hash_mismatch\", \"hash_mismatch\"\n",
    "    core = getattr(rc_mod, \"_csv_threshold_test\", globals().get(\"_csv_threshold_test\", None))\n",
    "    if core is None:\n",
    "        return False, \"no_core_tester\", \"invalid_type\"\n",
    "    ok, info, reason = core(t)\n",
    "    return ok, info, reason\n",
    "\n",
    "def _paired_runner_soft(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    parse = getattr(rc_mod, \"_parse_cnt_tests\", globals().get(\"_parse_cnt_tests\", lambda s: []))\n",
    "    for _, r in df.iterrows():\n",
    "        path  = r[\"path\"]\n",
    "        tests = parse(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            name  = t.get(\"name\", Path(path).stem)\n",
    "            ttype = t.get(\"type\",\"unknown\")\n",
    "            if ttype == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict_patch(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttype}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=name, type=ttype,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_holdout_name(name)),\n",
    "                base_key=_base_key(name),\n",
    "            ))\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        rep.to_csv(out_csv, index=False); return 0,0,0\n",
    "\n",
    "    # keep only strict-ok rows as candidates\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "\n",
    "    # pair gating\n",
    "    by_key = {k: list(idxs) for k, idxs in rep.groupby(\"base_key\").indices.items()}\n",
    "    to_pair_fail, to_needs = set(), set()\n",
    "    for key, idxs in by_key.items():\n",
    "        base_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==0]\n",
    "        hold_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==1]\n",
    "        base_pass = any(bool(rep.loc[i,\"passed\"]) for i in base_idxs)\n",
    "        hold_pass = any(bool(rep.loc[i,\"passed\"]) for i in hold_idxs)\n",
    "        if base_idxs and not hold_idxs:\n",
    "            to_needs.update(base_idxs)\n",
    "        elif hold_idxs and not base_idxs:\n",
    "            to_needs.update(hold_idxs)\n",
    "        else:\n",
    "            if not (base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    if to_needs:\n",
    "        rep.loc[list(to_needs), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_needs), \"reason\"] = \"needs_holdout\"\n",
    "    if to_pair_fail:\n",
    "        rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "    total  = int(rep[\"valid\"].sum())\n",
    "    passed = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))\n",
    "    return passed, total, runnable\n",
    "\n",
    "# Bind into the module used by run_cycle\n",
    "setattr(rc_mod, \"_csv_threshold_test_strict\", _csv_threshold_test_strict_patch)\n",
    "setattr(rc_mod, \"run_cnt_tests_on_df\", _paired_runner_soft)\n",
    "\n",
    "# ---------- (Optional) Escalate EWB pairs to AUC > 0.55 ----------\n",
    "if ESCALATE_EWB_TO_055 and DOC_EWB.exists():\n",
    "    txt = DOC_EWB.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    changed = 0\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not isinstance(spec, dict) or spec.get(\"type\")!=\"csv_threshold\":\n",
    "            continue\n",
    "        nm  = str(spec.get(\"name\",\"\"))\n",
    "        col = str(spec.get(\"column\",\"\"))\n",
    "        if (_norm(nm).startswith(\"pair_\") or _norm(nm).startswith(\"test_ewb_pair\")) and (\"auc\" in _norm(col) or \"precision\" in _norm(col)):\n",
    "            spec[\"op\"] = \">\"\n",
    "            spec[\"value\"] = 0.55\n",
    "            a,b = m.span()\n",
    "            txt = txt[:a] + (\"```cnt-test\\n\"+yaml.safe_dump(spec, sort_keys=False)+\"```\") + txt[b:]\n",
    "            changed += 1\n",
    "    if changed:\n",
    "        DOC_EWB.write_text(txt, encoding=\"utf-8\")\n",
    "        print(f\"[strict] escalated {changed} EWB tests to AUC>0.55\")\n",
    "\n",
    "# ---------- RUN once ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- PAIR DASHBOARD (robust, no fragile lambdas) ----------\n",
    "rep_paths = sorted(globmod.glob(str(OUT/\"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "rep = Path(rep_paths[-1])\n",
    "df  = pd.read_csv(rep)\n",
    "\n",
    "def _is_hold(name): return str(name).lower().strip().endswith(\"_holdout\")\n",
    "\n",
    "# Normalize flags (do NOT recompute base_key unless missing)\n",
    "if \"base_key\" not in df.columns:\n",
    "    df[\"base_key\"] = df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))\n",
    "df[\"is_hold\"]   = df[\"name\"].apply(_is_hold).astype(int)\n",
    "df[\"ok_row\"]    = (df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"base_pass\"] = ((df[\"is_hold\"]==0) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"hold_pass\"] = ((df[\"is_hold\"]==1) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "\n",
    "dash = df.groupby(\"base_key\").agg(\n",
    "    base_ok=(\"base_pass\",\"max\"),\n",
    "    hold_ok=(\"hold_pass\",\"max\"),\n",
    "    counted=(\"valid\",\"sum\"),\n",
    "    total=(\"name\",\"count\"),\n",
    ")\n",
    "dash[\"pair_ok\"] = (dash[\"base_ok\"] & dash[\"hold_ok\"]).astype(int)\n",
    "\n",
    "print(\"\\n=== Pair Summary ===\")\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(50))\n",
    "except Exception:\n",
    "    print(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(50).to_string())\n",
    "\n",
    "# ---------- PROOF BUNDLE (zip) ----------\n",
    "bundle_dir = ART / \"bundles\"\n",
    "bundle_dir.mkdir(parents=True, exist_ok=True)\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y%m%d-%H%M%S\")\n",
    "bundle = bundle_dir / f\"cnt_proof_bundle_{STAMP}.zip\"\n",
    "\n",
    "with zipfile.ZipFile(bundle, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    # core artifacts\n",
    "    if Path(rep).exists():          z.write(rep, arcname=Path(rep).name)\n",
    "    if STATE.exists():              z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():       z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists():      z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    # key docs that carry the tests\n",
    "    if DOC_EWB.exists():            z.write(DOC_EWB, arcname=DOC_EWB.name)\n",
    "    if DOC_COOL.exists():           z.write(DOC_COOL, arcname=DOC_COOL.name)\n",
    "\n",
    "print(f\"\\nProof bundle → {bundle}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf74a13f-ebbc-4343-9020-6a2f58e53f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seal] wrote CNT_SEAL.yaml and CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-225844_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Proof Seal v1 (Pairs-Only) — ONE CELL\n",
    "# ===========================================\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, zipfile, glob as globmod, hashlib\n",
    "\n",
    "# ---------- Paths ----------\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "DOC_EWB  = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Require engine bits\n",
    "try:\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    import re\n",
    "    TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _is_hold(name: str) -> bool:\n",
    "    return str(name or \"\").lower().strip().endswith(\"_holdout\")\n",
    "\n",
    "# ---------- 1) Load latest paired-evidence report ----------\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "df  = pd.read_csv(REP)\n",
    "\n",
    "# ensure expected columns\n",
    "for col in [\"base_key\",\"reason\",\"passed\",\"valid\",\"name\",\"doc\"]:\n",
    "    assert col in df.columns, f\"Report missing column '{col}'\"\n",
    "\n",
    "# keep only rows that are strict-ok AND counted valid\n",
    "df_ok = df[(df[\"reason\"]==\"ok\") & (df[\"valid\"]==1) & (df[\"passed\"]==1)].copy()\n",
    "assert not df_ok.empty, \"No passing rows found in latest report. Run the engine first.\"\n",
    "\n",
    "# group rows by normalized base key; a true pair has a base and a holdout\n",
    "df_ok[\"is_holdout\"] = df_ok[\"name\"].apply(_is_hold).astype(int)\n",
    "pairs = []\n",
    "for k, g in df_ok.groupby(\"base_key\"):\n",
    "    has_base = any(g[\"is_holdout\"]==0)\n",
    "    has_hold = any(g[\"is_holdout\"]==1)\n",
    "    if has_base and has_hold:\n",
    "        pairs.append((k, g.copy()))\n",
    "\n",
    "assert pairs, \"No true base↔holdout pairs in ok set.\"\n",
    "\n",
    "# ---------- 2) Parse all docs to map name -> full YAML spec ----------\n",
    "def _scan_doc(doc_path: Path):\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return {}\n",
    "    specs = {}\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"type\" in spec and \"name\" in spec:\n",
    "            specs[str(spec[\"name\"]).strip()] = spec\n",
    "    return specs\n",
    "\n",
    "# Build a unified spec index from manifest docs we care about\n",
    "name2spec = {}\n",
    "doc_candidates = set(df_ok[\"doc\"].tolist())\n",
    "# add canonical docs\n",
    "for extra in [DOC_EWB, DOC_COOL]:\n",
    "    if extra.exists():\n",
    "        doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_scan_doc(Path(d)))\n",
    "\n",
    "# ---------- 3) Assemble the SEAL payload (pairs-only) ----------\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "pairs_payload = []\n",
    "for base_key, g in pairs:\n",
    "    # pick one base and one holdout row\n",
    "    gb = g[g[\"is_holdout\"]==0].iloc[0]\n",
    "    gh = g[g[\"is_holdout\"]==1].iloc[0]\n",
    "    spec_b = name2spec.get(gb[\"name\"], {})\n",
    "    spec_h = name2spec.get(gh[\"name\"], {})\n",
    "    # sanity: ensure gold + hash present; if not, compute hashes now\n",
    "    def _enrich(spec):\n",
    "        out = dict(spec)\n",
    "        p = Path(out.get(\"path\",\"\"))\n",
    "        if p.exists() and not out.get(\"hash\"):\n",
    "            out[\"hash\"] = _sha256(p)\n",
    "        if p.exists() and not out.get(\"rows\"):\n",
    "            try:\n",
    "                out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "            except Exception:\n",
    "                pass\n",
    "        return out\n",
    "    spec_b = _enrich(spec_b)\n",
    "    spec_h = _enrich(spec_h)\n",
    "    pairs_payload.append(dict(\n",
    "        base_key   = base_key,\n",
    "        doc_base   = str(gb[\"doc\"]),\n",
    "        doc_hold   = str(gh[\"doc\"]),\n",
    "        spec_base  = spec_b,\n",
    "        spec_hold  = spec_h,\n",
    "        report_rows= [gb.to_dict(), gh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version = \"CNT-Proof-1\",\n",
    "    created_at   = STAMP,\n",
    "    lab_root     = str(LAB),\n",
    "    engine_state = (yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file  = REP.name,\n",
    "    pairs_ok     = len(pairs_payload),\n",
    "    pairs        = pairs_payload,\n",
    ")\n",
    "\n",
    "# ---------- 4) Write CNT_SEAL.{yaml,md} ----------\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "# Simple human-readable seal\n",
    "lines = []\n",
    "lines.append(f\"# CNT Proof Seal — Pairs-Only\")\n",
    "lines.append(f\"- Created: {STAMP}\")\n",
    "lines.append(f\"- Lab   : {LAB}\")\n",
    "lines.append(f\"- Pairs : {len(pairs_payload)}\\n\")\n",
    "for i, P in enumerate(pairs_payload, 1):\n",
    "    sb = P[\"spec_base\"]; sh = P[\"spec_hold\"]\n",
    "    lines.append(f\"## Pair {i}: `{P['base_key']}`\")\n",
    "    lines.append(f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\")\n",
    "    lines.append(f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\")\n",
    "    lines.append(f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\")\n",
    "    lines.append(f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')} {sh.get('value','?')}`  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\\n\")\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "\n",
    "print(f\"[seal] wrote {SEAL_YAML.name} and {SEAL_MD.name}\")\n",
    "\n",
    "# ---------- 5) Build Proof Bundle (with seal) ----------\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    # core artifacts\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    # seal\n",
    "    z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    z.write(SEAL_MD,   arcname=SEAL_MD.name)\n",
    "    # key docs\n",
    "    if DOC_EWB.exists():  z.write(DOC_EWB,  arcname=DOC_EWB.name)\n",
    "    if DOC_COOL.exists(): z.write(DOC_COOL, arcname=DOC_COOL.name)\n",
    "\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aea6ca94-3075-4b5e-a6a9-8fd2fd14e0f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[atlas] minted/updated pairs: 0 → E:\\CNT\\notes\\atlas_pairs.md\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7989761904761905,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8896968888565527,\n",
      "    \"falsifiability\": 1.0,\n",
      "    \"total\": 0.9221682698331858\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 12,\n",
      "  \"tests_passed\": 12,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9505677925712496,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.7949045085606743,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.7783610139281356,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-230307_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — 3I Atlas Paired Harvester + Seal Refresh (ONE CELL)\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, json, zipfile, hashlib\n",
    "import pandas as pd\n",
    "import glob as globmod\n",
    "\n",
    "# ---------- ROOTS ----------\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "ATLAS_ROOT = LAB / r\"notebooks\\archive\\cnt_3i_atlas_all8\"\n",
    "DOC_ATLAS  = LAB / r\"notes\\atlas_pairs.md\"  # where we’ll write the tests\n",
    "DOC_EWB    = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL   = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- REQUIRE MEGA-CELL CORE ----------\n",
    "try:\n",
    "    run_cycle\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your Mega Cell first so run_cycle() and TEST_FENCE exist.\")\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _pick_metric_col(df: pd.DataFrame, prefer=None):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    prefs = ([prefer] if prefer else []) + [\n",
    "        \"auc\",\"roc_auc\",\"auroc\",\"ap\",\"aupr\",\"f1\",\"f1_score\",\"precision\",\"recall\",\"accuracy\"\n",
    "    ]\n",
    "    for want in prefs:\n",
    "        if want and _norm(want) in nm:\n",
    "            return nm[_norm(want)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(series, mode=\"relative_90pct\"):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode == \"relative_90pct\":\n",
    "        return float(round(0.9*float(s.mean()), 6))\n",
    "    if mode == \"above_chance\":\n",
    "        return 0.50\n",
    "    if mode == \"strict_055\":\n",
    "        return 0.55\n",
    "    return float(round(0.9*float(s.mean()), 6))\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "\n",
    "def _upsert_fenced(doc_text: str, name: str, block: str) -> str:\n",
    "    out, replaced = doc_text, False\n",
    "    for m in TEST_FENCE.finditer(doc_text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.strip().lower():\n",
    "            a,b = m.span(); out = doc_text[:a] + block + doc_text[b:]; replaced=True; break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "def _atlas_basekey(stem: str):\n",
    "    # remove typical holdout/val/test tokens to group base↔holdout\n",
    "    s = stem\n",
    "    s = re.sub(r\"(?i)([_\\-](holdout|val|validation|test))+$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "# ---------- 1) SCAN ATLAS TABLES AND MINT PAIRS ----------\n",
    "pairs_minted = 0\n",
    "DOC_ATLAS.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt_atlas = DOC_ATLAS.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_ATLAS.exists() else \"# 3I Atlas — Paired Evidence\\n\"\n",
    "\n",
    "# Find all CSVs under .../out/tables/\n",
    "table_csvs = [Path(p) for p in globmod.glob(str(ATLAS_ROOT / \"**\" / \"out\" / \"tables\" / \"*.csv\"), recursive=True)]\n",
    "\n",
    "# Group by directory; within each dir, group by base key (stem without holdout/test tokens)\n",
    "from collections import defaultdict\n",
    "by_dirkey = defaultdict(lambda: {\"base\": None, \"hold\": None, \"all\": []})\n",
    "\n",
    "for p in table_csvs:\n",
    "    stem = p.stem\n",
    "    key  = _atlas_basekey(stem)\n",
    "    is_hold = bool(re.search(r\"(?i)(holdout|val|validation|test)\", stem))\n",
    "    rec = by_dirkey[(p.parent, key)]\n",
    "    rec[\"all\"].append(p)\n",
    "    if is_hold:\n",
    "        rec[\"hold\"] = p if (rec[\"hold\"] is None) else rec[\"hold\"]\n",
    "    else:\n",
    "        rec[\"base\"] = p if (rec[\"base\"] is None) else rec[\"base\"]\n",
    "\n",
    "for (parent, key), rec in by_dirkey.items():\n",
    "    base, hold = rec[\"base\"], rec[\"hold\"]\n",
    "    if not (base and hold and base.exists() and hold.exists()):\n",
    "        continue\n",
    "    try:\n",
    "        dfb = pd.read_csv(base); dfh = pd.read_csv(hold)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    col_b = _pick_metric_col(dfb, None)\n",
    "    col_h = _pick_metric_col(dfh, col_b)\n",
    "    if not col_b or not col_h:\n",
    "        continue\n",
    "\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty:\n",
    "        continue\n",
    "\n",
    "    thr_b = _policy_value(sb, \"relative_90pct\")\n",
    "    thr_h = _policy_value(sh, \"relative_90pct\")\n",
    "\n",
    "    name_base = f\"pair_atlas_{key}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(\n",
    "        name=name_base, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(base)), column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb))\n",
    "    )\n",
    "    spec_h = dict(\n",
    "        name=name_hold, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(hold)), column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(hold), rows=int(len(dfh))\n",
    "    )\n",
    "\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_base, _fence(spec_b))\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_hold, _fence(spec_h))\n",
    "    pairs_minted += 1\n",
    "\n",
    "DOC_ATLAS.write_text(txt_atlas, encoding=\"utf-8\")\n",
    "print(f\"[atlas] minted/updated pairs: {pairs_minted} → {DOC_ATLAS}\")\n",
    "\n",
    "# ---------- 2) RE-RUN ENGINE (paired-evidence runner assumed patched already) ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- 3) BUILD/REFRESH SEAL (pairs-only) AND BUNDLE ----------\n",
    "# Reuse the latest tests report, extract true base↔holdout ok pairs, write SEAL + bundle\n",
    "\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "dfrep = pd.read_csv(REP)\n",
    "\n",
    "def _is_hold(nm): return str(nm).lower().strip().endswith(\"_holdout\")\n",
    "def _base_key(nm):\n",
    "    s = str(nm).strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "ok = dfrep[(dfrep[\"reason\"]==\"ok\") & (dfrep[\"valid\"]==1) & (dfrep[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "pairs = []\n",
    "for k, g in ok.groupby(dfrep[\"name\"].apply(_base_key)):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if not gb.empty and not gh.empty:\n",
    "        pairs.append((k, gb.iloc[0], gh.iloc[0]))\n",
    "\n",
    "# Build name->spec index from key docs + any doc referenced by ok report rows\n",
    "name2spec = {}\n",
    "doc_candidates = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists():\n",
    "        doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"): out[\"hash\"]=_sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"]=int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "pairs_payload=[]\n",
    "for key, row_b, row_h in pairs:\n",
    "    sb = _enrich(name2spec.get(row_b[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(row_h[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=key,\n",
    "        doc_base=str(row_b[\"doc\"]),\n",
    "        doc_hold=str(row_h[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[row_b.to_dict(), row_h.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')} {sh.get('value','?')}`  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# Bundle everything (report + state + manifests + seal + docs)\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():     z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():       z.write(SEAL_MD, arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "acd14e40-5f37-4318-9abf-0d6a6f1162cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[atlas] scanned_dirs=12 csvs=131 minted_pairs=0 → E:\\CNT\\notes\\atlas_pairs.md\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7989761904761905,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8896968888565527,\n",
      "    \"falsifiability\": 0.7571428571428571,\n",
      "    \"total\": 0.8614539841189001\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9505677925712496,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.7949045085606743,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.7783610139281356,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-230826_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Atlas Deep Sweep (pairs + seal) — ONE CELL\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, zipfile, hashlib, glob as globmod\n",
    "\n",
    "# ---------- ROOTS ----------\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "# sweep ALL timestamped atlas dirs\n",
    "ATLAS_GLOB = str(LAB / r\"notebooks\\archive\\cnt_3i_atlas_all8*\")\n",
    "DOC_ATLAS  = LAB / r\"notes\\atlas_pairs.md\"  # where we’ll write the tests\n",
    "DOC_EWB    = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL   = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- REQUIRE MEGA-CELL CORE ----------\n",
    "try:\n",
    "    run_cycle\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your Mega Cell first so run_cycle() and TEST_FENCE exist.\")\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# pick meaningful metric columns if present\n",
    "METRIC_PREFS = [\"auc\",\"roc_auc\",\"auroc\",\"ap\",\"aupr\",\"f1\",\"f1_score\",\"precision\",\"recall\",\"accuracy\"]\n",
    "\n",
    "def _pick_metric_col(df: pd.DataFrame, prefer=None):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    prefs = ([prefer] if prefer else []) + METRIC_PREFS\n",
    "    for want in prefs:\n",
    "        if want and _norm(want) in nm:\n",
    "            return nm[_norm(want)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(series, mode=\"relative_90pct\"):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode == \"relative_90pct\": return float(round(0.9*float(s.mean()), 6))\n",
    "    if mode == \"above_chance\":   return 0.50\n",
    "    if mode == \"strict_055\":     return 0.55\n",
    "    return float(round(0.9*float(s.mean()), 6))\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "\n",
    "def _upsert_fenced(doc_text: str, name: str, block: str) -> str:\n",
    "    out, replaced = doc_text, False\n",
    "    for m in TEST_FENCE.finditer(doc_text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.strip().lower():\n",
    "            a,b = m.span(); out = doc_text[:a] + block + doc_text[b:]; replaced=True; break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "def _is_holdout_stem(stem: str) -> bool:\n",
    "    return bool(re.search(r\"(?i)(holdout|val|validation|test)\", stem))\n",
    "\n",
    "def _atlas_basekey(stem: str):\n",
    "    # strip common holdout/test tokens and trailing run indices\n",
    "    s = re.sub(r\"(?i)([_\\-](holdout|val|validation|test))+$\", \"\", stem)\n",
    "    s = re.sub(r\"[_\\-](v\\d+|\\d{6,})$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "# ---------- 1) SCAN ALL ATLAS CSVs (not just out/tables) ----------\n",
    "atlas_dirs = [Path(p) for p in globmod.glob(ATLAS_GLOB) if Path(p).is_dir()]\n",
    "csv_paths  = []\n",
    "for d in atlas_dirs:\n",
    "    csv_paths += [Path(p) for p in globmod.glob(str(d / \"**\" / \"*.csv\"), recursive=True)]\n",
    "\n",
    "# Group by (nearest 'out' dir if present else parent) + base key\n",
    "from collections import defaultdict\n",
    "by_bucket = defaultdict(lambda: {\"base\": None, \"hold\": None, \"all\": []})\n",
    "\n",
    "for p in csv_paths:\n",
    "    stem = p.stem\n",
    "    # bucket dir: prefer .../out/... if present\n",
    "    parts = p.parts\n",
    "    if \"out\" in [s.lower() for s in parts]:\n",
    "        # slice up to 'out'\n",
    "        idx = [s.lower() for s in parts].index(\"out\")\n",
    "        bucket_dir = Path(*parts[:idx+1])  # e.g., .../out\n",
    "    else:\n",
    "        bucket_dir = p.parent\n",
    "    key = _atlas_basekey(stem)\n",
    "    rec = by_bucket[(bucket_dir, key)]\n",
    "    rec[\"all\"].append(p)\n",
    "    if _is_holdout_stem(stem):\n",
    "        rec[\"hold\"] = rec[\"hold\"] or p\n",
    "    else:\n",
    "        rec[\"base\"] = rec[\"base\"] or p\n",
    "\n",
    "# ---------- 2) MINT GOLD base↔holdout tests into atlas_pairs.md ----------\n",
    "DOC_ATLAS.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt_atlas = DOC_ATLAS.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_ATLAS.exists() else \"# 3I Atlas — Paired Evidence\\n\"\n",
    "\n",
    "minted_pairs = 0\n",
    "for (bucket, key), rec in by_bucket.items():\n",
    "    base, hold = rec[\"base\"], rec[\"hold\"]\n",
    "    if not (base and hold and base.exists() and hold.exists()):\n",
    "        continue\n",
    "    try:\n",
    "        dfb = pd.read_csv(base); dfh = pd.read_csv(hold)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    col_b = _pick_metric_col(dfb, None)\n",
    "    col_h = _pick_metric_col(dfh, col_b)\n",
    "    if not col_b or not col_h:\n",
    "        continue\n",
    "\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty:\n",
    "        continue\n",
    "\n",
    "    thr_b = _policy_value(sb, \"relative_90pct\")\n",
    "    thr_h = _policy_value(sh, \"relative_90pct\")\n",
    "\n",
    "    # unique, stable names per bucket+key\n",
    "    bslug = _norm(str(bucket).replace(\"\\\\\",\"/\").split(\"/\")[-1] + \"_\" + key)[:48]\n",
    "    name_base = f\"pair_atlas_{bslug}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(\n",
    "        name=name_base, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(base)), column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb))\n",
    "    )\n",
    "    spec_h = dict(\n",
    "        name=name_hold, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(hold)), column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(hold), rows=int(len(dfh))\n",
    "    )\n",
    "\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_base, _fence(spec_b))\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_hold, _fence(spec_h))\n",
    "    minted_pairs += 1\n",
    "\n",
    "DOC_ATLAS.write_text(txt_atlas, encoding=\"utf-8\")\n",
    "print(f\"[atlas] scanned_dirs={len(atlas_dirs)} csvs={len(csv_paths)} minted_pairs={minted_pairs} → {DOC_ATLAS}\")\n",
    "\n",
    "# ---------- 3) RUN ENGINE (paired-evidence runner assumed already patched) ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- 4) REFRESH SEAL (pairs-only) + BUNDLE ----------\n",
    "# Use latest report to gather true pairs\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "dfrep = pd.read_csv(REP)\n",
    "\n",
    "def _is_hold(nm): return str(nm).lower().strip().endswith(\"_holdout\")\n",
    "def _base_key(nm):\n",
    "    s = str(nm).strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "ok = dfrep[(dfrep[\"reason\"]==\"ok\") & (dfrep[\"valid\"]==1) & (dfrep[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "\n",
    "# name -> spec across docs we care about\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "name2spec = {}\n",
    "doc_candidates = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists(): doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"):\n",
    "        out[\"hash\"] = _sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "pairs_payload=[]\n",
    "for k, g in ok.groupby(ok[\"name\"].apply(_base_key)):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if gb.empty or gh.empty: \n",
    "        continue\n",
    "    rb, rh = gb.iloc[0], gh.iloc[0]\n",
    "    sb = _enrich(name2spec.get(rb[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(rh[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=k,\n",
    "        doc_base=str(rb[\"doc\"]), doc_hold=str(rh[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[rb.to_dict(), rh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')}` {sh.get('value','?')}  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# ---------- 5) BUNDLE everything ----------\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():     z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():       z.write(SEAL_MD, arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "140b0969-b73d-455a-b2e4-99e11176575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[atlas] scanned_dirs=12 csvs=131 minted_pairs=0 → E:\\CNT\\notes\\atlas_pairs.md\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7989761904761905,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8896968888565527,\n",
      "    \"falsifiability\": 0.7571428571428571,\n",
      "    \"total\": 0.8614539841189001\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9505677925712496,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.7949045085606743,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.7783610139281356,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-230928_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Atlas Deep Sweep (pairs + seal) — ONE CELL\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, zipfile, hashlib, glob as globmod\n",
    "\n",
    "# ---------- ROOTS ----------\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "# sweep ALL timestamped atlas dirs\n",
    "ATLAS_GLOB = str(LAB / r\"notebooks\\archive\\cnt_3i_atlas_all8*\")\n",
    "DOC_ATLAS  = LAB / r\"notes\\atlas_pairs.md\"  # where we’ll write the tests\n",
    "DOC_EWB    = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL   = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- REQUIRE MEGA-CELL CORE ----------\n",
    "try:\n",
    "    run_cycle\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your Mega Cell first so run_cycle() and TEST_FENCE exist.\")\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# pick meaningful metric columns if present\n",
    "METRIC_PREFS = [\"auc\",\"roc_auc\",\"auroc\",\"ap\",\"aupr\",\"f1\",\"f1_score\",\"precision\",\"recall\",\"accuracy\"]\n",
    "\n",
    "def _pick_metric_col(df: pd.DataFrame, prefer=None):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    prefs = ([prefer] if prefer else []) + METRIC_PREFS\n",
    "    for want in prefs:\n",
    "        if want and _norm(want) in nm:\n",
    "            return nm[_norm(want)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(series, mode=\"relative_90pct\"):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode == \"relative_90pct\": return float(round(0.9*float(s.mean()), 6))\n",
    "    if mode == \"above_chance\":   return 0.50\n",
    "    if mode == \"strict_055\":     return 0.55\n",
    "    return float(round(0.9*float(s.mean()), 6))\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "\n",
    "def _upsert_fenced(doc_text: str, name: str, block: str) -> str:\n",
    "    out, replaced = doc_text, False\n",
    "    for m in TEST_FENCE.finditer(doc_text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.strip().lower():\n",
    "            a,b = m.span(); out = doc_text[:a] + block + doc_text[b:]; replaced=True; break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "def _is_holdout_stem(stem: str) -> bool:\n",
    "    return bool(re.search(r\"(?i)(holdout|val|validation|test)\", stem))\n",
    "\n",
    "def _atlas_basekey(stem: str):\n",
    "    # strip common holdout/test tokens and trailing run indices\n",
    "    s = re.sub(r\"(?i)([_\\-](holdout|val|validation|test))+$\", \"\", stem)\n",
    "    s = re.sub(r\"[_\\-](v\\d+|\\d{6,})$\", \"\", s)\n",
    "    return s\n",
    "\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "# ---------- 1) SCAN ALL ATLAS CSVs (not just out/tables) ----------\n",
    "atlas_dirs = [Path(p) for p in globmod.glob(ATLAS_GLOB) if Path(p).is_dir()]\n",
    "csv_paths  = []\n",
    "for d in atlas_dirs:\n",
    "    csv_paths += [Path(p) for p in globmod.glob(str(d / \"**\" / \"*.csv\"), recursive=True)]\n",
    "\n",
    "# Group by (nearest 'out' dir if present else parent) + base key\n",
    "from collections import defaultdict\n",
    "by_bucket = defaultdict(lambda: {\"base\": None, \"hold\": None, \"all\": []})\n",
    "\n",
    "for p in csv_paths:\n",
    "    stem = p.stem\n",
    "    # bucket dir: prefer .../out/... if present\n",
    "    parts = p.parts\n",
    "    if \"out\" in [s.lower() for s in parts]:\n",
    "        # slice up to 'out'\n",
    "        idx = [s.lower() for s in parts].index(\"out\")\n",
    "        bucket_dir = Path(*parts[:idx+1])  # e.g., .../out\n",
    "    else:\n",
    "        bucket_dir = p.parent\n",
    "    key = _atlas_basekey(stem)\n",
    "    rec = by_bucket[(bucket_dir, key)]\n",
    "    rec[\"all\"].append(p)\n",
    "    if _is_holdout_stem(stem):\n",
    "        rec[\"hold\"] = rec[\"hold\"] or p\n",
    "    else:\n",
    "        rec[\"base\"] = rec[\"base\"] or p\n",
    "\n",
    "# ---------- 2) MINT GOLD base↔holdout tests into atlas_pairs.md ----------\n",
    "DOC_ATLAS.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt_atlas = DOC_ATLAS.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_ATLAS.exists() else \"# 3I Atlas — Paired Evidence\\n\"\n",
    "\n",
    "minted_pairs = 0\n",
    "for (bucket, key), rec in by_bucket.items():\n",
    "    base, hold = rec[\"base\"], rec[\"hold\"]\n",
    "    if not (base and hold and base.exists() and hold.exists()):\n",
    "        continue\n",
    "    try:\n",
    "        dfb = pd.read_csv(base); dfh = pd.read_csv(hold)\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "    col_b = _pick_metric_col(dfb, None)\n",
    "    col_h = _pick_metric_col(dfh, col_b)\n",
    "    if not col_b or not col_h:\n",
    "        continue\n",
    "\n",
    "    sb = pd.to_numeric(dfb[col_b], errors=\"coerce\").dropna()\n",
    "    sh = pd.to_numeric(dfh[col_h], errors=\"coerce\").dropna()\n",
    "    if sb.empty or sh.empty:\n",
    "        continue\n",
    "\n",
    "    thr_b = _policy_value(sb, \"relative_90pct\")\n",
    "    thr_h = _policy_value(sh, \"relative_90pct\")\n",
    "\n",
    "    # unique, stable names per bucket+key\n",
    "    bslug = _norm(str(bucket).replace(\"\\\\\",\"/\").split(\"/\")[-1] + \"_\" + key)[:48]\n",
    "    name_base = f\"pair_atlas_{bslug}\"\n",
    "    name_hold = f\"{name_base}_holdout\"\n",
    "\n",
    "    spec_b = dict(\n",
    "        name=name_base, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(base)), column=col_b, op=\">\", value=thr_b, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(base), rows=int(len(dfb))\n",
    "    )\n",
    "    spec_h = dict(\n",
    "        name=name_hold, type=\"csv_threshold\",\n",
    "        path=str(PureWindowsPath(hold)), column=col_h, op=\">\", value=thr_h, agg=\"mean\",\n",
    "        gold=True, frozen_at=STAMP, hash=_sha256(hold), rows=int(len(dfh))\n",
    "    )\n",
    "\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_base, _fence(spec_b))\n",
    "    txt_atlas = _upsert_fenced(txt_atlas, name_hold, _fence(spec_h))\n",
    "    minted_pairs += 1\n",
    "\n",
    "DOC_ATLAS.write_text(txt_atlas, encoding=\"utf-8\")\n",
    "print(f\"[atlas] scanned_dirs={len(atlas_dirs)} csvs={len(csv_paths)} minted_pairs={minted_pairs} → {DOC_ATLAS}\")\n",
    "\n",
    "# ---------- 3) RUN ENGINE (paired-evidence runner assumed already patched) ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- 4) REFRESH SEAL (pairs-only) + BUNDLE ----------\n",
    "# Use latest report to gather true pairs\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "dfrep = pd.read_csv(REP)\n",
    "\n",
    "def _is_hold(nm): return str(nm).lower().strip().endswith(\"_holdout\")\n",
    "def _base_key(nm):\n",
    "    s = str(nm).strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "ok = dfrep[(dfrep[\"reason\"]==\"ok\") & (dfrep[\"valid\"]==1) & (dfrep[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "\n",
    "# name -> spec across docs we care about\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "name2spec = {}\n",
    "doc_candidates = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists(): doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"):\n",
    "        out[\"hash\"] = _sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "pairs_payload=[]\n",
    "for k, g in ok.groupby(ok[\"name\"].apply(_base_key)):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if gb.empty or gh.empty: \n",
    "        continue\n",
    "    rb, rh = gb.iloc[0], gh.iloc[0]\n",
    "    sb = _enrich(name2spec.get(rb[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(rh[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=k,\n",
    "        doc_base=str(rb[\"doc\"]), doc_hold=str(rh[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[rb.to_dict(), rh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')}` {sh.get('value','?')}  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# ---------- 5) BUNDLE everything ----------\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():     z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():       z.write(SEAL_MD, arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8666070e-da06-40d0-a1ec-e50d48a582de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[atlas] schema-inferred pairs minted: 19 → E:\\CNT\\notes\\atlas_pairs.md\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bucket</th>\n",
       "      <th>base</th>\n",
       "      <th>hold</th>\n",
       "      <th>colA</th>\n",
       "      <th>colB</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>EW_389.0nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>EW_388.3nm</td>\n",
       "      <td>EW_388.3nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>EW_388.3nm</td>\n",
       "      <td>EW_388.3nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>wavelength_nm</td>\n",
       "      <td>1.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               bucket  \\\n",
       "0   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "1   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "2   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "3   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "4   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "5   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "6   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "7   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "\n",
       "                                                 base  \\\n",
       "0   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "1   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "2   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "3   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "4   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "5   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "6   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "7   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...   \n",
       "\n",
       "                                                 hold           colA  \\\n",
       "0   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "1   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...     EW_389.0nm   \n",
       "2   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "3   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...     EW_389.0nm   \n",
       "4   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "5   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...     EW_389.0nm   \n",
       "6   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "7   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "8   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...     EW_388.3nm   \n",
       "9   E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "10  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...     EW_388.3nm   \n",
       "11  E:\\CNT\\notebooks\\archive\\cnt_3i_atlas_all8_202...  wavelength_nm   \n",
       "\n",
       "             colB  score  \n",
       "0   wavelength_nm   1.25  \n",
       "1      EW_389.0nm   1.25  \n",
       "2   wavelength_nm   1.25  \n",
       "3      EW_389.0nm   1.25  \n",
       "4   wavelength_nm   1.25  \n",
       "5      EW_389.0nm   1.25  \n",
       "6   wavelength_nm   1.25  \n",
       "7   wavelength_nm   1.25  \n",
       "8      EW_388.3nm   1.25  \n",
       "9   wavelength_nm   1.25  \n",
       "10     EW_388.3nm   1.25  \n",
       "11  wavelength_nm   1.25  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7956333333333334,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8834342625939264,\n",
      "    \"falsifiability\": 0.7666666666666666,\n",
      "    \"total\": 0.8614335656484816\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9987418722285857,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.9341605828009674,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8611955690854229,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-231112_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Atlas Pair Inference v3 (schema-based)\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, zipfile, hashlib, itertools, math\n",
    "import numpy as np\n",
    "import glob as globmod\n",
    "\n",
    "# ---------- ROOTS ----------\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "ATLAS_GLOB = str(LAB / r\"notebooks\\archive\\cnt_3i_atlas_all8*\")\n",
    "DOC_ATLAS  = LAB / r\"notes\\atlas_pairs.md\"   # where Atlas tests will live\n",
    "DOC_EWB    = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL   = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---------- REQUIRE ENGINE CORE ----------\n",
    "try:\n",
    "    run_cycle\n",
    "    TEST_FENCE\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your Mega Cell first so run_cycle() and TEST_FENCE exist in this kernel.\")\n",
    "\n",
    "# ---------- TUNABLES ----------\n",
    "MAX_PAIRS_PER_BUCKET   = 6      # cap new Atlas pairs per bucket so we don't spam\n",
    "MIN_COL_JACCARD        = 0.60   # require at least 60% overlap of normalized column names\n",
    "ROW_RATIO_MIN, ROW_RATIO_MAX = 0.5, 2.0  # similar table size guard\n",
    "CALIBRATION_MODE       = \"relative_90pct\"  # 'relative_90pct' | 'above_chance' | 'strict_055'\n",
    "METRIC_PREFS = [\"auc\",\"roc_auc\",\"auroc\",\"ap\",\"aupr\",\"f1\",\"f1_score\",\"precision\",\"recall\",\"accuracy\"]\n",
    "\n",
    "# ---------- HELPERS ----------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _metric_col(df: pd.DataFrame, prefer=None):\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    prefs = ([prefer] if prefer else []) + METRIC_PREFS\n",
    "    for want in prefs:\n",
    "        if want and _norm(want) in nm:\n",
    "            return nm[_norm(want)]\n",
    "    # fallback: first numeric column\n",
    "    for c in df.columns:\n",
    "        if pd.to_numeric(df[c], errors=\"coerce\").notna().any():\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "def _policy_value(series, mode=\"relative_90pct\"):\n",
    "    s = pd.to_numeric(series, errors=\"coerce\").dropna()\n",
    "    if s.empty: return None\n",
    "    if mode == \"relative_90pct\": return float(round(0.9*float(s.mean()), 6))\n",
    "    if mode == \"above_chance\":   return 0.50\n",
    "    if mode == \"strict_055\":     return 0.55\n",
    "    return float(round(0.9*float(s.mean()), 6))\n",
    "\n",
    "def _fence(d: dict) -> str:\n",
    "    return \"```cnt-test\\n\" + yaml.safe_dump(d, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "\n",
    "def _upsert_fenced(doc_text: str, name: str, block: str) -> str:\n",
    "    out, replaced = doc_text, False\n",
    "    for m in TEST_FENCE.finditer(doc_text or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and str(spec.get(\"name\",\"\")).strip().lower() == name.strip().lower():\n",
    "            a,b = m.span(); out = doc_text[:a] + block + doc_text[b:]; replaced=True; break\n",
    "    if not replaced:\n",
    "        out = (out.rstrip() + \"\\n\\n\" + block + \"\\n\")\n",
    "    return out\n",
    "\n",
    "def _col_sig(df: pd.DataFrame):\n",
    "    cols = [c for c in df.columns if pd.to_numeric(df[c], errors=\"coerce\").notna().any() or df[c].dtype.kind in \"biufcOS\"]\n",
    "    return set(_norm(c) for c in cols)\n",
    "\n",
    "def _jaccard(a:set, b:set):\n",
    "    if not a and not b: return 1.0\n",
    "    return len(a & b) / max(1, len(a | b))\n",
    "\n",
    "def _bucket_for(p: Path):\n",
    "    # prefer .../out/... ancestor; else parent folder as bucket\n",
    "    parts = [s.lower() for s in p.parts]\n",
    "    if \"out\" in parts:\n",
    "        idx = parts.index(\"out\")\n",
    "        return Path(*p.parts[:idx+1])\n",
    "    return p.parent\n",
    "\n",
    "# ---------- 1) COLLECT all Atlas CSVs across timestamped dirs ----------\n",
    "atlas_dirs = [Path(p) for p in globmod.glob(ATLAS_GLOB) if Path(p).is_dir()]\n",
    "csv_paths  = []\n",
    "for d in atlas_dirs:\n",
    "    csv_paths += [Path(p) for p in globmod.glob(str(d / \"**\" / \"*.csv\"), recursive=True)]\n",
    "\n",
    "if not csv_paths:\n",
    "    print(\"[atlas] no CSVs found under\", ATLAS_GLOB)\n",
    "\n",
    "# ---------- 2) BUILD per-file descriptors (row count, col signature, preferred metric) ----------\n",
    "files = []\n",
    "for p in csv_paths:\n",
    "    try:\n",
    "        df = pd.read_csv(p, nrows=500)  # cheap header/sample read for sig/metric\n",
    "        sig = _col_sig(df)\n",
    "        nrows_full = None\n",
    "        try:\n",
    "            # fast row count without loading entire file\n",
    "            nrows_full = sum(1 for _ in open(p, \"r\", encoding=\"utf-8\", errors=\"ignore\")) - 1\n",
    "        except Exception:\n",
    "            pass\n",
    "        metric = _metric_col(df, None)\n",
    "        files.append(dict(path=p, bucket=_bucket_for(p), rows=nrows_full, sig=sig, metric=metric))\n",
    "    except Exception:\n",
    "        continue\n",
    "\n",
    "# group by bucket\n",
    "from collections import defaultdict\n",
    "by_bucket = defaultdict(list)\n",
    "for f in files:\n",
    "    by_bucket[f[\"bucket\"]].append(f)\n",
    "\n",
    "# ---------- 3) INFER pairs inside each bucket by schema similarity ----------\n",
    "def pair_candidates(infos):\n",
    "    # compute scores for all pairs; greedy select non-overlapping best\n",
    "    scored = []\n",
    "    for i, j in itertools.combinations(range(len(infos)), 2):\n",
    "        A, B = infos[i], infos[j]\n",
    "        # basic filters\n",
    "        if not A[\"sig\"] or not B[\"sig\"]:\n",
    "            continue\n",
    "        jac = _jaccard(A[\"sig\"], B[\"sig\"])\n",
    "        if jac < MIN_COL_JACCARD:\n",
    "            continue\n",
    "        # row ratio close-ish\n",
    "        ra = A[\"rows\"] or 0; rb = B[\"rows\"] or 0\n",
    "        ok_rows = (ra==0 or rb==0) or (ROW_RATIO_MIN <= (ra / rb if rb else 1) <= ROW_RATIO_MAX)\n",
    "        if not ok_rows:\n",
    "            continue\n",
    "        # metric that exists in BOTH (prefer A.metric/B.metric; otherwise any intersecting numeric col)\n",
    "        common_cols = list(A[\"sig\"] & B[\"sig\"])\n",
    "        preferred = None\n",
    "        for pref in ([A[\"metric\"], B[\"metric\"]] + METRIC_PREFS):\n",
    "            if pref and _norm(pref) in common_cols:\n",
    "                preferred = pref; break\n",
    "        has_metric = preferred is not None\n",
    "        score = jac + (0.25 if has_metric else 0.0) + (0.05 if (\"holdout\" in str(B[\"path\"]).lower() or \"val\" in str(B[\"path\"]).lower() or \"test\" in str(B[\"path\"]).lower()) else 0.0)\n",
    "        scored.append((score, i, j, preferred))\n",
    "    scored.sort(reverse=True, key=lambda t: t[0])\n",
    "    # greedy non-overlap\n",
    "    used = set()\n",
    "    pairs = []\n",
    "    for score, i, j, pref in scored:\n",
    "        if i in used or j in used:\n",
    "            continue\n",
    "        pairs.append((infos[i], infos[j], pref, score))\n",
    "        used.add(i); used.add(j)\n",
    "        if len(pairs) >= MAX_PAIRS_PER_BUCKET:\n",
    "            break\n",
    "    return pairs\n",
    "\n",
    "# ---------- 4) MINT tests for accepted pairs ----------\n",
    "DOC_ATLAS.parent.mkdir(parents=True, exist_ok=True)\n",
    "txt_atlas = DOC_ATLAS.read_text(encoding=\"utf-8\", errors=\"ignore\") if DOC_ATLAS.exists() else \"# 3I Atlas — Paired Evidence\\n\"\n",
    "\n",
    "minted_pairs = 0\n",
    "mint_log = []\n",
    "\n",
    "for bucket, infos in by_bucket.items():\n",
    "    pairs = pair_candidates(infos)\n",
    "    for A, B, pref, score in pairs:\n",
    "        try:\n",
    "            dfA = pd.read_csv(A[\"path\"])\n",
    "            dfB = pd.read_csv(B[\"path\"])\n",
    "        except Exception:\n",
    "            continue\n",
    "        colA = _metric_col(dfA, pref)\n",
    "        colB = _metric_col(dfB, colA)\n",
    "        if not colA or not colB:\n",
    "            continue\n",
    "        sA = pd.to_numeric(dfA[colA], errors=\"coerce\").dropna()\n",
    "        sB = pd.to_numeric(dfB[colB], errors=\"coerce\").dropna()\n",
    "        if sA.empty or sB.empty:\n",
    "            continue\n",
    "\n",
    "        thrA = _policy_value(sA, CALIBRATION_MODE)\n",
    "        thrB = _policy_value(sB, CALIBRATION_MODE)\n",
    "\n",
    "        # stable slug for names (bucket last dir + common stem-ish)\n",
    "        bslug = _norm(str(bucket).replace(\"\\\\\",\"/\").split(\"/\")[-1])\n",
    "        stem_common = _norm(Path(A[\"path\"]).stem.split(\"_\")[0] + \"_\" + Path(B[\"path\"]).stem.split(\"_\")[0])[:32]\n",
    "        slug = (bslug + \"_\" + stem_common)[:48]\n",
    "\n",
    "        name_base = f\"pair_atlas_{slug}_a\"\n",
    "        name_hold = f\"pair_atlas_{slug}_b\"\n",
    "\n",
    "        specA = dict(\n",
    "            name=name_base, type=\"csv_threshold\",\n",
    "            path=str(PureWindowsPath(A[\"path\"])), column=colA, op=\">\", value=thrA, agg=\"mean\",\n",
    "            gold=True, frozen_at=STAMP, hash=_sha256(A[\"path\"]), rows=int(len(dfA))\n",
    "        )\n",
    "        specB = dict(\n",
    "            name=name_hold, type=\"csv_threshold\",\n",
    "            path=str(PureWindowsPath(B[\"path\"])), column=colB, op=\">\", value=thrB, agg=\"mean\",\n",
    "            gold=True, frozen_at=STAMP, hash=_sha256(B[\"path\"]), rows=int(len(dfB))\n",
    "        )\n",
    "\n",
    "        txt_atlas = _upsert_fenced(txt_atlas, name_base, _fence(specA))\n",
    "        txt_atlas = _upsert_fenced(txt_atlas, name_hold, _fence(specB))\n",
    "        minted_pairs += 1\n",
    "        mint_log.append(dict(bucket=str(bucket), base=str(A[\"path\"]), hold=str(B[\"path\"]), colA=colA, colB=colB, score=round(score,3)))\n",
    "\n",
    "DOC_ATLAS.write_text(txt_atlas, encoding=\"utf-8\")\n",
    "print(f\"[atlas] schema-inferred pairs minted: {minted_pairs} → {DOC_ATLAS}\")\n",
    "if mint_log:\n",
    "    df_minted = pd.DataFrame(mint_log)\n",
    "    try:\n",
    "        from IPython.display import display\n",
    "        display(df_minted.head(12))\n",
    "    except Exception:\n",
    "        print(df_minted.head(12).to_string(index=False))\n",
    "\n",
    "# ---------- 5) RUN ENGINE (paired-evidence runner assumed already patched) ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- 6) REFRESH SEAL + BUNDLE ----------\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        txt = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "# Gather true counted pairs from latest report\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "dfrep = pd.read_csv(REP)\n",
    "\n",
    "def _is_hold(nm): return str(nm).lower().strip().endswith(\"_holdout\")\n",
    "def _base_key(nm):\n",
    "    s = str(nm).strip()\n",
    "    return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "ok = dfrep[(dfrep[\"reason\"]==\"ok\") & (dfrep[\"valid\"]==1) & (dfrep[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "\n",
    "# name -> spec from docs\n",
    "name2spec = {}\n",
    "doc_candidates = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists(): doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"):\n",
    "        out[\"hash\"] = _sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "pairs_payload=[]\n",
    "for k, g in ok.groupby(ok[\"name\"].apply(_base_key)):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if gb.empty or gh.empty: \n",
    "        continue\n",
    "    rb, rh = gb.iloc[0], gh.iloc[0]\n",
    "    sb = _enrich(name2spec.get(rb[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(rh[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=k,\n",
    "        doc_base=str(rb[\"doc\"]), doc_hold=str(rh[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[rb.to_dict(), rh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')} {sh.get('value','?')}`  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# Bundle everything\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():     z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():       z.write(SEAL_MD, arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "84d4f47b-3668-4c28-ba00-157c1d042acb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[atlas-rename] slugs_seen=2 renamed_pairs=2\n",
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7956142857142857,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8834342625939264,\n",
      "    \"falsifiability\": 0.7666666666666666,\n",
      "    \"total\": 0.8614288037437197\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9987418722285857,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.9341605828009674,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8611955690854229,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "=== Pair Summary (after rename) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_ok</th>\n",
       "      <th>hold_ok</th>\n",
       "      <th>counted</th>\n",
       "      <th>total</th>\n",
       "      <th>pair_ok</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pairatlasdataspectrumspectru</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasdataspectrumspectrum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasoutgragr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasoutgragra</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments2025101723521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments20251017235217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary2025101723320</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary20251017233201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv212025101723401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2120251017234015</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv222025101723454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2220251017234543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv232025101723495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2320251017234953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpai</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpair</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresult</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testgoldverificationsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015163558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbaut</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecisio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015164130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresults</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testreadme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       base_ok  hold_ok  counted  total  \\\n",
       "base_key                                                                  \n",
       "pairatlasdataspectrumspectru                 0        0        0      1   \n",
       "pairatlasdataspectrumspectrum                0        0        0      1   \n",
       "pairatlasoutgragr                            0        0        0      1   \n",
       "pairatlasoutgragra                           0        0        0      1   \n",
       "pairewbcoolingsegments2025101723521          0        0        0      1   \n",
       "pairewbcoolingsegments20251017235217         0        0        0      1   \n",
       "pairewbsummary2025101723320                  0        0        0      1   \n",
       "pairewbsummary20251017233201                 0        0        0      1   \n",
       "pairewbsummaryv212025101723401               0        0        0      1   \n",
       "pairewbsummaryv2120251017234015              0        0        0      1   \n",
       "pairewbsummaryv222025101723454               0        0        0      1   \n",
       "pairewbsummaryv2220251017234543              0        0        0      1   \n",
       "pairewbsummaryv232025101723495               0        0        0      1   \n",
       "pairewbsummaryv2320251017234953              0        0        0      1   \n",
       "testewbauto                                  0        0        0      1   \n",
       "testewbpai                                   0        0        0      1   \n",
       "testewbpair                                  0        0        0      1   \n",
       "testewbprecision                             0        0        0      1   \n",
       "testewbresult                                0        0        0      1   \n",
       "testgoldverificationsummary                  0        0        0      1   \n",
       "testcntcorrelatesreport20251015163558        0        0        0      2   \n",
       "testewbaut                                   0        0        0      2   \n",
       "testewbprecisio                              0        0        0      2   \n",
       "testcntcorrelatesreport20251015164130        0        0        0      3   \n",
       "testewbresults                               0        0        0      3   \n",
       "testreadme                                   0        0        0      3   \n",
       "testsummary                                  0        0        0      4   \n",
       "\n",
       "                                       pair_ok  \n",
       "base_key                                        \n",
       "pairatlasdataspectrumspectru                 0  \n",
       "pairatlasdataspectrumspectrum                0  \n",
       "pairatlasoutgragr                            0  \n",
       "pairatlasoutgragra                           0  \n",
       "pairewbcoolingsegments2025101723521          0  \n",
       "pairewbcoolingsegments20251017235217         0  \n",
       "pairewbsummary2025101723320                  0  \n",
       "pairewbsummary20251017233201                 0  \n",
       "pairewbsummaryv212025101723401               0  \n",
       "pairewbsummaryv2120251017234015              0  \n",
       "pairewbsummaryv222025101723454               0  \n",
       "pairewbsummaryv2220251017234543              0  \n",
       "pairewbsummaryv232025101723495               0  \n",
       "pairewbsummaryv2320251017234953              0  \n",
       "testewbauto                                  0  \n",
       "testewbpai                                   0  \n",
       "testewbpair                                  0  \n",
       "testewbprecision                             0  \n",
       "testewbresult                                0  \n",
       "testgoldverificationsummary                  0  \n",
       "testcntcorrelatesreport20251015163558        0  \n",
       "testewbaut                                   0  \n",
       "testewbprecisio                              0  \n",
       "testcntcorrelatesreport20251015164130        0  \n",
       "testewbresults                               0  \n",
       "testreadme                                   0  \n",
       "testsummary                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-231719_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ================================\n",
    "# CNT — Atlas Pair Renamer (a/b → base/_holdout) + Re-Run + Seal\n",
    "# ================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, glob as globmod, hashlib, zipfile\n",
    "\n",
    "LAB = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "\n",
    "DOC_ATLAS = LAB / r\"notes\\atlas_pairs.md\"\n",
    "DOC_EWB   = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL  = LAB / r\"notes\\cooling_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# Need the mega-cell’s parser/runner\n",
    "try:\n",
    "    TEST_FENCE, run_cycle\n",
    "except NameError:\n",
    "    TEST_FENCE = re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL)\n",
    "    raise RuntimeError(\"Load your main Mega Cell first so TEST_FENCE and run_cycle are defined.\")\n",
    "\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p,\"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "# --- 1) Read atlas_pairs.md and collect pair_atlas_*_(a|b) tests\n",
    "if not DOC_ATLAS.exists():\n",
    "    raise SystemExit(f\"Atlas doc not found: {DOC_ATLAS}\")\n",
    "\n",
    "txt = DOC_ATLAS.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "pat_name = re.compile(r\"^(pair_atlas_.+?)_(a|b)$\", re.IGNORECASE)\n",
    "hold_tokens = re.compile(r\"(?i)\\b(holdout|oos|oot|out[-_]?of[-_]?sample|val|validation|test|dev|eval)\\b\")\n",
    "\n",
    "blocks = []\n",
    "for m in TEST_FENCE.finditer(txt or \"\"):\n",
    "    body = m.group(\"body\")\n",
    "    try:\n",
    "        spec = yaml.safe_load(body) or {}\n",
    "    except Exception:\n",
    "        continue\n",
    "    if not isinstance(spec, dict) or spec.get(\"type\") != \"csv_threshold\":\n",
    "        continue\n",
    "    nm = str(spec.get(\"name\",\"\")).strip()\n",
    "    mm = pat_name.match(nm)\n",
    "    if mm:\n",
    "        slug, tag = mm.group(1), mm.group(2).lower()\n",
    "        blocks.append(dict(slug=slug, tag=tag, name=nm, span=m.span(), spec=spec))\n",
    "\n",
    "# Group by slug, expect 2 per group\n",
    "from collections import defaultdict\n",
    "by_slug = defaultdict(list)\n",
    "for b in blocks:\n",
    "    by_slug[b[\"slug\"]].append(b)\n",
    "\n",
    "# --- 2) Decide base vs holdout for each slug, rename accordingly, keep GOLD metadata\n",
    "changes = []\n",
    "renamed_pairs = 0\n",
    "\n",
    "def pick_hold(a, b):\n",
    "    # Prefer file/name with holdout tokens\n",
    "    def score(item):\n",
    "        s = 0\n",
    "        p = str(item[\"spec\"].get(\"path\",\"\"))\n",
    "        n = item[\"name\"]\n",
    "        if hold_tokens.search(p): s += 2\n",
    "        if hold_tokens.search(n): s += 1\n",
    "        # Light heuristic: smaller mean metric might be holdout (optional)\n",
    "        col = item[\"spec\"].get(\"column\")\n",
    "        if p and col and Path(p).exists():\n",
    "            try:\n",
    "                v = pd.to_numeric(pd.read_csv(p)[col], errors=\"coerce\").dropna().mean()\n",
    "                item[\"_mean\"] = float(v)\n",
    "            except Exception:\n",
    "                pass\n",
    "        return s\n",
    "    sa, sb = score(a), score(b)\n",
    "    if sa > sb: return a, b  # (hold, base)\n",
    "    if sb > sa: return b, a\n",
    "    # Fallback: tag 'b' as holdout\n",
    "    return (b, a) if b[\"tag\"] == \"b\" else (a, b)\n",
    "\n",
    "for slug, items in by_slug.items():\n",
    "    if len(items) < 2:\n",
    "        continue\n",
    "    # two items: choose hold/base\n",
    "    hold, base = pick_hold(items[0], items[1])\n",
    "    # new names\n",
    "    base_name = slug\n",
    "    hold_name = f\"{slug}_holdout\"\n",
    "    # Build fenced blocks\n",
    "    base_spec = dict(base[\"spec\"]); base_spec[\"name\"] = base_name\n",
    "    hold_spec = dict(hold[\"spec\"]); hold_spec[\"name\"] = hold_name\n",
    "    # Ensure GOLD metadata completeness (hash/rows)\n",
    "    for sp in (base_spec, hold_spec):\n",
    "        p = Path(sp.get(\"path\",\"\"))\n",
    "        if p.exists() and not sp.get(\"hash\"): sp[\"hash\"] = _sha256(p)\n",
    "        if p.exists() and not sp.get(\"rows\"):\n",
    "            try: sp[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "            except Exception: pass\n",
    "        sp[\"gold\"] = True\n",
    "    # Fenced strings\n",
    "    fb = \"```cnt-test\\n\" + yaml.safe_dump(base_spec, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "    fh = \"```cnt-test\\n\" + yaml.safe_dump(hold_spec, sort_keys=False, allow_unicode=True) + \"```\"\n",
    "    # Queue replacements at their original spans\n",
    "    # Replace the exact matched blocks (order reversed later)\n",
    "    for it, rep in [(base, fb), (hold, fh)]:\n",
    "        changes.append((it[\"span\"][0], it[\"span\"][1], rep))\n",
    "    renamed_pairs += 1\n",
    "\n",
    "# Apply changes (reverse spans to keep indices stable)\n",
    "if changes:\n",
    "    new_txt = txt\n",
    "    for a,b,rep in sorted(changes, key=lambda t: t[0], reverse=True):\n",
    "        new_txt = new_txt[:a] + rep + new_txt[b:]\n",
    "    DOC_ATLAS.write_text(new_txt, encoding=\"utf-8\")\n",
    "print(f\"[atlas-rename] slugs_seen={len(by_slug)} renamed_pairs={renamed_pairs}\")\n",
    "\n",
    "# --- 3) Re-run engine once (paired-evidence runner already patched earlier)\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# --- 4) Pair dashboard (robust)\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1])\n",
    "df  = pd.read_csv(REP)\n",
    "\n",
    "def _is_hold(name): return str(name).lower().strip().endswith(\"_holdout\")\n",
    "if \"base_key\" not in df.columns:\n",
    "    df[\"base_key\"] = df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))\n",
    "df[\"is_hold\"]   = df[\"name\"].apply(_is_hold).astype(int)\n",
    "df[\"ok_row\"]    = (df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"base_pass\"] = ((df[\"is_hold\"]==0) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"hold_pass\"] = ((df[\"is_hold\"]==1) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "\n",
    "dash = df.groupby(\"base_key\").agg(\n",
    "    base_ok=(\"base_pass\",\"max\"),\n",
    "    hold_ok=(\"hold_pass\",\"max\"),\n",
    "    counted=(\"valid\",\"sum\"),\n",
    "    total=(\"name\",\"count\"),\n",
    ")\n",
    "dash[\"pair_ok\"] = (dash[\"base_ok\"] & dash[\"hold_ok\"]).astype(int)\n",
    "\n",
    "print(\"\\n=== Pair Summary (after rename) ===\")\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(50))\n",
    "except Exception:\n",
    "    print(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(50).to_string())\n",
    "\n",
    "# --- 5) Refresh SEAL (pairs-only) + bundle\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try:\n",
    "        t = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception:\n",
    "        return out\n",
    "    for m in TEST_FENCE.finditer(t or \"\"):\n",
    "        try:\n",
    "            spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception:\n",
    "            continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"): out[\"hash\"] = _sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "ok = df[(df[\"reason\"]==\"ok\") & (df[\"valid\"]==1) & (df[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "\n",
    "# name->spec index from relevant docs\n",
    "name2spec = {}\n",
    "docs_use = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists(): docs_use.add(str(extra))\n",
    "for d in docs_use:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "pairs_payload=[]\n",
    "for k, g in ok.groupby(df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if gb.empty or gh.empty: \n",
    "        continue\n",
    "    rb, rh = gb.iloc[0], gh.iloc[0]\n",
    "    sb = _enrich(name2spec.get(rb[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(rh[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=k,\n",
    "        doc_base=str(rb[\"doc\"]), doc_hold=str(rh[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[rb.to_dict(), rh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')} {sh.get('value','?')}`  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# Bundle\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    if Path(REP).exists():     z.write(REP, arcname=Path(REP).name)\n",
    "    if STATE.exists():         z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists():  z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists(): z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():     z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():       z.write(SEAL_MD, arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3171bf9d-96e7-46fb-9176-2f2d5fcd5e26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"score\": {\n",
      "    \"clarity\": 0.7956142857142857,\n",
      "    \"novelty\": 1.0,\n",
      "    \"coherence\": 0.8834342625939264,\n",
      "    \"falsifiability\": 0.7666666666666666,\n",
      "    \"total\": 0.8614288037437197\n",
      "  },\n",
      "  \"proposed\": 5,\n",
      "  \"accepted\": 0,\n",
      "  \"tests_total\": 0,\n",
      "  \"tests_passed\": 0,\n",
      "  \"hidden\": [\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_correlates_report_20251015-164130.txt\",\n",
      "      \"resid\": 0.9987418722285857,\n",
      "      \"hint\": \"== CNT Correlates Audit (Fused) == Timestamp: 20251015-164130 - Cooling logs: 8 - Cosmo triage tables: 1 - EEG laterality tables: 2 - Kuramoto/Ising summaries: 0 - Kuramoto dispersion CSVs: 0 - Gray-Scott edge images: 1 - Scanned logs/text: 50 - Glyph label tables: 0 == Results == [GREY] Cooling: Temp oscillation amplitude predicts clock stability Need logs with GPU temp + GPU clock columns. Add b\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\gra-v0.3\\\\README.md\",\n",
      "      \"resid\": 0.9341605828009674,\n",
      "      \"hint\": \"# Gauge-Restored Agents (GRA) v0.3 **Contract:** Invariant \\u2192 Restored \\u2192 True (or Abstain) This repo ships a tiny, enforceable safety contract for LLM answers: 1) Keep meaning invariant under symbol-preserving transformations, 2) Restore outputs to a domain-safe format when form wobbles, 3) Verify claims (or ABSTAIN if truth is uncertain). ## Domains (v0.3) - **Math:** structured gate (equation + r\"\n",
      "    },\n",
      "    {\n",
      "      \"path\": \"E:\\\\CNT\\\\notebooks\\\\archive\\\\cnt_ewb_theta2\\\\ewb_results.md\",\n",
      "      \"resid\": 0.8611955690854229,\n",
      "      \"hint\": \"# CNT \\u0398* Early-Warning \\u2014 Results (frozen \\u0398* = 0.55) **Registered (UTC):** 2025-10-18T04:09:49.361036Z **Persistence:** k = 3 **Hazard target:** ~25% positives (bounds 15\\u201335%) ## Top Segments (by AUC then Precision@\\u0398*) segment N W AUC Precision@Theta* Lead@Hit(steps) Lead@Any(steps) cnt_cooling_log_20251015_121543 79 32 0.779503 0.353846 22.0 54.0 cnt_cooling_log_20251015_121543_labeled 79 32 0.779\"\n",
      "    }\n",
      "  ]\n",
      "}\n",
      "\n",
      "Reasons breakdown:\n",
      "reason\n",
      "needs_holdout    39\n",
      "Name: count, dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>base_ok</th>\n",
       "      <th>hold_ok</th>\n",
       "      <th>counted</th>\n",
       "      <th>total</th>\n",
       "      <th>pair_ok</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>base_key</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pairatlasdataspectrumspectru</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasdataspectrumspectrum</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasoutgragr</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairatlasoutgragra</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments2025101723521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbcoolingsegments20251017235217</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary2025101723320</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummary20251017233201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv212025101723401</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2120251017234015</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv222025101723454</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2220251017234543</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv232025101723495</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pairewbsummaryv2320251017234953</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbauto</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpai</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbpair</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecision</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresult</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testgoldverificationsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015163558</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbaut</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbprecisio</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testcntcorrelatesreport20251015164130</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testewbresults</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testreadme</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>testsummary</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       base_ok  hold_ok  counted  total  \\\n",
       "base_key                                                                  \n",
       "pairatlasdataspectrumspectru                 0        0        0      1   \n",
       "pairatlasdataspectrumspectrum                0        0        0      1   \n",
       "pairatlasoutgragr                            0        0        0      1   \n",
       "pairatlasoutgragra                           0        0        0      1   \n",
       "pairewbcoolingsegments2025101723521          0        0        0      1   \n",
       "pairewbcoolingsegments20251017235217         0        0        0      1   \n",
       "pairewbsummary2025101723320                  0        0        0      1   \n",
       "pairewbsummary20251017233201                 0        0        0      1   \n",
       "pairewbsummaryv212025101723401               0        0        0      1   \n",
       "pairewbsummaryv2120251017234015              0        0        0      1   \n",
       "pairewbsummaryv222025101723454               0        0        0      1   \n",
       "pairewbsummaryv2220251017234543              0        0        0      1   \n",
       "pairewbsummaryv232025101723495               0        0        0      1   \n",
       "pairewbsummaryv2320251017234953              0        0        0      1   \n",
       "testewbauto                                  0        0        0      1   \n",
       "testewbpai                                   0        0        0      1   \n",
       "testewbpair                                  0        0        0      1   \n",
       "testewbprecision                             0        0        0      1   \n",
       "testewbresult                                0        0        0      1   \n",
       "testgoldverificationsummary                  0        0        0      1   \n",
       "testcntcorrelatesreport20251015163558        0        0        0      2   \n",
       "testewbaut                                   0        0        0      2   \n",
       "testewbprecisio                              0        0        0      2   \n",
       "testcntcorrelatesreport20251015164130        0        0        0      3   \n",
       "testewbresults                               0        0        0      3   \n",
       "testreadme                                   0        0        0      3   \n",
       "testsummary                                  0        0        0      4   \n",
       "\n",
       "                                       pair_ok  \n",
       "base_key                                        \n",
       "pairatlasdataspectrumspectru                 0  \n",
       "pairatlasdataspectrumspectrum                0  \n",
       "pairatlasoutgragr                            0  \n",
       "pairatlasoutgragra                           0  \n",
       "pairewbcoolingsegments2025101723521          0  \n",
       "pairewbcoolingsegments20251017235217         0  \n",
       "pairewbsummary2025101723320                  0  \n",
       "pairewbsummary20251017233201                 0  \n",
       "pairewbsummaryv212025101723401               0  \n",
       "pairewbsummaryv2120251017234015              0  \n",
       "pairewbsummaryv222025101723454               0  \n",
       "pairewbsummaryv2220251017234543              0  \n",
       "pairewbsummaryv232025101723495               0  \n",
       "pairewbsummaryv2320251017234953              0  \n",
       "testewbauto                                  0  \n",
       "testewbpai                                   0  \n",
       "testewbpair                                  0  \n",
       "testewbprecision                             0  \n",
       "testewbresult                                0  \n",
       "testgoldverificationsummary                  0  \n",
       "testcntcorrelatesreport20251015163558        0  \n",
       "testewbaut                                   0  \n",
       "testewbprecisio                              0  \n",
       "testcntcorrelatesreport20251015164130        0  \n",
       "testewbresults                               0  \n",
       "testreadme                                   0  \n",
       "testsummary                                  0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[seal] refreshed → CNT_SEAL.yaml, CNT_SEAL.md\n",
      "[bundle] E:\\CNT\\artifacts\\cnt_engine_megacell\\bundles\\cnt_proof_bundle_20251026-232425_SEAL.zip\n"
     ]
    }
   ],
   "source": [
    "# ===========================================\n",
    "# CNT — Recovery & Pair Count Fix (ONE CELL)\n",
    "# ===========================================\n",
    "from pathlib import Path, PureWindowsPath\n",
    "from datetime import datetime, timezone\n",
    "import os, re, yaml, pandas as pd, json, hashlib, glob as globmod, zipfile\n",
    "\n",
    "LAB   = Path(os.getenv(\"CNT_LAB_DIR\", r\"E:\\CNT\")).resolve()\n",
    "ART   = LAB / r\"artifacts\\cnt_engine_megacell\"\n",
    "OUT   = ART / \"out\"\n",
    "STATE = ART / \"CNT_STATE.yaml\"\n",
    "MANIFEST_CSV  = ART / \"gold_manifest.csv\"\n",
    "MANIFEST_YAML = ART / \"gold_manifest.yaml\"\n",
    "DOC_EWB  = LAB / r\"notebooks\\archive\\cnt_ewb_theta2\\publish\\ewb_publish_v0_2\\ewb_results.md\"\n",
    "DOC_COOL = LAB / r\"notes\\cooling_pairs.md\"\n",
    "DOC_ATLAS= LAB / r\"notes\\atlas_pairs.md\"\n",
    "\n",
    "STAMP = datetime.now(timezone.utc).strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "# ---- EXPECT MEGA-CELL CORE ----\n",
    "try:\n",
    "    run_cycle\n",
    "except NameError:\n",
    "    raise RuntimeError(\"Load your main Mega Cell first so run_cycle() exists in this kernel.\")\n",
    "TEST_FENCE = globals().get(\"TEST_FENCE\", re.compile(r\"```cnt-test\\s*(?P<body>.*?)```\", re.DOTALL))\n",
    "\n",
    "# ---------- Helpers ----------\n",
    "def _norm(s: str) -> str:\n",
    "    return re.sub(r\"[^a-z0-9]+\",\"\", str(s or \"\").strip().lower())\n",
    "\n",
    "def _sha256(p: Path, chunk=1<<20):\n",
    "    h = hashlib.sha256()\n",
    "    with open(p, \"rb\") as f:\n",
    "        for b in iter(lambda: f.read(chunk), b\"\"):\n",
    "            h.update(b)\n",
    "    return h.hexdigest()\n",
    "\n",
    "def _match_col(df: pd.DataFrame, requested: str):\n",
    "    want = _norm(requested or \"\")\n",
    "    if not want: return None\n",
    "    nm = {_norm(c): c for c in df.columns}\n",
    "    return nm.get(want)\n",
    "\n",
    "# ---------- Robust core CSV tester (fallback) ----------\n",
    "def _csv_threshold_test_core(t: dict):\n",
    "    \"\"\"\n",
    "    Evaluates a csv_threshold spec with tolerant column matching.\n",
    "    Returns (ok, info, reason) with reason in {\"ok\",\"skip\",\"non_gold\",\"missing_path\",\"hash_mismatch\",\"missing_column\",\"no_numeric\",\"invalid_type\"}.\n",
    "    \"\"\"\n",
    "    if t.get(\"skip\", False):\n",
    "        return False, \"skip\", \"skip\"\n",
    "\n",
    "    path = t.get(\"path\")\n",
    "    col  = t.get(\"column\")\n",
    "    op   = str(t.get(\"op\", \">\"))\n",
    "    try:  val = float(t.get(\"value\", 0.0))\n",
    "    except Exception: val = 0.0\n",
    "    agg  = str(t.get(\"agg\", \"mean\")).lower()\n",
    "\n",
    "    if not path or not Path(path).exists():\n",
    "        return False, \"missing_path\", \"missing_path\"\n",
    "\n",
    "    # hash check if present\n",
    "    if t.get(\"hash\"):\n",
    "        if _sha256(Path(path)) != str(t[\"hash\"]):\n",
    "            return False, \"hash_mismatch\", \"hash_mismatch\"\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "    col_actual = _match_col(df, col)\n",
    "    if col_actual is None:\n",
    "        # try a few common AUC/precision aliases\n",
    "        for want in [\"auc\",\"roc_auc\",\"auroc\",\"precision@theta*\",\"precision_at_theta\",\"delta_theta\",\"f1\",\"accuracy\"]:\n",
    "            col_actual = _match_col(df, want)\n",
    "            if col_actual: break\n",
    "    if col_actual is None:\n",
    "        return False, \"missing_column\", \"missing_column\"\n",
    "\n",
    "    s = pd.to_numeric(df[col_actual], errors=\"coerce\").dropna()\n",
    "    if s.empty:\n",
    "        return False, \"no_numeric\", \"no_numeric\"\n",
    "\n",
    "    if   agg == \"mean\":   metric = float(s.mean())\n",
    "    elif agg == \"median\": metric = float(s.median())\n",
    "    elif agg == \"any\":    metric = bool((s > val).any()) if op in [\">\", \">=\"] else bool((s < val).any())\n",
    "    elif agg == \"all\":    metric = bool((s > val).all()) if op in [\">\", \">=\"] else bool((s < val).all())\n",
    "    else:                 metric = float(s.mean())\n",
    "\n",
    "    def _cmp(a,b,op): return {\">\":a>b, \">=\":a>=b, \"<\":a<b, \"<=\":a<=b}.get(op, a>b)\n",
    "\n",
    "    if isinstance(metric, bool):\n",
    "        ok, info = metric, f\"{agg}({col_actual})→{ok}\"\n",
    "    else:\n",
    "        ok, info = _cmp(metric, val, op), f\"{agg}({col_actual})={metric:.6f} {op} {val}\"\n",
    "\n",
    "    return bool(ok), info, \"ok\"\n",
    "\n",
    "# ---------- Patch into the live module that owns run_cycle ----------\n",
    "import inspect\n",
    "rc_mod = inspect.getmodule(run_cycle)\n",
    "\n",
    "# Ensure the module exposes the core tester callable\n",
    "setattr(rc_mod, \"_csv_threshold_test\", _csv_threshold_test_core)\n",
    "\n",
    "# Strict wrapper: honors skip + gold + hash, delegates to core\n",
    "def _csv_threshold_test_strict_patch(t: dict):\n",
    "    if t.get(\"skip\", False):     return False, \"skip\", \"skip\"\n",
    "    if not t.get(\"gold\", False): return False, \"non_gold\", \"non_gold\"\n",
    "    # core tester also verifies path/hash/column\n",
    "    return _csv_threshold_test_core(t)\n",
    "\n",
    "# Soft paired runner: singles -> needs_holdout; base+hold must both pass\n",
    "def _paired_runner_soft(df: pd.DataFrame, out_csv: Path):\n",
    "    rows = []\n",
    "    parse = getattr(rc_mod, \"_parse_cnt_tests\", globals().get(\"_parse_cnt_tests\", lambda s: []))\n",
    "\n",
    "    def _is_hold(name: str) -> bool:\n",
    "        return str(name or \"\").strip().lower().endswith(\"_holdout\")\n",
    "    def _base_key(name: str) -> str:\n",
    "        s = str(name or \"\").strip()\n",
    "        return _norm(s[:-9] if s.lower().endswith(\"_holdout\") else s)\n",
    "\n",
    "    for _, r in df.iterrows():\n",
    "        path  = r[\"path\"]\n",
    "        tests = parse(r.get(\"text\",\"\"))\n",
    "        for t in tests:\n",
    "            nm   = t.get(\"name\", Path(path).stem)\n",
    "            ttyp = t.get(\"type\",\"unknown\")\n",
    "            if ttyp == \"csv_threshold\":\n",
    "                ok, info, reason = _csv_threshold_test_strict_patch(t)\n",
    "            else:\n",
    "                ok, info, reason = False, f\"unknown_type:{ttyp}\", \"invalid_type\"\n",
    "            rows.append(dict(\n",
    "                doc=path, name=nm, type=ttyp,\n",
    "                valid=int(reason==\"ok\"), passed=int(bool(ok and reason==\"ok\")),\n",
    "                info=info, reason=reason,\n",
    "                is_holdout=int(_is_hold(nm)), base_key=_base_key(nm),\n",
    "            ))\n",
    "\n",
    "    rep = pd.DataFrame(rows)\n",
    "    if rep.empty:\n",
    "        rep.to_csv(out_csv, index=False); return 0,0,0\n",
    "\n",
    "    # Only strict-ok rows can be counted\n",
    "    rep.loc[~rep[\"reason\"].eq(\"ok\"), [\"valid\",\"passed\"]] = 0\n",
    "\n",
    "    # Pair gating\n",
    "    by_key = {k: list(idxs) for k, idxs in rep.groupby(\"base_key\").indices.items()}\n",
    "    to_pair_fail, to_needs = set(), set()\n",
    "\n",
    "    for key, idxs in by_key.items():\n",
    "        base_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==0]\n",
    "        hold_idxs = [i for i in idxs if rep.loc[i,\"is_holdout\"]==1]\n",
    "        base_pass = any(bool(rep.loc[i,\"passed\"]) for i in base_idxs)\n",
    "        hold_pass = any(bool(rep.loc[i,\"passed\"]) for i in hold_idxs)\n",
    "\n",
    "        if base_idxs and not hold_idxs:\n",
    "            to_needs.update(base_idxs)\n",
    "        elif hold_idxs and not base_idxs:\n",
    "            to_needs.update(hold_idxs)\n",
    "        else:\n",
    "            if not (base_pass and hold_pass):\n",
    "                to_pair_fail.update(base_idxs + hold_idxs)\n",
    "\n",
    "    if to_needs:\n",
    "        rep.loc[list(to_needs), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_needs), \"reason\"] = \"needs_holdout\"\n",
    "    if to_pair_fail:\n",
    "        rep.loc[list(to_pair_fail), [\"valid\",\"passed\"]] = 0\n",
    "        rep.loc[list(to_pair_fail), \"reason\"] = \"pair_fail\"\n",
    "\n",
    "    rep.to_csv(out_csv, index=False)\n",
    "    total  = int(rep[\"valid\"].sum())\n",
    "    passed = int(rep[\"passed\"].sum())\n",
    "    runnable = int(len(rep))\n",
    "    return passed, total, runnable\n",
    "\n",
    "# Bind patched functions\n",
    "setattr(rc_mod, \"_csv_threshold_test_strict\", _csv_threshold_test_strict_patch)\n",
    "setattr(rc_mod, \"run_cnt_tests_on_df\", _paired_runner_soft)\n",
    "\n",
    "# ---------- RUN once ----------\n",
    "res = run_cycle()\n",
    "print(json.dumps(res, indent=2))\n",
    "\n",
    "# ---------- Reasons breakdown + compact dashboard ----------\n",
    "rep_paths = sorted(globmod.glob(str(OUT / \"tests_report_*.csv\")))\n",
    "assert rep_paths, f\"No tests_report_* in {OUT}\"\n",
    "REP = Path(rep_paths[-1]); df = pd.read_csv(REP)\n",
    "\n",
    "print(\"\\nReasons breakdown:\")\n",
    "print(df[\"reason\"].value_counts(dropna=False))\n",
    "\n",
    "def _is_hold(nm): return str(nm).lower().strip().endswith(\"_holdout\")\n",
    "if \"base_key\" not in df.columns:\n",
    "    df[\"base_key\"] = df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))\n",
    "df[\"is_hold\"]   = df[\"name\"].apply(_is_hold).astype(int)\n",
    "df[\"base_pass\"] = ((df[\"is_hold\"]==0) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "df[\"hold_pass\"] = ((df[\"is_hold\"]==1) & (df[\"passed\"]==1) & df[\"reason\"].eq(\"ok\")).astype(int)\n",
    "\n",
    "dash = df.groupby(\"base_key\").agg(\n",
    "    base_ok=(\"base_pass\",\"max\"),\n",
    "    hold_ok=(\"hold_pass\",\"max\"),\n",
    "    counted=(\"valid\",\"sum\"),\n",
    "    total=(\"name\",\"count\"),\n",
    ")\n",
    "dash[\"pair_ok\"] = (dash[\"base_ok\"] & dash[\"hold_ok\"]).astype(int)\n",
    "try:\n",
    "    from IPython.display import display\n",
    "    display(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(40))\n",
    "except Exception:\n",
    "    print(\"\\n=== Pair Summary ===\")\n",
    "    print(dash.sort_values([\"pair_ok\",\"counted\",\"total\"], ascending=[False,False,True]).head(40).to_string())\n",
    "\n",
    "# ---------- Refresh SEAL (pairs-only) + bundle ----------\n",
    "def _load_specs_from(doc_path: Path):\n",
    "    out = {}\n",
    "    try: t = doc_path.read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "    except Exception: return out\n",
    "    for m in TEST_FENCE.finditer(t or \"\"):\n",
    "        try: spec = yaml.safe_load(m.group(\"body\")) or {}\n",
    "        except Exception: continue\n",
    "        if isinstance(spec, dict) and \"name\" in spec and \"type\" in spec:\n",
    "            out[str(spec[\"name\"]).strip()] = spec\n",
    "    return out\n",
    "\n",
    "# keep only counted ok rows\n",
    "ok = df[(df[\"reason\"]==\"ok\") & (df[\"valid\"]==1) & (df[\"passed\"]==1)].copy()\n",
    "ok[\"is_holdout\"] = ok[\"name\"].apply(_is_hold).astype(int)\n",
    "\n",
    "name2spec = {}\n",
    "doc_candidates = set(ok[\"doc\"].tolist())\n",
    "for extra in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "    if extra.exists(): doc_candidates.add(str(extra))\n",
    "for d in doc_candidates:\n",
    "    name2spec.update(_load_specs_from(Path(d)))\n",
    "\n",
    "def _enrich(spec):\n",
    "    out = dict(spec or {})\n",
    "    p = Path(out.get(\"path\",\"\"))\n",
    "    if p.exists() and not out.get(\"hash\"):\n",
    "        out[\"hash\"] = _sha256(p)\n",
    "    if p.exists() and not out.get(\"rows\"):\n",
    "        try: out[\"rows\"] = int(len(pd.read_csv(p)))\n",
    "        except Exception: pass\n",
    "    return out\n",
    "\n",
    "pairs_payload=[]\n",
    "for k, g in ok.groupby(df[\"base_key\"] if \"base_key\" in df.columns else df[\"name\"].apply(lambda s: _norm(s[:-9]) if _is_hold(s) else _norm(s))):\n",
    "    gb = g[g[\"is_holdout\"]==0]\n",
    "    gh = g[g[\"is_holdout\"]==1]\n",
    "    if gb.empty or gh.empty: \n",
    "        continue\n",
    "    rb, rh = gb.iloc[0], gh.iloc[0]\n",
    "    sb = _enrich(name2spec.get(rb[\"name\"], {}))\n",
    "    sh = _enrich(name2spec.get(rh[\"name\"], {}))\n",
    "    pairs_payload.append(dict(\n",
    "        base_key=k,\n",
    "        doc_base=str(rb[\"doc\"]), doc_hold=str(rh[\"doc\"]),\n",
    "        spec_base=sb, spec_hold=sh,\n",
    "        report_rows=[rb.to_dict(), rh.to_dict()],\n",
    "    ))\n",
    "\n",
    "SEAL = dict(\n",
    "    seal_version=\"CNT-Proof-1\",\n",
    "    created_at=STAMP,\n",
    "    lab_root=str(LAB),\n",
    "    engine_state=(yaml.safe_load(STATE.read_text(encoding=\"utf-8\")) if STATE.exists() else {}),\n",
    "    report_file=Path(REP).name,\n",
    "    pairs_ok=len(pairs_payload),\n",
    "    pairs=pairs_payload,\n",
    ")\n",
    "\n",
    "SEAL_YAML = ART / \"CNT_SEAL.yaml\"\n",
    "SEAL_MD   = ART / \"CNT_SEAL.md\"\n",
    "with open(SEAL_YAML, \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.safe_dump(SEAL, f, sort_keys=False, allow_unicode=True)\n",
    "\n",
    "lines = [f\"# CNT Proof Seal — Pairs-Only\",\n",
    "         f\"- Created: {STAMP}\",\n",
    "         f\"- Lab   : {LAB}\",\n",
    "         f\"- Pairs : {len(pairs_payload)}\",\n",
    "         \"\"]\n",
    "for i,P in enumerate(pairs_payload,1):\n",
    "    sb,sh=P[\"spec_base\"],P[\"spec_hold\"]\n",
    "    lines += [\n",
    "        f\"## Pair {i}: `{P['base_key']}`\",\n",
    "        f\"- Base   : **{sb.get('name','?')}**  \\n  doc: `{P['doc_base']}`\",\n",
    "        f\"  - csv: `{sb.get('path','?')}`  \\n    col: `{sb.get('column','?')}`  \\n    rule: `{sb.get('op','?')} {sb.get('value','?')}`  \\n    hash: `{sb.get('hash','—')}`  \\n    rows: {sb.get('rows','?')}\",\n",
    "        f\"- Holdout: **{sh.get('name','?')}**  \\n  doc: `{P['doc_hold']}`\",\n",
    "        f\"  - csv: `{sh.get('path','?')}`  \\n    col: `{sh.get('column','?')}`  \\n    rule: `{sh.get('op','?')} {sh.get('value','?')}`  \\n    hash: `{sh.get('hash','—')}`  \\n    rows: {sh.get('rows','?')}\",\n",
    "        \"\"\n",
    "    ]\n",
    "SEAL_MD.write_text(\"\\n\".join(lines), encoding=\"utf-8\")\n",
    "print(f\"[seal] refreshed → {SEAL_YAML.name}, {SEAL_MD.name}\")\n",
    "\n",
    "# Bundle\n",
    "BUNDLES = ART / \"bundles\"; BUNDLES.mkdir(parents=True, exist_ok=True)\n",
    "BUNDLE  = BUNDLES / f\"cnt_proof_bundle_{datetime.now(timezone.utc).strftime('%Y%m%d-%H%M%S')}_SEAL.zip\"\n",
    "with zipfile.ZipFile(BUNDLE, \"w\", zipfile.ZIP_DEFLATED) as z:\n",
    "    rep_path = Path(REP)\n",
    "    if rep_path.exists():     z.write(rep_path, arcname=rep_path.name)\n",
    "    if STATE.exists():        z.write(STATE, arcname=STATE.name)\n",
    "    if MANIFEST_CSV.exists(): z.write(MANIFEST_CSV, arcname=MANIFEST_CSV.name)\n",
    "    if MANIFEST_YAML.exists():z.write(MANIFEST_YAML, arcname=MANIFEST_YAML.name)\n",
    "    if SEAL_YAML.exists():    z.write(SEAL_YAML, arcname=SEAL_YAML.name)\n",
    "    if SEAL_MD.exists():      z.write(SEAL_MD,   arcname=SEAL_MD.name)\n",
    "    for doc in [DOC_EWB, DOC_COOL, DOC_ATLAS]:\n",
    "        if doc.exists(): z.write(doc, arcname=doc.name)\n",
    "print(f\"[bundle] {BUNDLE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b901738-0b0c-4e5e-994a-0c14d32927a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNT Lab root: E:\\CNT\n",
      "Python: 3.13.5 (tags/v3.13.5:6cb20a2, Jun 11 2025, 16:15:46) [MSC v.1943 64 bit (AMD64)]\n",
      "Torch available: True\n",
      "Creating backup: E:\\CNT_backups\\CNT_backup_20251028-031155.zip\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\caleb\\AppData\\Local\\Temp\\ipykernel_26692\\1132815659.py:19: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n"
     ]
    }
   ],
   "source": [
    "# MEGA CELL: safe backup -> sanity checks -> small canary run\n",
    "# Drop this into your JupyterLab and run. It tries to be defensive and informative.\n",
    "\n",
    "import os, sys, shutil, json, time, traceback\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import subprocess\n",
    "\n",
    "# --- CONFIG (edit if you want different targets) ---\n",
    "LAB_ROOT = Path(os.getenv(\"CNT_LAB_DIR\") or Path.cwd())  # auto-detect or current dir\n",
    "BACKUP_DIR = LAB_ROOT.parent / f\"{LAB_ROOT.name}_backups\"\n",
    "BACKUP_KEEP = 5   # how many previous backups to keep\n",
    "ENGINE_CHECK_CMD = None  # optional shell command to run engine tests, e.g. \"pytest -q\"\n",
    "CANARY_RUN_CELLS = 1      # how many tiny canary cycles to run (keeps short)\n",
    "CANARY_NOTE = \"canary_small_run\"\n",
    "\n",
    "# --- HELPERS ---\n",
    "def now_tag():\n",
    "    return datetime.utcnow().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "def make_zip_backup(src: Path, dest_dir: Path):\n",
    "    dest_dir.mkdir(parents=True, exist_ok=True)\n",
    "    stamp = now_tag()\n",
    "    zip_name = dest_dir / f\"{src.name}_backup_{stamp}.zip\"\n",
    "    print(f\"Creating backup: {zip_name}\")\n",
    "    shutil.make_archive(str(zip_name.with_suffix('')), 'zip', root_dir=str(src))\n",
    "    # rotate\n",
    "    zips = sorted(dest_dir.glob(f\"{src.name}_backup_*.zip\"), key=lambda p: p.stat().st_mtime, reverse=True)\n",
    "    for old in zips[BACKUP_KEEP:]:\n",
    "        try:\n",
    "            old.unlink()\n",
    "            print(f\"Pruned old backup: {old.name}\")\n",
    "        except Exception:\n",
    "            pass\n",
    "    return zip_name\n",
    "\n",
    "def safe_call(func, *a, **kw):\n",
    "    try:\n",
    "        return (\"ok\", func(*a, **kw))\n",
    "    except Exception as e:\n",
    "        tb = traceback.format_exc()\n",
    "        return (\"err\", (e, tb))\n",
    "\n",
    "# --- STEP 0: quick readiness info ---\n",
    "print(\"CNT Lab root:\", LAB_ROOT)\n",
    "print(\"Python:\", sys.version.splitlines()[0])\n",
    "try:\n",
    "    import torch, importlib\n",
    "    has_torch = True\n",
    "except Exception:\n",
    "    has_torch = False\n",
    "print(\"Torch available:\", has_torch)\n",
    "\n",
    "# --- STEP 1: backup (zip snapshot) ---\n",
    "try:\n",
    "    backup_zip = make_zip_backup(LAB_ROOT, BACKUP_DIR)\n",
    "except Exception as e:\n",
    "    print(\"Backup failed (aborting). Reason:\", e)\n",
    "    raise\n",
    "\n",
    "# --- STEP 2: run engine sanity checks (non-destructive) ---\n",
    "sanity = {}\n",
    "# 2a: run a known 'run_cycle' if present\n",
    "try:\n",
    "    # If your engine is a module exposed in the notebook, try to call run_cycle\n",
    "    if 'run_cycle' in globals():\n",
    "        print(\"Found run_cycle() in globals — executing small call...\")\n",
    "        status, res = safe_call(globals()['run_cycle'])\n",
    "        sanity['run_cycle'] = status\n",
    "        sanity['run_cycle_res'] = res if status=='ok' else str(res[0]) + \"\\n\" + res[1]\n",
    "    else:\n",
    "        # try to import cnt_engine from expected path (best-effort)\n",
    "        try:\n",
    "            import cnt_engine\n",
    "            run_cycle = getattr(cnt_engine, 'run_cycle', None)\n",
    "            if callable(run_cycle):\n",
    "                print(\"Imported cnt_engine.run_cycle — executing small call...\")\n",
    "                status, res = safe_call(run_cycle)\n",
    "                sanity['run_cycle'] = status\n",
    "                sanity['run_cycle_res'] = res if status=='ok' else str(res[0]) + \"\\n\" + res[1]\n",
    "            else:\n",
    "                sanity['run_cycle'] = \"missing\"\n",
    "                print(\"cnt_engine.run_cycle not found.\")\n",
    "        except Exception as imp_e:\n",
    "            sanity['run_cycle'] = \"import_fail\"\n",
    "            sanity['run_cycle_err'] = traceback.format_exc()\n",
    "            print(\"Could not import cnt_engine:\", imp_e)\n",
    "except Exception as e:\n",
    "    sanity['run_cycle'] = \"err\"\n",
    "    sanity['run_cycle_err'] = traceback.format_exc()\n",
    "\n",
    "# 2b: discover latest tests_report CSVs in artifacts/out\n",
    "out_dir = LAB_ROOT / \"artifacts\" / \"cnt_engine_megacell\" / \"out\"\n",
    "reports = []\n",
    "if out_dir.exists():\n",
    "    reports = sorted(out_dir.glob(\"tests_report_*.csv\"), key=lambda p: p.stat().st_mtime)\n",
    "    if reports:\n",
    "        print(\"Found test reports; latest:\", reports[-1])\n",
    "        sanity['latest_report'] = str(reports[-1])\n",
    "    else:\n",
    "        print(\"No tests_report_*.csv found in\", out_dir)\n",
    "        sanity['latest_report'] = None\n",
    "else:\n",
    "    print(\"Expected out dir not found:\", out_dir)\n",
    "    sanity['latest_report'] = None\n",
    "\n",
    "# 2c: optional engine test command (pytest or bespoke)\n",
    "if ENGINE_CHECK_CMD:\n",
    "    print(\"Running engine test command:\", ENGINE_CHECK_CMD)\n",
    "    try:\n",
    "        cproc = subprocess.run(ENGINE_CHECK_CMD, shell=True, check=False, capture_output=True, text=True, cwd=str(LAB_ROOT))\n",
    "        sanity['engine_check_cmd'] = dict(returncode=cproc.returncode, stdout=cproc.stdout[:2000], stderr=cproc.stderr[:2000])\n",
    "        print(\"Engine check exit\", cproc.returncode)\n",
    "    except Exception as e:\n",
    "        sanity['engine_check_cmd'] = (\"err\", str(e))\n",
    "        print(\"Engine check command failed:\", e)\n",
    "\n",
    "# --- STEP 3: small CANARY run (non-destructive, short) ---\n",
    "canary = {}\n",
    "try:\n",
    "    # Strategy: run a single lightweight cycle or a \"dry\" run, prefer run_cycle(dry=True) if available\n",
    "    if 'run_cycle' in globals():\n",
    "        rc = globals()['run_cycle']\n",
    "        try:\n",
    "            print(\"Trying run_cycle(dry=True) ...\")\n",
    "            status, r = safe_call(rc)  # call plain first; many of your failures are in sub-functions so plain call is safest\n",
    "            canary['run_cycle_call'] = status\n",
    "            canary['run_cycle_res'] = r if status=='ok' else str(r[0])+\"\\n\"+r[1]\n",
    "        except TypeError:\n",
    "            # fallback: no-arg call attempted above; if it failed earlier, capture\n",
    "            canary['run_cycle_call'] = \"typeerror\"\n",
    "    else:\n",
    "        # fallback: try a tiny file-read and parsing to emulate a canary\n",
    "        print(\"No run_cycle in globals; doing a lightweight file-read canary.\")\n",
    "        sample_paths = list((LAB_ROOT / \"notebooks\" / \"archive\").glob(\"**/*.txt\"))[:3]\n",
    "        sample_info = []\n",
    "        for p in sample_paths:\n",
    "            try:\n",
    "                txt = p.read_text(encoding=\"utf-8\", errors=\"ignore\")[:2000]\n",
    "                sample_info.append((str(p), len(txt)))\n",
    "            except Exception as e:\n",
    "                sample_info.append((str(p), f\"err:{e}\"))\n",
    "        canary['sample_reads'] = sample_info\n",
    "except Exception as e:\n",
    "    canary['err'] = traceback.format_exc()\n",
    "\n",
    "# --- STEP 4: results & recommended decision ---\n",
    "print(\"\\n--- SNAPSHOT & SANITY SUMMARY ---\")\n",
    "print(\"Backup:\", backup_zip)\n",
    "print(json.dumps(sanity, indent=2)[:4000])\n",
    "print(\"\\nCANARY:\", json.dumps(canary, indent=2)[:4000])\n",
    "\n",
    "# Decision heuristic (suggested thresholds, edit if you like)\n",
    "# If run_cycle succeeded or we have at least one recent tests_report with OK count > 0, can proceed with canaries.\n",
    "proceed_reasons = []\n",
    "if sanity.get('run_cycle') == 'ok':\n",
    "    proceed_reasons.append(\"run_cycle succeeded\")\n",
    "if sanity.get('latest_report'):\n",
    "    try:\n",
    "        import pandas as pd\n",
    "        rep = pd.read_csv(sanity['latest_report'])\n",
    "        ok_count = rep['reason'].eq('ok').sum() if 'reason' in rep.columns else None\n",
    "        if ok_count and ok_count > 0:\n",
    "            proceed_reasons.append(f\"latest tests_report OK count = {ok_count}\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "if proceed_reasons:\n",
    "    print(\"\\nRecommendation: OK to begin limited 'attacks' (canary experiments). Reasons:\", proceed_reasons)\n",
    "    print(\"Suggested play: run 1-3 small canary experiments, monitor logs, then scale.\")\n",
    "    print(\"Suggested safety steps (do before heavy runs):\")\n",
    "    print(\"  1) git commit / tag current state or rely on created backup zip.\")\n",
    "    print(\"  2) run a single canary on a small dataset/segment.\")\n",
    "    print(\"  3) inspect tests_report_* CSV and engine logs; if any 'pair_fail' or 'needs_holdout' appear, pause and fix.\")\n",
    "else:\n",
    "    print(\"\\nRecommendation: do NOT run large experiments yet. Fix the failing/`needs_holdout` tests first.\")\n",
    "    print(\"Common quick fixes based on your recent errors:\")\n",
    "    print(\"  * ensure `glob` is imported from the stdlib: `from glob import glob` (your traceback showed `glob` was a function object).\")\n",
    "    print(\"  * watch for pandas Index vs list: replace `.index.index` mistaken calls with `.to_list()` or `.tolist()`.\")\n",
    "    print(\"  * rerun the mega cell tests after fixing the two errors (glob and Index.index).\")\n",
    "    print(\"  * re-run this mega cell after fixes to get a fresh backup + sanity check.\")\n",
    "    print(\"\\nIf you want I can also produce a targeted one-cell patch to fix the two specific tracebacks you saw (the `glob` misuse and the `Index.index` misuse).\")\n",
    "\n",
    "# --- final metadata write (helpful ledger) ---\n",
    "ledger = {\n",
    "    \"stamp\": now_tag(),\n",
    "    \"lab_root\": str(LAB_ROOT),\n",
    "    \"backup\": str(backup_zip),\n",
    "    \"sanity\": sanity,\n",
    "    \"canary\": canary,\n",
    "}\n",
    "ledger_file = BACKUP_DIR / f\"sanity_ledger_{now_tag()}.json\"\n",
    "try:\n",
    "    ledger_file.write_text(json.dumps(ledger, indent=2))\n",
    "    print(\"Wrote ledger:\", ledger_file)\n",
    "except Exception as e:\n",
    "    print(\"Failed to write ledger:\", e)\n",
    "\n",
    "# Return summary object for notebook consumption\n",
    "ledger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167a9fa1-b247-45c5-bb02-246ef718ca74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CNT Lab (Py3.13)",
   "language": "python",
   "name": "cnt_lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
